__FILENAME__ = Category
# written by Yuan Yuan, Jelle Roozenburg
# see LICENSE.txt for license information

import os
import re
import logging

from Tribler import LIBRARYNAME
from Tribler.Category.init_category import getCategoryInfo
from Tribler.Category.FamilyFilter import XXXFilter

CATEGORY_CONFIG_FILE = "category.conf"

class Category:

    # Code to make this a singleton
    __single = None
    __size_change = 1024 * 1024

    def __init__(self, install_dir='.', ffEnabled=False):
        self._logger = logging.getLogger(self.__class__.__name__)

        if Category.__single:
            raise RuntimeError("Category is singleton")
        filename = os.path.join(install_dir, LIBRARYNAME, 'Category', CATEGORY_CONFIG_FILE)
        Category.__single = self
        try:
            self.category_info = getCategoryInfo(filename)
            self.category_info.sort(cmp_rank)
        except:
            self.category_info = []
            self._logger.critical('', exc_info=True)

        self.xxx_filter = XXXFilter(install_dir)

        self._logger.debug("category: Categories defined by user: %s", self.getCategoryNames())

        self.ffEnabled = ffEnabled
        self.set_family_filter(None)

    # return Category instance
    def getInstance(*args, **kw):
        if Category.__single is None:
            Category(*args, **kw)
        return Category.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        Category.__single = None
    delInstance = staticmethod(delInstance)

    def getCategoryNames(self, filter=True):
        if self.category_info is None:
            return []
        keys = []
        for category in self.category_info:
            rank = category['rank']
            if rank == -1 and filter:
                break
            keys.append((category['name'], category['displayname']))
        return keys

    # calculate the category for a given torrent_dict of a torrent file
    # return list
    def calculateCategory(self, torrent_dict, display_name):
        # torrent_dict is the  dict of
        # a torrent file
        # return value: list of category the torrent belongs to

        files_list = []
        try:
            # the multi-files mode
            for ifiles in torrent_dict['info']["files"]:
                files_list.append((ifiles['path'][-1], ifiles['length'] / float(self.__size_change)))
        except KeyError:
            # single mode
            files_list.append((torrent_dict['info']["name"], torrent_dict['info']['length'] / float(self.__size_change)))

        tracker = torrent_dict.get('announce')
        if not tracker:
            tracker = torrent_dict.get('announce-list', [['']])[0][0]

        comment = torrent_dict.get('comment')
        return self.calculateCategoryNonDict(files_list, display_name, tracker, comment)

    def calculateCategoryNonDict(self, files_list, display_name, tracker, comment):
        # Check xxx
        try:

            if self.xxx_filter.isXXXTorrent(files_list, display_name, tracker, comment):
                return ['xxx']
        except:
            self._logger.critical('Category: Exception in explicit terms filter in torrent: %s', display_name, exc_info=True)

        torrent_category = None
        # filename_list ready
        strongest_cat = 0.0
        for category in self.category_info:  # for each category
            (decision, strength) = self.judge(category, files_list, display_name)
            if decision and (strength > strongest_cat):
                torrent_category = [category['name']]
                strongest_cat = strength

        if torrent_category == None:
            torrent_category = ['other']

        return torrent_category

    # judge whether a torrent file belongs to a certain category
    # return bool
    def judge(self, category, files_list, display_name=''):

        # judge file keywords
        display_name = display_name.lower()
        factor = 1.0
        fileKeywords = self._getWords(display_name)

        for ikeywords in category['keywords'].keys():
            try:
                fileKeywords.index(ikeywords)
                factor *= 1 - category['keywords'][ikeywords]
            except:
                pass
        if (1 - factor) > 0.5:
            if 'strength' in category:
                return (True, category['strength'])
            else:
                return (True, (1 - factor))

        # judge each file
        matchSize = 0
        totalSize = 1e-19
        for name, length in files_list:
            totalSize += length
            # judge file size
            if (length < category['minfilesize']) or \
                    (category['maxfilesize'] > 0 and length > category['maxfilesize']):
                continue

            # judge file suffix
            OK = False
            for isuffix in category['suffix']:
                if name.lower().endswith(isuffix):
                    OK = True
                    break
            if OK:
                matchSize += length
                continue

            # judge file keywords
            factor = 1.0
            fileKeywords = self._getWords(name.lower())

            for ikeywords in category['keywords'].keys():
                try:
                    fileKeywords.index(ikeywords)
                    # print ikeywords
                    factor *= 1 - category['keywords'][ikeywords]
                except:
                    pass
            if factor < 0.5:
                matchSize += length

        # match file
        if (matchSize / totalSize) >= category['matchpercentage']:
            if 'strength' in category:
                return (True, category['strength'])
            else:
                return (True, (matchSize / totalSize))

        return (False, 0)

    WORDS_REGEXP = re.compile('[a-zA-Z0-9]+')

    def _getWords(self, string):
        return self.WORDS_REGEXP.findall(string)

    def family_filter_enabled(self):
        """
        Return is xxx filtering is enabled in this client
        """
        return self.ffEnabled

    def set_family_filter(self, b=None):
        assert b in (True, False, None)
        old = self.family_filter_enabled()
        if b != old or b is None:  # update category data if initial call, or if state changes
            if b is None:
                b = old

            self.ffEnabled = b

            # change category data
            for category in self.category_info:
                if category['name'] == 'xxx':
                    if b:
                        category['old-rank'] = category['rank']
                        category['rank'] = -1
                    elif category['rank'] == -1:
                        category['rank'] = category['old-rank']
                    break

    def get_family_filter_sql(self, _getCategoryID, table_name=''):
        if self.family_filter_enabled():
            forbiddencats = [cat['name'] for cat in self.category_info if cat['rank'] == -1]
            if table_name:
                table_name += '.'
            if forbiddencats:
                return " and %scategory_id not in (%s)" % (table_name, ','.join([str(_getCategoryID([cat])) for cat in forbiddencats]))
        return ''


def cmp_rank(a, b):
    if not ('rank' in a):
        return 1
    elif not ('rank' in b):
        return -1
    elif a['rank'] == -1:
        return 1
    elif b['rank'] == -1:
        return -1
    elif a['rank'] == b['rank']:
        return 0
    elif a['rank'] < b['rank']:
        return -1
    else:
        return 1

########NEW FILE########
__FILENAME__ = FamilyFilter
# Written by Jelle Roozenburg
# see LICENSE.txt for license information

import re
import os
import logging

from Tribler import LIBRARYNAME

WORDS_REGEXP = re.compile('[a-zA-Z0-9]+')

class XXXFilter(object):

    def __init__(self, install_dir):
        super(XXXFilter, self).__init__()
        self._logger = logging.getLogger(self.__class__.__name__)

        termfilename = os.path.join(install_dir, LIBRARYNAME, 'Category', 'filter_terms.filter')
        self.xxx_terms, self.xxx_searchterms = self.initTerms(termfilename)

    def initTerms(self, filename):
        terms = set()
        searchterms = set()

        try:
            f = file(filename, 'r')
            lines = f.read().lower().splitlines()

            for line in lines:
                if line.startswith('*'):
                    searchterms.add(line[1:])
                else:
                    terms.add(line)
            f.close()
        except:
            self._logger.exception(u"Failed to init terms.")

        self._logger.debug('Read %d XXX terms from file %s', len(terms) + len(searchterms), filename)
        return terms, searchterms

    def _getWords(self, string):
        return [a.lower() for a in WORDS_REGEXP.findall(string)]

    def isXXXTorrent(self, files_list, torrent_name, tracker, comment=None):
        if tracker:
            tracker = tracker.lower().replace('http://', '').replace('announce', '')
        else:
            tracker = ''
        terms = [a[0].lower() for a in files_list]
        is_xxx = (self.isXXX(torrent_name, False) or
                  self.isXXX(tracker, False) or
                  any(self.isXXX(term) for term in terms) or
                  (comment and self.isXXX(comment, False))
                  )
        if is_xxx:
            self._logger.debug('Torrent is XXX: %s %s', torrent_name, tracker)
        else:
            self._logger.debug('Torrent is NOT XXX: %s %s', torrent_name, tracker)
        return is_xxx

    def isXXX(self, s, isFilename=True):
        s = s.lower()
        if self.isXXXTerm(s):  # We have also put some full titles in the filter file
            return True
        if not self.isAudio(s) and self.foundXXXTerm(s):
            return True
        words = self._getWords(s)
        words2 = [' '.join(words[i:i + 2]) for i in xrange(0, len(words) -1)]
        num_xxx = len([w for w in words + words2 if self.isXXXTerm(w, s)])
        if isFilename and self.isAudio(s):
            return num_xxx > 2  # almost never classify mp3 as porn
        else:
            return num_xxx > 0

    def foundXXXTerm(self, s):
        for term in self.xxx_searchterms:
            if term in s:
                self._logger.debug('XXXFilter: Found term "%s" in %s', term, s)
                return True
        return False

    def isXXXTerm(self, s, title=None):
        # check if term-(e)s is in xxx-terms
        s = s.lower()
        if s in self.xxx_terms:
            self._logger.debug('XXXFilter: "%s" is dirty%s', s, title and ' in %s' % title or '')
            return True
        if s.endswith('es'):
            if s[:-2] in self.xxx_terms:
                self._logger.debug('XXXFilter: "%s" is dirty%s', s[:-2], title and ' in %s' % title or '')
                return True
        elif s.endswith('s') or s.endswith('n'):
            if s[:-1] in self.xxx_terms:
                self._logger.debug('XXXFilter: "%s" is dirty%s', s[:-1], title and ' in %s' % title or '')
                return True

        return False

    audio_extensions = ['cda', 'flac', 'm3u', 'mp2', 'mp3', 'md5', 'vorbis', 'wav', 'wma', 'ogg']

    def isAudio(self, s):
        return s[s.rfind('.') + 1:] in self.audio_extensions

########NEW FILE########
__FILENAME__ = init_category
# Written by Yuan Yuan
# see LICENSE.txt for license information

# give the initial category information

import ConfigParser

def __split_list(string):
    the_list = []
    for word in string.split(","):
        word = word.strip()
        the_list.append(word)
    return the_list

INIT_FUNC_DICT = {
    "minfilenumber": int,
    "maxfilenumber": int,
    "minfilesize":int,
    "maxfilesize": int,
    "suffix": __split_list,
    "matchpercentage": float,
    "keywords": float,
    "strength": float,
    "displayname": str,
    "rank": int
}


def __get_default():
    category = {}
    category["name"] = ""
    category["keywords"] = {}
    category["suffix"] = []
    category["minfilesize"] = 0
    category["maxfilesize"] = -1
    return category

def getCategoryInfo(filename):
    config = ConfigParser.ConfigParser()
    config.readfp(open(filename))

    cate_list = []
    sections = config.sections()

    for isection in sections:
        category = __get_default()
        category["name"] = isection
        for (name, value) in config.items(isection):
            if name[0] != "*":
                category[name] = INIT_FUNC_DICT[name](value)
            else:
                name = name[1:]
                name = name.strip()
                category["keywords"][name] = INIT_FUNC_DICT["keywords"](value)
        cate_list.append(category)

    return cate_list

########NEW FILE########
__FILENAME__ = community
import logging
from random import sample
from time import time
from traceback import print_exc

from twisted.internet.task import LoopingCall
from twisted.python.threadable import isInIOThread

from .conversion import AllChannelConversion
from Tribler.community.allchannel.message import DelayMessageReqChannelMessage
from Tribler.community.allchannel.payload import (ChannelCastRequestPayload, ChannelCastPayload, VoteCastPayload,
                                                  ChannelSearchPayload, ChannelSearchResponsePayload)
from Tribler.community.channel.community import ChannelCommunity
from Tribler.community.channel.preview import PreviewChannelCommunity
from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.database import IgnoreCommits
from Tribler.dispersy.destination import CandidateDestination, CommunityDestination
from Tribler.dispersy.distribution import FullSyncDistribution, DirectDistribution
from Tribler.dispersy.exception import CommunityNotFoundException
from Tribler.dispersy.message import Message, BatchConfiguration
from Tribler.dispersy.resolution import PublicResolution


if __debug__:
    from Tribler.dispersy.tool.lencoder import log

logger = logging.getLogger(__name__)


CHANNELCAST_FIRST_MESSAGE = 3.0
CHANNELCAST_INTERVAL = 15.0
CHANNELCAST_BLOCK_PERIOD = 10.0 * 60.0  # block for 10 minutes
UNLOAD_COMMUNITY_INTERVAL = 60.0

DEBUG = False


class AllChannelCommunity(Community):

    """
    A single community that all Tribler members join and use to disseminate .torrent files.

    The dissemination of .torrent files, using 'community-propagate' messages, is NOT done using a
    dispersy sync mechanism.  We prefer more specific dissemination mechanism than dispersy
    provides.  Dissemination occurs by periodically sending:

     - N most recently received .torrent files
     - M random .torrent files
     - O most recent .torrent files, created by ourselves
     - P randomly choosen .torrent files, created by ourselves
    """
    @classmethod
    def get_master_members(cls, dispersy):
# generated: Fri Nov 25 10:51:27 2011
# curve: high <<< NID_sect571r1 >>>
# len: 571 bits ~ 144 bytes signature
# pub: 170 3081a7301006072a8648ce3d020106052b81040027038192000405548a13626683d4788ab19393fa15c9e9d6f5ce0ff47737747fa511af6c4e956f523dc3d1ae8d7b83b850f21ab157dd4320331e2f136aa01e70d8c96df665acd653725e767da9b5079f25cebea808832cd16015815797906e90753d135ed2d796b9dfbafaf1eae2ebea3b8846716c15814e96b93ae0f5ffaec44129688a38ea35f879205fdbe117323e73076561f112
# pub-sha1 8164f55c2f828738fa779570e4605a81fec95c9d
# -----BEGIN PUBLIC KEY-----
# MIGnMBAGByqGSM49AgEGBSuBBAAnA4GSAAQFVIoTYmaD1HiKsZOT+hXJ6db1zg/0
# dzd0f6URr2xOlW9SPcPRro17g7hQ8hqxV91DIDMeLxNqoB5w2Mlt9mWs1lNyXnZ9
# qbUHnyXOvqgIgyzRYBWBV5eQbpB1PRNe0teWud+6+vHq4uvqO4hGcWwVgU6WuTrg
# 9f+uxEEpaIo46jX4eSBf2+EXMj5zB2Vh8RI=
# -----END PUBLIC KEY-----
        master_key = "3081a7301006072a8648ce3d020106052b81040027038192000405548a13626683d4788ab19393fa15c9e9d6f5ce0ff47737747fa511af6c4e956f523dc3d1ae8d7b83b850f21ab157dd4320331e2f136aa01e70d8c96df665acd653725e767da9b5079f25cebea808832cd16015815797906e90753d135ed2d796b9dfbafaf1eae2ebea3b8846716c15814e96b93ae0f5ffaec44129688a38ea35f879205fdbe117323e73076561f112".decode("HEX")
        master = dispersy.get_member(public_key=master_key)
        return [master]

    @property
    def dispersy_sync_bloom_filter_strategy(self):
        return self._dispersy_claim_sync_bloom_filter_modulo

    def initiate_meta_messages(self):
        batch_delay = 1.0

        return super(AllChannelCommunity, self).initiate_meta_messages() + [
            Message(self, u"channelcast",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    ChannelCastPayload(),
                    self.check_channelcast,
                    self.on_channelcast),
            Message(self, u"channelcast-request",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    ChannelCastRequestPayload(),
                    self.check_channelcast_request,
                    self.on_channelcast_request),
            Message(self, u"channelsearch",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CommunityDestination(node_count=10),
                    ChannelSearchPayload(),
                    self.check_channelsearch,
                    self.on_channelsearch),
            Message(self, u"channelsearch-response",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    ChannelSearchResponsePayload(),
                    self.check_channelsearch_response,
                    self.on_channelsearch_response),
            Message(self, u"votecast",
                    MemberAuthentication(),
                    PublicResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10),
                    VoteCastPayload(),
                    self.check_votecast,
                    self.on_votecast,
                    self.undo_votecast,
                    batch=BatchConfiguration(max_window=batch_delay))
                ]

    def initialize(self, integrate_with_tribler=True, auto_join_channel=False):
        super(AllChannelCommunity, self).initialize()

        self._logger = logging.getLogger(self.__class__.__name__)

        self._blocklist = {}
        self._searchCallbacks = {}
        self._recentlyRequested = []
        self.integrate_with_tribler = integrate_with_tribler
        self.auto_join_channel = auto_join_channel

        if self.integrate_with_tribler:
            from Tribler.Core.CacheDB.SqliteCacheDBHandler import ChannelCastDBHandler, VoteCastDBHandler, PeerDBHandler

            # tribler channelcast database
            self._channelcast_db = ChannelCastDBHandler.getInstance()
            self._votecast_db = VoteCastDBHandler.getInstance()
            self._peer_db = PeerDBHandler.getInstance()

        else:
            self._channelcast_db = ChannelCastDBStub(self._dispersy)
            self._votecast_db = VoteCastDBStub(self._dispersy)
            self._peer_db = PeerDBStub(self._dispersy)

        # TODO(emilon): Have a generic superclass for classes that keep track of tasks
        self._pending_tasks["channelcast"] = lc = LoopingCall(self.create_channelcast)
        lc.start(CHANNELCAST_FIRST_MESSAGE, now=True)

        self._pending_tasks["unload preview"] = dc = LoopingCall(self.unload_preview)
        dc.start(UNLOAD_COMMUNITY_INTERVAL, now=False)

    def initiate_conversions(self):
        return [DefaultConversion(self), AllChannelConversion(self)]

    @property
    def dispersy_auto_download_master_member(self):
        # there is no dispersy-identity for the master member, so don't try to download
        return False

    @property
    def dispersy_sync_response_limit(self):
        return 25 * 1024

    def create_channelcast(self):
        assert isInIOThread()
        now = time()

        favoriteTorrents = None
        normalTorrents = None

        # cleanup blocklist
        for candidate in self._blocklist.keys():
            if self._blocklist[candidate] + CHANNELCAST_BLOCK_PERIOD < now:  # unblock address
                self._blocklist.pop(candidate)

        mychannel_id = self._channelcast_db.getMyChannelId()

        # loop through all candidates to see if we can find a non-blocked address
        for candidate in [candidate for candidate in self._iter_categories([u'walk', u'stumble'], once=True) if not candidate in self._blocklist]:
            if not candidate:
                continue

            didFavorite = False
            # only check if we actually have a channel
            if mychannel_id:
                peer_ids = set()
                key = candidate.get_member().public_key
                peer_ids.add(self._peer_db.addOrGetPeerID(key))

                # see if all members on this address are subscribed to my channel
                didFavorite = len(peer_ids) > 0
                for peer_id in peer_ids:
                    vote = self._votecast_db.getVoteForMyChannel(peer_id)
                    if vote != 2:
                        didFavorite = False
                        break

            # Modify type of message depending on if all peers have marked my channels as their favorite
            if didFavorite:
                if not favoriteTorrents:
                    favoriteTorrents = self._channelcast_db.getRecentAndRandomTorrents(0, 0, 25, 25, 5)
                torrents = favoriteTorrents
            else:
                if not normalTorrents:
                    normalTorrents = self._channelcast_db.getRecentAndRandomTorrents()
                torrents = normalTorrents

            if len(torrents) > 0:
                meta = self.get_meta_message(u"channelcast")
                message = meta.impl(authentication=(self._my_member,),
                                    distribution=(self.global_time,), destination=(candidate,), payload=(torrents,))

                self._dispersy._forward([message])

                # we've send something to this address, add to blocklist
                self._blocklist[candidate] = now

                nr_torrents = sum(len(torrent) for torrent in torrents.values())
                self._logger.debug("sending channelcast message containing %s torrents to %s didFavorite %s", nr_torrents, candidate.sock_addr, didFavorite)

                # we're done
                break

        else:
            self._logger.debug("Did not send channelcast messages, no candidates or torrents")

    def get_nr_connections(self):
        return len(list(self.dispersy_yield_candidates()))

    def check_channelcast(self, messages):
        with self._dispersy.database:
            for message in messages:
                for cid in message.payload.torrents.keys():
                    channel_id = self._get_channel_id(cid)
                    if not channel_id:
                        community = self._get_channel_community(cid)
                        yield DelayMessageReqChannelMessage(message, community, includeSnapshot=True)
                        break
                else:
                    yield message

            # ensure that no commits occur
            raise IgnoreCommits()

    def on_channelcast(self, messages):
        for message in messages:
            toCollect = {}
            for cid, torrents in message.payload.torrents.iteritems():
                for infohash in self._selectTorrentsToCollect(cid, torrents):
                    toCollect.setdefault(cid, set()).add(infohash)

            nr_requests = sum([len(torrents) for torrents in toCollect.values()])
            if nr_requests > 0:
                self.create_channelcast_request(toCollect, message.candidate)

    def create_channelcast_request(self, toCollect, candidate):
        # create channelcast request message
        meta = self.get_meta_message(u"channelcast-request")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), destination=(candidate,), payload=(toCollect,))
        self._dispersy._forward([message])

        nr_requests = sum([len(torrents) for torrents in toCollect.values()])
        self._logger.debug("requesting %s torrents from %s", nr_requests, candidate)

    def check_channelcast_request(self, messages):
        # no timeline check because PublicResolution policy is used
        return messages

    def on_channelcast_request(self, messages):
        for message in messages:
            requested_packets = []
            for cid, torrents in message.payload.torrents.iteritems():
                requested_packets.extend(self._get_packets_from_infohashes(cid, torrents))

            if requested_packets:
                self._dispersy._send_packets([message.candidate], requested_packets,
                    self, "-caused by channelcast-request-")

            self._logger.debug("got request for %s torrents from %s", len(requested_packets), message.candidate)

    def create_channelsearch(self, keywords, callback):
        # clear searchcallbacks if new search
        query = " ".join(keywords)
        if query not in self._searchCallbacks:
            self._searchCallbacks.clear()
        self._searchCallbacks.setdefault(query, set()).add(callback)

        meta = self.get_meta_message(u"channelsearch")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,),
                            payload=(keywords,))

        self._logger.debug("searching for channel matching '%s'", query)

        return self._dispersy._forward([message])

    def check_channelsearch(self, messages):
        # no timeline check because PublicResolution policy is used
        return messages

    def on_channelsearch(self, messages):
        for message in messages:
            keywords = message.payload.keywords
            query = " ".join(keywords)

            self._logger.debug("got search request for '%s'", query)

            results = self._channelcast_db.searchChannelsTorrent(query, 7, 7, dispersyOnly=True)
            if len(results) > 0:
                responsedict = {}
                for channel_id, dispersy_cid, name, infohash, torname, time_stamp in results:
                    infohashes = responsedict.setdefault(dispersy_cid, set())
                    infohashes.add(infohash)

                    self._logger.debug("found cid: %s infohash: %s", dispersy_cid.encode("HEX"), infohash.encode("HEX"))

                self.create_channelsearch_response(keywords, responsedict, message.candidate)

            else:
                self._logger.debug("no results")

    def create_channelsearch_response(self, keywords, torrents, candidate):
        # create channelsearch-response message
        meta = self.get_meta_message(u"channelsearch-response")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), destination=(candidate,), payload=(keywords, torrents))

        self._dispersy._forward([message])

        nr_requests = sum([len(tors) for tors in torrents.values()])
        self._logger.debug("sending %s results", nr_requests)

    def check_channelsearch_response(self, messages):
        with self._dispersy.database:
            for message in messages:
                for cid in message.payload.torrents.keys():
                    channel_id = self._get_channel_id(cid)
                    if not channel_id:
                        community = self._get_channel_community(cid)
                        yield DelayMessageReqChannelMessage(message, community, includeSnapshot=True)
                        break
                else:
                    yield message

            # ensure that no commits occur
            raise IgnoreCommits()

    def on_channelsearch_response(self, messages):
        # request missing torrents
        self.on_channelcast(messages)

        for message in messages:
            # show results in gui
            keywords = message.payload.keywords
            query = " ".join(keywords)

            self._logger.debug("got search response for '%s'", query)

            if query in self._searchCallbacks:
                torrents = message.payload.torrents
                for callback in self._searchCallbacks[query]:
                    callback(keywords, torrents)

    def disp_create_votecast(self, cid, vote, timestamp, store=True, update=True, forward=True):
        # reclassify community
        if vote == 2:
            communityclass = ChannelCommunity
        else:
            communityclass = PreviewChannelCommunity

        community = self._get_channel_community(cid)
        community = self.dispersy.reclassify_community(community, communityclass)

        # check if we need to cancel a previous vote
        latest_dispersy_id = self._votecast_db.get_latest_vote_dispersy_id(community._channel_id, None)
        if latest_dispersy_id:
            message = self._dispersy.load_message_by_packetid(self, latest_dispersy_id)
            if message:
                self._dispersy.create_undo(self, message)

        # create new vote message
        meta = self.get_meta_message(u"votecast")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(cid, vote, timestamp))
        self._dispersy.store_update_forward([message], store, update, forward)

        return message

    def check_votecast(self, messages):
        with self._dispersy.database:
            communities = {}
            channel_ids = {}
            for cid in set([message.payload.cid for message in messages]):
                channel_id = self._get_channel_id(cid)
                if channel_id:
                    channel_ids[cid] = channel_id
                else:
                    communities[cid] = self._get_channel_community(cid)

            for message in messages:
                community = communities.get(message.payload.cid)
                if community:
                    # at this point we should NOT have the channel message for this community
                    if __debug__:
                        try:
                            self._dispersy.database.execute(u"SELECT * FROM sync WHERE community = ? AND meta_message = ? AND undone = 0", (community.database_id, community.get_meta_message(u"channel").database_id)).next()
                            self._logger.error("We already have the channel message... no need to wait for it %s", community.cid.encode("HEX"))
                        except StopIteration:
                            pass

                    logger.debug("Did not receive channel, requesting channel message '%s' from %s", community.cid.encode("HEX"), message.candidate.sock_addr)
                    yield DelayMessageReqChannelMessage(message, community, includeSnapshot=message.payload.vote > 0)  # request torrents if positive vote

                else:
                    message.channel_id = channel_ids[message.payload.cid]
                    yield message

            # ensure that no commits occur
            raise IgnoreCommits()

    def on_votecast(self, messages):
        if self.integrate_with_tribler:
            votelist = []
            for message in messages:
                dispersy_id = message.packet_id
                channel_id = getattr(message, "channel_id", 0)

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None

                    # if channel_id is not found, then this is a manual join
                    # insert placeholder into database which will be replaced after channelmessage has been received
                    if not channel_id:
                        select_channel = "SELECT id FROM _Channels WHERE dispersy_cid = ?"
                        channel_id = self._channelcast_db._db.fetchone(select_channel, (buffer(message.payload.cid),))

                        if not channel_id:
                            insert_channel = "INSERT INTO _Channels (dispersy_cid, peer_id, name) VALUES (?, ?, ?); SELECT last_insert_rowid();"
                            channel_id = self._channelcast_db._db.fetchone(insert_channel, (buffer(message.payload.cid), -1, ''))
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                votelist.append((channel_id, peer_id, dispersy_id, message.payload.vote, message.payload.timestamp))

            self._votecast_db.on_votes_from_dispersy(votelist)

    def undo_votecast(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            contains_my_vote = False
            votelist = []
            now = long(time())
            for _, _, packet in descriptors:
                message = packet.load_message()
                dispersy_id = message.packet_id

                channel_id = self._get_channel_id(message.payload.cid)
                votelist.append((None if redo else now, channel_id, dispersy_id))

                authentication_member = message.authentication.member
                my_vote = authentication_member == self._my_member
                if my_vote:
                    contains_my_vote = True

            self._votecast_db.on_remove_votes_from_dispersy(votelist, contains_my_vote)

    def _get_channel_community(self, cid):
        assert isinstance(cid, str)
        assert len(cid) == 20

        try:
            return self._dispersy.get_community(cid, True)
        except CommunityNotFoundException:
            if self.auto_join_channel:
                logger.info("join channel community %s", cid.encode("HEX"))
                return ChannelCommunity.init_community(self._dispersy, self._dispersy.get_member(mid=cid), self._my_member, self.integrate_with_tribler)
            else:
                logger.info("join preview community %s", cid.encode("HEX"))
                return PreviewChannelCommunity.init_community(self._dispersy, self._dispersy.get_member(mid=cid), self._my_member, self.integrate_with_tribler)

    def unload_preview(self):
        cleanpoint = time() - 300
        inactive = [community for community in self.dispersy._communities.itervalues() if isinstance(community, PreviewChannelCommunity) and community.init_timestamp < cleanpoint]
        logger.debug("cleaning %d/%d previewchannel communities", len(inactive), len(self.dispersy._communities))

        for community in inactive:
            community.unload_community()

    def _get_channel_id(self, cid):
        assert isinstance(cid, str)
        assert len(cid) == 20

        return self._channelcast_db.getChannelIdFromDispersyCID(buffer(cid))

    def _selectTorrentsToCollect(self, cid, infohashes):
        channel_id = self._get_channel_id(cid)

        row = self._channelcast_db.getCountMaxFromChannelId(channel_id)
        if row:
            nrTorrrents, latestUpdate = row
        else:
            nrTorrrents = 0
            latestUpdate = 0

        collect = []

        # filter infohashes using recentlyRequested
        infohashes = filter(lambda infohash: infohash not in self._recentlyRequested, infohashes)

        # only request updates if nrT < 100 or we have not received an update in the last half hour
        if nrTorrrents < 100 or latestUpdate < (time() - 1800):
            infohashes = list(infohashes)
            haveTorrents = self._channelcast_db.hasTorrents(channel_id, infohashes)
            for i in range(len(infohashes)):
                if not haveTorrents[i]:
                    collect.append(infohashes[i])

        self._recentlyRequested.extend(collect)
        self._recentlyRequested = self._recentlyRequested[:100]

        return collect

    def _get_packets_from_infohashes(self, cid, infohashes):
        assert all(isinstance(infohash, str) for infohash in infohashes)
        assert all(len(infohash) == 20 for infohash in infohashes)

        channel_id = self._get_channel_id(cid)

        packets = []
        for infohash in infohashes:
            dispersy_id = self._channelcast_db.getTorrentFromChannelId(channel_id, infohash, ['ChannelTorrents.dispersy_id'])

            if dispersy_id and dispersy_id > 0:
                try:
                    # 2. get the message
                    packets.append(self._get_packet_from_dispersy_id(dispersy_id, "torrent"))
                except RuntimeError:
                    pass

        return packets

    def _get_packet_from_dispersy_id(self, dispersy_id, messagename):
        try:
            packet, = self._dispersy.database.execute(u"SELECT sync.packet FROM community JOIN sync ON sync.community = community.id WHERE sync.id = ?", (dispersy_id,)).next()
        except StopIteration:
            raise RuntimeError("Unknown dispersy_id")
        return str(packet)

    def _drop_all_newer(self, dispersy_id):
        self._channelcast_db.drop_all_newer(dispersy_id)


class ChannelCastDBStub():

    def __init__(self, dispersy):
        self._dispersy = dispersy
        self.channel_id = None
        self.mychannel = False
        self.latest_result = 0

        self.cachedTorrents = None
        self.recentTorrents = []

    def convert_to_messages(self, results):
        messages = self._dispersy.convert_packets_to_messages(str(packet) for packet, _ in results)
        for packet_id, message in zip((packet_id for _, packet_id in results), messages):
            if message:
                message.packet_id = packet_id
                yield message.community.cid, message

    def getChannelIdFromDispersyCID(self, cid):
        return self.channel_id

    def getCountMaxFromChannelId(self, channel_id):
        if self.cachedTorrents:
            return len(self.cachedTorrents), self.latest_result

    def getRecentAndRandomTorrents(self, NUM_OWN_RECENT_TORRENTS=15, NUM_OWN_RANDOM_TORRENTS=10, NUM_OTHERS_RECENT_TORRENTS=15, NUM_OTHERS_RANDOM_TORRENTS=10, NUM_OTHERS_DOWNLOADED=5):
        torrent_dict = {}

        for _, payload in self.recentTorrents[:max(NUM_OWN_RECENT_TORRENTS, NUM_OTHERS_RECENT_TORRENTS)]:
            torrent_dict.setdefault(self.channel_id, set()).add(payload.infohash)

        if len(self.recentTorrents) >= NUM_OWN_RECENT_TORRENTS:
            for infohash in self.getRandomTorrents(self.channel_id, max(NUM_OWN_RANDOM_TORRENTS, NUM_OTHERS_RANDOM_TORRENTS)):
                torrent_dict.setdefault(self.channel_id, set()).add(infohash)

        return torrent_dict

    def getRandomTorrents(self, channel_id, limit=15):
        torrents = self._cachedTorrents.keys()
        if len(torrents) > limit:
            return sample(torrents, limit)
        return torrents

    def newTorrent(self, message):
        self._cachedTorrents[message.payload.infohash] = message

        self.recentTorrents.append((message.distribution.global_time, message.payload))
        self.recentTorrents.sort(reverse=True)
        self.recentTorrents[:50]

        self.latest_result = time()

    def setChannelId(self, channel_id, mychannel):
        self.channel_id = channel_id
        self.mychannel = mychannel

    def getMyChannelId(self):
        if self.mychannel:
            return self.channel_id

    def hasTorrents(self, channel_id, infohashes):
        returnAr = []
        for infohash in infohashes:
            if infohash in self._cachedTorrents:
                returnAr.append(True)
            else:
                returnAr.append(False)
        return returnAr

    def getTorrentFromChannelId(self, channel_id, infohash, keys):
        if infohash in self._cachedTorrents:
            return self._cachedTorrents[infohash].packet_id

    def on_dynamic_settings(self, channel_id):
        pass

    @property
    def _cachedTorrents(self):
        if self.cachedTorrents is None:
            self.cachedTorrents = {}
            self._cacheTorrents()

        return self.cachedTorrents

    def _cacheTorrents(self):
        sql = u"SELECT sync.packet, sync.id FROM sync JOIN meta_message ON sync.meta_message = meta_message.id JOIN community ON community.id = sync.community WHERE meta_message.name = 'torrent'"
        results = list(self._dispersy.database.execute(sql))
        messages = self.convert_to_messages(results)

        for _, message in messages:
            self._cachedTorrents[message.payload.infohash] = message
            self.recentTorrents.append((message.distribution.global_time, message.payload))

        self.recentTorrents.sort(reverse=True)
        self.recentTorrents[:50]


class VoteCastDBStub():

    def __init__(self, dispersy):
        self._dispersy = dispersy
        self._votecache = {}

    def getDispersyId(self, cid, public_key):
        if public_key in self._votecache:
            return self._votecache[public_key]

        sql = u"SELECT sync.id FROM sync JOIN member ON sync.member = member.id JOIN community ON community.id = sync.community JOIN meta_message ON sync.meta_message = meta_message.id WHERE community.classification = 'AllChannelCommunity' AND meta_message.name = 'votecast' AND member.public_key = ? ORDER BY global_time DESC LIMIT 1"
        try:
            id, = self._dispersy.database.execute(sql, (buffer(public_key),)).next()
            self._votecache[public_key] = int(id)
            return self._votecache[public_key]
        except StopIteration:
            return

    def getVoteForMyChannel(self, public_key):
        id = self.getDispersyId(None, public_key)
        if id:  # if we have a votecastmessage from this peer in our sync table, then signal a mark as favorite
            return 2
        return 0

    def get_latest_vote_dispersy_id(self, channel_id, voter_id):
        return


class PeerDBStub():

    def __init__(self, dispersy):
        self._dispersy = dispersy

    def addOrGetPeerID(self, public_key):
        return public_key

########NEW FILE########
__FILENAME__ = conversion
from struct import pack, unpack_from
from random import choice, sample

from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.dispersy.message import DropPacket
from Tribler.dispersy.conversion import BinaryConversion


class AllChannelConversion(BinaryConversion):

    def __init__(self, community):
        super(AllChannelConversion, self).__init__(community, "\x01")
        self.define_meta_message(chr(1), community.get_meta_message(u"channelcast"), self._encode_channelcast, self._decode_channelcast)
        self.define_meta_message(chr(2), community.get_meta_message(u"channelcast-request"), self._encode_channelcast, self._decode_channelcast)
        self.define_meta_message(chr(3), community.get_meta_message(u"channelsearch"), self._encode_channelsearch, self._decode_channelsearch)
        self.define_meta_message(chr(4), community.get_meta_message(u"channelsearch-response"), self._encode_channelsearch_response, self._decode_channelsearch_response)
        self.define_meta_message(chr(5), community.get_meta_message(u"votecast"), self._encode_votecast, self._decode_votecast)

    def _encode_channelcast(self, message):
        max_len = self._community.dispersy_sync_bloom_filter_bits / 8

        def create_msg():
            return encode(message.payload.torrents)

        packet = create_msg()
        while len(packet) > max_len:
            community = choice(message.payload.torrents.keys())
            nrTorrents = len(message.payload.torrents[community])
            if nrTorrents == 1:
                del message.payload.torrents[community]
            else:
                message.payload.torrents[community] = set(sample(message.payload.torrents[community], nrTorrents - 1))

            packet = create_msg()

        return packet,

    def _decode_channelcast(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the channelcast-payload")

        if not isinstance(payload, dict):
            raise DropPacket("Invalid payload type")

        for cid, infohashes in payload.iteritems():
            if not (isinstance(cid, str) and len(cid) == 20):
                raise DropPacket("Invalid 'cid' type or value")

            for infohash in infohashes:
                if not (isinstance(infohash, str) and len(infohash) == 20):
                    raise DropPacket("Invalid 'infohash' type or value")
        return offset, placeholder.meta.payload.implement(payload)

    def _encode_channelsearch(self, message):
        packet = encode(message.payload.keywords)
        return packet,

    def _decode_channelsearch(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the channelcast-payload")

        if not isinstance(payload, list):
            raise DropPacket("Invalid payload type")

        for keyword in payload:
            if not isinstance(keyword, unicode):
                raise DropPacket("Invalid 'keyword' type")
        return offset, placeholder.meta.payload.implement(payload)

    def _encode_channelsearch_response(self, message):
        packet = encode((message.payload.keywords, message.payload.torrents))
        return packet,

    def _decode_channelsearch_response(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the channelcast-payload")

        if not isinstance(payload, tuple):
            raise DropPacket("Invalid payload type")

        keywords, torrents = payload
        for keyword in keywords:
            if not isinstance(keyword, unicode):
                raise DropPacket("Invalid 'keyword' type")

        for cid, infohashes in torrents.iteritems():
            if not (isinstance(cid, str) and len(cid) == 20):
                raise DropPacket("Invalid 'cid' type or value")

            for infohash in infohashes:
                if not (isinstance(infohash, str) and len(infohash) == 20):
                    raise DropPacket("Invalid 'infohash' type or value")

        return offset, placeholder.meta.payload.implement(keywords, torrents)

    def _encode_votecast(self, message):
        return pack('!20shl', message.payload.cid, message.payload.vote, message.payload.timestamp),

    def _decode_votecast(self, placeholder, offset, data):
        if len(data) < offset + 26:
            raise DropPacket("Unable to decode the payload")

        cid, vote, timestamp = unpack_from('!20shl', data, offset)
        if not vote in [-1, 0, 2]:
            raise DropPacket("Invalid 'vote' type or value")

        return offset + 26, placeholder.meta.payload.implement(cid, vote, timestamp)

    # def _encode_torrent_request(self, message):
    #     return message.payload.infohash,

    # def _decode_torrent_request(self, placeholder, offset, data):
    #     if len(data) < offset + 20:
    #         raise DropPacket("Insufficient packet size")

    #     infohash = data[offset:offset+20]
    #     offset += 20

    #     return offset, placeholder.meta.payload.implement(infohash)

########NEW FILE########
__FILENAME__ = message
from Tribler.dispersy.message import DelayMessage
from Tribler.community.channel.community import ChannelCommunity

class DelayMessageReqChannelMessage(DelayMessage):

    """
    Raised during ChannelCommunity.check_ if the channel message has not been received yet.
    """
    def __init__(self, delayed, channel_community, includeSnapshot=False):
        super(DelayMessageReqChannelMessage, self).__init__(delayed)
        if __debug__:
            from Tribler.dispersy.message import Message
        assert isinstance(delayed, Message.Implementation), type(delayed)
        assert isinstance(channel_community, ChannelCommunity), type(channel_community)

        self._channel_community = channel_community
        self._includeSnapshot = includeSnapshot

    @property
    def match_info(self):
        # we return the channel_community cid here, to register the delay at that community
        return (self._channel_community.cid, u"channel", None, None, []),

    def send_request(self, community, candidate):
        # the request is sent from within the channel_community
        self._channel_community.disp_create_missing_channel(candidate, self._includeSnapshot)

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload


class ChannelCastPayload(Payload):

    """
    Propagate semi random channel data.

    One channel-propagate message could contain a list with the following ChannelCommunity packets:
     - torrent
    """
    class Implementation(Payload.Implementation):

        def __init__(self, meta, torrents):
            if __debug__:
                assert isinstance(torrents, dict), 'torrents should be a dictionary containing cid:set(infohashes)'
                for cid, infohashes in torrents.iteritems():
                    assert isinstance(cid, str)
                    assert len(cid) == 20
                    assert isinstance(infohashes, set)
                    assert not filter(lambda x: not isinstance(x, str), infohashes)
                    assert not filter(lambda x: not len(x) == 20, infohashes)
                    assert len(infohashes) > 0

            super(ChannelCastPayload.Implementation, self).__init__(meta)
            self._torrents = torrents

        @property
        def torrents(self):
            return self._torrents


class ChannelCastRequestPayload(ChannelCastPayload):
    pass


class ChannelSearchPayload(Payload):

    """
    Propagate a search for a channel
    """
    class Implementation(Payload.Implementation):

        def __init__(self, meta, keywords):
            if __debug__:
                assert isinstance(keywords, list), 'keywords should be list'
                for keyword in keywords:
                    assert isinstance(keyword, unicode), '%s is type %s' % (keyword, type(keyword))
                    assert len(keyword) > 0

            super(ChannelSearchPayload.Implementation, self).__init__(meta)
            self._keywords = keywords

        @property
        def keywords(self):
            return self._keywords


class ChannelSearchResponsePayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, keywords, torrents):
            if __debug__:
                assert isinstance(keywords, list), 'keywords should be list'
                assert isinstance(torrents, dict), 'torrents should be a dictionary containing cid:set(infohashes)'
                for cid, infohashes in torrents.iteritems():
                    assert isinstance(cid, str)
                    assert len(cid) == 20
                    assert isinstance(infohashes, set)
                    assert not filter(lambda x: not isinstance(x, str), infohashes)
                    assert not filter(lambda x: not len(x) == 20, infohashes)
                    assert len(infohashes) > 0

            super(ChannelSearchResponsePayload.Implementation, self).__init__(meta)
            self._keywords = keywords
            self._torrents = torrents

        @property
        def keywords(self):
            return self._keywords

        @property
        def torrents(self):
            return self._torrents


class VoteCastPayload(Payload):

    """
    Propagate vote for a channel
    """
    class Implementation(Payload.Implementation):

        def __init__(self, meta, cid, vote, timestamp):
            assert isinstance(cid, str)
            assert len(cid) == 20
            assert isinstance(vote, int)
            assert vote in [-1, 0, 2]
            assert isinstance(timestamp, (int, long))

            super(VoteCastPayload.Implementation, self).__init__(meta)
            self._cid = cid
            self._vote = vote
            self._timestamp = timestamp

        @property
        def cid(self):
            return self._cid

        @property
        def vote(self):
            return self._vote

        @property
        def timestamp(self):
            return self._timestamp

########NEW FILE########
__FILENAME__ = cache
"""
Cache module for the ProxyCommunity.

Keeps track of outstanding PING and EXTEND requests and of candidates used in
CREATE and CREATED requests.

"""
import logging

from Tribler.dispersy.requestcache import NumberCache
from Tribler.dispersy.util import call_on_reactor_thread


__author__ = 'chris'


class CircuitRequestCache(NumberCache):
    PREFIX = u"anon-circuit"

    """
    Circuit request cache is used to keep track of circuit building. It
    succeeds when the circuit reaches full length.

    On timeout the circuit is removed

    @param ProxyCommunity community: the instance of the ProxyCommunity
    @param int force_number:
    """

    def __init__(self, community, circuit):
        number = self.create_identifier(circuit)

        NumberCache.__init__(self, community.request_cache, self.PREFIX, number)
        self._logger = logging.getLogger(__name__)
        self.community = community
        self.circuit = circuit
        ''' :type : Tribler.community.anontunnel.community.Circuit '''

    @property
    def timeout_delay(self):
        return 10.0

    def on_success(self):
        """
        Mark the Request as successful, cancelling the timeout
        """

        # TODO(emilon): Is there a reason to import these here instead of at the beggining?
        from Tribler.community.anontunnel.globals \
            import CIRCUIT_STATE_READY

        if self.circuit.state == CIRCUIT_STATE_READY:
            self._logger.info("Circuit %d is ready", self.number)
            self.community.request_cache.pop(self.prefix, self.number)

    def on_timeout(self):
        from Tribler.community.anontunnel.globals \
            import CIRCUIT_STATE_READY

        if not self.circuit.state == CIRCUIT_STATE_READY:
            reason = 'timeout on CircuitRequestCache, state = %s, candidate = %s' % \
                     (self.circuit.state, self.circuit.first_hop)
            self.community.remove_circuit(self.number, reason)

    @classmethod
    def create_identifier(cls, circuit):
        return circuit.circuit_id


class PingRequestCache(NumberCache):
    PREFIX = u"anon-ping"

    """
    Request cache that is used to time-out PING messages

    @param ProxyCommunity community: instance of the ProxyCommunity
    @param force_number:
    """
    def __init__(self, community, circuit):
        NumberCache.__init__(self, community.request_cache, self.PREFIX, circuit.circuit_id)

        self.circuit = circuit
        self.community = community

    @property
    def timeout_delay(self):
        return 10.0

    @call_on_reactor_thread
    def on_pong(self, message):
        self.community.circuits[self.number].beat_heart()
        self.community.request_cache.pop(self.PREFIX, self.number)

    def on_timeout(self):
        self.community.remove_circuit(self.number, 'ping time out')


class CreatedRequestCache(NumberCache):
    PREFIX = u"anon-created"

    def __init__(self, community, circuit_id, candidate, candidates):
        """

        @param int circuit_id: the circuit's id
        @param WalkCandidate candidate: the candidate from which we got the CREATE
        @param dict[str, WalkCandidate] candidates: we sent to the candidate to pick from
        """

        number = self.create_identifier(circuit_id, candidate)
        super(CreatedRequestCache, self).__init__(community.request_cache, self.PREFIX, number)

        self.circuit_id = circuit_id
        self.candidate = candidate
        self.candidates = dict(candidates)

    @property
    def timeout_delay(self):
        return 10.0

    def on_timeout(self):
        pass

    @classmethod
    def create_identifier(cls, circuit_id, candidate):
        return circuit_id

########NEW FILE########
__FILENAME__ = community
"""
AnonTunnel community module
"""

# Python imports
import logging
import random
import threading
import time
from collections import defaultdict

from twisted.internet.task import LoopingCall
from twisted.internet import reactor

from Tribler.community.anontunnel import crypto, extendstrategies, selectionstrategies, lengthstrategies
from Tribler.community.anontunnel.cache import CircuitRequestCache, PingRequestCache, CreatedRequestCache
from Tribler.community.anontunnel.conversion import CustomProxyConversion, ProxyConversion
from Tribler.community.anontunnel.globals import (MESSAGE_EXTEND, MESSAGE_CREATE, MESSAGE_CREATED, MESSAGE_DATA,
                                                  MESSAGE_EXTENDED, MESSAGE_PING, MESSAGE_PONG, MESSAGE_TYPE_STRING,
                                                  CIRCUIT_STATE_READY, CIRCUIT_STATE_EXTENDING, ORIGINATOR,
                                                  PING_INTERVAL, ENDPOINT)
from Tribler.community.anontunnel.payload import (StatsPayload, CreateMessage, CreatedMessage, ExtendedMessage,
                                                  PongMessage, PingMessage, DataMessage)
from Tribler.community.anontunnel.routing import Circuit, Hop, RelayRoute
from Tribler.community.anontunnel.tests.test_libtorrent import LibtorrentTest
from Tribler.dispersy.authentication import MemberAuthentication, NoAuthentication
from Tribler.dispersy.candidate import Candidate, WalkCandidate
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CommunityDestination
from Tribler.dispersy.distribution import LastSyncDistribution
from Tribler.dispersy.message import Message, DelayMessageByProof
from Tribler.dispersy.resolution import PublicResolution
from Tribler.dispersy.util import blocking_call_on_reactor_thread, call_on_reactor_thread


__author__ = 'chris'



class ProxySettings:
    """
    Data structure containing settings, including some defaults,
    for the ProxyCommunity
    """

    def __init__(self):
        length = random.randint(3, 3)

        self.max_circuits = 1
        self.delay = 300

        self.extend_strategy = extendstrategies.NeighbourSubset
        self.select_strategy = selectionstrategies.RoundRobin()
        self.length_strategy = lengthstrategies.ConstantCircuitLength(length)
        self.crypto = crypto.DefaultCrypto()


class ProxyCommunity(Community):
    """
    The dispersy community which discovers other proxies on the internet and
    creates TOR-like circuits together with them

    @type dispersy: Tribler.dispersy.dispersy.Dispersy
    @type master_member: Tribler.dispersy.member.Member
    @type settings: ProxySettings or unknown
    @type tribler_session: Tribler.Core.Session.Session
    """

    def __init__(self, dispersy, master_member, my_member):
        super(ProxyCommunity, self).__init__(dispersy, master_member, my_member)

        self.lock = threading.RLock()
        self._logger = logging.getLogger(__name__)

        # Custom conversion
        self.__packet_prefix = "fffffffe".decode("HEX")

        self.observers = []
        ''' :type : list of TunnelObserver'''

        self.proxy_conversion = CustomProxyConversion()
        self._message_handlers = defaultdict(lambda: lambda *args: None)
        ''' :type : dict[
            str,
            (
                int, Candidate,
                StatsPayload|Tribler.community.anontunnel.payload.BaseMessage
            ) -> bool]
        '''

        self.circuits = {}
        """ :type : dict[int, Circuit] """
        self.directions = {}

        self.relay_from_to = {}
        """ :type :  dict[((str, int),int),RelayRoute] """

        self.waiting_for = {}
        """ :type :  dict[((str, int),int), bool] """

        # Map destination address to the circuit to be used
        self.destination_circuit = {}
        ''' @type: dict[(str, int), int] '''

        self.circuit_pools = []
        ''' :type : list[CircuitPool] '''

    def initialize(self, tribler_session=None, settings=None):
        super(ProxyCommunity, self).initialize()

        self.settings = settings if settings else ProxySettings()
        self._tribler_session = tribler_session

        # Attach message handlers
        self._initiate_message_handlers()

        # add self to crypto
        self.settings.crypto.set_proxy(self)

        # Enable global counters
        from Tribler.community.anontunnel.stats import StatsCollector

        self.global_stats = StatsCollector(self, "global")
        self.global_stats.start()

        # Listen to prefix endpoint
        try:
            self._dispersy.endpoint.listen_to(self.__packet_prefix, self.__handle_packet)
        except AttributeError:
            self._logger.error("Cannot listen to our prefix, are you sure that you are using the DispersyBypassEndpoint?")

        if self._tribler_session:
            from Tribler.Core.CacheDB.Notifier import Notifier
            self.notifier = Notifier.getInstance()
            delay = self.settings.delay if self.settings.delay is not None else 300
            self._tribler_session.lm.rawserver.add_task(lambda: LibtorrentTest(self, self._tribler_session, delay))
        else:
            self.notifier = None

        self._pending_tasks["discover"] = lc = LoopingCall(self.__discover)
        lc.start(5, now=True)

        self._pending_tasks["ping circuits"] = lc = LoopingCall(self.__ping_circuits)
        lc.start(PING_INTERVAL)


    @classmethod
    def get_master_members(cls, dispersy):
        # generated: Wed Sep 18 22:47:22 2013
        # curve: high <<< NID_sect571r1 >>>
        # len: 571 bits ~ 144 bytes signature
        # pub: 170 3081a7301006072a8648ce3d020106052b81040027038192000404608
        # 29f9bb72f0cb094904aa6f885ff70e1e98651e81119b1e7b42402f3c5cfa183d8d
        # 96738c40ffd909a70020488e3b59b67de57bb1ac5dec351d172fe692555898ac94
        # 4b68c730590f850ab931c5732d5a9d573a7fe1f9dc8a9201bc3cb63ab182c9e485
        # d08ff4ac294f09e16d3925930946f87e91ef9c40bbb4189f9c5af6696f57eec3b8
        # f2f77e7ab56fd8d6d63
        # pub-sha1 089515d307ed31a25eec2c54667ddcd2d402c041
        #-----BEGIN PUBLIC KEY-----
        # MIGnMBAGByqGSM49AgEGBSuBBAAnA4GSAAQEYIKfm7cvDLCUkEqm+IX/cOHphlHo
        # ERmx57QkAvPFz6GD2NlnOMQP/ZCacAIEiOO1m2feV7saxd7DUdFy/mklVYmKyUS2
        # jHMFkPhQq5McVzLVqdVzp/4fncipIBvDy2OrGCyeSF0I/0rClPCeFtOSWTCUb4fp
        # HvnEC7tBifnFr2aW9X7sO48vd+erVv2NbWM=
        #-----END PUBLIC KEY-----
        master_key = "3081a7301006072a8648ce3d020106052b810400270381920004" \
                     "0460829f9bb72f0cb094904aa6f885ff70e1e98651e81119b1e7" \
                     "b42402f3c5cfa183d8d96738c40ffd909a70020488e3b59b67de" \
                     "57bb1ac5dec351d172fe692555898ac944b68c730590f850ab93" \
                     "1c5732d5a9d573a7fe1f9dc8a9201bc3cb63ab182c9e485d08ff" \
                     "4ac294f09e16d3925930946f87e91ef9c40bbb4189f9c5af6696" \
                     "f57eec3b8f2f77e7ab56fd8d6d63".decode("HEX")

        master = dispersy.get_member(public_key=master_key)
        return [master]

    @property
    def crypto(self):
        """
        @rtype: ElgamalCrypto
        """
        return self.dispersy.crypto

    @property
    def packet_crypto(self):
        return self.settings.crypto

    def __discover(self):
        circuits_needed = lambda: max(
            sum(pool.lacking for pool in self.circuit_pools),
            self.settings.max_circuits - len(self.circuits)
        )

        with self.lock:
            for i in range(0, circuits_needed()):
                self._logger.debug("Need %d new circuits!", circuits_needed())
                goal_hops = self.settings.length_strategy.circuit_length()

                if goal_hops == 0:
                    circuit_id = self._generate_circuit_id()
                    self.circuits[circuit_id] = Circuit(circuit_id, self)

                    first_pool = next((pool for pool in self.circuit_pools if pool.lacking), None)
                    if first_pool:
                        first_pool.fill(self.circuits[circuit_id])

                else:
                    circuit_candidates = set([c.first_hop for c in self.circuits.values()])
                    candidate = next(
                        (
                            c for c in self.dispersy_yield_verified_candidates()
                            if (c.sock_addr not in circuit_candidates) and \
                               self.packet_crypto.is_key_compatible(c.get_member()._ec)
                        ), None
                    )

                    if candidate is None:
                        return
                    else:
                        try:
                            self.create_circuit(candidate, goal_hops)
                        except:
                            self._logger.exception("Error creating circuit while running __discover")

    def unload_community(self):
        """
        Called by dispersy when the ProxyCommunity is being unloaded
        @return:
        """
        for observer in self.observers:
            observer.on_unload()
        Community.unload_community(self)

    def _initiate_message_handlers(self):
        self._message_handlers[MESSAGE_CREATE] = self.on_create
        self._message_handlers[MESSAGE_CREATED] = self.on_created
        self._message_handlers[MESSAGE_DATA] = self.on_data
        self._message_handlers[MESSAGE_EXTEND] = self.on_extend
        self._message_handlers[MESSAGE_EXTENDED] = self.on_extended
        self._message_handlers[MESSAGE_PING] = self.on_ping
        self._message_handlers[MESSAGE_PONG] = self.on_pong

    def initiate_conversions(self):
        """
        Called by dispersy when we need to return our message Conversions
        @rtype: list[Tribler.dispersy.conversion.Conversion]
        """
        return [DefaultConversion(self), ProxyConversion(self)]

    def initiate_meta_messages(self):
        """
        Called by dispersy when we need to define the messages we would like
        to use in the community
        @rtype: list[Message]
        """
        return super(ProxyCommunity, self).initiate_meta_messages() + [
            Message(
                self,
                u"stats",
                MemberAuthentication(),
                PublicResolution(),
                LastSyncDistribution(synchronization_direction=u"DESC",
                                     priority=128, history_size=1),
                CommunityDestination(node_count=10),
                StatsPayload(),
                self._generic_timeline_check,
                self._on_stats
        )]

    def _generic_timeline_check(self, messages):
        meta = messages[0].meta
        if isinstance(meta.authentication, NoAuthentication):
            # we can not timeline.check this message because it uses the NoAuthentication policy
            for message in messages:
                yield message

        else:
            for message in messages:
                allowed, proofs = self.timeline.check(message)
                if allowed:
                    yield message
                else:
                    yield DelayMessageByProof(message)

    def _on_stats(self, messages):
        for observer in self.observers:
            for message in messages:
                observer.on_tunnel_stats(self, message.authentication.member, message.candidate, message.payload.stats)

    @call_on_reactor_thread
    def send_stats(self, stats):
        """
        Send a stats message to the community
        @param dict stats: the statistics dictionary to share
        """

        meta = self.get_meta_message(u"stats")
        record = meta.impl(authentication=(self._my_member,),
                           distribution=(self.claim_global_time(),),
                           payload=(stats,))

        self._logger.warning("Sending stats")
        self.dispersy.store_update_forward([record], True, False, True)

    def __handle_incoming(self, circuit_id, am_originator, sock_addr, data):
        # Let packet_crypto handle decrypting the incoming packet
        data = self.packet_crypto.handle_incoming_packet(sock_addr, circuit_id, data)

        if not data:
            self._logger.error("Circuit ID {0} doesn't talk crypto language, dropping packet".format(circuit_id))
            return False

        # Try to parse the packet

        try:
            _, payload = self.proxy_conversion.decode(data)
        except KeyError as e:
            self._logger.warning("Cannot decode payload, probably orphaned session")
            return False;

        packet_type = self.proxy_conversion.get_type(data)
        str_type = MESSAGE_TYPE_STRING.get(packet_type)

        # Let packet_crypto handle decrypting packet contents
        payload = self.packet_crypto.handle_incoming_packet_content(sock_addr, circuit_id, payload, packet_type)

        # If un-decrypt-able, drop packet
        if not payload:
            self._logger.warning("IGNORED %s from %s:%d over circuit %d",
                                 str_type, sock_addr[0],
                                 sock_addr[1], circuit_id)
            return False

        if am_originator:
            self.circuits[circuit_id].beat_heart()

        handler = self._message_handlers[packet_type]
        result = handler(circuit_id, sock_addr, payload)

        if result:
            self.__dict_inc(u"success", str_type)
        else:
            self.__dict_inc(u"success", str_type + '-ignored')
            self._logger.debug("Prev message was IGNORED")

        return True

    def __relay(self, circuit_id, data, relay_key, sock_addr):
        # First, relay packet if we know whom to forward message to for
        # this circuit. This happens only when the circuit is already
        # established with both parent and child and if the node is not
        # waiting for a CREATED message from the child

        direction = self.directions[relay_key]
        next_relay = self.relay_from_to[relay_key]

        # let packet_crypto handle en-/decrypting relay packet
        data = self.packet_crypto.handle_relay_packet(direction, sock_addr, circuit_id, data)

        if not data:
            return False

        this_relay_key = (next_relay.sock_addr, next_relay.circuit_id)

        if this_relay_key in self.relay_from_to:
            this_relay = self.relay_from_to[this_relay_key]
            this_relay.last_incoming = time.time()

            # TODO: check whether direction is set correctly here!
            for observer in self.observers:
                observer.on_relay(this_relay_key, relay_key, direction, data)

        packet_type = self.proxy_conversion.get_type(data)

        str_type = MESSAGE_TYPE_STRING.get(
            packet_type, 'unknown-type-%d' % ord(packet_type)
        )

        self.send_packet(
            destination=next_relay.sock_addr,
            circuit_id=next_relay.circuit_id,
            message_type=packet_type,
            packet=data,
            relayed=True
        )

        self.__dict_inc(u"success", str_type + '-relayed')

        return True

    def __handle_packet(self, sock_addr, orig_packet):
        """
        @param (str, int) sock_addr: socket address in tuple format
        @param orig_packet:
        @return:
        """
        packet = orig_packet[len(self.__packet_prefix):]
        circuit_id, data = self.proxy_conversion.get_circuit_and_data(packet)
        relay_key = (sock_addr, circuit_id)

        is_relay = circuit_id > 0 and relay_key in self.relay_from_to \
            and not relay_key in self.waiting_for
        is_originator = not is_relay and circuit_id in self.circuits
        is_initial = not is_relay and not is_originator

        try:
            if is_relay:
                result = self.__relay(circuit_id, data, relay_key, sock_addr)
            else:
                result = self.__handle_incoming(circuit_id, is_originator, sock_addr, data)
        except:
            result = False
            self._logger.exception(
                "Incoming from %s on %d message error."
                "INITIAL=%s, ORIGINATOR=%s, RELAY=%s",
                sock_addr, circuit_id, is_initial, is_originator, is_relay)

        if not result:
            if is_relay:
                self.remove_relay(relay_key, "error on incoming packet!")
            elif is_originator:
                self.remove_circuit(circuit_id, "error on incoming packet!")

    def create_circuit(self, first_hop, goal_hops, extend_strategy=None, deferred=None):
        """ Create a new circuit, with one initial hop

        @param WalkCandidate first_hop: The first hop of our circuit, needs to
            be a candidate.
        @param int goal_hops: The number of hops the circuit should reach
        @param T <= extendstrategies.ExtendStrategy extend_strategy:
        The extend strategy used

        @rtype: Tribler.community.anontunnel.routing.Circuit
        """

        if not (goal_hops > 0):
            raise ValueError("We can only create circuits with more than 0 hops using create_circuit()!")

        # TODO(emilon): Can this lock be removed or at least be converted to a DeferredLock?
        with self.lock:
            circuit_id = self._generate_circuit_id(first_hop.sock_addr)
            circuit = Circuit(
                circuit_id=circuit_id,
                goal_hops=goal_hops,
                first_hop=first_hop.sock_addr,
                proxy=self)

            @blocking_call_on_reactor_thread
            def _add_cache():
                self._request_cache.add(CircuitRequestCache(self, circuit))

            _add_cache()

            if extend_strategy:
                circuit.extend_strategy = extend_strategy
            else:
                circuit.extend_strategy = self.settings.extend_strategy(
                    self, circuit)

            hop_public_key = first_hop.get_member()._ec
            circuit.unverified_hop = Hop(hop_public_key)
            circuit.unverified_hop.address = first_hop.sock_addr

            self._logger.warning("Creating circuit %d of %d hops. Fist hop: %s:%d",
                circuit_id, circuit.goal_hops,
                first_hop.sock_addr[0],
                first_hop.sock_addr[1]
            )

            self.circuits[circuit_id] = circuit
            self.waiting_for[(first_hop.sock_addr, circuit_id)] = True

            destination_key = first_hop.get_member()._ec
            self.send_message(first_hop.sock_addr, circuit_id, MESSAGE_CREATE,
                              CreateMessage("", self.my_member.public_key, destination_key))

            return circuit

    def remove_circuit(self, circuit_id, additional_info=''):
        """
        Removes a circuit from our pool, destroying it
        @param int circuit_id: the id of the circuit to destroy
        @param str additional_info: optional reason, useful for logging
        @return: whether the removal was successful
        """
        assert isinstance(circuit_id, (long, int)), type(circuit_id)

        if circuit_id in self.circuits:
            self._logger.error("Breaking circuit %d " + additional_info,
                               circuit_id)
            circuit = self.circuits[circuit_id]

            circuit.destroy()
            del self.circuits[circuit_id]
            for observer in self.observers:
                observer.on_break_circuit(circuit)

            return True
        return False

    def remove_relay(self, relay_key, additional_info=''):
        """
        Removes a relay from our routing table, will drop any incoming packets
        and eventually cause a timeout at the originator

        @param ((str, int) int) relay_key: the key of the relay to remove
        @param str additional_info: optional reason, useful for logging
        @return: whether the removal was successful
        """
        if relay_key in self.relay_from_to:
            self._logger.error(
                ("Breaking relay %s:%d %d " + additional_info) % (
                    relay_key[0][0], relay_key[0][1], relay_key[1]))

            # Only remove one side of the relay, this isn't as pretty but
            # both sides have separate incoming timer, hence
            # after removing one side the other will follow.
            del self.relay_from_to[relay_key]

            for observer in self.observers:
                observer.on_break_relay(relay_key)

            return True
        return False

    def on_create(self, circuit_id, sock_addr, message):
        """
        Handle incoming CREATE message, acknowledge the CREATE request with a
        CREATED reply

        @param int circuit_id: The circuit's identifier
        @param (string, int) sock_addr: The candidate we got a CREATE message from
        @param CreateMessage message: The message's payload
        """
        relay_key = (sock_addr, circuit_id)
        self.directions[relay_key] = ENDPOINT
        self._logger.info('We joined circuit %d with neighbour %s'
                          , circuit_id, sock_addr)

        candidates = {}
        ''' :type : dict[str, WalkCandidate] '''

        for _ in range(1, 5):
            candidate_temp = next((c for c in self.dispersy_yield_verified_candidates() if self.packet_crypto.is_candidate_compatible(c)), None)
            " :type: WalkCandidate"

            if not candidate_temp:
                break

            candidates[candidate_temp.get_member().public_key] = candidate_temp

        candidate_list = [c.get_member().public_key for c in candidates.itervalues()]

        self.create_created_cache(circuit_id, sock_addr, candidates)

        if self.notifier:
            from Tribler.Core.simpledefs import NTFY_ANONTUNNEL, NTFY_JOINED

            self.notifier.notify(NTFY_ANONTUNNEL, NTFY_JOINED,
                                 sock_addr, circuit_id)

        return self.send_message(
            destination=sock_addr,
            circuit_id=circuit_id,
            message_type=MESSAGE_CREATED,
            message=CreatedMessage(candidate_list, reply_to=message)
        )

    def on_created(self, circuit_id, sock_addr, message):
        """ Handle incoming CREATED messages relay them backwards towards
        the originator if necessary

        @param int circuit_id: The circuit's id we got a CREATED message on
        @param (string, int) sock_addr: The candidate we got the message from
        @param CreatedMessage message: The message we received

        @return: whether the message could be handled correctly

        """
        relay_key = (sock_addr, circuit_id)

        if not relay_key in self.waiting_for:
            self._logger.error("Got an unexpected CREATED message for circuit %d from %s:%d", circuit_id, *sock_addr)
            return False

        del self.waiting_for[relay_key]
        self.directions[relay_key] = ORIGINATOR
        if relay_key in self.relay_from_to:
            self._logger.debug("Got CREATED message, "
                               "forward as EXTENDED to origin.")
            extended_message = ExtendedMessage(message.key,
                                               message.candidate_list)
            forwarding_relay = self.relay_from_to[relay_key]

            return self.send_message(forwarding_relay.sock_addr, forwarding_relay.circuit_id,
                                     MESSAGE_EXTENDED, extended_message)

        # This is ours!
        if circuit_id in self.circuits:
            circuit = self.circuits[circuit_id]
            return self._ours_on_created_extended(circuit, message)

        return False

    def _ours_on_created_extended(self, circuit, message):
        """
        @param ExtendedMessage | CreatedMessage message: the CREATED or
            EXTENDED message we received
        """

        @blocking_call_on_reactor_thread
        def _get_cache():
            return self.request_cache.get(CircuitRequestCache.PREFIX, CircuitRequestCache.create_identifier(circuit))

        request = _get_cache()
        candidate_list = message.candidate_list

        circuit.add_hop(circuit.unverified_hop)
        circuit.unverified_hop = None

        if self.my_member.public_key in candidate_list:
            candidate_list.remove(self.my_member.public_key)

        for hop in circuit.hops:
            if hop.public_key in candidate_list:
                candidate_list.remove(hop.public_key)

        for i in range(len(candidate_list) - 1, -1, -1):
            public_key = self.crypto.key_from_public_bin(candidate_list[i])
            if not self.packet_crypto.is_key_compatible(public_key):
                candidate_list.pop(i)

        if circuit.state == CIRCUIT_STATE_EXTENDING:
            try:
                if not circuit.extend_strategy.extend(candidate_list):
                    raise ValueError("Extend strategy returned False")
            except BaseException as e:
                self.remove_circuit(circuit.circuit_id, e.message)
                return False

        elif circuit.state == CIRCUIT_STATE_READY:
            reactor.callFromThread(request.on_success)

            first_pool = next((pool for pool in self.circuit_pools if pool.lacking), None)
            if first_pool:
                first_pool.fill(circuit)
        else:
            return False

        if self.notifier:
            from Tribler.Core.simpledefs import NTFY_ANONTUNNEL, \
                NTFY_CREATED, NTFY_EXTENDED

            if len(circuit.hops) == 1:
                self.notifier.notify(
                    NTFY_ANONTUNNEL, NTFY_CREATED, circuit)
            else:
                self.notifier.notify(
                    NTFY_ANONTUNNEL, NTFY_EXTENDED, circuit)

        return True

    def on_data(self, circuit_id, sock_addr, message):
        """
        Handles incoming DATA message

        Determines whether the data comes from the outside world (origin set)
        or whether the data came from the origin (destination set)

        If the data comes from the outside world the on_incoming_from_tunnel
        method is called on the observers and the circuit is marked as active

        When the data comes from the origin we need to EXIT to the outside
        world. This is left to the observers as well, by calling the
        on_exiting_from_tunnel method.

        @param int circuit_id: the circuit's id we received the DATA message on
        @param (string, int) sock_addr: the messenger of the packet
        @param DataMessage message: the message's content

        @return: whether the message could be handled correctly
        """

        # If its our circuit, the messenger is the candidate assigned to that
        # circuit and the DATA's destination is set to the zero-address then
        # the packet is from the outside world and addressed to us from
        if circuit_id in self.circuits and message.origin \
                and sock_addr == self.circuits[circuit_id].first_hop:

            self.circuits[circuit_id].beat_heart()
            for observer in self.observers:
                observer.on_incoming_from_tunnel(self, self.circuits[circuit_id], message.origin, message.data)

            return True
        # It is not our circuit so we got it from a relay, we need to EXIT it!
        if message.destination != ('0.0.0.0', 0):

            for observer in self.observers:
                observer.on_exiting_from_tunnel(circuit_id, sock_addr, message.destination, message.data)

            return True
        return False

    def on_extend(self, circuit_id, sock_addr, message):
        """
        Upon reception of a EXTEND message the message is forwarded over the
        Circuit if possible. At the end of the circuit a CREATE request is
        send to the Proxy to extend the circuit with. It's CREATED reply will
        eventually be received and propagated back along the Circuit.

        @param int circuit_id: the circuit's id we got the EXTEND message on
        @param (string, int) sock_addr: the relay which sent us the EXTEND
        @param ExtendMessage message: the message's content

        @return: whether the message could be handled correctly
        """

        if message.extend_with:
            cache = self.pop_created_cache(circuit_id, sock_addr)

            if not cache:
                self._logger.warning("Cannot find created cache for circuit %d", circuit_id)
                return False

            extend_candidate = cache.candidates[message.extend_with]

            self._logger.warning(
                "ON_EXTEND send CREATE for circuit (%s, %d) to %s:%d!",
                sock_addr,
                circuit_id,
                extend_candidate.sock_addr[0],
                extend_candidate.sock_addr[1])
        else:
            self._logger.error("Cancelling EXTEND, no candidate!")
            return

        relay_key = (sock_addr, circuit_id)
        if relay_key in self.relay_from_to:
            current_relay = self.relay_from_to[relay_key]
            assert not current_relay.online, \
                "shouldn't be called whenever relay is online, " \
                "the extend message should have been forwarded"

            # We will just forget the attempt and try again, possible with
            # another candidate
            old_to_key = current_relay.sock_addr, current_relay.circuit_id
            del self.relay_from_to[old_to_key]
            del self.relay_from_to[relay_key]

        new_circuit_id = self._generate_circuit_id(extend_candidate.sock_addr)
        to_key = (extend_candidate.sock_addr, new_circuit_id)

        self.waiting_for[to_key] = True
        self.relay_from_to[to_key] = RelayRoute(circuit_id, sock_addr)
        self.relay_from_to[relay_key] = RelayRoute(new_circuit_id,
                                                   extend_candidate.sock_addr)

        key = message.key

        self.directions[to_key] = ORIGINATOR
        self.directions[relay_key] = ENDPOINT

        self._logger.info("Extending circuit, got candidate with IP %s:%d from cache", *extend_candidate.sock_addr)
        destination_key = extend_candidate.get_member()._ec
        return self.send_message(extend_candidate.sock_addr, new_circuit_id,
                                 MESSAGE_CREATE, CreateMessage(key, self.my_member.public_key, destination_key))

    def on_extended(self, circuit_id, candidate, message):
        """
        A circuit has been extended, forward the acknowledgment back to the
        origin of the EXTEND. If we are the origin update our records.

        @param int circuit_id: the circuit's id we got the EXTENDED message on
        @param (string, int) sock_addr: the relay which sent us the EXTENDED
        @param ExtendedMessage message: the message's content

        @return: whether the message could be handled correctly
        """

        circuit = self.circuits[circuit_id]
        return self._ours_on_created_extended(circuit, message)

    def create_ping(self, sock_addr, circuit):
        """
        Creates, sends and keeps track of a PING message to given candidate on
        the specified circuit.

        @param (string, int) sock_addr: the candidate to which we want to sent a
            ping
        @param Circuit circuit: the circuit id to sent the ping over
        """
        circuit_id = circuit.circuit_id
        @call_on_reactor_thread
        def _create_ping():
            if not self._request_cache.has(PingRequestCache.PREFIX, circuit_id):
                cache = PingRequestCache(self, circuit)
                self._request_cache.add(cache)

        _create_ping()
        self._logger.debug("SEND PING TO CIRCUIT {0}".format(circuit_id))

        self.send_message(sock_addr, circuit_id, MESSAGE_PING, PingMessage())

    def on_ping(self, circuit_id, sock_addr, message):
        """
        Upon reception of a PING message we respond with a PONG message

        @param int circuit_id: the circuit's id we got the PING from
        @param (string, int) sock_addr: the relay we got the PING from
        @param PingMessage message: the message's content

        @return: whether the message could be handled correctly
        """
        self._logger.debug("GOT PING FROM CIRCUIT {0}".format(circuit_id))
        return self.send_message(
            destination=sock_addr,
            circuit_id=circuit_id,
            message_type=MESSAGE_PONG,
            message=PongMessage())

    def on_pong(self, circuit_id, sock_addr, message):
        """
        When we receive a PONG message on our circuit we can be sure that the
        circuit is alive and well.

        @param int circuit_id: the circuit's id we got the PONG message on
        @param (string, int) sock_addr: the relay which sent us the PONG
        @param PongMessage message: the message's content

        @return: whether the message could be handled correctly
        """

        @blocking_call_on_reactor_thread
        def pop_cache():
            return self._request_cache.pop(PingRequestCache.PREFIX, circuit_id)

        request = pop_cache()

        if request:
            request.on_pong(message)
            return True
        return False

    def _generate_circuit_id(self, neighbour=None):
        circuit_id = random.randint(1, 255000)

        # prevent collisions
        while circuit_id in self.circuits or \
                (neighbour and (neighbour, circuit_id) in self.relay_from_to):
            circuit_id = random.randint(1, 255000)

        return circuit_id

    def send_message(self, destination, circuit_id, message_type, message):
        """
        Send a message to a specified destination and circuit
        @param (string, int) destination: the relay's candidate
        @param int circuit_id: the circuit to sent over
        @param str message_type: the messages type, used to determine how to
         serialize it
        @param BaseMessage message: the messages content in object form
        @return:
        """
        message = self.packet_crypto.handle_outgoing_packet_content(destination, circuit_id, message, message_type)

        if message is None:
            return False

        content = self.proxy_conversion.encode(message_type, message)
        content = self.packet_crypto.handle_outgoing_packet(destination, circuit_id, message_type, message, content)

        if content is None:
            return False

        return self.send_packet(destination, circuit_id, message_type, content)

    def send_packet(self, destination, circuit_id, message_type, packet,
                    relayed=False):
        """
        Sends a packet to a relay over the specified circuit
        @param (string, int): the relay's candidate structure
        @param int circuit_id: the circuit to sent over
        @param str message_type: the messages type, for logging purposes
        @param str packet: the messages content in serialised form
        @param bool relayed: whether this is a relay packet or not
        @return: whether the send was successful
        """
        assert isinstance(packet, str), type(packet)

        packet = self.proxy_conversion.add_circuit(packet, circuit_id)

        str_type = MESSAGE_TYPE_STRING.get(
            message_type, "unknown-type-" + str(ord(message_type)))

        # we need to make sure that this endpoint is thread safe
        return self.dispersy._send_packets([Candidate(destination, False)], [self.__packet_prefix + packet],
            self, '-caused by %s-' % (str_type + ('-relayed' if relayed else '')))

    def __dict_inc(self, statistics_dict, key, inc=1):
        key = u"anontunnel-" + key
        self.statistics.increase_msg_count(statistics_dict, key, inc)

    @property
    def active_circuits(self):
        """
        Dict of active circuits, a circuit is active when its state is
        CIRCUIT_STATE_READY
        @rtype: dict[int, Tribler.community.anontunnel.routing.Circuit]
        """
        return dict((circuit_id, circuit)
                for circuit_id, circuit in self.circuits.items()
                if circuit.state == CIRCUIT_STATE_READY)

    def __ping_circuits(self):
        try:
            to_be_removed = [
                self.remove_relay(relay_key, 'no activity')
                for relay_key, relay in self.relay_from_to.items()
                if relay.ping_time_remaining == 0]

            self._logger.info("removed %d relays", len(to_be_removed))
            assert all(to_be_removed)

            to_be_pinged = [
                circuit for circuit in self.circuits.values()
                if circuit.ping_time_remaining < PING_INTERVAL
                and circuit.first_hop]

            # self._logger.info("pinging %d circuits", len(to_be_pinged))
            for circuit in to_be_pinged:
                self.create_ping(circuit.first_hop, circuit)
        except Exception:
            self._logger.error("Ping error")
            raise

    def tunnel_data_to_end(self, ultimate_destination, payload, circuit):
        """
        Tunnel data to the end and request an EXIT to the outside world

        @param (str, int) ultimate_destination: The destination outside the
            tunnel community
        @param str payload: The raw payload to send to the ultimate destination
        @param Tribler.community.anontunnel.routing.Circuit circuit: The
            circuit id to tunnel data over

        @return: Whether the request has been handled successfully
        """

        if circuit.goal_hops == 0:
            for observer in self.observers:
                observer.on_exiting_from_tunnel(circuit.circuit_id, None, ultimate_destination, payload)
        else:
            self.send_message(
                circuit.first_hop, circuit.circuit_id, MESSAGE_DATA,
                DataMessage(ultimate_destination, payload, None))

            for observer in self.observers:
                observer.on_send_data(circuit.circuit_id, circuit.first_hop, ultimate_destination, payload)

    def tunnel_data_to_origin(self, circuit_id, sock_addr, source_address,
                              payload):
        """
        Tunnel data to originator

        @param int circuit_id: The circuit's id to return data over
        @param Candidate sock_addr: The relay to return data over
        @param (str, int) source_address: The source outside the tunnel
            community
        @param str payload: The raw payload to return to the originator

        @return: Whether the request has been handled successfully
        """
        with self.lock:
            result = self.send_message(
                sock_addr, circuit_id, MESSAGE_DATA,
                DataMessage(None, payload, source_address))

            if result:
                for observer in self.observers:
                    observer.on_enter_tunnel(circuit_id, sock_addr, source_address, payload)

            return result

    @blocking_call_on_reactor_thread
    def create_created_cache(self, circuit_id, candidate, candidates):
        """

        @param int circuit_id: the circuit id we received the CREATE from
        @param WalkCandidate candidate: the candidate we got the CREATE from
        @param dict[str, WalkCandidate] candidates: list of extend candidates we sent back
        """
        self._request_cache.add(CreatedRequestCache(self, circuit_id, candidate, candidates))

    @blocking_call_on_reactor_thread
    def pop_created_cache(self, circuit_id, candidate):
        return self.request_cache.pop(CreatedRequestCache.PREFIX, CreatedRequestCache.create_identifier(circuit_id,
                                                                                                        candidate))

########NEW FILE########
__FILENAME__ = conversion
import logging
import sys
from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.community.anontunnel.globals import MESSAGE_CREATE, \
    MESSAGE_CREATED, MESSAGE_EXTEND, MESSAGE_EXTENDED, MESSAGE_DATA, \
    MESSAGE_PING, MESSAGE_PONG
from Tribler.community.anontunnel.payload import ExtendMessage, DataMessage, \
    PingMessage, PongMessage, CreatedMessage, ExtendedMessage, CreateMessage
from Tribler.dispersy.conversion import BinaryConversion
import struct


class ProxyConversion(BinaryConversion):
    """
    The dispersy conversion used for the STATS message in the ProxyCommunity
    @param ProxyCommunity community: the instance of the ProxyCommunity
    """

    def __init__(self, community):
        super(ProxyConversion, self).__init__(community, "\x01")

        self._logger = logging.getLogger(__name__)

        self.define_meta_message(
            chr(1),
            community.get_meta_message(u"stats"),
            self._encode_stats,
            self._decode_stats
        )

    @staticmethod
    def _encode_stats(message):
        return encode(message.payload.stats),

    @staticmethod
    def _decode_stats(placeholder, offset, data):
        offset, stats = decode(data, offset)

        return offset, placeholder.meta.payload.implement(stats)


class CustomProxyConversion():
    """
    Custom conversion for Proxy messages. This conversion encodes objects
    to bytes and vice versa
    """
    def __init__(self):
        self._logger = logging.getLogger(__name__)

        self.encode_functions = {
            MESSAGE_CREATE: self.__encode_create,
            MESSAGE_CREATED: self.__encode_created,
            MESSAGE_EXTEND: self.__encode_extend,
            MESSAGE_EXTENDED: self.__encode_extended,
            MESSAGE_DATA: self.__encode_data,
            MESSAGE_PING: lambda _: '',
            MESSAGE_PONG: lambda _: ''
        }

        self.decode_functions = {
            MESSAGE_CREATE: self.__decode_create,
            MESSAGE_CREATED: self.__decode_created,
            MESSAGE_EXTEND: self.__decode_extend,
            MESSAGE_EXTENDED: self.__decode_extended,
            MESSAGE_DATA: self.__decode_data,
            MESSAGE_PING: lambda offset, data: PingMessage(),
            MESSAGE_PONG: lambda offset, data: PongMessage(),
        }

    def encode(self, message_type, message):
        """
        Encodes an object into a byte string
        @param str message_type: the messages type (see the constants)
        @param BaseMessage message: the message to serialize
        @return: the message in byte format
        @rtype: str
        """
        return message_type + self.encode_functions[message_type](message)

    def decode(self, data, offset=0):
        """
        Decode a byte string to a message
        @param str data: raw byte string to decode
        @param int offset: the offset to start at
        @return: the message in object format
        @rtype: BaseMessage
        """
        message_type = data[offset]
        assert message_type > 0
        return message_type, self.decode_functions[message_type](
            data, offset + 1)

    def get_circuit_and_data(self, message_buffer, offset=0):
        """
        Get the circuit id and the payload byte string from a byte string
        @param str message_buffer: the byte string to parse
        @param int offset: the offset to start decoding from
        @rtype (int, str)
        """
        circuit_id, = struct.unpack_from("!L", message_buffer[offset:offset+4])
        offset += 4

        return circuit_id, message_buffer[offset:]

    def get_type(self, data):
        """
        Gets the type from a raw byte string

        @param str data: the raw byte string to get the type of
        @rtype: str
        """
        return data[0]

    def add_circuit(self, data, new_id):
        """
        Prepends the circuit id to the raw byte string
        @param str data: the raw byte string to prepend the circuit id to
        @param int new_id: the circuit id to prepend
        @rtype: str
        """
        return struct.pack("!L", new_id) + data

    def __encode_extend(self, extend_message):
        extend_with = extend_message.extend_with
        key = extend_message.key

        data = "".join([
            struct.pack("!HH", len(extend_with), len(key)),
            extend_with,
            key
        ])

        return data

    def __decode_extend(self, message_buffer, offset=0):
        if len(message_buffer) < offset + 4:
            raise ValueError(
                "Cannot unpack extend_with, insufficient packet size")

        extendwith_length, key_length = struct.unpack_from("!HH", message_buffer[offset:offset+4])
        offset += 4

        extend_with = message_buffer[offset:offset + extendwith_length]
        offset += extendwith_length

        key = message_buffer[offset:offset+key_length]

        message = ExtendMessage(extend_with)
        message.key = key
        return message

    def __encode_data(self, data_message):
        if data_message.destination is None:
            (host, port) = ("0.0.0.0", 0)
        else:
            (host, port) = data_message.destination

        if data_message.origin is None:
            origin = ("0.0.0.0", 0)
        else:
            origin = data_message.origin

        return ''.join([
            struct.pack(
                "!HHHHL", len(host), port, len(origin[0]),
                origin[1], len(data_message.data)
            ),
            host,
            origin[0],
            data_message.data
        ])

    def __decode_data(self, message_buffer, offset=0):
        host_length, port, origin_host_length, origin_port, payload_length = \
            struct.unpack_from("!HHHHL", message_buffer, offset)
        offset += 12

        if len(message_buffer) < offset + host_length:
            raise ValueError("Cannot unpack Host, insufficient packet size")
        host = message_buffer[offset:offset + host_length]
        offset += host_length

        destination = (host, port)

        if len(message_buffer) < offset + origin_host_length:
            raise ValueError(
                "Cannot unpack Origin Host, insufficient packet size")
        origin_host = message_buffer[offset:offset + origin_host_length]
        offset += origin_host_length

        origin = (origin_host, origin_port)

        if origin == ("0.0.0.0", 0):
            origin = None

        if destination == ("0.0.0.0", 0):
            destination = None

        if payload_length == 0:
            payload = None
        else:
            if len(message_buffer) < offset + payload_length:
                raise ValueError(
                    "Cannot unpack Data, insufficient packet size")
            payload = message_buffer[offset:offset + payload_length]

        return DataMessage(destination, payload, origin)

    def __encode_created(self, message):
        # if len(message.candidate_list) % 16 > 0:
        #     raise Exception("Should be multiple of 16")

        #key = long_to_bytes(messages.key, DIFFIE_HELLMAN_MODULUS_SIZE / 8)
        return struct.pack("!H", len(message.key)) + message.key + \
               message.candidate_list

    def __decode_created(self, message_buffer, offset=0):
        key_length, = struct.unpack_from("!H",
                                         message_buffer[offset:offset + 2])
        offset += 2
        key = message_buffer[offset:offset + key_length]
        offset += key_length

        encrypted_candidate_list = message_buffer[offset:]

        # if len(encrypted_candidate_list) % 16 > 0:
        #     raise Exception("Should be multiple of 16")

        message = CreatedMessage(encrypted_candidate_list)
        message.key = key
        return message

    def __encode_extended(self, message):
        return struct.pack("!H", len(message.key)) + message.key + \
               message.candidate_list

    def __decode_extended(self, message_buffer, offset=0):
        key_length, = struct.unpack_from("!H", message_buffer[offset:offset + 2])
        offset += 2
        key = message_buffer[offset:offset+key_length]
        offset += key_length

        encrypted_candidate_list = message_buffer[offset:]

        return ExtendedMessage(key, encrypted_candidate_list)

    def __encode_create(self, create_message):
        """
        :type create_message : CreateMessage
        """
        return "".join([
            struct.pack("!HH", len(create_message.key), len(create_message.public_key)),
            create_message.key,
            create_message.public_key
        ])

    def __decode_create(self, message_buffer, offset=0):
        len_key, len_pub_key = struct.unpack_from("!HH", message_buffer[offset:offset+4])
        offset += 4

        key = message_buffer[offset:offset+len_key]
        offset += len_key

        public_key = message_buffer[offset:offset + len_pub_key]
        offset += len_pub_key

        return CreateMessage(key, public_key)
########NEW FILE########
__FILENAME__ = crypto
from Crypto.Util.number import bytes_to_long, long_to_bytes
from Tribler.community.privatesemantic.crypto.optional_crypto import mpz, rand, aes_decrypt_str, aes_encrypt_str
from collections import defaultdict
import hashlib
import logging
from Tribler.Core.Utilities import encoding
from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.community.anontunnel.events import TunnelObserver


from Tribler.community.anontunnel.globals import MESSAGE_CREATED, ORIGINATOR, \
    ENDPOINT, MESSAGE_CREATE, MESSAGE_EXTEND, MESSAGE_EXTENDED, \
    DIFFIE_HELLMAN_MODULUS, DIFFIE_HELLMAN_MODULUS_SIZE, \
    DIFFIE_HELLMAN_GENERATOR
from Tribler.dispersy.util import attach_runtime_statistics


class CryptoError(Exception):
    pass


class Crypto(TunnelObserver):

    def __init__(self):
        TunnelObserver.__init__(self)
        self.encrypt_outgoing_packet_content = defaultdict()
        self.decrypt_incoming_packet_content = defaultdict()
        self._logger = logging.getLogger(__name__)

    def outgoing_packet_crypto(self, sock_addr, circuit, message_type, message, payload):
        return payload

    def incoming_packet_crypto(self, sock_addr, circuit, payload):
        return payload

    def relay_packet_crypto(self, destination, circuit, message_type, content):
        return content

    def handle_incoming_packet(self, sock_addr, circuit_id, data):
        """
        As soon as a packet comes in it has to be decrypted depending on candidate / circuit id
        @param sock_addr: The sock_addr of the packet
        @param circuit_id: The circuit ID in the packet
        @param data: The packet data
        @return: The unencrypted data
        """

        data = self.incoming_packet_crypto(sock_addr, circuit_id, data)
        if not data:
            return None
        return data

    def handle_incoming_packet_content(self, sock_addr, circuit_id, payload, packet_type):
        """
        As soon as an incoming packet is decrypted, the content has to be decrypted
        depending on the packet type
        @param sock_addr: The originator of the packet
        @param circuit_id: The circuit ID in the packet
        @param payload: The packet data
        @param packet_type: The type of the packet
        @return: The payload with unencrypted content
        """

        if packet_type in self.decrypt_incoming_packet_content:
            payload = self.decrypt_incoming_packet_content[packet_type](sock_addr, circuit_id, payload)
        if not payload:
            return None
        return payload

    def handle_outgoing_packet(self, destination, circuit_id, message_type, message, content):
        """
        Outgoing packets have to be encrypted according to the destination, packet type and
        circuit identifier
        @param destination: The originator of the packet
        @param circuit_id: The circuit ID in the packet
        @param message_type: The type of the packet
        @param content: The packet data
        @return: The encrypted content
        """
        try:
            content = self.outgoing_packet_crypto(destination, circuit_id, message_type, message, content)
            return content
        except:
            self._logger.exception("Cannot encrypt outgoing packet content")
            return None

    def handle_outgoing_packet_content(self, destination, circuit_id, message, message_type):
        """
        Content of outgoing packets have to be encrypted according to the destination, 4
        message type and circuit identifier
        @param destination: The originator of the packet
        @param circuit_id: The circuit ID in the packet
        @param message_type: The type of the packet
        @param message: The message
        @return: The message with encrypted content
        """

        try:
            if message_type in self.encrypt_outgoing_packet_content:
                message = self.encrypt_outgoing_packet_content[message_type](destination, circuit_id, message)
            return message
        except:
            self._logger.exception("Cannot encrypt outgoing packet content")
            return None

    def handle_relay_packet(self, direction, sock_addr, circuit_id, data):
        """
        Relayed messages have to be encrypted / decrypted depending on direction, sock address and
        circuit identifier
        @param direction: direction of the packet
        @param circuit_id: The circuit ID in the packet
        @param sock_addr: socket address of the originator of the message
        @param data: The message data
        @return: The message data, en- / decrypted according to the circuitdirection
        """
        try:
            data = self.relay_packet_crypto(direction, sock_addr, circuit_id, data)
            return data
        except:
            self._logger.error("Cannot crypt relay packet")
            return None

    def is_candidate_compatible(self, candidate):
        """
        Test if we can use this candidate, and its key, to encrypt/decrypt messages
        """
        return True

    def is_key_compatible(self, key):
        """
        Test if we can use this key, to encrypt/decrypt messages
        """
        return True


class NoCrypto(Crypto):
    def __init__(self):
        Crypto.__init__(self)
        self.proxy = None
        self.key_to_forward = None
        self.encrypt_outgoing_packet_content[MESSAGE_CREATED] = self._encrypt_created_content
        self.decrypt_incoming_packet_content[MESSAGE_CREATED] = self._decrypt_created_content
        self.decrypt_incoming_packet_content[MESSAGE_EXTENDED] = self._decrypt_extended_content


    def set_proxy(self, proxy):
        """
        Method which enables the "nocrypto" cryptography settings for the given
        community. NoCrypto encodes and decodes candidate lists, everything is
        passed as a string in the messages

        @param ProxyCommunity proxy: Proxy community to which this crypto
         object is coupled
        """
        self.proxy = proxy

    def disable(self):
        """
        Disables the crypto settings
        """
        self.outgoing_packet_crypto = lambda sock_addr, circuit, message, payload: payload
        self.incoming_packet_crypto = lambda sock_addr, circuit, payload: payload
        self.relay_packet_crypto = lambda destination, circuit, message_type, content: content
        self.encrypt_outgoing_packet_content = defaultdict()
        self.decrypt_incoming_packet_content = defaultdict()

    def _encrypt_created_content(self, sock_addr, circuit_id, message):
        """
        Candidate list must be converted to a string in nocrypto

        @param sock_addr: Destination of the message
        @param int circuit_id: Circuit identifier
        @param CreatedMessage message: Message as passed from the community
        @return CreatedMessage: Version of the message with candidate string
        """
        message.candidate_list = encode(message.candidate_list)
        return message

    def _decrypt_created_content(self, sock_addr, circuit_id, message):
        """
        If created is for us, decode candidate list from string to dict

        @param sock_addr: Sender of the message
        @param int circuit_id: Circuit identifier
        @param CreatedMessage message: Message as passed from the community
        @return CreatedMessage: Message with candidates as dict
        """
        if circuit_id in self.proxy.circuits:
            _, message.candidate_list = decode(message.candidate_list)
        return message

    def _decrypt_extended_content(self, sock_addr, circuit_id, message):
        """
        Convert candidate list from string to dict

        @param sock_addr: Sender of the message
        @param int circuit_id: Circuit identifier
        @param ExtendedMessage message: Message as passed from the community
        @return ExtendedMessage: Extended message with candidate list as dict
        """
        _, message.candidate_list = decode(message.candidate_list)
        return message


class DefaultCrypto(Crypto):

    @staticmethod
    def _generate_diffie_secret():
        """
        Generates a new Diffie Hellman g^x. Note the mpz lib used for Windows
        @return: tuple of x and g^x
        """
        dh_secret = 0
        while dh_secret >= DIFFIE_HELLMAN_MODULUS or dh_secret < 2:
              dh_secret = rand("next", DIFFIE_HELLMAN_MODULUS)
        dh_secret = mpz(dh_secret)

        dh_first_part = mpz(pow(DIFFIE_HELLMAN_GENERATOR, dh_secret, DIFFIE_HELLMAN_MODULUS))
        return dh_secret, dh_first_part

    def __init__(self):
        Crypto.__init__(self)
        self.proxy = None
        self.my_curve = None
        """ :type proxy: ProxyCommunity """
        self._logger = logging.getLogger(__name__)
        self._received_secrets = {}
        self.session_keys = {}
        self.encrypt_outgoing_packet_content[MESSAGE_CREATE] = self._encrypt_create_content
        self.encrypt_outgoing_packet_content[MESSAGE_CREATED] = self._encrypt_created_content
        self.encrypt_outgoing_packet_content[MESSAGE_EXTEND] = self._encrypt_extend_content
        self.encrypt_outgoing_packet_content[MESSAGE_EXTENDED] = self._encrypt_extended_content
        self.decrypt_incoming_packet_content[MESSAGE_CREATE] = self._decrypt_create_content
        self.decrypt_incoming_packet_content[MESSAGE_CREATED] = self._decrypt_created_content
        self.decrypt_incoming_packet_content[MESSAGE_EXTEND] = self._decrypt_extend_content
        self.decrypt_incoming_packet_content[MESSAGE_EXTENDED] = self._decrypt_extended_content

    def is_key_compatible(self, key):
        his_curve = self.proxy.crypto.get_curve(key)
        return self.my_curve == his_curve

    def on_break_relay(self, relay_key):
        """
        Method called whenever a relay is broken after for example a timeout
        or an invalid packet. Callback from the community to remove the session
        key
        @param relay_key:
        """
        if relay_key in self.session_keys:
            del self.session_keys[relay_key]

    def set_proxy(self, proxy):
        """
        Method which enables the "defaultcrypto" cryptography settings for
        the given community. Default crypto uses cryptography for all message
        types, based on exchanged secrets established with DIFFIE HELLMAN and
        Elliptic Curve Elgamal. See documentation for extra info.

        @param ProxyCommunity proxy: Proxy community to which this crypto
         object is coupled
        """
        self.proxy = proxy
        proxy.observers.append(self)

        self.my_curve = self.proxy.crypto.get_curve(self.proxy.my_member._ec)

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _encrypt_create_content(self, sock_addr, circuit_id, message):
        """
        Method which encrypts the contents of a CREATE message before it
        is being sent. The only thing in a CREATE message that needs to be
        encrypted is the first part of the DIFFIE HELLMAN handshake, which is
        created in this method.

        @param sock_addr: Destination of the message
        @param int circuit_id: Circuit identifier
        @param CreateMessage message: Message as passed from the community
        @return CreateMessage: Version of the message with encrypted contents
        """

        pub_key = message.destination_key
        message.public_key = self.proxy.crypto.key_to_bin(self.proxy.my_member._ec.pub())

        if circuit_id in self.proxy.circuits:
            dh_secret, dh_first_part = self._generate_diffie_secret()

            encrypted_dh_first_part = self.proxy.crypto.encrypt(
                pub_key, long_to_bytes(dh_first_part))
            message.key = encrypted_dh_first_part

            hop = self.proxy.circuits[circuit_id].unverified_hop
            hop.dh_secret = dh_secret
            hop.dh_first_part = dh_first_part
            hop.public_key = pub_key
        else:
            message.key = self.key_to_forward
            self.key_to_forward = None

        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _decrypt_create_content(self, sock_addr, circuit_id, message):
        """
        The first part of the DIFFIE HELLMAN handshake is encrypted with
        Elgamal and is decrypted here

        @param sock_addr: Sender of the message
        @param int circuit_id: Circuit identifier
        @param CreateMessage message: Message as passed from the community
        @return CreateMessage: Message with decrypted contents
        """
        relay_key = (sock_addr, circuit_id)
        my_key = self.proxy.my_member._ec
        dh_second_part = mpz(bytes_to_long(self.proxy.crypto.decrypt(my_key, message.key)))
        message.key = dh_second_part

        if dh_second_part < 2 or dh_second_part > DIFFIE_HELLMAN_MODULUS - 1:
            self._logger.warning("Invalid DH data received over circuit {}.".format(circuit_id))
            return None

        self._received_secrets[relay_key] = dh_second_part
        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _encrypt_extend_content(self, sock_addr, circuit_id, message):
        """
        Method which encrypts the contents of an EXTEND message before it
        is being sent. The only thing in an EXTEND message that needs to be
        encrypted is the first part of the DIFFIE HELLMAN handshake, which is
        created in this method.

        @param sock_addr: Destination of the message
        @param int circuit_id: Circuit identifier
        @param ExtendMessage message: Message as passed from the community
        @return ExtendMessage: Version of the message with encrypted contents
        """
        dh_secret, dh_first_part = self._generate_diffie_secret()

        pub_key = self.proxy.circuits[circuit_id].unverified_hop.public_key

        encrypted_dh_first_part = self.proxy.crypto.encrypt(
            pub_key, long_to_bytes(dh_first_part))
        message.key = encrypted_dh_first_part

        hop = self.proxy.circuits[circuit_id].unverified_hop
        hop.dh_first_part = dh_first_part
        hop.dh_secret = dh_secret

        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _decrypt_extend_content(self, sock_addr, circuit_id, message):
        """
        Nothing is encrypted in an Extend message

        @param sock_addr: Sender of the message
        @param int circuit_id: Circuit identifier
        @param ExtendMessage message: Message as passed from the community
        @return ExtendMessage: Message with decrypted contents
        """
        self.key_to_forward = message.key
        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _encrypt_created_content(self, sock_addr, circuit_id, message):
        """
        Method which encrypts the contents of a CREATED message before it
        is being sent. There are two things that need to be encrypted in a
        CREATED message. The second part of the DIFFIE HELLMAN handshake, which
        is being generated and encrypted in this method, and the candidate
        list, which is passed from the community.

        @param sock_addr: Destination of the message
        @param int circuit_id: Circuit identifier
        @param CreatedMessage message: Message as passed from the community
        @return CreatedMessage: Version of the message with encrypted contents
        """
        relay_key = (sock_addr, circuit_id)
        dh_secret, _ = self._generate_diffie_secret()

        key = pow(self._received_secrets[relay_key],
                  dh_secret, DIFFIE_HELLMAN_MODULUS)

        m = hashlib.sha256()
        m.update(str(key))
        key = m.digest()[0:16]

        self.session_keys[relay_key] = key
        return_key = pow(DIFFIE_HELLMAN_GENERATOR, dh_secret,
                         DIFFIE_HELLMAN_MODULUS)
        message.key = long_to_bytes(return_key)

        encoded_dict = encoding.encode(message.candidate_list)
        message.candidate_list = aes_encrypt_str(self.session_keys[relay_key], encoded_dict)

        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _decrypt_created_content(self, sock_addr, circuit_id, message):
        """
        Nothing to decrypt if you're not the originator of the circuit. Else,
        The candidate list should be decrypted as if it was an Extended
        message.

        @param sock_addr: Sender of the message
        @param int circuit_id: Circuit identifier
        @param CreatedMessage message: Message as passed from the community
        @return CreatedMessage: Message with decrypted contents
        """
        if circuit_id in self.proxy.circuits:
            return self._decrypt_extended_content(
                sock_addr, circuit_id, message)
        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _encrypt_extended_content(self, sock_addr, circuit_id, message):
        """
        Everything is already encrypted in an Extended message

        @param sock_addr: Destination of the message
        @param int circuit_id: Circuit identifier
        @param ExtendedMessage | CreatedMessage message: Message as passed
        from the community
        @return ExtendedMessage: Same
        """
        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def _decrypt_extended_content(self, sock_addr, circuit_id, message):
        """
        This method decrypts the contents of an encrypted Extended message.
        If the candidate list is undecryptable, the message is malformed and
        the circuit should be broken.

        @param sock_addr: Sender of the message
        @param int circuit_id: Circuit identifier
        @param ExtendedMessage|CreatedMessage message: Message as passed from
        the community
        @return ExtendedMessage|CreatedMessage: Extended message with
        unencrypted contents
        """
        unverified_hop = self.proxy.circuits[circuit_id].unverified_hop

        dh_second_part = mpz(bytes_to_long(message.key))

        if dh_second_part < 2 or dh_second_part > DIFFIE_HELLMAN_MODULUS - 1:
            self._logger.warning("Invalid DH data received over circuit {}.".format(circuit_id))
            return None

        session_key = pow(dh_second_part,
                          unverified_hop.dh_secret,
                          DIFFIE_HELLMAN_MODULUS)
        m = hashlib.sha256()
        m.update(str(session_key))
        key = m.digest()[0:16]
        unverified_hop.session_key = key
        try:
            encoded_dict = aes_decrypt_str(unverified_hop.session_key, message.candidate_list)
            _, cand_dict = encoding.decode(encoded_dict)
            message.candidate_list = cand_dict
        except:
            reason = "Can't decrypt candidate list!"
            self._logger.exception(reason)
            self.proxy.remove_circuit(circuit_id, reason)
            return None

        return message

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def outgoing_packet_crypto(self, sock_addr, circuit_id,
                                message_type, message, content):
        """
        Apply crypto to outgoing messages. The current protocol handles 3
        distinct cases: CREATE/CREATED, ORIGINATOR, ENDPOINT / RELAY.

        Messages of type CREATE or CREATED are encrypted using Elgamal, when
        these messages are received they need to be encrypted using the
        recipients PUBLIC KEY.

        If you have a SESSION KEY for the outgoing message use it to encrypt
        the packet, in this case you are a hop of the circuit. This adds a
        layer to the onion.

        If you do not have a SESSION KEY for the outgoing message but created
        the circuit encrypt it with the SESSION KEY linked to the circuit
        itself

        @param sock_addr: the recipient of the message
        @param int circuit_id: the circuit to sent the message over
        @param str message_type: the message's type
        @param str content: the raw (serialized) content of the message
        @rtype: str
        @return: the encrypted payload
        """

        relay_key = (sock_addr, circuit_id)

        # CREATE and CREATED have to be Elgamal encrypted
        if message_type == MESSAGE_CREATED or message_type == MESSAGE_CREATE:
            candidate_pub_key = message.destination_key if message_type == MESSAGE_CREATE \
                else self.proxy.crypto.key_from_public_bin(message.reply_to.public_key)

            content = self.proxy.crypto.encrypt(candidate_pub_key, content)
        # Else add AES layer
        elif relay_key in self.session_keys:
            content = aes_encrypt_str(self.session_keys[relay_key], content)
        # If own circuit, AES layers have to be added
        elif circuit_id in self.proxy.circuits:
            # I am the originator so I have to create the full onion
            circuit = self.proxy.circuits[circuit_id]
            hops = circuit.hops
            for hop in reversed(hops):
                content = aes_encrypt_str(hop.session_key, content)
        else:
            raise CryptoError("Don't know how to encrypt outgoing message")

        return content

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def relay_packet_crypto(self, direction, sock_addr, circuit_id, data):
        """
        Crypto RELAY messages. Two distinct cases are considered: relaying to
        the ENDPOINT and relaying back to the ORIGINATOR.

        When relaying to the ENDPOINT we need to strip one layer of the onion,
        before forwarding the packet to the next hop. This is done by
        decrypting with our SESSION_KEY.

        In the case that we relay towards the ORIGINATOR an additional onion
        layer must be added. This is done by encrypting with our SESSION KEY

        @param str direction: the direction of the relay
        @param sock_addr: the destination of the relay message
        @param circuit_id: the destination circuit
        @param data: the data to relay
        @return: the onion encrypted payload
        @rtype: str
        """
        relay_key = (sock_addr, circuit_id)
        next_relay = self.proxy.relay_from_to[relay_key]
        next_relay_key = (next_relay.sock_addr, next_relay.circuit_id)

        # Message is going downstream so I have to add my onion layer
        if direction == ORIGINATOR:
            data = aes_encrypt_str(
                self.session_keys[next_relay_key], data)

        # Message is going upstream so I have to remove my onion layer
        elif direction == ENDPOINT:
            data = aes_decrypt_str(
                self.session_keys[relay_key], data)
        else:
            raise ValueError("The parameter 'direction' must be either"
                             "ORIGINATOR or ENDPOINT")

        return data

    @attach_runtime_statistics(u"{0.__class__.__name__}.{function_name}")
    def incoming_packet_crypto(self, sock_addr, circuit_id, data):
        """
        Decrypt incoming packets. Three cases are considered. The case that
        we are the ENDPOINT of the circuit, the case that we are the ORIGINATOR
        and finally the case that we are neither. This means that this is our
        first packet on this circuit and that it MUST be a CREATE or CREATED
        message

        @todo: Check whether it really is a CREATE or CREATED message ?

        @param sock_addr: the candidate we got the message from
        @param int circuit_id: the circuit we got the message on
        @param str data: the raw payload we received
        @return: the decrypted payload
        @rtype: str
        """

        relay_key = (sock_addr, circuit_id)
        # I'm the last node in the circuit, probably an EXTEND message,
        # decrypt with AES
        if relay_key in self.session_keys:

            try:
                # last node in circuit, circuit already exists
                return aes_decrypt_str(self.session_keys[relay_key], data)
            except:
                self._logger.warning("Cannot decrypt a message destined for us, the end of a circuit.")
                return None

        # If I am the circuits originator I want to peel layers
        elif circuit_id in self.proxy.circuits and len(
                self.proxy.circuits[circuit_id].hops) > 0:

            try:
                # I am the originator so I'll peel the onion skins
                for hop in self.proxy.circuits[circuit_id].hops:
                    data = aes_decrypt_str(hop.session_key, data)

                return data
            except:
                self._logger.warning("Cannot decrypt packet. It should be a packet coming of our own circuit, but we cannot peel the onion.")
                return None

        # I don't know the sender! Let's decrypt with my private Elgamal key
        else:
            try:
                # last node in circuit, circuit does not exist yet,
                # decrypt with Elgamal key
                self._logger.debug(
                    "Circuit does not yet exist, decrypting with my Elgamal key")
                my_key = self.proxy.my_member._ec
                data = self.proxy.crypto.decrypt(my_key, data)

                return data
            except:
                self._logger.warning("Cannot decrypt packet, should be an initial packet encrypted with our public Elgamal key");
                return None


class OpportunisticCrypto(DefaultCrypto):

    def __init__(self):
        DefaultCrypto.__init__(self)
        self.counters = {}
        self.missed_packets = {}

    def initialize_session_key(self, session_key):
        self.counters[session_key] = 0
        self.missed_packets[session_key] = {}

    def get_key(self, session_key, counter):
        return aes_encrypt_str(session_key, str(counter))

    def increment_counter_for_session_key(self, session_key):
        self.counters[session_key] += 1

    def clean_missed_packets(self, session_key):
        for index, packet_number in self.missed_packets[session_key].items():
            if packet_number + 5 > self.counters[session_key]:
                del self.missed_packets[session_key][index]

    def add_missed_packet(self, session_key, missed_packet_number):
        self.missed_packets[session_key].append(missed_packet_number)

    def outgoing_packet_crypto(self, sock_addr, circuit_id,
                                message_type, message, content):

        relay_key = (sock_addr, circuit_id)

        # CREATE and CREATED have to be Elgamal encrypted
        if message_type == MESSAGE_CREATED or message_type == MESSAGE_CREATE:
            candidate_pub_key = message.destination_key if message_type == MESSAGE_CREATE \
                else self.proxy.crypto.key_from_public_bin(message.reply_to.public_key)

            content = self.proxy.crypto.encrypt(candidate_pub_key, content)
        # Else add AES layer
        elif relay_key in self.session_keys:
            content = aes_encrypt_str(self.session_keys[relay_key], content)
        # If own circuit, AES layers have to be added
        elif circuit_id in self.proxy.circuits:
            # I am the originator so I have to create the full onion
            circuit = self.proxy.circuits[circuit_id]
            hops = circuit.hops
            first = True
            for hop in reversed(hops):
                if first:
                    if not hop.session_key in self.counters:
                        self.initialize_session_key(hop.session_key)
                    key = self.get_key(hop.session_key, self.counters[hop.session_key])
                    content += str(self.counters[hop.session_key]).zfill(10)
                    self.increment_counter_for_session_key(hop.session_key)
                    content = aes_encrypt_str(key, content, 'aes_128_cbc')
                    #self._logger.error("Encrypted with counter {}, key {}"
                    #    , self.counters[hop.session_key], bytes_to_long(key))
                    first = False
                else:
                    content = aes_encrypt_str(hop.session_key, content)
        else:
            raise CryptoError("Don't know how to encrypt outgoing message")

        return content

    def incoming_packet_crypto(self, sock_addr, circuit_id, data):

        relay_key = (sock_addr, circuit_id)
        # I'm the last node in the circuit, probably an EXTEND or DATAREQUEST message,
        # decrypt with AES
        if relay_key in self.session_keys:
            session_key = self.session_keys[relay_key]
            if not session_key in self.counters:
                self.initialize_session_key(session_key)
            #try with missed packets
            for counter in self.missed_packets[session_key]:
                key = self.get_key(session_key, counter)
                message = aes_decrypt_str(key, data, 'aes_128_cbc')
                if message[-10:] != str(counter).zfill(10):
                    #self._logger.error("Couldn't decrypt with counter {}".format(counter))
                    continue
                #self._logger.error("Decrypted packet with missed counter {}: key {}".format(counter, bytes_to_long(key)))
                del self.missed_packets[session_key][counter]
                return message[0:-10]
            # try the current one and three after that
            for missed in [0, 1, 2, 3, 4, 5]:
                counter = self.counters[session_key] + missed
                key = self.get_key(session_key, counter)
                message = aes_decrypt_str(key, data, 'aes_128_cbc')
                if message[-10:] != str(counter).zfill(10):
                    #self._logger.error("Couldn't decrypt with counter {}".format(counter))
                    self.missed_packets[session_key].append(counter)
                    continue

                self.counters[session_key] = counter + 1
                self.clean_missed_packets(session_key)
                #self._logger.error("Decrypted packet with counter: {}, missed: {}, key: {}".format(counter, missed, bytes_to_long(key)))
                return message[0:-10]

            self._logger.warning("Cannot decrypt a message destined for us, the end of a circuit.")
            return None

        # If I am the circuits originator I want to peel layers
        elif circuit_id in self.proxy.circuits and len(
                self.proxy.circuits[circuit_id].hops) > 0:

            try:
                # I am the originator so I'll peel the onion skins
                for hop in self.proxy.circuits[circuit_id].hops:
                    data = aes_decrypt_str(hop.session_key, data)

                return data
            except:
                self._logger.warning("Cannot decrypt packet. It should be a packet coming of our own circuit, but we cannot peel the onion.")
                return None

        # I don't know the sender! Let's decrypt with my private Elgamal key
        else:
            try:
                # last node in circuit, circuit does not exist yet,
                # decrypt with Elgamal key
                self._logger.debug(
                    "Circuit does not yet exist, decrypting with my Elgamal key")
                my_key = self.proxy.my_member._ec
                data = self.proxy.crypto.decrypt(my_key, data)

                return data
            except:
                self._logger.warning("Cannot decrypt packet, should be an initial packet encrypted with our public Elgamal key");
                return None


########NEW FILE########
__FILENAME__ = endpoint
"""
Contains the DispersyBypassEndpoint to be used as Dispersy endpoint when the
ProxyCommunity is being used
"""


from Queue import Queue, Full
from threading import Thread
from Tribler.dispersy.endpoint import RawserverEndpoint
import logging
__author__ = 'chris'


class DispersyBypassEndpoint(RawserverEndpoint):
    """
    Creates an Dispersy Endpoint which bypasses the Dispersy message handling
    system for incoming packets matching set prefixes

    @type raw_server: Tribler.Core.RawServer.RawServer.RawServer
    @type port: int
    @type ip: str
    """
    def __init__(self, raw_server, port, ip="0.0.0.0"):
        super(DispersyBypassEndpoint, self).__init__(raw_server, port, ip)
        self.packet_handlers = {}
        self.queue = Queue()

        self._logger = logging.getLogger(__name__)

    def listen_to(self, prefix, handler):
        """
        Register a prefix to a handler

        @param str prefix: the prefix of a packet to register to the handler
        @param ((str, int), str) -> None handler: the handler that will be
        called for packets starting with the set prefix
        """
        self.packet_handlers[prefix] = handler

    def data_came_in(self, packets, cache=True):
        """
        Called by the RawServer when UDP packets arrive
        @type packets: list[((str, int), str)]
        @return:
        """
        normal_packets = []
        try:
            for packet in packets:

                prefix = next((p for p in self.packet_handlers if
                               packet[1].startswith(p)), None)
                if prefix:
                    self.packet_handlers[prefix](*packet)
                else:
                    normal_packets.append(packet)
        except Full:
            self._logger.warning(
                "DispersyBypassEndpoint cant keep up with incoming packets!")

        if normal_packets:
            super(DispersyBypassEndpoint, self).data_came_in(normal_packets, cache)
########NEW FILE########
__FILENAME__ = events
"""
Event handling related module

Can be safely imported as it does not import any dependencies in the global
 namespace
"""

__author__ = 'chris'


class TunnelObserver(object):
    """
    The TunnelObserver class is being notified by the ProxyCommunity in case
    a circuit / relay breaks, the global state changes or when data is being
    sent and received
    """

    def __init__(self):
        pass

    def on_break_circuit(self, circuit):
        """
        Called when a circuit has been broken and removed from the
        ProxyCommunity
        @param Circuit circuit: the circuit that has been broken
        """
        pass

    # noinspection PyMethodMayBeStatic
    def on_break_relay(self, relay_key):
        """
        Called when a relay has been broken due to inactivity
        @param ((str, int), int) relay_key: the identifier in
            (sock_addr, circuit) format
        """
        pass

    def on_incoming_from_tunnel(self, community, circuit, origin, data):
        """
        Called when we are receiving data from our circuit

        @type community: Tribler.community.anontunnel.community.ProxyCommunity
        @param Circuit circuit: the circuit the data was received on
        @param (str, int) origin: the origin of the packet in sock_addr format
        @param str data: the data received
        """
        pass

    def on_exiting_from_tunnel(self, circuit_id, sock_addr, destination, data):
        """
        Called when a DATA message has been received destined for the outside
        world

        @param int circuit_id: the circuit id where the the DATA message was
            received on
        @param (string, int) sock_addr: the relay candidate who relayed the message
        @param (str, int) destination: the packet's ultimate destination
        @param data: the payload
        """
        pass

    def on_tunnel_stats(self, community, member, candidate, stats):
        """
        Called when a STATS message has been received
        @param Member member: member according to authentication
        @type community: Tribler.community.anontunnel.community.ProxyCommunity
        @type candidate: Candidate
        @type stats: dict
        """
        pass

    def on_enter_tunnel(self, circuit_id, sock_addr, origin, payload):
        """
        Called when we received a packet from the outside world

        @param int circuit_id: the circuit for which we received data from the
            outside world
        @param (string, int) sock_addr: the known relay for this circuit
        @param (str, int) origin: the outside origin of the packet
        @param str payload: the packet's payload
        """
        pass

    def on_send_data(self, circuit_id, sock_addr, destination, payload):
        """
        Called when uploading data over a circuit

        @param int circuit_id: the circuit where data being uploaded over
        @param (string, int) sock_addr: the relay used to send data over
        @param (str, int) destination: the destination of the packet
        @param str payload: the packet's payload
        """
        pass

    def on_relay(self, from_key, to_key, direction, data):
        """
        Called when we are relaying data from_key to to_key

        @param ((str, int), int) from_key: the relay we are getting data from
        @param ((str, int), int) to_key: the relay we are sending data to
        @param direction: ENDPOINT if we are relaying towards the end of the
            tunnel, ORIGINATOR otherwise
        @type data: str
        @return:
        """
        pass

    def on_unload(self):
        """
        Called when the ProxyCommunity is being unloaded
        """
        pass


class CircuitPoolObserver(object):
    """
    An observer interface for circuit pools. Contains the event triggered when
    a new circuit has been added to the pool
    """
    def __init__(self):
        pass

    def on_circuit_added(self, pool, circuit):
        """
        A circuit has been added to the pool
        @param CircuitPool pool: the pool to which the circuit has been added
        @param Circuit circuit: the circuit that has been added
        """
        pass

########NEW FILE########
__FILENAME__ = exitsocket
from Tribler.community.anontunnel.payload import DataMessage

__author__ = 'Chris'

import logging


class TunnelExitSocket(object):
    """
    Sends incoming UDP packets back over the DispersyTunnelProxy.
    """

    def __init__(self, raw_server, proxy, circuit_id, destination_address):
        """
        Instantiate a new return handler

        :param proxy: instance to use to push packets back into upon reception
            of an external UDP packet
        :param circuit_id: the circuit to use to pass messages over in the
            tunnel proxy
        :param destination_address: the first hop of the circuit

        :type proxy: Tribler.community.anontunnel.community.ProxyCommunity

        """

        socket = raw_server.create_udpsocket(0, "0.0.0.0")
        raw_server.start_listening_udp(socket, self)

        self.proxy = proxy
        self.destination_address = destination_address
        self.circuit_id = circuit_id
        self.socket = socket
        self._logger = logging.getLogger(__name__)

    def sendto(self, data, destination):
        """
        Sends data to the destination over an UDP socket
        @param str data: the data to send
        @param (str, int) destination: the destination to send to
        """
        self.socket.sendto(data, destination)

    def data_came_in(self, packets):
        """
        Method called by the server when a new UDP packet has been received
        :param packets: list of tuples (source address, packet) of the UDP
            packets received
        """

        for source_address, packet in packets:
            self.proxy.tunnel_data_to_origin(
                circuit_id=self.circuit_id,
                sock_addr=self.destination_address,
                source_address=source_address,
                payload=packet)


class ShortCircuitExitSocket(object):
    """
    Only used when there are no circuits, it will be a 0-hop tunnel. So there
    is no anonymity at all.
    """

    def __init__(self, raw_server, proxy, circuit_id, destination_address):
        """
        Instantiate a new return handler

        :param proxy: instance to use to push packets back into upon reception
            of an external UDP packet
        :param destination_address: the first hop of the circuit

        :type proxy: ProxyCommunity

        """

        socket = raw_server.create_udpsocket(0, "0.0.0.0")
        raw_server.start_listening_udp(socket, self)

        self.proxy = proxy
        self.destination_address = destination_address
        self.socket = socket
        self.circuit_id = circuit_id
        self._logger = logging.getLogger(__name__)

    def data_came_in(self, packets):
        """
        Method called by the server when a new UDP packet has been received

        :param packets: list of tuples (source address, packet) of the UDP
            packets received
        """

        for source_address, packet in packets:
            message = DataMessage(("0.0.0.0", 0), packet, source_address)
            self.proxy.on_data(self.circuit_id, None, message)

    def sendto(self, data, destination):
        """
        Sends data to the destination over an UDP socket
        @param str data: the data to send
        @param (str, int) destination: the destination to send to
        """

        self.socket.sendto(data, destination)
########NEW FILE########
__FILENAME__ = exitstrategies
import socket
import logging
from Tribler.community.anontunnel import exitsocket
from Tribler.community.anontunnel.events import TunnelObserver

__author__ = 'chris'


class DefaultExitStrategy(TunnelObserver):
    def __init__(self, raw_server, proxy):
        """
        @type proxy: ProxyCommunity
        """

        TunnelObserver.__init__(self)
        self.raw_server = raw_server
        self._logger = logging.getLogger(__name__)

        self.proxy = proxy
        self._exit_sockets = {}

    def on_exiting_from_tunnel(self, circuit_id, sock_addr, destination,
                               data):
        try:
            exit_socket = self.get_exit_socket(circuit_id, sock_addr)
            exit_socket.sendto(data, destination)
        except socket.error:
            self._logger.error("Dropping packets while EXITing data")

    @staticmethod
    def create(proxy, raw_server, circuit_id, address):
        # There is a special case where the circuit_id is None, then we act as
        # EXIT node ourselves. In this case we create a ShortCircuitHandler
        # that bypasses dispersy by patching ENTER packets directly into the
        # Proxy's on_data event.

        if circuit_id in proxy.circuits and \
                        proxy.circuits[circuit_id].goal_hops == 0:
            return_handler = exitsocket.ShortCircuitExitSocket(
                raw_server, proxy, circuit_id, address)
        else:
            # Otherwise incoming ENTER packets should propagate back over the
            # Dispersy tunnel, we use the CircuitReturnHandler. It will use the
            # DispersyTunnelProxy.send_data method to forward the data packet
            return_handler = exitsocket.TunnelExitSocket(raw_server, proxy,
                                                         circuit_id, address)

        return return_handler

    def get_exit_socket(self, circuit_id, address):
        # If we don't have an exit socket yet for this socket, create one
        if not (circuit_id in self._exit_sockets):
            return_handler = self.create(self.proxy, self.raw_server,
                                         circuit_id, address)
            self._exit_sockets[circuit_id] = return_handler
        return self._exit_sockets[circuit_id]
########NEW FILE########
__FILENAME__ = extendstrategies
import logging
from Tribler.community.anontunnel.globals import CIRCUIT_STATE_EXTENDING, \
    MESSAGE_EXTEND
from Tribler.community.anontunnel.payload import ExtendMessage
from Tribler.community.anontunnel.routing import Hop

__author__ = 'chris'


class NoCandidatesException(ValueError):
    pass


class ExtendStrategy:
    def __init__(self):
        self._logger = logging.getLogger(__name__)

    def extend(self, candidate_list=None):
        if not candidate_list:
            candidate_list = []

        raise NotImplementedError()


class TrustThyNeighbour(ExtendStrategy):
    def __init__(self, proxy, circuit):
        """
        :type proxy: Tribler.community.anontunnel.community.ProxyCommunity
        :param circuit:
        """
        ExtendStrategy.__init__(self)
        self.proxy = proxy
        self.circuit = circuit

    def extend(self, candidate_list=None):
        if not candidate_list:
            candidate_list = []

        assert self.circuit.state == CIRCUIT_STATE_EXTENDING, \
            "Only circuits with state CIRCUIT_STATE_EXTENDING can be extended"
        assert self.circuit.goal_hops > len(self.circuit.hops), \
            "Circuits with correct length cannot be extended"

        self._logger.info("Trusting our tunnel to extend circuit %d",
                    self.circuit.circuit_id)
        self.proxy.send_message(self.circuit.first_hop,
                                self.circuit.circuit_id, MESSAGE_EXTEND,
                                ExtendMessage(None))


class NeighbourSubset(ExtendStrategy):
    def __init__(self, proxy, circuit):
        """
        :type proxy: Tribler.community.anontunnel.community.ProxyCommunity
        :param circuit:
        """
        ExtendStrategy.__init__(self)
        self.proxy = proxy
        self.circuit = circuit

    def extend(self, candidate_list=None):
        if not candidate_list:
            candidate_list = []

        assert self.circuit.state == CIRCUIT_STATE_EXTENDING, \
            "Only circuits with state CIRCUIT_STATE_EXTENDING can be extended"
        assert self.circuit.goal_hops > len(self.circuit.hops), \
            "Circuits with correct length cannot be extended"

        extend_hop_public_bin = next(iter(candidate_list), None)

        if not extend_hop_public_bin:
            raise NoCandidatesException("No candidates (with key) to extend, bailing out.")

        extend_hop_public_key = self.proxy.dispersy.crypto.key_from_public_bin(extend_hop_public_bin)
        hashed_public_key = self.proxy.dispersy.crypto.key_to_hash(extend_hop_public_key)

        self.circuit.unverified_hop = Hop(extend_hop_public_key)

        try:
            self._logger.info(
                "We chose %s from the list to extend circuit %d",
                hashed_public_key, self.circuit.circuit_id)

            self.proxy.send_message(
                self.circuit.first_hop, self.circuit.circuit_id,
                MESSAGE_EXTEND,
                ExtendMessage(extend_hop_public_bin))
        except BaseException:
            self._logger.exception("Encryption error")
            return False

        return True
########NEW FILE########
__FILENAME__ = globals
from Tribler.community.privatesemantic.crypto.optional_crypto import mpz
from Tribler.dispersy.candidate import CANDIDATE_WALK_LIFETIME

ORIGINATOR = "originator"
ENDPOINT = "endpoint"

ANON_DOWNLOAD_DELAY = 300

CIRCUIT_STATE_READY = 'READY'
CIRCUIT_STATE_EXTENDING = 'EXTENDING'
CIRCUIT_STATE_TO_BE_EXTENDED = 'TO_BE_EXTENDED'
CIRCUIT_STATE_BROKEN = 'BROKEN'

MESSAGE_CREATE = chr(1)
MESSAGE_CREATED = chr(2)
MESSAGE_EXTEND = chr(3)
MESSAGE_EXTENDED = chr(4)
MESSAGE_DATA = chr(5)
MESSAGE_PING = chr(6)
MESSAGE_PONG = chr(7)
MESSAGE_STATS = chr(10)

AES_KEY_SIZE = 16

MESSAGE_TYPE_STRING = {
    MESSAGE_CREATE: u'create',
    MESSAGE_CREATED: u'created',
    MESSAGE_EXTEND: u'extend',
    MESSAGE_EXTENDED: u'extended',
    MESSAGE_DATA: u'data',
    MESSAGE_PING: u'ping',
    MESSAGE_PONG: u'pong',
    MESSAGE_STATS: u'stats'
}

PING_INTERVAL = 10.0
# we use group 14 of the IETF rfc3526 with a 2048 bit modulus
# http://tools.ietf.org/html/rfc3526
DIFFIE_HELLMAN_GENERATOR = 2
DIFFIE_HELLMAN_MODULUS = mpz(0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE45B3DC2007CB8A163BF0598DA48361C55D39A69163FA8FD24CF5F83655D23DCA3AD961C62F356208552BB9ED529077096966D670C354E4ABC9804F1746C08CA18217C32905E462E36CE3BE39E772C180E86039B2783A2EC07A28FB5C55DF06F4C52C9DE2BCBF6955817183995497CEA956AE515D2261898FA051015728E5A8AACAA68FFFFFFFFFFFFFFFF)
DIFFIE_HELLMAN_MODULUS_SIZE = 2048
########NEW FILE########
__FILENAME__ = lengthstrategies
from random import randint

__author__ = 'chris'


class CircuitLengthStrategy(object):
    def __init__(self):
        pass

    def circuit_length(self):
        raise NotImplementedError()


class RandomCircuitLengthStrategy(CircuitLengthStrategy):
    def __init__(self, minimum_length, maximum_length):
        super(RandomCircuitLengthStrategy, self).__init__()
        self.min = int(minimum_length)
        self.max = int(maximum_length)

    def circuit_length(self):
        return randint(self.min, self.max)


class ConstantCircuitLength(CircuitLengthStrategy):
    def __init__(self, desired_length):
        super(ConstantCircuitLength, self).__init__()
        self.desired_length = int(desired_length)

    def circuit_length(self):
        return self.desired_length
########NEW FILE########
__FILENAME__ = Main
"""
AnonTunnel CLI interface
"""
import argparse
import logging.config
import os
import sys
import threading
import time
from threading import Thread, Event
from traceback import print_exc
from twisted.conch import stdio
from twisted.internet import reactor
from twisted.internet.stdio import StandardIO

from twisted.internet.task import LoopingCall
import twisted
from twisted.protocols.basic import LineReceiver

from Tribler.Core.RawServer.RawServer import RawServer
from Tribler.community.anontunnel import exitstrategies
from Tribler.community.anontunnel.Socks5.server import Socks5Server
from Tribler.community.anontunnel.community import ProxyCommunity, \
    ProxySettings
from Tribler.community.anontunnel.endpoint import DispersyBypassEndpoint
from Tribler.community.anontunnel.extendstrategies import TrustThyNeighbour, \
    NeighbourSubset
from Tribler.community.anontunnel.lengthstrategies import \
    RandomCircuitLengthStrategy, ConstantCircuitLength
from Tribler.community.anontunnel.selectionstrategies import \
    RandomSelectionStrategy, LengthSelectionStrategy
from Tribler.community.anontunnel.stats import StatsCrawler
from Tribler.community.privatesemantic.crypto.elgamalcrypto import \
    ElgamalCrypto
from Tribler.dispersy.dispersy import Dispersy
from Tribler.dispersy.util import call_on_reactor_thread


logging.config.fileConfig(
    os.path.dirname(os.path.realpath(__file__)) + "/logger.conf")

logger = logging.getLogger(__name__)

try:
    import yappi
except ImportError:
    logger.warning("Yappi not installed, profiling options won't be available")


class AnonTunnel():
    """
    The standalone AnonTunnel application. Does not depend on Tribler Session
    or LaunchManyCore but creates all dependencies by itself.

    @param int socks5_port: the SOCKS5 port to listen on, or None to disable
    the SOCKS5 server
    @param ProxySettings settings: the settings to pass to the ProxyCommunity
    @param bool crawl: whether to store incoming Stats messages using the
    StatsCrawler
    """

    def __init__(self, socks5_port, settings=None, crawl=False):
        self.crawl = crawl
        self.settings = settings
        self.server_done_flag = Event()
        self.raw_server = RawServer(self.server_done_flag,
                                    1,
                                    600.0,
                                    ipv6_enable=False,
                                    failfunc=lambda (e): print_exc(),
                                    errorfunc=lambda (e): print_exc())

        self.socks5_port = socks5_port
        self.socks5_server = None

        endpoint = DispersyBypassEndpoint(self.raw_server, port=10000)
        self.dispersy = Dispersy(endpoint, u".", u":memory:",
                                 crypto=ElgamalCrypto())

        self.community = None
        ''' @type: ProxyCommunity '''

    def __calc_diff(self, then, bytes_exit0, bytes_enter0, bytes_relay0):
        now = time.time()

        if not self.community or not then:
            return now, 0, 0, 0, 0, 0, 0

        diff = now - then

        stats = self.community.global_stats.stats
        relay_stats = self.community.global_stats.relay_stats

        speed_exit = (stats['bytes_exit'] - bytes_exit0) / diff if then else 0
        bytes_exit = stats['bytes_exit']

        speed_enter = (stats[
                           'bytes_enter'] - bytes_enter0) / diff if then else 0
        bytes_enter = stats['bytes_enter']

        relay_2 = sum([r.bytes[1] for r in relay_stats.values()])

        speed_relay = (relay_2 - bytes_relay0) / diff if then else 0
        bytes_relay = relay_2

        return now, speed_exit, speed_enter, speed_relay, \
               bytes_exit, bytes_enter, bytes_relay

    def __speed_stats(self):
        tmp = dict()
        tmp['time'] = None
        tmp['bytes_exit'] = 0
        tmp['bytes_enter'] = 0
        tmp['bytes_relay'] = 0

        def speed_stats_lc():
            stats = self.__calc_diff(tmp['time'], tmp['bytes_exit'], tmp['bytes_enter'],
                                     tmp['bytes_relay'] )
            time, speed_exit, speed_enter, speed_relay, bytes_exit, bytes_enter, bytes_relay = stats

            tmp['time'] = time
            tmp['bytes_exit'] = bytes_exit
            tmp['bytes_enter'] = bytes_enter
            tmp['bytes_relay'] = bytes_relay

            active_circuits = len(self.community.circuits)
            num_routes = len(self.community.relay_from_to) / 2

            print "CIRCUITS %d RELAYS %d EXIT %.2f KB/s ENTER %.2f KB/s RELAY %.2f KB/s\n" % (
                active_circuits, num_routes, speed_exit / 1024.0,
                speed_enter / 1024.0, speed_relay / 1024.0),

        lc = LoopingCall(speed_stats_lc)
        lc.start(3, now=True)

    def run(self):
        """
        Start the standalone AnonTunnel
        """

        self.dispersy.start()
        logger.error(
            "Dispersy is listening on port %d" % self.dispersy.lan_address[1])

        member = self.dispersy.get_new_member(u"NID_secp160k1")
        self.community = self.dispersy.define_auto_load(ProxyCommunity, member,
                                                   (False, self.settings),
                                                   load=True)[0]
        ''' @type: ProxyCommunity '''

        if self.socks5_server:
            self.socks5_server = Socks5Server(
                self.community, self.raw_server, self.socks5_port)
            self.socks5_server.start()

        exit_strategy = exitstrategies.DefaultExitStrategy(self.raw_server, self.community)
        self.community.observers.append(exit_strategy)

        if self.crawl:
            self.community.observers.append(
                StatsCrawler(self.dispersy, self.raw_server))

        ''' :type : Tribler.community.anontunnel.community.ProxyCommunity '''

        self.__speed_stats()
        raw_server_thread = Thread(target=self.raw_server.listen_forever, args=(None,))
        raw_server_thread.start()

    def stop(self):
        """
        Stop the standalone AnonTunnel
        """
        if self.dispersy:
            self.dispersy.stop()

        self.server_done_flag.set()

        if self.raw_server:
            self.raw_server.shutdown()


class LineHandler(LineReceiver):
    from os import linesep as delimiter

    def __init__(self, anon_tunnel, profile):
        self.anon_tunnel = anon_tunnel
        self.profile = profile

    def lineReceived(self, line):
        anon_tunnel = self.anon_tunnel
        profile = self.profile

        if line == 'threads':
            for thread in threading.enumerate():
                print "%s \t %d" % (thread.name, thread.ident)
        elif line == 'p':
            if profile:

                for func_stats in yappi.get_func_stats().sort("subtime")[:50]:
                    print "YAPPI: %10dx  %10.3fs" % (
                        func_stats.ncall, func_stats.tsub), func_stats.name
            else:
                print >> sys.stderr, "Profiling disabled!"

        elif line == 'P':
            if profile:
                filename = 'callgrindc_%d.yappi' % \
                           anon_tunnel.dispersy.lan_address[1]
                yappi.get_func_stats().save(filename, type='callgrind')
            else:
                print >> sys.stderr, "Profiling disabled!"

        elif line == 't':
            if profile:
                yappi.get_thread_stats().sort("totaltime").print_all()

            else:
                print >> sys.stderr, "Profiling disabled!"

        elif line == 'c':
            stats = anon_tunnel.community.global_stats.circuit_stats

            print "========\nCircuits\n========\n" \
                  "id\taddress\t\t\t\t\tgoal\thops\tIN (MB)\tOUT (MB)"
            for circuit_id, circuit in anon_tunnel.community.circuits.items():
                print "%d\t%s:%d\t%d\t%d\t\t%.2f\t\t%.2f" % (
                    circuit.circuit_id, circuit.first_hop[0],
                    circuit.first_hop[1],
                    circuit.goal_hops, len(circuit.hops),
                    stats[circuit_id].bytes_downloaded / 1024.0 / 1024.0,
                    stats[circuit_id].bytes_uploaded / 1024.0 / 1024.0
                )
        elif line == 'q':
            anon_tunnel.stop()
            os._exit(0)
            return
        elif line == 'r':
            print "circuit\t\t\tdirection\tcircuit\t\t\tTraffic (MB)"

            from_to = anon_tunnel.community.relay_from_to

            for key in from_to.keys():
                relay = from_to[key]

                print "%s-->\t%s\t\t%.2f" % (
                    (key[0], key[1]),
                    (relay.sock_addr, relay.circuit_id),
                    relay.bytes[1] / 1024.0 / 1024.0,
                )

def main(argv):
    """
    Start CLI interface of the AnonTunnel
    @param argv: the CLI arguments, except the first
    """
    parser = argparse.ArgumentParser(
        description='Anonymous Tunnel CLI interface')

    try:
        parser.add_argument('-p', '--socks5', help='Socks5 port')
        parser.add_argument('-y', '--yappi',
                            help="Profiling mode, either 'wall' or 'cpu'")
        parser.add_argument('-l', '--length-strategy', default=[], nargs='*',
                            help='Circuit length strategy')
        parser.add_argument('-s', '--select-strategy', default=[], nargs='*',
                            help='Circuit selection strategy')
        parser.add_argument('-e', '--extend-strategy', default='subset',
                            help='Circuit extend strategy')
        parser.add_argument('--max-circuits', nargs=1, default=10,
                            help='Maximum number of circuits to create')
        parser.add_argument('--crawl', default=False,
                            help='Record stats from others in results.db')
        parser.add_help = True
        args = parser.parse_args(sys.argv[1:])

    except argparse.ArgumentError:
        parser.print_help()
        sys.exit(2)

    socks5_port = None

    if args.yappi == 'wall':
        profile = "wall"
    elif args.yappi == 'cpu':
        profile = "cpu"
    else:
        profile = None

    if args.socks5:
        socks5_port = int(args.socks5)

    if profile:
        yappi.set_clock_type(profile)
        yappi.start(builtins=True)
        print "Profiling using %s time" % yappi.get_clock_type()['type']

    crawl = True if args.crawl else False
    proxy_settings = ProxySettings()

    # Set extend strategy
    if args.extend_strategy == 'delegate':
        logger.error("EXTEND STRATEGY DELEGATE: We delegate the selection of "
                     "hops to the rest of the circuit")
        proxy_settings.extend_strategy = TrustThyNeighbour
    elif args.extend_strategy == 'subset':
        logger.error("SUBSET STRATEGY DELEGATE: We delegate the selection of "
                     "hops to the rest of the circuit")
        proxy_settings.extend_strategy = NeighbourSubset
    else:
        raise ValueError("extend_strategy must be either random or delegate")

    # Circuit length strategy
    if args.length_strategy[:1] == ['random']:
        strategy = RandomCircuitLengthStrategy(*args.length_strategy[1:])
        proxy_settings.length_strategy = strategy
        logger.error("Using RandomCircuitLengthStrategy with arguments %s",
                     ', '.join(args.length_strategy[1:]))

    elif args.length_strategy[:1] == ['constant']:
        strategy = ConstantCircuitLength(*args.length_strategy[1:])
        proxy_settings.length_strategy = strategy
        logger.error(
            "Using ConstantCircuitLength with arguments %s",
            ', '.join(args.length_strategy[1:]))

    # Circuit selection strategies
    if args.select_strategy[:1] == ['random']:
        strategy = RandomSelectionStrategy(*args.select_strategy[1:])
        proxy_settings.selection_strategy = strategy
        logger.error("Using RandomCircuitLengthStrategy with arguments %s"
                     ', '.join(args.select_strategy[1:]))

    elif args.select_strategy[:1] == ['length']:
        strategy = LengthSelectionStrategy(*args.select_strategy[1:])
        proxy_settings.selection_strategy = strategy
        logger.error("Using LengthSelectionStrategy with arguments %s",
                     ', '.join(args.select_strategy[1:]))

    anon_tunnel = AnonTunnel(socks5_port, proxy_settings, crawl)
    ''' @type: AnonTunnel '''



    from twisted.internet import reactor

    StandardIO(LineHandler(anon_tunnel, profile))
    reactor.callWhenRunning(anon_tunnel.run)
    reactor.run()

if __name__ == "__main__":
    main(sys.argv[1:])

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload

__author__ = 'Chris'


#noinspection PyClassHasNoInit
class BaseMessage:
    pass


class PingMessage(BaseMessage):
    def __init__(self):
        pass


class PongMessage(BaseMessage):
    def __init__(self):
        pass


class CreateMessage(BaseMessage):
    def __init__(self, key="\0"*336, public_key="", destination_key=""):
        assert isinstance(key, basestring)
        assert isinstance(public_key, basestring)

        self.key = key
        self.public_key = public_key
        self.destination_key = destination_key


class CreatedMessage(BaseMessage):
    def __init__(self, candidate_list, reply_to=None):
        # Assert candidate_list is a list and that all items are strings
        assert all(isinstance(key, basestring) for key in candidate_list)
        assert reply_to is None or isinstance(reply_to, CreateMessage)

        self.key = ""
        self.candidate_list = candidate_list
        self.reply_to = reply_to


class ExtendMessage(BaseMessage):
    def __init__(self, extend_with):
        assert extend_with is None or isinstance(extend_with, basestring)

        self.extend_with = extend_with
        self.key = ""


class ExtendedMessage(BaseMessage):
    def __init__(self, key, candidate_list):
        assert isinstance(key, basestring)
        assert all(isinstance(key, basestring) for key in candidate_list)

        self.key = key
        self.candidate_list = candidate_list


class DataMessage(BaseMessage):
    def __init__(self, destination, data, origin=None):
        assert destination is None or isinstance(destination[0], basestring) and isinstance(destination[1], int)
        assert isinstance(data, basestring)
        assert origin is None or isinstance(origin[0], basestring) and isinstance(origin[1], int)

        self.destination = destination
        self.data = data
        self.origin = origin


class StatsPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, stats):
            super(StatsPayload.Implementation, self).__init__(meta)
            self.stats = stats
########NEW FILE########
__FILENAME__ = routing
import hashlib
import logging
import threading
import time
from M2Crypto.EC import EC_pub
from Tribler.community.anontunnel.events import TunnelObserver
from Tribler.community.anontunnel.globals import CIRCUIT_STATE_READY, \
    CIRCUIT_STATE_BROKEN, CIRCUIT_STATE_EXTENDING, PING_INTERVAL
from Tribler.dispersy.candidate import CANDIDATE_WALK_LIFETIME, Candidate

__author__ = 'chris'


class Circuit:
    """ Circuit data structure storing the id, state and hops """

    def __init__(self, circuit_id, goal_hops=0, first_hop=None, proxy=None):
        """
        Instantiate a new Circuit data structure
        :type proxy: ProxyCommunity
        :param int circuit_id: the id of the candidate circuit
        :param WalkCandidate first_hop: the first hop of the circuit
        :return: Circuit
        """

        self._broken = False
        self._hops = []
        self._logger = logging.getLogger(__name__)

        self.circuit_id = circuit_id
        self.first_hop = first_hop
        self.goal_hops = goal_hops
        self.extend_strategy = None
        self.last_incoming = time.time()

        self.proxy = proxy

        self.unverified_hop = None
        ''' :type : Hop '''

    @property
    def hops(self):
        """
        Return a read only tuple version of the hop-list of this circuit
        @rtype tuple[Hop]
        """
        return tuple(self._hops)

    def add_hop(self, hop):
        """
        Adds a hop to the circuits hop collection
        @param Hop hop: the hop to add
        """
        self._hops.append(hop)

    @property
    def state(self):
        """
        The circuit state, can be either:
         CIRCUIT_STATE_BROKEN, CIRCUIT_STATE_EXTENDING or CIRCUIT_STATE_READY
        @rtype: str
        """
        if self._broken:
            return CIRCUIT_STATE_BROKEN

        if len(self.hops) < self.goal_hops:
            return CIRCUIT_STATE_EXTENDING
        else:
            return CIRCUIT_STATE_READY

    @property
    def ping_time_remaining(self):
        """
        The time left before we consider the circuit inactive, when it returns
        0 a PING must be sent to keep the circuit, including relays at its hop,
        alive.
        """
        too_old = time.time() - 2 * PING_INTERVAL
        diff = self.last_incoming - too_old
        return diff if diff > 0 else 0

    def __contains__(self, other):
        if isinstance(other, Candidate):
            # TODO: should compare to a list here
            return other == self.first_hop

    def beat_heart(self):
        """
        Mark the circuit as active
        """
        self.last_incoming = time.time()

    def tunnel_data(self, destination, payload):
        """
        Convenience method to tunnel data over this circuit
        @param (str, int) destination: the destination of the packet
        @param str payload: the packet's payload
        @return bool: whether the tunnel request has succeeded, this is in no
         way an acknowledgement of delivery!
        """

        return self.proxy.tunnel_data_to_end(destination, payload, self)

    def destroy(self, reason='unknown'):
        """
        Destroys the circuit and calls the error callback of the circuit's
        deferred if it has not been called before

        @param str reason: the reason why the circuit is being destroyed
        """
        self._broken = True


class Hop:
    """
    Circuit Hop containing the address, its public key and the first part of
    the Diffie-Hellman handshake
    """

    def __init__(self, public_key=None):
        """
        @param None|EC_pub public_key: public key object of the hop
        """

        assert public_key is None or isinstance(public_key, EC_pub)

        self.session_key = None
        self.dh_first_part = None
        self.dh_secret = None
        self.address = None
        self.public_key = public_key

    @property
    def host(self):
        """
        The hop's hostname
        """
        if self.address:
            return self.address[0]
        return " UNKNOWN HOST "

    @property
    def port(self):
        """
        The hop's port
        """
        if self.address:
            return self.address[1]
        return " UNKNOWN PORT "


class RelayRoute(object):
    """
    Relay object containing the destination circuit, socket address and whether
    it is online or not
    """

    def __init__(self, circuit_id, sock_addr):
        """
        @type sock_addr: (str, int)
        @type circuit_id: int
        @return:
        """

        self.sock_addr = sock_addr
        self.circuit_id = circuit_id
        self.online = False
        self.last_incoming = time.time()

    @property
    def ping_time_remaining(self):
        """
        The time left before we consider the relay inactive
        """
        too_old = time.time() - CANDIDATE_WALK_LIFETIME - 5.0
        diff = self.last_incoming - too_old
        return diff if diff > 0 else 0


class CircuitPool(TunnelObserver):
    def __init__(self, size, name):
        super(CircuitPool, self).__init__()

        self._logger = logging.getLogger(__name__)
        self._logger.info("Creating a circuit pool of size %d with name '%s'", size, name)

        self.lock = threading.RLock()
        self.size = size
        self.circuits = set()
        self.allocated_circuits = set()
        self.name = name

        self.observers = []

    def on_break_circuit(self, circuit):
        if circuit in self.circuits:
            self.remove_circuit(circuit)

    @property
    def lacking(self):
        return max(0, self.size - len(self.circuits))

    @property
    def available_circuits(self):
        return [circuit
                for circuit in self.circuits
                if circuit not in self.allocated_circuits]

    def remove_circuit(self, circuit):
        self._logger.info("Removing circuit %d from pool '%s'", circuit.circuit_id, self.name)
        with self.lock:
            self.circuits.remove(circuit)

    def fill(self, circuit):
        self._logger.info("Adding circuit %d to pool '%s'", circuit.circuit_id, self.name)

        with self.lock:
            self.circuits.add(circuit)
            for observer in self.observers:
                observer.on_circuit_added(self, circuit)

    def deallocate(self, circuit):
        self._logger.info("Deallocate circuit %d from pool '%s'", circuit.circuit_id, self.name)

        with self.lock:
            self.allocated_circuits.remove(circuit)

    def allocate(self):
        with self.lock:
            try:
                circuit = next((c for c in self.circuits if c not in self.allocated_circuits))
                self.allocated_circuits.add(circuit)
                self._logger.info("Allocate circuit %d from pool %s", circuit.circuit_id, self.name)

                return circuit

            except StopIteration:
                if not self.lacking:
                    self._logger.warning("Growing size of pool %s from %d to %d", self.name, self.size, self.size*2)
                    self.size *= 2

                raise NotEnoughCircuitsException()


class NotEnoughCircuitsException(Exception):
    pass
########NEW FILE########
__FILENAME__ = selectionstrategies
import random
import logging

__author__ = 'chris'


class SelectionStrategy:
    """
    Base class for selection strategies
    """
    def __init__(self):
        self._logger = logging.getLogger(__name__)

    def select(self, circuits_to_select_from):
        """
        Selects a circuit from a list of candidates
        @param list[Circuit] circuits_to_select_from: the circuits to pick from
        @rtype: Circuit
        """
        pass


class RoundRobin(SelectionStrategy):
    """
    Selects circuits in round robin fashion
    """
    def __init__(self):
        SelectionStrategy.__init__(self)
        self.index = -1

    def select(self, circuits_to_select_from):
        self.index = (self.index + 1) % len(circuits_to_select_from)
        return circuits_to_select_from[self.index]


class RandomSelectionStrategy(SelectionStrategy):
    """
    Strategy that selects a circuit at random
    """

    def select(self, circuits_to_select_from):
        if not circuits_to_select_from:
            raise ValueError("Variable circuits_to_select must be a list of circuits")

        circuit = random.choice(circuits_to_select_from)
        return circuit


class LengthSelectionStrategy(SelectionStrategy):
    """
    Selects a circuit which length is between the min and max given (inclusive)
    """
    def __init__(self, minimum_length, maximum_length, random_selection=True):
        SelectionStrategy.__init__(self)
        self.min = int(minimum_length)
        self.max = int(maximum_length)
        self.random = random_selection

    def select(self, circuits_to_select_from):
        candidates = [c for c in circuits_to_select_from if
                      self.min <= len(c.hops) <= self.max]

        if not candidates:
            raise ValueError("No circuit matching the criteria")

        if self.random:
            return random.choice(candidates)
        else:
            return candidates[0]
########NEW FILE########
__FILENAME__ = connection
"""
Created on 3 jun. 2013

@author: Chris
"""
import logging
from socket import socket
from Tribler.community.anontunnel.Socks5 import conversion


class ConnectionState:
    """
    Enumeration of possible SOCKS5 connection states
    """
    def __init__(self):
        pass

    BEFORE_METHOD_REQUEST = 'BEFORE_METHOD_REQUEST'
    METHOD_REQUESTED = 'METHOD_REQUESTED'
    CONNECTED = 'CONNECTED'
    PROXY_REQUEST_RECEIVED = 'PROXY_REQUEST_RECEIVED'
    PROXY_REQUEST_ACCEPTED = 'PROXY_REQUEST_ACCEPTED'
    TCP_RELAY = 'TCP_RELAY'


class Socks5ConnectionObserver:
    """
    Socks5 Connection observer
    """

    def __init__(self):
        pass

    def on_udp_associate_request(self, connection, request):
        """

        @param Socks5Connection connection: the Socks5 connection we got the
        request on
        @param Request request: the request received
        """
        pass


class Socks5Connection(object):
    """
    SOCKS5 TCP Connection handler

    Supports a subset of the SOCKS5 protocol, no authentication and no support
    for TCP BIND requests
    """

    def __init__(self, single_socket, socks5_server):
        self.state = ConnectionState.BEFORE_METHOD_REQUEST
        self._logger = logging.getLogger(__name__)

        self.observers = []
        ''' :type : list[Socks5ConnectionObserver] '''

        self.single_socket = single_socket
        ''' :type : SingleSocket '''

        self.socks5_server = socks5_server
        """ :type : TcpConnectionHandler """

        self.buffer = ''
        self.tcp_relay = None
        self.udp_associate = None
        ''' :type : (Socks5Connection) -> socket '''

    def data_came_in(self, data):
        """
        Called by the TcpConnectionHandler when new data has been received.

        Processes the incoming buffer by attempting to read messages defined
        in the SOCKS5 protocol

        :param data: the data received
        :return: None
        """

        if len(self.buffer) == 0:
            self.buffer = data
        else:
            self.buffer = self.buffer + data

        if self.tcp_relay:
            self._try_tcp_relay()
        else:
            self._process_buffer()

    def _try_handshake(self):

        # Try to read a HANDSHAKE request
        offset, request = conversion.decode_methods_request(0, self.buffer)

        # No (complete) HANDSHAKE received, so dont do anything
        if request is None:
            return None

        # Consume the buffer
        self.buffer = self.buffer[offset:]

        assert isinstance(request, conversion.MethodRequest)

        # Only accept NO AUTH
        if request.version != 0x05 or 0x00 not in request.methods:
            self._logger.error("Client has sent INVALID METHOD REQUEST")
            self.buffer = ''
            self.close()
            return

        self._logger.info("Client {0} has sent METHOD REQUEST".format(
            (self.single_socket.get_ip(), self.single_socket.get_port())
        ))

        # Respond that we would like to use NO AUTHENTICATION (0x00)
        if self.state is not ConnectionState.CONNECTED:
            response = conversion.encode_method_selection_message(
                conversion.SOCKS_VERSION, 0x00)
            self.write(response)

        # We are connected now, the next incoming message will be a REQUEST
        self.state = ConnectionState.CONNECTED

    def _try_tcp_relay(self):
        """
        Forward the complete buffer to the paired TCP socket

        :return: None
        """
        self._logger.info("Relaying TCP data")
        self.tcp_relay.sendall(self.buffer)
        self.buffer = ''

    def deny_request(self, request, drop_connection=True):
        """
        Deny SOCKS5 request
        @param Request request: the request to deny
        @param bool drop_connection: whether to drop the connection or not
        """
        if self.state != ConnectionState.PROXY_REQUEST_RECEIVED:
            raise ValueError("There must be a request before we can deny it")

        self.state = ConnectionState.CONNECTED

        response = conversion.encode_reply(
            0x05, conversion.REP_COMMAND_NOT_SUPPORTED, 0x00,
            conversion.ADDRESS_TYPE_IPV4, "0.0.0.0", 0)

        self.write(response)

        if self.single_socket:
            self._logger.error(
                "DENYING SOCKS5 Request from {0}".format(
                (self.single_socket.get_ip(),
                 self.single_socket.get_port())
                )
            )

        if drop_connection:
            self.close()

    def accept_udp_associate(self, request, udp_socket):
        """
        Accept the UDP request given and redirect the client to the udp_socket
        @param request:
        @param socket udp_socket: the udp relay socket
        """

        if not isinstance(udp_socket, socket):
            raise ValueError("Parameter udp_socket must be of socket type")

        if self.state != ConnectionState.PROXY_REQUEST_RECEIVED:
            raise ValueError("SOCKS5 connection has not been established yet!")

        # We use same IP as the single socket, but the port number
        # comes from the newly created UDP listening socket
        ip = self.single_socket.get_myip()
        port = udp_socket.getsockname()[1]

        self._logger.warning(
            "Accepting UDP ASSOCIATE request from %s:%d, "
            "direct client to %s:%d",
            self.single_socket.get_ip(), self.single_socket.get_port(),
            ip, port)

        response = conversion.encode_reply(
            0x05, conversion.REP_SUCCEEDED, 0x00,
            conversion.ADDRESS_TYPE_IPV4, ip, port)
        self.write(response)

    def _try_request(self):
        """
        Try to consume a REQUEST message and respond whether we will accept the
        request.

        Will setup a TCP relay or an UDP socket to accommodate TCP RELAY and
        UDP ASSOCIATE requests. After a TCP relay is set up the handler will
        deactivate itself and change the Connection to a TcpRelayConnection.
        Further data will be passed on to that handler.

        :return: None
        """
        self._logger.debug("Client {0} has sent PROXY REQUEST".format(
            (self.single_socket.get_ip(), self.single_socket.get_port())
        ))
        offset, request = conversion.decode_request(0, self.buffer)

        if request is None:
            return None

        self.buffer = self.buffer[offset:]

        assert isinstance(request, conversion.Request)
        self.state = ConnectionState.PROXY_REQUEST_RECEIVED

        accept = True

        try:
            if request.cmd == conversion.REQ_CMD_UDP_ASSOCIATE:
                for observer in self.observers:
                    observer.on_udp_associate_request(self, request)

                accept = False
            elif request.cmd == conversion.REQ_CMD_BIND:
                response = conversion.encode_reply(
                    0x05, conversion.REP_SUCCEEDED, 0x00,
                    conversion.ADDRESS_TYPE_IPV4, "127.0.0.1", 1081)
                self.write(response)
                self.state = ConnectionState.PROXY_REQUEST_ACCEPTED
            elif request.cmd == conversion.REQ_CMD_CONNECT:
                self._logger.warning(
                    "TCP req to %s:%d support it. Returning HOST UNREACHABLE",
                    *request.destination)
                response = conversion.encode_reply(
                    0x05, conversion.REP_HOST_UNREACHABLE, 0x00,
                    conversion.ADDRESS_TYPE_IPV4, "0.0.0.0", 0)
                self.write(response)
                accept = False
            else:
                self.deny_request(request, False)
                accept = False
        except:
            response = conversion.encode_reply(
                    0x05, conversion.REP_COMMAND_NOT_SUPPORTED, 0x00,
                    conversion.ADDRESS_TYPE_IPV4, "0.0.0.0", 0)
            self.write(response)
            self._logger.exception("Exception thrown. Returning unsupported "
                                   "command response")
            accept = False

        if accept:
            self.state = ConnectionState.PROXY_REQUEST_ACCEPTED

        return accept

    def _process_buffer(self):
        """
        Processes the buffer by attempting to messages which are to be expected
        in the current state
        """
        while len(self.buffer) > 0:
            self.state = self._guess_state()

            # We are at the initial state, so we expect a handshake request.
            if self.state == ConnectionState.BEFORE_METHOD_REQUEST:
                if not self._try_handshake():
                    break  # Not enough bytes so wait till we got more

            # We are connected so the
            elif self.state == ConnectionState.CONNECTED:
                if not self._try_request():
                    break  # Not enough bytes so wait till we got more
            else:
                self.buffer = ''

    def _guess_state(self):
        if len(self.buffer) < 3:
            return self.state

        data = self.buffer
        is_version = ord(data[0]) == 0x05
        if is_version and data[1] == chr(0x01) and chr(0x00) == data[2]:
            guessed_state = ConnectionState.BEFORE_METHOD_REQUEST

            if self.state != guessed_state:
                self._logger.error("GUESSING SOCKS5 state %s should be %s!", guessed_state, self.state)
                
            return guessed_state

        has_valid_command = ord(data[1]) in [0x01, 0x02, 0x03]
        has_valid_address = ord(data[2]) in [0x01, 0x03, 0x04]

        if is_version and has_valid_command and has_valid_address:
            return ConnectionState.CONNECTED

        return self.state

    def write(self, data):
        if self.single_socket is not None:
            self.single_socket.write(data)

    def close(self):
        if self.single_socket is not None:
            self._logger.error(
                "On close() of %s:%d", self.single_socket.get_ip(),
                self.single_socket.get_port())

            self.single_socket.close()
            self.single_socket = None
            ''' :type : SingleSocket '''

            if self.tcp_relay:
                self.tcp_relay.close()

########NEW FILE########
__FILENAME__ = conversion
import struct
import socket

# Some constants used in the RFC 1928 specification
SOCKS_VERSION = 0x05

ADDRESS_TYPE_IPV4 = 0x01
ADDRESS_TYPE_DOMAIN_NAME = 0x03
ADDRESS_TYP_IPV6 = 0x04

REQ_CMD_CONNECT = 0x01
REQ_CMD_BIND = 0x02
REQ_CMD_UDP_ASSOCIATE = 0x03

REP_SUCCEEDED = 0x00
REP_GENERAL_SOCKS_SERVER_FAIL = 0x01
REP_CONNECTION_NOT_ALLOWED_BY_RULE_SET = 0x02
REP_NETWORK_UNREACHABLE = 0x03
REP_HOST_UNREACHABLE = 0x04
REP_CONNECTION_REFUSED = 0x05
REP_TTL_EXPIRED = 0x06
REP_COMMAND_NOT_SUPPORTED = 0x07
REP_ADDRESS_TYPE_NOT_SUPPORTED = 0x08


class MethodRequest(object):
    def __init__(self, version, methods):
        self.version = version
        self.methods = methods


class Request(object):
    def __init__(self, version, cmd, rsv, address_type, destination_address,
                 destination_port):
        self.version = version
        self.cmd = cmd
        self.rsv = rsv
        self.address_type = address_type
        self.destination_host = destination_address
        self.destination_port = destination_port

    @property
    def destination(self):
        """
        The destination address as a tuple
        @rtype: (str, int)
        """
        return self.destination_host, self.destination_port


class UdpRequest(object):
    """

    @param rsv: the reserved bits in the SOCKS protocol
    @param frag:
    @param address_type: whether we deal with an IPv4 or IPv6 address
    @param str destination_address: the destination host
    @param int destination_port: the destination port
    @param str payload: the payload
    """

    def __init__(self, rsv, frag, address_type, destination_address,
                 destination_port, payload):
        self.rsv = rsv
        self.frag = frag
        self.address_type = address_type
        self.destination_host = destination_address
        self.destination_port = destination_port
        self.payload = payload

    @property
    def destination(self):
        """
        The destination address as a tuple
        @rtype: (str, int)
        """
        return self.destination_host, self.destination_port


def decode_methods_request(offset, data):
    """
    Try to decodes a METHOD request
    @param int offset: the offset to start in the data
    @param str data: the serialised data to decode from
    @return: Tuple (offset, None) on failure, else (new_offset, MethodRequest)
    @rtype: (int, None|MethodRequest)
    """
    # Check if we have enough bytes
    if len(data) - offset < 2:
        return offset, None

    (version, number_of_methods) = struct.unpack_from("BB", data, offset)

    # We only know how to handle Socks5 protocol
    if not version == SOCKS_VERSION:
        return offset, None

    offset += 2

    methods = set([])
    for i in range(number_of_methods):
        method, = struct.unpack_from("B", data, offset)
        methods.add(method)
        offset += 1

    return offset, MethodRequest(version, methods)


def encode_method_selection_message(version, method):
    """
    Serialise a Method Selection message
    @param version: the SOCKS5 version
    @param method: the authentication method to select
    @return: the serialised format
    @rtype: str
    """
    return struct.pack("BB", version, method)


def __encode_address(address_type, address):
    if address_type == ADDRESS_TYPE_IPV4:
        data = socket.inet_aton(address)
    elif address_type == ADDRESS_TYP_IPV6:
        raise ValueError("IPv6 not implemented")
    elif address_type == ADDRESS_TYPE_DOMAIN_NAME:
        data = struct.pack("B", len(address)) + address
    else:
        raise ValueError(
            "address_type must be either IPv4, IPv6 or a domain name")

    return data


def __decode_address(address_type, offset, data):
    if address_type == ADDRESS_TYPE_IPV4:
        destination_address = socket.inet_ntoa(data[offset:offset + 4])
        offset += 4
    elif address_type == ADDRESS_TYPE_DOMAIN_NAME:
        domain_length, = struct.unpack_from("B", data, offset)
        offset += 1
        destination_address = data[offset:offset + domain_length]
        offset += domain_length
    elif address_type == ADDRESS_TYP_IPV6:
        return offset, None
    else:
        raise ValueError("Unsupported address type")

    return offset, destination_address


def decode_request(orig_offset, data):
    """
    Try to decode a SOCKS5 request
    @param int orig_offset: the offset to start decoding in the data
    @param str data: the raw data
    @return: tuple (new_offset, Request) or (original_offset, None) on failure
    @rtype: (int, Request|None)
    """
    offset = orig_offset

    # Check if we have enough bytes
    if len(data) - offset < 4:
        return orig_offset, None

    version, cmd, rsv, address_type = struct.unpack_from("BBBB", data, offset)
    offset += 4

    assert version == SOCKS_VERSION
    assert rsv == 0

    offset, destination_address = __decode_address(address_type, offset, data)

    # Check if we could decode address, if not bail out
    if not destination_address:
        return orig_offset, None

        # Check if we have enough bytes
    if len(data) - offset < 2:
        return orig_offset, None

    destination_port, = struct.unpack_from("!H", data, offset)
    offset += 2

    return offset, Request(version, cmd, rsv, address_type,
                           destination_address, destination_port)


def encode_reply(version, rep, rsv, address_type, bind_address, bind_port):
    """
    Encode a REPLY
    @param int version: SOCKS5 version
    @param int rep: the response
    @param int rsv: reserved bytes
    @param address_type: the address type of the bind address
    @param bind_address: the bind address host
    @param bind_port: the bind address port
    @return:
    """
    data = struct.pack("BBBB", version, rep, rsv, address_type)

    data += __encode_address(address_type, bind_address)

    data += struct.pack("!H", bind_port)
    return data


def decode_udp_packet(data):
    """
    Decodes a SOCKS5 UDP packet
    @param str data: the raw packet data
    @return: An UdpRequest object containing the parsed data
    @rtype: UdpRequest
    """
    offset = 0
    (rsv, frag, address_type) = struct.unpack_from("!HBB", data, offset)
    offset += 4

    offset, destination_address = __decode_address(address_type, offset, data)

    destination_port, = struct.unpack_from("!H", data, offset)
    offset += 2

    payload = data[offset:]

    return UdpRequest(rsv, frag, address_type, destination_address,
                      destination_port, payload)


def encode_udp_packet(rsv, frag, address_type, address, port, payload):
    """
    Encodes a SOCKS5 UDP packet
    @param rsv: reserved bytes
    @param frag: fragment
    @param address_type: the address's type
    @param address: address host
    @param port: address port
    @param payload: the original UDP payload
    @return: serialised byte string
    @rtype: str
    """
    strings = [
        struct.pack("!HBB", rsv, frag, address_type),
        __encode_address(address_type, address),
        struct.pack("!H", port),
        payload
    ]

    return ''.join(strings)
########NEW FILE########
__FILENAME__ = server
from Tribler.community.anontunnel.events import TunnelObserver

import logging
import socket
from Tribler.Core.RawServer.SocketHandler import SingleSocket
from Tribler.community.anontunnel.globals import CIRCUIT_STATE_READY
from Tribler.community.anontunnel.routing import CircuitPool
from .session import Socks5Session
from .connection import Socks5Connection

__author__ = 'chris'


class Socks5Server(TunnelObserver):
    """
    The SOCKS5 server which allows clients to proxy UDP over Circuits in the
    ProxyCommunity

    @param ProxyCommunity tunnel: the ProxyCommunity to request circuits from
    @param RawServer raw_server: the RawServer instance to bind on
    @param int socks5_port: the port to listen on
    """
    def __init__(self, tunnel, raw_server, socks5_port=1080, num_circuits=4, min_circuits=4, min_session_circuits=4):
        super(Socks5Server, self).__init__()
        self._logger = logging.getLogger(__name__)

        self.tunnel = tunnel
        self.socks5_port = socks5_port
        self.raw_server = raw_server
        ''' @type : RawServer '''
        self.reserved_circuits = []
        ''' @type : list[Circuit] '''
        self.awaiting_circuits = 0
        ''' @type : int '''
        self.tcp2session = {}
        ''' @type : dict[Socks5Connection, Socks5Session] '''

        self.circuit_pool = CircuitPool(num_circuits, "SOCKS5(master)")
        self.tunnel.observers.append(self.circuit_pool)
        self.tunnel.circuit_pools.append(self.circuit_pool)

        self.min_circuits = min_circuits
        self.min_session_circuits = min_session_circuits

        raw_server.add_task(self.__start_anon_session, 5.0)

    def __start_anon_session(self):
        made_session = False

        if len(self.circuit_pool.available_circuits) >= self.min_circuits:
            try:
                from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr
                if LibtorrentMgr.hasInstance():
                    self._logger.info("Creating ANON session")
                    LibtorrentMgr.getInstance().create_anonymous_session()
                    made_session = True

            except ImportError:
                self._logger.exception("Cannot create anonymous session!")

        if not made_session:
            self.raw_server.add_task(self.__start_anon_session, delay=1.0)

        return made_session

    def start(self):
        try:
            self.raw_server.bind(self.socks5_port, reuse=True, handler=self)
            self._logger.info("SOCKS5 listening on port %d", self.socks5_port)
            self.tunnel.observers.append(self)
        except socket.error:
            self._logger.error(
                "Cannot listen on SOCK5 port %s:%d, perhaps another "
                "instance is running?",
                "0.0.0.0", self.socks5_port)
        except:
            self._logger.exception("Exception trying to reserve circuits")

    def external_connection_made(self, single_socket):
        """
        Called by the RawServer when a new connection has been made

        @param SingleSocket single_socket: the new connection
        """
        self._logger.info("accepted SOCKS5 new connection")
        s5con = Socks5Connection(single_socket, self)

        try:
            session_pool = CircuitPool(4, "SOCKS5(%s:%d)" % (single_socket.get_ip(), single_socket.get_port()))
            session = Socks5Session(self.raw_server, s5con, self, session_pool, min_circuits=self.min_session_circuits)
            self.tunnel.observers.append(session)
            self.tunnel.observers.append(session_pool)
            self.tunnel.circuit_pools.insert(0, session_pool)

            self.tcp2session[single_socket] = session
        except:
            self._logger.exception("Error while accepting SOCKS5 connection")
            s5con.close()

    def connection_flushed(self, single_socket):
        pass

    def connection_lost(self, single_socket):
        self._logger.info("SOCKS5 TCP connection lost")

        if single_socket not in self.tcp2session:
            return

        session = self.tcp2session[single_socket]
        self.tunnel.observers.remove(session)
        self.tunnel.circuit_pools.remove(session.circuit_pool)

        # Reclaim good circuits
        good_circuits = [circuit for circuit in session.circuit_pool.available_circuits if circuit.state == CIRCUIT_STATE_READY]

        self._logger.warning(
            "Reclaiming %d good circuits due to %s:%d",
            len(good_circuits),
            single_socket.get_ip(), single_socket.get_port())

        for circuit in good_circuits:
            self.circuit_pool.fill(circuit)

        s5con = session.connection
        del self.tcp2session[single_socket]

        try:
            s5con.close()
        except:
            pass

    def data_came_in(self, single_socket, data):
        """
        Data is in the READ buffer, depending on MODE the Socks5 or
        Relay mechanism will be used

        :param single_socket:
        :param data:
        :return:
        """
        tcp_connection = self.tcp2session[single_socket].connection
        try:
            tcp_connection.data_came_in(data)
        except:
            self._logger.exception("Error while handling incoming TCP data")

    def on_break_circuit(self, circuit):
        if circuit in self.reserved_circuits:
            self.reserved_circuits.remove(circuit)

########NEW FILE########
__FILENAME__ = session
import logging
from Tribler.community.anontunnel.Socks5 import conversion
from Tribler.community.anontunnel.Socks5.connection import \
    Socks5ConnectionObserver
from Tribler.community.anontunnel.events import TunnelObserver, \
    CircuitPoolObserver
from Tribler.community.anontunnel.globals import CIRCUIT_STATE_READY
from Tribler.community.anontunnel.routing import NotEnoughCircuitsException
from Tribler.community.anontunnel.selectionstrategies import RoundRobin


class Socks5Session(TunnelObserver, Socks5ConnectionObserver):
    """
    A SOCKS5 session, composed by a TCP connection, an UDP proxy port and a
    list of circuits where data can be tunneled over

    @param Socks5Connection connection: the Socks5Connection
    @param RawServer raw_server: The raw server, used to create and listen on
    UDP-sockets
    @param CircuitPool circuit_pool:  the circuit pool
    """
    def __init__(self, raw_server, connection, server, circuit_pool, min_circuits=4):
        TunnelObserver.__init__(self)
        self.raw_server = raw_server
        self._logger = logging.getLogger(__name__)
        self.connection = connection
        self.connection.observers.append(self)
        self.circuit_pool = circuit_pool

        self.min_circuits = min_circuits

        self.server = server

        self.destinations = {}
        ''' :type: dict[(str, int), Circuit] '''

        self.selection_strategy = RoundRobin()

        self.remote_udp_address = None
        self._udp_socket = None

    def on_udp_associate_request(self, connection, request):
        """
        @param Socks5Connection connection: the connection
        @param request:
        @return:
        """
        if not self.circuit_pool.available_circuits:
            try:
                for _ in range(self.min_circuits):
                    circuit = self.server.circuit_pool.allocate()
                    # Move from main pool to session pool
                    self.server.circuit_pool.remove_circuit(circuit)
                    self.circuit_pool.fill(circuit)
            except NotEnoughCircuitsException:
                self.close_session("not enough circuits")
                connection.deny_request(request)
                return

        self._udp_socket = self.raw_server.create_udpsocket(0, "0.0.0.0")
        self.raw_server.start_listening_udp(self._udp_socket, self)
        connection.accept_udp_associate(request, self._udp_socket)

    def close_session(self, reason='unspecified'):
        """
        Closes the session and the linked TCP connection
        @param str reason: the reason why the session should be closed
        """
        self._logger.error("Closing session, reason = {0}".format(reason))
        self.connection.close()

    def on_break_circuit(self, broken_circuit):
        """
        When a circuit breaks and it affects our operation we should re-add the
        peers when a new circuit is available to reinitiate the 3-way handshake

        @param Circuit broken_circuit: the circuit that has been broken
        @return:
        """
        from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr

        if not LibtorrentMgr.hasInstance():
            return

        affected_destinations = set(destination
                                    for destination, tunnel_circuit
                                    in self.destinations.iteritems()
                                    if tunnel_circuit == broken_circuit)

        # We are not affected by the circuit that has been broken, continue
        # without any changes
        if not affected_destinations:
            return

        mgr = LibtorrentMgr.getInstance()
        anon_session = mgr.ltsession_anon
        ''' :type : libtorrent.session '''

        affected_torrents = dict((download, affected_destinations.intersection(peer.ip for peer in download.handle.get_peer_info()))
                             for infohash, (download, session)
                             in mgr.torrents.items()
                             if session == anon_session
                             )
        ''' :type : dict[LibtorrentDownloadImpl, set[(str, int)] '''

        def _peer_add():
            for destination in affected_destinations:
                if destination in self.destinations:
                    del self.destinations[destination]
                    self._logger.error("Deleting peer %s from destination list", destination)

            for torrent, peers in affected_torrents.items():
                for peer in peers:
                    self._logger.error("Readding peer %s to torrent %s", peer, torrent.tdef.get_infohash().encode("HEX"))
                    torrent.add_peer(peer)

        # Observer that waits for a new circuit before re-adding the peers
        # is used only when there are no other circuits left
        class _peer_adder(CircuitPoolObserver):
            def on_circuit_added(self, pool, circuit):
                _peer_add()
                pool.observers.remove(self)

        # If there are any other circuits we will just map them to any
        # new circuit
        if [circuit for circuit in self.circuit_pool.available_circuits if circuit != broken_circuit]:
            _peer_add()
        else:
            self._logger.warning("Waiting for new circuits before re-adding peers")
            self.circuit_pool.observers.append(_peer_adder())

    def _select(self, destination):
        if not destination in self.destinations:
            selected_circuit = self.selection_strategy.select(self.circuit_pool.available_circuits)
            self.destinations[destination] = selected_circuit

            self._logger.warning("SELECT circuit {0} for {1}".format(
                self.destinations[destination].circuit_id,
                destination
            ))

        return self.destinations[destination]

    def data_came_in(self, packets):
        for source_address, packet in packets:
            if self.remote_udp_address and \
                    self.remote_udp_address != source_address:
                self.close_session('invalid source_address!')
                return

            self.remote_udp_address = source_address

            request = conversion.decode_udp_packet(packet)

            circuit = self._select(request.destination)

            if circuit.state != CIRCUIT_STATE_READY:
                self._logger.error("Circuit is not ready, dropping %d bytes to %s", len(request.payload), request.destination)
            else:
                circuit.tunnel_data(request.destination, request.payload)

    def on_incoming_from_tunnel(self, community, circuit, origin, data):
        if circuit not in self.circuit_pool.circuits:
            return

        if not self.remote_udp_address:
            self._logger.warning("No return address yet, dropping packet!")
            return

        self.destinations[origin] = circuit

        socks5_udp = conversion.encode_udp_packet(
            0, 0, conversion.ADDRESS_TYPE_IPV4, origin[0], origin[1], data)

        bytes_written = self._udp_socket.sendto(socks5_udp,
                                                self.remote_udp_address)
        if bytes_written < len(socks5_udp):
            self._logger.error("Packet drop on return!")

########NEW FILE########
__FILENAME__ = stats
import logging
import os
import sqlite3
import time
import uuid
from collections import defaultdict

from twisted.internet.base import DelayedCall
from twisted.internet.defer import Deferred
from twisted.internet.task import LoopingCall

from Tribler.community.anontunnel.crypto import NoCrypto
from Tribler.community.anontunnel.events import TunnelObserver
from Tribler.dispersy.database import Database


__author__ = 'chris'

sqlite3.register_converter('GUID', lambda b: uuid.UUID(bytes_le=b))
sqlite3.register_adapter(uuid.UUID, lambda u: buffer(u.bytes_le))

class CircuitStats:
    def __init__(self):
        self.timestamp = None
        self.times = []
        self.bytes_up_list = []
        self.bytes_down_list = []

        self.bytes_down = [0, 0]
        self.bytes_up = [0, 0]

        self.speed_up = 0.0
        self.speed_down = 0.0

    @property
    def bytes_downloaded(self):
        return self.bytes_down[1]

    @property
    def bytes_uploaded(self):
        return self.bytes_up[1]


class RelayStats:
    def __init__(self):
        self.timestamp = None

        self.times = []
        self.bytes_list = []
        self.bytes = [0, 0]
        self.speed = 0


class StatsCollector(TunnelObserver):
    def __init__(self, proxy, name):
        """
        @type proxy: Tribler.community.anontunnel.community.ProxyCommunity
        """

        TunnelObserver.__init__(self)

        self._logger = logging.getLogger(__name__)
        self.name = name

        self._pending_tasks = {}

        self.stats = {
            'bytes_returned': 0,
            'bytes_exit': 0,
            'bytes_enter': 0,
            'broken_circuits': 0
        }
        self.download_stats = {}
        self.session_id = uuid.uuid4()
        self.proxy = proxy
        self.running = False
        self.circuit_stats = defaultdict(lambda: CircuitStats())
        ''':type : dict[int, CircuitStats] '''
        self.relay_stats = defaultdict(lambda: RelayStats())
        ''':type : dict[((str,int),int), RelayStats] '''
        self._circuit_cache = {}
        ''':type : dict[int, Circuit] '''

    def cancel_pending_task(self, key):
        task = self._pending_tasks.pop(key)
        if isinstance(task, Deferred) and not task.called:
            # Have in mind that any deferred in the pending tasks list should have been constructed with a
            # canceller function.
            task.cancel()
        elif isinstance(task, DelayedCall) and task.active():
            task.cancel()
        elif isinstance(task, LoopingCall) and task.running:
            task.stop()

    def pause(self):
        """
        Pause stats collecting
        """
        self._logger.info("Removed StatsCollector %s as observer", self.name)
        self.running = False
        self.proxy.observers.remove(self)

        # cancel all pending tasks
        for key in self._pending_tasks.keys():
            self.cancel_pending_task(key)

    def clear(self):
        """
        Clear collected stats
        """

        self.circuit_stats.clear()
        self.relay_stats.clear()

    def stop(self):
        self.pause()
        self.clear()

    def start(self):
        if self.running:
            raise ValueError("Cannot start collector {0} since it is already running".format(self.name))

        self._logger.info("Resuming stats collector {0}!".format(self.name))
        self.running = True
        self.proxy.observers.append(self)
        self._pending_tasks["calc speeds"] = lc = LoopingCall(self.__calc_speeds)
        lc.start(1, now=True)

    def on_break_circuit(self, circuit):
        if len(circuit.hops) == circuit.goal_hops:
            self.stats['broken_circuits'] += 1

    def __calc_speeds(self):
        if self.running:
            t2 = time.time()
            self._circuit_cache.update(self.proxy.circuits)

            for circuit_id in self.proxy.circuits.keys():
                c = self.circuit_stats[circuit_id]

                if c.timestamp is None:
                    c.timestamp = time.time()
                elif c.timestamp < t2:

                    if len(c.bytes_up_list) == 0 or c.bytes_up[-1] != \
                            c.bytes_up_list[-1] and c.bytes_down[-1] != \
                            c.bytes_down_list[-1]:
                        c.bytes_up_list.append(c.bytes_up[-1])
                        c.bytes_down_list.append(c.bytes_down[-1])
                        c.times.append(t2)

                    c.speed_up = 1.0 * (c.bytes_up[1] - c.bytes_up[0]) / (
                        t2 - c.timestamp)
                    c.speed_down = 1.0 * (
                        c.bytes_down[1] - c.bytes_down[0]) / (t2 - c.timestamp)

                    c.timestamp = t2
                    c.bytes_up = [c.bytes_up[1], c.bytes_up[1]]
                    c.bytes_down = [c.bytes_down[1], c.bytes_down[1]]

            for relay_key in self.proxy.relay_from_to.keys():
                r = self.relay_stats[relay_key]

                if r.timestamp is None:
                    r.timestamp = time.time()
                elif r.timestamp < t2:
                    changed = len(r.bytes_list) == 0 \
                        or r.bytes[-1] != r.bytes_list[-1]

                    if changed:
                        r.bytes_list.append(r.bytes[-1])
                        r.times.append(t2)

                    r.speed = 1.0 * (r.bytes[1] - r.bytes[0]) / (
                        t2 - r.timestamp)
                    r.timestamp = t2
                    r.bytes = [r.bytes[1], r.bytes[1]]

    def on_enter_tunnel(self, circuit_id, candidate, origin, payload):
        self.stats['bytes_enter'] += len(payload)

    def on_incoming_from_tunnel(self, community, circuit, origin, data):
        self.stats['bytes_returned'] += len(data)
        self.circuit_stats[circuit.circuit_id].bytes_down[1] += len(data)

    def on_exiting_from_tunnel(self, circuit_id, candidate, destination, data):
        self.stats['bytes_exit'] += len(data)

        valid = False if circuit_id not in self.proxy.circuits \
            else self.proxy.circuits[circuit_id].goal_hops == 0

        if valid:
            self.circuit_stats[circuit_id].bytes_up[-1] += len(data)

    def on_send_data(self, circuit_id, candidate, destination,
                     payload):
        self.circuit_stats[circuit_id].bytes_up[-1] += len(payload)

    def on_relay(self, from_key, to_key, direction, data):
        self.relay_stats[from_key].bytes[-1] += len(data)
        self.relay_stats[to_key].bytes[-1] += len(data)

    def _create_stats(self):
        stats = {
            'uuid': self.session_id.get_bytes_le(),
            'encryption': 0 if isinstance(self.proxy.settings.crypto, NoCrypto) else 1,
            'swift': self.download_stats,
            'bytes_enter': self.stats['bytes_enter'],
            'bytes_exit': self.stats['bytes_exit'],
            'bytes_return': self.stats['bytes_returned'],
            'broken_circuits': self.stats['broken_circuits'],
            'circuits': [
                {
                    'hops': self._circuit_cache[circuit_id].goal_hops,
                    'bytes_down': c.bytes_down_list[-1] - c.bytes_down_list[0],
                    'bytes_up': c.bytes_up_list[-1] - c.bytes_up_list[0],
                    'time': c.times[-1] - c.times[0]
                }
                for circuit_id, c in self.circuit_stats.items()
                if len(c.times) >= 2
            ],
            'relays': [
                {
                    'bytes': r.bytes_list[-1],
                    'time': r.times[-1] - r.times[0]
                }
                for r in self.relay_stats.values()
                if r.times and len(r.times) >= 2
            ]
        }

        return stats

    def on_unload(self):
        if self.download_stats:
            self._logger.error("Sharing statistics now!")
            self.share_stats()

    def share_stats(self):
        self.proxy.send_stats(self._create_stats())


class StatsDatabase(Database):
    LATEST_VERSION = 1
    schema = u"""
        CREATE TABLE result (
            "result_id" INTEGER PRIMARY KEY AUTOINCREMENT,
            "mid" BLOB,
            "session_id" GUID,
            "time" DATETIME,
            "host" NULL,
            "port" NULL,
            "swift_size" NULL,
            "swift_time" NULL,
            "bytes_enter" NULL,
            "bytes_exit" NULL,
            "bytes_returned" NULL,
            "encryption" INTEGER NOT NULL DEFAULT ('0')
        , "broken_circuits" INTEGER);

        CREATE TABLE IF NOT EXISTS result_circuit (
            result_circuit_id INTEGER PRIMARY KEY AUTOINCREMENT,
            result_id,
            hops,
            bytes_up,
            bytes_down,
            time
        );

        CREATE TABLE IF NOT EXISTS result_relay(
            result_relay_id INTEGER PRIMARY KEY AUTOINCREMENT,
            result_id,
            bytes,
            time
        );

        CREATE TABLE option(key TEXT PRIMARY KEY, value BLOB);
        INSERT INTO option(key, value) VALUES('database_version', '""" + str(LATEST_VERSION) + """');
    """

    if __debug__:
        __doc__ = schema

    def __init__(self, dispersy):
        self._dispersy = dispersy

        super(StatsDatabase, self).__init__(os.path.join(dispersy.working_directory, u"anontunnel.db"))

    def open(self, initial_statements=True, prepare_visioning=True):
        self._dispersy.database.attach_commit_callback(self.commit)
        return super(StatsDatabase, self).open(initial_statements, prepare_visioning)

    def close(self, commit=True):
        self._dispersy.database.detach_commit_callback(self.commit)
        return super(StatsDatabase, self).close(commit)

    def check_database(self, database_version):
        assert isinstance(database_version, unicode)
        assert database_version.isdigit()
        assert int(database_version) >= 0
        database_version = int(database_version)

        # setup new database with current database_version
        if database_version < 1:
            self.executescript(self.schema)
            self.commit()

        else:
            # upgrade to version 2
            if database_version < 2:
                # there is no version 2 yet...
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2)
                # self.executescript(u"""UPDATE option SET value = '2' WHERE key = 'database_version';""")
                # self.commit()
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2, " (done)")
                pass

        return self.LATEST_VERSION

    def add_stat(self, member, candidate, stats):
        """
        @param Member member:
        @param Candidate candidate:
        @param stats:
        """

        sock_addr = candidate.sock_addr

        self.execute(
            u'''INSERT OR FAIL INTO result
                (
                    mid, encryption, session_id, time,
                    host, port, swift_size, swift_time,
                    bytes_enter, bytes_exit, bytes_returned, broken_circuits
                )
                VALUES (?, ?, ?,DATETIME('now'),?,?,?,?,?,?,?,?)''',
            (
                buffer(member.mid),
                stats['encryption'] or 0,
                uuid.UUID(bytes_le=stats['uuid']),
                unicode(sock_addr[0]), sock_addr[1],
                stats['swift']['size'], stats['swift']['download_time'],
                stats['bytes_enter'], stats['bytes_exit'],
                (stats['bytes_return'] or 0),
                (stats['broken_circuits'] or 0)
            )
        )

        result_id = self.last_insert_rowid

        for circuit in stats['circuits']:
            self.execute(u'''
                INSERT INTO result_circuit (
                    result_id, hops, bytes_up, bytes_down, time
                ) VALUES (?, ?, ?, ?, ?)''',
                (
                   result_id, circuit['hops'],
                   circuit['bytes_up'],
                   circuit['bytes_down'],
                   circuit['time']
                ))

        for relay in stats['relays']:
            self.execute(u'''
                INSERT INTO result_relay (result_id, bytes, time)
                    VALUES (?, ?, ?)
            ''', (result_id, relay['bytes'], relay['time']))

        self.commit()

    def get_num_stats(self):
        '''
        @rtype: int
        @return: number of stats
        '''

        return self.execute(u'''
            SELECT COUNT(*)
            FROM result
        ''').fetchone()[0]


class StatsCrawler(TunnelObserver):
    """
    Stores incoming stats in a SQLite database
    @param RawServer raw_server: the RawServer instance to queue database tasks
    on
    """

    def __init__(self, dispersy, raw_server):
        TunnelObserver.__init__(self)
        self._logger = logging.getLogger(__name__)
        self._logger.warning("Running StatsCrawler")
        self.raw_server = raw_server
        self.database = StatsDatabase(dispersy)
        self.raw_server.add_task(lambda: self.database.open())

    def on_tunnel_stats(self, community, member, candidate, stats):
        self.raw_server.add_task(lambda: self.database.add_stat(member, candidate, stats))

    def get_num_stats(self):
        return self.database.get_num_stats()

    def stop(self):
        self._logger.error("Stopping crawler")
        self.raw_server.add_task(lambda: self.database.close())

########NEW FILE########
__FILENAME__ = test_circuit
from unittest import TestCase
import time
from Tribler.community.anontunnel.globals import CIRCUIT_STATE_EXTENDING, \
    CIRCUIT_STATE_READY, CIRCUIT_STATE_BROKEN
from Tribler.community.anontunnel.routing import Circuit, Hop
from Tribler.dispersy.candidate import Candidate

__author__ = 'chris'


class TestCircuit(TestCase):
    def test_destroy(self):
        candidate = Candidate(("127.0.0.1", 1000), False)
        circuit = Circuit(1, 1, candidate)

        self.assertNotEqual(CIRCUIT_STATE_BROKEN, circuit.state, "Newly created circuit should not be considered broken")
        circuit.destroy("Because we want to")
        self.assertEqual(CIRCUIT_STATE_BROKEN, circuit.state, "Destroyed circuit should be considered broken")

    def test_beat_heart(self):
        candidate = Candidate(("127.0.0.1", 1000), False)
        circuit = Circuit(1, 1, candidate)
        circuit.add_hop(Hop(None))

        circuit.beat_heart()
        self.assertAlmostEqual(time.time(), circuit.last_incoming, delta=0.1, msg="Beat heart should update the last_incoming time")

    def test_state(self):
        candidate = Candidate(("127.0.0.1", 1000), False)

        circuit = Circuit(1, 2, candidate)
        self.assertNotEqual(
            CIRCUIT_STATE_READY, circuit.state,
            "Circuit should not be online when goal hops not reached")

        circuit = Circuit(1, 1, candidate)
        self.assertNotEqual(
            CIRCUIT_STATE_READY, circuit.state,
            "Single hop circuit without confirmed first hop should always be offline")

        circuit.add_hop(Hop(None))
        self.assertEqual(
            CIRCUIT_STATE_READY, circuit.state,
            "Single hop circuit with candidate should always be online")

        circuit = Circuit(0)
        self.assertEqual(CIRCUIT_STATE_READY, circuit.state,
                        "Zero hop circuit should always be online")

########NEW FILE########
__FILENAME__ = test_circuitPool
from unittest import TestCase
from Tribler.community.anontunnel.routing import CircuitPool, Circuit

__author__ = 'Chris'


class TestCircuitPool(TestCase):
    def setUp(self):
        self.pool = CircuitPool(5, 'test pool')

    def test_on_break_circuit(self):
        for i in range(1, 5):
            circuit = Circuit(0, 0)
            self.pool.fill(circuit)
            self.pool.on_break_circuit(circuit)
            self.assertNotIn(circuit, self.pool.circuits)
            self.assertNotIn(circuit, self.pool.available_circuits)

    def test_lacking(self):
        for i in range(1, 5):
            circuit = Circuit(0, 0)
            self.pool.fill(circuit)

            self.assertEqual(self.pool.lacking, 5-i)

    def test_available_circuits(self):
        circuits = [Circuit(0, 0) for _ in range(5)]

        for circuit in circuits:
            self.pool.fill(circuit)
            self.assertIn(circuit, self.pool.available_circuits)
            self.pool.remove_circuit(circuit)
            self.assertNotIn(circuit, self.pool.available_circuits)

    def test_remove_circuit(self):
        circuits = [Circuit(0, 0) for _ in range(5)]

        for circuit in circuits:
            self.pool.fill(circuit)
            self.assertIn(circuit, self.pool.circuits)
            self.pool.remove_circuit(circuit)
            self.assertNotIn(circuit, self.pool.circuits)

    def test_fill(self):
        for i in range(1, 5):
            circuit = Circuit(0, 0)
            self.pool.fill(circuit)

            self.assertIn(circuit, self.pool.circuits)
            self.assertIn(circuit, self.pool.available_circuits)

    def test_deallocate(self):
        circuits = [Circuit(0, 0) for _ in range(5)]

        for circuit in circuits:
            self.pool.fill(circuit)

        for i in range(1, 5):
            circuit = self.pool.allocate()
            self.assertIn(circuit, self.pool.circuits)
            self.assertNotIn(circuit, self.pool.available_circuits)
            self.pool.deallocate(circuit)
            self.assertIn(circuit, self.pool.available_circuits)

    def test_allocate(self):
        circuits = [Circuit(0, 0) for _ in range(5)]

        for circuit in circuits:
            self.pool.fill(circuit)

        for i in range(1, 5):
            circuit = self.pool.allocate()
            self.assertIn(circuit, self.pool.circuits)
            self.assertNotIn(circuit, self.pool.available_circuits)
########NEW FILE########
__FILENAME__ = test_defaultCrypto
import logging.config
import os
import random
from mock import Mock
import time
from Tribler.Test.test_as_server import TestAsServer
from Tribler.community.anontunnel import exitstrategies
from Tribler.community.anontunnel.community import ProxyCommunity, ProxySettings
from Tribler.community.anontunnel.crypto import NoCrypto, DefaultCrypto
from Tribler.community.anontunnel.payload import CreateMessage, ExtendMessage, CreatedMessage
from Tribler.community.anontunnel.routing import Circuit, Hop
from Tribler.community.privatesemantic.conversion import long_to_bytes
from Tribler.dispersy.candidate import WalkCandidate, CANDIDATE_ELIGIBLE_DELAY
from Tribler.dispersy.endpoint import NullEndpoint

from twisted.internet.threads import blockingCallFromThread

logging.config.fileConfig(
    os.path.dirname(os.path.realpath(__file__)) + "/../logger.conf")

__author__ = 'rutger'

class DummyEndpoint(NullEndpoint):
    def send_simple(self, *args):
        pass

class DummyCandidate():
    def __init__(self, key=None):
        # super(DummyCandidate, self).__init__(self)
        self.sock_addr = Mock()
        self.member = Mock()
        if not key:
            key = self.dispersy.crypto.generate_key(u"NID_secp160k1")
        self.member._ec = key

    def get_member(self):
        return self.member

class TestDefaultCrypto(TestAsServer):
    @property
    def crypto(self):
        return self.community.settings.crypto

    @call_on_reactor_thread
    def setUp(self):
        super(TestDefaultCrypto, self).setUp()
        self.__candidate_counter = 0
        self.dispersy = self.session.lm.dispersy

        dispersy = self.dispersy

        keypair = dispersy.crypto.generate_key(u"NID_secp160k1")
        dispersy_member = dispersy.get_member(private_key=dispersy.crypto.key_to_bin(keypair))

        settings = ProxySettings()
        settings.crypto = DefaultCrypto()

        self.community = dispersy.define_auto_load(ProxyCommunity, dispersy_member, (settings, None), load=True)[0]
        exitstrategies.DefaultExitStrategy(self.session.lm.rawserver, self.community)

        ''' :type : ProxyCommunity '''

    def setUpPreSession(self):
        super(TestDefaultCrypto, self).setUpPreSession()
        self.config.set_dispersy(True)

    @call_on_reactor_thread
    def __create_walk_candidate(self):
        self.__candidate_counter += 1
        wan_address = ("8.8.8.{0}".format(self.__candidate_counter), self.__candidate_counter)
        lan_address = ("0.0.0.0", 0)
        candidate = WalkCandidate(wan_address, False, lan_address, wan_address, u'unknown')


        key = self.dispersy.crypto.generate_key(u"NID_secp160k1")
        member = self.dispersy.get_member(public_key=self.dispersy.crypto.key_to_bin(key.pub()))
        candidate.associate(member)

        now = time.time()
        candidate.walk(now - CANDIDATE_ELIGIBLE_DELAY)
        candidate.walk_response(now)
        return candidate

    def __prepare_for_create(self):
        self.crypto.key_to_forward = '0' * 16

    def __prepare_for_created(self, candidate, circuit_id):
        dh_key = self.crypto._generate_diffie_secret()
        hop = Hop(self.community.my_member._ec.pub())
        hop.dh_secret = dh_key[0]
        hop.dh_first_part = dh_key[1]
        self.community.circuits[circuit_id] = Circuit(circuit_id, 1, candidate, self.community)
        self.community.circuits[circuit_id].unverified_hop = hop
        self.crypto._received_secrets[(candidate.sock_addr, circuit_id)] = dh_key[1]

    def __generate_candidate_list(self):
        list = {}
        list['a'] = 'A'
        list['b'] = 'B'
        return list

    def __add_circuit(self, circuit_id):
        self.crypto.proxy.circuits[circuit_id] = Circuit(circuit_id)

    def __add_relay(self, relay_key=None):
        if not relay_key:
            circuit_id = random.randint(1000)
            relay_key = (Mock(), circuit_id)
        self.crypto.session_keys[relay_key] = "1"

    def test_on_break_relay_existing_key(self):
        relay_key = ("a", "b")
        self.crypto.session_keys[relay_key] = "test"
        self.crypto.on_break_relay(relay_key)
        self.assertNotIn(relay_key, self.crypto.session_keys)

    def test_on_break_relay_non_existing_key(self):
        relay_key = ("a", "b")
        self.assertNotIn(relay_key, self.crypto.session_keys)

    def test_on_break_relay_different_keys(self):
        relay_key = ("a", "b")
        second_relay_key = ("b", "a")
        self.crypto.session_keys[relay_key] = "test"
        self.crypto.on_break_relay(second_relay_key)
        self.assertIn(relay_key, self.crypto.session_keys)
        self.assertNotIn(second_relay_key, self.crypto.session_keys)

    def test__encrypt_decrypt_create_content(self):
        # test own circuit create
        candidate = DummyCandidate(self.community.my_member._ec)

        create_message = CreateMessage()
        circuit_id = 123
        self.community.circuits[123] = Circuit(123, 1, candidate, self.community)
        hop = Hop(self.community.my_member._ec.pub())
        self.community.circuits[123].unverified_hop = hop

        encrypted_create_message = \
            self.crypto._encrypt_create_content(candidate, circuit_id, create_message)

        unverified_hop = self.community.circuits[123].unverified_hop
        unencrypted_key = unverified_hop.dh_first_part
        unencrypted_pub_key = self.community.crypto.key_to_bin(self.community.my_member._ec.pub())
        self.assertNotEquals(unencrypted_key, encrypted_create_message.key)

        decrypted_create_message = self.crypto._decrypt_create_content(candidate, circuit_id, encrypted_create_message)

        self.assertEquals(unencrypted_key, decrypted_create_message.key)
        self.assertEquals(unencrypted_pub_key, decrypted_create_message.public_key)

        # test other circuit create
        self.__prepare_for_create()
        del self.community.circuits[123]
        candidate = DummyCandidate(self.community.my_member._ec)

        create_message = CreateMessage()
        circuit_id = 123
        self.community.circuits[123] = Circuit(123, 1, candidate, self.community)
        hop = Hop(self.community.my_member._ec.pub())
        self.community.circuits[123].unverified_hop = hop

        encrypted_create_message = \
            self.crypto._encrypt_create_content(candidate, circuit_id, create_message)

        unverified_hop = self.community.circuits[123].unverified_hop
        unencrypted_key = unverified_hop.dh_first_part
        unencrypted_pub_key = self.community.crypto.key_to_bin(self.community.my_member._ec.pub())
        self.assertNotEquals(unencrypted_key, encrypted_create_message.key)

        decrypted_create_message = self.crypto._decrypt_create_content(candidate, circuit_id, encrypted_create_message)

        self.assertEquals(unencrypted_key, decrypted_create_message.key)
        self.assertEquals(unencrypted_pub_key, decrypted_create_message.public_key)


    def test__encrypt_decrypt_extend_content(self):
        candidate = DummyCandidate(self.community.my_member._ec)

        extend_message = ExtendMessage(self.community.my_member.mid)
        circuit_id = 123
        self.community.circuits[123] = Circuit(123, 1, candidate, self.community)
        hop = Hop(self.community.my_member._ec.pub())
        self.community.circuits[123].unverified_hop = hop

        encrypted_extend_message = \
            self.crypto._encrypt_extend_content(candidate, circuit_id, extend_message)

        unverified_hop = self.community.circuits[123].unverified_hop
        unencrypted_key = unverified_hop.dh_first_part
        self.assertNotEquals(unencrypted_key, encrypted_extend_message.key)

        decrypted_extend_message = self.crypto._decrypt_create_content(candidate, circuit_id, encrypted_extend_message)

        self.assertEquals(unencrypted_key, decrypted_extend_message.key)
        self.assertEquals(self.community.my_member.mid, decrypted_extend_message.extend_with)


    def test__encrypt_decrypt_created_content(self):
        candidate = DummyCandidate(self.community.my_member._ec)
        candidate_list = self.__generate_candidate_list()

        circuit_id = 123
        self.__prepare_for_created(candidate, circuit_id)

        created_message = CreatedMessage(candidate_list)

        encrypted_created_message = \
            self.crypto._encrypt_created_content(candidate, circuit_id, created_message)

        unverified_hop = self.community.circuits[circuit_id].unverified_hop
        unencrypted_key = unverified_hop.dh_first_part
        self.assertNotEquals(unencrypted_key, encrypted_created_message.key)

        decrypted_created_message = self.crypto._decrypt_created_content(candidate, circuit_id, encrypted_created_message)

        self.assertEquals(candidate_list, decrypted_created_message.candidate_list)

########NEW FILE########
__FILENAME__ = test_defaultExitStrategy
from threading import Event
from unittest import TestCase
from mock import Mock
from Tribler.Core.RawServer.RawServer import RawServer
from Tribler.community.anontunnel.exitsocket import ShortCircuitExitSocket, TunnelExitSocket
from Tribler.community.anontunnel.exitstrategies import DefaultExitStrategy
from Tribler.community.anontunnel.payload import DataMessage
from Tribler.community.anontunnel.routing import Circuit, Hop

__author__ = 'Chris'


class TestDefaultExitStrategy(TestCase):
    def setUp(self):
        self.socket = Mock()
        self.socket.sendto = Mock(return_value=True)

        raw_server = Mock()
        raw_server.create_udpsocket = Mock(return_value=self.socket)
        raw_server.start_listening_udp = Mock(return_value=None)

        self.raw_server = raw_server
        self.__create_counter = 0

    def __create_circuit(self, hops):
        circuit = Circuit(self.__create_counter, hops)
        for _ in range(hops):
            circuit.add_hop(Hop(None))

        self.__create_counter += 1
        return circuit

    def test_on_exiting_from_tunnel(self):
        proxy = Mock()
        proxy.circuits = [
            self.__create_circuit(0),
            self.__create_circuit(1),
        ]

        proxy.on_data = Mock()

        return_candidate = Mock()
        destination = ("google.com", 80)
        data = "Hello world"

        strategy = DefaultExitStrategy(self.raw_server, proxy)
        strategy.on_exiting_from_tunnel(proxy.circuits[0].circuit_id, return_candidate, destination, data)
        self.socket.sendto.assert_called_with(data, destination)

    def on_create(self):
        proxy = Mock()
        proxy.circuits = [
            self.__create_circuit(0),
            self.__create_circuit(1),
        ]

        destination = ("google.com", 80)

        strategy = DefaultExitStrategy(self.raw_server, proxy)

        exit_socket = strategy.create(proxy, self.raw_server, proxy.circuits[0].circuit_id, destination)
        self.assertIsInstance(exit_socket, ShortCircuitExitSocket)

        exit_socket = strategy.create(proxy, self.raw_server, proxy.circuits[1].circuit_id, destination)
        self.assertIsInstance(exit_socket, TunnelExitSocket)

    def on_get_socket(self):
        proxy = Mock()
        proxy.circuits = [
            self.__create_circuit(0),
            self.__create_circuit(1),
        ]

        destination = ("google.com", 80)

        strategy = DefaultExitStrategy(self.raw_server, proxy)

        exit_socket = strategy.get_exit_socket(proxy.circuits[0].circuit_id, destination)
        exit_socket2 = strategy.get_exit_socket(proxy.circuits[0].circuit_id, destination)
        self.assertEqual(exit_socket, exit_socket2, "Subsequent exit packets to the same destination should use the exact same exit socket")
########NEW FILE########
__FILENAME__ = test_dispersyBypassEndpoint
import threading
from unittest import TestCase
from Tribler.Core.RawServer.RawServer import RawServer
from Tribler.community.anontunnel.endpoint import DispersyBypassEndpoint

__author__ = 'chris'


class TestDispersyBypassEndpoint(TestCase):
    def on_bypass_message(self, sock_addr, payload):
        """

        @param (str, int) sock_addr: ip address
        @param str payload: the payload
        """
        self.bypass_message = (sock_addr, payload)

    def setUp(self):
        self.succeed = False

        done_flag = threading.Event()
        raw_server = RawServer(done_flag, 10, 5)

        self.endpoint = DispersyBypassEndpoint(raw_server, 0)

    def test_data_came_in(self):
        prefix = str(('f' * 23 + 'e').decode("HEX"))
        self.endpoint.listen_to(prefix, self.on_bypass_message)

        packet = (
            ("127.0.0.1", 100),
            prefix + "Hello world!"
        )

        self.endpoint.data_came_in([packet])
        self.assertEqual(self.bypass_message, packet)
########NEW FILE########
__FILENAME__ = test_extendStrategies
from unittest import TestCase
from Tribler.community.anontunnel.extendstrategies import TrustThyNeighbour
from Tribler.community.anontunnel.globals import MESSAGE_EXTEND, \
    CIRCUIT_STATE_BROKEN
from Tribler.community.anontunnel.payload import ExtendMessage
from Tribler.community.anontunnel.routing import Circuit, Hop
from Tribler.dispersy.candidate import Candidate

__author__ = 'chris'


class ProxyMock:
    def __init__(self):
        self.message = None

    def send_message(self, *args):
        self.message = args


#noinspection PyTypeChecker,PyTypeChecker
class TestTrustThyNeighbour(TestCase):
    def setUp(self):
        self.proxy = ProxyMock()

    def test_extend_ready_circuit(self):
        circuit_candidate = Candidate(("127.0.0.1", 1000), False)
        circuit = Circuit(1, 1, circuit_candidate)
        circuit.add_hop(Hop(None))

        es = TrustThyNeighbour(self.proxy, circuit)
        self.assertRaises(AssertionError, es.extend)

    def test_extend_broken_circuit(self):
        circuit_candidate = Candidate(("127.0.0.1", 1000), False)
        circuit = Circuit(1, 1, circuit_candidate)

        # Break circuit
        circuit.destroy()
        self.assertEqual(circuit.state, CIRCUIT_STATE_BROKEN)

        es = TrustThyNeighbour(self.proxy, circuit)
        self.assertRaises(AssertionError, es.extend)

    def test_extend_extending_circuit(self):
        circuit_candidate = Candidate(("127.0.0.1", 1000), False)
        circuit = Circuit(1, 2, circuit_candidate)
        es = TrustThyNeighbour(self.proxy, circuit)
        es.extend()

        self.assertIsInstance(self.proxy.message, tuple)

        candidate, circuit_id, message_type, message = self.proxy.message

        self.assertEqual(candidate, circuit.first_hop,
                         "Candidate should be first hop of circuit")
        self.assertEqual(circuit_id, circuit.circuit_id,
                         "Circuit_id should be circuit's id")
        self.assertEqual(message_type, MESSAGE_EXTEND,
                         "Send message should be an extend type")
        self.assertIsInstance(message, ExtendMessage)

########NEW FILE########
__FILENAME__ = test_lengthStrategies
from unittest import TestCase
from Tribler.community.anontunnel.lengthstrategies import \
    RandomCircuitLengthStrategy, ConstantCircuitLength

__author__ = 'chris'


class TestRandomCircuitLengthStrategy(TestCase):
    def test_circuit_length(self):
        ls = RandomCircuitLengthStrategy(3, 100)
        self.assertGreaterEqual(ls.circuit_length(), 3, "Should be at least 3")
        self.assertLessEqual(ls.circuit_length(), 100,
                             "Should be at least 100")

        ls = RandomCircuitLengthStrategy(3, 3)
        self.assertEqual(ls.circuit_length(), 3, "Should be 3 exactly")


class TestConstantCircuitLengthStrategy(TestCase):
    def test_circuit_length(self):
        ls = ConstantCircuitLength(42)
        self.assertEqual(ls.circuit_length(), 42, "Should be 42 exactly")

########NEW FILE########
__FILENAME__ = test_libtorrent
import logging
import os
import time
from Tribler.community.anontunnel.events import TunnelObserver
import shutil


class LibtorrentTest(TunnelObserver):
    """
    @param ProxyCommunity proxy : The proxy community instance
    @param Tribler.Core.Session.Session tribler_session: The Tribler Session
    """

    def __init__(self, proxy, tribler_session, delay):
        super(LibtorrentTest, self).__init__()

        self._logger = logging.getLogger(__name__)
        self.proxy = proxy
        self.tribler_session = tribler_session
        self.delay = delay
        self.tribler_session.lm.rawserver.add_task(self.schedule)
        self.download = None
        self.stopping = False

        self.download_started_at = None
        self.download_finished_at = None

    def schedule(self):
        self._logger.debug("Scheduling Anonymous LibTorrent download")
        self.tribler_session.lm.rawserver.add_task(self.start, self.delay)

    def _mark_test_completed(self):
        filename = self.tribler_session.get_state_dir() + "/anon_test.txt"
        handle = open(filename, "w")

        try:
            handle.write("Delete this file to redo the anonymous download test")
        finally:
            handle.close()

    def on_unload(self):
        self.stop()

    def stop(self, delay=0.0):
        if self.download:
            def remove_download():
                self.tribler_session.remove_download(self.download, True, True)
                self.download = None
                self._logger.error("Removed test download")

            self.tribler_session.lm.rawserver.add_task(remove_download, delay=delay)

    def _has_completed_before(self):
        return os.path.isfile(self.tribler_session.get_state_dir() + "/anon_test.txt")

    def start(self):
        from Tribler.community.anontunnel.stats import StatsCollector
        import wx
        from Tribler.Core.TorrentDef import TorrentDef
        from Tribler.Core.simpledefs import DLSTATUS_DOWNLOADING, DLSTATUS_SEEDING
        from Tribler.Main.globals import DefaultDownloadStartupConfig
        from Tribler.Main.vwxGUI import forceWxThread

        hosts = [("94.23.38.156", 51413), ("95.211.198.147", 51413), ("95.211.198.142", 51413), ("95.211.198.140", 51413), ("95.211.198.141", 51413)]

        @forceWxThread
        def thank_you(file_size, start_time, end_time):
            avg_speed_KBps = 1.0 * file_size / (end_time - start_time) / 1024.0
            wx.MessageBox('Your average speed was %.2f KB/s' % (avg_speed_KBps) , 'Download Completed', wx.OK | wx.ICON_INFORMATION)

        def state_call():
            stats_collector = StatsCollector(self.proxy, "AnonTest")

            def _callback(ds):
                if self.stopping:
                    return 1.0, False

                if ds.get_status() == DLSTATUS_DOWNLOADING:
                    if not self.download_started_at:
                        self.download_started_at = time.time()
                        stats_collector.start()

                    stats_collector.download_stats = {
                        'size': ds.get_progress() * ds.get_length(),
                        'download_time': time.time() - self.download_started_at
                    }

                elif ds.get_status() == DLSTATUS_SEEDING and self.download_started_at and not self.download_finished_at:
                    self.download_finished_at = time.time()
                    stats_collector.download_stats = {
                        'size': ds.get_length(),
                        'download_time': self.download_finished_at - self.download_started_at
                    }

                    stats_collector.share_stats()
                    stats_collector.stop()
                    self.stop(5.0)

                    self._mark_test_completed()

                    thank_you(ds.get_length(), self.download_started_at, self.download_finished_at)
                return 1.0, False

            return _callback

        if self._has_completed_before():
            self._logger.warning("Skipping Anon Test since it has been run before")
            return False

        destination_dir = self.tribler_session.get_state_dir() + "/anon_test/"

        try:
            shutil.rmtree(destination_dir)
        except:
            pass

        tdef = TorrentDef.load("anon_test.torrent")
        defaultDLConfig = DefaultDownloadStartupConfig.getInstance()
        dscfg = defaultDLConfig.copy()
        ''' :type : DefaultDownloadStartupConfig '''

        dscfg.set_anon_mode(True)
        dscfg.set_dest_dir(destination_dir)

        self.download = self.tribler_session.start_download(tdef, dscfg)
        self.download.set_state_callback(state_call(), delay=1)

        for peer in hosts:
            self.download.add_peer(peer)

########NEW FILE########
__FILENAME__ = test_proxyCommunity
import logging.config
import os
import time

from mock import Mock
from twisted.internet import reactor
from twisted.internet.threads import blockingCallFromThread

from Tribler.Test.test_as_server import TestAsServer
from Tribler.community.anontunnel import exitstrategies
from Tribler.community.anontunnel.community import ProxyCommunity, ProxySettings
from Tribler.community.anontunnel.crypto import NoCrypto
from Tribler.community.anontunnel.events import TunnelObserver
from Tribler.community.anontunnel.globals import (MESSAGE_CREATED, MESSAGE_CREATE, CIRCUIT_STATE_READY,
                                                  CIRCUIT_STATE_EXTENDING, CIRCUIT_STATE_BROKEN,
                                                  MESSAGE_EXTEND, MESSAGE_PONG)
from Tribler.community.anontunnel.payload import (CreateMessage, CreatedMessage, ExtendedMessage, ExtendMessage,
                                                  DataMessage, PingMessage, PongMessage)
from Tribler.community.anontunnel.routing import Circuit
from Tribler.dispersy.candidate import WalkCandidate, CANDIDATE_ELIGIBLE_DELAY
from Tribler.dispersy.endpoint import NullEndpoint
from Tribler.dispersy.util import call_on_reactor_thread


__author__ = 'Chris'

logging.config.fileConfig(
    os.path.dirname(os.path.realpath(__file__)) + "/../logger.conf")


class DummyEndpoint(NullEndpoint):
    def send_simple(self, *args):
        pass


class TestProxyCommunity(TestAsServer):
    @call_on_reactor_thread
    def setUp(self):
        super(TestProxyCommunity, self).setUp()
        self.__candidate_counter = 0
        self.dispersy = self.session.lm.dispersy

        dispersy = self.dispersy

        keypair = dispersy.crypto.generate_key(u"NID_secp160k1")
        dispersy_member = dispersy.get_member(private_key=dispersy.crypto.key_to_bin(keypair))

        settings = ProxySettings()
        settings.crypto = NoCrypto()

        self.community = dispersy.define_auto_load(ProxyCommunity, dispersy_member, (settings, None), load=True)[0]
        exit_strategy = exitstrategies.DefaultExitStrategy(self.session.lm.rawserver, self.community)
        self.community.observers.append(exit_strategy)

        ''' :type : ProxyCommunity '''

    def setUpPreSession(self):
        super(TestProxyCommunity, self).setUpPreSession()
        self.config.set_dispersy(True)

    @call_on_reactor_thread
    def __create_walk_candidate(self):
        self.__candidate_counter += 1
        wan_address = ("8.8.8.{0}".format(self.__candidate_counter), self.__candidate_counter)
        lan_address = ("0.0.0.0", 0)
        candidate = WalkCandidate(wan_address, False, lan_address, wan_address, u'unknown')

        key = self.dispersy.crypto.generate_key(u"NID_secp160k1")
        member = self.dispersy.get_member(public_key=self.dispersy.crypto.key_to_bin(key.pub()))
        candidate.associate(member)

        now = time.time()
        candidate.walk(now - CANDIDATE_ELIGIBLE_DELAY)
        candidate.walk_response(now)
        return candidate



    def test_on_create(self):
        create_sender = self.__create_walk_candidate()

        create_message = CreateMessage()
        circuit_id = 1337

        self.community.send_message = send_message = Mock()
        self.community.on_create(circuit_id, create_sender, create_message)

        args, keyargs = send_message.call_args

        self.assertEqual(create_sender, keyargs['destination'])
        self.assertEqual(circuit_id, keyargs['circuit_id'])
        self.assertEqual(MESSAGE_CREATED, keyargs['message_type'])
        self.assertIsInstance(keyargs['message'], CreatedMessage)

    def test_create_circuit(self):
        create_sender = self.__create_walk_candidate()

        self.assertRaises(ValueError, self.community.create_circuit, create_sender, 0)

        self.community.send_message = send_message = Mock()

        hops = 1
        circuit = self.community.create_circuit(create_sender, hops)

        # Newly created circuit should be stored in circuits dict
        self.assertIsInstance(circuit, Circuit)
        self.assertEqual(create_sender, circuit.first_hop)
        self.assertEqual(hops, circuit.goal_hops)
        self.assertIn(circuit.circuit_id, self.community.circuits)
        self.assertEqual(circuit, self.community.circuits[circuit.circuit_id])
        self.assertEqual(CIRCUIT_STATE_EXTENDING, circuit.state)

        # We must have sent a CREATE message to the candidate in question
        args, kwargs = send_message.call_args
        destination, reply_circuit, message_type, created_message = args
        self.assertEqual(circuit.circuit_id, reply_circuit)
        self.assertEqual(create_sender, destination)
        self.assertEqual(MESSAGE_CREATE, message_type)
        self.assertIsInstance(created_message, CreateMessage)

    def test_on_created(self):
        first_hop = self.__create_walk_candidate()
        circuit = self.community.create_circuit(first_hop, 1)

        self.community.on_created(circuit.circuit_id, first_hop, CreatedMessage([]))
        self.assertEqual(CIRCUIT_STATE_READY, circuit.state)

    def test_on_extended(self):
        # 2 Hop - should fail due to no extend candidates
        first_hop = self.__create_walk_candidate()
        circuit = self.community.create_circuit(first_hop, 2)

        result = self.community.on_created(circuit.circuit_id, first_hop, CreatedMessage([]))
        self.assertFalse(result)
        self.assertEqual(CIRCUIT_STATE_BROKEN, circuit.state)

        # 2 Hop - should succeed
        second_hop = self.__create_walk_candidate()

        public_bin = second_hop.get_member().public_key
        key = second_hop.get_member()._ec

        candidate_list = []
        candidate_list.append(self.community.crypto.key_to_bin(key))
        circuit = self.community.create_circuit(first_hop, 2)

        self.community.send_message = send_message = Mock()

        result = self.community.on_created(circuit.circuit_id, first_hop, CreatedMessage(candidate_list))
        self.assertTrue(result)

        # ProxyCommunity should send an EXTEND message with the hash of second_hop's pub-key
        args, kwargs = send_message.call_args
        circuit_candidate, circuit_id, message_type, message = args

        self.assertEqual(first_hop, circuit_candidate)
        self.assertEqual(circuit.circuit_id, circuit_id)
        self.assertEqual(MESSAGE_EXTEND, message_type)
        self.assertIsInstance(message, ExtendMessage)
        self.assertEqual(message.extend_with, public_bin)

        # Upon reception of the ON_EXTENDED the circuit should reach it full 2-hop length and thus be ready for use
        result = self.community.on_extended(circuit.circuit_id, first_hop, ExtendedMessage("", []))
        self.assertTrue(result)
        self.assertEqual(CIRCUIT_STATE_READY, circuit.state)

    def test_remove_circuit(self):
        first_hop = self.__create_walk_candidate()
        circuit = self.community.create_circuit(first_hop, 1)

        self.assertIn(circuit.circuit_id, self.community.circuits)
        self.community.remove_circuit(circuit.circuit_id)
        self.assertNotIn(circuit, self.community.circuits)

    def test_on_data(self):
        first_hop = self.__create_walk_candidate()
        circuit = self.community.create_circuit(first_hop, 1)
        self.community.on_created(circuit.circuit_id, first_hop, CreatedMessage([]))

        payload = "Hello world"
        origin = ("google.com", 80)
        data_message = DataMessage(None, payload, origin=origin)

        observer = TunnelObserver()
        observer.on_incoming_from_tunnel = on_incoming_from_tunnel = Mock()
        self.community.observers.append(observer)

        # Its on our own circuit so it should trigger the on_incoming_from_tunnel event
        self.community.on_data(circuit.circuit_id, first_hop, data_message)
        on_incoming_from_tunnel.assert_called_with(self.community, circuit, origin, payload)

        # Not our own circuit so we need to exit it
        destination = ("google.com", 80)
        exit_message = DataMessage(destination, payload, origin=None)
        observer.on_exiting_from_tunnel = on_exiting_from_tunnel = Mock()
        self.community.on_data(1337, first_hop, exit_message)
        on_exiting_from_tunnel.assert_called_with(1337, first_hop, destination, payload)

    def test_on_extend(self):
        # We mimick the intermediary hop ( ORIGINATOR - INTERMEDIARY - NODE_TO_EXTEND_ORIGINATORS_CIRCUIT_WITH )
        originator = self.__create_walk_candidate()
        node_to_extend_with = self.__create_walk_candidate()
        originator_circuit_id = 1337

        extend_pub_key = node_to_extend_with.get_member()._ec
        extend_pub_key = self.dispersy.crypto.key_to_bin(extend_pub_key)

        # make sure our node_to_extend_with comes up when yielding verified candidates
        blockingCallFromThread(reactor, self.community.add_candidate, node_to_extend_with)
        self.assertIn(node_to_extend_with, self.community._candidates.itervalues())

        self.community.send_message = send_message = Mock()
        self.community.on_create(originator_circuit_id, originator, CreateMessage())

        # Check whether we are sending node_to_extend_with in the CreatedMessage reply
        args, kwargs = send_message.call_args
        created_message = kwargs['message']
        candidate_dict = created_message.candidate_list
        self.assertIsInstance(created_message, CreatedMessage)
        self.assertIn(extend_pub_key, candidate_dict)

        self.community.on_extend(originator_circuit_id, originator, ExtendMessage(extend_pub_key))

        # Check whether we are sending a CREATE to node_to_extend_with
        args, kwargs = send_message.call_args
        create_destination, circuit_id, message_type, message = args
        self.assertEqual(node_to_extend_with, create_destination)
        self.assertEqual(MESSAGE_CREATE, message_type)
        self.assertIsInstance(message, CreateMessage)

        # Check whether the routing table has been updated
        relay_from_originator = (originator.sock_addr, originator_circuit_id)
        relay_from_endpoint = (node_to_extend_with.sock_addr, circuit_id)

        self.assertIn(relay_from_originator, self.community.relay_from_to)
        self.assertIn(relay_from_endpoint, self.community.relay_from_to)

    def test_on_pong(self):
        first_hop = self.__create_walk_candidate()
        circuit = self.community.create_circuit(first_hop, 1)
        self.community.on_created(circuit.circuit_id, first_hop, CreatedMessage({}))

        result = self.community.on_pong(circuit.circuit_id, first_hop, PongMessage())
        self.assertFalse(result, "Cannot handle a pong when we never sent a PING")

        self.community.create_ping(first_hop, circuit)

        # Check whether the circuit last incoming time is correct after the pong
        circuit.last_incoming = 0
        result = self.community.on_pong(circuit.circuit_id, first_hop, PongMessage())
        self.assertTrue(result)

        self.assertAlmostEqual(circuit.last_incoming, time.time(), delta=0.5)

    def test_on_ping(self):
        circuit_id = 1337
        first_hop = self.__create_walk_candidate()
        self.community.add_candidate(first_hop)

        self.community.on_create(circuit_id, first_hop, CreateMessage())

        self.community.send_message = send_message = Mock()
        self.community.on_ping(circuit_id, first_hop, PingMessage())

        # Check whether we responded with a pong
        args, kwargs = send_message.call_args

        self.assertEqual(first_hop, kwargs['destination'])
        self.assertEqual(circuit_id, kwargs['circuit_id'])
        self.assertEqual(MESSAGE_PONG, kwargs['message_type'])
        self.assertIsInstance(kwargs['message'], PongMessage)

########NEW FILE########
__FILENAME__ = test_selectionStrategies
from random import randint
from unittest import TestCase
from Tribler.community.anontunnel.routing import Circuit, Hop

from Tribler.community.anontunnel.selectionstrategies import \
    LengthSelectionStrategy, RandomSelectionStrategy
from Tribler.dispersy.candidate import Candidate


__author__ = 'chris'


class TestLengthSelectionStrategy(TestCase):
    def setUp(self):
        self.circuits = [self.__circuit(0), self.__circuit(1),
                         self.__circuit(2), self.__circuit(3),
                         self.__circuit(4)]

    @staticmethod
    def __circuit(hops):
        candidate = Candidate(("127.0.0.1", 1000), False)

        circuit = Circuit(randint(0, 1000), hops, candidate)
        for c in [candidate] * hops:
            circuit.add_hop(Hop(None))

        return circuit

    def test_select(self):
        cs = LengthSelectionStrategy(3, 3)
        self.assertEqual(cs.select(self.circuits), self.circuits[3])

        cs = LengthSelectionStrategy(0, 3)
        self.assertIn(cs.select(self.circuits), self.circuits[0:4])

        cs = LengthSelectionStrategy(1, 3)
        self.assertIn(cs.select(self.circuits), self.circuits[1:3])

        cs = LengthSelectionStrategy(5, 10)
        self.assertRaises(ValueError, cs.select, self.circuits)


class TestRandomSelectionStrategy(TestCase):
    def setUp(self):
        self.circuits = [self.__circuit(1), self.__circuit(2),
                         self.__circuit(3), self.__circuit(4)]

    @staticmethod
    def __circuit(hops):
        candidate = Candidate(("127.0.0.1", 1000), False)

        circuit = Circuit(randint(0, 1000), hops, candidate)
        for c in [candidate] * hops:
            circuit.add_hop = c

        return circuit

    def test_select(self):
        cs = RandomSelectionStrategy()
        self.assertIsInstance(cs.select(self.circuits), Circuit)

        # Cannot select from empty list
        self.assertRaises(ValueError, cs.select, [])
########NEW FILE########
__FILENAME__ = test_shortCircuitExitSocket
from unittest import TestCase
from mock import Mock
from Tribler.community.anontunnel.exitsocket import ShortCircuitExitSocket
from Tribler.community.anontunnel.payload import DataMessage

__author__ = 'Chris'


class TestShortCircuitExitSocket(TestCase):
    def setUp(self):

        self.socket = Mock()
        self.socket.sendto = Mock(return_value=True)

        raw_server = Mock()
        raw_server.create_udpsocket = Mock(return_value=self.socket)
        raw_server.start_listening_udp = Mock(return_value=None)

        self.circuit_id = 123

        self.proxy = Mock()
        self.proxy.on_data = Mock()

        self.return_address = ("127.0.0.1", 1337)
        self.exit_socket = ShortCircuitExitSocket(raw_server, self.proxy, self.circuit_id, self.return_address)

    def test_data_came_in(self):
        packet = "Hello world"
        source_address = ("google.com", 80)
        self.exit_socket.data_came_in([(source_address, packet)])

        args, kwargs = self.proxy.on_data.call_args
        circuit_id, none, message = args
        expected_message = DataMessage(("0.0.0.0", 0), packet, source_address)

        self.assertEqual(self.circuit_id, circuit_id)
        self.assertIsNone(none)
        self.assertEqual(expected_message.data, message.data)
        self.assertEqual(expected_message.destination, message.destination)
        self.assertEqual(expected_message.origin, message.origin)

    def test_sendto(self):
        data = "Hello world"
        destination = ("google.com", 80)
        self.exit_socket.sendto(data, destination)

        # The underlying socket must be called by the ExitSocket
        self.socket.sendto.assert_called_with(data, destination)
########NEW FILE########
__FILENAME__ = test_tunnelExitSocket
from unittest import TestCase
from mock import Mock
from Tribler.community.anontunnel.exitsocket import TunnelExitSocket

__author__ = 'Chris'


class TestTunnelExitSocket(TestCase):
    def setUp(self):

        self.socket = Mock()
        self.socket.sendto = Mock(return_value=True)

        raw_server = Mock()
        raw_server.create_udpsocket = Mock(return_value=self.socket)
        raw_server.start_listening_udp = Mock(return_value=None)

        self.circuit_id = 123

        self.proxy = Mock()
        self.proxy.tunnel_data_to_origin = Mock()

        self.return_address = ("127.0.0.1", 1337)
        self.exit_socket = TunnelExitSocket(raw_server, self.proxy, self.circuit_id, self.return_address)

    def test_data_came_in(self):
        packet = "Hello world"
        source_address = ("google.com", 80)
        self.exit_socket.data_came_in([(source_address, packet)])

        # Incoming packets must be routed back using the proxy
        self.proxy.tunnel_data_to_origin.assert_called_with(
            circuit_id=self.circuit_id,
            candidate=self.return_address,
            source_address=source_address,
            payload=packet
        )

    def test_sendto(self):
        data = "Hello world"
        destination = ("google.com", 80)
        self.exit_socket.sendto(data, destination)

        # The underlying socket must be called by the ExitSocket
        self.socket.sendto.assert_called_with(data, destination)
########NEW FILE########
__FILENAME__ = community
import logging
from random import random
from time import time

from twisted.internet import reactor

from .conversion import BarterConversion
from .database import BarterDatabase
from .efforthistory import CYCLE_SIZE, EffortHistory
from .payload import BarterRecordPayload, PingPayload, PongPayload, MemberRequestPayload, MemberResponsePayload
from Tribler.dispersy.authentication import DoubleMemberAuthentication, NoAuthentication, MemberAuthentication
from Tribler.dispersy.candidate import WalkCandidate, Candidate
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CommunityDestination, CandidateDestination
from Tribler.dispersy.distribution import LastSyncDistribution, DirectDistribution, GlobalTimePruning
from Tribler.dispersy.message import BatchConfiguration, Message, DropMessage
from Tribler.dispersy.requestcache import RandomNumberCache
from Tribler.dispersy.resolution import PublicResolution


try:
    # python 2.7 only...
    from collections import OrderedDict
except ImportError:
    from Tribler.dispersy.python27_ordereddict import OrderedDict


logger = logging.getLogger(__name__)

# generated: Fri Apr 19 17:07:32 2013
# curve: high <<< NID_sect571r1 >>>
# len: 571 bits ~ 144 bytes signature
# pub: 170 3081a7301006072a8648ce3d020106052b8104002703819200040792e72441554e5d5448043bcf516c18d93125cf299244f85fa3bc2c89cdca3029b2f8d832573d337babae5f64ff49dbf70ceca5a0a15e1b13a685c50c4bf285252667e3470b82f90318ac8ee2ad2d09ddabdc140ca879b938921831f0089511321e456b67c3b545ca834f67259e4cf7eff02fbd797c03a2df6db5b945ff3589227d686d6bf593b1372776ece283ab0d
# pub-sha1 4fe1172862c649485c25b3d446337a35f389a2a2
# -----BEGIN PUBLIC KEY-----
# MIGnMBAGByqGSM49AgEGBSuBBAAnA4GSAAQHkuckQVVOXVRIBDvPUWwY2TElzymS
# RPhfo7wsic3KMCmy+NgyVz0ze6uuX2T/Sdv3DOyloKFeGxOmhcUMS/KFJSZn40cL
# gvkDGKyO4q0tCd2r3BQMqHm5OJIYMfAIlREyHkVrZ8O1RcqDT2clnkz37/AvvXl8
# A6LfbbW5Rf81iSJ9aG1r9ZOxNyd27OKDqw0=
# -----END PUBLIC KEY-----
MASTER_MEMBER_PUBLIC_KEY = "3081a7301006072a8648ce3d020106052b8104002703819200040792e72441554e5d5448043bcf516c18d93125cf299244f85fa3bc2c89cdca3029b2f8d832573d337babae5f64ff49dbf70ceca5a0a15e1b13a685c50c4bf285252667e3470b82f90318ac8ee2ad2d09ddabdc140ca879b938921831f0089511321e456b67c3b545ca834f67259e4cf7eff02fbd797c03a2df6db5b945ff3589227d686d6bf593b1372776ece283ab0d".decode("HEX")
MASTER_MEMBER_PUBLIC_KEY_DIGEST = "4fe1172862c649485c25b3d446337a35f389a2a2".decode("HEX")


def bitcount(l):
    c = 0
    while l:
        if l & 1:
            c += 1
        l >>= 1
    return c


class PingCache(RandomNumberCache):

    def __init__(self, community, candidate, member):
        super(PingCache, self).__init__(community.request_cache, u"ping")
        self.community = community
        self.candidate = candidate
        self.member = member

    def on_timeout(self):
        self.community.remove_from_slope(self.member)
        if isinstance(self.candidate, WalkCandidate):
            self.candidate.obsolete(time())


class MemberRequestCache(RandomNumberCache):

    def __init__(self, community, func):
        super(MemberRequestCache, self).__init__(community.request_cache, u"member-request")
        self.func = func

    def on_timeout(self):
        logger.warning("unable to find missing member [%s]", self)


class RecordCandidate(object):

    """
    Container class for a candidate that is on our slope.
    """
    # TODO(emilon): the callback_id could be removed and use the object itself as a key on the pending tasks dict
    def __init__(self, candidate, callback_id):
        super(RecordCandidate, self).__init__()
        self.candidate = candidate
        self.callback_id = callback_id


class Association(object):

    def __init__(self):
        self.timestamp = 0.0
        self.member = None

    def retrieve(self):
        """
        Returns True when this association may be updated again.
        """
        now = time()
        if now - self.timestamp > 60.0:
            self.timestamp = now
            return True

        return False


class Book(object):

    """
    Container class for all the bookkeeping information per peer.
    """
    def __init__(self, member):
        super(Book, self).__init__()
        self.member = member
        self.cycle = 0
        self.effort = None
        self.upload = 0
        self.download = 0

    @property
    def score(self):
        """
        Score is used to order members by how useful it is to make a (new) record with them.
        """
        # how much this member contributed - how much this member consumed
        return self.upload - self.download


class BarterCommunity(Community):

    @classmethod
    def get_master_members(cls, dispersy):
        return [dispersy.get_member(MASTER_MEMBER_PUBLIC_KEY)]

    def __init__(self, dispersy, master, my_member, swift_process):
        logger.debug("loading the Barter community")

        # original walker callbacks (will be set during super(...).__init__)
        self._original_on_introduction_request = None
        self._original_on_introduction_response = None

        super(BarterCommunity, self).__init__(dispersy, master, my_member)

        # _SWIFT is a SwiftProcess instance (allowing us to schedule CLOSE_EVENT callbacks)
        self._swift = swift_process
        self._swift.set_subscribe_channel_close("ALL", True, self.i2ithread_channel_close)

        # _DATABASE stores all direct observations and indirect hearsay
        self._database = BarterDatabase(self._dispersy)
        self._database.open()

        options = dict(self._database.execute(u"SELECT key, value FROM option"))
        # _TOTAL_UP and _TOTAL_DOWN contain the total up and down statistics received from swift
        self._total_up = long(str(options.get(u"total-up", 0)))
        self._total_down = long(str(options.get(u"total-down", 0)))
        # _UNKNOWN_UP and _UNKNOWN_DOWN contain the total up and down statistics received from swift
        # where we were able to associate to a Dispersy member
        self._associated_up = long(str(options.get(u"associated-up", 0)))
        self._associated_down = long(str(options.get(u"associated-down", 0)))

        # _BOOKS cache (reduce _DATABASE access)
        self._books_length = 512
        self._books = OrderedDict()

        # _ADDRESS_ASSOCIATION containing address:Association pairs
        self._address_association_length = 512
        self._address_association = OrderedDict()

        # _DOWNLOAD_STATES contains all peers that are currently downloading.  when we determine
        # that a peer is missing, we will update its bandwidth statistics
        self._download_states = dict()

        # _SLOPE contains the promising members as Member:RecordCandidate
        self._slope_length = 10
        self._slope = {}

        # _SIGNATURE_COUNT is the number of members that will be asked to sign
        self._signature_count = 5

        # _HAS_BEEN_KILLED makes Tribler remove the community pointer
        self._has_been_killed = False

        # wait till next time we can create records with the candidates on our slope
        self._pending_tasks["periodically create records"] = reactor.callLater(0, self._periodically_create_records)

    @property
    def database(self):
        return self._database

    @property
    def has_been_killed(self):
        return self._has_been_killed

    @property
    def dispersy_sync_response_limit(self):
        return 5 * 1024

    @property
    def dispersy_sync_bloom_filter_strategy(self):
        return self._dispersy_claim_sync_bloom_filter_modulo

    def initiate_meta_messages(self):
        pruning = GlobalTimePruning(10000, 11000)
        return super(BarterCommunity, self).initiate_meta_messages() + [
            Message(self, u"barter-record",
                    DoubleMemberAuthentication(allow_signature_func=self.allow_signature_request),
                    PublicResolution(),
                    LastSyncDistribution(synchronization_direction=u"DESC", priority=128, history_size=1, pruning=pruning),
                    CommunityDestination(node_count=10),
                    BarterRecordPayload(),
                    self.check_barter_record,
                    self.on_barter_record,
                    batch=BatchConfiguration(max_window=4.5)),
            Message(self, u"ping",
                    NoAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    PingPayload(),
                    self.check_ping,
                    self.on_ping),
            Message(self, u"pong",
                    NoAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    PongPayload(),
                    self.check_pong,
                    self.on_pong),
            Message(self, u"member-request",
                    NoAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    MemberRequestPayload(),
                    self.check_member_request,
                    self.on_member_request),
            Message(self, u"member-response",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    MemberResponsePayload(),
                    self.check_member_response,
                    self.on_member_response),
        ]

    def _initialize_meta_messages(self):
        super(BarterCommunity, self)._initialize_meta_messages()

        # replace the callbacks for the dispersy-introduction-request and
        # dispersy-introduction-response messages
        meta = self._meta_messages[u"dispersy-introduction-request"]
        self._original_on_introduction_request = meta.handle_callback
        self._meta_messages[meta.name] = Message(meta.community, meta.name, meta.authentication, meta.resolution, meta.distribution, meta.destination, meta.payload, meta.check_callback, self.on_introduction_request, meta.undo_callback, meta.batch)
        assert self._original_on_introduction_request

        meta = self._meta_messages[u"dispersy-introduction-response"]
        self._original_on_introduction_response = meta.handle_callback
        self._meta_messages[meta.name] = Message(meta.community, meta.name, meta.authentication, meta.resolution, meta.distribution, meta.destination, meta.payload, meta.check_callback, self.on_introduction_response, meta.undo_callback, meta.batch)
        assert self._original_on_introduction_response

    def initiate_conversions(self):
        return [DefaultConversion(self), BarterConversion(self)]

    def dispersy_cleanup_community(self, message):
        self._has_been_killed = True
        # remove all data from the local database
        self._database.cleanup()
        # re-classify to prevent loading
        return super(BarterCommunity, self).dispersy_cleanup_community(message)

    def unload_community(self):
        logger.debug("unloading the Barter community")
        super(BarterCommunity, self).unload_community()

        self._swift.set_subscribe_channel_close("ALL", False, self.i2ithread_channel_close)

        # cancel outstanding pings
        for record_candidate in self._slope.itervalues():
            self.cancel_pending_task(record_candidate.callback_id)
        self._slope = {}

        # update all up and download values
        self.download_state_callback([], False)

        # store all cached bookkeeping
        self._database.executemany(u"INSERT OR REPLACE INTO book (member, cycle, effort, upload, download) VALUES (?, ?, ?, ?, ?)",
                                   [(book.member.database_id, book.cycle, buffer(book.effort.bytes), book.upload, book.download) for book in self._books.itervalues()])

        # store bandwidth counters
        self._database.executemany(u"INSERT OR REPLACE INTO option (key, value) VALUES (?, ?)",
                                   [(u"total-up", buffer(str(self._total_up))),
                                    (u"total-down", buffer(str(self._total_down))),
                                    (u"associated-up", buffer(str(self._associated_up))),
                                    (u"associated-down", buffer(str(self._associated_down)))])

        # close database
        self._database.close()

    def get_book(self, member):
        # try cache
        book = self._books.get(member.database_id)
        if not book:
            book = Book(member)

            # fetch from database
            try:
                cycle, effort, upload, download = self._database.execute(u"SELECT cycle, effort, upload, download FROM book WHERE member = ?",
                                                                         (member.database_id,)).next()
            except StopIteration:
                now = time()
                book.cycle = int(now / CYCLE_SIZE)
                book.effort = EffortHistory(now)
            else:
                book.cycle = cycle
                book.effort = EffortHistory(str(effort), float(cycle * CYCLE_SIZE))
                book.upload = upload
                book.download = download

            # store in cache
            self._books[member.database_id] = book
            if len(self._books) > self._books_length:
                _, old = self._books.popitem(False)
                self._database.execute(u"INSERT OR REPLACE INTO book (member, cycle, effort, upload, download) VALUES (?, ?, ?, ?)",
                                       (old.member.database_id, old.cycle, buffer(old.effort.bytes), old.upload, old.download))
        return book

    def update_book_from_address(self, swift_address, timestamp, bytes_up, bytes_down, delayed=True):
        """
        Updates the book associated with SWIFT_ADDRESS.

        When we do not yet know the book associated with SWIFT_ADDRESS we will attempt to retrieve
        this information, the update will only occur when this is successful.
        """
        assert isInIOThread(), "Must be called on the reactor thread"

        def _update(member):
            if member:
                book = self.get_book(member)
                book.cycle = max(book.cycle, int(timestamp / CYCLE_SIZE))
                book.upload += bytes_up
                book.download += bytes_down
                logger.debug("update book for %s +%d -%d", member.mid.encode("HEX"), book.upload, book.download)

                # associated_{up,down} is from our viewpoint while bytes_{up,down} is from the other
                # peers' viewpoint
                self._associated_up += bytes_down
                self._associated_down += bytes_up
                return True
            return False

        def _delayed_update(response):
            member = response.authentication.member
            logger.debug("retrieved member %s from swift address %s:%d [%s]",
                         member.mid.encode("HEX"),
                         swift_address[0],
                         swift_address[1],
                         cache)
            association = self._address_association.setdefault(swift_address, Association())
            association.member = member
            if len(self._address_association) > self._address_association_length:
                self._address_association.popitem(False)
            return _update(response.authentication.member)

        # total_{up,down} is from our viewpoint while bytes_{up,down} is from the other peers'
        # viewpoint
        self._total_up += bytes_down
        self._total_down += bytes_up

        association = self._address_association.setdefault(swift_address, Association())
        if association.member:
            _update(association.member)

        elif delayed and association.retrieve():
            # we do not have the member associated to the address, we will attempt to retrieve it
            cache = self._request_cache.add(MemberRequestCache(self, _delayed_update))
            meta = self._meta_messages[u"member-request"]
            request = meta.impl(distribution=(self.global_time,),
                                destination=(Candidate(swift_address, True),),  # assume tunnel=True
                                payload=(cache.number,))
            logger.debug("trying to obtain member from swift address %s:%d [%s]",
                         swift_address[0],
                         swift_address[1],
                         cache)
            self._dispersy.store_update_forward([request], False, False, True)

        # else:
        #     logger.debug("not yet allowed to obtain member from swift address %s:%d",
        #                  swift_address[0],
        #                  swift_address[1])

    def i2ithread_channel_close(self, *args):
        reactor.callFromThread(self._channel_close, *args)

    def _channel_close(self, roothash_hex, address, raw_bytes_up, raw_bytes_down, cooked_bytes_up, cooked_bytes_down):
        assert isinstance(roothash_hex, str), type(roothash_hex)
        assert isinstance(address, tuple), type(address)
        assert isinstance(raw_bytes_up, (int, long)), type(raw_bytes_up)
        assert isinstance(raw_bytes_down, (int, long)), type(raw_bytes_down)
        assert isinstance(cooked_bytes_up, (int, long)), type(cooked_bytes_up)
        assert isinstance(cooked_bytes_down, (int, long)), type(cooked_bytes_down)
        assert isInIOThread(), "Must be called on the reactor thread"
        if cooked_bytes_up or cooked_bytes_down:
            logger.debug("swift channel close %s:%d with +%d -%d", address[0], address[1], cooked_bytes_up, cooked_bytes_down)
            self.update_book_from_address(address, time(), cooked_bytes_up, cooked_bytes_down, delayed=True)

    def download_state_callback(self, states, delayed):
        assert isInIOThread(), "Must be called on the reactor thread"
        assert isinstance(states, list), type(states)
        assert isinstance(delayed, bool), type(delayed)
        timestamp = int(time())

        # get all swift downloads that have peers
        active = dict((state.get_download().get_def().get_id(), state)
                      for state
                      in states
                      if state.get_download().get_def().get_def_type() == "swift" and state.get_peerlist())

        # OLD is used to determine stopped downloads and peers that left.  NEW will become the next OLD
        old = self._download_states
        new = self._download_states = dict()

        # find downloads that stopped
        for identifier in set(old.iterkeys()).difference(set(active.iterkeys())):
            for address, (up, down) in old[identifier].iteritems():
                logger.debug("%s]  %s:%d  +%d   -%d", identifier.encode("HEX"), address[0], address[1], up, down)
                self.update_book_from_address(address, timestamp, up, down, delayed=delayed)

        for identifier, state in active.iteritems():
            if identifier in old:
                # find peers that left
                for address in set(old[identifier]).difference(set((peer["ip"], peer["port"]) for peer in state.get_peerlist())):
                    up, down = old[identifier][address]
                    logger.debug("%s]  %s:%d  +%d   -%d", identifier.encode("HEX"), address[0], address[1], up, down)
                    self.update_book_from_address(address, timestamp, up, down, delayed=delayed)

            # set OLD for the next call to DOWNLOAD_STATE_CALLBACK
            new[identifier] = dict(((str(peer["ip"]), peer["port"]),
                                    (long(peer["utotal"]), long(peer["dtotal"])))
                                   for peer
                                   in state.get_peerlist()
                                   if peer["utotal"] > 0 or peer["dtotal"] > 0)

    def on_introduction_request(self, messages):
        try:
            return self._original_on_introduction_request(messages)
        finally:
            cycle = int(time() / CYCLE_SIZE)
            for message in messages:
                # logger.debug("received introduction-request message from %s", message.candidate)

                book = self.get_book(message.authentication.member)
                if book.cycle < cycle:
                    book.cycle = cycle
                    book.effort.set(cycle * CYCLE_SIZE)

                self.try_adding_to_slope(message.candidate, book.member)

    def on_introduction_response(self, messages):
        try:
            return self._original_on_introduction_response(messages)
        finally:
            cycle = int(time() / CYCLE_SIZE)
            for message in messages:
                # logger.debug("received introduction-response message from %s", message.candidate)

                book = self.get_book(message.authentication.member)
                if book.cycle < cycle:
                    book.cycle = cycle
                    book.effort.set(cycle * CYCLE_SIZE)

                self.try_adding_to_slope(message.candidate, book.member)

    def create_barter_record(self, second_candidate, second_member):
        """
        Create a dispersy-signature-request that encapsulates a barter-record.
        """
        book = self.get_book(second_member)
        upload_first_to_second = book.download
        upload_second_to_first = book.upload
        logger.debug("asking %s to sign effort: %s  self->peer: %d  peer->self: %d",
                     second_member.mid.encode("HEX"),
                     bin(book.effort.long),
                     upload_first_to_second,
                     upload_second_to_first)

        meta = self.get_meta_message(u"barter-record")
        record = meta.impl(authentication=([self._my_member, second_member],),
                           distribution=(self.claim_global_time(),),
                           payload=(book.cycle, book.effort, upload_first_to_second, upload_second_to_first,
                                    # the following parameters are used for debugging only
                                    time(), book.download, book.upload, self._total_up, self._total_down, self._associated_up, self._associated_down,
                                    time(), 0, 0, 0, 0, 0, 0),
                           sign=False)
        return self.create_dispersy_signature_request(second_candidate, record, self.on_signature_response)

    def allow_signature_request(self, message):
        """
        A dispersy-signature-request has been received.

        Return None or a Message.Implementation.
        """
        assert message.name == u"barter-record"
        assert not message.authentication.is_signed
        logger.debug("%s", message)

        _, first_member = message.authentication.signed_members[0]
        _, second_member = message.authentication.signed_members[1]

        if not second_member == self._my_member:
            # the first_member is us.  meaning that we will get duplicate global times because
            # someone else claimed the global time for us
            logger.warning("invalid request.  second_member != my_member")
            return None

        book = self.get_book(first_member)
        proposed_effort = message.payload.effort
        local_effort = book.effort

        if not (message.payload.cycle == proposed_effort.cycle == local_effort.cycle):
            # there is a problem determining the current cycle.  this can be caused by (a)
            # difference in local clock times, (b) record creation during transition between cycles,
            # (c) delay in message processing resulting in issue b.
            logger.warning("invalid request. cycle mismatch (%d ?= %d ?= %d)", message.payload.cycle, proposed_effort.cycle, local_effort.cycle)
            return None
        cycle = message.payload.cycle

        if proposed_effort.long ^ local_effort.long:
            # there is a mismatch in bits, this should not occur on the DAS4, however, we will need
            # to repair this once we go into the big bad world
            logger.warning("bits mismatch. using AND merge (%s != %s)", bin(proposed_effort.long), bin(local_effort.long))

        # merge effort using AND
        effort = EffortHistory(proposed_effort.long & local_effort.long, cycle * CYCLE_SIZE)

        # merge bandwidth using MIN/MAX
        upload_first_to_second = min(message.payload.upload_first_to_second, book.upload)
        upload_second_to_first = max(message.payload.upload_second_to_first, book.download)

        # the first_member took the initiative this cycle.  prevent us from also taking the
        # initiative and create duplicate records this cycle
        self.remove_from_slope(first_member)

        # return the modified barter-record we propose
        meta = self.get_meta_message(u"barter-record")
        return meta.impl(authentication=([first_member, second_member],),
                         distribution=(message.distribution.global_time,),
                         payload=(cycle, effort, upload_first_to_second, upload_second_to_first,
                                  # the following parameters are used for debugging only
                                  message.payload.first_timestamp,
                                  message.payload.first_upload,
                                  message.payload.first_download,
                                  message.payload.first_total_up,
                                  message.payload.first_total_down,
                                  message.payload.first_associated_up,
                                  message.payload.first_associated_down,
                                  time(),
                                  book.upload,
                                  book.download,
                                  self._total_up,
                                  self._total_down,
                                  self._associated_up,
                                  self._associated_down))

    def on_signature_response(self, cache, new_message, changed):
        """
        A dispersy-signature-response has been received.

        Return True or False to either accept or decline the message.
        """
        logger.debug("new message: %s", new_message)

        # TODO: we should ensure that new_message is correct (i.e. all checks made above)

        if new_message:
            # self._observation(new_message.candidate, cache.members[0], time())
            assert cache.request.payload.message.meta == new_message.meta
            return True

        else:
            self.remove_from_slope(cache.members[0])
            return False

    def _periodically_create_records(self):
        """
        Periodically initiates signature requests with the current optimal peers on self._SLOPE.

        Each cycle is divided into three phases.  The first phase consists of only hill climbing,
        during the second phase signature requests are made at random intervals, and during the
        third phase hill climbing already start for the next phase, although no signature request
        are made.

        |-----------50%-----------|---------40%--------|-10%-|
                                      record creation
        """
        # WINNERS holds the members that have 'won' this cycle
        winners = set()

        @inlineCallbacks
        def do_iteration():
            now = time()
            start_climb = int(now / CYCLE_SIZE) * CYCLE_SIZE
            start_create = start_climb + CYCLE_SIZE * 0.5
            start_idle = start_climb + CYCLE_SIZE * 0.9
            start_next = start_climb + CYCLE_SIZE

            if start_climb <= now < start_create:
                logger.debug("cycle %d.  first climbing phase.  wait %.2f seconds until the next phase",
                             now / CYCLE_SIZE, start_create - now)
                yield deferLater(reactor, start_create - now, lambda: None)

            elif start_create <= now < start_idle and len(winners) < self._signature_count:
                logger.debug("cycle %d.  record creation phase.  wait %.2f seconds until record creation",
                             now / CYCLE_SIZE, CYCLE_SIZE * 0.4 / self._signature_count)
                yield deferLater(reactor, (CYCLE_SIZE * 0.4 / self._signature_count) * random(), lambda: None)

                # find the best candidate for this cycle
                score = 0
                winner = None
                for member in self._slope.iterkeys():
                    book = self.get_book(member)
                    if book.score > score and not member in winners:
                        winner = member

                if winner:
                    logger.debug("cycle %d.  attempt record creation with %d",
                                 now / CYCLE_SIZE, winner.mid.encode("HEX"))
                    record_candidate = self._slope[winner]

                    # prevent this winner to 'win' again in this cycle
                    winners.add(winner)

                    # TODO: this may be and invalid assumption
                    # assume that the peer is online
                    # record_candidate.history.set(now)

                    self.cancel_pending_task(record_candidate.callback_id)
                    self.create_barter_record(record_candidate.candidate, winner)

                else:
                    logger.debug("cycle %d.  no peers available for record creation (%d peers on slope)",
                                 int(now / CYCLE_SIZE), len(self._slope))

            else:
                logger.debug("cycle %d.  second climbing phase.  wait %.2f seconds until the next phase",
                             now / CYCLE_SIZE, start_next - now)
                assert now >= start_idle or len(winners) >= self._signature_count
                for record_candidate in self._slope.itervalues():
                    self.cancel_pending_task(record_candidate.callback_id)
                self._slope = {}
                winners = set()
                yield deferLater(reactor, start_next - now, lambda: None)

        return do_iteration()

    def try_adding_to_slope(self, candidate, member):
        if not member in self._slope:
            book = self.get_book(member)
            # logger.debug("attempt to add %s with score %f", member, book.score)
            if (book.score > 0 and
                (len(self._slope) < self._slope_length or
                 min(self.get_book(mbr).score for mbr in self._slope.iterkeys()) < book.score)):

                logger.debug("add %s with score %f", member, book.score)
                callback_id = self._dispersy.callback.register(self._ping, (candidate, member), delay=50.0)
                self._slope[member] = RecordCandidate(candidate, callback_id)

                if len(self._slope) > self._slope_length:
                    smallest_member = member
                    smallest_score = book.score

                    for member in self._slope.iterkeys():
                        candidate_book = self.get_book(member)
                        if candidate_book.score < smallest_score:
                            smallest_member = member
                            smallest_score = candidate_book.score

                    self.remove_from_slope(smallest_member)

                return True
        return False

    def remove_from_slope(self, member):
        try:
            record_candidate = self._slope.pop(member)
        except KeyError:
            pass
        else:
            self._dispersy.callback.unregister(record_candidate.callback_id)

    def _ping(self, candidate, member):
        meta = self._meta_messages[u"ping"]
        while True:
            cache = self._request_cache.add(PingCache(self, candidate, member))
            ping = meta.impl(distribution=(self._global_time,), destination=(candidate,), payload=(cache.number, self._my_member))
            self._dispersy.store_update_forward([ping], False, False, True)

            yield 50.0

    def check_ping(self, messages):
        return messages

    def on_ping(self, messages):
        cycle = int(time() / CYCLE_SIZE)
        for message in messages:
            book = self.get_book(message.payload.member)
            if book.cycle < cycle:
                book.cycle = cycle
                book.effort.set(cycle * CYCLE_SIZE)

        meta = self._meta_messages[u"pong"]
        responses = [meta.impl(distribution=(self._global_time,), destination=(ping.candidate,), payload=(ping.payload.identifier, self._my_member)) for ping in messages]
        self._dispersy.store_update_forward(responses, False, False, True)

    def check_pong(self, messages):
        for message in messages:
            if not self._request_cache.has(u"ping", message.payload.identifier):
                yield DropMessage(message, "invalid response identifier")
                continue

            yield message

    def on_pong(self, messages):
        cycle = int(time() / CYCLE_SIZE)
        for message in messages:
            self._request_cache.pop(u"ping", message.payload.identifier)
            book = self.get_book(message.payload.member)
            if book.cycle < cycle:
                book.cycle = cycle
                book.effort.set(cycle * CYCLE_SIZE)

    def check_barter_record(self, messages):
        # stupidly accept everything...
        return messages

    def on_barter_record(self, messages):
        def ordering(message):
            if message.authentication.members[0].database_id < message.authentication.members[1].database_id:
                return (message.packet_id,
                        message.authentication.members[0].database_id,
                        message.authentication.members[1].database_id,
                        message.distribution.global_time,
                        message.payload.cycle,
                        buffer(message.payload.effort.bytes),
                        message.payload.upload_first_to_second,
                        message.payload.upload_second_to_first,
                        # the following debug values are all according to first_member
                        int(message.payload.first_timestamp),
                        message.payload.first_upload,
                        message.payload.first_download,
                        message.payload.first_total_up,
                        message.payload.first_total_down,
                        message.payload.first_associated_up,
                        message.payload.first_associated_down,
                        # the following debug values are all according to second_member
                        int(message.payload.second_timestamp),
                        message.payload.second_upload,
                        message.payload.second_download,
                        message.payload.second_total_up,
                        message.payload.second_total_down,
                        message.payload.second_associated_up,
                        message.payload.second_associated_down)

            else:
                return (message.packet_id,
                        message.authentication.members[1].database_id,
                        message.authentication.members[0].database_id,
                        message.distribution.global_time,
                        message.payload.cycle,
                        buffer(message.payload.effort.bytes),
                        message.payload.upload_second_to_first,
                        message.payload.upload_first_to_second,
                        # the following debug values are all according to second_member
                        int(message.payload.second_timestamp),
                        message.payload.second_upload,
                        message.payload.second_download,
                        message.payload.second_total_up,
                        message.payload.second_total_down,
                        message.payload.second_associated_up,
                        message.payload.second_associated_down,
                        # the following debug values are all according to first_member
                        int(message.payload.first_timestamp),
                        message.payload.first_upload,
                        message.payload.first_download,
                        message.payload.first_total_up,
                        message.payload.first_total_down,
                        message.payload.first_associated_up,
                        message.payload.first_associated_down)

        logger.debug("storing %d barter records", len(messages))
        self._database.executemany(u"INSERT OR REPLACE INTO record VALUES (?, ?, ?, ?, ?, ?, ? ,?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                   (ordering(message) for message in messages))

    def check_member_request(self, messages):
        # stupidly accept everything...
        return messages

    def on_member_request(self, messages):
        meta = self._meta_messages[u"member-response"]
        responses = [meta.impl(authentication=(self._my_member,),
                               distribution=(self._global_time,),
                               destination=(request.candidate,),
                               payload=(request.payload.identifier,))
                     for request
                     in messages]
        self._dispersy.store_update_forward(responses, False, False, True)

    def check_member_response(self, messages):
        # stupidly accept everything...
        # Niels: this should at least check if we have a member-request associated with this identifier
        return messages

    def on_member_response(self, messages):
        for message in messages:
            cache = self._request_cache.pop(u"member-request", message.payload.identifier)
            cache.func(message)

########NEW FILE########
__FILENAME__ = conversion
from struct import pack, unpack_from

from .efforthistory import EffortHistory, CYCLE_SIZE

from Tribler.dispersy.member import Member
from Tribler.dispersy.conversion import BinaryConversion
from Tribler.dispersy.message import DropPacket


class BarterConversion(BinaryConversion):

    def __init__(self, community):
        super(BarterConversion, self).__init__(community, "\x02")
        self.define_meta_message(chr(1), community.get_meta_message(u"barter-record"), self._encode_barter_record, self._decode_barter_record)
        self.define_meta_message(chr(2), community.get_meta_message(u"ping"), self._encode_ping_pong, self._decode_ping_pong)
        self.define_meta_message(chr(3), community.get_meta_message(u"pong"), self._encode_ping_pong, self._decode_ping_pong)
        self.define_meta_message(chr(4), community.get_meta_message(u"member-request"), self._encode_identifier, self._decode_identifier)
        self.define_meta_message(chr(5), community.get_meta_message(u"member-response"), self._encode_identifier, self._decode_identifier)

    def _encode_barter_record(self, message):
        payload = message.payload
        bytes_ = payload.effort.bytes

        return (pack(">LQQB",
                     long(payload.cycle),
                     long(payload.upload_first_to_second),
                     long(payload.upload_second_to_first),
                     len(bytes_)),
                bytes_,
                # the following parameters are used for debugging only
                pack(">LQQQQQQLQQQQQQ",
                     long(payload.first_timestamp),
                     long(payload.first_upload),
                     long(payload.first_download),
                     long(payload.first_total_up),
                     long(payload.first_total_down),
                     long(payload.first_associated_up),
                     long(payload.first_associated_down),
                     long(payload.second_timestamp),
                     long(payload.second_upload),
                     long(payload.second_download),
                     long(payload.second_total_up),
                     long(payload.second_total_down),
                     long(payload.second_associated_up),
                     long(payload.second_associated_down)))

    def _decode_barter_record(self, placeholder, offset, data):
        if len(data) < offset + 21:
            raise DropPacket("Insufficient packet size (_decode_barter_record)")

        cycle, upload_first_to_second, upload_second_to_first, length = unpack_from(">LQQB", data, offset)
        offset += 21

        if len(data) < offset + length:
            raise DropPacket("Insufficient packet size (_decode_barter_record)")
        effort = EffortHistory(data[offset:offset + length], cycle * CYCLE_SIZE)
        offset += length

        # the following parameters are used for debugging only
        if len(data) < offset + 104:
            raise DropPacket("Insufficient packet size (_decode_barter_record)")
        (first_timestamp,
         first_upload,
         first_download,
         first_total_up,
         first_total_down,
         first_associated_up,
         first_associated_down,
         second_timestamp,
         second_upload,
         second_download,
         second_total_up,
         second_total_down,
         second_associated_up,
         second_associated_down) = unpack_from(">LQQQQQQLQQQQQQ", data, offset)
        offset += 104

        return offset, placeholder.meta.payload.implement(cycle,
                                                          effort,
                                                          upload_first_to_second,
                                                          upload_second_to_first,
                                                          # the following parameters are used for debugging only
                                                          float(first_timestamp),
                                                          first_upload,
                                                          first_download,
                                                          first_total_up,
                                                          first_total_down,
                                                          first_associated_up,
                                                          first_associated_down,
                                                          float(second_timestamp),
                                                          second_upload,
                                                          second_download,
                                                          second_total_up,
                                                          second_total_down,
                                                          second_associated_up,
                                                          second_associated_down)

    def _encode_ping_pong(self, message):
        payload = message.payload
        return self._struct_BH.pack(len(payload.member.public_key), payload.identifier), payload.member.public_key

    def _decode_ping_pong(self, placeholder, offset, data):
        if len(data) < offset + 3:
            raise DropPacket("Insufficient packet size (_decode_ping_pong)")

        key_length, identifier = self._struct_BH.unpack_from(data, offset)
        offset += 3

        if len(data) < offset + key_length:
            raise DropPacket("Insufficient packet size (_decode_ping_pong)")
        try:
            member = Member(data[offset:offset + key_length])
        except:
            raise DropPacket("Invalid public key (_decode_ping_pong)")
        offset += key_length

        return offset, placeholder.meta.payload.Implementation(placeholder.meta.payload, identifier, member)

    def _encode_identifier(self, message):
        return self._struct_Q.pack(message.payload.identifier),

    def _decode_identifier(self, placeholder, offset, data):
        if len(data) < offset + 8:
            raise DropPacket("Insufficient packet size (_decode_identifier)")

        identifier, = self._struct_Q.unpack_from(data, offset)
        offset += 8

        return offset, placeholder.meta.payload.Implementation(placeholder.meta.payload, identifier)

########NEW FILE########
__FILENAME__ = database
from os import path

from Tribler.dispersy.database import Database

LATEST_VERSION = 1

schema = u"""
-- record contains all received and non-pruned barter records.  this information is, most likely
-- also available at other peers, since the barter records are gossiped around.
CREATE TABLE record(
 sync INTEGER,                          -- REFERENCES sync(id)
 first_member INTEGER,                  -- REFERENCES user(id)
 second_member INTEGER,                 -- REFERENCES user(id)
 global_time INTEGER,                   -- global time when this record was made
 cycle INTEGER,                         -- the cycle when this record was made
 effort BLOB,                           -- raw bytes where each bit represents a cycle, LSB corresponds with the cycle when this record was made
 upload_first_to_second INTEGER,        -- in cooked bytes
 upload_second_to_first INTEGER,        -- in cooked bytes

 -- the following debug values are all according to first_member
 first_timestamp INTEGER,               -- DEBUG timestamp when this record was made
 first_upload INTEGER,                  -- DEBUG bytes uploaded from first to second
 first_download INTEGER,                -- DEBUG bytes uploaded from second to first
 first_total_up INTEGER,                -- DEBUG bytes uploaded from first to others (any transfer)
 first_total_down INTEGER,              -- DEBUG bytes uploaded from others to first (any transfer)
 first_associated_up INTEGER,           -- DEBUG bytes uploaded from first to others (only transfers resulting in records)
 first_associated_down INTEGER,         -- DEBUG bytes uploaded from others to first (only transfers resulting in records)

 -- the following debug values are all according to second_member
 second_timestamp INTEGER,              -- DEBUG timestamp when this record was made (according to second)
 second_upload INTEGER,                 -- DEBUG bytes uploaded from second to first
 second_download INTEGER,               -- DEBUG bytes uploaded from first to second
 second_total_up INTEGER,               -- DEBUG bytes uploaded from second to others (any transfer)
 second_total_down INTEGER,             -- DEBUG bytes uploaded from others to second (any transfer)
 second_associated_up INTEGER,          -- DEBUG bytes uploaded from second to others (only transfers resulting in records)
 second_associated_down INTEGER,        -- DEBUG bytes uploaded from others to second (only transfers resulting in records)

 PRIMARY KEY (sync),
 UNIQUE (first_member, second_member));

-- book contains all local observations.  when criteria match, these observations are used to create
-- barter records.  until that time we should remember as much of our interactions with others as
-- possible.
CREATE TABLE book(
 member INTEGER,                        -- REFERENCES user(id)
 cycle INTEGER,                         -- the cycle when the last book update was made
 effort BLOB,                           -- raw bytes where each bit represents a cycle, LSB corresponds with the cycle when this record was made
 upload INTEGER,                        -- bytes uploaded from member to me
 download INTEGER,                      -- bytes uploaded from me to member
 PRIMARY KEY (member));

CREATE TABLE option(key TEXT PRIMARY KEY, value BLOB);
INSERT INTO option(key, value) VALUES('database_version', '""" + str(LATEST_VERSION) + """');
"""

cleanup = u"""
DELETE FROM record;
DELETE FROM book;
"""


class BarterDatabase(Database):
    if __debug__:
        __doc__ = schema

    def __init__(self, dispersy):
        self._dispersy = dispersy
        super(BarterDatabase, self).__init__(path.join(dispersy.working_directory, u"sqlite", u"barter.db"))

    def open(self):
        self._dispersy.database.attach_commit_callback(self.commit)
        return super(BarterDatabase, self).open()

    def close(self, commit=True):
        self._dispersy.database.detach_commit_callback(self.commit)
        return super(BarterDatabase, self).close(commit)

    def cleanup(self):
        self.executescript(cleanup)

    def check_database(self, database_version):
        assert isinstance(database_version, unicode)
        assert database_version.isdigit()
        assert int(database_version) >= 0
        database_version = int(database_version)

        # setup new database with current database_version
        if database_version < 1:
            self.executescript(schema)
            self.commit()

        else:
            # upgrade to version 2
            if database_version < 2:
                # there is no version 2 yet...
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2)
                # self.executescript(u"""UPDATE option SET value = '2' WHERE key = 'database_version';""")
                # self.commit()
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2, " (done)")
                pass

        return LATEST_VERSION

########NEW FILE########
__FILENAME__ = efforthistory
import logging
logger = logging.getLogger(__name__)

from binascii import hexlify, unhexlify

# a cycle is defined as a N second period
CYCLE_SIZE = 60.0 * 30

# the number of bits used per history
BIT_COUNT = 64 * 8
assert BIT_COUNT % 8 == 0


class EffortHistory(object):

    """
    The EffortHistory constructor takes parameters that are interpreted differently, depending on
    their type.  The following type combination, and their interpretations, are possible:

    - EffortHistory(float:origin)

      Will create an empty history.

    - EffortHistory(long:bits, float:origin)

      Will create a history from existing bits.

    - EffortHistory(str:bytes, float:origin)

      Will create a history from existing bytes.
    """

    @classmethod
    def _overload_constructor_arguments(cls, args):
        # matches: EffortHistory(float:origin)
        if len(args) == 1 and isinstance(args[0], float):
            long_ = 0
            origin = args[0]

        # matches: EffortHistory(long:bits, float:origin)
        elif len(args) == 2 and isinstance(args[0], long) and isinstance(args[1], float):
            long_ = args[0]
            origin = args[1]

        # matches: EffortHistory(str:bytes, float:origin)
        elif len(args) == 2 and isinstance(args[0], str) and isinstance(args[1], float):
            assert len(args[0]) > 0, len(args[0])
            long_ = long(hexlify(args[0][::-1]), 16)
            origin = args[1]

        else:
            raise RuntimeError("Unknown combination of argument types %s" % str([type(arg) for arg in args]))

        return long_, origin

    def __init__(self, *args):
        # get constructor arguments
        self._long, self._origin = self._overload_constructor_arguments(args)
        assert isinstance(self._long, (int, long)), type(self._long)
        assert isinstance(self._origin, float), type(self._origin)

    @property
    def bits(self):
        "Size in bits."
        return BIT_COUNT

    @property
    def origin(self):
        "Time of most recent update, starting point of least significant bit."
        return self._origin

    @property
    def cycle(self):
        "Cycle of the most recent update, starting point of least significant bit."
        return long(self._origin / CYCLE_SIZE)

    @property
    def long(self):
        "Bits as a long integer."
        return self._long

    @property
    def bytes(self):
        "Bits as a byte string."
        hex_ = "%x" % self._long
        return (unhexlify(hex_)[::-1]) if len(hex_) % 2 == 0 else (unhexlify("0" + hex_)[::-1])

    def set(self, origin):
        """
        """
        assert isinstance(origin, float)
        difference = int(origin / CYCLE_SIZE) - int(self._origin / CYCLE_SIZE)
        logger.debug("difference %d (%d seconds)", difference, origin - self._origin)
        if origin < self._origin:
            logger.warning("currently it is not possible to set bits in the past")

        if difference > 0:
            if __debug__:
                BEFORE = self._long

            self._origin = origin

            # shift
            self._long <<= difference

            # remove now obsolete bits
            self._long &= (2 ** BIT_COUNT - 1)

            # set last bit ACTIVE
            self._long |= 1

            if __debug__:
                AFTER = self._long
                logger.debug("%s -> %s (bits: %d)", bin(BEFORE), bin(AFTER), BIT_COUNT)

            return True

        else:
            if self._long & 1:
                return False
            else:
                self._long |= 1
                return True

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload


class BarterRecordPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self,
                     meta,
                     cycle,
                     effort,
                     upload_first_to_second,
                     upload_second_to_first,
                     # the following debug values are all according to first_member
                     first_timestamp,
                     first_upload,
                     first_download,
                     first_total_up,
                     first_total_down,
                     first_associated_up,
                     first_associated_down,
                     # the following debug values are all according to second_member
                     second_timestamp,
                     second_upload,
                     second_download,
                     second_total_up,
                     second_total_down,
                     second_associated_up,
                     second_associated_down):

            if __debug__:
                from .efforthistory import EffortHistory
            assert isinstance(cycle, (int, long))
            assert isinstance(effort, EffortHistory)
            assert isinstance(upload_first_to_second, (int, long))
            assert isinstance(upload_second_to_first, (int, long))
            assert isinstance(first_timestamp, float)
            assert isinstance(first_upload, (int, long))
            assert isinstance(first_download, (int, long))
            assert isinstance(first_total_up, (int, long))
            assert isinstance(first_total_down, (int, long))
            assert isinstance(first_associated_up, (int, long))
            assert isinstance(first_associated_down, (int, long))
            assert isinstance(second_timestamp, float)
            assert isinstance(second_upload, (int, long))
            assert isinstance(second_download, (int, long))
            assert isinstance(second_total_up, (int, long))
            assert isinstance(second_total_down, (int, long))
            assert isinstance(second_associated_up, (int, long))
            assert isinstance(second_associated_down, (int, long))

            super(BarterRecordPayload.Implementation, self).__init__(meta)
            self.cycle = cycle
            self.effort = effort
            self.upload_first_to_second = upload_first_to_second
            self.upload_second_to_first = upload_second_to_first
            # the following debug values are all according to first_member
            self.first_timestamp = first_timestamp
            self.first_upload = first_upload
            self.first_download = first_download
            self.first_total_up = first_total_up
            self.first_total_down = first_total_down
            self.first_associated_up = first_associated_up
            self.first_associated_down = first_associated_down
            # the following debug values are all according to second_member
            self.second_timestamp = second_timestamp
            self.second_upload = second_upload
            self.second_download = second_download
            self.second_total_up = second_total_up
            self.second_total_down = second_total_down
            self.second_associated_up = second_associated_up
            self.second_associated_down = second_associated_down


class PingPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, member):
            super(PingPayload.Implementation, self).__init__(meta)
            self.identifier = identifier
            self.member = member


class PongPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, member):
            super(PongPayload.Implementation, self).__init__(meta)
            self.identifier = identifier
            self.member = member


class MemberRequestPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier):
            super(MemberRequestPayload.Implementation, self).__init__(meta)
            self.identifier = identifier


class MemberResponsePayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier):
            super(MemberResponsePayload.Implementation, self).__init__(meta)
            self.identifier = identifier

########NEW FILE########
__FILENAME__ = script
from .community import BarterCommunity


class DummySwiftProcess(object):

    def set_subscribe_channel_close(self, *args, **kargs):
        pass


class BarterCrawler(object):

    def __init__(self, dispersy, my_member):
        masters = BarterCommunity.get_master_members(dispersy)
        assert len(masters) == 1
        self._community = BarterCommunity(dispersy, masters[0], my_member, DummySwiftProcess())

    def next_testcase(self):
        # TODO we will remove next_testcase once we cleanup the script starting
        pass

########NEW FILE########
__FILENAME__ = community
import binascii
import json
import logging
from struct import pack
from time import time
from traceback import print_stack

from twisted.python.threadable import isInIOThread

from Tribler.Core.CacheDB.sqlitecachedb import str2bin
from Tribler.community.channel.payload import ModerationPayload
from Tribler.dispersy.authentication import MemberAuthentication, NoAuthentication
from Tribler.dispersy.candidate import CANDIDATE_WALK_LIFETIME
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CandidateDestination, CommunityDestination
from Tribler.dispersy.distribution import FullSyncDistribution, DirectDistribution
from Tribler.dispersy.message import BatchConfiguration, Message, DropMessage, DelayMessageByProof
from Tribler.dispersy.resolution import LinearResolution, PublicResolution, DynamicResolution
from Tribler.dispersy.util import call_on_reactor_thread
from conversion import ChannelConversion
from message import DelayMessageReqChannelMessage
from payload import (ChannelPayload, TorrentPayload, PlaylistPayload, CommentPayload, ModificationPayload,
                     PlaylistTorrentPayload, MissingChannelPayload, MarkTorrentPayload)


if __debug__:
    from Tribler.dispersy.tool.lencoder import log


logger = logging.getLogger(__name__)

def warnDispersyThread(func):
    def invoke_func(*args, **kwargs):
        if not isInIOThread():
            logger.critical("This method MUST be called on the DispersyThread")
            print_stack()
            return None
        else:
            return func(*args, **kwargs)

    invoke_func.__name__ = func.__name__
    return invoke_func

class ChannelCommunity(Community):

    """
    Each user owns zero or more ChannelCommunities that other can join and use to discuss.
    """
    def initialize(self, integrate_with_tribler=True):
        self._channel_id = None
        self.integrate_with_tribler = integrate_with_tribler

        super(ChannelCommunity, self).initialize()
        self._logger = logging.getLogger(self.__class__.__name__)

        if self.integrate_with_tribler:
            from Tribler.Core.CacheDB.SqliteCacheDBHandler import ChannelCastDBHandler, PeerDBHandler

            # tribler channelcast database
            self._peer_db = PeerDBHandler.getInstance()
            self._channelcast_db = ChannelCastDBHandler.getInstance()

            # tribler channel_id
            self._channel_id = self._channelcast_db._db.fetchone(u"SELECT id FROM Channels WHERE dispersy_cid = ? and (peer_id <> -1 or peer_id ISNULL)", (buffer(self._master_member.mid),))

            # modification_types
            self._modification_types = self._channelcast_db.modification_types

        else:
            try:
                message = self._get_latest_channel_message()
                if message:
                    self._channel_id = self.cid
            except:
                pass

            from Tribler.community.allchannel.community import AllChannelCommunity
            for community in self.dispersy.get_communities():
                if isinstance(community, AllChannelCommunity):
                    self._channelcast_db = community._channelcast_db

    def initiate_meta_messages(self):
        batch_delay = 3.0

        # 30/11/11 Boudewijn: we frequently see dropped packets when joining a channel.  this can be
        # caused when a sync results in both torrent and modification messages.  when the
        # modification messages are processed first they will all cause the associated torrent
        # message to be requested, when these are received they are duplicates.  solution: ensure
        # that the modification messages are processed after messages that they can request.  normal
        # priority is 128, therefore, modification_priority is one less
        modification_priority = 128 - 1

        return super(ChannelCommunity, self).initiate_meta_messages() + [
            Message(self, u"channel",
                    MemberAuthentication(),
                    LinearResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=130),
                    CommunityDestination(node_count=10),
                    ChannelPayload(),
                    self._disp_check_channel,
                    self._disp_on_channel),
            Message(self, u"torrent",
                    MemberAuthentication(),
                    DynamicResolution(LinearResolution(), PublicResolution()),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=129),
                    CommunityDestination(node_count=10),
                    TorrentPayload(),
                    self._disp_check_torrent,
                    self._disp_on_torrent,
                    self._disp_undo_torrent,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"playlist",
                    MemberAuthentication(),
                    LinearResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10),
                    PlaylistPayload(),
                    self._disp_check_playlist,
                    self._disp_on_playlist,
                    self._disp_undo_playlist,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"comment",
                    MemberAuthentication(),
                    DynamicResolution(LinearResolution(), PublicResolution()),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10),
                    CommentPayload(),
                    self._disp_check_comment,
                    self._disp_on_comment,
                    self._disp_undo_comment,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"modification",
                    MemberAuthentication(),
                    DynamicResolution(LinearResolution(), PublicResolution()),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=modification_priority),
                    CommunityDestination(node_count=10),
                    ModificationPayload(),
                    self._disp_check_modification,
                    self._disp_on_moderation,
                    self._disp_undo_modification,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"playlist_torrent",
                    MemberAuthentication(),
                    DynamicResolution(LinearResolution(), PublicResolution()),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10),
                    PlaylistTorrentPayload(),
                    self._disp_check_playlist_torrent,
                    self._disp_on_playlist_torrent,
                    self._disp_undo_playlist_torrent,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"moderation",
                    MemberAuthentication(),
                    DynamicResolution(LinearResolution(), PublicResolution()),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10),
                    ModerationPayload(),
                    self._disp_check_moderation,
                    self._disp_on_moderation,
                    self._disp_undo_moderation,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"mark_torrent",
                    MemberAuthentication(),
                    DynamicResolution(LinearResolution(), PublicResolution()),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10),
                    MarkTorrentPayload(),
                    self._disp_check_mark_torrent,
                    self._disp_on_mark_torrent,
                    self._disp_undo_mark_torrent,
                    batch=BatchConfiguration(max_window=batch_delay)),
            Message(self, u"missing-channel",
                    NoAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    MissingChannelPayload(),
                    self._disp_check_missing_channel,
                    self._disp_on_missing_channel),
        ]

    @property
    def dispersy_sync_response_limit(self):
        return 25 * 1024

    def initiate_conversions(self):
        return [DefaultConversion(self), ChannelConversion(self)]

    CHANNEL_CLOSED, CHANNEL_SEMI_OPEN, CHANNEL_OPEN, CHANNEL_MODERATOR = range(4)
    CHANNEL_ALLOWED_MESSAGES = ([], [u"comment", u"mark_torrent"], [u"torrent", u"comment", u"modification", u"playlist_torrent", u"moderation", u"mark_torrent"], [u"channel", u"torrent", u"playlist", u"comment", u"modification", u"playlist_torrent", u"moderation", u"mark_torrent"])

    def get_channel_mode(self):
        public = set()
        permitted = set()

        for meta in self.get_meta_messages():
            if isinstance(meta.resolution, DynamicResolution):
                policy, _ = self._timeline.get_resolution_policy(meta, self.global_time + 1)
            else:
                policy = meta.resolution

            if isinstance(policy, PublicResolution):
                public.add(meta.name)
            else:
                allowed, _ = self._timeline.allowed(meta)
                if allowed:
                    permitted.add(meta.name)

        def isCommunityType(state, checkPermitted=False):
            for type in ChannelCommunity.CHANNEL_ALLOWED_MESSAGES[state]:
                if type not in public:
                    if checkPermitted and type in permitted:
                        continue
                    return False
            return True

        isModerator = isCommunityType(ChannelCommunity.CHANNEL_MODERATOR, True)
        if isCommunityType(ChannelCommunity.CHANNEL_OPEN):
            return ChannelCommunity.CHANNEL_OPEN, isModerator

        if isCommunityType(ChannelCommunity.CHANNEL_SEMI_OPEN):
            return ChannelCommunity.CHANNEL_SEMI_OPEN, isModerator

        return ChannelCommunity.CHANNEL_CLOSED, isModerator

    def set_channel_mode(self, mode):
        curmode, isModerator = self.get_channel_mode()
        if isModerator and mode != curmode:
            public_messages = ChannelCommunity.CHANNEL_ALLOWED_MESSAGES[mode]

            new_policies = []
            for meta in self.get_meta_messages():
                if isinstance(meta.resolution, DynamicResolution):
                    if meta.name in public_messages:
                        new_policies.append((meta, meta.resolution.policies[1]))
                    else:
                        new_policies.append((meta, meta.resolution.policies[0]))

            self.create_dynamic_settings(new_policies)

    def create_channel(self, name, description, store=True, update=True, forward=True):
        self._disp_create_channel(name, description, store, update, forward)

    @call_on_reactor_thread
    def _disp_create_channel(self, name, description, store=True, update=True, forward=True):
        name = unicode(name[:255])
        description = unicode(description[:1023])

        meta = self.get_meta_message(u"channel")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(name, description))
        self._dispersy.store_update_forward([message], store, update, forward)
        return message

    def _disp_check_channel(self, messages):
        for message in messages:
            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            yield message

    def _disp_on_channel(self, messages):
        if self.integrate_with_tribler:
            for message in messages:
                assert self._cid == self._master_member.mid
                logger.debug("%s %s", message.candidate, self._cid.encode("HEX"))

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)
                self._channel_id = self._channelcast_db.on_channel_from_dispersy(self._master_member.mid, peer_id, message.payload.name, message.payload.description)
        else:
            for message in messages:
                self._channel_id = self._master_member.mid
                authentication_member = message.authentication.member

                self._channelcast_db.setChannelId(self._channel_id, authentication_member == self._my_member)

    def _disp_create_torrent_from_torrentdef(self, torrentdef, timestamp, store=True, update=True, forward=True):
        files = torrentdef.get_files_as_unicode_with_length()
        return self._disp_create_torrent(torrentdef.get_infohash(), timestamp, torrentdef.get_name_as_unicode(), tuple(files), torrentdef.get_trackers_as_single_tuple(), store, update, forward)

    def _disp_create_torrent(self, infohash, timestamp, name, files, trackers, store=True, update=True, forward=True):
        meta = self.get_meta_message(u"torrent")

        global_time = self.claim_global_time()
        current_policy, _ = self._timeline.get_resolution_policy(meta, global_time)
        message = meta.impl(authentication=(self._my_member,),
                            resolution=(current_policy.implement(),),
                            distribution=(global_time,),
                            payload=(infohash, timestamp, name, files, trackers))
        self._dispersy.store_update_forward([message], store, update, forward)
        return message

    def _disp_create_torrents(self, torrentlist, store=True, update=True, forward=True):
        messages = []

        meta = self.get_meta_message(u"torrent")
        current_policy, _ = self._timeline.get_resolution_policy(meta, self.global_time + 1)
        for infohash, timestamp, name, files, trackers in torrentlist:
            message = meta.impl(authentication=(self._my_member,),
                                resolution=(current_policy.implement(),),
                                distribution=(self.claim_global_time(),),
                                payload=(infohash, timestamp, name, files, trackers))

            messages.append(message)

        self._dispersy.store_update_forward(messages, store, update, forward)
        return messages

    def _disp_check_torrent(self, messages):
        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue
            yield message

    def _disp_on_torrent(self, messages):
        if self.integrate_with_tribler:
            torrentlist = []
            for message in messages:
                dispersy_id = message.packet_id
                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                torrentlist.append((self._channel_id, dispersy_id, peer_id, message.payload.infohash, message.payload.timestamp, message.payload.name, message.payload.files, message.payload.trackers))

                # TODO: schedule a request for roothashes
            self._channelcast_db.on_torrents_from_dispersy(torrentlist)
        else:
            for message in messages:
                self._channelcast_db.newTorrent(message)

    def _disp_undo_torrent(self, descriptors, redo=False):
        for _, _, packet in descriptors:
            dispersy_id = packet.packet_id
            self._channelcast_db.on_remove_torrent_from_dispersy(self._channel_id, dispersy_id, redo)

    def remove_torrents(self, dispersy_ids):
        for dispersy_id in dispersy_ids:
            message = self._dispersy.load_message_by_packetid(dispersy_id)
            if message:
                if not message.undone:
                    self._dispersy.create_undo(self, message)

                else:  # hmm signal gui that this message has been removed already
                    self._disp_undo_torrent([(None, None, message)])

    def remove_playlists(self, dispersy_ids):
        for dispersy_id in dispersy_ids:
            message = self._dispersy.load_message_by_packetid(dispersy_id)
            if message:
                if not message.undone:
                    self._dispersy.create_undo(self, message)

                else:  # hmm signal gui that this message has been removed already
                    self._disp_undo_playlist([(None, None, message)])

    # create, check or receive playlists
    @call_on_reactor_thread
    def create_playlist(self, name, description, infohashes=[], store=True, update=True, forward=True):
        message = self._disp_create_playlist(name, description)
        if len(infohashes) > 0:
            self._disp_create_playlist_torrents(message, infohashes, store, update, forward)

    @call_on_reactor_thread
    def _disp_create_playlist(self, name, description, store=True, update=True, forward=True):
        name = unicode(name[:255])
        description = unicode(description[:1023])

        meta = self.get_meta_message(u"playlist")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(name, description))
        self._dispersy.store_update_forward([message], store, update, forward)
        return message

    def _disp_check_playlist(self, messages):
        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue
            yield message

    def _disp_on_playlist(self, messages):
        if self.integrate_with_tribler:
            for message in messages:
                dispersy_id = message.packet_id
                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                self._channelcast_db.on_playlist_from_dispersy(self._channel_id, dispersy_id, peer_id, message.payload.name, message.payload.description)

    def _disp_undo_playlist(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            for _, _, packet in descriptors:
                dispersy_id = packet.packet_id
                self._channelcast_db.on_remove_playlist_from_dispersy(self._channel_id, dispersy_id, redo)

    # create, check or receive comments
    @call_on_reactor_thread
    def create_comment(self, text, timestamp, reply_to, reply_after, playlist_id, infohash, store=True, update=True, forward=True):
        reply_to_message = reply_to
        reply_after_message = reply_after
        playlist_message = playlist_id

        if reply_to:
            reply_to_message = self._dispersy.load_message_by_packetid(reply_to)
        if reply_after:
            reply_after_message = self._dispersy.load_message_by_packetid(reply_after)
        if playlist_id:
            playlist_message = self._get_message_from_playlist_id(playlist_id)
        self._disp_create_comment(text, timestamp, reply_to_message, reply_after_message, playlist_message, infohash, store, update, forward)

    @call_on_reactor_thread
    def _disp_create_comment(self, text, timestamp, reply_to_message, reply_after_message, playlist_message, infohash, store=True, update=True, forward=True):
        reply_to_mid = None
        reply_to_global_time = None
        if reply_to_message:
            message = reply_to_message.load_message()
            reply_to_mid = message.authentication.member.mid
            reply_to_global_time = message.distribution.global_time

        reply_after_mid = None
        reply_after_global_time = None
        if reply_after_message:
            message = reply_after_message.load_message()
            reply_after_mid = message.authentication.member.mid
            reply_after_global_time = message.distribution.global_time

        text = unicode(text[:1023])

        meta = self.get_meta_message(u"comment")
        global_time = self.claim_global_time()
        current_policy, _ = self._timeline.get_resolution_policy(meta, global_time)
        message = meta.impl(authentication=(self._my_member,),
                            resolution=(current_policy.implement(),),
                            distribution=(global_time,),
                            payload=(text, timestamp, reply_to_mid, reply_to_global_time, reply_after_mid, reply_after_global_time, playlist_message, infohash))
        self._dispersy.store_update_forward([message], store, update, forward)
        return message

    def _disp_check_comment(self, messages):
        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue
            yield message

    def _disp_on_comment(self, messages):
        if self.integrate_with_tribler:

            for message in messages:
                dispersy_id = message.packet_id

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                mid_global_time = pack('!20sQ', message.authentication.member.mid, message.distribution.global_time)

                reply_to_id = None
                if message.payload.reply_to_mid:
                    try:
                        reply_to_id = self._get_packet_id(message.payload.reply_to_global_time, message.payload.reply_to_mid)
                    except:
                        reply_to_id = pack('!20sQ', message.payload.reply_to_mid, message.payload.reply_to_global_time)

                reply_after_id = None
                if message.payload.reply_after_mid:
                    try:
                        reply_after_id = self._get_packet_id(message.payload.reply_after_global_time, message.payload.reply_after_mid)
                    except:
                        reply_after_id = pack('!20sQ', message.payload.reply_after_mid, message.payload.reply_after_global_time)

                playlist_dispersy_id = None
                if message.payload.playlist_packet:
                    playlist_dispersy_id = message.payload.playlist_packet.packet_id

                self._channelcast_db.on_comment_from_dispersy(self._channel_id, dispersy_id, mid_global_time, peer_id, message.payload.text, message.payload.timestamp, reply_to_id, reply_after_id, playlist_dispersy_id, message.payload.infohash)

    def _disp_undo_comment(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            for _, _, packet in descriptors:
                dispersy_id = packet.packet_id

                message = packet.load_message()
                infohash = message.payload.infohash
                self._channelcast_db.on_remove_comment_from_dispersy(self._channel_id, dispersy_id, infohash, redo)

    def remove_comment(self, dispersy_id):
        message = self._dispersy.load_message_by_packetid(self, dispersy_id)
        if message:
            self._dispersy.create_undo(self, message)

    # modify channel, playlist or torrent
    @call_on_reactor_thread
    def modifyChannel(self, modifications, store=True, update=True, forward=True):
        latest_modifications = {}
        for type, value in modifications.iteritems():
            type = unicode(type)
            type_id = self._modification_types[type]
            latest_modifications[type] = self._get_latest_modification_from_channel_id(type_id)
        modification_on_message = self._get_latest_channel_message()

        for type, value in modifications.iteritems():
            type = unicode(type)
            timestamp = long(time())
            self._disp_create_modification(type, value, timestamp, modification_on_message, latest_modifications[type], store, update, forward)

    @call_on_reactor_thread
    def modifyPlaylist(self, playlist_id, modifications, store=True, update=True, forward=True):
        latest_modifications = {}
        for type, value in modifications.iteritems():
            type = unicode(type)
            type_id = self._modification_types[type]
            latest_modifications[type] = self._get_latest_modification_from_playlist_id(playlist_id, type_id)

        modification_on_message = self._get_message_from_playlist_id(playlist_id)
        for type, value in modifications.iteritems():
            type = unicode(type)
            timestamp = long(time())
            self._disp_create_modification(type, value, timestamp, modification_on_message, latest_modifications[type], store, update, forward)

    @call_on_reactor_thread
    def modifyTorrent(self, channeltorrent_id, modifications, store=True, update=True, forward=True):
        latest_modifications = {}
        for type, value in modifications.iteritems():
            type = unicode(type)
            type_id = self._modification_types[type]
            try:
                latest_modifications[type] = self._get_latest_modification_from_torrent_id(channeltorrent_id, type_id)
            except:
                logger.error(exc_info=True)

        modification_on_message = self._get_message_from_torrent_id(channeltorrent_id)
        for type, value in modifications.iteritems():
            timestamp = long(time())
            self._disp_create_modification(type, value, timestamp, modification_on_message, latest_modifications[type], store, update, forward)

    def _disp_create_modification(self, modification_type, modifcation_value, timestamp, modification_on, latest_modification, store=True, update=True, forward=True):
        modification_type = unicode(modification_type)
        modifcation_value = unicode(modifcation_value[:1023])

        latest_modification_mid = None
        latest_modification_global_time = None
        if latest_modification:
            message = latest_modification.load_message()
            latest_modification_mid = message.authentication.member.mid
            latest_modification_global_time = message.distribution.global_time

        meta = self.get_meta_message(u"modification")
        global_time = self.claim_global_time()
        current_policy, _ = self._timeline.get_resolution_policy(meta, global_time)
        message = meta.impl(authentication=(self._my_member,),
                            resolution=(current_policy.implement(),),
                            distribution=(global_time,),
                            payload=(modification_type, modifcation_value, timestamp, modification_on, latest_modification, latest_modification_mid, latest_modification_global_time))
        self._dispersy.store_update_forward([message], store, update, forward)
        return message

    def _disp_check_modification(self, messages):
        from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler
        from Tribler.community.search.community import SearchCommunity

        th_handler = RemoteTorrentHandler.getInstance()

        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            if message.payload.modification_on.name == u"torrent" and message.payload.modification_type == "swift-thumbnails":
                try:
                    hex_roothash = json.loads(message.payload.modification_value)[1]
                except:
                    yield DropMessage(message, "Not compatible json format")
                    continue
                else:
                    roothash = binascii.unhexlify(hex_roothash)
                    modifying_dispersy_id = message.payload.modification_on.packet_id
                    torrent_id = self._channelcast_db._db.fetchone(u"SELECT torrent_id FROM _ChannelTorrents WHERE dispersy_id = ?", (modifying_dispersy_id,))
                    infohash = self._channelcast_db._db.fetchone(u"SELECT infohash FROM Torrent WHERE torrent_id = ?", (torrent_id,))
                    if infohash:
                        infohash = str2bin(infohash)
                        logger.debug("Incoming swift-thumbnails with roothash %s from %s", hex_roothash.encode("HEX"), message.candidate.sock_addr[0])

                        if not th_handler.has_metadata("thumbs", infohash):
                            @call_on_reactor_thread
                            def callback(_, message=message):
                                self.on_messages([message])
                            logger.debug("Will try to download swift-thumbnails with roothash %s from %s", hex_roothash.encode("HEX"), message.candidate.sock_addr[0])
                            th_handler.download_metadata("thumbs", message.candidate, roothash, infohash, timeout=CANDIDATE_WALK_LIFETIME, usercallback=callback)
                            continue

            yield message

    def _disp_on_modification(self, messages):
        if self.integrate_with_tribler:
            channeltorrentDict = {}
            playlistDict = {}

            for message in messages:
                dispersy_id = message.packet_id
                message_name = message.payload.modification_on.name
                mid_global_time = "%s@%d" % (message.authentication.member.mid, message.distribution.global_time)

                modifying_dispersy_id = message.payload.modification_on.packet_id
                modification_type = message.payload.modification_type
                modification_type_id = self._modification_types[modification_type]
                modification_value = message.payload.modification_value
                timestamp = message.payload.timestamp

                if message.payload.prev_modification_packet:
                    prev_modification_id = message.payload.prev_modification_packet.packet_id
                else:
                    prev_modification_id = message.payload.prev_modification_id
                prev_modification_global_time = message.payload.prev_modification_global_time

                # load local ids from database
                if message_name == u"torrent":
                    channeltorrent_id = self._get_torrent_id_from_message(modifying_dispersy_id)
                    if not channeltorrent_id:
                        self._logger.info("CANNOT FIND channeltorrent_id %s", modifying_dispersy_id)
                    channeltorrentDict[modifying_dispersy_id] = channeltorrent_id

                elif message_name == u"playlist":
                    playlist_id = self._get_playlist_id_from_message(modifying_dispersy_id)
                    playlistDict[modifying_dispersy_id] = playlist_id

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                # always store metadata
                self._channelcast_db.on_metadata_from_dispersy(message_name, channeltorrentDict.get(modifying_dispersy_id, None), playlistDict.get(modifying_dispersy_id, None), self._channel_id, dispersy_id, peer_id, mid_global_time, modification_type_id, modification_value, timestamp, prev_modification_id, prev_modification_global_time)

            for message in messages:
                dispersy_id = message.packet_id
                message_name = message.payload.modification_on.name

                modifying_dispersy_id = message.payload.modification_on.packet_id
                modification_type = message.payload.modification_type
                modification_type_id = self._modification_types[modification_type]
                modification_value = message.payload.modification_value

                # see if this is new information, if so call on_X_from_dispersy to update local 'cached' information
                if message_name == u"torrent":
                    channeltorrent_id = channeltorrentDict[modifying_dispersy_id]

                    latest = self._get_latest_modification_from_torrent_id(channeltorrent_id, modification_type_id)
                    if not latest or latest.packet_id == dispersy_id:
                        self._channelcast_db.on_torrent_modification_from_dispersy(channeltorrent_id, modification_type, modification_value)

                elif message_name == u"playlist":
                    playlist_id = playlistDict[modifying_dispersy_id]

                    latest = self._get_latest_modification_from_playlist_id(playlist_id, modification_type_id)
                    if not latest or latest.packet_id == dispersy_id:
                        self._channelcast_db.on_playlist_modification_from_dispersy(playlist_id, modification_type, modification_value)

                elif message_name == u"channel":
                    latest = self._get_latest_modification_from_channel_id(modification_type_id)
                    if not latest or latest.packet_id == dispersy_id:
                        self._channelcast_db.on_channel_modification_from_dispersy(self._channel_id, modification_type, modification_value)

            if __debug__:
                for message in messages:
                    if message.payload.modification_on.name == u"torrent" and message.payload.modification_type == "video-info":
                        self._logger.debug("Incoming video-info with value %s", message.payload.modification_value)

    def _disp_undo_modification(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            for _, _, packet in descriptors:
                dispersy_id = packet.packet_id

                message = packet.load_message()
                message_name = message.name
                modifying_dispersy_id = message.payload.modification_on.packet_id
                modification_type = message.payload.modification_type
                modification_type_id = self._modification_types[modification_type]

                # load local ids from database
                playlist_id = channeltorrent_id = None
                if message_name == u"torrent":
                    channeltorrent_id = self._get_torrent_id_from_message(modifying_dispersy_id)

                elif message_name == u"playlist":
                    playlist_id = self._get_playlist_id_from_message(modifying_dispersy_id)
                self._channelcast_db.on_remove_metadata_from_dispersy(self._channel_id, dispersy_id, redo)

                if message_name == u"torrent":
                    latest = self._get_latest_modification_from_torrent_id(channeltorrent_id, modification_type_id)

                    if not latest or latest.packet_id == dispersy_id:
                        modification_value = latest.payload.modification_value if latest else ''
                        self._channelcast_db.on_torrent_modification_from_dispersy(channeltorrent_id, modification_type, modification_value)

                elif message_name == u"playlist":
                    latest = self._get_latest_modification_from_playlist_id(playlist_id, modification_type_id)

                    if not latest or latest.packet_id == dispersy_id:
                        modification_value = latest.payload.modification_value if latest else ''
                        self._channelcast_db.on_playlist_modification_from_dispersy(playlist_id, modification_type, modification_value)

                elif message_name == u"channel":
                    latest = self._get_latest_modification_from_channel_id(modification_type_id)

                    if not latest or latest.packet_id == dispersy_id:
                        modification_value = latest.payload.modification_value if latest else ''
                        self._channelcast_db.on_channel_modification_from_dispersy(self._channel_id, modification_type, modification_value)

    # create, check or receive playlist_torrent messages
    @call_on_reactor_thread
    def create_playlist_torrents(self, playlist_id, infohashes, store=True, update=True, forward=True):
        playlist_packet = self._get_message_from_playlist_id(playlist_id)
        self._disp_create_playlist_torrents(playlist_packet, infohashes, store, update, forward)

    def remove_playlist_torrents(self, playlist_id, dispersy_ids):
        for dispersy_id in dispersy_ids:
            message = self._dispersy.load_message_by_packetid(self, dispersy_id)
            if message:
                self._dispersy.create_undo(self, message)

    @call_on_reactor_thread
    def _disp_create_playlist_torrents(self, playlist_packet, infohashes, store=True, update=True, forward=True):
        meta = self.get_meta_message(u"playlist_torrent")
        current_policy, _ = self._timeline.get_resolution_policy(meta, self.global_time + 1)

        messages = []
        for infohash in infohashes:
            message = meta.impl(authentication=(self._my_member,),
                                resolution=(current_policy.implement(),),
                                distribution=(self.claim_global_time(),),
                                payload=(infohash, playlist_packet))
            messages.append(message)

        self._dispersy.store_update_forward(messages, store, update, forward)
        return message

    def _disp_check_playlist_torrent(self, messages):
        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
            yield message

    def _disp_on_playlist_torrent(self, messages):
        if self.integrate_with_tribler:
            for message in messages:
                dispersy_id = message.packet_id
                playlist_dispersy_id = message.payload.playlist.packet_id

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                self._channelcast_db.on_playlist_torrent(dispersy_id, playlist_dispersy_id, peer_id, message.payload.infohash)

    def _disp_undo_playlist_torrent(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            for _, _, packet in descriptors:
                message = packet.load_message()
                infohash = message.payload.infohash
                playlist_dispersy_id = message.payload.playlist.packet_id

                self._channelcast_db.on_remove_playlist_torrent(self._channel_id, playlist_dispersy_id, infohash, redo)

    # check or receive moderation messages
    @call_on_reactor_thread
    def _disp_create_moderation(self, text, timestamp, severity, cause, store=True, update=True, forward=True):
        causemessage = self._dispersy.load_message_by_packetid(self, cause)
        if causemessage:
            text = unicode(text[:1023])

            meta = self.get_meta_message(u"moderation")
            global_time = self.claim_global_time()
            current_policy, _ = self._timeline.get_resolution_policy(meta, global_time)

            message = meta.impl(authentication=(self._my_member,),
                                resolution=(current_policy.implement(),),
                                distribution=(global_time,),
                                payload=(text, timestamp, severity, causemessage))
            self._dispersy.store_update_forward([message], store, update, forward)
            return message

    def _disp_check_moderation(self, messages):
        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)

            yield message

    def _disp_on_moderation(self, messages):
        if self.integrate_with_tribler:
            for message in messages:
                dispersy_id = message.packet_id

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                # if cause packet is present, it is enforced by conversion
                cause = message.payload.causepacket.packet_id
                cause_message = message.payload.causepacket.load_message()
                authentication_member = cause_message.authentication.member
                if authentication_member == self._my_member:
                    by_peer_id = None
                else:
                    by_peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)

                # determine if we are reverting latest
                updateTorrent = False

                modifying_dispersy_id = cause_message.payload.modification_on.packet_id
                channeltorrent_id = self._get_torrent_id_from_message(modifying_dispersy_id)
                if channeltorrent_id:
                    modification_type = cause_message.payload.modification_type
                    modification_type_id = self._modification_types[modification_type]

                    latest = self._get_latest_modification_from_torrent_id(channeltorrent_id, modification_type_id)
                    if not latest or latest.packet_id == cause_message.packet_id:
                        updateTorrent = True

                self._channelcast_db.on_moderation(self._channel_id, dispersy_id, peer_id, by_peer_id, cause, message.payload.text, message.payload.timestamp, message.payload.severity)

                if updateTorrent:
                    latest = self._get_latest_modification_from_torrent_id(channeltorrent_id, modification_type_id)

                    modification_value = latest.payload.modification_value if latest else ''
                    self._channelcast_db.on_torrent_modification_from_dispersy(channeltorrent_id, modification_type, modification_value)

    def _disp_undo_moderation(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            for _, _, packet in descriptors:
                dispersy_id = packet.packet_id
                self._channelcast_db.on_remove_moderation(self._channel_id, dispersy_id, redo)

    # check or receive torrent_mark messages
    @call_on_reactor_thread
    def _disp_create_mark_torrent(self, infohash, type, timestamp, store=True, update=True, forward=True):
        meta = self.get_meta_message(u"mark_torrent")
        global_time = self.claim_global_time()
        current_policy, _ = self._timeline.get_resolution_policy(meta, global_time)

        message = meta.impl(authentication=(self._my_member,),
                            resolution=(current_policy.implement(),),
                            distribution=(global_time,),
                            payload=(infohash, type, timestamp))
        self._dispersy.store_update_forward([message], store, update, forward)
        return message

    def _disp_check_mark_torrent(self, messages):
        for message in messages:
            if not self._channel_id:
                yield DelayMessageReqChannelMessage(message)
                continue

            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
            yield message

    def _disp_on_mark_torrent(self, messages):
        if self.integrate_with_tribler:
            for message in messages:
                dispersy_id = message.packet_id
                global_time = message.distribution.global_time

                authentication_member = message.authentication.member
                if authentication_member == self._my_member:
                    peer_id = None
                else:
                    peer_id = self._peer_db.addOrGetPeerID(authentication_member.public_key)
                self._channelcast_db.on_mark_torrent(self._channel_id, dispersy_id, global_time, peer_id, message.payload.infohash, message.payload.type, message.payload.timestamp)

    def _disp_undo_mark_torrent(self, descriptors, redo=False):
        if self.integrate_with_tribler:
            for _, _, packet in descriptors:
                dispersy_id = packet.packet_id
                self._channelcast_db.on_remove_mark_torrent(self._channel_id, dispersy_id, redo)

    def disp_create_missing_channel(self, candidate, includeSnapshot):
        logger.debug("%s sending missing-channel %s %s", candidate, self._cid.encode("HEX"), includeSnapshot)
        meta = self._meta_messages[u"missing-channel"]
        request = meta.impl(distribution=(self.global_time,), destination=(candidate,), payload=(includeSnapshot,))
        self._dispersy._forward([request])

    # check or receive missing channel messages
    def _disp_check_missing_channel(self, messages):
        return messages

    def _disp_on_missing_channel(self, messages):
        channelmessage = self._get_latest_channel_message()
        packets = None

        for message in messages:
            if message.payload.includeSnapshot:
                if packets is None:
                    packets = []
                    packets.append(channelmessage.packet)

                    torrents = self._channelcast_db.getRandomTorrents(self._channel_id)
                    for infohash in torrents:
                        tormessage = self._get_message_from_torrent_infohash(infohash)
                        if tormessage:
                            packets.append(tormessage.packet)

                self._dispersy._send_packets([message.candidate], packets,
                    self, "-caused by missing-channel-response-snapshot-")

            else:
                self._dispersy._send_packets([message.candidate], [channelmessage.packet],
                    self, "-caused by missing-channel-response-")


    def on_dynamic_settings(self, *args, **kwargs):
        Community.on_dynamic_settings(self, *args, **kwargs)
        if self._channel_id and self.integrate_with_tribler:
            self._channelcast_db.on_dynamic_settings(self._channel_id)

    # helper functions
    @warnDispersyThread
    def _get_latest_channel_message(self):
        channel_meta = self.get_meta_message(u"channel")

        # 1. get the packet
        try:
            packet, packet_id = self._dispersy.database.execute(u"SELECT packet, id FROM sync WHERE meta_message = ? ORDER BY global_time DESC LIMIT 1",
                                                                (channel_meta.database_id,)).next()
        except StopIteration:
            raise RuntimeError("Could not find requested packet")

        message = self._dispersy.convert_packet_to_message(str(packet))
        if message:
            assert message.name == u"channel", "Expecting a 'channel' message"
            message.packet_id = packet_id
        else:
            raise RuntimeError("Unable to convert packet, could not find channel-message for channel %d" % channel_meta.database_id)

        return message

    def _get_message_from_playlist_id(self, playlist_id):
        assert isinstance(playlist_id, (int, long))

        # 1. get the dispersy identifier from the channel_id
        dispersy_id, _ = self._channelcast_db.getPlaylist(playlist_id, ('Playlists.dispersy_id',))

        # 2. get the message
        if dispersy_id and dispersy_id > 0:
            return self._dispersy.load_message_by_packetid(self, dispersy_id)

    def _get_playlist_id_from_message(self, dispersy_id):
        assert isinstance(dispersy_id, (int, long))
        return self._channelcast_db._db.fetchone(u"SELECT id FROM _Playlists WHERE dispersy_id = ?", (dispersy_id,))

    def _get_message_from_torrent_id(self, torrent_id):
        assert isinstance(torrent_id, (int, long))

        # 1. get the dispersy identifier from the channel_id
        dispersy_id = self._channelcast_db.getTorrentFromChannelTorrentId(torrent_id, ['ChannelTorrents.dispersy_id'])

        # 2. get the message
        if dispersy_id and dispersy_id > 0:
            return self._dispersy.load_message_by_packetid(self, dispersy_id)

    def _get_message_from_torrent_infohash(self, torrent_infohash):
        assert isinstance(torrent_infohash, str), 'infohash is a %s' % type(torrent_infohash)
        assert len(torrent_infohash) == 20, 'infohash has length %d' % len(torrent_infohash)

        # 1. get the dispersy identifier from the channel_id
        dispersy_id = self._channelcast_db.getTorrentFromChannelId(self._channel_id, torrent_infohash, ['ChannelTorrents.dispersy_id'])

        if dispersy_id and dispersy_id > 0:
            # 2. get the message
            return self._dispersy.load_message_by_packetid(self, dispersy_id)

    def _get_torrent_id_from_message(self, dispersy_id):
        assert isinstance(dispersy_id, (int, long)), "dispersy_id type is '%s'" % type(dispersy_id)

        return self._channelcast_db._db.fetchone(u"SELECT id FROM _ChannelTorrents WHERE dispersy_id = ?", (dispersy_id,))

    def _get_latest_modification_from_channel_id(self, type_id):
        assert isinstance(type_id, (int, long)), "type_id type is '%s'" % type(type_id)

        # 1. get the dispersy identifier from the channel_id
        dispersy_ids = self._channelcast_db._db.fetchall(u"SELECT dispersy_id, prev_global_time FROM ChannelMetaData WHERE type_id = ? AND channel_id = ? AND id NOT IN (SELECT metadata_id FROM MetaDataTorrent) AND id NOT IN (SELECT metadata_id FROM MetaDataPlaylist) AND dispersy_id not in (SELECT cause FROM Moderations WHERE channel_id = ?) ORDER BY prev_global_time DESC", (type_id, self._channel_id, self._channel_id))
        return self._determine_latest_modification(dispersy_ids)

    def _get_latest_modification_from_torrent_id(self, channeltorrent_id, type_id):
        assert isinstance(channeltorrent_id, (int, long)), "channeltorrent_id type is '%s'" % type(channeltorrent_id)
        assert isinstance(type_id, (int, long)), "type_id type is '%s'" % type(type_id)

        # 1. get the dispersy identifier from the channel_id
        dispersy_ids = self._channelcast_db._db.fetchall(u"SELECT dispersy_id, prev_global_time FROM ChannelMetaData, MetaDataTorrent WHERE ChannelMetaData.id = MetaDataTorrent.metadata_id AND type_id = ? AND channeltorrent_id = ? AND dispersy_id not in (SELECT cause FROM Moderations WHERE channel_id = ?) ORDER BY prev_global_time DESC", (type_id, channeltorrent_id, self._channel_id))
        return self._determine_latest_modification(dispersy_ids)

    def _get_latest_modification_from_playlist_id(self, playlist_id, type_id):
        assert isinstance(playlist_id, (int, long)), "playlist_id type is '%s'" % type(playlist_id)
        assert isinstance(type_id, (int, long)), "type_id type is '%s'" % type(type_id)

        # 1. get the dispersy identifier from the channel_id
        dispersy_ids = self._channelcast_db._db.fetchall(u"SELECT dispersy_id, prev_global_time FROM ChannelMetaData, MetaDataPlaylist WHERE ChannelMetaData.id = MetaDataPlaylist.metadata_id AND type_id = ? AND playlist_id = ? AND dispersy_id not in (SELECT cause FROM Moderations WHERE channel_id = ?) ORDER BY prev_global_time DESC", (type_id, playlist_id, self._channel_id))
        return self._determine_latest_modification(dispersy_ids)

    @warnDispersyThread
    def _determine_latest_modification(self, list):

        if len(list) > 0:
            # 1. determine if we have a conflict
            max_global_time = list[0][1]
            conflicting_messages = []
            for dispersy_id, prev_global_time in list:
                if prev_global_time >= max_global_time:
                    try:
                        message = self._dispersy.load_message_by_packetid(dispersy_id)
                        if message:
                            message = message.load_message()
                            conflicting_messages.append(message)

                            max_global_time = prev_global_time
                    except RuntimeError:
                        pass
                else:
                    break

            # 2. see if we have a conflict
            if len(conflicting_messages) > 1:

                # 3. solve conflict using mid to sort on
                def cleverSort(message_a, message_b):
                    public_key_a = message_a.authentication.member.public_key
                    public_key_b = message_a.authentication.member.public_key

                    if public_key_a == public_key_b:
                        return cmp(message_b.distribution.global_time, message_a.distribution.global_time)

                    return cmp(public_key_a, public_key_b)

                conflicting_messages.sort(cleverSort)

            if len(conflicting_messages) > 0:
                # 4. return first message
                return conflicting_messages[0]

    @warnDispersyThread
    def _get_packet_id(self, global_time, mid):
        if global_time and mid:
            try:
                packet_id, = self._dispersy.database.execute(u"""
                    SELECT sync.id
                    FROM sync
                    JOIN member ON (member.id = sync.member)
                    JOIN meta_message ON (meta_message.id = sync.meta_message)
                    WHERE sync.community = ? AND sync.global_time = ? AND member.mid = ?""",
                                                             (self.database_id, global_time, buffer(mid))).next()
            except StopIteration:
                pass
            return packet_id

########NEW FILE########
__FILENAME__ = conversion
from struct import pack, unpack_from
from random import sample
import zlib

from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.dispersy.message import DropPacket, Packet, \
    DelayPacketByMissingMessage, DelayPacketByMissingMember
from Tribler.dispersy.conversion import BinaryConversion

DEBUG = False


class ChannelConversion(BinaryConversion):

    def __init__(self, community):
        super(ChannelConversion, self).__init__(community, "\x01")
        self.define_meta_message(chr(1), community.get_meta_message(u"channel"), lambda message: self._encode_decode(self._encode_channel, self._decode_channel, message), self._decode_channel)
        self.define_meta_message(chr(2), community.get_meta_message(u"torrent"), lambda message: self._encode_decode(self._encode_torrent, self._decode_torrent, message), self._decode_torrent)
        self.define_meta_message(chr(3), community.get_meta_message(u"playlist"), lambda message: self._encode_decode(self._encode_playlist, self._decode_playlist, message), self._decode_playlist)
        self.define_meta_message(chr(4), community.get_meta_message(u"comment"), lambda message: self._encode_decode(self._encode_comment, self._decode_comment, message), self._decode_comment)
        self.define_meta_message(chr(5), community.get_meta_message(u"modification"), lambda message: self._encode_decode(self._encode_modification, self._decode_modification, message), self._decode_modification)
        self.define_meta_message(chr(6), community.get_meta_message(u"playlist_torrent"), lambda message: self._encode_decode(self._encode_playlist_torrent, self._decode_playlist_torrent, message), self._decode_playlist_torrent)
        self.define_meta_message(chr(7), community.get_meta_message(u"missing-channel"), lambda message: self._encode_decode(self._encode_missing_channel, self._decode_missing_channel, message), self._decode_missing_channel)
        self.define_meta_message(chr(8), community.get_meta_message(u"moderation"), lambda message: self._encode_decode(self._encode_moderation, self._encode_moderation, message), self._decode_moderation)
        self.define_meta_message(chr(9), community.get_meta_message(u"mark_torrent"), lambda message: self._encode_decode(self._encode_mark_torrent, self._decode_mark_torrent, message), self._decode_mark_torrent)

    def _encode_decode(self, encode, decode, message):
        result = encode(message)
        try:
            decode(None, 0, result[0])

        except DropPacket:
            raise
        except:
            pass
        return result

    def _encode_channel(self, message):
        return encode((message.payload.name, message.payload.description)),

    def _decode_channel(self, placeholder, offset, data):
        try:
            offset, values = decode(data, offset)
            if len(values) != 2:
                raise ValueError
        except ValueError:
            raise DropPacket("Unable to decode the channel-payload")

        name = values[0]
        if not (isinstance(name, unicode) and len(name) < 256):
            raise DropPacket("Invalid 'name' type or value")

        description = values[1]
        if not (isinstance(description, unicode) and len(description) < 1024):
            raise DropPacket("Invalid 'description' type or value")

        return offset, placeholder.meta.payload.implement(name, description)

    def _encode_playlist(self, message):
        return self._encode_channel(message)

    def _decode_playlist(self, placeholder, offset, data):
        return self._decode_channel(placeholder, offset, data)

    def _encode_torrent(self, message):
        max_len = self._community.dispersy_sync_bloom_filter_bits / 8

        files = message.payload.files
        trackers = message.payload.trackers

        def create_msg():
            normal_msg = pack('!20sQ', message.payload.infohash, message.payload.timestamp), message.payload.name, tuple(files), tuple(trackers)
            normal_msg = encode(normal_msg)
            return zlib.compress(normal_msg)

        compressed_msg = create_msg()
        while len(compressed_msg) > max_len:
            if len(trackers) > 10:
                # only use first 10 trackers, .torrents in the wild have been seen to have 1000+ trackers...
                trackers = trackers[:10]
            else:
                # reduce files by the amount we are currently to big
                reduce_by = max_len / (len(compressed_msg) * 1.0)
                nr_files_to_include = int(len(files) * reduce_by)
                files = sample(files, nr_files_to_include)

            compressed_msg = create_msg()
        return compressed_msg,

    def _decode_torrent(self, placeholder, offset, data):
        uncompressed_data = zlib.decompress(data[offset:])
        offset = len(data)

        try:
            _, values = decode(uncompressed_data)
        except ValueError:
            raise DropPacket("Unable to decode the torrent-payload")

        infohash_time, name, files, trackers = values
        if len(infohash_time) != 28:
            raise DropPacket("Unable to decode the torrent-payload, got %d bytes expected 28" % (len(infohash_time)))
        infohash, timestamp = unpack_from('!20sQ', infohash_time)

        if not isinstance(name, unicode):
            raise DropPacket("Invalid 'name' type")

        if not isinstance(files, tuple):
            raise DropPacket("Invalid 'files' type")

        if len(files) == 0:
            raise DropPacket("Should have at least one file")

        for file in files:
            if len(file) != 2:
                raise DropPacket("Invalid 'file_len' type")

            path, length = file
            if not isinstance(path, unicode):
                raise DropPacket("Invalid 'files_path' type is %s" % type(path))
            if not isinstance(length, (int, long)):
                raise DropPacket("Invalid 'files_length' type is %s" % type(length))

        if not isinstance(trackers, tuple):
            raise DropPacket("Invalid 'trackers' type")
        for tracker in trackers:
            if not isinstance(tracker, str):
                raise DropPacket("Invalid 'tracker' type")

        return offset, placeholder.meta.payload.implement(infohash, timestamp, name, files, trackers)

    def _encode_comment(self, message):
        dict = {"text": message.payload.text,
                "timestamp": message.payload.timestamp}

        playlist_packet = message.payload.playlist_packet
        infohash = message.payload.infohash

        if message.payload.reply_to_mid:
            dict["reply-to-mid"] = message.payload.reply_to_mid
            dict["reply-to-global-time"] = message.payload.reply_to_global_time

        if message.payload.reply_after_mid:
            dict["reply-after-mid"] = message.payload.reply_after_mid
            dict["reply-after-global-time"] = message.payload.reply_after_global_time

        if playlist_packet:
            message = playlist_packet.load_message()
            dict["playlist-mid"] = message.authentication.member.mid
            dict["playlist-global-time"] = message.distribution.global_time

        if infohash:
            dict['infohash'] = infohash
        return encode(dict),

    def _decode_comment(self, placeholder, offset, data):
        try:
            offset, dic = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the payload")

        if not "text" in dic:
            raise DropPacket("Missing 'text'")
        text = dic["text"]
        if not (isinstance(text, unicode) and len(text) < 1024):
            raise DropPacket("Invalid 'text' type or value")

        if not "timestamp" in dic:
            raise DropPacket("Missing 'timestamp'")
        timestamp = dic["timestamp"]
        if not isinstance(timestamp, (int, long)):
            raise DropPacket("Invalid 'timestamp' type or value")

        reply_to_mid = dic.get("reply-to-mid", None)
        if reply_to_mid and not (isinstance(reply_to_mid, str) and len(reply_to_mid) == 20):
            raise DropPacket("Invalid 'reply-to-mid' type or value")

        reply_to_global_time = dic.get("reply-to-global-time", None)
        if reply_to_global_time and not isinstance(reply_to_global_time, (int, long)):
            raise DropPacket("Invalid 'reply-to-global-time' type")

        reply_after_mid = dic.get("reply-after-mid", None)
        if reply_after_mid and not (isinstance(reply_after_mid, str) and len(reply_after_mid) == 20):
            raise DropPacket("Invalid 'reply-after-mid' type or value")

        reply_after_global_time = dic.get("reply-after-global-time", None)
        if reply_after_global_time and not isinstance(reply_after_global_time, (int, long)):
            raise DropPacket("Invalid 'reply-after-global-time' type")

        playlist_mid = dic.get("playlist-mid", None)
        if playlist_mid and not (isinstance(playlist_mid, str) and len(playlist_mid) == 20):
            raise DropPacket("Invalid 'playlist-mid' type or value")

        playlist_global_time = dic.get("playlist-global-time", None)
        if playlist_global_time and not isinstance(playlist_global_time, (int, long)):
            raise DropPacket("Invalid 'playlist-global-time' type")

        if playlist_mid and playlist_global_time:
            try:
                packet_id, packet, message_name = self._get_message(playlist_global_time, playlist_mid)
                playlist = Packet(self._community.get_meta_message(message_name), packet, packet_id)
            except DropPacket:
                member = self._community.get_member(mid=playlist_mid)
                if not member:
                    raise DelayPacketByMissingMember(self._community, playlist_mid)
                raise DelayPacketByMissingMessage(self._community, member, playlist_global_time)
        else:
            playlist = None

        infohash = dic.get("infohash", None)
        if infohash and not (isinstance(infohash, str) and len(infohash) == 20):
            raise DropPacket("Invalid 'infohash' type or value")
        return offset, placeholder.meta.payload.implement(text, timestamp, reply_to_mid, reply_to_global_time, reply_after_mid, reply_after_global_time, playlist, infohash)

    def _encode_moderation(self, message):
        dict = {"text": message.payload.text,
                "timestamp": message.payload.timestamp,
                "severity": message.payload.severity}

        dict["cause-mid"] = message.payload.cause_mid
        dict["cause-global-time"] = message.payload.cause_global_time
        return encode(dict),

    def _decode_moderation(self, placeholder, offset, data):
        try:
            offset, dic = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the payload")

        if not "text" in dic:
            raise DropPacket("Missing 'text'")
        text = dic["text"]
        if not (isinstance(text, unicode) and len(text) < 1024):
            raise DropPacket("Invalid 'text' type or value")

        if not "timestamp" in dic:
            raise DropPacket("Missing 'timestamp'")
        timestamp = dic["timestamp"]
        if not isinstance(timestamp, (int, long)):
            raise DropPacket("Invalid 'timestamp' type or value")

        if not "severity" in dic:
            raise DropPacket("Missing 'severity'")
        severity = dic["severity"]
        if not isinstance(severity, (int, long)):
            raise DropPacket("Invalid 'severity' type or value")

        cause_mid = dic.get("cause-mid", None)
        if not (isinstance(cause_mid, str) and len(cause_mid) == 20):
            raise DropPacket("Invalid 'cause-mid' type or value")

        cause_global_time = dic.get("cause-global-time", None)
        if not isinstance(cause_global_time, (int, long)):
            raise DropPacket("Invalid 'cause-global-time' type")

        try:
            packet_id, packet, message_name = self._get_message(cause_global_time, cause_mid)
            cause_packet = Packet(self._community.get_meta_message(message_name), packet, packet_id)

        except DropPacket:
            member = self._community.get_member(mid=cause_mid)
            if not member:
                raise DelayPacketByMissingMember(self._community, cause_mid)
            raise DelayPacketByMissingMessage(self._community, member, cause_global_time)

        return offset, placeholder.meta.payload.implement(text, timestamp, severity, cause_packet)

    def _encode_mark_torrent(self, message):
        dict = {"infohash": message.payload.infohash,
                "timestamp": message.payload.timestamp,
                "type": message.payload.type}

        return encode(dict),

    def _decode_mark_torrent(self, placeholder, offset, data):
        try:
            offset, dic = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the payload")

        if not "infohash" in dic:
            raise DropPacket("Missing 'infohash'")
        infohash = dic["infohash"]
        if not (isinstance(infohash, str) and len(infohash) == 20):
            raise DropPacket("Invalid 'infohash' type or value")

        if not "timestamp" in dic:
            raise DropPacket("Missing 'timestamp'")
        timestamp = dic["timestamp"]
        if not isinstance(timestamp, (int, long)):
            raise DropPacket("Invalid 'timestamp' type or value")

        if not "type" in dic:
            raise DropPacket("Missing 'type'")
        type = dic["type"]
        if not (isinstance(type, unicode) and len(type) < 25):
            raise DropPacket("Invalid 'type' type or value")

        return offset, placeholder.meta.payload.implement(infohash, type, timestamp)

    def _encode_modification(self, message):
        modification_on = message.payload.modification_on.load_message()
        dict = {"modification-type": message.payload.modification_type,
                "modification-value": message.payload.modification_value,
                "timestamp": message.payload.timestamp,
                "modification-on-mid": modification_on.authentication.member.mid,
                "modification-on-global-time": modification_on.distribution.global_time}

        prev_modification = message.payload.prev_modification_packet
        if prev_modification:
            message = prev_modification.load_message()
            dict["prev-modification-mid"] = message.authentication.member.mid
            dict["prev-modification-global-time"] = message.distribution.global_time

        return encode(dict),

    def _decode_modification(self, placeholder, offset, data):
        try:
            offset, dic = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the payload")

        if not "modification-type" in dic:
            raise DropPacket("Missing 'modification-type'")
        modification_type = dic["modification-type"]
        if not isinstance(modification_type, unicode):
            raise DropPacket("Invalid 'modification_type' type")

        if not "modification-value" in dic:
            raise DropPacket("Missing 'modification-value'")
        modification_value = dic["modification-value"]
        if not (isinstance(modification_value, unicode) and len(modification_value) < 1024):
            raise DropPacket("Invalid 'modification_value' type or value")

        if not "timestamp" in dic:
            raise DropPacket("Missing 'timestamp'")
        timestamp = dic["timestamp"]
        if not isinstance(timestamp, (int, long)):
            raise DropPacket("Invalid 'timestamp' type or value")

        if not "modification-on-mid" in dic:
            raise DropPacket("Missing 'modification-on-mid'")
        modification_on_mid = dic["modification-on-mid"]
        if not (isinstance(modification_on_mid, str) and len(modification_on_mid) == 20):
            raise DropPacket("Invalid 'modification-on-mid' type or value")

        if not "modification-on-global-time" in dic:
            raise DropPacket("Missing 'modification-on-global-time'")
        modification_on_global_time = dic["modification-on-global-time"]
        if not isinstance(modification_on_global_time, (int, long)):
            raise DropPacket("Invalid 'modification-on-global-time' type")

        try:
            packet_id, packet, message_name = self._get_message(modification_on_global_time, modification_on_mid)
            modification_on = Packet(self._community.get_meta_message(message_name), packet, packet_id)
        except DropPacket:
            member = self._community.dispersy.get_member(mid=modification_on_mid)
            if not member:
                raise DelayPacketByMissingMember(self._community, modification_on_mid)
            raise DelayPacketByMissingMessage(self._community, member, modification_on_global_time)

        prev_modification_mid = dic.get("prev-modification-mid", None)
        if prev_modification_mid and not (isinstance(prev_modification_mid, str) and len(prev_modification_mid) == 20):
            raise DropPacket("Invalid 'prev-modification-mid' type or value")

        prev_modification_global_time = dic.get("prev-modification-global-time", None)
        if prev_modification_global_time and not isinstance(prev_modification_global_time, (int, long)):
            raise DropPacket("Invalid 'prev-modification-global-time' type")

        try:
            packet_id, packet, message_name = self._get_message(prev_modification_global_time, prev_modification_mid)
            prev_modification_packet = Packet(self._community.get_meta_message(message_name), packet, packet_id)
        except:
            prev_modification_packet = None

        return offset, placeholder.meta.payload.implement(modification_type, modification_value, timestamp, modification_on, prev_modification_packet, prev_modification_mid, prev_modification_global_time)

    def _encode_playlist_torrent(self, message):
        playlist = message.payload.playlist.load_message()
        return pack('!20s20sQ', message.payload.infohash, playlist.authentication.member.mid, playlist.distribution.global_time),

    def _decode_playlist_torrent(self, placeholder, offset, data):
        if len(data) < offset + 48:
            raise DropPacket("Unable to decode the payload")

        infohash, playlist_mid, playlist_global_time = unpack_from('!20s20sQ', data, offset)
        try:
            packet_id, packet, message_name = self._get_message(playlist_global_time, playlist_mid)

        except DropPacket:
            member = self._community.dispersy.get_member(mid=playlist_mid)
            if not member:
                raise DelayPacketByMissingMember(self._community, playlist_mid)
            raise DelayPacketByMissingMessage(self._community, member, playlist_global_time)

        playlist = Packet(self._community.get_meta_message(message_name), packet, packet_id)
        return offset + 48, placeholder.meta.payload.implement(infohash, playlist)

    def _get_message(self, global_time, mid):
        assert isinstance(global_time, (int, long))
        assert isinstance(mid, str)
        assert len(mid) == 20
        if global_time and mid:
            try:
                packet_id, packet, message_name = self._community.dispersy.database.execute(u"""
                    SELECT sync.id, sync.packet, meta_message.name
                    FROM sync
                    JOIN member ON (member.id = sync.member)
                    JOIN meta_message ON (meta_message.id = sync.meta_message)
                    WHERE sync.community = ? AND sync.global_time = ? AND member.mid = ?""",
                                                                                           (self._community.database_id, global_time, buffer(mid))).next()
            except StopIteration:
                raise DropPacket("Missing message")

            return packet_id, str(packet), message_name

    def _encode_missing_channel(self, message):
        return pack('!B', int(message.payload.includeSnapshot)),

    def _decode_missing_channel(self, placeholder, offset, data):
        if len(data) < offset + 1:
            raise DropPacket("Unable to decode the payload")

        includeSnapshot, = unpack_from('!B', data, offset)
        if not (includeSnapshot == 0 or includeSnapshot == 1):
            raise DropPacket("Unable to decode includeSnapshot")
        includeSnapshot = bool(includeSnapshot)

        return offset + 1, placeholder.meta.payload.implement(includeSnapshot)

########NEW FILE########
__FILENAME__ = message
from Tribler.dispersy.message import DelayMessage


class DelayMessageReqChannelMessage(DelayMessage):

    """
    Raised during ChannelCommunity.check_ if the channel message has not been received yet.
    """
    def __init__(self, delayed, includeSnapshot=False):
        super(DelayMessageReqChannelMessage, self).__init__(delayed)
        if __debug__:
            from Tribler.dispersy.message import Message
        assert isinstance(delayed, Message.Implementation)
        self._includeSnapshot = includeSnapshot

    @property
    def match_info(self):
        return (self._cid, u"channel", None, None, []),

    def send_request(self, community, candidate):
        self._community.disp_create_missing_channel(candidate, self._includeSnapshot)

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.message import Packet
from Tribler.dispersy.payload import Payload
from struct import pack


class ChannelPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, name, description):
            assert isinstance(name, unicode)
            assert len(name) < 256
            assert isinstance(description, unicode)
            assert len(description) < 1024
            super(ChannelPayload.Implementation, self).__init__(meta)
            self._name = name
            self._description = description

        @property
        def name(self):
            return self._name

        @property
        def description(self):
            return self._description


class PlaylistPayload(ChannelPayload):
    pass


class TorrentPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, infohash, timestamp, name, files, trackers):
            assert isinstance(infohash, str), 'infohash is a %s' % type(infohash)
            assert len(infohash) == 20, 'infohash has length %d' % len(infohash)
            assert isinstance(timestamp, (int, long))

            assert isinstance(name, unicode)
            assert isinstance(files, tuple)
            for path, length in files:
                assert isinstance(path, unicode)
                assert isinstance(length, (int, long))

            assert isinstance(trackers, tuple)
            for tracker in trackers:
                assert isinstance(tracker, str), 'tracker is a %s' % type(tracker)

            super(TorrentPayload.Implementation, self).__init__(meta)
            self._infohash = infohash
            self._timestamp = timestamp
            self._name = name
            self._files = files
            self._trackers = trackers

        @property
        def infohash(self):
            return self._infohash

        @property
        def timestamp(self):
            return self._timestamp

        @property
        def name(self):
            return self._name

        @property
        def files(self):
            return self._files

        @property
        def trackers(self):
            return self._trackers


class CommentPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, text, timestamp, reply_to_mid, reply_to_global_time, reply_after_mid, reply_after_global_time, playlist_packet, infohash):
            assert isinstance(text, unicode)
            assert len(text) < 1024
            assert isinstance(timestamp, (int, long))

            assert not reply_to_mid or isinstance(reply_to_mid, str), 'reply_to_mid is a %s' % type(reply_to_mid)
            assert not reply_to_mid or len(reply_to_mid) == 20, 'reply_to_mid has length %d' % len(reply_to_mid)
            assert not reply_to_global_time or isinstance(reply_to_global_time, (int, long)), 'reply_to_global_time is a %s' % type(reply_to_global_time)

            assert not reply_after_mid or isinstance(reply_after_mid, str), 'reply_after_mid is a %s' % type(reply_after_mid)
            assert not reply_after_mid or len(reply_after_mid) == 20, 'reply_after_mid has length %d' % len(reply_after_global_time)
            assert not reply_after_global_time or isinstance(reply_after_global_time, (int, long)), 'reply_after_global_time is a %s' % type(reply_to_global_time)

            assert not playlist_packet or isinstance(playlist_packet, Packet)

            assert not infohash or isinstance(infohash, str), 'infohash is a %s' % type(infohash)
            assert not infohash or len(infohash) == 20, 'infohash has length %d' % len(infohash)

            super(CommentPayload.Implementation, self).__init__(meta)
            self._text = text
            self._timestamp = timestamp
            self._reply_to_mid = reply_to_mid
            self._reply_to_global_time = reply_to_global_time

            self._reply_after_mid = reply_after_mid
            self._reply_after_global_time = reply_after_global_time

            self._playlist_packet = playlist_packet
            self._infohash = infohash

        @property
        def text(self):
            return self._text

        @property
        def timestamp(self):
            return self._timestamp

        @property
        def reply_to_mid(self):
            return self._reply_to_mid

        @property
        def reply_to_global_time(self):
            return self._reply_to_global_time

        @property
        def reply_after_mid(self):
            return self._reply_after_mid

        @property
        def reply_after_global_time(self):
            return self._reply_after_global_time

        @property
        def playlist_packet(self):
            return self._playlist_packet

        @property
        def infohash(self):
            return self._infohash


class ModerationPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, text, timestamp, severity, causepacket):

            assert isinstance(causepacket, Packet)

            assert isinstance(text, unicode)
            assert len(text) < 1024
            assert isinstance(timestamp, (int, long))
            assert isinstance(severity, (int, long))

            super(ModerationPayload.Implementation, self).__init__(meta)
            self._text = text
            self._timestamp = timestamp
            self._severity = severity
            self._causepacket = causepacket

            message = causepacket.load_message()
            self._mid = message.authentication.member.mid
            self._global_time = message.distribution.global_time

        @property
        def text(self):
            return self._text

        @property
        def timestamp(self):
            return self._timestamp

        @property
        def severity(self):
            return self._severity

        @property
        def causepacket(self):
            return self._causepacket

        @property
        def cause_mid(self):
            return self._mid

        @property
        def cause_global_time(self):
            return self._global_time


class MarkTorrentPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, infohash, type_str, timestamp):
            assert isinstance(infohash, str), 'infohash is a %s' % type(infohash)
            assert len(infohash) == 20, 'infohash has length %d' % len(infohash)

            assert isinstance(type_str, unicode)
            assert len(type_str) < 25
            assert isinstance(timestamp, (int, long))

            super(MarkTorrentPayload.Implementation, self).__init__(meta)
            self._infohash = infohash
            self._type = type_str
            self._timestamp = timestamp

        @property
        def infohash(self):
            return self._infohash

        @property
        def type(self):
            return self._type

        @property
        def timestamp(self):
            return self._timestamp


class ModificationPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, modification_type, modification_value, timestamp, modification_on, prev_modification_packet, prev_modification_mid, prev_modification_global_time):
            assert isinstance(modification_type, unicode)
            assert modification_value is not None
            assert isinstance(modification_value, unicode)
            assert len(modification_value) < 1024
            assert isinstance(modification_on, Packet)

            assert not prev_modification_packet or isinstance(prev_modification_packet, Packet)
            assert not prev_modification_mid or isinstance(prev_modification_mid, str), 'prev_modification_mid is a %s' % type(prev_modification_mid)
            assert not prev_modification_mid or len(prev_modification_mid) == 20, 'prev_modification_mid has length %d' % len(prev_modification_mid)
            assert not prev_modification_global_time or isinstance(prev_modification_global_time, (int, long)), 'prev_modification_global_time is a %s' % type(prev_modification_global_time)

            super(ModificationPayload.Implementation, self).__init__(meta)
            self._modification_type = modification_type
            self._modification_value = modification_value
            self._timestamp = timestamp

            self._modification_on = modification_on

            self._prev_modification_packet = prev_modification_packet
            self._prev_modification_mid = prev_modification_mid
            self._prev_modification_global_time = prev_modification_global_time

        @property
        def modification_type(self):
            return self._modification_type

        @property
        def modification_value(self):
            return self._modification_value

        @property
        def timestamp(self):
            return self._timestamp

        @property
        def modification_on(self):
            return self._modification_on

        @property
        def prev_modification_packet(self):
            return self._prev_modification_packet

        @property
        def prev_modification_id(self):
            if self._prev_modification_mid and self._prev_modification_global_time:
                return "%s@%d" % (self._prev_modification_mid, self._prev_modification_global_time)

        @property
        def prev_modification_mid(self):
            return self._prev_modification_mid

        @property
        def prev_modification_global_time(self):
            return self._prev_modification_global_time


class PlaylistTorrentPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, infohash, playlist):
            assert isinstance(infohash, str), 'infohash is a %s' % type(infohash)
            assert len(infohash) == 20, 'infohash has length %d' % len(infohash)
            assert isinstance(playlist, Packet), type(playlist)
            super(PlaylistTorrentPayload.Implementation, self).__init__(meta)
            self._infohash = infohash
            self._playlist = playlist

        @property
        def infohash(self):
            return self._infohash

        @property
        def playlist(self):
            return self._playlist


class MissingChannelPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, includeSnapshot=False):
            assert isinstance(includeSnapshot, bool), 'includeSnapshot is a %s' % type(includeSnapshot)
            super(MissingChannelPayload.Implementation, self).__init__(meta)

            self._includeSnapshot = includeSnapshot

        @property
        def includeSnapshot(self):
            return self._includeSnapshot

########NEW FILE########
__FILENAME__ = preview
from Tribler.community.channel.community import ChannelCommunity
from time import time

class PreviewChannelCommunity(ChannelCommunity):

    """
    The PreviewChannelCommunity extends the ChannelCommunity to allow ChannelCommunity messages to
    be decoded while not actually joining or participating in an actual ChannelCommunity.
    """

    def __init__(self, *args, **kargs):
        super(PreviewChannelCommunity, self).__init__(*args, **kargs)
        self.init_timestamp = time()

    @property
    def dispersy_enable_bloom_filter_sync(self):
        return False

    @property
    def dispersy_enable_candidate_walker(self):
        return False

    def get_channel_mode(self):
        return ChannelCommunity.CHANNEL_CLOSED, False


########NEW FILE########
__FILENAME__ = community
# Written by Niels Zeilemaker
from conversion import DemersConversion
from payload import TextPayload

from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CommunityDestination
from Tribler.dispersy.distribution import FullSyncDistribution
from Tribler.dispersy.message import Message, DelayMessageByProof
from Tribler.dispersy.resolution import PublicResolution
from Tribler.dispersy.tool.lencoder import log


class DemersTest(Community):
    def initiate_meta_messages(self):
        return super(DemersTest, self).initiate_meta_messages() + [
            Message(self, u"text",
                    MemberAuthentication(),
                    PublicResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128),
                    CommunityDestination(node_count=10), TextPayload(),
                    self.check_text,
                    self.on_text)
        ]

    def initiate_conversions(self):
        return [DefaultConversion(self), DemersConversion(self)]

    @property
    def dispersy_sync_response_limit(self):
        return 1

    @property
    def dispersy_sync_skip_enable(self):
        return False

    @property
    def dispersy_sync_cache_enable(self):
        return False

    def create_text(self, text, store=True, update=True, forward=True):
        meta = self.get_meta_message(u"text")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(text,))
        self._dispersy.store_update_forward([message], store, update, forward)

    def check_text(self, messages):
        for message in messages:
            allowed, _ = self._timeline.check(message)
            if allowed:
                yield message
            else:
                yield DelayMessageByProof(message)

    def on_text(self, messages):
        for message in messages:
            log("dispersy.log", "handled-record", type="text", global_time=message._distribution.global_time)

########NEW FILE########
__FILENAME__ = conversion
# Written by Niels Zeilemaker
from struct import pack, unpack_from

from Tribler.dispersy.conversion import BinaryConversion
from Tribler.dispersy.message import DropPacket


class DemersConversion(BinaryConversion):

    def __init__(self, community):
        super(DemersConversion, self).__init__(community, "\x02")
        self.define_meta_message(chr(1), community.get_meta_message(u"text"), self._encode_text, self._decode_text)

    def _encode_text(self, message):
        assert len(message.payload.text.encode("UTF-8")) < 256
        text = message.payload.text.encode("UTF-8")
        return pack("!B", len(text)), text[:255]

    def _decode_text(self, placeholder, offset, data):
        if len(data) < offset + 1:
            raise DropPacket("Insufficient packet size")

        text_length, = unpack_from("!B", data, offset)
        offset += 1

        try:
            text = data[offset:offset + text_length].decode("UTF-8")
            offset += text_length
        except UnicodeError:
            raise DropPacket("Unable to decode UTF-8")

        return offset, placeholder.meta.payload.implement(text)

########NEW FILE########
__FILENAME__ = payload
# Written by Niels Zeilemaker
from Tribler.dispersy.payload import Payload


class TextPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, text):
            assert isinstance(text, unicode)
            assert len(text.encode("UTF-8")) <= 255
            super(TextPayload.Implementation, self).__init__(meta)
            self._text = text

        @property
        def text(self):
            return self._text

########NEW FILE########
__FILENAME__ = community
import binascii
import json
import logging

from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.candidate import CANDIDATE_WALK_LIFETIME
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CommunityDestination
from Tribler.dispersy.distribution import LastSyncDistribution
from Tribler.dispersy.message import Message, DropMessage
from Tribler.dispersy.resolution import PublicResolution
from Tribler.dispersy.util import call_on_reactor_thread
from conversion import MetadataConversion
from payload import MetadataPayload


class MetadataCommunity(Community):

    def initialize(self, integrate_with_tribler=True):
        super(MetadataCommunity, self).initialize()

        self._logger = logging.getLogger(self.__class__.__name__)
        self._integrate_with_tribler = integrate_with_tribler

        if self._integrate_with_tribler:
            from Tribler.Core.CacheDB.SqliteCacheDBHandler import MetadataDBHandler, TorrentDBHandler
            # tribler channelcast database
            self._metadata_db = MetadataDBHandler.getInstance()
            self._torrent_db = TorrentDBHandler.getInstance()
        else:
            self._metadata_db = MetadataDBStub(self._dispersy)

    @classmethod
    def get_master_members(cls, dispersy):
# generated: Fri Apr  4 21:27:04 2014
# curve: NID_sect571r1
# len: 571 bits ~ 144 bytes signature
# pub: 170 3081a7301006072a8648ce3d020106052b8104002703819200040569d8061423ca91a3f35b16e34ff5d83af8ab595a5144b7f0e7888e6199b4959a120613122bb5248b22ae769dc8729c1e69f8170f2d05c035dd036ce07ab4c678f488cbeaceb0c506efb4e04a4be16968dfe520248328734204fc346b0c9c091089736aa4e531674fe595bba0b384d0887f9d38a019d57dc4818dce70492bc629e4a61f9cb39ee2711a874e30f06aba
# pub-sha1 42b40842737abc5e9b006972753877d78d9aedb5
# -----BEGIN PUBLIC KEY-----
# MIGnMBAGByqGSM49AgEGBSuBBAAnA4GSAAQFadgGFCPKkaPzWxbjT/XYOvirWVpR
# RLfw54iOYZm0lZoSBhMSK7UkiyKudp3IcpweafgXDy0FwDXdA2zgerTGePSIy+rO
# sMUG77TgSkvhaWjf5SAkgyhzQgT8NGsMnAkQiXNqpOUxZ0/llbugs4TQiH+dOKAZ
# 1X3EgY3OcEkrxinkph+cs57icRqHTjDwaro=
# -----END PUBLIC KEY-----
        master_key = "3081a7301006072a8648ce3d020106052b8104002703819200040569d8061423ca91a3f35b16e34ff5d83af8ab595a5144b7f0e7888e6199b4959a120613122bb5248b22ae769dc8729c1e69f8170f2d05c035dd036ce07ab4c678f488cbeaceb0c506efb4e04a4be16968dfe520248328734204fc346b0c9c091089736aa4e531674fe595bba0b384d0887f9d38a019d57dc4818dce70492bc629e4a61f9cb39ee2711a874e30f06aba".decode("HEX")
        master = dispersy.get_member(public_key=master_key)
        return [master]

    @property
    def dispersy_sync_skip_enable(self):
        return self._integrate_with_tribler

    @property
    def dispersy_sync_cache_enable(self):
        return self._integrate_with_tribler

    def initiate_conversions(self):
        return [DefaultConversion(self), MetadataConversion(self)]


    def initiate_meta_messages(self):
        custom_callback = (self.custom_callback_check, self.custom_callback_store)
        return super(MetadataCommunity, self).initiate_meta_messages() + [
            Message(self, u"metadata", MemberAuthentication(),
                    PublicResolution(),
                    LastSyncDistribution(synchronization_direction=u"DESC",
                                         priority=128,
                                         history_size=1,
                                         custom_callback=custom_callback),
                    CommunityDestination(node_count=10),
                    MetadataPayload(),
                    self.check_metadata,
                    self.on_metadata),
        ]


    def create_metadata_message(self, infohash, roothash, data_list):
        columns = ("previous_global_time", "previous_mid", "this_global_time", "this_mid", "message_id")
        result_list = self._metadata_db.getMetadataMessageList(
            infohash, roothash, columns)

        prev_mid = None
        prev_global_time = None
        merged_data_list = data_list
        if result_list:
            result_list.sort()
            prev_global_time = result_list[-1][2]
            prev_mid = result_list[-1][3]

            # merge data-list
            message_id = result_list[-1][-1]
            prev_data_list = self._metadata_db.getMetadataData(message_id)

            merged_data_set = set(data_list)
            # check duplicates
            for data in prev_data_list:
                if data in merged_data_set:
                    self._logger.warn("Duplicate key in new and old data-list: %s", data[0])
            # merge
            merged_data_set.update(prev_data_list)
            merged_data_list = list(merged_data_set)

            # shrink the values to <= 1KB
            for idx in xrange(len(merged_data_list)):
                if len(merged_data_list[idx][1]) > 1024:
                    merged_data_list[idx] = (merged_data_list[idx][0], merged_data_list[idx][1][:1024])

        meta = self.get_meta_message(u"metadata")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(infohash, roothash, merged_data_list,
                                prev_mid, prev_global_time))
        self.__log(-1, message)
        self._dispersy.store_update_forward([message], True, True, True)


    def check_metadata(self, messages):
        for message in messages:
            # do not test downloading thumbnails in dispersy tests
            if not self._integrate_with_tribler:
                yield message
                continue

            infohash = message.payload.infohash
            roothash = message.payload.roothash

            if infohash:
                do_continue = False
                for key, value in message.payload.data_list:
                    if key.startswith("swift-"):
                        data_type = key.split('-', 1)[1]

                        _, roothash, contenthash = json.loads(value)
                        roothash = binascii.unhexlify(roothash)
                        contenthash = binascii.unhexlify(contenthash)

                        from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler
                        th_handler = RemoteTorrentHandler.getInstance()
                        if not th_handler.has_metadata(data_type, infohash, contenthash):
                            self._logger.debug("Will try to download %s with roothash %s from %s",
                                key, roothash.encode("HEX"), message.candidate.sock_addr[0])

                            @call_on_reactor_thread
                            def callback(_, message=message):
                                self.on_messages([message])

                            th_handler.download_metadata(data_type, message.candidate,
                                roothash, infohash, contenthash,
                                timeout=CANDIDATE_WALK_LIFETIME, usercallback=callback)
                            do_continue = True
                            break

                        else:
                            self._logger.debug("Don't need to download swift-thumbs with roothash %s from %s, already on disk", roothash.encode("HEX"), message.candidate.sock_addr[0])

                if do_continue:
                    continue

            yield message


    def on_metadata(self, messages):
        # DO NOTHING
        pass

    def __log(self, count, message, info_str=None):
        prev_global_time = None
        prev_mid = None
        if message.payload.prev_mid:
            prev_global_time = message.payload.prev_global_time
            prev_mid = binascii.hexlify(message.payload.prev_mid)[:7]
        global_time = message.distribution.global_time
        mid = binascii.hexlify(message.authentication.member.mid)[:7]
        if message.payload.infohash:
            infohash = binascii.hexlify(message.payload.infohash)[:7]
        else:
            infohash = None
        if message.payload.roothash:
            roothash = binascii.hexlify(message.payload.roothash)[:7]
        else:
            roothash = None

        if count == 0:
            self._logger.debug("ACCEPT ip[%s:%s] member[(%s %s)->(%s %s)] msg[%s %s]",
                message.candidate.sock_addr[0], message.candidate.sock_addr[1],
                global_time, mid, prev_global_time, prev_mid, infohash, roothash)
        elif count == -1:
            self._logger.debug("CREATE member[%s %s] msg[(%s %s)->(%s %s)]",
                global_time, mid, prev_global_time, prev_mid, infohash, roothash)
        elif count == -2:
            self._logger.debug("IGNORE ip[%s:%s] member[(%s %s)->(%s %s)] msg[%s %s]",
                message.candidate.sock_addr[0], message.candidate.sock_addr[1],
                global_time, mid, prev_global_time, prev_mid, infohash, roothash)
        elif count >= 100:
            self._logger.debug("CUSTOM ip[%s:%s] member[(%s %s)->(%s %s)] msg[%s %s] | %s",
                message.candidate.sock_addr[0], message.candidate.sock_addr[1],
                global_time, mid, prev_global_time, prev_mid, infohash, roothash, info_str)
        else:
            self._logger.debug("DROP[%d] ip[%s:%s] member[(%s %s)->(%s %s)] msg[%s %s]",
                count, message.candidate.sock_addr[0], message.candidate.sock_addr[1],
                global_time, mid, prev_global_time, prev_mid, infohash, roothash)

    def custom_callback_check(self, unique, times, message):
        """
        Checks if we drop this message or not. We update the metadata with
        the following rules:
          (1) UNIQUE: If we have received this message before. (DROP)
          (2) NEW METADATA BEFORE FULL: The number of metadata for the same
              object has not reached the maximum number X and there is no previous
              metadata. If not we DROP.
        """
        assert isinstance(unique, set)
        assert isinstance(times, dict)
        assert isinstance(message, Message.Implementation)

        # check UNIQUE
        key = (message.authentication.member.database_id, message.distribution.global_time)
        if key in unique:
            self.__log(1, message)
            return DropMessage(message, u"already processed message by member^global_time")

        else:
            unique.add(key)

            if not message.authentication.member.database_id in times:
                times[message.authentication.member.database_id] = [global_time for global_time, in self._dispersy._database.execute(u"SELECT global_time FROM sync WHERE community = ? AND member = ? AND meta_message = ?", (message.community.database_id, message.authentication.member.database_id, message.database_id))]
                # assert len(times[message.authentication.member.database_id]) <= message.distribution.history_size, [message.packet_id, message.distribution.history_size, times[message.authentication.member.database_id]]

            tim = times[message.authentication.member.database_id]

            if message.distribution.global_time in tim and \
                    self._dispersy._is_duplicate_sync_message(message):
                self.__log(2, message)
                return DropMessage(message, "duplicate message by member^global_time (3)")

            # select the metadata messages from DB
            message_list = self._metadata_db.getMetadataMessageList(
                message.payload.infohash, message.payload.roothash,
                ("previous_global_time", "previous_mid",
                 "this_global_time", "this_mid", "dispersy_id"))

            if message.payload.prev_mid:
                prev_mid = message.payload.prev_mid
                prev_global_time = message.payload.prev_global_time
                this_message = (prev_global_time, prev_mid,
                    message.distribution.global_time,
                    message.authentication.member.mid, None)
            else:
                this_message = (None, None, message.distribution.global_time,
                    message.authentication.member.mid, None)

            # compare previous pointers
            if message_list:
                message_list.append(this_message)
                message_list.sort()

                # This message be in the top X in order to be stored, otherwise
                # it is an old message and we send back our latest one.
                history_size = message.distribution.history_size
                history_size = 1 if history_size < 1 else history_size
                if this_message not in message_list[-history_size:]:
                    # dirty way
                    if message.distribution.history_size == 1:
                        # send the latest message to the sender
                        try:
                            packet, = self._dispersy._database.execute(
                                u"SELECT packet FROM sync WHERE id = ?",
                                    (message_list[-1][-1],)).next()
                        except StopIteration:
                            pass
                        else:
                            self._dispersy._send_packets([message.candidate], [str(packet)],
                                self, "-caused by custom-check-lastdist-")

                    self.__log(3, message)
                    return DropMessage(message, u"This metadata message is old.")

            self.__log(0, message)
            return message


    def custom_callback_store(self, messages):
        """
        Store everything into MetadataMessage table and MetadataData table.

        Return a list of SyncIDs (dispersy IDs) with need to be removed from
        the dispersy sync table.
        """
        # STEP 1: insert everything
        to_clear_set = set()
        value_list = []
        for message in messages:
            to_clear_set.add((message.payload.infohash, message.payload.roothash))

            dispersy_id = message.packet_id
            this_global_time = message.distribution.global_time
            this_mid = message.authentication.member.mid

            # insert new metadata message
            message_id = self._metadata_db.addAndGetIDMetadataMessage(
                dispersy_id, this_global_time, this_mid,
                message.payload.infohash, message.payload.roothash,
                message.payload.prev_mid, message.payload.prev_global_time)

            # new metadata data to insert
            for key, value in message.payload.data_list:
                value_list.append((message_id, key, value))

        self._metadata_db.addMetadataDataInBatch(value_list)

        # STEP 2: cleanup and update metadataData
        sync_id_list = []
        for to_clear_infohash, to_clear_roothash in to_clear_set:
            message_list = self._metadata_db.getMetadataMessageList(
                to_clear_infohash, to_clear_roothash,
                ("previous_global_time", "previous_mid", "this_global_time", "this_mid", "dispersy_id"))

            # compare previous pointers
            if message_list:
                message_list.sort()

                for message in message_list[:-1]:
                    dispersy_id = message[-1]
                    self._metadata_db.deleteMetadataMessage(dispersy_id)

                    sync_id_list.append((dispersy_id, dispersy_id))

        return sync_id_list


class MetadataDBStub(object):

    def __init__(self, dispersy):
        self._logger = logging.getLogger(self.__class__.__name__)

        self._dispersy = dispersy

        # the dirty way: simulate the database with lists
        self._auto_message_id = 1
        self._metadata_message_db_list = []
        self._metadata_data_db_list = []


    def getAllMetadataMessage(self):
        return self._metadata_message_db_list


    def getMetadataMessageList(self, infohash, roothash, columns):
        message_list = []
        for data in self._metadata_message_db_list:
            if data["infohash"] != infohash or data["roothash"] != roothash:
                continue

            message = []
            for column in columns:
                message.append(data[column])

            message_list.append(tuple(message))

        return message_list


    def addAndGetIDMetadataMessage(self, dispersy_id, this_global_time, this_mid,
            infohash, roothash, prev_mid=None, prev_global_time=None):
        data = {"message_id": self._auto_message_id,
                "dispersy_id": dispersy_id,
                "this_global_time": this_global_time,
                "this_mid": this_mid,
                "infohash": infohash,
                "roothash": roothash,
                "previous_mid": prev_mid,
                "previous_global_time": prev_global_time}
        self._metadata_message_db_list.append(data)

        this_message_id = self._auto_message_id
        self._auto_message_id += 1

        return this_message_id


    def addMetadataDataInBatch(self, value_tuple_list):
        for value_tuple in value_tuple_list:
            data = {"message_id": value_tuple[0],
                    "data_key": value_tuple[1],
                    "data_value": value_tuple[2]
            }
            self._metadata_data_db_list.append(data)


    def deleteMetadataMessage(self, dispersy_id):
        new_metadata_message_db_list = []
        for data in self._metadata_message_db_list:
            if data["dispersy_id"] != dispersy_id:
                new_metadata_message_db_list.append(data)
        self._metadata_message_db_list = new_metadata_message_db_list


    def getMetadataData(self, message_id):
        data_list = []
        for msg_id, key, value in self._metadata_data_db_list:
            if msg_id != message_id:
                continue
            data_list.append((key, value))
        return data_list

########NEW FILE########
__FILENAME__ = conversion
import zlib
import logging
from random import sample

from Tribler.dispersy.conversion import BinaryConversion
from Tribler.dispersy.message import DropPacket

from Tribler.Core.Utilities.encoding import encode, decode


class MetadataConversion(BinaryConversion):

    def __init__(self, community):
        super(MetadataConversion, self).__init__(community, "\x01")
        self.__logger = logging.getLogger(self.__class__.__name__)
        self.define_meta_message(chr(1), community.get_meta_message(u"metadata"), lambda message: self._encode_decode(self._encode_metadata, self._decode_metadata, message), self._decode_metadata)


    def _encode_decode(self, encode, decode, message):
        result = encode(message)
        try:
            decode(None, 0, result[0])

        except DropPacket:
            raise
        except:
            pass
        return result


    def _encode_metadata(self, message):
        """
        Encodes the metadata message payload.
        """
        max_len = 8 * 1024

        data_list = message.payload.data_list

        def create_msg():
            msg_dict = {
                "infohash": message.payload.infohash,
                "roothash": message.payload.roothash,
                "data-list": message.payload.data_list
            }
            if message.payload.prev_mid:
                msg_dict["prev-mid"] = message.payload.prev_mid
                msg_dict["prev-global-time"] = message.payload.prev_global_time

            normal_msg = encode(msg_dict)
            return zlib.compress(normal_msg)

        compressed_msg = create_msg()
        while len(compressed_msg) > max_len:
            # reduce files by the amount we are currently to big
            reduce_by = max_len / (len(compressed_msg) * 1.0)
            nr_data_to_include = int(len(data_list) * reduce_by)
            data_list = sample(data_list, nr_data_to_include)

            compressed_msg = create_msg()
        return compressed_msg,


    def _decode_metadata(self, placeholder, offset, data):
        """
        Decodes the metadata message payload.
        """
        uncompressed_data = zlib.decompress(data[offset:])
        offset = len(data)

        try:
            _, dic = decode(uncompressed_data)
        except ValueError:
            raise DropPacket("Unable to decode metadata message payload")

        if not "infohash" in dic:
            raise DropPacket("Missing 'infohash'")
        infohash = dic["infohash"]
        if not (isinstance(infohash, str) and len(infohash) == 20):
            raise DropPacket("Invalid 'infohash' type or value")

        if not "roothash" in dic:
            raise DropPacket("Missing 'roothash'")
        roothash = dic["roothash"]
        if roothash and not (isinstance(roothash, str) and len(roothash) == 20):
            raise DropPacket("Invalid 'roothash' type or value")

        if not "data-list" in dic:
            raise DropPacket("Missing 'data-list'")
        data_list = dic["data-list"]
        if not isinstance(data_list, list):
            raise DropPacket("Invalid 'data-list' type or value")
        for data in data_list:
            if not isinstance(data, tuple):
                raise DropPacket("Invalid 'data' type")
            elif len(data) != 2:
                raise DropPacket("Invalid 'data' value")
            elif len(data[1]) > 1024:
                raise DropPacket("'data' value too big (> 1024 bytes)")

        prev_mid = dic.get("prev-mid", None)
        if prev_mid and not (isinstance(prev_mid, str) and len(prev_mid) == 20):
            raise DropPacket("Invalid 'prev-mid' type or value")

        prev_global_time = dic.get("prev-global-time", None)
        if prev_global_time and not isinstance(prev_global_time, (int, long)):
            raise DropPacket("Invalid 'prev-global-time' type")

        if (prev_mid and not prev_global_time):
            raise DropPacket("Incomplete previous pointer (mid and NO global-time)")
        if (not prev_mid and prev_global_time):
            raise DropPacket("Incomplete previous pointer (global-time and NO mid)")

        return offset, placeholder.meta.payload.implement(infohash, roothash, data_list, prev_mid, prev_global_time)

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload


class MetadataPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, infohash, roothash, data_list, prev_mid=None, prev_global_time=None):
            assert isinstance(infohash, str), u"infohash is a %s" % type(infohash)
            assert len(infohash) == 20, u"infohash has length %d" % len(infohash)
            if roothash:
                assert isinstance(roothash, str), u"roothash is a %s" % type(roothash)
                assert len(roothash) == 20, u"roothash has length %d" % len(roothash)

            assert isinstance(data_list, list), u"data_list is a %s" % type(data_list)
            for data in data_list:
                assert isinstance(data, tuple), u"data is a %s" % type(data)
                assert len(data) == 2, u"data has length %d" % len(data)

            assert not prev_mid or isinstance(prev_mid, str), u"prev_mid is a %s" % type(prev_mid)
            assert not prev_mid or len(prev_mid) == 20, u"prev_mid has length %d" % len(prev_mid)
            assert not prev_global_time or isinstance(prev_global_time, (int, long)), \
                u"prev_global_time is a %s" % type(prev_global_time)

            super(MetadataPayload.Implementation, self).__init__(meta)

            self._infohash = infohash
            self._roothash = roothash
            self._data_list = data_list

            self._prev_mid = prev_mid
            self._prev_global_time = prev_global_time

        @property
        def infohash(self):
            return self._infohash

        @property
        def roothash(self):
            return self._roothash

        @property
        def data_list(self):
            return self._data_list

        @property
        def prev_mid(self):
            return self._prev_mid

        @property
        def prev_global_time(self):
            return self._prev_global_time

########NEW FILE########
__FILENAME__ = community
# Written by Niels Zeilemaker
import sys
from math import ceil
from os import path
from random import sample, randint, shuffle, random
from time import time

from twisted.internet import reactor
from twisted.internet.defer import inlineCallbacks

from Tribler.community.channel.preview import PreviewChannelCommunity
from Tribler.community.privatesemantic.community import PForwardCommunity, HForwardCommunity, PoliForwardCommunity
from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.bloomfilter import BloomFilter
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CandidateDestination, CommunityDestination
from Tribler.dispersy.distribution import DirectDistribution, FullSyncDistribution
from Tribler.dispersy.exception import CommunityNotFoundException
from Tribler.dispersy.message import Message, DelayMessageByProof, DropMessage
from Tribler.dispersy.requestcache import NumberCache, RandomNumberCache
from Tribler.dispersy.resolution import PublicResolution
from conversion import SearchConversion
from payload import *


DEBUG = False
DEBUG_VERBOSE = False
TTL = 4
NEIGHBORS = 5
FNEIGHBORS = 1
FPROB = 0.5
ENCRYPTION = True

class TTLSearchCommunity(Community):
    """
    A single community that all Tribler members join and use to disseminate .torrent files.
    """
    @classmethod
    def get_master_members(cls, dispersy):
        master_key = "3081a7301006072a8648ce3d020106052b81040027038192000404a041c3a8415021f193ef0614360b4d99ac8f985eff2259f88f1f64070ae2bcc21c473c9c0b958b39da9ae58d6d0aec316341f65bd7daa42ffd73f5eeee53aa6199793f98afc47f008a601cd659479f801157e7dd69525649d8eec7885bd0d832746c46d067c60341a6d84b12a6e5d3ce25e20352ed8e0ff311e74b801c06286a852976bdba67dfe62dfb75a5b9c0d2".decode("HEX")
        master = dispersy.get_member(master_key)
        return [master]

    def initialize(self, integrate_with_tribler=True, ttl=TTL, neighbors=NEIGHBORS, fneighbors=FNEIGHBORS, prob=FPROB, log_searches=False, use_megacache=True):
        super(TTLSearchCommunity, self).initialize()

        self.integrate_with_tribler = integrate_with_tribler
        self.ttl = ttl
        self.neighbors = neighbors
        self.fneighbors = fneighbors
        self.log_searches = log_searches
        self.use_megacache = bool(use_megacache)
        self.prob = prob
        self.fprob = FPROB

        self.search_timeout = 0
        self.search_forward = 0
        self.search_forward_success = 0
        self.search_forward_timeout = 0
        self.search_endpoint = 0
        self.search_cycle_detected = 0
        self.search_megacachesize = 0
        self.search_no_candidates_remain = 0

        if self.integrate_with_tribler:
            from Tribler.Core.CacheDB.SqliteCacheDBHandler import ChannelCastDBHandler, TorrentDBHandler, MyPreferenceDBHandler, MiscDBHandler
            from Tribler.Core.CacheDB.Notifier import Notifier

            # tribler channelcast database
            self._channelcast_db = ChannelCastDBHandler.getInstance()
            self._misc_db = MiscDBHandler.getInstance()
            self._torrent_db = TorrentDBHandler.getInstance()
            self._notifier = Notifier.getInstance()

            # fast connecting
            self._pending_tasks["fast walker"] = reactor.callLater(0, self.fast_walker)
        else:
            self._torrent_db = self._channelcast_db = Das4DBStub(self._dispersy)
            self._notifier = None

    # TODO(emilon): Replace this with the new dispersy property
    @inlineCallbacks
    def fast_walker(self):
        for cycle in xrange(10):
            if cycle < 2:
                # poke bootstrap peers
                for candidate in self._dispersy._bootstrap_candidates.itervalues():
                    self.create_introduction_request(candidate, allow_sync=False)

            # request -everyone- that is eligible
            candidates = [candidate for candidate in self._iter_categories([u'walk', u'stumble', u'intro'], once=True) if candidate]
            for candidate in candidates:
                self.create_introduction_request(candidate, allow_sync=False)

            # wait for NAT hole punching
            yield deferLater(reactor, 1, lambda: None)

    def initiate_meta_messages(self):
        return super(SearchCommunity, self).initiate_meta_messages() + [
            Message(self, u"search-request",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    SearchRequestPayload(),
                    self._dispersy._generic_timeline_check,
                    self.on_search),
            Message(self, u"search-response",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    SearchResponsePayload(),
                    self.check_search_response,
                    self.on_search_response),
            Message(self, u"torrent-request",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    TorrentRequestPayload(),
                    self._dispersy._generic_timeline_check,
                    self.on_torrent_request),
            Message(self, u"torrent",
                    MemberAuthentication(),
                    PublicResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"ASC", priority=128),
                    CommunityDestination(node_count=0),
                    TorrentPayload(),
                    self._dispersy._generic_timeline_check,
                    self.on_torrent)
                ]

    def initiate_conversions(self):
        return [DefaultConversion(self), SearchConversion(self)]

    @property
    def dispersy_auto_download_master_member(self):
        # there is no dispersy-identity for the master member, so don't try to download
        return False

    @property
    def dispersy_sync_bloom_filter_strategy(self):
        # disable sync bloom filter
        return lambda: None

    class SearchRequest(object):
        def __init__(self, community, number, keywords, ttl, callback, results=[], return_candidate=None, requested_candidates=[]):

            self.number = number
            self.community = community
            self.keywords = keywords
            self.callback = callback
            self.results = results
            self.return_candidate = return_candidate
            self.created_by_me = not return_candidate

            self.requested_candidates = requested_candidates
            self.requested_mids = set()
            for candidate in self.requested_candidates:
                self.requested_mids.add(candidate.get_member().mid)
            self.received_candidates = []

            # setting timeout
            if self.return_candidate:
                self.timeout_delay = 5.0
            else:
                self.timeout_delay = 30.0

            self.timeout_delay += (ttl * 2)
            self.processed = False

            # call self.on_timeout after self.timeout_delay seconds.  We do not need to cancel this
            # call registered call because we rely on the self.processed boolean
            self._pending_tas["on timeout"] = reactor.callLater(self.timeout_delay, self.on_timeout)

        def did_request(self, candidate_mid):
            return candidate_mid in self.requested_mids

        def on_success(self, candidate_mid, keywords, results, candidate):
            if not self.processed:

                if self.did_request(candidate_mid):
                    self.received_candidates.append(candidate_mid)
                    self.results.extend(results)
                    shuffle(self.results)

                self.processed = len(self.received_candidates) == len(self.requested_candidates)
                if self.return_candidate and self.processed:
                    self.callback(keywords, self.results, self.return_candidate)  # send message containing all results
                    self.community.search_forward_success += 1

                if not self.return_candidate:
                    self.callback(keywords, results, candidate)  # local query, update immediately do not pass self.results as it contains all results

            return self.processed

        def on_timeout(self):
            # timeout, message was probably lost return our local results
            if not self.processed:
                self.processed = True
                if self.return_candidate:
                    self.callback(self.keywords, self.results, self.return_candidate)
                    self.community.search_forward_timeout += 1

                    if DEBUG:
                        print >> sys.stderr, long(time()), "TTLSearchCommunity: timeout for searchrequest, returning my local results waited for %.1f seconds" % self.timeout_delay
                else:
                    self.community.search_timeout += (len(self.requested_candidates) - len(self.received_candidates))

    class MSearchRequest(NumberCache):
        def __init__(self, number, search_request):
            assert isinstance(number, int), type(number)
            assert number == search_request.number, [number, search_request.number]
            super(TTLSearchCommunity.MSearchRequest, self).__init__(u"m-search-request", number)
            self._number = number
            self._timeout_delay = search_request.timeout_delay

            self.search_requests = []
            self.search_requests.append(search_request)

        @property
        def timeout_delay(self):
            return self._timeout_delay

        def add_request(self, search_request):
            if __debug__:
                requested_candidates = self.get_requested_candidates()
                assert all(mid not in requested_candidates for mid in search_request.requested_mids), "requested candidates cannot overlap"
                assert search_request.identifier == self.identifier, [search_request.identifier, self.identifier]
                assert search_request.keywords == self.keywords, [search_request.keywords, self.keywords]

            self.search_requests.append(search_request)

        def get_requested_candidates(self):
            requested_candidates = set()
            for search_request in self.search_requests:
                requested_candidates.update(search_request.requested_mids)
            return requested_candidates

        def on_success(self, candidate_mid, keywords, results, candidate):
            for i in range(len(self.search_requests) - 1, -1, -1):
                search_request = self.search_requests[i]
                if search_request.did_request(candidate_mid):
                    if search_request.on_success(candidate_mid, keywords, results, candidate):
                        self.search_requests.pop(i)
                    break

            return len(self.search_requests) == 0

        def on_timeout(self):
            for search_request in self.search_requests:
                search_request.on_timeout()

        @property
        def keywords(self):
            return self.search_requests[0].keywords

        @property
        def created_by_me(self):
            return self.search_requests[0].created_by_me

    def create_search(self, keywords, callback, number=None, ttl=None, nrcandidates=None, bloomfilter=None, results=None, return_candidate=None, return_member=None):
        if ttl == None:
            if isinstance(self.ttl, tuple):
                _ttl = self.ttl[1]
            elif isinstance(self.ttl, int):
                _ttl = self.ttl
            else:
                _ttl = 1
        else:
            _ttl = ttl

        if nrcandidates == None:
            nrcandidates = self.neighbors

        if isinstance(nrcandidates, tuple):
            nrcandidates = randint(nrcandidates[0], nrcandidates[1])
        elif isinstance(nrcandidates, float):
            nrcandidates = int(ceil(_ttl * nrcandidates))

        if bloomfilter == None:
            bloomfilter = BloomFilter(0.01, 100)

        # put local results in bloomfilter
        if results == None:
            results = self._get_results(keywords, bloomfilter, True)

        # fetch requested candidates from previous forward
        if number is None:
            prev_mrequest = None
            ignore_candidates = set()
        else:
            prev_mrequest = self.request_cache.get(u"m-search-request", number)
            ignore_candidates = prev_mrequest.get_requested_candidates() if prev_mrequest else set()

        if return_member:
            ignore_candidates.add(return_member.mid)

        # impose upper limit for forwarding
        candidates = []

        if len(ignore_candidates) < 10:
            random_peers, taste_buddies = self.get_randompeers_tastebuddies(ignore_candidates)
            shuffle(taste_buddies)
            shuffle(random_peers)

            for _ in xrange(nrcandidates):
                # prefer taste buddies, fallback to random peers
                if taste_buddies:
                    candidate = taste_buddies.pop()
                elif random_peers:
                    candidate = random_peers.pop()
                else:
                    break

                candidates.append(candidate)

        if candidates:
            if prev_mrequest:
                assert prev_mrequest.keywords == keywords
                this_request = TTLSearchCommunity.SearchRequest(self, prev_mrequest.number, keywords, ttl or 7, callback, results, return_candidate, requested_candidates=candidates)
                this_mrequest = prev_mrequest
                this_mrequest.add_request(this_request)

            else:
                if number is None:
                    number = RandomNumberCache.find_unclaimed_identifier(self._request_cache, u"m-search-request")
                    if self.log_searches:
                        self.log_searches("search-statistics", identifier=number, keywords=keywords, created_by_me=True)

                this_request = TTLSearchCommunity.SearchRequest(self, number, keywords, ttl or 7, callback, results, return_candidate, requested_candidates=candidates)
                this_mrequest = self._request_cache.add(TTLSearchCommunity.MSearchRequest(number, this_request))

            # create request message
            meta = self.get_meta_message(u"search-request")
            message = meta.impl(authentication=(self._my_member,),
                                distribution=(self.global_time,), payload=(this_mrequest.number, _ttl, keywords, bloomfilter))
            self._dispersy._send(candidates, [message])

            if DEBUG:
                print >> sys.stderr, long(time()), "TTLSearchCommunity: sending search request for", keywords, "to", map(str, candidates)
        else:
            self.search_no_candidates_remain += 1

        return candidates, results, number

    def on_search(self, messages):
        for message in messages:
            if self.log_searches:
                self.log_searches("search-statistics", number=message.payload.identifier, cycle=self._request_cache.has(TTLSearchCommunity.MSearchRequest.create_identifier(message.payload.identifier)))

            number = message.payload.identifier
            keywords = message.payload.keywords
            bloomfilter = message.payload.bloom_filter

            if DEBUG:
                print >> sys.stderr, long(time()), "TTLSearchCommunity: got search request for", keywords

            # compute new ttl
            if isinstance(self.ttl, int):
                ttl = message.payload.ttl - 1

            elif isinstance(self.ttl, tuple):
                ttl = message.payload.ttl
                if ttl == self.ttl[0]:
                    ttl -= 0 if random() < self.fprob else 1
                elif ttl == self.ttl[1]:
                    ttl -= 0 if random() < self.prob else 1
                else:
                    ttl -= 1
            else:
                ttl = 7 if random() < self.ttl else 0

            forward_message = ttl > 0

            # detect cycle
            results = []
            mrequest = self._request_cache.get(u"m-search-request", number)
            if mrequest:
                self.search_cycle_detected += 1
                if mrequest.keywords != keywords:  # abort, return
                    forward_message = False
            else:
                results = self._get_results(keywords, bloomfilter, False)
                if not results and DEBUG:
                    print >> sys.stderr, long(time()), "TTLSearchCommunity: no results"

            # temp fake immediate response of peers
            # if results and self.log_searches:
            #     self.log_searches("search-response", identifier=message.payload.identifier)

            if forward_message:
                if DEBUG:
                    print >> sys.stderr, long(time()), "TTLSearchCommunity: ttl = %d, initial ttl = %d, forwarding (%f, %f)" % (ttl, message.payload.ttl, self.prob, self.fprob)

                callback = lambda keywords, newresults, candidate, mynumber = number: self._create_search_response(mynumber, newresults, candidate)
                candidates, _, _ = self.create_search(keywords, callback, number, ttl, self.fneighbors, bloomfilter, results, message.candidate, message.authentication.member)

                if DEBUG:
                    print >> sys.stderr, long(time()), "TTLSearchCommunity: ttl = %d, initial ttl = %d, forwarding, sent to %d candidates (identifier = %d, %f, %f) received from" % (ttl, message.payload.ttl, len(candidates), number, self.prob, self.fprob), message.candidate

                if len(candidates):
                    self.search_forward += len(candidates)
                else:
                    forward_message = False
            else:
                if DEBUG:
                    print >> sys.stderr, long(time()), "TTLSearchCommunity: not forwarding initial ttl = %d, replying to (identifier = %d)" % (message.payload.ttl, number), message.candidate

            if not forward_message:
                if DEBUG:
                    print >> sys.stderr, long(time()), "TTLSearchCommunity: returning"
                self._create_search_response(number, results, message.candidate)
                self.search_endpoint += 1

    def _get_results(self, keywords, bloomfilter, local):
        results = []
        dbresults = self._torrent_db.searchNames(keywords, local=local, keys=['infohash', 'T.name', 'T.length', 'T.num_files', 'T.category_id', 'T.creation_date', 'T.num_seeders', 'T.num_leechers', 'swift_hash', 'swift_torrent_hash'])
        if len(dbresults) > 0:
            for dbresult in dbresults:
                if not (bloomfilter and dbresult[0] in bloomfilter):
                    channel_details = dbresult[-10:]

                    dbresult = list(dbresult[:10])
                    dbresult[1] = unicode(dbresult[1])
                    dbresult[2] = long(dbresult[2])
                    dbresult[3] = int(dbresult[3])
                    dbresult[4] = [self._misc_db.categoryId2Name(dbresult[4]), ]
                    dbresult[5] = long(dbresult[5])
                    dbresult[6] = int(dbresult[6] or 0)
                    dbresult[7] = int(dbresult[7] or 0)
                    if dbresult[8]:
                        dbresult[8] = str(dbresult[8])
                    if dbresult[9]:
                        dbresult[9] = str(dbresult[9])

                    if channel_details[1]:
                        channel_details[1] = str(channel_details[1])
                    dbresult.append(channel_details[1])

                    results.append(tuple(dbresult))

                    if bloomfilter:
                        bloomfilter.add(dbresult[0])

                    if len(results) == 25:
                        break
        return results

    def _create_search_response(self, number, results, candidate):
        # create search-response message
        meta = self.get_meta_message(u"search-response")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), payload=(number, results))
        self._dispersy._send([candidate], [message])

        if DEBUG:
            print >> sys.stderr, long(time()), "SearchCommunity: returning", len(results), "results to", candidate

    def check_search_response(self, messages):
        for message in messages:
            accepted, _ = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            if not self._request_cache.has(u"m-search-request", message.payload.identifier):
                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchCommunity: got search response identifier not found", message.payload.identifier

                yield DropMessage(message, "invalid response identifier")
                continue

            yield message

    def on_search_response(self, messages):
        for message in messages:
            # fetch callback using identifier
            search_request = self._request_cache.get(u"m-search-request", message.payload.identifier)
            if search_request:
                if search_request.created_by_me and message.payload.results and self.log_searches:
                    self.log_searches("search-response", identifier=message.payload.identifier)

                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchCommunity: got search response for", search_request.keywords, len(message.payload.results), message.candidate

                if len(message.payload.results) > 0 and self.use_megacache:
                    self.search_megacachesize = self._torrent_db.on_search_response(message.payload.results)

                removeCache = search_request.on_success(message.authentication.member.mid, search_request.keywords, message.payload.results, message.candidate)
                if removeCache:
                    self._request_cache.pop(u"m-search-request", message.payload.identifier)

                # see if we need to join some channels
                channels = set([result[10] for result in message.payload.results if result[10]])
                if channels:
                    channels = self._get_unknown_channels(channels)

                    if DEBUG:
                        print >> sys.stderr, long(time()), "SearchCommunity: joining %d preview communities" % len(channels)

                    for cid in channels:
                        community = self._get_channel_community(cid)
                        community.disp_create_missing_channel(message.candidate, includeSnapshot=False)
            else:
                print >> sys.stderr, long(time()), "SearchCommunity: got search response for somehow the request is missing from the cache? Did we just pop?", sum(1 if message.payload.identifier == curmessage.payload.identifier else 0 for curmessage in messages)

    def on_torrent_request(self, messages):
        for message in messages:
            requested_packets = []
            for cid, torrents in message.payload.torrents.iteritems():
                requested_packets.extend(self._get_packets_from_infohashes(cid, torrents))

            if requested_packets:
                self._dispersy._send_packets([message.candidate], requested_packets,
                    self, "-caused by on-torrent-request-")

            if DEBUG:
                print >> sys.stderr, long(time()), long(time()), "SearchCommunity: got request for ", len(requested_packets), "torrents from", message.candidate

    def on_torrent(self, messages):
        for message in messages:
            self._torrent_db.addExternalTorrentNoDef(message.payload.infohash, message.payload.name, message.payload.files, message.payload.trackers, message.payload.timestamp, "DISP_SC", {'dispersy_id': message.packet_id})

    def get_nr_connections(self):
        return len(self.get_connections())

    def get_connections(self, nr=10, ignore_candidate=None):
        # use taste buddies and fill with random candidates
        candidates = set(self.yield_taste_buddies_candidates(ignore_candidate))
        if len(candidates) < nr:
            sock_addresses = set(candidate.sock_addr for candidate in candidates)
            if ignore_candidate:
                sock_addresses.add(ignore_candidate.sock_addr)

            for candidate in self.dispersy_yield_verified_candidates():
                if candidate.sock_addr not in sock_addresses:
                    candidates.add(candidate)
                    sock_addresses.add(candidate.sock_addr)

                if len(candidates) == nr:
                    break

        elif len(candidates) > nr:
            candidates = sample(candidates, nr)

        return candidates

    def get_randompeers_tastebuddies(self, ignore_candidates=set()):
        taste_buddies = list(self.yield_taste_buddies_candidates())

        random_peers = []
        sock_addresses = set(candidate.sock_addr for candidate in taste_buddies)
        for candidate in self.dispersy_yield_verified_candidates():
            if candidate.sock_addr not in sock_addresses:
                random_peers.append(candidate)
                sock_addresses.add(candidate.sock_addr)

        if ignore_candidates:
            _random_peers = []
            _taste_buddies = []
            for candidate in random_peers:
                add = True
                if candidate.get_member().mid in ignore_candidates:
                    add = False
                    break

                if add:
                    _random_peers.append(candidate)

            for candidate in taste_buddies:
                add = True
                if candidate.get_member().mid in ignore_candidates:
                    add = False
                    break

                if add:
                    _taste_buddies.append(candidate)

            return _random_peers, _taste_buddies
        return random_peers, taste_buddies

    def _get_channel_id(self, cid):
        assert isinstance(cid, str)
        assert len(cid) == 20

        return self._channelcast_db._db.fetchone(u"SELECT id FROM Channels WHERE dispersy_cid = ?", (buffer(cid),))

    def _get_unknown_channels(self, cids):
        assert all(isinstance(cid, str) for cid in cids)
        assert all(len(cid) == 20 for cid in cids)

        parameters = u",".join(["?"] * len(cids))
        known_cids = self._channelcast_db._db.fetchall(u"SELECT dispersy_cid FROM Channels WHERE dispersy_cid in (" + parameters + ")", map(buffer, cids))
        known_cids = map(str, known_cids)
        return [cid for cid in cids if cid not in known_cids]

    def _get_channel_community(self, cid):
        assert isinstance(cid, str)
        assert len(cid) == 20

        try:
            return self._dispersy.get_community(cid, True)
        except CommunityNotFoundException:
            return PreviewChannelCommunity.init_community(self._dispersy, self._dispersy.get_member(mid=cid), self._my_member, self.integrate_with_tribler)

    def _get_packets_from_infohashes(self, cid, infohashes):
        packets = []

        def add_packet(dispersy_id):
            if dispersy_id and dispersy_id > 0:
                try:
                    packet = self._get_packet_from_dispersy_id(dispersy_id)
                    if packet:
                        packets.append(packet)
                except RuntimeError:
                    pass

        if cid == self._master_member.mid:
            channel_id = None
        else:
            channel_id = self._get_channel_id(cid)

        for infohash in infohashes:
            dispersy_id = None

            # 1. try to find the torrentmessage for this cid, infohash combination
            if channel_id:
                dispersy_id = self._channelcast_db.getTorrentFromChannelId(channel_id, infohash, ['ChannelTorrents.dispersy_id'])
            else:
                torrent = self._torrent_db.getTorrent(infohash, ['dispersy_id', 'torrent_file_name'], include_mypref=False)
                if torrent:
                    dispersy_id = torrent['dispersy_id']

                    # 2. if still not found, create a new torrentmessage and return this one
                    if not dispersy_id and torrent['torrent_file_name'] and path.isfile(torrent['torrent_file_name']):
                        message = self.create_torrent(torrent['torrent_file_name'], store=True, update=False, forward=False)
                        if message:
                            packets.append(message.packet)
            add_packet(dispersy_id)
        return packets

    def _get_packet_from_dispersy_id(self, dispersy_id):
        # 1. get the packet
        try:
            packet, packet_id = self._dispersy.database.execute(u"SELECT sync.packet, sync.id FROM community JOIN sync ON sync.community = community.id WHERE sync.id = ?", (dispersy_id,)).next()
        except StopIteration:
            raise RuntimeError("Unknown dispersy_id")

        return str(packet)

class SearchCommunity(HForwardCommunity, TTLSearchCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, ttl=TTL, neighbors=NEIGHBORS, fneighbors=FNEIGHBORS, prob=FPROB, log_searches=False, use_megacache=True, max_prefs=None, max_fprefs=None):
        TTLSearchCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, ttl, neighbors, fneighbors, prob, log_searches, use_megacache)
        HForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 0, max_prefs, max_fprefs)

    def initiate_conversions(self):
        return HForwardCommunity.initiate_conversions(self) + [SearchConversion(self)]

    def initiate_meta_messages(self):
        return TTLSearchCommunity.initiate_meta_messages(self) + HForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        TTLSearchCommunity._initialize_meta_messages(self)
        HForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        HForwardCommunity.unload_community(self)
        TTLSearchCommunity.unload_community(self)

class PSearchCommunity(PForwardCommunity, TTLSearchCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, ttl=TTL, neighbors=NEIGHBORS, fneighbors=FNEIGHBORS, prob=FPROB, log_searches=False, use_megacache=True, max_prefs=None, max_fprefs=None):
        TTLSearchCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, ttl, neighbors, fneighbors, prob, log_searches, use_megacache)
        PForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs)

    def initiate_conversions(self):
        return PForwardCommunity.initiate_conversions(self) + [SearchConversion(self)]

    def initiate_meta_messages(self):
        return TTLSearchCommunity.initiate_meta_messages(self) + PForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        TTLSearchCommunity._initialize_meta_messages(self)
        PForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        PForwardCommunity.unload_community(self)
        TTLSearchCommunity.unload_community(self)

class HSearchCommunity(HForwardCommunity, TTLSearchCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, ttl=TTL, neighbors=NEIGHBORS, fneighbors=FNEIGHBORS, prob=FPROB, log_searches=False, use_megacache=True, max_prefs=None, max_fprefs=None):
        TTLSearchCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, ttl, neighbors, fneighbors, prob, log_searches, use_megacache)
        HForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs)

    def initiate_conversions(self):
        return HForwardCommunity.initiate_conversions(self) + [SearchConversion(self)]

    def initiate_meta_messages(self):
        return TTLSearchCommunity.initiate_meta_messages(self) + HForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        TTLSearchCommunity._initialize_meta_messages(self)
        HForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        HForwardCommunity.unload_community(self)
        TTLSearchCommunity.unload_community(self)

class PoliSearchCommunity(PoliForwardCommunity, TTLSearchCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, ttl=TTL, neighbors=NEIGHBORS, fneighbors=FNEIGHBORS, prob=FPROB, log_searches=False, use_megacache=True, max_prefs=None, max_fprefs=None):
        TTLSearchCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, ttl, neighbors, fneighbors, prob, log_searches, use_megacache)
        PoliForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs)

    def initiate_conversions(self):
        return PoliForwardCommunity.initiate_conversions(self) + [SearchConversion(self)]

    def initiate_meta_messages(self):
        return TTLSearchCommunity.initiate_meta_messages(self) + PoliForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        TTLSearchCommunity._initialize_meta_messages(self)
        PoliForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        PoliForwardCommunity.unload_community(self)
        TTLSearchCommunity.unload_community(self)

class Das4DBStub():

    def __init__(self, dispersy):
        self._dispersy = dispersy

        try:
            # python 2.7 only...
            from collections import OrderedDict
        except ImportError:
            from python27_ordereddict import OrderedDict

        self.myMegaCache = OrderedDict()
        self.myTorrentCache = {}
        self.id2category = {1:u''}

    def searchNames(self, keywords, local=True, keys=[]):
        my_preferences = {}

        for infohash, is_local in self.myTorrentCache.iteritems():
            if local and not is_local:
                continue
            my_preferences[infohash] = u"%s %d" % self._dispersy._lan_address

        for infohash, results in self.myMegaCache.iteritems():
            if infohash not in my_preferences:
                my_preferences[infohash] = results[1]

        results = []
        for keyword in keywords:
            keyword = str(keyword)
            if keyword in my_preferences:
                results.append((keyword, unicode(my_preferences[keyword]), 1L, 1, 1, 0L, 0, 0, None, None, None, None, '', '', 0, 0, 0, 0, 0, False))
        return results

    def on_search_response(self, results):
        for result in results:
            assert isinstance(result[0], str), type(result[0])
            if result[0] not in self.myMegaCache:
                self.myMegaCache[result[0]] = (result[0], result[1], 0, 0, 0, time())
        return len(self.myMegaCache)

    def addTorrent(self, infohash, local=True):
        assert isinstance(infohash, str), type(infohash)
        self.myTorrentCache[infohash] = local

    def deleteTorrent(self, infohash, delete_file=False, commit=True):
        assert isinstance(infohash, str), type(infohash)
        if infohash in self.myMegaCache:
            del self.myMegaCache[infohash]

########NEW FILE########
__FILENAME__ = conversion
from struct import pack, unpack_from
from random import choice, sample
from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.dispersy.message import DropPacket
from Tribler.dispersy.conversion import NoDefBinaryConversion
from Tribler.dispersy.bloomfilter import BloomFilter


class SearchConversion(NoDefBinaryConversion):

    def __init__(self, community):
        super(SearchConversion, self).__init__(community, "\x02")
        self.define_meta_message(chr(1), community.get_meta_message(u"search-request"), lambda message: self._encode_decode(self._encode_search_request, self._decode_search_request, message), self._decode_search_request)
        self.define_meta_message(chr(2), community.get_meta_message(u"search-response"), lambda message: self._encode_decode(self._encode_search_response, self._decode_search_response, message), self._decode_search_response)
        self.define_meta_message(chr(3), community.get_meta_message(u"torrent-request"), lambda message: self._encode_decode(self._encode_torrent_request, self._decode_torrent_request, message), self._decode_torrent_request)

    def _encode_search_request(self, message):
        packet = pack('!HH', message.payload.identifier, message.payload.ttl), message.payload.keywords
        if message.payload.bloom_filter:
            packet = packet + (message.payload.bloom_filter.functions, message.payload.bloom_filter.prefix, message.payload.bloom_filter.bytes)
        packet = encode(packet)
        return packet,

    def _decode_search_request(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the search-payload")

        if len(payload) < 2:
            raise DropPacket("Invalid payload length")

        identifier, keywords = payload[:2]

        if len(identifier) != 4:
            raise DropPacket("Unable to decode the search-payload, got %d bytes expected 4" % (len(identifier)))
        identifier, ttl = unpack_from('!HH', identifier)

        if not isinstance(keywords, list):
            raise DropPacket("Invalid 'keywords' type")
        for keyword in keywords:
            if not isinstance(keyword, unicode):
                raise DropPacket("Invalid 'keyword' type")

        if len(payload) == 5:
            functions, prefix, bytes_ = payload[2:5]

            if not isinstance(functions, int):
                raise DropPacket("Invalid functions type")
            if not 0 < functions:
                raise DropPacket("Invalid functions value")

            size = len(bytes_)
            if not 0 < size:
                raise DropPacket("Invalid size of bloomfilter")
            if not size % 8 == 0:
                raise DropPacket("Invalid size of bloomfilter, must be a multiple of eight")

            if not isinstance(prefix, str):
                raise DropPacket("Invalid prefix type")
            if not 0 <= len(prefix) < 256:
                raise DropPacket("Invalid prefix length")

            bloom_filter = BloomFilter(bytes_, functions, prefix=prefix)
        else:
            bloom_filter = None

        return offset, placeholder.meta.payload.implement(identifier, ttl, keywords, bloom_filter)

    def _encode_search_response(self, message):
        packet = pack('!H', message.payload.identifier), message.payload.results
        return encode(packet),

    def _decode_search_response(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the search-reponse-payload")

        if len(payload) < 2:
            raise DropPacket("Invalid payload length")

        identifier, results = payload[:2]

        if len(identifier) != 2:
            raise DropPacket("Unable to decode the search-response-payload, got %d bytes expected 2" % (len(identifier)))
        identifier, = unpack_from('!H', identifier)

        if not isinstance(results, list):
            raise DropPacket("Invalid 'results' type")

        for result in results:
            if not isinstance(result, tuple):
                raise DropPacket("Invalid result type")

            if len(result) < 11:
                raise DropPacket("Invalid result length")

            infohash, swarmname, length, nrfiles, categorykeys, creation_date, seeders, leechers, swift_hash, swift_torrent_hash, cid = result[:11]

            if not isinstance(infohash, str):
                raise DropPacket("Invalid infohash type")
            if len(infohash) != 20:
                raise DropPacket("Invalid infohash length")

            if not isinstance(swarmname, unicode):
                raise DropPacket("Invalid swarmname type")

            if not isinstance(length, long):
                raise DropPacket("Invalid length type '%s'" % type(length))

            if not isinstance(nrfiles, int):
                raise DropPacket("Invalid nrfiles type")

            if not isinstance(categorykeys, list):
                raise DropPacket("Invalid categorykeys type")

            if not all(isinstance(key, unicode) for key in categorykeys):
                raise DropPacket("Invalid categorykey type")

            if not isinstance(creation_date, long):
                raise DropPacket("Invalid creation_date type")

            if not isinstance(seeders, int):
                raise DropPacket("Invalid seeders type '%s'" % type(seeders))

            if not isinstance(leechers, int):
                raise DropPacket("Invalid leechers type '%s'" % type(leechers))

            if swift_hash:
                if not isinstance(swift_hash, str):
                    raise DropPacket("Invalid swift_hash type '%s'" % type(swift_hash))

                if len(swift_hash) != 20:
                    raise DropPacket("Invalid swift_hash length")

            if swift_torrent_hash:
                if not isinstance(swift_torrent_hash, str):
                    raise DropPacket("Invalid swift_torrent_hash type")

                if len(swift_torrent_hash) != 20:
                    raise DropPacket("Invalid swift_torrent_hash length")

            if cid:
                if not isinstance(cid, str):
                    raise DropPacket("Invalid cid type")

                if len(cid) != 20:
                    raise DropPacket("Invalid cid length")

        return offset, placeholder.meta.payload.implement(identifier, results)

    def _encode_torrent_request(self, message):
        max_len = self._community.dispersy_sync_bloom_filter_bits / 8

        def create_msg():
            return encode(message.payload.torrents)

        packet = create_msg()
        while len(packet) > max_len:
            community = choice(message.payload.torrents.keys())
            nrTorrents = len(message.payload.torrents[community])
            if nrTorrents == 1:
                del message.payload.torrents[community]
            else:
                message.payload.torrents[community] = set(sample(message.payload.torrents[community], nrTorrents - 1))

            packet = create_msg()
        return packet,

    def _decode_torrent_request(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the torrent-request")

        if not isinstance(payload, dict):
            raise DropPacket("Invalid payload type")

        for cid, infohashes in payload.iteritems():
            if not (isinstance(cid, str) and len(cid) == 20):
                raise DropPacket("Invalid 'cid' type or value")

            for infohash in infohashes:
                if not (isinstance(infohash, str) and len(infohash) == 20):
                    raise DropPacket("Invalid 'infohash' type or value")
        return offset, placeholder.meta.payload.implement(payload)

    def _encode_decode(self, encode, decode, message):
        result = encode(message)
        try:
            decode(None, 0, result[0])

        except DropPacket:
            raise
        except:
            pass
        return result

########NEW FILE########
__FILENAME__ = community
from Tribler.community.privatesearch.community import TTLSearchCommunity
from Tribler.community.privatesemantic.community import PoliForwardCommunity
from Tribler.community.privatesearch.oneswarm.SearchManager import SearchManager
from Tribler.community.privatesearch.oneswarm.OverlayManager import OverlayManager

from Tribler.dispersy.tool.lencoder import log
from Tribler.dispersy.destination import CandidateDestination
from Tribler.dispersy.distribution import DirectDistribution
from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.message import Message, DelayMessageByProof
from Tribler.dispersy.resolution import PublicResolution
from Tribler.dispersy.dispersydatabase import DispersyDatabase
from Tribler.community.privatesearch.oneswarm.payload import SearchCancelPayload
from Tribler.community.privatesearch.oneswarm.conversion import OneSwarmConversion
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.requestcache import RandomNumberCache

ENCRYPTION = True

class OneSwarmCommunity(TTLSearchCommunity):

    def initialize(self, integrate_with_tribler=True, log_searches=False, cancel_after=None):
        self.overlay_manager = OverlayManager(self)
        self.search_manager = SearchManager(self, self.overlay_manager, cancel_after)

    def initiate_meta_messages(self):
        messages = TTLSearchCommunity.initiate_meta_messages(self)
        messages.append(Message(self, u"search-cancel", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), SearchCancelPayload(), self._dispersy._generic_timeline_check, self.on_search_cancel))
        return messages

    def initiate_conversions(self):
        return [DefaultConversion(self), OneSwarmConversion(self)]

    def create_search(self, keywords, callback):
        identifier = RandomNumberCache.find_unclaimed_identifier(self._request_cache, u"search")
        if self.log_searches:
            self.log_searches("search-statistics", identifier=identifier, keywords=keywords, created_by_me=True)

        # create request message
        meta = self.get_meta_message(u"search-request")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), payload=(identifier, 0, keywords, None))

        # create a callback converter
        def callback_converter(wrapped_msg):
            msg = wrapped_msg.dispersy_msg

            if self.log_searches and msg.payload.results:
                self.log_searches("search-response", identifier=msg.payload.identifier)

            callback(keywords, msg.payload.results, msg.candidate)

        wrapped_candidates = self.search_manager.sendTextSearch(identifier, MessageWrapper(message, mine=True), callback_converter)
        return [wrapped_candidate.dispersy_source for wrapped_candidate in wrapped_candidates], [], identifier

    def on_search(self, messages):
        for message in messages:
            # making datastructures compatible
            connection = SourceWrapper(self, message.candidate)
            message = MessageWrapper(message)

            cycle = self.overlay_manager.handleSearch(message, connection, self.search_manager.handleIncomingSearch)
            if self.log_searches:
                self.log_searches("search-statistics", identifier=message.dispersy_msg.payload.identifier, cycle=cycle)

    def send_response(self, original_request, single_result):
        original_request = original_request.dispersy_msg
        self._create_search_response(original_request.payload.identifier, [single_result], original_request.candidate)

    def forward_response(self, response_msg, connection):
        self._dispersy._send([connection.dispersy_source], [response_msg.dispersy_msg])

    def check_search_response(self, messages):
        for message in messages:
            accepted, _ = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            yield message

    def on_search_response(self, messages):
        for message in messages:
            # making datastructures compatible
            connection = SourceWrapper(self, message.candidate)
            message = MessageWrapper(message)

            self.search_manager.handleIncomingSearchResponse(connection, message)

    def _create_cancel(self, identifier, mine=False):
        meta = self.get_meta_message(u"search-cancel")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), payload=(identifier,))

        return MessageWrapper(message, mine=mine)

    def on_search_cancel(self, messages):
        for message in messages:
            # making datastructures compatible
            connection = SourceWrapper(self, message.candidate)
            message = MessageWrapper(message)

            self.search_manager.handleIncomingSearchCancel(connection, message)

    def get_wrapped_connections(self, nr=10, ignore_candidate=None):
        return [SourceWrapper(self, connection) for connection in self.get_connections(nr, ignore_candidate)]

    def send_wrapped(self, connection, message):
        if not message.mine:
            self.search_forward += 1

        self.dispersy._send([connection.dispersy_source], [message.dispersy_msg])

class MessageWrapper:
    def __init__(self, dispersy_msg, mine=False):
        self.dispersy_msg = dispersy_msg
        self.mine = mine

    def getDescription(self):
        return " ".join(self.dispersy_msg.payload.keywords).strip()
    def getSearchString(self):
        return self.dispersy_msg.payload.keywords

    def getSearchID(self):
        return self.dispersy_msg.payload.identifier
    def getValueID(self):
        return self.__java_hashcode(self.getDescription())

    def __java_hashcode(self, s):
        h = 0
        for c in s:
            h = (31 * h + ord(c)) & 0xFFFFFFFF
            return ((h + 0x80000000) & 0xFFFFFFFF) - 0x80000000

    def getSize(self):
        return len(self.dispersy_msg.packet)

    def __str__(self):
        return str(self.dispersy_msg)

class SourceWrapper:
    def __init__(self, community, dispersy_source):
        self.community = community
        self.dispersy_source = dispersy_source

    def getRemoteFriend(self):
        return self

    def getNick(self):
        return str(self.dispersy_source)

    def isCanSeeFileList(self):
        return self.community.is_taste_buddy(self.dispersy_source)

    def getRemotePublicKeyHash(self):
        member = self.dispersy_source.get_member()
        if member:
            return member.mid
        return str(self.dispersy_source.sock_addr[1])

    def __str__(self):
        return str(self.dispersy_source)

class PoliOneSwarmCommunity(PoliForwardCommunity, OneSwarmCommunity):

    def __init__(self, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, log_searches=False, use_megacache=True, max_prefs=None, max_fprefs=None, cancel_after=None):
        OneSwarmCommunity.__init__(self, master, my_member, integrate_with_tribler, log_searches, cancel_after=cancel_after)
        PoliForwardCommunity.__init__(self, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs)

    def initiate_conversions(self):
        return PoliForwardCommunity.initiate_conversions(self) + OneSwarmCommunity.initiate_conversions(self)

    def initiate_meta_messages(self):
        return OneSwarmCommunity.initiate_meta_messages(self) + PoliForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        OneSwarmCommunity._initialize_meta_messages(self)
        PoliForwardCommunity._initialize_meta_messages(self)

########NEW FILE########
__FILENAME__ = conversion
from struct import pack, unpack_from
from Tribler.dispersy.message import DropPacket
from Tribler.dispersy.conversion import BinaryConversion
from Tribler.community.privatesearch.conversion import SearchConversion

class OneSwarmConversion(SearchConversion):
    def __init__(self, community):
        super(OneSwarmConversion, self).__init__(community)
        self.define_meta_message(chr(10), community.get_meta_message(u"search-cancel"), lambda message: self._encode_decode(self._encode_search_cancel, self._decode_search_cancel, message), self._decode_search_cancel)

    def _encode_search_cancel(self, message):
        return pack('!H', message.payload.identifier),

    def _decode_search_cancel(self, placeholder, offset, data):
        identifier, = unpack_from('!H', data, offset)
        offset += 2

        return offset, placeholder.meta.payload.implement(identifier)

    def _encode_decode(self, encode, decode, message):
        result = encode(message)
        try:
            decode(None, 0, result[0])

        except DropPacket:
            raise
        except:
            pass
        return result

########NEW FILE########
__FILENAME__ = OverlayManager
import sys
from hashlib import md5
from time import time
from random import getrandbits
from collections import defaultdict

DEBUG = False

# OneSwarm defaults
mForwardSearchProbability = 0.5
MAX_OUTGOING_SEARCH_RATE = 300
MAX_INCOMING_SEARCH_RATE = 1000 * 1.5

class OverlayManager:
    def __init__(self, community):
        self.community = community
        self.randomnessManager = RandomnessManager()

        self.receivedSearches = {}

        self.incomingSearchRate = defaultdict(lambda: Average(1000, 10))
        self.outgoingSearchRate = defaultdict(lambda: Average(1000, 10))

    def sendSearchOrCancel(self, search, skipQueue, forceSend):
        connections = self.community.get_wrapped_connections(10)
        if DEBUG:
            print >> sys.stderr, long(time()), "OverlayManager sending search/cancel to", len(connections), "connections"

        numSent = 0;
        for conn in connections:
            shouldSend = True
            if not forceSend:
                # Niels: not sure if this should be getSearchID() or using the keywords
                shouldSend = self.shouldForwardSearch(search.getSearchID(), conn)

            if shouldSend:
                if DEBUG:
                    print >> sys.stderr, "OverlayManager about to send a search to", conn
                self.sendSearch(conn, search, skipQueue)
                numSent += 1

                if DEBUG:
                    print >> sys.stderr, "OverlayManager sent a search to", conn

        # for searches sent by us, if we didn't send it to anyone try again but
        # without the randomness linitng who we are sending to
        if numSent == 0 and not forceSend:
            return self.sendSearchOrCancel(search, skipQueue, True)
        return connections

    def forwardSearchOrCancel(self, ignoreConn, msg):
        for connection in self.community.get_wrapped_connections(10, ignoreConn.dispersy_source):
            if DEBUG:
                print >> sys.stderr, long(time()), "OverlayManager forwarding search/cancel to:", connection

            if self.shouldForwardSearch(msg.getSearchID(), ignoreConn):
                self.sendSearch(connection, msg, False)

    def shouldForwardSearch(self, id, conn):
        if conn.getRemoteFriend().isCanSeeFileList():
            return True

        all = str(id) + conn.getRemotePublicKeyHash()
        randomVal = self.randomnessManager.getDeterministicRandomInt(all)
        if randomVal < 0:
            randomVal = -randomVal

        if randomVal < sys.maxint * mForwardSearchProbability:
            return True
        else:
            return False

    def sendSearch(self, connection, search, skipQueue):
        if (search.getSearchID(), connection.getRemotePublicKeyHash()) in self.receivedSearches:
            if DEBUG:
                print >> sys.stderr, long(time()), "OverlayManager not sending search, this search id is already received from this friend"
            return

        average = self.outgoingSearchRate[connection.getRemotePublicKeyHash()].getAverage()
        if average > MAX_OUTGOING_SEARCH_RATE:
            if DEBUG:
                print >> sys.stderr, long(time()), "OverlayManager dropping search, sending too fast"
            return

        self.outgoingSearchRate[connection.getRemotePublicKeyHash()].addValue(1);

        if DEBUG:
            print >> sys.stderr, long(time()), "OverlayManager forwarding text search:", search.getDescription()

        self.sendMessage(connection, search, skipQueue);

    def sendMessage(self, connection, message, skipQueue):
        self.community.send_wrapped(connection, message)

    def handleSearch(self, message, connection, callback):
        # possibleprune is always false for all incoming search messages
        # hence logic is removed

        self.incomingSearchRate[connection.getRemotePublicKeyHash()].addValue(1);
        average = self.incomingSearchRate[connection.getRemotePublicKeyHash()].getAverage()

        if average > MAX_INCOMING_SEARCH_RATE:
            if DEBUG:
                print >> sys.stderr, long(time()), "OverlayManager search spam detected, closing connection, friend banned for 10 min"
            return

        if DEBUG:
            print >> sys.stderr, long(time()), "OverlayManager incoming search. desc: ", connection.getNick(), ", rate=", average

        self.receivedSearches[(message.getSearchID(), connection.getRemotePublicKeyHash())] = time()
        return callback(connection, message)

class RandomnessManager:
    def __init__(self, secretBytes=None):
        if not secretBytes:
            self.secretBytes = getrandbits(20 * 8)
        else:
            self.secretBytes = secretBytes

    # returns a random int between 0 (inclusive) and n (exclusive) seeded by seedBytes
    def getDeterministicNextInt(self, seedlong, minValue, maxValue):
        randomInt = self.getDeterministicRandomInt(seedlong)
        if randomInt < 0:
            randomInt = -randomInt;

        return minValue + (randomInt % (maxValue - minValue))

    def getDeterministicRandomInt(self, seed):
        if self.secretBytes:
            # the implementation is slightly different to oneswarm, but basically does the same thing
            # first hash, then return the first 32 bits
            bitmask = (2 ** 31) - 1
            return long(md5(str(seed) + str(self.secretBytes)).hexdigest(), 16) & bitmask

    def getSecretBytes(self):
        return self.secretBytes

class Average:
    # refreshrate in ms, period in seconds
    def __init__(self, refreshRate, period):
        self.refreshRate = refreshRate / 1000
        self.period = period

        self.nbElements = self.period / self.refreshRate + 2
        self.lastUpdate = int(time() / self.refreshRate)
        self.values = [0] * self.nbElements

    def addValue(self, value):
        # we get the current time factor
        timeFactor = int(time() / self.refreshRate)

        # we first update the buffer
        self.update(timeFactor)

        # and then we add our value to the current element
        self.values[(timeFactor % self.nbElements)] += value

    def update(self, timeFactor):
        # If we have a really OLD lastUpdate, we could erase the buffer a
        # huge number of time, so if it's really old, we change it so we'll only
        # erase the buffer once.

        if self.lastUpdate < timeFactor - self.nbElements:
            self.lastUpdate = timeFactor - self.nbElements - 1;

        # For all values between lastUpdate + 1 (next value than last updated)
        # and timeFactor (which is the new value insertion position)
        for i in range(self.lastUpdate + 1, timeFactor):
            self.values[i % self.nbElements] = 0

        # We also clear the next value to be inserted (so on next time change...)
        self.values[(timeFactor + 1) % self.nbElements] = 0

        # And we update lastUpdate.
        self.lastUpdate = timeFactor

    def getAverage(self):
        return self.getSum() / float(self.period)

    def getSum(self):
        # We get the current timeFactor
        timeFactor = int(time() / self.refreshRate)

        # We first update the buffer
        self.update(timeFactor)

        # The sum of all elements used for the average.
        sum = 0

        # Starting on oldest one (the one after the next one)
        # Ending on last one fully updated (the one previous current one)
        for i in range(timeFactor + 2, timeFactor + self.nbElements + 1):
            # Simple addition
            sum += self.values[i % self.nbElements]

        return sum

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload

class SearchCancelPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)

            super(SearchCancelPayload.Implementation, self).__init__(meta)
            self._identifier = identifier

        @property
        def identifier(self):
            return self._identifier

########NEW FILE########
__FILENAME__ = SearchManager
# Written by Niels Zeilemaker
# conversion of SearchManager.java from OneSwarm
import sys
from Queue import Queue
from math import floor
from random import random, randint
from threading import Thread
from time import time, sleep
from traceback import print_exc

from twisted.internet import reactor


DEBUG = False

# OneSwarm defaults
f2f_search_forward_delay = 150
NO_FORWARD_FRAC_OF_MAX_UPLOAD = 0.9
NO_RESPONSE_TOTAL_FRAC_OF_MAX_UPLOAD = 0.9
NO_RESPONSE_TRANSPORT_FRAC_OF_MAX_UPLOAD = 0.75
NO_RESPONSE_TORRENT_AVERAGE_RATE = 10000

MAX_SEARCH_QUEUE_LENGTH = 100
MAX_OUTGOING_SEARCH_RATE = 300
MAX_SEARCH_AGE = 60

mMIN_RESPONSE_DELAY = 1
mMAX_RESPONSE_DELAY = 2

mMIN_DELAY_LINK_LATENCY = 1
mMAX_DELAY_LINK_LATENCY = 2

mMaxSearchResponsesBeforeCancel = 40

class SearchManager:

    def __init__(self, community, overlayManager, cancel_after=None):
        self.community = community
        self.overlayManager = overlayManager

        self.sentSearches = {}
        self.forwardedSearches = {}
        self.canceledSearches = {}
        self.recentSearches = set()
        self.delayedSearchQueue = DelayedSearchQueue(self, f2f_search_forward_delay)

        self.bloomSearchesBlockedCurr = 0
        self.bloomSearchesSentCurr = 0
        self.forwardedSearchNum = 0
        self.lastSearchAccountingFlush = time()

        if cancel_after:
            self.mMaxSearchResponsesBeforeCancel = cancel_after
        else:
            self.mMaxSearchResponsesBeforeCancel = mMaxSearchResponsesBeforeCancel

    def sendTextSearch(self, newSearchId, msg, callback):
        return self.sendSearch(newSearchId, msg, callback, True, False)

    def sendSearch(self, newSearchId, search, callback, skipQueue, forceSend):
        self.sentSearches[newSearchId] = SentSearch(search, callback)
        return self.overlayManager.sendSearchOrCancel(search, skipQueue, forceSend);

    def handleIncomingSearch(self, source, msg):
        if DEBUG:
            print >> sys.stderr, long(time()), "SearchManager got search:", msg.getDescription()

        if msg.getSearchID() in self.forwardedSearches:
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager message already forwarded"
            return True
        if msg.getSearchID() in self.sentSearches:
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager message is mine"
            return True
        if self.delayedSearchQueue.isQueued(msg):
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager message is scheduled to be forwarded"
            return True

        # only implementing textsearch
        shouldForward = self.handleTextSearch(source, msg)

        # check if we are at full capacity
        if not self.canForwardSearch():
            shouldForward = False

        if shouldForward:
            # ok, seems like we should attempt to forward this, put it in
            # the queue
            self.delayedSearchQueue.add(source, msg)

        return False

    def handleTextSearch(self, source, msg):
        shouldForward = True
        if DEBUG:
            print >> sys.stderr, long(time()), "SearchManager handleTextSearch:", msg.getDescription(), "from", source.getRemoteFriend().getNick()

        searchString = msg.getSearchString()

        # removed filtering, modified call to get results
        results = self.community._get_results(searchString, None, False)
        if DEBUG:
            print >> sys.stderr, long(time()), "SearchManager found matches", len(results)

        if len(results) > 0:
            if self.canRespondToSearch():
                for result in results:
                    task = DelayedSearchResponse(msg, result, self, self.community)
                    delay = self.getSearchDelayForInfohash(source.getRemoteFriend())
                    reactor.callFromThread(reactor.callLater, delay/1000.0, task.run)
            else:
                shouldForward = False
        return shouldForward


    """
     There are 2 possible explanations for getting a search response, either
     we got a response for a search we sent ourselves, or we got a response
     for a search we forwarded
    """
    def handleIncomingSearchResponse(self, source, msg):
        sentSearch = self.sentSearches.get(msg.getSearchID(), None)

        # first, if might be a search we sent
        if sentSearch:
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager got response to search:", sentSearch.getSearch().getDescription()

            # update response stats
            sentSearch.gotResponse()

            # check if we got enough search responses to cancel this search
            # we will still use the data, even if the search is canceled. I
            # mean, since it already made it here why not use it...

            if sentSearch.getResponseNum() > self.mMaxSearchResponsesBeforeCancel:
                # only send a cancel message once
                sendCancel = False
                if msg.getSearchID() not in self.canceledSearches:
                    self.canceledSearches[msg.getSearchID()] = time()

                    if DEBUG:
                        print >> sys.stderr, long(time()), "SearchManager canceling search", msg
                    sendCancel = True;

                if sendCancel:
                    self.overlayManager.sendSearchOrCancel(self.community._create_cancel(msg.getSearchID(), mine=True), True, False)

            sentSearch.callback(msg)

        # sentsearch == null
        else:
            # ok, this is for a search we forwarded
            search = self.forwardedSearches.get(msg.getSearchID(), None)
            if search == None:
                # Search responses after 60 seconds are dropped (not that unusual)
                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchManager got response for slow/unknown search:", source, ":", msg.getDescription()
                return

            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager got response to forwarded search:", search.getSearch().getDescription()

            if msg.getSearchID() in self.canceledSearches:
                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchManager not forwarding search, it is already canceled,", msg.getSearchID()
                return

            searcher = search.getSource()
            responder = source
            if search.getResponseNum() > mMaxSearchResponsesBeforeCancel:
                # we really shouldn't cancel other peoples searches, but if
                # they don't do it we have to
                self.canceledSearches[msg.getSearchID()] = time()

                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchManager sending cancel for someone elses search!, searcher=", searcher.getRemoteFriend(), " responder=", responder.getRemoteFriend(), ":\t", search

                self.overlayManager.forwardSearchOrCancel(source, self.community._create_cancel(msg.getSearchID()))

            else:
                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchManager forwarding response to", searcher.getRemoteFriend(), " responder=", responder.getRemoteFriend()

                # assuming honest connections during this experiment, not implementing overlay registering
                search.gotResponse()

                # send out the search
                self.community.forward_response(msg, searcher)

    def handleIncomingSearchCancel(self, source, msg):
        forward = False

        # if this is the first time we see the cancel, check if we
        # forwarded this search, if we did, send a cancel

        if msg.getSearchID() not in self.canceledSearches:
            self.canceledSearches[msg.getSearchID()] = time()

            # we only forward the cancel if we already sent the search
            if msg.getSearchID() in self.forwardedSearches:
                forward = True;
            else:
                if DEBUG:
                    print >> sys.stderr, long(time()), "SearchManager got search cancel for unknown search id"

        if forward:
            self.overlayManager.forwardSearchOrCancel(source, msg)

    def forwardSearch(self, source, search):
        # check if search is canceled or forwarded first
        searchID = search.getSearchID();
        if searchID in self.forwardedSearches:
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager not forwarding search, already forwarded. id:", searchID
            return

        if searchID in self.canceledSearches:
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager not forwarding search, cancel received. id:", searchID
            return

        valueID = search.getValueID();
        if (searchID, valueID) in self.recentSearches:
            self.bloomSearchesBlockedCurr += 1
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager not forwarding search, in recent filter. id:", searchID
            return

        self.bloomSearchesSentCurr += 1
        self.forwardedSearchNum += 1
        if DEBUG:
            print >> sys.stderr, long(time()), "SearchManager forwarding search", search.getDescription(), "id:", searchID

        self.forwardedSearches[searchID] = ForwardedSearch(source, search)
        self.recentSearches.add((searchID, valueID))

        self.overlayManager.forwardSearchOrCancel(source, search)

    def canForwardSearch(self):
        util = self.fracUpload()
        if util == -1 or util < NO_FORWARD_FRAC_OF_MAX_UPLOAD:
            return True
        else:
            if DEBUG:
                print >> sys.stderr, long(time()), "SearchManager not forwarding search (overloaded, util=", util, ")"
            return False

    def canRespondToSearch(self):
        totalUtil = self.fracUpload()
        if totalUtil == -1:
            return True

        # ok, check if we are using more than 90% of total
        if totalUtil < NO_RESPONSE_TOTAL_FRAC_OF_MAX_UPLOAD:
            return True

        transUtil = self.fracTransportUpload()
        # check if we are using more than 75% for transports
        if transUtil < NO_RESPONSE_TRANSPORT_FRAC_OF_MAX_UPLOAD:
            return True

        torrentAvgSpeed = self.getAverageUploadPerRunningTorrent()
        if torrentAvgSpeed == -1:
            return True

        if torrentAvgSpeed > NO_RESPONSE_TORRENT_AVERAGE_RATE:
            return True

        if DEBUG:
            print >> sys.stderr, long(time()), "SearchManager not responding to search (overloaded, util=", transUtil, ")"
        return False

    def isSearchCanceled(self, searchID):
        return searchID in self.canceledSearches

    def fracUpload(self):
        # TODO: fill some sane numbers here
        return -1

    def fracTransportUpload(self):
        # TODO: fill some sane numbers here
        return -1

    def getAverageUploadPerRunningTorrent(self):
        # TODO: fill some sane numbers here
        return -1

    def getSearchDelayForInfohash(self, destination):
        if destination.isCanSeeFileList():
            return 0.0
        else:
            searchDelay = randint(mMIN_RESPONSE_DELAY, mMAX_RESPONSE_DELAY)
            latencyDelay = randint(mMIN_DELAY_LINK_LATENCY, mMAX_DELAY_LINK_LATENCY)
            return float(searchDelay + latencyDelay)

class DelayedSearchResponse:
    def __init__(self, msg, result, search_manager, community):
        self.msg = msg
        self.result = result
        self.search_manager = search_manager
        self.community = community

    def run(self):
        if DEBUG:
            print >> sys.stderr, "DelayedSearchResponse, attempting to send search response", self.msg.getSearchID(), self.result

        if not self.search_manager.isSearchCanceled(self.msg.getSearchID()):
            if DEBUG:
                print >> sys.stderr, "DelayedSearchResponse, sending search response", self.msg.getSearchID(), self.result
            self.community.send_response(self.msg, self.result)

class ForwardedSearch:
    def __init__(self, source, search):
        self.source = source
        self.search = search

        self.responsesForwarded = 0
        self.initialized = time()

    def getAge(self):
        return time() - self.initialized

    def getResponseNum(self):
        return self.responsesForwarded

    def getSearch(self):
        return self.search

    def getSearchId(self):
        return self.search.getSearchID()

    def getSource(self):
        return self.source

    def gotResponse(self):
        self.responsesForwarded += 1

    def isTimedOut(self):
        return self.getAge() > MAX_SEARCH_AGE;

class SentSearch:
    def __init__(self, search, callback):
        self.search = search
        self.callback = callback
        self.responses = 0
        self.initialized = time()

    def getSearch(self):
        return self.search

    def getAge(self):
        return time() - self.initialized

    def getResponseNum(self):
        return self.responses

    def gotResponse(self):
        self.responses += 1

    def isTimedOut(self):
        return self.getAge() > MAX_SEARCH_AGE

class DelayedSearchQueue:
    def __init__(self, searchManager, delay):
        self.searchManager = searchManager
        self.mDelay = delay

        self.lastSearchesPerSecondLogTime = 0
        self.searchCount = 0;
        self.lastBytesPerSecondCount = 0;

        self.queue = Queue()
        self.queuedSearches = {}
        self.searchesPerFriend = {}

        self.t = DelayedSearchQueueThread(searchManager, self.queue, self.queuedSearches, self.searchesPerFriend)
        self.t.start()

    def add(self, source, search):
        if self.lastSearchesPerSecondLogTime + 1 < time():
            if DEBUG:
                print >> sys.stderr, long(time()), "DelayedSearchQueue searches/sec:", self.searchCount, "bytes:", self.lastBytesPerSecondCount, "searchQueueSize:", len(self.queuedSearches)

            self.lastSearchesPerSecondLogTime = time()
            self.searchCount = 0
            self.lastBytesPerSecondCount = 0

        self.searchCount += 1
        self.lastBytesPerSecondCount += search.getSize()

        # Flush the accounting info every 60 seconds
        if self.searchManager.lastSearchAccountingFlush + 60 < time():
            self.searchManager.lastSearchAccountingFlush = time()
            self.searchesPerFriend.clear()

        # If the search queue is more than half full, start dropping searches
        # proportional to how much of the total queue each person is consuming
        if len(self.queuedSearches) > 0.25 * MAX_SEARCH_QUEUE_LENGTH:
            if source.getRemoteFriend() in self.searchesPerFriend:
                outstanding = self.searchesPerFriend[source.getRemoteFriend()].v

                # We add a hard limit on the number of searches from any one person.
                if outstanding > 0.15 * MAX_SEARCH_QUEUE_LENGTH:
                    if DEBUG:
                        print >> sys.stderr, long(time()), "DelayedSearchQueue dropping due to 25% of total queue consumption", source.getRemoteFriend().getNick(), outstanding, "/", MAX_SEARCH_QUEUE_LENGTH
                    return

                # In other cases, we drop proportional to the consumption of the overall queue.
                acceptProb = float(outstanding) / float(len(self.queuedSearches))
                if random() < acceptProb:
                    if DEBUG:
                        print >> sys.stderr, long(time()), "DelayedSearchQueue *** RED for search from", source, "outstanding:", outstanding, "total:", len(self.queuedSearches)
                    return


        if len(self.queuedSearches) > MAX_SEARCH_QUEUE_LENGTH:
            if DEBUG:
                print >> sys.stderr, long(time()), "DelayedSearchQueue not forwarding search, queue length too large. id:", search.getSearchID()
            return

        if search.getSearchID() not in self.queuedSearches:
            if DEBUG:
                print >> sys.stderr, long(time()), "DelayedSearchQueue adding search to forward queue, will forward in " , self.mDelay, "ms"

            entry = DelayedSearchQueueEntry(search, source, time() + (self.mDelay / 1000.0))

            if source.getRemoteFriend() not in self.searchesPerFriend:
                self.searchesPerFriend[source.getRemoteFriend()] = MutableInteger()
            self.searchesPerFriend[source.getRemoteFriend()].v += 1

            if DEBUG:
                print >> sys.stderr, long(time()), "DelayedSearchQueue search for friend:", source.getRemoteFriend().getNick(), self.searchesPerFriend[source.getRemoteFriend()].v

            self.queuedSearches[search.getSearchID()] = entry
            self.queue.put(entry);
        elif DEBUG:
            print >> sys.stderr, long(time()), "DelayedSearchQueue search already in queue, not adding"

    def isQueued(self, search):
        return search.getSearchID() in self.queuedSearches

class DelayedSearchQueueThread(Thread):
    def __init__(self, searchManager, queue, queuedSearches, searchesPerFriend):
        Thread.__init__(self)
        self.searchManager = searchManager
        self.queue = queue
        self.queuedSearches = queuedSearches
        self.searchesPerFriend = searchesPerFriend

    def run(self):
        while True:
            try:
                e = self.queue.get()
                timeUntilSend = e.dontSendBefore - time()
                timeUntilSend *= 1000  # convert back to ms
                if timeUntilSend > 0:
                    if DEBUG:
                        print >> sys.stderr, long(time()), "DelayedSearchQueueThread: got search (", e.search.getDescription(), ") to forward, waiting ", timeUntilSend, "ms until sending"
                    sleep(timeUntilSend / 1000.0)  # convert back to s

                self.searchManager.forwardSearch(e.source, e.search)

                # remove the search from the queuedSearchesMap
                del self.queuedSearches[e.search.getSearchID()]

                # searchesPerFriend could have been  flushed while this
                # search was in the queue
                if e.source.getRemoteFriend() in self.searchesPerFriend:
                    self.searchesPerFriend[e.source.getRemoteFriend()].v -= 1

                # if we didn't sleep at all, sleep the min time between searches
                if timeUntilSend < 1:
                    ms = 1000.0 / MAX_OUTGOING_SEARCH_RATE
                    msFloor = int(floor(ms))
                    nanosLeft = int(round((ms - msFloor) * 1000000.0))

                    # we need to convert to seconds, as python accepts floats in sleep
                    sleepSeconds = (msFloor / 1000.0) + (nanosLeft / 1000000000.0)

                    if DEBUG:
                        print >> sys.stderr, long(time()), "DelayedSearchQueueThread sleeping", msFloor, "ms", nanosLeft, "ns or", sleepSeconds, "seconds in python-speak"

                    sleep(sleepSeconds)

            except:
                print_exc()

class DelayedSearchQueueEntry:
    def __init__(self, search, source, dontSendBefore):
        self.insertionTime = time()
        self.search = search
        self.source = source
        self.dontSendBefore = dontSendBefore

class MutableInteger:
    def __init__(self):
        self.v = 0

########NEW FILE########
__FILENAME__ = test_average
import unittest
from time import sleep

from Tribler.community.privatesearch.oneswarm.OverlayManager import Average

class TestAverage(unittest.TestCase):
    def setUp(self):
        self.average = Average(1000, 10)

    def tearDown(self):
        del self.average

    def test_add_value(self):
        self.average.addValue(1)
        self.average.addValue(2)

        assert self.average.getSum() == 3, self.average.getSum()

    def test_average(self):
        self.average.addValue(1)
        sleep(1)
        self.average.addValue(2)

        assert self.average.getSum() == 3, self.average.getSum()
        assert self.average.getAverage() == 0.3, self.average.getAverage()

    def test_cleanup(self):
        self.average.addValue(1)
        sleep(11)
        self.average.addValue(2)

        assert self.average.getSum() == 2, self.average.getSum()
        assert self.average.getAverage() == 0.2, self.average.getAverage()

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_randomness
import unittest
import sys

from random import randint

from Tribler.community.privatesearch.oneswarm.OverlayManager import RandomnessManager

class TestRandomness(unittest.TestCase):
    def setUp(self):
        self.randomness = RandomnessManager()

    def tearDown(self):
        del self.randomness

    def test_deterministic_random(self):
        val1 = self.randomness.getDeterministicRandomInt(1l)
        val2 = self.randomness.getDeterministicRandomInt(2l)
        val3 = self.randomness.getDeterministicRandomInt(2l)

        assert val2 == val3, (val2, val3)
        assert val1 != val2, (val1, val2)

    def test_deterministic_next(self):
        val1 = self.randomness.getDeterministicNextInt(1l, 0, 5)
        val2 = self.randomness.getDeterministicNextInt(2l, 0, 5)
        val3 = self.randomness.getDeterministicNextInt(2l, 0, 5)

        assert val2 == val3, (val2, val3)
        assert val1 != val2, (val1, val2)

        assert 0 <= val1 < 5, val1
        assert 0 <= val2 < 5, val2

    def test_secretbytes(self):
        randomness2 = RandomnessManager()
        assert self.randomness.getSecretBytes() != randomness2.getSecretBytes()

    def test_usecase(self):
        mForwardSearchProbability = 0.5
        yes = 0
        maxval = 0

        for _ in xrange(100000):
            id = randint(0, sys.maxint)
            all = str(id)

            randomVal = self.randomness.getDeterministicRandomInt(all)
            assert randomVal < sys.maxint, randomVal

            if randomVal < 0:
                randomVal = -randomVal

            if randomVal < sys.maxint * mForwardSearchProbability:
                yes += 1

            maxval = max(maxval, randomVal)

        assert 45000 < yes < 55000, yes

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload, IntroductionRequestPayload
from Tribler.dispersy.bloomfilter import BloomFilter

MAXLONG128 = (1 << 1024) - 1
MAXLONG256 = (1 << 2048) - 1

# Search stuffs
class SearchRequestPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, ttl, keywords, bloom_filter=None):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(ttl, int), type(ttl)
                assert isinstance(keywords, list), 'keywords should be list'
                for keyword in keywords:
                    assert isinstance(keyword, unicode), '%s is type %s' % (keyword, type(keyword))
                    assert len(keyword) > 0

                assert not bloom_filter or isinstance(bloom_filter, BloomFilter), type(bloom_filter)

            super(SearchRequestPayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._ttl = ttl
            self._keywords = keywords
            self._bloom_filter = bloom_filter

        @property
        def identifier(self):
            return self._identifier

        @property
        def ttl(self):
            return self._ttl

        @property
        def keywords(self):
            return self._keywords

        @property
        def bloom_filter(self):
            return self._bloom_filter


class SearchResponsePayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, results):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(results, list), type(results)
                for result in results:
                    assert isinstance(result, tuple), type(result)
                    assert len(result) > 10

                    infohash, swarmname, length, nrfiles, categorykeys, creation_date, seeders, leechers, swift_hash, swift_torrent_hash, cid = result[:11]
                    assert isinstance(infohash, str), type(infohash)
                    assert len(infohash) == 20, len(infohash)
                    assert isinstance(swarmname, unicode), type(swarmname)
                    assert isinstance(length, long), type(length)
                    assert isinstance(nrfiles, int), type(nrfiles)
                    assert isinstance(categorykeys, list), type(categorykeys)
                    assert all(isinstance(key, unicode) for key in categorykeys), categorykeys
                    assert isinstance(creation_date, long), type(creation_date)
                    assert isinstance(seeders, int), type(seeders)
                    assert isinstance(leechers, int), type(leechers)
                    assert not swift_hash or isinstance(swift_hash, str), type(swift_hash)
                    assert not swift_hash or len(swift_hash) == 20, swift_hash
                    assert not swift_torrent_hash or isinstance(swift_torrent_hash, str), type(swift_torrent_hash)
                    assert not swift_torrent_hash or len(swift_torrent_hash) == 20, swift_torrent_hash
                    assert not cid or isinstance(cid, str), type(cid)
                    assert not cid or len(cid) == 20, cid

            super(SearchResponsePayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._results = results

        @property
        def identifier(self):
            return self._identifier

        @property
        def results(self):
            return self._results


class TorrentRequestPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, torrents):
            if __debug__:
                assert isinstance(torrents, dict), type(torrents)
                for cid, infohashes in torrents.iteritems():
                    assert isinstance(cid, str)
                    assert len(cid) == 20
                    assert isinstance(infohashes, set)
                    assert not filter(lambda x: not isinstance(x, str), infohashes)
                    assert not filter(lambda x: not len(x) == 20, infohashes)
                    assert len(infohashes) > 0

            super(TorrentRequestPayload.Implementation, self).__init__(meta)
            self._torrents = torrents

        @property
        def torrents(self):
            return self._torrents


class TorrentPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, infohash, timestamp, name, files, trackers):
            assert isinstance(infohash, str), 'infohash is a %s' % type(infohash)
            assert len(infohash) == 20, 'infohash has length %d' % len(infohash)
            assert isinstance(timestamp, (int, long))

            assert isinstance(name, unicode)
            assert isinstance(files, tuple)
            for path, length in files:
                assert isinstance(path, unicode)
                assert isinstance(length, (int, long))

            assert isinstance(trackers, tuple)
            for tracker in trackers:
                assert isinstance(tracker, str), 'tracker is a %s' % type(tracker)

            super(TorrentPayload.Implementation, self).__init__(meta)
            self._infohash = infohash
            self._timestamp = timestamp
            self._name = name
            self._files = files
            self._trackers = trackers

        @property
        def infohash(self):
            return self._infohash

        @property
        def timestamp(self):
            return self._timestamp

        @property
        def name(self):
            return self._name

        @property
        def files(self):
            return self._files

        @property
        def trackers(self):
            return self._trackers

########NEW FILE########
__FILENAME__ = python27_ordereddict
# Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and pypy.
# Passes Python2.7's test suite and incorporates all the latest updates.

try:
    from thread import get_ident as _get_ident
except ImportError:
    from dummy_thread import get_ident as _get_ident

try:
    from _abcoll import KeysView, ValuesView, ItemsView
except ImportError:
    pass


class OrderedDict(dict):
    'Dictionary that remembers insertion order'
    # An inherited dict maps keys to values.
    # The inherited dict provides __getitem__, __len__, __contains__, and get.
    # The remaining methods are order-aware.
    # Big-O running times for all methods are the same as for regular dictionaries.

    # The internal self.__map dictionary maps keys to links in a doubly linked list.
    # The circular doubly linked list starts and ends with a sentinel element.
    # The sentinel element never gets deleted (this simplifies the algorithm).
    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].

    def __init__(self, *args, **kwds):
        '''Initialize an ordered dictionary.  Signature is the same as for
        regular dictionaries, but keyword arguments are not recommended
        because their insertion order is arbitrary.

        '''
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))
        try:
            self.__root
        except AttributeError:
            self.__root = root = []                     # sentinel node
            root[:] = [root, root, None]
            self.__map = {}
        self.__update(*args, **kwds)

    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
        'od.__setitem__(i, y) <==> od[i]=y'
        # Setting a new item creates a new link which goes at the end of the linked
        # list, and the inherited dictionary is updated with the new key/value pair.
        if key not in self:
            root = self.__root
            last = root[0]
            last[1] = root[0] = self.__map[key] = [last, root, key]
        dict_setitem(self, key, value)

    def __delitem__(self, key, dict_delitem=dict.__delitem__):
        'od.__delitem__(y) <==> del od[y]'
        # Deleting an existing item uses self.__map to find the link which is
        # then removed by updating the links in the predecessor and successor nodes.
        dict_delitem(self, key)
        link_prev, link_next, key = self.__map.pop(key)
        link_prev[1] = link_next
        link_next[0] = link_prev

    def __iter__(self):
        'od.__iter__() <==> iter(od)'
        root = self.__root
        curr = root[1]
        while curr is not root:
            yield curr[2]
            curr = curr[1]

    def __reversed__(self):
        'od.__reversed__() <==> reversed(od)'
        root = self.__root
        curr = root[0]
        while curr is not root:
            yield curr[2]
            curr = curr[0]

    def clear(self):
        'od.clear() -> None.  Remove all items from od.'
        try:
            for node in self.__map.itervalues():
                del node[:]
            root = self.__root
            root[:] = [root, root, None]
            self.__map.clear()
        except AttributeError:
            pass
        dict.clear(self)

    def popitem(self, last=True):
        '''od.popitem() -> (k, v), return and remove a (key, value) pair.
        Pairs are returned in LIFO order if last is true or FIFO order if false.

        '''
        if not self:
            raise KeyError('dictionary is empty')
        root = self.__root
        if last:
            link = root[0]
            link_prev = link[0]
            link_prev[1] = root
            root[0] = link_prev
        else:
            link = root[1]
            link_next = link[1]
            root[1] = link_next
            link_next[0] = root
        key = link[2]
        del self.__map[key]
        value = dict.pop(self, key)
        return key, value

    # -- the following methods do not depend on the internal structure --

    def keys(self):
        'od.keys() -> list of keys in od'
        return list(self)

    def values(self):
        'od.values() -> list of values in od'
        return [self[key] for key in self]

    def items(self):
        'od.items() -> list of (key, value) pairs in od'
        return [(key, self[key]) for key in self]

    def iterkeys(self):
        'od.iterkeys() -> an iterator over the keys in od'
        return iter(self)

    def itervalues(self):
        'od.itervalues -> an iterator over the values in od'
        for k in self:
            yield self[k]

    def iteritems(self):
        'od.iteritems -> an iterator over the (key, value) items in od'
        for k in self:
            yield (k, self[k])

    def update(*args, **kwds):
        '''od.update(E, **F) -> None.  Update od from dict/iterable E and F.

        If E is a dict instance, does:           for k in E: od[k] = E[k]
        If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
        Or if E is an iterable of items, does:   for k, v in E: od[k] = v
        In either case, this is followed by:     for k, v in F.items(): od[k] = v

        '''
        if len(args) > 2:
            raise TypeError('update() takes at most 2 positional '
                            'arguments (%d given)' % (len(args),))
        elif not args:
            raise TypeError('update() takes at least 1 argument (0 given)')
        self = args[0]
        # Make progressively weaker assumptions about "other"
        other = ()
        if len(args) == 2:
            other = args[1]
        if isinstance(other, dict):
            for key in other:
                self[key] = other[key]
        elif hasattr(other, 'keys'):
            for key in other.keys():
                self[key] = other[key]
        else:
            for key, value in other:
                self[key] = value
        for key, value in kwds.items():
            self[key] = value

    __update = update  # let subclasses override update without breaking __init__

    __marker = object()

    def pop(self, key, default=__marker):
        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.

        '''
        if key in self:
            result = self[key]
            del self[key]
            return result
        if default is self.__marker:
            raise KeyError(key)
        return default

    def setdefault(self, key, default=None):
        'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
        if key in self:
            return self[key]
        self[key] = default
        return default

    def __repr__(self, _repr_running={}):
        'od.__repr__() <==> repr(od)'
        call_key = id(self), _get_ident()
        if call_key in _repr_running:
            return '...'
        _repr_running[call_key] = 1
        try:
            if not self:
                return '%s()' % (self.__class__.__name__,)
            return '%s(%r)' % (self.__class__.__name__, self.items())
        finally:
            del _repr_running[call_key]

    def __reduce__(self):
        'Return state information for pickling'
        items = [[k, self[k]] for k in self]
        inst_dict = vars(self).copy()
        for k in vars(OrderedDict()):
            inst_dict.pop(k, None)
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def copy(self):
        'od.copy() -> a shallow copy of od'
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
        and values equal to v (which defaults to None).

        '''
        d = cls()
        for key in iterable:
            d[key] = value
        return d

    def __eq__(self, other):
        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
        while comparison to a regular mapping is order-insensitive.

        '''
        if isinstance(other, OrderedDict):
            return len(self)==len(other) and self.items() == other.items()
        return dict.__eq__(self, other)

    def __ne__(self, other):
        return not self == other

    # -- the following methods are only used in Python 2.7 --

    def viewkeys(self):
        "od.viewkeys() -> a set-like object providing a view on od's keys"
        return KeysView(self)

    def viewvalues(self):
        "od.viewvalues() -> an object providing a view on od's values"
        return ValuesView(self)

    def viewitems(self):
        "od.viewitems() -> a set-like object providing a view on od's items"
        return ItemsView(self)

########NEW FILE########
__FILENAME__ = community
# Written by Niels Zeilemaker
import sys
from binascii import hexlify
from collections import defaultdict, namedtuple
from hashlib import md5
from itertools import groupby
from random import sample, randint, shuffle, choice
from time import time

from Crypto.Random.random import StrongRandom
from twisted.internet import reactor
from twisted.internet.defer import inlineCallbacks
from twisted.internet.task import LoopingCall, deferLater

from .conversion import ForwardConversion, PSearchConversion, HSearchConversion, PoliSearchConversion
from .crypto.paillier import (paillier_add, paillier_init, paillier_encrypt, paillier_decrypt, paillier_polyval,
                              paillier_multiply, paillier_add_unenc)
from .crypto.polycreate import compute_coeff, polyval
from .crypto.rsa import rsa_init, rsa_encrypt, rsa_decrypt, rsa_compatible, hash_element
from .payload import *
from Tribler.community.privatesemantic.conversion import bytes_to_long, long_to_bytes
from Tribler.community.privatesemantic.database import SemanticDatabase
from Tribler.dispersy.authentication import MemberAuthentication, NoAuthentication
from Tribler.dispersy.candidate import CANDIDATE_WALK_LIFETIME, WalkCandidate, BootstrapCandidate, Candidate
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CandidateDestination
from Tribler.dispersy.distribution import DirectDistribution
from Tribler.dispersy.member import Member
from Tribler.dispersy.message import Message, DelayMessageByProof, DropMessage
from Tribler.dispersy.requestcache import NumberCache, IntroductionRequestCache, RandomNumberCache
from Tribler.dispersy.resolution import PublicResolution

DEBUG = False
DEBUG_VERBOSE = False
ENCRYPTION = True

PING_INTERVAL = CANDIDATE_WALK_LIFETIME / 5
PING_TIMEOUT = CANDIDATE_WALK_LIFETIME / 2
TIME_BETWEEN_CONNECTION_ATTEMPTS = 10.0

PSI_CARDINALITY, PSI_OVERLAP, PSI_AES = range(3)

class TasteBuddy():
    def __init__(self, overlap, sock_addr):
        assert isinstance(overlap, (list, int, long, float)), type(overlap)
        if isinstance(overlap, list):
            assert all(isinstance(cur_overlap, (int, long, float)) for cur_overlap in overlap)

        self.overlap = overlap
        self.sock_addr = sock_addr

    def update_overlap(self, other):
        if isinstance(self.overlap, list):
            if len(other.overlap) > len(self.overlap):
                self.overlap = other.overlap
        else:
            self.overlap = max(self.overlap, other.overlap)

    def does_overlap(self, preference):
        if isinstance(self.overlap, list):
            return preference in self.overlap
        return False

    def __cmp__(self, other):
        if isinstance(other, TasteBuddy):
            if isinstance(self.overlap, list):
                return cmp(len(self.overlap), len(other.overlap))
            return cmp(self.overlap, other.overlap)

        elif isinstance(other, int):
            if isinstance(self.overlap, list):
                return cmp(len(self.overlap), other)
            return cmp(self.overlap, other)

    def __str__(self):
        overlap = self.overlap
        if isinstance(self.overlap, list):
            overlap = len(overlap)
        return "TB_%s_%s" % (overlap, self.sock_addr)

    def __hash__(self):
        return hash(self.sock_addr)

class ActualTasteBuddy(TasteBuddy):
    def __init__(self, overlap, timestamp, candidate):
        assert isinstance(candidate, WalkCandidate), type(candidate)

        TasteBuddy.__init__(self, overlap, candidate.sock_addr)
        self.timestamp = timestamp
        self.candidate = candidate

    def should_cache(self):
        return self.candidate.connection_type == u"public"

    def time_remaining(self):
        too_old = time() - PING_TIMEOUT
        diff = self.timestamp - too_old
        return diff if diff > 0 else 0

    def __eq__(self, other):
        if isinstance(other, TasteBuddy):
            return self.sock_addr == other.sock_addr

        elif isinstance(other, Member):
            return other.mid == self.candidate.get_member().mid

        elif isinstance(other, Candidate):
            return self.candidate.sock_addr == other.sock_addr

        elif isinstance(other, tuple):
            return self.candidate.sock_addr == other

    def __str__(self):
        overlap = self.overlap
        if isinstance(self.overlap, list):
            overlap = len(overlap)
        return "ATB_%d_%s_%s" % (self.timestamp, overlap, self.candidate)

class PossibleTasteBuddy(TasteBuddy):
    def __init__(self, overlap, timestamp, candidate_mid, received_from):
        assert isinstance(timestamp, (long, float)), type(timestamp)
        assert isinstance(received_from, WalkCandidate), type(received_from)

        TasteBuddy.__init__(self, overlap, None)
        self.timestamp = timestamp
        self.candidate_mid = candidate_mid
        self.received_from = received_from

    def time_remaining(self):
        too_old = time() - PING_TIMEOUT
        diff = self.timestamp - too_old
        return diff if diff > 0 else 0

    def __eq__(self, other):
        if isinstance(other, Candidate):
            return self.received_from.sock_addr == other.sock_addr
        return self.candidate_mid == other.candidate_mid

    def __str__(self):
        overlap = self.overlap
        if isinstance(self.overlap, list):
            overlap = len(overlap)
        return "PTB_%d_%d_%s_%s" % (self.timestamp, overlap, self.candidate_mid.encode("HEX"), self.received_from)

    def __hash__(self):
        return hash(self.candidate_mid)

class ForwardCommunity():

    def initialize(self, integrate_with_tribler=True, encryption=ENCRYPTION, forward_to=10, max_prefs=None, max_fprefs=None, max_taste_buddies=10, psi_mode=PSI_CARDINALITY, send_simi_reveal=False):
        self.integrate_with_tribler = bool(integrate_with_tribler)
        self.encryption = bool(encryption)
        self.key = self.init_key()
        self.psi_mode = psi_mode

        if not max_prefs:
            max_len = 2 ** 16 - 60  # self.dispersy_sync_bloom_filter_bits
            max_prefs = max_len / self.key.encsize
            max_hprefs = max_len / 20
        else:
            max_hprefs = max_prefs

        if not max_fprefs:
            max_fprefs = max_prefs

        self.max_prefs = max_prefs
        self.max_h_prefs = max_hprefs
        self.max_f_prefs = max_fprefs

        self.forward_to = forward_to
        self.max_taste_buddies = max_taste_buddies

        self.send_simi_reveal = send_simi_reveal

        self.taste_buddies = []
        self.possible_taste_buddies = []
        self.requested_introductions = {}

        self.my_preference_cache = [None, None]

        self.create_time_encryption = 0.0
        self.create_time_decryption = 0.0
        self.receive_time_encryption = 0.0

        self.send_packet_size = 0
        self.forward_packet_size = 0
        self.reply_packet_size = 0

        if self.integrate_with_tribler:
            from Tribler.Core.CacheDB.SqliteCacheDBHandler import MyPreferenceDBHandler
            from Tribler.Core.CacheDB.Notifier import Notifier

            # tribler channelcast database
            self._mypref_db = MyPreferenceDBHandler.getInstance()
            self._notifier = Notifier.getInstance()
        else:
            self._mypref_db = Das4DBStub(self._dispersy)
            self._notifier = None

        self._peercache = SemanticDatabase(self._dispersy)
        self._peercache.open()

    def init_key(self):
        return rsa_init()

    def unload_community(self):
        self._peercache.close()

    def initiate_meta_messages(self):
        return [Message(self, u"similarity-reveal", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), SimiRevealPayload(), self.check_similarity_reveal, self.on_similarity_reveal),
                Message(self, u"ping", NoAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), PingPayload(), self._generic_timeline_check, self.on_ping),
                Message(self, u"pong", NoAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), PongPayload(), self.check_pong, self.on_pong)]

    def _initialize_meta_messages(self):
        ori = self._meta_messages[u"dispersy-introduction-request"]
        new = Message(self, ori.name, ori.authentication, ori.resolution, ori.distribution, ori.destination, ExtendedIntroPayload(), ori.check_callback, ori.handle_callback)
        self._meta_messages[u"dispersy-introduction-request"] = new

    def initiate_conversions(self):
        return [DefaultConversion(self), ForwardConversion(self)]

    def add_taste_buddies(self, new_taste_buddies):
        for new_taste_buddy in new_taste_buddies:
            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "ForwardCommunity: new taste buddy?", new_taste_buddy

            for taste_buddy in self.taste_buddies:
                if new_taste_buddy == taste_buddy:
                    if DEBUG_VERBOSE:
                        print >> sys.stderr, long(time()), "ForwardCommunity: new taste buddy? no equal to", new_taste_buddy, taste_buddy

                    taste_buddy.update_overlap(new_taste_buddy)
                    new_taste_buddies.remove(new_taste_buddy)
                    break

            # new peer
            else:
                if len(self.taste_buddies) < self.max_taste_buddies or new_taste_buddy > self.taste_buddies[-1]:
                    if DEBUG_VERBOSE:
                        print >> sys.stderr, long(time()), "ForwardCommunity: new taste buddy? yes adding to list"

                    self.taste_buddies.append(new_taste_buddy)
                    if "send_ping_requests" not in self._pending_tasks:
                        self._pending_tasks["send_ping_requests"] = lc = LoopingCall(self.create_ping_requests)
                        lc.start(PING_INTERVAL)

                elif DEBUG_VERBOSE:
                    print >> sys.stderr, long(time()), "ForwardCommunity: new taste buddy? no smaller than", new_taste_buddy, self.taste_buddies[-1]

                self.new_taste_buddy(new_taste_buddy)

        self.taste_buddies.sort(reverse=True)
        self.taste_buddies = self.taste_buddies[:self.max_taste_buddies]

        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "ForwardCommunity: current tastebuddy list", len(self.taste_buddies), map(str, self.taste_buddies)
        elif DEBUG:
            print >> sys.stderr, long(time()), "ForwardCommunity: current tastebuddy list", len(self.taste_buddies)

    def yield_taste_buddies(self, ignore_candidate=None):
        for i in range(len(self.taste_buddies) - 1, -1, -1):
            if self.taste_buddies[i].time_remaining() == 0:
                if DEBUG:
                    print >> sys.stderr, long(time()), "ForwardCommunity: removing tastebuddy too old", self.taste_buddies[i]
                self.taste_buddies.pop(i)

        taste_buddies = self.taste_buddies[:]
        shuffle(taste_buddies)
        ignore_sock_addr = ignore_candidate.sock_addr if ignore_candidate else None

        for taste_buddy in taste_buddies:
            if taste_buddy.overlap and taste_buddy.candidate.sock_addr != ignore_sock_addr:
                yield taste_buddy

    def yield_taste_buddies_candidates(self, ignore_candidate=None):
        for tb in self.yield_taste_buddies(ignore_candidate):
            yield tb.candidate

    def is_taste_buddy(self, candidate):
        for tb in self.yield_taste_buddies():
            if tb == candidate:
                return tb

    def is_taste_buddy_mid(self, mid):
        assert isinstance(mid, str), type(mid)
        assert len(mid) == 20, len(mid)

        for tb in self.yield_taste_buddies():
            if mid == tb.candidate.get_member().mid:
                return tb

    def is_taste_buddy_sock(self, sock_addr):
        for tb in self.yield_taste_buddies():
            if tb == sock_addr:
                return tb

    def is_overlapping_taste_buddy_mid(self, mid):
        assert isinstance(mid, str), type(mid)
        assert len(mid) == 20, len(mid)

        if self.is_taste_buddy_mid(mid):
            return True

        _mid = long(hexlify(mid), 16)
        for tb in self.yield_taste_buddies():
            if tb.does_overlap(_mid):
                return True

    def reset_taste_buddy(self, candidate):
        for tb in self.yield_taste_buddies():
            if tb == candidate:
                tb.timestamp = time()
                break

    def remove_taste_buddy(self, candidate):
        for tb in self.yield_taste_buddies():
            if tb == candidate:
                self.taste_buddies.remove(tb)
                break

    def new_taste_buddy(self, tb):
        # if we have any similarity, cache peer
        if tb.overlap and tb.should_cache():
            self._peercache.add_peer(tb.overlap, *tb.candidate.sock_addr)

    def add_possible_taste_buddies(self, possibles):
        if __debug__:
            for possible in possibles:
                assert isinstance(possible, PossibleTasteBuddy), type(possible)

        low_sim = self.get_least_similar_tb()
        for new_possible in possibles:
            if new_possible <= low_sim or self.is_taste_buddy_mid(new_possible.candidate_mid) or self.my_member.mid == new_possible.candidate_mid:
                possibles.remove(new_possible)
                continue

            for i, possible in enumerate(self.possible_taste_buddies):
                if possible == new_possible:
                    new_possible.update_overlap(possible)

                    # replace in list
                    self.possible_taste_buddies[i] = new_possible
                    break

            # new peer
            else:
                self.possible_taste_buddies.append(new_possible)

        self.possible_taste_buddies.sort(reverse=True)
        if DEBUG_VERBOSE and possibles:
            print >> sys.stderr, long(time()), "ForwardCommunity: got possible taste buddies, current list", len(self.possible_taste_buddies), map(str, self.possible_taste_buddies)
        elif DEBUG and possibles:
            print >> sys.stderr, long(time()), "ForwardCommunity: got possible taste buddies, current list", len(self.possible_taste_buddies)

    def clean_possible_taste_buddies(self):
        low_sim = self.get_least_similar_tb()
        for i in range(len(self.possible_taste_buddies) - 1, -1, -1):
            to_low_sim = self.possible_taste_buddies[i] <= low_sim
            to_old = self.possible_taste_buddies[i].time_remaining() == 0
            is_tb = self.is_taste_buddy_mid(self.possible_taste_buddies[i].candidate_mid)

            if to_low_sim or to_old or is_tb:
                if DEBUG:
                    print >> sys.stderr, long(time()), "ForwardCommunity: removing possible tastebuddy", long(time()), to_low_sim, to_old, is_tb, self.possible_taste_buddies[i]
                self.possible_taste_buddies.pop(i)

    def has_possible_taste_buddies(self, candidate):
        for possible in self.possible_taste_buddies:
            if possible == candidate:
                return True
        return False

    def get_least_similar_tb(self):
        if len(self.taste_buddies) == self.max_taste_buddies:
            return self.taste_buddies[-1]
        return 0

    def get_most_similar(self, candidate):
        assert isinstance(candidate, WalkCandidate), [type(candidate), candidate]

        self.clean_possible_taste_buddies()

        if self.possible_taste_buddies:
            most_similar = self.possible_taste_buddies.pop(0)
            return most_similar.received_from, most_similar.candidate_mid

        return candidate, None

    def get_connections(self, nr=10, ignore_candidate=None):
        # use taste buddies and fill with random candidates
        candidates = set(self.yield_taste_buddies_candidates(ignore_candidate))
        if len(candidates) < nr:
            sock_addresses = set(candidate.sock_addr for candidate in candidates)
            if ignore_candidate:
                sock_addresses.add(ignore_candidate.sock_addr)

            for candidate in self.dispersy_yield_verified_candidates():
                if candidate.sock_addr not in sock_addresses:
                    candidates.add(candidate)
                    sock_addresses.add(candidate.sock_addr)

                if len(candidates) == nr:
                    break

        elif len(candidates) > nr:
            candidates = sample(candidates, nr)

        return list(candidates)

    # connect to first nr peers in peercache
    def connect_to_peercache(self, nr=10, standins=10):
        payload = self.create_similarity_payload()
        if payload:
            tbs = self.get_tbs_from_peercache(nr, standins)
            if DEBUG:
                print >> sys.stderr, long(time()), "ForwardCommunity: connecting to", len(tbs), [str(tb_possibles[0]) for tb_possibles in tbs]

            @inlineCallbacks
            def attempt_to_connect(tbs):
                for tb in tbs:
                    candidate = self.get_candidate(tb.sock_addr, replace=False)
                    if not candidate:
                        candidate = self.create_candidate(tb.sock_addr, False, tb.sock_addr, tb.sock_addr, u"unknown")

                    if not self.is_taste_buddy_sock(candidate.sock_addr):
                        self.create_similarity_request(candidate, payload)

                    yield deferLater(reactor, TIME_BETWEEN_CONNECTION_ATTEMPTS, lambda: None)

                    if self.is_taste_buddy_sock(candidate.sock_addr):
                        break

            for i, tb_possibles in enumerate(tbs):
                self._pending_tasts["attempt to connect %d" % i] = reactor.callLater(0.005 * i, attempt_to_connect, tb_possibles)

        elif DEBUG:
            print >> sys.stderr, long(time()), "ForwardCommunity: no similarity_payload, cannot connect"

    def get_tbs_from_peercache(self, nr, standins):
        return [[TasteBuddy(overlap, (ip, port))] * standins for overlap, ip, port in self._peercache.get_peers()[:nr]]

    class SimilarityAttempt(RandomNumberCache):

        def __init__(self, community, requested_candidate):
            super(ForwardCommunity.SimilarityAttempt, self).__init__(community.request_cache, u"similarity-attempt")
            assert isinstance(requested_candidate, WalkCandidate), type(requested_candidate)
            self.community = community
            self.requested_candidate = requested_candidate

        @property
        def timeout_delay(self):
            return 10.5

        def on_timeout(self):
            self.community.send_introduction_request(self.requested_candidate)

    def create_introduction_request(self, destination, allow_sync):
        assert isinstance(destination, WalkCandidate), [type(destination), destination]

        if DEBUG:
            print >> sys.stderr, long(time()), "ForwardCommunity: creating intro request", isinstance(destination, BootstrapCandidate), self.is_taste_buddy(destination), self.has_possible_taste_buddies(destination)

        send = False
        if not isinstance(destination, BootstrapCandidate) and not self.is_taste_buddy(destination) and not self.has_possible_taste_buddies(destination):
            send = self.create_msimilarity_request(destination)

        if not send:
            self.send_introduction_request(destination, allow_sync=allow_sync)

    def create_similarity_payload(self):
        raise NotImplementedError()

    def process_similarity_response(self, candidate, candidate_mid, payload):
        raise NotImplementedError()
    def process_msimilarity_response(self, message):
        raise NotImplementedError()

    def create_msimilarity_request(self, destination):
        payload = self.create_similarity_payload()
        if payload:
            cache = self._request_cache.add(ForwardCommunity.SimilarityAttempt(self, destination))

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "ForwardCommunity: sending msimilarity request to", destination, "with identifier", cache.number

            self.send_msimilarity_request(destination, cache.number, payload)
            return True

        return False

    def send_msimilarity_request(self, destination, identifier, payload):
        assert isinstance(identifier, int), type(identifier)
        raise NotImplementedError()

    class MSimilarityRequest(NumberCache):

        def __init__(self, community, requesting_candidate, requested_candidates, force_number, send_reveal=False):
            NumberCache.__init__(self, community.request_cache, u"m-similarity-request", force_number)
            self.community = community

            self.requesting_candidate = requesting_candidate
            self.requested_candidates = requested_candidates

            self.received_candidates = set()
            self.received_lists = []
            self.isProcessed = False
            self.send_reveal = send_reveal

        @property
        def timeout_delay(self):
            return 7.0

        @property
        def cleanup_delay(self):
            return 0.0

        def add_response(self, candidate, member, response):
            if candidate:
                rcandidate = self.did_request(candidate)
                if rcandidate:
                    # we need to associated this candidate with this mid, apparently this is only done when receiving an induction response
                    rcandidate.associate(member)

                    if rcandidate not in self.received_candidates:
                        self.received_candidates.add(rcandidate)
                        self.received_lists.append((rcandidate, member.mid, response))

                elif DEBUG:
                    print >> sys.stderr, long(time()), "ForwardCommunity: did not send request to candidate", candidate, "ignoring response"

            else:
                self.my_response = response

        def did_request(self, candidate):
            if candidate:
                for rcandidate in self.requested_candidates:
                    if rcandidate.sock_addr == candidate.sock_addr:
                        return rcandidate
            return False

        def is_complete(self):
            return len(self.received_lists) == len(self.requested_candidates)

        def process(self):
            if not self.isProcessed:
                self.isProcessed = True

                if self.requesting_candidate:
                    if DEBUG_VERBOSE:
                        print >> sys.stderr, long(time()), "ForwardCommunity: processed MSimilarityRequest send msimilarity-response to", self.requesting_candidate, self.received_lists

                    self.community.request_cache.pop(self.prefix, self.number)
                    return self.community.send_msimilarity_response(self.requesting_candidate, self.number, self.my_response, self.received_lists)

                for response in self.received_lists:
                    overlap = self.community.process_similarity_response(response[0], response[1], response[2])

                    if self.send_reveal and overlap:
                        if DEBUG_VERBOSE:
                            print >> sys.stderr, long(time()), "ForwardCommunity: sending reveal to", self.requested_candidates
                        self.community.send_similarity_reveal(response[0], overlap)
                return 0

        def on_timeout(self):
            if not self.isProcessed:
                if DEBUG:
                    print >> sys.stderr, long(time()), "ForwardCommunity: timeout MSimilarityRequest", self.number, len(self.received_lists), len(self.requested_candidates), str(self.requested_candidates[0])

                self.process()

    def check_msimilarity_request(self, messages):
        for message in messages:
            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            if self._request_cache.has(u"similarity-attempt", message.payload.identifier):
                yield DropMessage(message, "send similarity attempt to myself?")
                continue

            if self._request_cache.has(u"m-similarity-request", message.payload.identifier):
                yield DropMessage(message, "currently processing another msimilarity request with this identifier")
                continue

            yield message

    def on_msimilarity_request(self, messages):
        for message in messages:
            # get candidates to forward requests to, excluding the requesting peer
            candidates = self.get_connections(self.forward_to, message.candidate)

            # create a register similarity request
            request = ForwardCommunity.MSimilarityRequest(self, message.candidate, candidates, message.payload.identifier)
            # TODO: this shouldn't be necessary, requires a change in dispersy
            request._number = message.payload.identifier
            assert request.number == message.payload.identifier, (request.number, message.payload.identifier)

            # add local response
            request.add_response(None, None, self.on_similarity_request([message], False))

            if candidates:
                # forward it to others
                self.send_similarity_request(candidates, message.payload.identifier, message.payload)
                self._request_cache.add(request)

            if request.is_complete():
                request.process()

    def create_similarity_request(self, destination, payload):
        cache = self._request_cache.add(ForwardCommunity.MSimilarityRequest(self, None, [destination], RandomNumberCache.find_unclaimed_identifier(self._request_cache, u"m-similarity-request"), self.send_simi_reveal))
        self.send_similarity_request([destination], cache.number, payload)

        if DEBUG:
            print >> sys.stderr, long(time()), "ForwardCommunity: send_similarity_request to", destination, cache.number

    def send_similarity_request(self, candidates, identifier, payload):
        raise NotImplementedError()

    def check_similarity_request(self, messages):
        for message in messages:
            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            if self._request_cache.has(u"similarity-attempt", message.payload.identifier):
                yield DropMessage(message, "got similarity request issued by myself?")
                continue

            if self._request_cache.has(u"m-similarity-request", message.payload.identifier):
                yield DropMessage(message, "got similarity request forwarded by myself?")
                continue

            yield message

    def on_similarity_request(self, messages, send_messages=True):
        raise NotImplementedError()

    def check_similarity_response(self, messages):
        for message in messages:
            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            request = self._request_cache.get(u"m-similarity-request", message.payload.identifier)
            if not request:
                yield DropMessage(message, "unknown identifier")
                continue

            if not request.did_request(message.candidate):
                yield DropMessage(message, "did not send request to this candidate")
                continue

            yield message

    def on_similarity_response(self, messages):
        for message in messages:
            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "ForwardCommunity: got similarity response from", message.candidate

            request = self._request_cache.get(u"m-similarity-request", message.payload.identifier)
            if request:
                request.add_response(message.candidate, message.authentication.member, message.payload)
                if request.is_complete():
                    self.reply_packet_size += request.process()

            elif DEBUG:
                print >> sys.stderr, long(time()), "ForwardCommunity: could not get msimilarity requestcache for", message.payload.identifier

    def send_msimilarity_response(self, requesting_candidate, identifier, my_response, received_responses):
        assert isinstance(identifier, int), type(identifier)
        raise NotImplementedError()

    def check_msimilarity_response(self, messages):
        for message in messages:
            accepted, proof = self._timeline.check(message)
            if not accepted:
                yield DelayMessageByProof(message)
                continue

            request = self._request_cache.get(u"similarity-attempt", message.payload.identifier)
            if not request:
                print >> sys.stderr, "cannot find", message.payload.identifier, self._request_cache._identifiers.keys()

                yield DropMessage(message, "unknown identifier")
                continue

            yield message

    def on_msimilarity_response(self, messages):
        for message in messages:
            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "ForwardCommunity: got msimilarity response from", message.candidate

            request = self._request_cache.pop(u"similarity-attempt", message.payload.identifier)
            if request:
                # replace message.candidate with WalkCandidate
                # TODO: this seems to be a bit dodgy
                message._candidate = request.requested_candidate

                overlap = self.process_msimilarity_response(message)
                if self.send_simi_reveal and overlap:
                    self.send_similarity_reveal(message.candidate, overlap)

                destination, introduce_me_to = self.get_most_similar(message.candidate)
                self.send_introduction_request(destination, introduce_me_to)

                if DEBUG and introduce_me_to:
                    print >> sys.stderr, long(time()), "ForwardCommunity: asking candidate %s to introduce me to %s after receiving similarities from %s" % (destination, introduce_me_to.encode("HEX"), message.candidate)
            elif DEBUG:
                print >> sys.stderr, long(time()), "ForwardCommunity: could not get similarity requestcache for", message.payload.identifier

    def send_similarity_reveal(self, destination, overlap):
        assert isinstance(destination, WalkCandidate), [type(destination), destination]
        assert isinstance(overlap, (list, int))

        meta_request = self.get_meta_message(u"similarity-reveal")
        request = meta_request.impl(authentication=(self.my_member,),
                                distribution=(self.global_time,),
                                destination=(destination,),
                                payload=(overlap,))
        self._dispersy._forward([request])

    def check_similarity_reveal(self, messages):
        for message in messages:
            yield message

    def on_similarity_reveal(self, messages):
        for message in messages:
            if not isinstance(message.candidate, WalkCandidate):
                candidate = self.create_candidate(message.candidate.sock_addr, message.candidate.tunnel, message.candidate.sock_addr, message.candidate.sock_addr, u"unknown")
                candidate.associate(message.authentication.member)
                message._candidate = candidate

            self.add_taste_buddies([ActualTasteBuddy(message.payload.overlap, time(), message.candidate)])

            if DEBUG:
                print >> sys.stderr, "GOT similarity reveal from", message.candidate, self.is_taste_buddy(message.candidate), message.payload.overlap

    def send_introduction_request(self, destination, introduce_me_to=None, allow_sync=True, advice=True):
        assert isinstance(destination, WalkCandidate), [type(destination), destination]
        assert not introduce_me_to or isinstance(introduce_me_to, str), type(introduce_me_to)

        cache = self._request_cache.add(IntroductionRequestCache(self, destination))
        destination.walk(time())

        if allow_sync:
            sync = self.dispersy_claim_sync_bloom_filter(cache)
        else:
            sync = None
        payload = (destination.sock_addr, self._dispersy._lan_address, self._dispersy._wan_address, advice, self._dispersy._connection_type, sync, cache.number, introduce_me_to)

        meta_request = self.get_meta_message(u"dispersy-introduction-request")
        request = meta_request.impl(authentication=(self.my_member,),
                                distribution=(self.global_time,),
                                destination=(destination,),
                                payload=payload)

        self._dispersy._forward([request])

        if DEBUG:
            print >> sys.stderr, long(time()), "ForwardCommunity: sending introduction-request to %s (%s,%s,%s)" % (destination, introduce_me_to.encode("HEX") if introduce_me_to else '', allow_sync, advice)


    def on_introduction_request(self, messages):
        for message in messages:
            introduce_me_to = ''
            if message.payload.introduce_me_to:
                candidate = self.get_walkcandidate(message)
                message._candidate = candidate

                if DEBUG:
                    ctb = self.is_taste_buddy(candidate)
                    print >> sys.stderr, "Got intro request from", ctb, ctb.overlap

                self.requested_introductions[candidate] = introduce_me_to = self.get_tb_or_candidate_mid(message.payload.introduce_me_to)

            if DEBUG:
                print >> sys.stderr, long(time()), "ForwardCommunity: got introduction request", message.payload.introduce_me_to.encode("HEX") if message.payload.introduce_me_to else '', introduce_me_to, self.requested_introductions

        Community.on_introduction_request(self, messages)

        if self._notifier:
            from Tribler.Core.simpledefs import NTFY_ACT_MEET, NTFY_ACTIVITIES, NTFY_INSERT
            for message in messages:
                self._notifier.notify(NTFY_ACTIVITIES, NTFY_INSERT, NTFY_ACT_MEET, "%s:%d" % message.candidate.sock_addr)

    def get_tb_or_candidate_mid(self, mid):
        tb = self.is_taste_buddy_mid(mid)
        if tb:
            return tb.candidate

        # no exact match, see if this is a friend
        _mid = long(hexlify(mid), 16)
        tbs = [tb for tb in self.yield_taste_buddies() if tb.does_overlap(_mid)]
        if tbs:
            tb = choice(tbs)
            return tb.candidate

        return self.get_candidate_mid(mid)

    def dispersy_get_introduce_candidate(self, exclude_candidate=None):
        if exclude_candidate:
            if exclude_candidate in self.requested_introductions:
                intro_me_candidate = self.requested_introductions[exclude_candidate]
                del self.requested_introductions[exclude_candidate]
                return intro_me_candidate

        return Community.dispersy_get_introduce_candidate(self, exclude_candidate)

    class PingRequestCache(RandomNumberCache):

        def __init__(self, community, requested_candidates):
            RandomNumberCache.__init__(self, community._request_cache, u"ping")
            self.community = community
            self.requested_candidates = requested_candidates
            self.received_candidates = set()

        def on_success(self, candidate):
            if self.did_request(candidate):
                self.received_candidates.add(candidate)

            return self.is_complete()

        def is_complete(self):
            return len(self.received_candidates) == len(self.requested_candidates)

        def did_request(self, candidate):
            # TODO: change if there's an __eq__ implemented in candidate
            return candidate.sock_addr in [rcandidate.sock_addr for rcandidate in self.requested_candidates]

        def on_timeout(self):
            for candidate in self.requested_candidates:
                if candidate not in self.received_candidates:
                    if DEBUG:
                        print >> sys.stderr, long(time()), "ForwardCommunity: no response on ping, removing from taste_buddies", candidate
                    self.community.remove_taste_buddy(candidate)

    def create_ping_requests(self):
        tbs = self.filter_tb(self.yield_taste_buddies())
        tbs = [tb.candidate for tb in tbs if tb.time_remaining() < PING_INTERVAL]

        if tbs:
            cache = self._request_cache.add(ForwardCommunity.PingRequestCache(self, tbs))
            self._create_pingpong(u"ping", tbs, cache.number)

    def on_ping(self, messages):
        for message in messages:
            self._create_pingpong(u"pong", [message.candidate], message.payload.identifier)

            self.reset_taste_buddy(message.candidate)

    def check_pong(self, messages):
        for message in messages:
            request = self._request_cache.get(u"ping", message.payload.identifier)
            if not request:
                yield DropMessage(message, "invalid response identifier")
                continue

            if not request.did_request(message.candidate):
                print >> sys.stderr, "did not send request to", message.candidate.sock_addr, [rcandidate.sock_addr for rcandidate in request.requested_candidates]
                yield DropMessage(message, "did not send ping to this candidate")
                continue

            yield message

    def on_pong(self, messages):
        for message in messages:
            request = self._request_cache.get(u"ping", message.payload.identifier)
            if request.on_success(message.candidate):
                self._request_cache.pop(u"ping", message.payload.identifier)

            self.reset_taste_buddy(message.candidate)

    def _create_pingpong(self, meta_name, candidates, identifier):
        meta = self.get_meta_message(meta_name)
        message = meta.impl(distribution=(self.global_time,), payload=(identifier,))
        self._dispersy._send(candidates, [message])

        if DEBUG:
            print >> sys.stderr, long(time()), "ForwardCommunity: send", meta_name, "to", len(candidates), "candidates:", map(str, candidates)

    def filter_tb(self, tbs):
        return list(tbs)

class PForwardCommunity(ForwardCommunity):

    def init_key(self):
        return paillier_init(ForwardCommunity.init_key(self))

    def initiate_meta_messages(self):
        messages = ForwardCommunity.initiate_meta_messages(self)
        messages.append(Message(self, u"msimilarity-request", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedVectorPayload(), self.check_msimilarity_request, self.on_msimilarity_request))
        messages.append(Message(self, u"similarity-request", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedVectorPayload(), self.check_similarity_request, self.on_similarity_request))
        messages.append(Message(self, u"msimilarity-response", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedSumsPayload(), self.check_msimilarity_response, self.on_msimilarity_response))
        messages.append(Message(self, u"similarity-response", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedSumPayload(), self.check_similarity_response, self.on_similarity_response))
        return messages

    def initiate_conversions(self):
        return [DefaultConversion(self), PSearchConversion(self)]

    def create_similarity_payload(self):
        t1 = time()

        global_vector = self.create_global_vector()
        str_global_vector = str(global_vector)
        if self.my_preference_cache[0] == str_global_vector:
            encrypted_vector = self.my_preference_cache[1]
        else:
            my_vector = self.get_my_vector(global_vector, local=True)
            if self.encryption:
                encrypted_vector = []
                for element in my_vector:
                    cipher = paillier_encrypt(self.key, element)
                    encrypted_vector.append(cipher)
            else:
                encrypted_vector = my_vector

            self.my_preference_cache = [str_global_vector, encrypted_vector]

        self.create_time_encryption += time() - t1

        if encrypted_vector:
            Payload = namedtuple('Payload', ['key_n', 'preference_list', 'global_vector'])
            return Payload(long(self.key.n), encrypted_vector, global_vector)
        return False

    def process_similarity_response(self, candidate, candidate_mid, payload):
        overlap = self.compute_overlap(payload._sum)
        self.add_taste_buddies([ActualTasteBuddy(overlap, time(), candidate)])
        return overlap

    def process_msimilarity_response(self, message):
        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "PSearchCommunity: got msimi response from", message.candidate, len(message.payload.sums)

        overlap = self.compute_overlap(message.payload._sum)
        self.add_taste_buddies([ActualTasteBuddy(overlap, time(), message.candidate)])

        _sums = [PossibleTasteBuddy(self.compute_overlap(_sum), time(), candidate_mid, message.candidate) for candidate_mid, _sum in message.payload.sums]
        if _sums:
            self.add_possible_taste_buddies(_sums)

        return overlap

    def compute_overlap(self, _sum):
        t1 = time()

        if self.encryption:
            _sum = paillier_decrypt(self.key, _sum)

        self.create_time_decryption += time() - t1

        return _sum

    def send_msimilarity_request(self, destination, identifier, payload):
        meta_request = self.get_meta_message(u"msimilarity-request")
        request = meta_request.impl(authentication=(self.my_member,),
                                distribution=(self.global_time,),
                                destination=(destination,),
                                payload=(identifier, payload.key_n, payload.preference_list, payload.global_vector))

        if self._dispersy._forward([request]):
            self.send_packet_size += len(request.packet)

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "PSearchCommunity: sending msimilarity request to", destination, "containing", len(payload.preference_list), "hashes"
            return True
        return False

    def send_similarity_request(self, candidates, identifier, payload):
        # forward it to others
        meta_request = self.get_meta_message(u"similarity-request")
        request = meta_request.impl(authentication=(self.my_member,),
                            distribution=(self.global_time,),
                            payload=(identifier, payload.key_n, payload.preference_list, payload.global_vector))

        if self._dispersy._send(candidates, [request]):
            self.forward_packet_size += len(request.packet) * len(candidates)

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "PSearchCommunity: sending similarity request to", map(str, candidates), "containing", len(payload.preference_list), "hashes"
            return True
        return False

    def on_similarity_request(self, messages, send_messages=True):
        t1 = time()

        for message in messages:
            user_vector = message.payload.preference_list
            global_vector = message.payload.global_vector
            my_vector = self.get_my_vector(global_vector)
            assert len(global_vector) == len(user_vector) and len(global_vector) == len(my_vector), "vector sizes not equal %d vs %d vs %d" % (len(global_vector), len(user_vector), len(my_vector))

            if self.encryption:
                _sum = 1l
                user_n2 = pow(message.payload.key_n, 2)

                for i, element in enumerate(user_vector):
                    if my_vector[i]:
                        _sum = paillier_add(_sum, element, user_n2)
            else:
                _sum = 0l
                for i, element in enumerate(user_vector):
                    if my_vector[i] and element:
                        _sum += 1

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "PSearchCommunity: calculated sum", _sum

            if send_messages:
                meta_request = self.get_meta_message(u"similarity-response")
                response = meta_request.impl(authentication=(self.my_member,),
                                        distribution=(self.global_time,),
                                        destination=(message.candidate,),
                                        payload=(message.payload.identifier, _sum))

                self._dispersy._forward([response])
            else:
                self.receive_time_encryption += time() - t1
                return _sum

        self.receive_time_encryption += time() - t1

    def send_msimilarity_response(self, requesting_candidate, identifier, my_sum, received_sums):
        assert isinstance(identifier, int), type(identifier)
        received_sums = [(mid, payload._sum) for _, mid, payload in received_sums]

        meta_request = self.get_meta_message(u"msimilarity-response")
        response = meta_request.impl(authentication=(self._my_member,),
                                distribution=(self.global_time,),
                                destination=(requesting_candidate,),
                                payload=(identifier, my_sum, received_sums))

        self._dispersy._forward([response])
        return len(response.packet)

    def create_global_vector(self):
        # 1. fetch my preferences
        global_vector = [long(preference) for preference in self._mypref_db.getMyPrefListInfohash(local=True) if preference]

        # 2. reduce/extend the vector in size
        if len(global_vector) > self.max_prefs:
            global_vector = sample(global_vector, self.max_prefs)

        elif len(global_vector) < self.max_prefs:
            global_vector += [0l] * (self.max_prefs - len(global_vector))

        assert len(global_vector) == self.max_prefs, 'vector sizes not equal'
        return global_vector

    def get_my_vector(self, global_vector, local=False):
        my_preferences = set([preference for preference in self._mypref_db.getMyPrefListInfohash(local=local) if preference])
        my_vector = [0l] * len(global_vector)
        for i, element in enumerate(global_vector):
            if element in my_preferences:
                my_vector[i] = 1l
        return my_vector

class HForwardCommunity(ForwardCommunity):

    def initiate_meta_messages(self):
        messages = ForwardCommunity.initiate_meta_messages(self)
        messages.append(Message(self, u"msimilarity-request", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), SimilarityRequest(), self.check_msimilarity_request, self.on_msimilarity_request))
        messages.append(Message(self, u"similarity-request", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), SimilarityRequest(), self.check_similarity_request, self.on_similarity_request))
        messages.append(Message(self, u"msimilarity-response", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), BundledEncryptedResponsePayload(), self.check_msimilarity_response, self.on_msimilarity_response))
        messages.append(Message(self, u"similarity-response", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedResponsePayload(), self.check_similarity_response, self.on_similarity_response))
        return messages

    def initiate_conversions(self):
        return [DefaultConversion(self), HSearchConversion(self)]

    def create_similarity_payload(self):
        t1 = time()

        myPreferences = [preference for preference in self._mypref_db.getMyPrefListInfohash() if preference]
        str_myPreferences = str(myPreferences)

        if self.my_preference_cache[0] == str_myPreferences:
            myPreferences = self.my_preference_cache[1]

        else:
            if len(myPreferences) > self.max_prefs:
                myPreferences = sample(myPreferences, self.max_prefs)
            shuffle(myPreferences)

            # 1. hash to limit size
            myPreferences = [hash_element(preference) for preference in myPreferences]

            # 2. convert to long
            myPreferences = [bytes_to_long(preference) for preference in myPreferences]

            # 3. encrypt
            if self.encryption:
                myPreferences = [rsa_encrypt(self.key, preference) for preference in myPreferences]

            self.my_preference_cache = [str_myPreferences, myPreferences]

        self.create_time_encryption += time() - t1

        if myPreferences:
            Payload = namedtuple('Payload', ['key_n', 'preference_list'])
            return Payload(long(self.key.n), myPreferences)

        return False

    def process_similarity_response(self, candidate, candidate_mid, payload):
        overlap = self.compute_overlap([payload.preference_list, payload.his_preference_list])
        self.add_taste_buddies([ActualTasteBuddy(overlap, time(), candidate)])
        return overlap

    def process_msimilarity_response(self, message):
        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "HSearchCommunity: got msimi response from", message.candidate, len(message.payload.bundled_responses)

        overlap = self.compute_overlap([message.payload.preference_list, message.payload.his_preference_list])
        self.add_taste_buddies([ActualTasteBuddy(overlap, time(), message.candidate)])

        possibles = []
        for candidate_mid, remote_response in message.payload.bundled_responses:
            possibles.append(PossibleTasteBuddy(self.compute_overlap(remote_response), time(), candidate_mid, message.candidate))

        self.add_possible_taste_buddies(possibles)
        return overlap

    def compute_overlap(self, lists):
        t1 = time()

        preference_list, his_preference_list = lists

        if self.encryption:
            preference_list = [rsa_decrypt(self.key, preference) for preference in preference_list]
        preference_list = [hash_element(preference) for preference in preference_list]

        assert all(isinstance(preference, str) for preference in preference_list)
        assert all(isinstance(his_preference, str) for his_preference in his_preference_list)

        overlap = 0
        for pref in preference_list:
            if pref in his_preference_list:
                overlap += 1

        self.create_time_decryption += time() - t1

        return overlap

    def send_msimilarity_request(self, destination, identifier, payload):
        meta_request = self.get_meta_message(u"msimilarity-request")
        request = meta_request.impl(authentication=(self.my_member,),
                                distribution=(self.global_time,),
                                destination=(destination,),
                                payload=(identifier, payload.key_n, payload.preference_list))

        if self._dispersy._forward([request]):
            self.send_packet_size += len(request.packet)

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "HSearchCommunity: sending msimilarity request to", destination, "containing", len(payload.preference_list), "hashes"
            return True
        return False

    def send_similarity_request(self, candidates, identifier, payload):
        # forward it to others
        meta_request = self.get_meta_message(u"similarity-request")
        request = meta_request.impl(authentication=(self.my_member,),
                            distribution=(self.global_time,),
                            payload=(identifier, payload.key_n, payload.preference_list[:self.max_f_prefs]))

        if self._dispersy._send(candidates, [request]):
            self.forward_packet_size += len(request.packet) * len(candidates)

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "PoliSearchCommunity: sending similarity request to", map(str, candidates), "containing", len(payload.preference_list), "hashes"

            return True
        return False

    def on_similarity_request(self, messages, send_messages=True):
        t1 = time()

        # 1. fetch my preferences
        myPreferences = [preference for preference in self._mypref_db.getMyPrefListInfohash(local=False) if preference]
        myListLen = len(myPreferences)

        # 2. use subset if we have to many preferences
        if myListLen > self.max_h_prefs:
            myPreferences = sample(myPreferences, self.max_h_prefs)

        # 3. hash to limit size
        myPreferences = [hash_element(preference) for preference in myPreferences]

        # 4. convert to long
        myPreferences = [bytes_to_long(preference) for preference in myPreferences]

        for message in messages:
            if self.encryption:
                # 5. construct a rsa key to encrypt my preferences
                his_n = message.payload.key_n
                fake_phi = his_n / 2
                compatible_key = rsa_compatible(his_n, fake_phi)

                # 6. encrypt hislist and mylist + hash mylist
                hisList = [rsa_encrypt(compatible_key, preference) for preference in message.payload.preference_list]
                myList = [hash_element(rsa_encrypt(compatible_key, preference)) for preference in myPreferences]

            else:
                hisList = message.payload.preference_list
                myList = [hash_element(preference) for preference in myPreferences]

            shuffle(hisList)
            shuffle(myList)
            if send_messages:
                # 5. create a messages, containing hislist encrypted with my compatible key and mylist only encrypted by the compatible key + hashed
                meta = self.get_meta_message(u"similarity-response")
                resp_message = meta.impl(authentication=(self._my_member,),
                                    distribution=(self.global_time,),
                                    destination=(message.candidate,),
                                    payload=(message.payload.identifier, hisList, myList))

                self._dispersy._forward([resp_message])

                if DEBUG_VERBOSE:
                    print >> sys.stderr, long(time()), "HSearchCommunity: sending similarity-response to", message.payload.identifier, message.candidate
            else:
                self.receive_time_encryption += time() - t1
                return hisList, myList

        self.receive_time_encryption += time() - t1

    def send_msimilarity_response(self, requesting_candidate, identifier, my_response, received_responses):
        assert isinstance(identifier, int), type(identifier)
        received_responses = [(mid, (payload.preference_list, payload.his_preference_list)) for _, mid, payload in received_responses]

        meta_request = self.get_meta_message(u"msimilarity-response")
        response = meta_request.impl(authentication=(self._my_member,),
                                distribution=(self.global_time,),
                                destination=(requesting_candidate,),
                                payload=(identifier, my_response, received_responses))

        self._dispersy._forward([response])
        return len(response.packet)

class PoliForwardCommunity(ForwardCommunity):

    def init_key(self):
        return paillier_init(ForwardCommunity.init_key(self))

    def initiate_conversions(self):
        return [DefaultConversion(self), PoliSearchConversion(self)]

    def initiate_meta_messages(self):
        messages = ForwardCommunity.initiate_meta_messages(self)
        messages.append(Message(self, u"msimilarity-request", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), PoliSimilarityRequest(), self.check_msimilarity_request, self.on_msimilarity_request))
        messages.append(Message(self, u"similarity-request", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), PoliSimilarityRequest(), self.check_similarity_request, self.on_similarity_request))
        messages.append(Message(self, u"msimilarity-response", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedPoliResponsesPayload(), self.check_msimilarity_response, self.on_msimilarity_response))
        messages.append(Message(self, u"similarity-response", MemberAuthentication(), PublicResolution(), DirectDistribution(), CandidateDestination(), EncryptedPoliResponsePayload(), self.check_similarity_response, self.on_similarity_response))
        return messages

    def create_similarity_payload(self):
        t1 = time()

        # 1. fetch my preferences
        myPreferences = [preference for preference in self._mypref_db.getMyPrefListInfohash() if preference]
        str_myPreferences = str(myPreferences)

        if self.my_preference_cache[0] == str_myPreferences:
            partitions = self.my_preference_cache[1]
        else:
            if len(myPreferences) > self.max_prefs:
                myPreferences = sample(myPreferences, self.max_prefs)
            shuffle(myPreferences)

            # convert our infohashes to 40 bit long
            bitmask = (2 ** 40) - 1
            myPreferences = [long(md5(str(infohash)).hexdigest(), 16) & bitmask for infohash in myPreferences]

            # partition the infohashes
            partitionmask = (2 ** 32) - 1
            myPreferences = [(int(val >> 32), val & partitionmask) for val in myPreferences]

            partitions = {}
            for partition, g in groupby(myPreferences, lambda x: x[0]):
                values = [value for _, value in list(g)]
                coeffs = compute_coeff(values)

                if self.encryption:
                    coeffs = [paillier_encrypt(self.key, coeff) for coeff in coeffs]
                else:
                    coeffs = [long(coeff) for coeff in coeffs]

                partitions[partition] = coeffs

            self.my_preference_cache = [str_myPreferences, partitions]

        self.create_time_encryption += time() - t1

        if partitions:
            Payload = namedtuple('Payload', ['key_n', 'key_g', 'coefficients'])
            return Payload(long(self.key.n), 0l if self.psi_mode == PSI_CARDINALITY else long(self.key.g), partitions)
        return False

    def process_similarity_response(self, candidate, candidate_mid, payload):
        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "PoliSearchCommunity: got simi response from", candidate, payload.identifier

        overlap = self.compute_overlap(payload.my_response)
        self.add_taste_buddies([ActualTasteBuddy(overlap, time(), candidate)])
        return overlap

    def process_msimilarity_response(self, message):
        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "PoliSearchCommunity: got msimi response from", message.candidate, len(message.payload.bundled_responses)

        overlap = self.compute_overlap(message.payload.my_response)
        self.add_taste_buddies([ActualTasteBuddy(overlap, time(), message.candidate)])

        possibles = []
        for candidate_mid, remote_response in message.payload.bundled_responses:
            possibles.append(PossibleTasteBuddy(self.compute_overlap(remote_response), time(), candidate_mid, message.candidate))

        self.add_possible_taste_buddies(possibles)
        return overlap

    def compute_overlap(self, evaluated_polynomial):
        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "PoliSearchCommunity: determining overlap", evaluated_polynomial

        t1 = time()

        decrypted_values = []
        if self.encryption:
            for py in evaluated_polynomial:
                decrypted_values.append(paillier_decrypt(self.key, py))
        else:
            decrypted_values = evaluated_polynomial

        self.create_time_decryption += time() - t1

        if self.psi_mode == PSI_CARDINALITY:
            overlap = sum(1 if value == 0 else 0 for value in decrypted_values)

        elif self.psi_mode == PSI_OVERLAP:
            bitmask = (2 ** 32) - 1
            myPreferences = set([preference for preference in self._mypref_db.getMyPrefListInfohash() if preference])
            myPreferences = dict([(long(md5(str(preference)).hexdigest(), 16) & bitmask, preference) for preference in myPreferences])

            overlap = [myPreferences[value] for value in decrypted_values if value in myPreferences]

        else:
            MAX_128 = (2 ** 129) - 1
            overlap = [value for value in decrypted_values if value < MAX_128]

            if all(value == overlap[0] for value in overlap):
                aes_key = overlap[0]
                overlap = len(overlap)

                assert aes_key == 42, [aes_key, 42]

        return overlap

    def send_msimilarity_request(self, destination, identifier, payload):
        meta_request = self.get_meta_message(u"msimilarity-request")
        request = meta_request.impl(authentication=(self.my_member,),
                                distribution=(self.global_time,),
                                destination=(destination,),
                                payload=(identifier, payload.key_n, payload.key_g, payload.coefficients))

        if self._dispersy._forward([request]):
            self.send_packet_size += len(request.packet)

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "PoliSearchCommunity: sending msimilarity request to", destination, "containing", len(payload.coefficients), "partitions and", sum(len(coeffs) for coeffs in payload.coefficients.itervalues()), "coefficients"

            return True
        return False

    def send_similarity_request(self, candidates, identifier, payload):
        coefficients = payload.coefficients.copy()
        if self.max_f_prefs != self.max_prefs:
            # modify the coefficients to at most forward max_f_prefs coefficients
            new_coefficients = {}
            while len(coefficients.keys()) > 0 and sum(len(coeffs) - 1 for coeffs in new_coefficients.itervalues()) < self.max_f_prefs:
                partition = choice(coefficients.keys())
                new_coefficients[partition] = coefficients[partition]
                del coefficients[partition]

            coefficients = new_coefficients

        # forward it to others
        meta_request = self.get_meta_message(u"similarity-request")
        request = meta_request.impl(authentication=(self.my_member,),
                            distribution=(self.global_time,),
                            payload=(identifier, payload.key_n, payload.key_g, coefficients))

        if self._dispersy._send(candidates, [request]):
            self.forward_packet_size += len(request.packet) * len(candidates)

            if DEBUG_VERBOSE:
                print >> sys.stderr, long(time()), "PoliSearchCommunity: sending similarity request to", map(str, candidates), "containing", len(coefficients), "partitions and", sum(len(coeffs) for coeffs in coefficients.itervalues()), "coefficients"
            return True
        return False

    def on_similarity_request(self, messages, send_messages=True):
        t1 = time()

        # 1. fetch my preferences
        myPreferences = [preference for preference in self._mypref_db.getMyPrefListInfohash(local=False) if preference]

        # 2. partition the preferences
        # convert our infohashes to 40 bit long
        bitmask = (2 ** 40) - 1
        myPreferences = [long(md5(str(infohash)).hexdigest(), 16) & bitmask for infohash in myPreferences]

        # partition the infohashes
        partitionmask = (2 ** 32) - 1
        myPreferences = [(int(val >> 32), val & partitionmask) for val in myPreferences]

        for message in messages:
            _myPreferences = [(partition, val) for partition, val in myPreferences if partition in message.payload.coefficients]

            if self.psi_mode == PSI_AES:
                # generate 128 bit session key
                aes_key = StrongRandom().getrandbits(128)
                aes_key = 42l

            results = []
            if self.encryption:
                user_n2 = pow(message.payload.key_n, 2)
                for partition, val in _myPreferences:
                    py = paillier_polyval(message.payload.coefficients[partition], val, user_n2)
                    py = paillier_multiply(py, randint(0, 2 ** self.key.size), user_n2)
                    if self.psi_mode == PSI_OVERLAP:
                        py = paillier_add_unenc(py, val, message.payload.key_g, user_n2)
                    elif self.psi_mode == PSI_AES:
                        py = paillier_add_unenc(py, aes_key, message.payload.key_g, user_n2)
                    results.append(py)
            else:
                for partition, val in _myPreferences:
                    py = polyval(message.payload.coefficients[partition], val)
                    py = py * randint(0, 2 ** self.key.size)
                    if self.psi_mode == PSI_OVERLAP:
                        py += val
                    elif self.psi_mode == PSI_AES:
                        py += aes_key
                    results.append(py)

            if len(results) > self.max_prefs:
                results = sample(results, self.max_prefs)
            else:
                shuffle(results)

            if send_messages:
                # 4. create a messages, containing the py values
                meta = self.get_meta_message(u"similarity-response")
                resp_message = meta.impl(authentication=(self._my_member,),
                                    distribution=(self.global_time,),
                                    destination=(message.candidate,),
                                    payload=(message.payload.identifier, results))

                self._dispersy._forward([resp_message])
                self.reply_packet_size += len(resp_message.packet)

                if DEBUG_VERBOSE:
                    print >> sys.stderr, long(time()), "PoliSearchCommunity: sending similarity-response to", message.payload.identifier, message.candidate, results
            else:
                self.receive_time_encryption += time() - t1
                return results

        self.receive_time_encryption += time() - t1

    def send_msimilarity_response(self, requesting_candidate, identifier, my_response, received_responses):
        assert isinstance(identifier, int), type(identifier)
        received_responses = [(mid, payload.my_response) for _, mid, payload in received_responses]

        meta_request = self.get_meta_message(u"msimilarity-response")
        response = meta_request.impl(authentication=(self._my_member,),
                                distribution=(self.global_time,),
                                destination=(requesting_candidate,),
                                payload=(identifier, my_response, received_responses))

        self._dispersy._forward([response])
        return len(response.packet)

    def get_most_similar(self, candidate):
        if self.psi_mode == PSI_CARDINALITY:
            return ForwardCommunity.get_most_similar(self, candidate)

        ctb = self.is_taste_buddy(candidate)
        if ctb and ctb.overlap:
            # see which peer i havn't made a connection to/have fewest connections with
            connections = defaultdict(int)
            for keyhash in ctb.overlap:
                connections[keyhash] += 1

            for tb in self.yield_taste_buddies(candidate):
                for keyhash in tb.overlap:
                    if keyhash in connections:
                        connections[keyhash] += 1

            ckeys = connections.keys()
            ckeys.sort(cmp=lambda a, b: cmp(connections[a], connections[b]))
            return candidate, long_to_bytes(ckeys[0], 20)

        return candidate, None

class Das4DBStub():
    def __init__(self, dispersy):
        self._dispersy = dispersy

        self.myPreferences = set()
        self.myTestPreferences = set()

        try:
            # python 2.7 only...
            from collections import OrderedDict
        except ImportError:
            from python27_ordereddict import OrderedDict

        self.id2category = {1:u''}

    def addMyPreference(self, preference, data):
        assert isinstance(preference, long), type(preference)
        self.myPreferences.add(preference)

    def addTestPreference(self, preference):
        assert isinstance(preference, long), type(preference)
        self.myTestPreferences.add(preference)

    def getMyPrefListInfohash(self, limit=None, local=True):
        preferences = self.myPreferences
        if not local:
            preferences = preferences | self.myTestPreferences
        preferences = list(preferences)

        if limit:
            return preferences[:limit]
        return preferences

########NEW FILE########
__FILENAME__ = conversion
from struct import pack, unpack_from
from random import choice, sample

from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.dispersy.message import DropPacket
from Tribler.dispersy.conversion import BinaryConversion
from Tribler.dispersy.bloomfilter import BloomFilter

from binascii import hexlify, unhexlify
def long_to_bytes(val, nrbytes=0):
    hex_val = '%x' % abs(val)
    if nrbytes:
        padding = '0' * ((abs(nrbytes) * 2) - len(hex_val))
    else:
        padding = ''
    result = unhexlify(padding + hex_val)[::-1]

    if nrbytes < 0:
        return ("-" if val < 0 else "+") + result
    return result

def bytes_to_long(val, nrbytes=0):
    if nrbytes < 0 and (val[0] == "-" or val[0] == "+"):
        _val = long(hexlify(val[1:][::-1]), 16)
        if val[0] == "-":
            return -_val
        return _val
    else:
        return long(hexlify(val[::-1]), 16)

class ForwardConversion(BinaryConversion):
    def __init__(self, community):
        super(ForwardConversion, self).__init__(community, "\x02")
        # we need to use 4 , 5, and 6 as we are combining this overlay with the searchcommunity which has 1,2,and 3 defined.
        self.define_meta_message(chr(4), community.get_meta_message(u"similarity-reveal"), lambda message: self._encode_decode(self._encode_simi_reveal, self._decode_simi_reveal, message), self._decode_simi_reveal)
        self.define_meta_message(chr(5), community.get_meta_message(u"ping"), lambda message: self._encode_decode(self._encode_ping, self._decode_ping, message), self._decode_ping)
        self.define_meta_message(chr(6), community.get_meta_message(u"pong"), lambda message: self._encode_decode(self._encode_pong, self._decode_pong, message), self._decode_pong)

    def _encode_simi_reveal(self, message):
        if isinstance(message.payload.overlap, int):
            return pack('!ci', 'I', message.payload.overlap),

        # convert long into string
        str_overlap = [long_to_bytes(overlap, 20) for overlap in message.payload.overlap]
        return pack('!c' + '20s' * len(message.payload.overlap), 'L', *str_overlap),

    def _decode_simi_reveal(self, placeholder, offset, data):
        if len(data) < offset + 1:
            raise DropPacket("Insufficient packet size")

        identifier, = unpack_from('!c', data, offset)
        offset += 1

        if identifier == 'I':
            overlap, = unpack_from('!i', data, offset)
            offset += 4
        else:
            length = len(data) - offset
            if length % 20 != 0:
                raise DropPacket("Invalid number of bytes available (sr)")

            if length:
                hashpack = '20s' * (length / 20)
                str_overlap = unpack_from('!' + hashpack, data, offset)
                overlap = [bytes_to_long(str_over) for str_over in str_overlap]
            else:
                overlap = []

            offset += length
        return offset, placeholder.meta.payload.implement(overlap)

    def _encode_ping(self, message):
        return pack('!H', message.payload.identifier),

    def _decode_ping(self, placeholder, offset, data):
        if len(data) < offset + 2:
            raise DropPacket("Insufficient packet size")

        identifier, = unpack_from('!H', data, offset)
        offset += 2

        return offset, placeholder.meta.payload.implement(identifier)

    def _encode_pong(self, message):
        return self._encode_ping(message)
    def _decode_pong(self, placeholder, offset, data):
        return self._decode_ping(placeholder, offset, data)

    def _encode_introduction_request(self, message):
        data = BinaryConversion._encode_introduction_request(self, message)

        if message.payload.introduce_me_to:
            data.insert(0, pack('!c20s', 'Y', message.payload.introduce_me_to))
        return data

    def _decode_introduction_request(self, placeholder, offset, data):
        has_introduce_me, = unpack_from('!c', data, offset)
        if has_introduce_me == 'Y':
            # we assume that it contains an introduce_me, doesn't have to be true
            offset += 1
            candidate_mid, = unpack_from('!20s', data, offset)
            offset += 20

            try:
                # no exception, hence a valid mid
                offset, payload = BinaryConversion._decode_introduction_request(self, placeholder, offset, data)
                payload.set_introduce_me_to(candidate_mid)
                return offset, payload

            except DropPacket:
                # could not decode, reset offset parse as normal introduction request
                offset -= 21

        return BinaryConversion._decode_introduction_request(self, placeholder, offset, data)

    def _encode_decode(self, encode, decode, message):
        result = encode(message)
        try:
            decode(None, 0, result[0])

        except DropPacket:
            raise
        except:
            pass
        return result

class PSearchConversion(ForwardConversion):

    def __init__(self, community):
        ForwardConversion.__init__(self, community)
        self.define_meta_message(chr(7), community.get_meta_message(u"msimilarity-request"), lambda message: self._encode_decode(self._encode_sum_request, self._decode_sum_request, message), self._decode_sum_request)
        self.define_meta_message(chr(8), community.get_meta_message(u"similarity-request"), lambda message: self._encode_decode(self._encode_sum_request, self._decode_sum_request, message), self._decode_sum_request)
        self.define_meta_message(chr(9), community.get_meta_message(u"msimilarity-response"), lambda message: self._encode_decode(self._encode_sums, self._decode_sums, message), self._decode_sums)
        self.define_meta_message(chr(10), community.get_meta_message(u"similarity-response"), lambda message: self._encode_decode(self._encode_sum, self._decode_sum, message), self._decode_sum)

    def _encode_sum_request(self, message):
        str_n = long_to_bytes(message.payload.key_n, 128)
        str_prefs = [long_to_bytes(preference, 256) for preference in message.payload.preference_list]
        str_prefs = str_prefs + [long_to_bytes(preference, 256) for preference in message.payload.global_vector]

        fmt = "!H128s" + "256s"*len(str_prefs)
        packet = pack(fmt, message.payload.identifier, str_n, *str_prefs)
        return packet,

    def _decode_sum_request(self, placeholder, offset, data):
        identifier, str_n = unpack_from('!H128s', data, offset)
        offset += 130

        length = len(data) - offset
        if length % 256 != 0:
            raise DropPacket("Invalid number of bytes available (encr_res)")

        if length:
            hashpack = '256s' * (length / 256)
            str_prefs = unpack_from('!' + hashpack, data, offset)

            prefs = [bytes_to_long(str_pref) for str_pref in str_prefs]
            global_vector = prefs[len(prefs) / 2:]
            prefs = prefs[:len(prefs) / 2]
            offset += length

        return offset, placeholder.meta.payload.implement(identifier, bytes_to_long(str_n), prefs, global_vector)

    def _encode_sum(self, message):
        str_sum = long_to_bytes(message.payload._sum, 256)
        return pack("!H256s", message.payload.identifier, str_sum),

    def _decode_sum(self, placeholder, offset, data):
        identifier, _sum = unpack_from('!H256s', data, offset)
        offset += 258

        return offset, placeholder.meta.payload.implement(identifier, bytes_to_long(_sum))

    def _encode_sums(self, message):
        str_sum = long_to_bytes(message.payload._sum, 256)

        sums = []
        for candidate_mid, address_sum in message.payload.sums:
            sums.append(candidate_mid)
            sums.append(long_to_bytes(address_sum, 256))

        fmt = "!H256s" + "20s256s" * len(message.payload.sums)
        packet = pack(fmt, message.payload.identifier, str_sum, *sums)
        return packet,

    def _decode_sums(self, placeholder, offset, data):
        identifier, _sum = unpack_from('!H256s', data, offset)
        offset += 258

        length = len(data) - offset
        if length % 276 != 0:
            raise DropPacket("Invalid number of bytes available (encr_sums)")

        _sums = []
        if length:
            hashpack = '20s256s' * (length / 276)
            raw_values = unpack_from('!' + hashpack, data, offset)
            for i in range(len(raw_values) / 2):
                candidate_mid = raw_values[i * 2]
                _sums.append([candidate_mid, bytes_to_long(raw_values[(i * 2) + 1])])

            offset += length

        return offset, placeholder.meta.payload.implement(identifier, bytes_to_long(_sum), _sums)

class HSearchConversion(ForwardConversion):

    def __init__(self, community):
        ForwardConversion.__init__(self, community)
        self.define_meta_message(chr(7), community.get_meta_message(u"msimilarity-request"), lambda message: self._encode_decode(self._encode_simi_request, self._decode_simi_request, message), self._decode_simi_request)
        self.define_meta_message(chr(8), community.get_meta_message(u"similarity-request"), lambda message: self._encode_decode(self._encode_simi_request, self._decode_simi_request, message), self._decode_simi_request)
        self.define_meta_message(chr(9), community.get_meta_message(u"msimilarity-response"), lambda message: self._encode_decode(self._encode_simi_responses, self._decode_simi_responses, message), self._decode_simi_responses)
        self.define_meta_message(chr(10), community.get_meta_message(u"similarity-response"), lambda message: self._encode_decode(self._encode_simi_response, self._decode_simi_response, message), self._decode_simi_response)

    def _encode_simi_request(self, message):
        str_n = long_to_bytes(message.payload.key_n, 128)
        str_prefs = [long_to_bytes(preference, 128) for preference in message.payload.preference_list]

        fmt = "!H128s" + "128s"*len(str_prefs)
        packet = pack(fmt, message.payload.identifier, str_n, *str_prefs)
        return packet,

    def _decode_simi_request(self, placeholder, offset, data):
        identifier, str_n = unpack_from('!H128s', data, offset)
        offset += 130

        length = len(data) - offset
        if length % 128 != 0:
            raise DropPacket("Invalid number of bytes available (simi_request)")

        if length:
            hashpack = '128s' * (length / 128)
            str_prefs = unpack_from('!' + hashpack, data, offset)
            prefs = [bytes_to_long(str_pref) for str_pref in str_prefs]
            offset += length
        else:
            prefs = []

        return offset, placeholder.meta.payload.implement(identifier, bytes_to_long(str_n), prefs)

    def _encode_simi_response(self, message):
        str_identifer = pack("!H", message.payload.identifier)
        str_prefs = pack("!" + "128s"*len(message.payload.preference_list), *[long_to_bytes(preference, 128) for preference in message.payload.preference_list])
        str_his_prefs = pack("!" + "20s"*len(message.payload.his_preference_list), *message.payload.his_preference_list)
        return encode([str_identifer, str_prefs, str_his_prefs]),

    def _decode_simi_response(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the simi_res-payload")

        str_identifier, str_prefs, str_his_prefs = payload

        identifier, = unpack_from('!H', str_identifier)

        length = len(str_prefs)
        if length % 128 != 0:
            raise DropPacket("Invalid number of bytes available (simi_res)")
        if length:
            hashpack = '128s' * (length / 128)
            hashes = unpack_from('!' + hashpack, str_prefs)
            hashes = [bytes_to_long(hash) for hash in hashes]
        else:
            hashes = []

        length = len(str_his_prefs)
        if length % 20 != 0:
            raise DropPacket("Invalid number of bytes available (simi_res)")
        if length:
            hashpack = '20s' * (length / 20)
            his_hashes = list(unpack_from('!' + hashpack, str_his_prefs))
        else:
            his_hashes = []
        return offset, placeholder.meta.payload.implement(identifier, hashes, his_hashes)

    def _encode_simi_responses(self, message):
        max_len = 65000 - (1500 - (self._community.dispersy_sync_bloom_filter_bits / 8))

        def create_msg():
            def _encode_response(mid, preference_list, his_preference_list):
                str_mid = pack("!20s", mid) if mid else ''
                str_prefs = pack("!" + "128s"*len(preference_list), *[long_to_bytes(preference, 128) for preference in preference_list])
                str_hprefs = pack("!" + "20s"*len(his_preference_list), *his_preference_list)
                return (str_mid, str_prefs, str_hprefs)

            responses = []
            responses.append(_encode_response(None, message.payload.preference_list, message.payload.his_preference_list))
            for mid, list_tuple in message.payload.bundled_responses:
                responses.append(_encode_response(mid, list_tuple[0], list_tuple[1]))

            packet = pack('!H', message.payload.identifier), responses
            return encode(packet)

        packet = create_msg()
        while len(packet) > max_len:
            nr_to_reduce = int((len(packet) - max_len) / 128.0) + 1

            for _ in range(nr_to_reduce):
                nr_bundled_responses = len(message.payload.bundled_responses)
                if nr_bundled_responses:
                    index = choice(range(nr_bundled_responses))

                    nr_my_responses = len(message.payload.bundled_responses[index][1][0])
                    nr_his_responses = len(message.payload.bundled_responses[index][1][1])
                    if nr_my_responses <= 1 or nr_his_responses <= 1:
                        message.payload.bundled_responses.pop(index)

                    elif nr_my_responses > nr_his_responses:
                        message.payload.bundled_responses[index][1][0].pop(choice(range(nr_my_responses)))

                    else:
                        message.payload.bundled_responses[index][1][1].pop(choice(range(nr_his_responses)))
                else:
                    nr_my_responses = len(message.payload.preference_list)
                    nr_his_responses = len(message.payload.his_preference_list)

                    if nr_my_responses > nr_his_responses:
                        message.payload.preference_list.pop(choice(range(nr_my_responses)))
                    else:
                        message.payload.his_preference_list.pop(choice(range(nr_his_responses)))

            packet = create_msg()

        return packet,

    def _decode_simi_responses(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the simi-payload")

        identifier, responses = payload[:2]

        if len(identifier) != 2:
            raise DropPacket("Unable to decode the search-response-payload, got %d bytes expected 2" % (len(identifier)))
        identifier, = unpack_from('!H', identifier)

        prefs = hprefs = None
        bundled_responses = []
        for str_mid, str_prefs, str_hprefs in responses:
            length = len(str_prefs)
            if length % 128 != 0:
                raise DropPacket("Invalid number of bytes available (encr_res)")
            if length:
                hashpack = '128s' * (length / 128)
                hashes = unpack_from('!' + hashpack, str_prefs)
                hashes = [bytes_to_long(hash) for hash in hashes]

            length = len(str_hprefs)
            if length % 20 != 0:
                raise DropPacket("Invalid number of bytes available (encr_res)")
            if length:
                hashpack = '20s' * (length / 20)
                his_hashes = list(unpack_from('!' + hashpack, str_hprefs))
            else:
                his_hashes = []

            if str_mid:
                str_mid, = unpack_from("!20s", str_mid)
                bundled_responses.append((str_mid, (hashes, his_hashes)))
            else:
                prefs = hashes
                hprefs = his_hashes

        return offset, placeholder.meta.payload.implement(identifier, [prefs, hprefs], bundled_responses)

class PoliSearchConversion(ForwardConversion):

    def __init__(self, community):
        ForwardConversion.__init__(self, community)
        self.define_meta_message(chr(7), community.get_meta_message(u"msimilarity-request"), lambda message: self._encode_decode(self._encode_simi_request, self._decode_simi_request, message), self._decode_simi_request)
        self.define_meta_message(chr(8), community.get_meta_message(u"similarity-request"), lambda message: self._encode_decode(self._encode_simi_request, self._decode_simi_request, message), self._decode_simi_request)
        self.define_meta_message(chr(9), community.get_meta_message(u"msimilarity-response"), lambda message: self._encode_decode(self._encode_simi_responses, self._decode_simi_responses, message), self._decode_simi_responses)
        self.define_meta_message(chr(10), community.get_meta_message(u"similarity-response"), lambda message: self._encode_decode(self._encode_simi_response, self._decode_simi_response, message), self._decode_simi_response)

    def _encode_simi_request(self, message):
        contents = []

        fmt = "!H128s128s"
        contents.append(long_to_bytes(message.payload.key_n, 128))
        contents.append(long_to_bytes(message.payload.key_g, 128))

        if len(message.payload.coefficients) > 0:
            fmt += "257s"
            contents.append(long_to_bytes(message.payload.coefficients.values()[0][0], -256))

        for partition, coeffs in message.payload.coefficients.iteritems():
            fmt += "BB" + "257s"*(len(coeffs) - 1)
            contents.append(partition)
            contents.append(len(coeffs) - 1)
            contents.extend([long_to_bytes(coeff, -256) for coeff in coeffs[1:]])

        packet = pack(fmt, message.payload.identifier, *contents)
        return packet,

    def _decode_simi_request(self, placeholder, offset, data):
        identifier, str_n, str_g = unpack_from('!H128s128s', data, offset)
        offset += 258

        preferences = {}
        length = len(data) - offset
        if length:
            one_coeff, = unpack_from("!257s", data, offset)
            one_coeff = bytes_to_long(one_coeff, -256)

            offset += 257
            length = len(data) - offset

        while length:
            partition, nr_coeffs = unpack_from("!BB", data, offset)
            offset += 2

            hashpack = '257s' * nr_coeffs
            str_coeffs = unpack_from('!' + hashpack, data, offset)
            offset += 257 * nr_coeffs
            preferences[partition] = [one_coeff] + [bytes_to_long(str_coeff, -256) for str_coeff in str_coeffs]

            length = len(data) - offset
        return offset, placeholder.meta.payload.implement(identifier, bytes_to_long(str_n), bytes_to_long(str_g), preferences)

    def _encode_simi_response(self, message):
        str_identifer = pack("!H", message.payload.identifier)
        str_prefs = pack("!" + "256s"*len(message.payload.my_response), *[long_to_bytes(preference, 256) for preference in message.payload.my_response])
        return encode([str_identifer, str_prefs]),

    def _decode_simi_response(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the encr-payload")

        str_identifier, str_prefs = payload

        identifier, = unpack_from('!H', str_identifier)

        length = len(str_prefs)
        if length % 256 != 0:
            raise DropPacket("Invalid number of bytes available (encr_res)")

        if length:
            hashpack = '256s' * (length / 256)
            hashes = unpack_from('!' + hashpack, str_prefs)
            hashes = [bytes_to_long(hash) for hash in hashes]
        else:
            hashes = []

        return offset, placeholder.meta.payload.implement(identifier, hashes)

    def _encode_simi_responses(self, message):
        max_len = 65000 - (1500 - (self._community.dispersy_sync_bloom_filter_bits / 8))

        def create_msg():
            def _encode_response(mid, evaluated_polinomials):
                str_mid = pack("!20s", mid) if mid else ''
                str_polynomials = pack("!" + "256s"*len(evaluated_polinomials), *[long_to_bytes(py, 256) for py in evaluated_polinomials])
                return (str_mid, str_polynomials)

            responses = []
            responses.append(_encode_response(None, message.payload.my_response))
            for mid, response in message.payload.bundled_responses:
                responses.append(_encode_response(mid, response))

            packet = pack('!H', message.payload.identifier), responses
            return encode(packet)

        packet = create_msg()
        while len(packet) > max_len:
            nr_to_reduce = int((len(packet) - max_len) / 256.0) + 1

            for _ in range(nr_to_reduce):
                index = choice(range(len(message.payload.bundled_responses)))
                nr_polynomials = len(message.payload.bundled_responses[index][1])
                if nr_polynomials <= 1:
                    message.payload.bundled_responses.pop(index)
                else:
                    message.payload.bundled_responses[index][1].pop(choice(range(nr_polynomials)))

            packet = create_msg()

        return packet,

    def _decode_simi_responses(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the simi-payload")

        identifier, responses = payload[:2]

        if len(identifier) != 2:
            raise DropPacket("Unable to decode the search-response-payload, got %d bytes expected 2" % (len(identifier)))
        identifier, = unpack_from('!H', identifier)

        prefs = None
        bundled_responses = []
        for str_mid, str_prefs in responses:
            length = len(str_prefs)
            if length % 256 != 0:
                raise DropPacket("Invalid number of bytes available (encr_res)")

            if length:
                hashpack = '256s' * (length / 256)
                hashes = unpack_from('!' + hashpack, str_prefs)
                hashes = [bytes_to_long(hash) for hash in hashes]
            else:
                hashes = []

            if str_mid:
                str_mid, = unpack_from("!20s", str_mid)
                bundled_responses.append((str_mid, hashes))
            else:
                prefs = hashes

        return offset, placeholder.meta.payload.implement(identifier, prefs, bundled_responses)

########NEW FILE########
__FILENAME__ = ecelgamal
# Based on https://gist.github.com/bellbind/1414867, added some
# https://github.com/gdcurt/eccrypto in the mix
# Modified by Niels Zeilemaker, optimized using mpz etc.

from cProfile import Profile
from random import randint, choice
from string import ascii_uppercase, digits
from sys import maxint
from time import time

from optional_crypto import rand, StrongRandom, aes_encrypt_str, aes_decrypt_str
from ecutils import Point, EllipticCurve, \
    OpenSSLCurves, ECElgamalKey_Pub, ECElgamalKey

def ecelgamal_init(bits=192, curve=None):
    if curve == None:
        if bits == 192:
            coef_a = -3
            coef_b = 0x64210519e59c80e70fa7e9ab72243049feb8deecc146b9b1
            modulus = 6277101735386680763835789423207666416083908700390324961279

            base_x = 0x188da80eb03090f67cbf20eb43a18800f4ff0afd82ff1012
            base_y = 0x07192b95ffc8da78631011ed6b24cdd573f977a11e794811
            curve = EllipticCurve(coef_a, coef_b, modulus, base_x, base_y)

        if bits == 256:
            coef_a = -3
            coef_b = 0x5ac635d8aa3a93e7b3ebbd55769886bc651d06b0cc53b0f63bce3c3e27d2604b
            modulus = 115792089210356248762697446949407573530086143415290314195533631308867097853951

            base_x = 0x6b17d1f2e12c4247f8bce6e563a440f277037d812deb33a0f4a13945d898c296
            base_y = 0x4fe342e2fe1a7f9b8ee7eb4a7c0f9e162bce33576b315ececbb6406837bf51f5
            curve = EllipticCurve(coef_a, coef_b, modulus, base_x, base_y)

        if bits == 384:
            coef_a = -3
            coef_b = 0xb3312fa7e23ee7e4988e056be3f82d19181d9c6efe8141120314088f5013875ac656398d8a2ed19d2a85c8edd3ec2aef
            modulus = 39402006196394479212279040100143613805079739270465446667948293404245721771496870329047266088258938001861606973112319
            base_x = 0xaa87ca22be8b05378eb1c71ef320ad746e1d3b628ba79b9859f741e082542a385502f25dbf55296c3a545e3872760ab7
            base_y = 0x3617de4a96262c6f5d9e98bf9292dc29f8f41dbd289a147ce9da3113b5f0b8c00a60b1ce1d7e819d7a431d7c90ea0e5f
            curve = EllipticCurve(coef_a, coef_b, modulus, base_x, base_y)

        if bits == 521:
            coef_a = -3
            coef_b = 0x051953eb9618e1c9a1f929a21a0b68540eea2da725b99b315f3b8b489918ef109e156193951ec7e937b1652c0bd3bb1bf073573df883d2c34f1ef451fd46b503f00
            modulus = 6864797660130609714981900799081393217269435300143305409394463459185543183397656052122559640661454554977296311391480858037121987999716643812574028291115057151
            base_x = 0xc6858e06b70404e9cd9e3ecb662395b4429c648139053fb521f828af606b4d3dbaa14b5e77efe75928fe1dc127a2ffa8de3348b3c1856a429bf97e7e31c2e5bd66
            base_y = 0x11839296a789a3bc0045c8a5fb42c7d1bd998f54449579b446817afbd17273e662c97ee72995ef42640c550b9013fad0761353c7086a272c24088be94769fd16650
            curve = EllipticCurve(coef_a, coef_b, modulus, base_x, base_y)

    if curve:
        rand('init', 128)
        rand('seed', StrongRandom().randint(0, maxint))
        x = rand('next', 10000)
        Q = x * curve.g
        return ECElgamalKey(curve, x, Q, bits / 8, bits / 8 * 4)

def ecelgamal_encrypt(key, M):
    assert M in key.ec
    k = rand('next', 10000)

    R = k * key.ec.g
    S = M + k * key.Q
    return (R, S)

def ecelgamal_decrypt(key, cipher):
    assert not isinstance(key, ECElgamalKey_Pub)

    R, S = cipher
    M = S - key.x * R
    return M

def ecelgamal_add(cipher1, cipher2):
    R = cipher1[0] + cipher2[0]
    S = cipher1[1] + cipher2[1]
    return R, S

def encrypt_str(key, plain_str):
    aes_key = StrongRandom().getrandbits(128)
    enc_str = aes_encrypt_str(aes_key, plain_str)
    R, S = ecelgamal_encrypt(key, key.ec.convert_to_point(aes_key))
    R = Point.to_bytes(R, key.size)
    S = Point.to_bytes(S, key.size)

    assert len(R) == key.size * 2, "converted point is not as expected %d vs %d" % (len(R), key.size * 2)
    assert len(S) == key.size * 2, "converted point is not as expected %d vs %d" % (len(S), key.size * 2)

    enc_keylength = len(R) + len(S)
    assert enc_keylength == key.encsize, ("encrypted keylength is not as expected %d vs %d" % (enc_keylength, key.encsize))

    return R + S + enc_str

def decrypt_str(key, encr_str):
    assert not isinstance(key, ECElgamalKey_Pub)
    enc_aes_key = encr_str[:key.encsize]
    R = enc_aes_key[:len(enc_aes_key) / 2]
    S = enc_aes_key[len(enc_aes_key) / 2:]

    R = key.ec.from_bytes(R, key.size)
    S = key.ec.from_bytes(S, key.size)
    M = ecelgamal_decrypt(key, (R, S))
    aes_key = key.ec.convert_to_long(M)

    plain_str = aes_decrypt_str(aes_key, encr_str[key.encsize:])
    return plain_str

if __name__ == "__main__":
    # lets check if this ecelgamal thing works
    from Tribler.dispersy.crypto import ECCrypto
    ec = ECCrypto()
    openssl = OpenSSLCurves()

    m2key = ec.generate_key(u'NID_secp160k1')
    key = openssl.get_ecelgamalkey_for_key(m2key)

    M1 = key.ec.convert_to_point(1)
    M2 = key.ec.convert_to_point(2)

    assert key.ec.convert_to_long(M1) == 1, key.ec.convert_to_int(M1)
    assert key.ec.convert_to_long(M2) == 2, key.ec.convert_to_int(M2)

    encr_1 = ecelgamal_encrypt(key, M1)
    encr_2 = ecelgamal_encrypt(key, M2)

    M1M2 = ecelgamal_decrypt(key, ecelgamal_add(encr_1, encr_2))

    assert key.ec.convert_to_long(M1M2 - M2) == 1, key.ec.convert_to_long(M1M2 - M2)
    assert key.ec.convert_to_long(M1M2 - M1) == 2, key.ec.convert_to_long(M1M2 - M1)

    random_large_string = ''.join(choice(ascii_uppercase + digits) for _ in range(100001))
    encrypted_str = encrypt_str(key, random_large_string)
    assert random_large_string == decrypt_str(key, encrypted_str)

    # performance
    def do_perf():
        t1 = time()
        random_list = [key.ec.convert_to_point(randint(0, maxint)) for _ in xrange(1000)]
        t2 = time()

        encrypted_values = []
        for i, value in enumerate(random_list):
            encrypted_values.append(ecelgamal_encrypt(key, value))

        t3 = time()
        for cipher in encrypted_values:
            ecelgamal_decrypt(key, cipher)

        print "Took %.2fs to encrypt %d points, %.2fs to decrypt them (%.2fs to generate the points)" % (t3 - t2, len(random_list), time() - t3, t2 - t1)

    profiler = Profile()
    profiler.runcall(do_perf)
    profiler.print_stats()

########NEW FILE########
__FILENAME__ = ecutils
from optional_crypto import mpz, invert

from collections import defaultdict, namedtuple
import os

from pyasn1.type import univ, namedtype, tag
from pyasn1.codec.der import decoder

from Tribler.dispersy.crypto import ECCrypto
from Tribler.community.privatesemantic.conversion import long_to_bytes, \
    bytes_to_long

from M2Crypto.EC import EC_pub

ECElgamalKey = namedtuple('ECElgamalKey', ['ec', 'x', 'Q', 'size', 'encsize'])
ECElgamalKey_Pub = namedtuple('ECElgamalKey_Pub', ['ec', 'Q', 'size', 'encsize'])

class Point(object):
    __slots__ = ('x', 'y')
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def is_zero(self):
        return self.x == 0 and self.y == 0

    def __eq__(self, p):
        return self.x == p.x and self.y == p.y

    def __str__(self):
        return '(%d : %d)' % (self.x, self.y)

    @staticmethod
    def to_bytes(point, length_bytes):
        return long_to_bytes(point.x, length_bytes) + long_to_bytes(point.y, length_bytes)

    @staticmethod
    def from_bytes(str_bytes, length_bytes):
        return Point(bytes_to_long(str_bytes[:length_bytes]), bytes_to_long(str_bytes[length_bytes:]))

class PointOnCurve(Point):
    __slots__ = ('ec')

    def __init__(self, ec, x, y):
        Point.__init__(self, x, y)
        self.ec = ec

        assert x < self.ec.q
        assert y < self.ec.q
        assert self in self.ec

    def __add__(self, b):
        # <add> of elliptic curve: negate of 3rd cross point of (p1,p2) line
        if False:
            d = self +b
            assert self.ec.is_valid(d)
            assert d - b == self
            assert self -self == self.ec.zero
            assert self +b == b + self
            assert self +(b + d) == (self +b) + d

        if self.is_zero(): return b
        if b.is_zero(): return self
        if self == -b: return self.ec.zero
        if self == b:
            l = (mpz(3) * self.x * self.x + self.ec.a) * invert(2 * self.y, self.ec.q) % self.ec.q
        else:
            l = (b.y - self.y) * invert(b.x - self.x, self.ec.q) % self.ec.q

        x = (l * l - self.x - b.x) % self.ec.q
        y = (l * (self.x - x) - self.y) % self.ec.q
        return self.ec.point(x, y)

    def __sub__(self, p):
        return self.__add__(-p)

    def __rmul__(self, n):
        r = self.ec.zero

        result = self
        while 0 < n:
            if n & 1 == 1:
                r += result
            result = result + result
            n /= 2
        return r

    def __neg__(self):
        return self.ec.point(self.x, -self.y % self.ec.q)

class EllipticCurve(object):
    """System of Elliptic Curve"""
    def __init__(self, a, b, q, base_x, base_y):
        """elliptic curve as: (y**2 = x**3 + a * x + b) mod q
        - a, b: params of curve formula
        - q: prime number
        """
        assert a < q
        assert 0 < b
        assert b < q
        assert q > 2
        assert (4 * (a ** 3) + 27 * (b ** 2)) % q != 0

        self.a = mpz(a)
        self.b = mpz(b)
        self.q = mpz(q)

        self.g = self.point(base_x, base_y)
        self.zero = self.point(0, 0)

    def point(self, x, y):
        _x = mpz(x)
        _y = mpz(y)

        return PointOnCurve(self, _x, _y)

    def convert_to_point(self, element):
        for i in xrange(1000):
            x = mpz(1000 * element + i)
            s = (x ** 3 + self.a * x + self.b) % self.q
            if pow(s, (self.q - 1) / 2, self.q) != 1:
                continue
            return self.point(x, pow(s, (self.q + 1) / 4, self.q))

    def convert_to_long(self, point):
        return long(point.x / 1000)

    def __contains__(self, p):
        # elliptic curve is defined as: (y**2 = x**3 + a * x + b) mod q
        # hence a point should adhere to this equation
        if p.is_zero(): return True
        l = pow(p.y, 2, self.q)
        r = (pow(p.x, 3, self.q) + (self.a * p.x) + self.b) % self.q
        return l == r

    def from_bytes(self, str_bytes, bits):
        p = Point.from_bytes(str_bytes, bits)
        return self.point(p.x, p.y)

# from http://www.ietf.org/rfc/rfc5480.txt
class PubECParameters(univ.Choice):
    componentType = namedtype.NamedTypes(
        namedtype.NamedType('namedCurve', univ.ObjectIdentifier()),
        namedtype.NamedType('implicitCurve', univ.Null()),
        namedtype.NamedType('specifiedCurv', univ.Any()))

class AlgorithmIdentifier(univ.Sequence):
    componentType = namedtype.NamedTypes(
        namedtype.NamedType('algorithm', univ.ObjectIdentifier()),
        namedtype.NamedType('parameters', PubECParameters()))

class SubjectPublicKeyInfo(univ.Sequence):
    componentType = namedtype.NamedTypes(
        namedtype.NamedType('algorithm', AlgorithmIdentifier()),
        namedtype.NamedType('subjectPublicKey', univ.BitString()))

# from http://tools.ietf.org/html/rfc5915

taggedBitString = univ.BitString().subtype(implicitTag=tag.Tag(tag.tagClassContext, tag.tagFormatSimple, 1))
taggedECParameters = PubECParameters().subtype(implicitTag=tag.Tag(tag.tagClassContext, tag.tagFormatSimple, 0))

class ECPrivateKey(univ.Sequence):
    componentType = namedtype.NamedTypes(
        namedtype.NamedType('version', univ.Integer()),
        namedtype.NamedType('privateKey', univ.OctetString()),
        namedtype.NamedType('parameters', taggedECParameters),
        namedtype.OptionalNamedType('publicKey', taggedBitString))

# from http://www.ietf.org/rfc/rfc3279.txt
class Pentanomial(univ.Sequence):
    componentType = namedtype.NamedTypes(
         namedtype.NamedType('k1', univ.Integer()),
         namedtype.NamedType('k2', univ.Integer()),
         namedtype.NamedType('k3', univ.Integer()))

class CharacteristicTwo(univ.Sequence):
    componentType = namedtype.NamedTypes(
         namedtype.NamedType('m', univ.Integer()),
         namedtype.NamedType('basis', univ.ObjectIdentifier()),
         namedtype.NamedType('parameters', univ.Any()))

class Curve(univ.Sequence):
    componentType = namedtype.NamedTypes(
         namedtype.NamedType('a', univ.OctetString()),
         namedtype.NamedType('b', univ.OctetString()),
         namedtype.OptionalNamedType('seed', univ.BitString()))

class FieldID(univ.Sequence):
    componentType = namedtype.NamedTypes(
         namedtype.NamedType('fieldType', univ.ObjectIdentifier()),
         namedtype.NamedType('parameters', univ.Any()))

class ECParameters(univ.Sequence):
    componentType = namedtype.NamedTypes(
         namedtype.NamedType('version', univ.Integer()),
         namedtype.NamedType('fieldID', FieldID()),
         namedtype.NamedType('curve', Curve()),
         namedtype.NamedType('base', univ.OctetString()),
         namedtype.NamedType('order', univ.Integer()),
         namedtype.OptionalNamedType('cofactor', univ.Integer()))

class EcpkParameters(univ.Choice):
    componentType = namedtype.NamedTypes(
        namedtype.NamedType('ecParameters', ECParameters()),
        namedtype.NamedType('namedCurve', univ.ObjectIdentifier()),
        namedtype.NamedType('implicitlyCA', univ.Null()))


class OpenSSLCurves():

    def __init__(self):
        self.curve_dict = defaultdict(lambda: ["", "", ""])

        implicit = True
        f = open(os.path.join(os.path.dirname(__file__), 'curves.ec'), 'r')
        for line in f:
            line = line.strip()

            if not (line.startswith('#') or line.startswith('-----BEGIN')):
                if line.startswith('===') and line.endswith('==='):
                    curname = line[3:-3]
                elif line.startswith('-----END'):
                    self.curve_dict[curname][1 if implicit else 2] = self.curve_dict[curname][1 if implicit else 2].decode("BASE64")
                    implicit = not implicit
                else:
                    self.curve_dict[curname][1 if implicit else 2] += line
        f.close()

        for curve in self.curve_dict.itervalues():
            try:
                decoded_implicit, _ = decoder.decode(curve[1])
                curve[1] = str(decoded_implicit)
            except Exception, ex:
                curve[1] = ex

    def get_curvename_for_key(self, key):
        ec = ECCrypto()
        der_encoded_str = ec.key_to_bin(key)

        if isinstance(key, EC_pub):
            decoded_pk, _ = decoder.decode(der_encoded_str, asn1Spec=SubjectPublicKeyInfo())
            return str(decoded_pk[0]['parameters']['namedCurve'])

        decoded_pk, _ = decoder.decode(der_encoded_str, asn1Spec=ECPrivateKey())
        return str(decoded_pk['parameters']['namedCurve'])

    def get_curve_for_key(self, key):
        ec = ECCrypto()
        der_encoded_str = ec.key_to_bin(key)

        decoded_pk, _ = decoder.decode(der_encoded_str, asn1Spec=SubjectPublicKeyInfo())
        return self.get_curve(str(decoded_pk[0]['parameters']['namedCurve']))

    def get_ecelgamalkey_for_key(self, key):
        ec = ECCrypto()
        size = ec.get_signature_length(key) / 2

        der_encoded_str = ec.key_to_bin(key)

        if isinstance(key, EC_pub):
            decoded_pk, _ = decoder.decode(der_encoded_str, asn1Spec=SubjectPublicKeyInfo())
            curve = self.get_curve(str(decoded_pk[0]['parameters']['namedCurve']))
            bitstring = "".join(map(str, decoded_pk[1]))

            x = None
        else:
            decoded_pk, _ = decoder.decode(der_encoded_str, asn1Spec=ECPrivateKey())
            curve = self.get_curve(str(decoded_pk['parameters']['namedCurve']))
            bitstring = "".join(map(str, decoded_pk['publicKey']))

            x = self.os2ip(decoded_pk['privateKey'].asNumbers())

        octetstring = str(univ.OctetString(binValue=bitstring))
        Q = curve.point(*self.parse_ecpoint(octetstring))
        if x:
            return ECElgamalKey(curve, x, Q, size, size * 4)
        return ECElgamalKey_Pub(curve, Q, size, size * 4)


    def get_curve(self, namedCurve):
        for curve in self.curve_dict.itervalues():
            if namedCurve == curve[1]:
                if not isinstance(curve[2], EllipticCurve):
                    decoded_explicit, _ = decoder.decode(curve[2], asn1Spec=EcpkParameters())

                    fieldType = decoded_explicit[0]['fieldID']['fieldType'][-1]
                    if fieldType == 1:
                        modulo, _ = decoder.decode(decoded_explicit[0]['fieldID']['parameters'], asn1Spec=univ.Integer())
                        modulo = long(modulo)
                    else:
                        raise RuntimeError('no clue how to decode modulo')

#                     elif fieldType == 2:
#                         decoded_explicit[0]['fieldID']['parameters'], _ = decoder.decode(decoded_explicit[0]['fieldID']['parameters'], asn1Spec=CharacteristicTwo())
#
#                         if decoded_explicit[0]['fieldID']['parameters']['basis'][-1] == 3:
#                             decoded_explicit[0]['fieldID']['parameters']['parameters'], _ = decoder.decode(decoded_explicit[0]['fieldID']['parameters']['parameters'], asn1Spec=Pentanomial())

                    coef_a = long(str(decoded_explicit[0]['curve']['a']).encode('HEX'), 16)
                    coef_b = long(str(decoded_explicit[0]['curve']['b']).encode('HEX'), 16)
                    base_x, base_y = self.parse_ecpoint(str(decoded_explicit[0]['base']))
                    curve[2] = EllipticCurve(coef_a, coef_b, modulo, base_x, base_y)
                return curve[2]

    def get_named_curves(self):
        curve_list = []
        for curname, curve in self.curve_dict.iteritems():
            curve_list.append((curname, curve[1]))
        return curve_list

    def parse_ecpoint(self, ecpoint):
        # uncompressed ecpoints start with 04 and then the two points
        hexstr = ecpoint.encode('HEX')
        if hexstr[:2] == '04':
            hexstr = hexstr[2:]
            return long(hexstr[:len(hexstr) / 2], 16), long(hexstr[len(hexstr) / 2:], 16)
        else:
            raise RuntimeError('no clue how to decode ecpoint')

    def os2ip(self, octects_list):
        x = 0
        for i, xleni in enumerate(reversed(octects_list)):
            x += xleni * (256 ** i)

        return x

if __name__ == "__main__":
    openssl = OpenSSLCurves()
    print "\n".join(map(str, openssl.get_named_curves()))

########NEW FILE########
__FILENAME__ = elgamal
from time import time
from collections import namedtuple
from random import Random

ElGamalKey = namedtuple('ElGamalKey', ['p', 'g', 'y', 'x', 'size'])

def elgamal_init(bits):
    key = ElGamal.generate(bits, Random.new().read)
    return ElGamalKey(mpz(key.p), mpz(key.g), mpz(key.y), mpz(key.x), bits)

def elgamal_encrypt(key, element):
    assert isinstance(element, (long, int)), type(element)

    _p = long(key.p)
    while 1:
        k = StrongRandom().randint(1, _p - 1)
        if GCD(k, _p - 1) == 1: break

    _element = mpz(element)
    _k = mpz(k)

    c1 = pow(key.g, _k, key.p)
    c2 = (_element * pow(key.y, _k, key.p)) % key.p
    return (long(c1), long(c2))

def elgamal_decrypt(key, cipher):
    ax = pow(cipher[0], key.x, key.p)
    plaintext = (cipher[1] * inverse(ax, long(key.p))) % key.p
    return plaintext

if __name__ == "__main__":
    # lets check if this elgamal thing works

    t1 = time()
    key = elgamal_init(1024)

    t2 = time()
    encrypted3 = elgamal_encrypt(key, 3l)

    t3 = time()
    encrypted2 = elgamal_encrypt(key, 2l)

    t4 = time()
    encrypted6 = (encrypted3[0] * encrypted2[0], encrypted3[1] * encrypted2[1])

    t5 = time()

    print elgamal_decrypt(key, encrypted6)
    print time() - t5, t5 - t4, t4 - t3, t3 - t2, t2 - t1

########NEW FILE########
__FILENAME__ = elgamalcrypto
from Tribler.dispersy.crypto import ECCrypto, NoCrypto
from Tribler.community.privatesemantic.crypto.ecutils import OpenSSLCurves
from Tribler.community.privatesemantic.crypto.ecelgamal import encrypt_str, decrypt_str

class ElgamalCrypto(ECCrypto):

    def __init__(self):
        ECCrypto.__init__(self)
        self.openssl = OpenSSLCurves()

    def encrypt(self, key, string):
        "Encrypt a string with this key."
        ecelgamalkey = self.openssl.get_ecelgamalkey_for_key(key)
        return encrypt_str(ecelgamalkey, string)

    def decrypt(self, key, string):
        "Decrypt a string with this key."
        ecelgamalkey = self.openssl.get_ecelgamalkey_for_key(key)
        return decrypt_str(ecelgamalkey, string)

    def get_curve(self, key):
        return self.openssl.get_curvename_for_key(key)

class NoElgamalCrypto(NoCrypto, ElgamalCrypto):

    def __init__(self):
        ECCrypto.__init__(self)

    def encrypt(self, key, string):
        return string

    def decrypt(self, key, string):
        return string

    def get_curve(self, key):
        return "(42)"

########NEW FILE########
__FILENAME__ = optional_crypto
import logging
logger = logging.getLogger(__name__)

try:
    from gmpy import mpz, rand, invert

except ImportError:
    logger.warning('Using fallback for gmpy, not recommended as it hurts performance and is less tested')

    def mpz(a):
        return a

    from random import randint
    def rand(calltype, param):
        if calltype == 'next':
            return randint(0, param)

    def egcd(a, b):
        lastremainder, remainder = abs(a), abs(b)
        x, lastx, y, lasty = 0, 1, 1, 0
        while remainder:
            lastremainder, (quotient, remainder) = remainder, divmod(lastremainder, remainder)
            x, lastx = lastx - quotient * x, x
            y, lasty = lasty - quotient * y, y
        return lastremainder, lastx * (-1 if a < 0 else 1), lasty * (-1 if b < 0 else 1)

    def invert(x, m):
        g, x, y = egcd(x, m)
        if g != 1:
            raise Exception('modular inverse does not exist, "%d"' % g)
        return x % m

try:
    raise ImportError()
    from Crypto.Util.number import long_to_bytes
    from Crypto.Random.random import StrongRandom
    from Crypto.Cipher import AES

    def aes_encrypt_str(aes_key, plain_str):
        if isinstance(aes_key, long):
            aes_key = long_to_bytes(aes_key, 16)
        cipher = AES.new(aes_key, AES.MODE_CFB, '\x00' * 16)
        return cipher.encrypt(plain_str)

    def aes_decrypt_str(aes_key, encr_str):
        if isinstance(aes_key, long):
            aes_key = long_to_bytes(aes_key, 16)
        cipher = AES.new(aes_key, AES.MODE_CFB, '\x00' * 16)
        return cipher.decrypt(encr_str)

except ImportError:
    from random import Random as StrongRandom

    from Tribler.community.privatesemantic.conversion import long_to_bytes
    from Tribler.dispersy.util import attach_runtime_statistics
    from M2Crypto import EVP

    def aes_encrypt_str(aes_key, plain_str):
        if isinstance(aes_key, long):
            aes_key = long_to_bytes(aes_key, 16)
        cipher = EVP.Cipher(alg='aes_128_ecb', key=aes_key, iv='\x00' * 16, op=1)
        ret = cipher.update(plain_str)
        return ret + cipher.final()

    def aes_decrypt_str(aes_key, encr_str):
        if isinstance(aes_key, long):
            aes_key = long_to_bytes(aes_key, 16)
        cipher = EVP.Cipher(alg='aes_128_ecb', key=aes_key, iv='\x00' * 16, op=0)
        ret = cipher.update(encr_str)
        return ret + cipher.final()

########NEW FILE########
__FILENAME__ = paillier
# Written by Niels Zeilemaker

from Crypto.Util.number import GCD, bytes_to_long, long_to_bytes
from optional_crypto import mpz, invert, rand, StrongRandom, aes_encrypt_str, aes_decrypt_str

from random import randint, Random, choice
from time import time
from hashlib import md5
from sys import maxint

from rsa import rsa_init
from collections import namedtuple
from polycreate import compute_coeff
from itertools import groupby
from cProfile import Profile
from string import ascii_uppercase, digits

PaillierKey = namedtuple('PaillierKey', ['n', 'n2', 'g', 'lambda_', 'd', 'size', 'encsize'])

# using same variable names as implementation by Zeki
def improved_pow(base, exponent, modulo):
    if exponent == 1:
        return base

    if exponent > 1:
        return pow(base, exponent, modulo)

    d = invert(base, modulo)
    return pow(d, -exponent, modulo)

def paillier_init(rsa_key):
    rand('init', 128)
    rand('seed', StrongRandom().randint(0, maxint))

    n = mpz(rsa_key.n)
    n2 = mpz(n ** 2)

    g = mpz(n + 1)

    # LCM from https://github.com/kmcneelyshaw/pycrypto/commit/98c22cc691c1840db380ad04c22169721a946b50
    x = rsa_key.p - 1
    y = rsa_key.q - 1
    if y > x:
        x, y = y, x

    lambda_ = mpz((x / GCD(x, y)) * y)

    d = pow(g, lambda_, n2)
    d = (d - 1) / n
    d = mpz(invert(d, n))
    return PaillierKey(n, n2, g, lambda_, d, rsa_key.size, rsa_key.size * 2)

def paillier_encrypt(key, element):
    assert isinstance(element, (int, long)), type(element)

    _n = long(key.n)
    while True:
        r = rand('next', _n)
        if GCD(r, _n) == 1: break
    r = mpz(r)

    t1 = improved_pow(key.g, element, key.n2)
    t2 = pow(r, key.n, key.n2)
    cipher = (t1 * t2) % key.n2
    return long(cipher)

def paillier_decrypt(key, cipher):
    cipher_ = mpz(cipher)

    t1 = pow(cipher_, key.lambda_, key.n2)
    t1 = (t1 - 1) / key.n

    value = (t1 * key.d) % key.n
    return long(value)

def paillier_decrypt_str(key, cipher):
    assert isinstance(cipher, str), type(cipher)
    return

def paillier_multiply(cipher, times, n2):
    cipher_ = mpz(cipher)
    times_ = mpz(times)
    n2_ = mpz(n2)
    return long(pow(cipher_, times_, n2_))

def paillier_add(cipher1, cipher2, n2):
    return (cipher1 * cipher2) % n2

def paillier_add_unenc(cipher, value, g, n2):
    return cipher * improved_pow(g, value, n2)

def paillier_polyval(coefficients, x, n2):
    result = coefficients[0]
    for coefficient in coefficients[1:]:
        result = paillier_add(paillier_multiply(result, x, n2), coefficient, n2)

    return result

def encrypt_str(key, plain_str):
    aes_key = StrongRandom().getrandbits(128)
    enc_str = aes_encrypt_str(aes_key, plain_str)
    enc_aes_key = long_to_bytes(paillier_encrypt(key, aes_key), key.encsize / 8)
    return enc_aes_key + enc_str

def decrypt_str(key, encr_str):
    enc_aes_key = bytes_to_long(encr_str[:key.encsize / 8])
    aes_key = paillier_decrypt(key, enc_aes_key)
    plain_str = aes_decrypt_str(aes_key, encr_str[key.encsize / 8:])
    return plain_str

if __name__ == "__main__":
    # lets check if this paillier thing works
    key = rsa_init(1024)
    key = paillier_init(key)

    assert bytes_to_long(long_to_bytes(key.g, 128)) == key.g

    r = Random()
    set1 = [r.randint(0, 2 ** 40) for i in range(100)]
    set2 = [r.randint(0, 2 ** 40) for i in range(100)]
    should_overlap = set2[0] = set1[0]  # force overlap

    # create partitions
    # convert our infohashes to 40 bit long
    bitmask = (2 ** 40) - 1
    set1 = [long(md5(str(infohash)).hexdigest(), 16) & bitmask for infohash in set1]
    set2 = [long(md5(str(infohash)).hexdigest(), 16) & bitmask for infohash in set2]

    assert all(val < bitmask for val in set1)
    assert all(val < bitmask for val in set2)

    # partition the infohashes
    partitionmask = (2 ** 32) - 1
    set1 = [(val >> 32, val & partitionmask) for val in set1]
    set2 = [(val >> 32, val & partitionmask) for val in set2]

    set1.sort()
    set2.sort()

    a_results = {}
    for partition, g in groupby(set1, lambda x: x[0]):
        assert 0 <= partition <= 255, partition

        values = [value for _, value in list(g)]
        coeffs = compute_coeff(values)
        coeffs = [paillier_encrypt(key, coeff) for coeff in coeffs]

        a_results[partition] = coeffs

    b_results = []
    for partition, g in groupby(set2, lambda x: x[0]):
        assert partition <= 255, partition
        assert partition >= 0, partition

        if partition in a_results:
            values = [value for _, value in list(g)]
            for val in values:
                py = paillier_polyval(a_results[partition], val, key.n2)
                py = paillier_multiply(py, randint(0, 2 ** 40), key.n2)
                py = paillier_add_unenc(py, val, key.g, key.n2)
                b_results.append((py, val))

    for b_result, b_val in b_results:
        if should_overlap == b_val:
            assert paillier_decrypt(key, b_result) == b_val

    encrypted1 = paillier_encrypt(key, 1l)
    _encrypted0 = paillier_add_unenc(encrypted1, -1, key.g, key.n2)
    assert 0l == paillier_decrypt(key, _encrypted0)

    encrypted0 = paillier_encrypt(key, 0l)
    encrypted1 = paillier_encrypt(key, 1l)

    test = paillier_decrypt(key, 1l)
    assert test == 0l, test

    test = paillier_decrypt(key, encrypted0)
    assert test == 0l, test

    test = paillier_decrypt(key, encrypted1)
    assert test == 1l, test

    encrypted2 = paillier_add(encrypted1, encrypted1, key.n2)
    test = paillier_decrypt(key, encrypted2)
    assert test == 2l, test

    encrypted4 = paillier_add(encrypted2, encrypted2, key.n2)
    test = paillier_decrypt(key, encrypted4)
    assert test == 4l, test

    encrypted1_ = paillier_add(1, encrypted1, key.n2)
    test = paillier_decrypt(key, encrypted1_)
    assert test == 1l, test

    encrypted0_ = paillier_multiply(encrypted0, 10, key.n2)
    test = paillier_decrypt(key, encrypted0_)
    assert test == 0l, test

    encrypted10 = paillier_multiply(encrypted1, 10, key.n2)
    test = paillier_decrypt(key, encrypted10)
    assert test == 10l, test

    # bytes_to_long check
    test = bytes_to_long(long_to_bytes(key.n, 128))
    assert test == key.n, test

    test = paillier_decrypt(key, bytes_to_long(long_to_bytes(encrypted0, 128)))
    assert test == 0l, test

    test = paillier_decrypt(key, bytes_to_long(long_to_bytes(encrypted1, 128)))
    assert test == 1l, test

    random_large_string = ''.join(choice(ascii_uppercase + digits) for _ in range(100001))
    encrypted_str = encrypt_str(key, random_large_string)
    assert random_large_string == decrypt_str(key, encrypted_str)

    def do_perf():
        # performance
        t1 = time()
        random_list = [randint(0, 1) for _ in xrange(1000)]

        t2 = time()
        encrypted_values = []
        for i, value in enumerate(random_list):
            encrypted_values.append(paillier_encrypt(key, value))

        t3 = time()
        for cipher in encrypted_values:
            paillier_decrypt(key, cipher)

        print "Took %.2fs to encrypt %d values, %.2fs to decrypt them (%.2fs to generate the points)" % (t3 - t2, len(random_list), time() - t3, t2 - t1)

    profiler = Profile()
    profiler.runcall(do_perf)
    profiler.print_stats()

########NEW FILE########
__FILENAME__ = polycreate
# Written by Niels Zeilemaker

from itertools import product, groupby
from random import Random
from time import time

from gmpy import mpz
from hashlib import md5

from Tribler.community.privatesemantic.conversion import bytes_to_long, \
    long_to_bytes

class X:
    def __init__(self, val, power):
        self.val = val
        self.power = power

    def multiply(self, other):
        return X(self.val * other.val, self.power + other.power)

    def merge(self, other):
        assert self.power == other.power
        self.val += other.val

    def __repr__(self):
        if self.power:
            if self.val == 1:
                return "X^%d" % self.power
            if self.val == -1:
                return "-X^%d" % self.power
            return "%dX^%d" % (self.val, self.power)
        return "%d" % self.val

def multiply(terms):
    if len(terms) == 1:
        return terms[0]

    me = terms[0]
    other = terms[1]
    if len(terms) > 2:
        other = multiply(terms[1:])

    combinations = product(me, other)
    results = [a.multiply(b) for a, b in combinations]
    results.sort(cmp=lambda a, b : cmp(a.power, b.power), reverse=True)
    merged_results = []
    for _, g in groupby(results, lambda x: x.power):
        g = list(g)
        first = g[0]
        g = g[1:]
        while len(g):
            first.merge(g[0])
            g = g[1:]
        merged_results.append(first)
    return merged_results

def compute_coeff(roots):
    terms = [[X(1, 1), X(-root, 0)] for root in roots]
    coeffs = multiply(terms)
    return [coeff.val for coeff in coeffs]

def polyval(coefficients, x):
    result = 0
    for coefficient in coefficients:
        result = result * x + coefficient
    return result

if __name__ == "__main__":
    r = Random()
    set1 = [r.randint(0, 2 ** 40) for i in range(10)]
    print set1

    bitmask = (2 ** 40) - 1
    set1 = [long(md5(str(infohash)).hexdigest(), 16) & bitmask for infohash in set1]

    partitionmask = (2 ** 32) - 1
    set1 = [val & partitionmask for val in set1]

    t1 = time()
    print compute_coeff(set1)
    print time() - t1

    coeffs = compute_coeff(set1)

    MAXLONG256 = (1 << 2048) - 1
    for coeff in coeffs:
        assert bytes_to_long(long_to_bytes(coeff, -256), -256) == coeff, (bytes_to_long(long_to_bytes(coeff, -256), -256), coeff, long_to_bytes(coeff, -256))

    coeffs = [long_to_bytes(coeff, -256) for coeff in coeffs]
    coeffs = [bytes_to_long(str_coeff, -256) for str_coeff in coeffs]

    for val in set1:
        print val, polyval(coeffs, val)

    t1 = time()
    nr_false_positive = 0
    for _ in range(100000):
        i = r.randint(0, 2 ** 32)
        if i not in set1:
            returnval = polyval(coeffs, i)
            if returnval == 0:
                nr_false_positive += 1
    print time() - t1, nr_false_positive / 100000.0

########NEW FILE########
__FILENAME__ = rsa
# Written by Niels Zeilemaker

from optional_crypto import mpz, StrongRandom, aes_encrypt_str, aes_decrypt_str

from Crypto.PublicKey import RSA
from Crypto.Util.number import GCD, bytes_to_long, long_to_bytes

from string import ascii_uppercase, digits
from hashlib import sha1

from time import time
from random import randint, choice
from collections import namedtuple
from sys import maxint
import json

RSAKey = namedtuple('RSAKey', ['n', 'e', 'p', 'q', 'd', 'size', 'encsize'])

def rsa_init(bits=1024):
    key = RSA.generate(bits)
    return RSAKey(mpz(key.key.n), mpz(key.key.e), mpz(key.key.p), mpz(key.key.q), mpz(key.key.d), bits, bits)

def rsa_compatible(n, phi):
    phi = long(phi)
    while True:
        e = StrongRandom().randint(1, phi - 1)
        if GCD(e, phi) == 1: break
    return RSAKey(mpz(n), mpz(e), None, None, None, 1024, 1024)

def rsa_encrypt(key, element):
    assert isinstance(element, (long, int)), type(element)

    _element = mpz(element)
    return long(pow(_element, key.e, key.n))

def rsa_decrypt(key, cipher):
    assert isinstance(cipher, long), type(cipher)

    _cipher = mpz(cipher)
    return long(pow(_cipher, key.d, key.n))

def rsa_sign(key, message):
    message_hash = long(sha1(str(message)).hexdigest(), 16)
    _message_hash = mpz(message_hash)
    return long(pow(_message_hash, key.d, key.n))

def rsa_verify(key, message, signature):
    message_hash = long(sha1(str(message)).hexdigest(), 16)

    _signature = mpz(signature)
    should_be_hash = long(pow(_signature, key.e, key.n))
    return message_hash == should_be_hash

def encrypt_str(key, plain_str):
    aes_key = StrongRandom().getrandbits(128)
    enc_str = aes_encrypt_str(aes_key, plain_str)
    enc_aes_key = long_to_bytes(rsa_encrypt(key, aes_key), key.encsize / 8)
    return enc_aes_key + enc_str

def decrypt_str(key, encr_str):
    enc_aes_key = bytes_to_long(encr_str[:key.encsize / 8])
    aes_key = rsa_decrypt(key, enc_aes_key)
    plain_str = aes_decrypt_str(aes_key, encr_str[key.encsize / 8:])
    return plain_str

def hash_element(element):
    return sha1(str(element)).digest()

def get_bits(number):
    bits = 0
    while number > 2 ** bits:
        bits += 1
    return bits

def key_to_bytes(key):
    non_mpzdict = {}
    for i, prop in enumerate(['n', 'e', 'p', 'q', 'd', 'size']):
        if key[i]:
            non_mpzdict[prop] = long(key[i])

    return json.dumps(non_mpzdict)

def bytes_to_key(bytes):
    keydict = json.loads(bytes)
    return RSAKey(mpz(keydict['n']), mpz(keydict['e']), mpz(keydict['p']) if 'p' in keydict else None, mpz(keydict['q'])  if 'q' in keydict else None, mpz(keydict['d'])  if 'd' in keydict else None, keydict['size'], keydict['size'])

if __name__ == "__main__":
    MAXLONG128 = (1 << 1024) - 1

    # lets check if this rsa thing works
    key = rsa_init(1024)
    serialized_key = bytes_to_key(key_to_bytes(key))

    assert key.n == serialized_key.n, (key.n, serialized_key.n)
    assert key.e == serialized_key.e, (key.e, serialized_key.e)
    assert key.p == serialized_key.p, (key.p, serialized_key.p)
    assert key.q == serialized_key.q, (key.q, serialized_key.q)
    assert key.d == serialized_key.d, (key.d, serialized_key.d)
    assert key.size == serialized_key.size

    encrypted0 = rsa_encrypt(key, 0l)
    encrypted1 = rsa_encrypt(key, 1l)
    assert encrypted0 < MAXLONG128
    assert encrypted1 < MAXLONG128

    test = rsa_decrypt(key, encrypted0)
    assert test == 0l, test

    test = rsa_decrypt(key, encrypted1)
    assert test == 1l, test

    comp_key = rsa_compatible(key.n, key.n / 2)
    compencrypted0 = rsa_encrypt(comp_key, 0l)
    compencrypted1 = rsa_encrypt(comp_key, 1l)
    assert compencrypted0 < MAXLONG128
    assert compencrypted1 < MAXLONG128

    twiceencrypted0 = rsa_encrypt(comp_key, encrypted0)
    twiceencrypted1 = rsa_encrypt(comp_key, encrypted1)
    assert twiceencrypted0 < MAXLONG128
    assert twiceencrypted1 < MAXLONG128

    assert compencrypted0 == rsa_decrypt(key, twiceencrypted0)
    assert compencrypted1 == rsa_decrypt(key, twiceencrypted1)

    hcompencrypted0 = hash_element(compencrypted0)
    hcompecnrypted1 = hash_element(compencrypted1)
    assert isinstance(hcompencrypted0, str) and len(hcompencrypted0) == 20
    assert isinstance(hcompecnrypted1, str) and len(hcompecnrypted1) == 20

    assert hcompencrypted0 == hash_element(rsa_decrypt(key, twiceencrypted0))
    assert hcompecnrypted1 == hash_element(rsa_decrypt(key, twiceencrypted1))

    fakeinfohash = '296069              '
    assert long_to_bytes(rsa_decrypt(key, rsa_encrypt(key, bytes_to_long(fakeinfohash)))) == fakeinfohash

    random_large_string = ''.join(choice(ascii_uppercase + digits) for _ in range(100001))
    signature = rsa_sign(key, random_large_string)
    assert rsa_verify(key, random_large_string, signature)

    encrypted_str = encrypt_str(key, random_large_string)
    assert random_large_string == decrypt_str(key, encrypted_str)

    # performance
    random_list = [randint(0, maxint) for i in xrange(100)]

    t1 = time()
    encrypted_values = []
    for i, value in enumerate(random_list):
        encrypted_values.append(rsa_encrypt(key, value))

    t2 = time()
    for cipher in encrypted_values:
        rsa_decrypt(key, cipher)

    print "Encrypting took", t2 - t1
    print "Decrypting took", time() - t2

    his_n = key.n
    fake_phi = his_n / 2

    t1 = time()
    for i in range(1000):
        rsa_compatible(his_n, fake_phi + i)

    print "Compatible took", time() - t2




########NEW FILE########
__FILENAME__ = database
from os import path
from time import time

from Tribler.dispersy.database import Database

LATEST_VERSION = 1

schema = u"""
CREATE TABLE peercache(
 ip text,
 port interger,
 overlap text,
 last_connected real,
 connected_times integer DEFAULT 0,
 PRIMARY KEY (ip, port));
 
CREATE TABLE option(key TEXT PRIMARY KEY, value BLOB);
INSERT INTO option(key, value) VALUES('database_version', '""" + str(LATEST_VERSION) + """');
"""

class SemanticDatabase(Database):
    if __debug__:
        __doc__ = schema

    def __init__(self, dispersy):
        self._dispersy = dispersy

        if self._dispersy._database._file_path == u":memory:":
            super(SemanticDatabase, self).__init__(u":memory:")
        else:
            super(SemanticDatabase, self).__init__(path.join(dispersy.working_directory, u"sqlite", u"peercache.db"))

    def open(self):
        self._dispersy.database.attach_commit_callback(self.commit)
        return super(SemanticDatabase, self).open()

    def close(self, commit=True):
        self._dispersy.database.detach_commit_callback(self.commit)
        return super(SemanticDatabase, self).close(commit)

    def check_database(self, database_version):
        assert isinstance(database_version, unicode)
        assert database_version.isdigit()
        assert int(database_version) >= 0
        database_version = int(database_version)

        # setup new database with current database_version
        if database_version < 1:
            self.executescript(schema)
            self.commit()

        else:
            # upgrade to version 2
            if database_version < 2:
                # there is no version 2 yet...
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2)
                # self.executescript(u"""UPDATE option SET value = '2' WHERE key = 'database_version';""")
                # self.commit()
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2, " (done)")
                pass

        return LATEST_VERSION

    def get_database_stats(self):
        stats_dict = {}

        for tablename, in list(self.execute(u'SELECT name FROM sqlite_master WHERE type = "table"')):
            count, = self.execute(u"SELECT COUNT(*) FROM " + tablename).next()
            stats_dict[str(tablename)] = count
        return stats_dict

    def add_peer(self, overlap, ip, port, last_connected=None):
        assert isinstance(overlap, (list, int, long, float)), type(overlap)
        if isinstance(overlap, list):
            assert all(isinstance(cur_overlap, (int, long, float)) for cur_overlap in overlap), [type(cur_overlap) for cur_overlap in overlap]

        if isinstance(overlap, list):
            overlap = ",".join(map(str, overlap))
            overlap = buffer(overlap)

        try:
            self.execute(u"INSERT INTO peercache (ip, port, overlap, last_connected) VALUES (?,?,?,?)", (unicode(ip), port, overlap, last_connected or time()))
        except:
            self.execute(u"UPDATE peercache SET overlap = ?, last_connected = ?, connected_times = connected_times + 1 WHERE ip = ? AND port = ?", (overlap, last_connected or time(), unicode(ip), port))

    def get_peers(self):
        peers = list(self.execute(u"SELECT overlap, ip, port FROM peercache"))
        for i in range(len(peers)):
            peers[i] = list(peers[i])
            if isinstance(peers[i][0], buffer):
                peers[i][0] = [long(overlap) for overlap in str(peers[i][0]).split(",") if overlap]
            else:
                peers[i][0] = float(peers[i][0])
            peers[i][1] = str(peers[i][1])

        peers.sort(reverse=True)
        return peers

########NEW FILE########
__FILENAME__ = payload
from Tribler.dispersy.payload import Payload, IntroductionRequestPayload

MAXLONG128 = (1 << 1024) - 1
MAXLONG256 = (1 << 2048) - 1

# HSearchCommunity
class SimilarityRequest(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, key_n, preference_list):
            assert isinstance(identifier, int), type(identifier)
            assert not key_n or isinstance(key_n, long), type(key_n)
            assert not preference_list or isinstance(preference_list, list), type(preference_list)
            if preference_list:
                for preference in preference_list:
                    assert isinstance(preference, long), type(preference)

            self._identifier = identifier
            self._key_n = key_n
            self._preference_list = preference_list

        @property
        def identifier(self):
            return self._identifier

        @property
        def key_n(self):
            return self._key_n

        @property
        def preference_list(self):
            return self._preference_list

class EncryptedResponsePayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, preference_list, his_preference_list):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(preference_list, list), 'preferencelist should be list not %s' % type(preference_list)
                for preference in preference_list:
                    assert isinstance(preference, long), type(preference)

                assert isinstance(his_preference_list, list), 'his_preference_list should be list not %s' % type(his_preference_list)
                for hpreference in his_preference_list:
                    assert isinstance(hpreference, str), type(hpreference)
                    assert len(hpreference) == 20, len(hpreference)

            super(EncryptedResponsePayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._preference_list = preference_list
            self._his_preference_list = his_preference_list

        @property
        def identifier(self):
            return self._identifier

        @property
        def preference_list(self):
            return self._preference_list

        @property
        def his_preference_list(self):
            return self._his_preference_list

class BundledEncryptedResponsePayload(EncryptedResponsePayload):
    class Implementation(EncryptedResponsePayload.Implementation):
        def __init__(self, meta, identifier, my_response, bundled_responses):
            EncryptedResponsePayload.Implementation.__init__(self, meta, identifier, my_response[0], my_response[1])

            assert isinstance(bundled_responses, list), 'bundled_responses should be list not %s' % type(bundled_responses)
            assert len(bundled_responses) == len(set(mid for mid, _ in bundled_responses)), 'bundled_responses should not contain more than one entry per mid'

            for candidate_mid, response in bundled_responses:
                assert isinstance(candidate_mid, str), 'candidate_mid should be str'
                assert len(candidate_mid) == 20, len(candidate_mid)

                assert isinstance(response, tuple), type(response)
                assert len(response) == 2, len(response)

                preference_list, his_preference_list = response
                assert isinstance(preference_list, list), 'preferencelist should be list not %s' % type(preference_list)
                for preference in preference_list:
                    assert isinstance(preference, long), type(preference)

                assert isinstance(his_preference_list, list), 'his_preference_list should be list not %s' % type(his_preference_list)
                for hpreference in his_preference_list:
                    assert isinstance(hpreference, str), type(hpreference)
                    assert len(hpreference) == 20, len(hpreference)

            self._bundled_responses = bundled_responses

        @property
        def bundled_responses(self):
            return self._bundled_responses

# ForwardCommunity
class ExtendedIntroPayload(IntroductionRequestPayload):
    class Implementation(IntroductionRequestPayload.Implementation):

        def __init__(self, meta, destination_address, source_lan_address, source_wan_address, advice, connection_type, sync, identifier, introduce_me_to=None):
            IntroductionRequestPayload.Implementation.__init__(self, meta, destination_address, source_lan_address, source_wan_address, advice, connection_type, sync, identifier)
            if introduce_me_to:
                assert isinstance(introduce_me_to, str), 'introduce_me_to should be str'
                assert len(introduce_me_to) == 20, len(introduce_me_to)

            self._introduce_me_to = introduce_me_to

        def set_introduce_me_to(self, introduce_me_to):
            self._introduce_me_to = introduce_me_to

        @property
        def introduce_me_to(self):
            return self._introduce_me_to

# PSearchCommunity
class EncryptedVectorPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, key_n, preference_list, global_vector):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(key_n, long), type(key_n)
                assert key_n < MAXLONG128
                assert isinstance(preference_list, list), 'preference_list should be list not %s' % type(preference_list)
                for preference in preference_list:
                    assert isinstance(preference, long), type(preference)
                    assert preference < MAXLONG256

                assert isinstance(global_vector, list), 'global_vector should be list not %s' % type(preference_list)
                for item in global_vector:
                    assert isinstance(item, long), type(item)
                    assert item < MAXLONG256

            super(EncryptedVectorPayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._key_n = key_n
            self._preference_list = preference_list
            self._global_vector = global_vector

        @property
        def identifier(self):
            return self._identifier

        @property
        def key_n(self):
            return self._key_n

        @property
        def preference_list(self):
            return self._preference_list

        @property
        def global_vector(self):
            return self._global_vector

class EncryptedSumPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, _sum):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(_sum, long), type(_sum)
                assert _sum < MAXLONG256

            super(EncryptedSumPayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self.__sum = _sum

        @property
        def identifier(self):
            return self._identifier

        @property
        def _sum(self):
            return self.__sum

class EncryptedSumsPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, _sum, _sums):
            assert isinstance(_sums, list), type(_sums)
            assert len(_sums) == len(set(mid for mid, _ in _sums)), 'bundled_responses should not contain more than one entry per mid'

            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(_sum, long), type(_sum)
                assert _sum < MAXLONG256

                for candidate_mid, address_sum in _sums:
                    assert isinstance(candidate_mid, str), type(candidate_mid)
                    assert len(candidate_mid) == 20, len(candidate_mid)
                    assert isinstance(address_sum, long), type(address_sum)
                    assert address_sum < MAXLONG256

            super(EncryptedSumsPayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self.__sum = _sum
            self._sums = _sums

        @property
        def identifier(self):
            return self._identifier

        @property
        def _sum(self):
            return self.__sum

        @property
        def sums(self):
            return self._sums

# PoliSearchCommunity
class PoliSimilarityRequest(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, key_n, key_g, coefficients):
            assert isinstance(identifier, int), type(identifier)
            assert not key_n or isinstance(key_n, long), type(key_n)
            assert not key_g or isinstance(key_g, long), type(key_g)
            assert not coefficients or isinstance(coefficients, dict), type(coefficients)
            if coefficients:
                for partition, coeffs in coefficients.iteritems():
                    assert isinstance(partition, int), type(partition)
                    assert partition <= 255, partition
                    assert partition >= 0, partition
                    for coeff in coeffs:
                        assert isinstance(coeff, long), type(coeff)

            self._identifier = identifier
            self._key_n = key_n
            self._key_g = key_g
            self._coefficients = coefficients

        @property
        def identifier(self):
            return self._identifier

        @property
        def key_n(self):
            return self._key_n

        @property
        def key_g(self):
            return self._key_g

        @property
        def coefficients(self):
            return self._coefficients

class EncryptedPoliResponsePayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier, my_response):
            assert isinstance(identifier, int), type(identifier)
            assert isinstance(my_response, list), type(my_response)
            for py in my_response:
                assert isinstance(py, long), type(py)

            super(EncryptedPoliResponsePayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._my_response = my_response

        @property
        def identifier(self):
            return self._identifier

        @property
        def my_response(self):
            return self._my_response

class EncryptedPoliResponsesPayload(EncryptedPoliResponsePayload):
    class Implementation(EncryptedPoliResponsePayload.Implementation):
        def __init__(self, meta, identifier, my_response, bundled_responses):
            EncryptedPoliResponsePayload.Implementation.__init__(self, meta, identifier, my_response)

            assert isinstance(bundled_responses, list)
            assert len(bundled_responses) == len(set(mid for mid, _ in bundled_responses)), 'bundled_responses should not contain more than one entry per mid'
            for candidate_mid, response in bundled_responses:
                assert isinstance(candidate_mid, str), type(candidate_mid)
                assert len(candidate_mid) == 20, len(candidate_mid)

                assert isinstance(response, list), type(response)
                for py in response:
                    assert isinstance(py, long), type(py)

            self._bundled_responses = bundled_responses

        @property
        def bundled_responses(self):
            return self._bundled_responses

# ForwardCommunity
class PingPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, identifier):
            assert isinstance(identifier, int), type(identifier)

            super(PingPayload.Implementation, self).__init__(meta)
            self._identifier = identifier

        @property
        def identifier(self):
            return self._identifier

class PongPayload(PingPayload):
    pass

class SimiRevealPayload(Payload):
    class Implementation(Payload.Implementation):
        def __init__(self, meta, overlap):
            assert isinstance(overlap, (list, int)), type(overlap)

            super(SimiRevealPayload.Implementation, self).__init__(meta)
            self._overlap = overlap

        @property
        def overlap(self):
            return self._overlap

########NEW FILE########
__FILENAME__ = python27_ordereddict
# Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and pypy.
# Passes Python2.7's test suite and incorporates all the latest updates.

try:
    from thread import get_ident as _get_ident
except ImportError:
    from dummy_thread import get_ident as _get_ident

try:
    from _abcoll import KeysView, ValuesView, ItemsView
except ImportError:
    pass


class OrderedDict(dict):
    'Dictionary that remembers insertion order'
    # An inherited dict maps keys to values.
    # The inherited dict provides __getitem__, __len__, __contains__, and get.
    # The remaining methods are order-aware.
    # Big-O running times for all methods are the same as for regular dictionaries.

    # The internal self.__map dictionary maps keys to links in a doubly linked list.
    # The circular doubly linked list starts and ends with a sentinel element.
    # The sentinel element never gets deleted (this simplifies the algorithm).
    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].

    def __init__(self, *args, **kwds):
        '''Initialize an ordered dictionary.  Signature is the same as for
        regular dictionaries, but keyword arguments are not recommended
        because their insertion order is arbitrary.

        '''
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))
        try:
            self.__root
        except AttributeError:
            self.__root = root = []                     # sentinel node
            root[:] = [root, root, None]
            self.__map = {}
        self.__update(*args, **kwds)

    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
        'od.__setitem__(i, y) <==> od[i]=y'
        # Setting a new item creates a new link which goes at the end of the linked
        # list, and the inherited dictionary is updated with the new key/value pair.
        if key not in self:
            root = self.__root
            last = root[0]
            last[1] = root[0] = self.__map[key] = [last, root, key]
        dict_setitem(self, key, value)

    def __delitem__(self, key, dict_delitem=dict.__delitem__):
        'od.__delitem__(y) <==> del od[y]'
        # Deleting an existing item uses self.__map to find the link which is
        # then removed by updating the links in the predecessor and successor nodes.
        dict_delitem(self, key)
        link_prev, link_next, key = self.__map.pop(key)
        link_prev[1] = link_next
        link_next[0] = link_prev

    def __iter__(self):
        'od.__iter__() <==> iter(od)'
        root = self.__root
        curr = root[1]
        while curr is not root:
            yield curr[2]
            curr = curr[1]

    def __reversed__(self):
        'od.__reversed__() <==> reversed(od)'
        root = self.__root
        curr = root[0]
        while curr is not root:
            yield curr[2]
            curr = curr[0]

    def clear(self):
        'od.clear() -> None.  Remove all items from od.'
        try:
            for node in self.__map.itervalues():
                del node[:]
            root = self.__root
            root[:] = [root, root, None]
            self.__map.clear()
        except AttributeError:
            pass
        dict.clear(self)

    def popitem(self, last=True):
        '''od.popitem() -> (k, v), return and remove a (key, value) pair.
        Pairs are returned in LIFO order if last is true or FIFO order if false.

        '''
        if not self:
            raise KeyError('dictionary is empty')
        root = self.__root
        if last:
            link = root[0]
            link_prev = link[0]
            link_prev[1] = root
            root[0] = link_prev
        else:
            link = root[1]
            link_next = link[1]
            root[1] = link_next
            link_next[0] = root
        key = link[2]
        del self.__map[key]
        value = dict.pop(self, key)
        return key, value

    # -- the following methods do not depend on the internal structure --

    def keys(self):
        'od.keys() -> list of keys in od'
        return list(self)

    def values(self):
        'od.values() -> list of values in od'
        return [self[key] for key in self]

    def items(self):
        'od.items() -> list of (key, value) pairs in od'
        return [(key, self[key]) for key in self]

    def iterkeys(self):
        'od.iterkeys() -> an iterator over the keys in od'
        return iter(self)

    def itervalues(self):
        'od.itervalues -> an iterator over the values in od'
        for k in self:
            yield self[k]

    def iteritems(self):
        'od.iteritems -> an iterator over the (key, value) items in od'
        for k in self:
            yield (k, self[k])

    def update(*args, **kwds):
        '''od.update(E, **F) -> None.  Update od from dict/iterable E and F.

        If E is a dict instance, does:           for k in E: od[k] = E[k]
        If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
        Or if E is an iterable of items, does:   for k, v in E: od[k] = v
        In either case, this is followed by:     for k, v in F.items(): od[k] = v

        '''
        if len(args) > 2:
            raise TypeError('update() takes at most 2 positional '
                            'arguments (%d given)' % (len(args),))
        elif not args:
            raise TypeError('update() takes at least 1 argument (0 given)')
        self = args[0]
        # Make progressively weaker assumptions about "other"
        other = ()
        if len(args) == 2:
            other = args[1]
        if isinstance(other, dict):
            for key in other:
                self[key] = other[key]
        elif hasattr(other, 'keys'):
            for key in other.keys():
                self[key] = other[key]
        else:
            for key, value in other:
                self[key] = value
        for key, value in kwds.items():
            self[key] = value

    __update = update  # let subclasses override update without breaking __init__

    __marker = object()

    def pop(self, key, default=__marker):
        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.

        '''
        if key in self:
            result = self[key]
            del self[key]
            return result
        if default is self.__marker:
            raise KeyError(key)
        return default

    def setdefault(self, key, default=None):
        'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
        if key in self:
            return self[key]
        self[key] = default
        return default

    def __repr__(self, _repr_running={}):
        'od.__repr__() <==> repr(od)'
        call_key = id(self), _get_ident()
        if call_key in _repr_running:
            return '...'
        _repr_running[call_key] = 1
        try:
            if not self:
                return '%s()' % (self.__class__.__name__,)
            return '%s(%r)' % (self.__class__.__name__, self.items())
        finally:
            del _repr_running[call_key]

    def __reduce__(self):
        'Return state information for pickling'
        items = [[k, self[k]] for k in self]
        inst_dict = vars(self).copy()
        for k in vars(OrderedDict()):
            inst_dict.pop(k, None)
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def copy(self):
        'od.copy() -> a shallow copy of od'
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
        and values equal to v (which defaults to None).

        '''
        d = cls()
        for key in iterable:
            d[key] = value
        return d

    def __eq__(self, other):
        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
        while comparison to a regular mapping is order-insensitive.

        '''
        if isinstance(other, OrderedDict):
            return len(self)==len(other) and self.items() == other.items()
        return dict.__eq__(self, other)

    def __ne__(self, other):
        return not self == other

    # -- the following methods are only used in Python 2.7 --

    def viewkeys(self):
        "od.viewkeys() -> a set-like object providing a view on od's keys"
        return KeysView(self)

    def viewvalues(self):
        "od.viewvalues() -> an object providing a view on od's values"
        return ValuesView(self)

    def viewitems(self):
        "od.viewitems() -> a set-like object providing a view on od's items"
        return ItemsView(self)

########NEW FILE########
__FILENAME__ = test
import sys

from Tribler.dispersy.community import Community
from Tribler.community.privatesemantic.community import HForwardCommunity, \
    PForwardCommunity, PoliForwardCommunity

ENCRYPTION = True

class NoFSemanticCommunity(HForwardCommunity, Community):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, send_simi_reveal=True):
        Community.__init__(self, dispersy, master, my_member)
        HForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 0, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, send_simi_reveal=send_simi_reveal)

    def initiate_conversions(self):
        return HForwardCommunity.initiate_conversions(self)

    def initiate_meta_messages(self):
        return HForwardCommunity.initiate_meta_messages(self)

    def unload_community(self):
        HForwardCommunity.unload_community(self)
        Community.unload_community(self)

class HFSemanticCommunity(HForwardCommunity, Community):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, send_simi_reveal=True):
        Community.__init__(self, dispersy, master, my_member)
        HForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, send_simi_reveal=send_simi_reveal)

    def initiate_conversions(self):
        return HForwardCommunity.initiate_conversions(self)

    def initiate_meta_messages(self):
        return HForwardCommunity.initiate_meta_messages(self)

    def unload_community(self):
        HForwardCommunity.unload_community(self)
        Community.unload_community(self)

class PFSemanticCommunity(PForwardCommunity, Community):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, send_simi_reveal=True):
        Community.__init__(self, dispersy, master, my_member)
        PForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, send_simi_reveal=send_simi_reveal)

    def initiate_conversions(self):
        return PForwardCommunity.initiate_conversions(self)

    def initiate_meta_messages(self):
        return PForwardCommunity.initiate_meta_messages(self)

    def unload_community(self):
        PForwardCommunity.unload_community(self)
        Community.unload_community(self)

class PoliFSemanticCommunity(PoliForwardCommunity, Community):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, send_simi_reveal=True):
        Community.__init__(self, dispersy, master, my_member)
        PoliForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, send_simi_reveal=send_simi_reveal)

    def initiate_conversions(self):
        return PoliForwardCommunity.initiate_conversions(self)

    def initiate_meta_messages(self):
        return PoliForwardCommunity.initiate_meta_messages(self)

    def unload_community(self):
        PoliForwardCommunity.unload_community(self)
        Community.unload_community(self)

########NEW FILE########
__FILENAME__ = community
# Written by Niels Zeilemaker
import sys

from conversion import SocialConversion
from payload import TextPayload
from collections import defaultdict
from time import time
from random import sample, shuffle

from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CommunityDestination
from Tribler.dispersy.distribution import FullSyncDistribution
from Tribler.dispersy.message import Message
from Tribler.dispersy.resolution import PublicResolution
from Tribler.community.privatesocial.payload import EncryptedPayload
from Tribler.community.privatesemantic.community import PoliForwardCommunity, \
    HForwardCommunity, PForwardCommunity, TasteBuddy, PSI_CARDINALITY

from random import choice
from database import FriendDatabase
from Tribler.community.privatesemantic.crypto.elgamalcrypto import ElgamalCrypto

DEBUG = False
DEBUG_VERBOSE = False
ENCRYPTION = True

SYNC_WITH_TASTE_BUDDIES_INTERVAL = 300

class SocialCommunity(Community):

    def initialize(self, integrate_with_tribler=True, encryption=ENCRYPTION, log_text=None):
        assert isinstance(self.dispersy.crypto, ElgamalCrypto)

        super(SocialCommunity, self).initialize()

        self.encryption = bool(encryption)
        self.log_text = log_text

        self._friend_db = FriendDatabase(self.dispersy)
        self._friend_db.open()

        # never sync while taking a step, only sync with friends
        self._orig_send_introduction_request = self.send_introduction_request
        self.send_introduction_request = lambda destination, introduce_me_to = None, allow_sync = True, advice = True: self._orig_send_introduction_request(destination, introduce_me_to, False, True)

    def unload_community(self):
        super(SocialCommunity, self).unload_community()
        self._friend_db.close()

    def initiate_meta_messages(self):
        return super(SocialCommunity, self).initiate_meta_messages() + [
                Message(self, u"text", MemberAuthentication(), PublicResolution(), FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128), CommunityDestination(node_count=0), TextPayload(), self._generic_timeline_check, self.on_text),
                Message(self, u"encrypted", MemberAuthentication(), PublicResolution(), FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"DESC", priority=128), CommunityDestination(node_count=0), EncryptedPayload(), self._generic_timeline_check, self.on_encrypted)]

    def initiate_conversions(self):
        return [DefaultConversion(self), SocialConversion(self)]

    @property
    def dispersy_sync_skip_enable(self):
        return False

    @property
    def dispersy_sync_cache_enable(self):
        return False

    def sync_with_friend(self, tb):
        if self.is_taste_buddy(tb):
            self._orig_send_introduction_request(tb.candidate, None, True, False)
        else:
            self.cancel_pending_task(tb)

    def new_taste_buddy(self, tb):
        if tb.overlap:
            self._pending_tasks[tb] = lc = LoopingCall(self._sync_with_friend, tb)
            lc.start(SYNC_WITH_TASTE_BUDDIES_INTERVAL, now=True)

    def _get_packets_for_bloomfilters(self, requests, include_inactive=True):
        for message, time_low, time_high, offset, modulo in requests:

            tb = self.is_taste_buddy(message.candidate)
            if tb and tb.overlap:
                if DEBUG_VERBOSE:
                    print >> sys.stderr, "GOT sync-request from", message.candidate, tb

                keyhashes = tuple(buffer(str(overlapping_friend)) for overlapping_friend in tb.overlap)
                sync_ids = self._friend_db.execute(u"SELECT sync_id FROM friendsync WHERE global_time BETWEEN ? AND ? AND (global_time + ?) % ? = 0 AND keyhash in (" + ", ".join("?" * len(keyhashes)) + ")",
                                                   (time_low, time_high, offset, modulo) + keyhashes)

                sync_ids = tuple(str(sync_id) for sync_id, in sync_ids)
                yield message, ((str(packet),) for packet, in self._dispersy._database.execute(u"SELECT packet FROM sync WHERE undone = 0 AND id IN (" + ",".join(sync_ids) + ") ORDER BY global_time DESC"))

            elif DEBUG:
                print >> sys.stderr, "GOT sync-request from, ignoring", message.candidate

    def _select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher=True):
        tb = self.is_taste_buddy(request_cache.helper_candidate)
        if tb and tb.overlap:
            if DEBUG_VERBOSE:
                print >> sys.stderr, "SELECTING packets for", request_cache.helper_candidate, tb

            keyhashes = tuple(buffer(str(overlapping_friend)) for overlapping_friend in tb.overlap)

            # first select_and_fix based on friendsync table
            if higher:
                data = list(self._friend_db.execute(u"SELECT global_time, sync_id FROM friendsync WHERE global_time > ? AND keyhash in (" + ", ".join("?" * len(keyhashes)) + ") ORDER BY global_time ASC LIMIT ?",
                                                        (global_time,) + keyhashes + (to_select + 1,)))
            else:
                data = list(self._friend_db.execute(u"SELECT global_time, sync_id FROM friendsync WHERE global_time < ? AND keyhash in (" + ", ".join("?" * len(keyhashes)) + ") ORDER BY global_time DESC LIMIT ?",
                                                        (global_time,) + keyhashes + (to_select + 1,)))

            fixed = False
            if len(data) > to_select:
                fixed = True

                # if last 2 packets are equal, then we need to drop those
                global_time = data[-1][0]
                del data[-1]
                while data and data[-1][0] == global_time:
                    del data[-1]

            # next get actual packets from sync table, friendsync does not contain any non-syncable_messages hence this variable isn't used
            sync_ids = tuple(str(sync_id) for _, sync_id in data)
            if higher:
                data = list(self._dispersy._database.execute(u"SELECT global_time, packet FROM sync WHERE undone = 0 AND id IN (" + ",".join(sync_ids) + ") ORDER BY global_time ASC"))
            else:
                data = list(self._dispersy._database.execute(u"SELECT global_time, packet FROM sync WHERE undone = 0 AND id IN (" + ",".join(sync_ids) + ") ORDER BY global_time DESC"))

            if not higher:
                data.reverse()

            return data, fixed
        return [], False

    def _dispersy_claim_sync_bloom_filter_modulo(self, request_cache):
        raise NotImplementedError()

    def create_text(self, text, friends):
        assert isinstance(text, unicode), type(text)
        assert all(isinstance(friend, str) for friend in friends), [type(friend) for friend in friends]

        meta = self.get_meta_message(u"text")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(text,))

        for friend in friends:
            self.create_encrypted(message.packet, friend)

        # self._dispersy.store_update_forward([message], True, True, False)

    def on_text(self, messages):
        for message in messages:
            if self.log_text:
                self.log_text("text-statistics", message.candidate.sock_addr, global_time=message._distribution.global_time + 1, created_by=message.authentication.member.mid.encode('hex'))

    def create_encrypted(self, message_str, dest_friend):
        assert isinstance(message_str, str)
        assert isinstance(dest_friend, str)

        # get key
        key, keyhash = self._friend_db.get_friend(dest_friend)

        if key:
            # encrypt message
            encrypted_message = self.dispersy.crypto.encrypt(key, message_str)

            # get overlapping connections
            overlapping_candidates = [tb.candidate for tb in self.filter_overlap(self.yield_taste_buddies(), [keyhash, ])]

            meta = self.get_meta_message(u"encrypted")
            message = meta.impl(authentication=(self._my_member,),
                                distribution=(self.claim_global_time(),),
                                destination=(tuple(overlapping_candidates)),
                                payload=(keyhash, encrypted_message))

            self._dispersy.store_update_forward([message], True, True, True)

    def on_encrypted(self, messages):
        if __debug__:
            key_hashes = [keyhash for _, keyhash in self._friend_db.get_my_keys()] + [keyhash for _, _, keyhash in self._friend_db.get_friend_keys()]
            assert all(message.payload.keyhash in key_hashes for message in messages)

        decrypted_messages = []
        for message in messages:
            self._friend_db.add_message(message.packet_id, message._distribution.global_time, message.payload.keyhash)

            could_decrypt = False
            for key, keyhash in self._friend_db.get_my_keys():
                if keyhash == message.payload._keyhash:
                    decrypted_messages.append((message.candidate, self.dispersy.crypto.decrypt(key, message.payload.encrypted_message)))
                    could_decrypt = True
                    break

            if self.log_text:
                # if no candidate -> message is created by me
                self.log_text("encrypted-statistics", message.candidate.sock_addr if message.candidate else None, global_time=message._distribution.global_time, created_by=message.authentication.member.mid.encode('hex'), created_by_me=(message.candidate == None), could_decrypt=could_decrypt)

        if decrypted_messages:
            self._dispersy.on_incoming_packets(decrypted_messages, cache=False)

    def get_tbs_from_peercache(self, nr, nr_standins):
        tbs = [TasteBuddy(overlap, (ip, port)) for overlap, ip, port in self._peercache.get_peers()]

        friends, foafs = self.determine_friends_foafs(tbs)
        my_key_hashes = [keyhash for _, keyhash in self._friend_db.get_my_keys()]

        if len(friends) > nr:
            friends = sample(list(friends), nr)

        peercache_candidates = []
        for friend in friends:
            peercache_friend = [friend] * 2

            standins = set()
            for overlapping_hash in friend.overlap:
                if overlapping_hash not in my_key_hashes:
                    standins.update(foafs.get(overlapping_hash, []))

            remaining_standins = nr_standins - len(peercache_friend)
            if len(standins) > remaining_standins:
                standins = sample(list(standins), remaining_standins)

            peercache_friend.extend(standins)
            peercache_candidates.append(peercache_friend)

        return peercache_candidates

    def filter_tb(self, tbs):
        tbs = list(tbs)

        to_maintain, foafs = self.determine_friends_foafs(tbs)

        # for each friend we maintain an additional connection to at least one foaf
        # this peer is chosen randomly to attempt to load balance these pings
        for keyhash, f_tbs in foafs.iteritems():
            to_maintain.add(choice(f_tbs))

        if DEBUG:
            print >> sys.stderr, long(time()), "SocialCommunity: Will maintain", len(to_maintain), "connections instead of", len(tbs)

        return to_maintain

    def determine_friends_foafs(self, tbs):
        my_key_hashes = [keyhash for _, keyhash in self._friend_db.get_my_keys()]

        friends = self.filter_overlap(tbs, my_key_hashes)
        foafs = defaultdict(list)
        for tb in tbs:
            if tb not in friends:
                for keyhash in tb.overlap:
                    foafs[keyhash].append(tb)

        return friends, foafs

    def filter_overlap(self, tbs, keys):
        to_maintain = set()
        for tb in tbs:
            # if a peer has overlap with any of my_key_hashes, its my friend -> maintain connection
            if any(map(tb.does_overlap, keys)):
                to_maintain.add(tb)

        return to_maintain

    def add_possible_taste_buddies(self):
        my_key_hashes = [keyhash for _, keyhash in self._friend_db.get_my_keys()]

        connections = defaultdict(int)
        for tb in self.yield_taste_buddies():
            for keyhash in tb.overlap:
                connections[keyhash] += 1

        def prefer_my_friends(a, b):
            if any(map(a.does_overlap, my_key_hashes)):
                return 1

            if any(map(b.does_overlap, my_key_hashes)):
                return -1

            if a.overlap and b.overlap:
                # neither are my friend, sort by a foaf which connects me to a least connected friend
                min_a = min(connections[overlapping] for overlapping in a.overlap)
                min_b = min(connections[overlapping] for overlapping in b.overlap)
                return cmp(min_a, min_b)

            if a.overlap:
                return 1
            if b.overlap:
                return -1
            return cmp(a, b)

        self.possible_taste_buddies.sort(cmp=prefer_my_friends, reverse=True)

        if DEBUG_VERBOSE:
            print >> sys.stderr, long(time()), "SocialCommunity: After sorting", [any(map(tb.does_overlap, my_key_hashes)) for tb in self.possible_taste_buddies], map(str, self.possible_taste_buddies),
        elif DEBUG:
            print >> sys.stderr, long(time()), "SocialCommunity: After sorting", [any(map(tb.does_overlap, my_key_hashes)) for tb in self.possible_taste_buddies]

class NoFSocialCommunity(HForwardCommunity, SocialCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, psi_mode=PSI_CARDINALITY, log_text=None):
        SocialCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, encryption, log_text)
        HForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 0, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, psi_mode=psi_mode, send_simi_reveal=True)

    def initiate_conversions(self):
        return HForwardCommunity.initiate_conversions(self) + [SocialConversion(self)]

    def initiate_meta_messages(self):
        return SocialCommunity.initiate_meta_messages(self) + HForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        SocialCommunity._initialize_meta_messages(self)
        HForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        HForwardCommunity.unload_community(self)
        SocialCommunity.unload_community(self)

    def add_possible_taste_buddies(self, possibles):
        HForwardCommunity.add_possible_taste_buddies(self, possibles)
        SocialCommunity.add_possible_taste_buddies(self)

    def new_taste_buddy(self, tb):
        HForwardCommunity.new_taste_buddy(self, tb)
        SocialCommunity.new_taste_buddy(self, tb)

    def filter_tb(self, tbs):
        return SocialCommunity.filter_tb(self, tbs)

    def get_tbs_from_peercache(self, nr, standins):
        return SocialCommunity.get_tbs_from_peercache(self, nr, standins)

    def _dispersy_claim_sync_bloom_filter_modulo(self):
        return SocialCommunity._dispersy_claim_sync_bloom_filter_modulo(self)

    def _select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher=True):
        return SocialCommunity._select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher)

class PSocialCommunity(PForwardCommunity, SocialCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, psi_mode=PSI_CARDINALITY, log_text=None):
        SocialCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, encryption, log_text)
        PForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, psi_mode=psi_mode, send_simi_reveal=True)

    def initiate_conversions(self):
        return PForwardCommunity.initiate_conversions(self) + [SocialConversion(self)]

    def initiate_meta_messages(self):
        return SocialCommunity.initiate_meta_messages(self) + PForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        SocialCommunity._initialize_meta_messages(self)
        PForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        PForwardCommunity.unload_community(self)
        SocialCommunity.unload_community(self)

    def add_possible_taste_buddies(self, possibles):
        PForwardCommunity.add_possible_taste_buddies(self, possibles)
        SocialCommunity.add_possible_taste_buddies(self)

    def new_taste_buddy(self, tb):
        PForwardCommunity.new_taste_buddy(self, tb)
        SocialCommunity.new_taste_buddy(self, tb)

    def filter_tb(self, tbs):
        return SocialCommunity.filter_tb(self, tbs)

    def get_tbs_from_peercache(self, nr, standins):
        return SocialCommunity.get_tbs_from_peercache(self, nr, standins)

    def _dispersy_claim_sync_bloom_filter_modulo(self):
        return SocialCommunity._dispersy_claim_sync_bloom_filter_modulo(self)

    def _select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher=True):
        return SocialCommunity._select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher)

class HSocialCommunity(HForwardCommunity, SocialCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, psi_mode=PSI_CARDINALITY, log_text=None):
        SocialCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, encryption, log_text)
        HForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, psi_mode=psi_mode, send_simi_reveal=True)

    def initiate_conversions(self):
        return HForwardCommunity.initiate_conversions(self) + [SocialConversion(self)]

    def initiate_meta_messages(self):
        return SocialCommunity.initiate_meta_messages(self) + HForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        SocialCommunity._initialize_meta_messages(self)
        HForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        HForwardCommunity.unload_community(self)
        SocialCommunity.unload_community(self)

    def add_possible_taste_buddies(self, possibles):
        HForwardCommunity.add_possible_taste_buddies(self, possibles)
        SocialCommunity.add_possible_taste_buddies(self)

    def new_taste_buddy(self, tb):
        HForwardCommunity.new_taste_buddy(self, tb)
        SocialCommunity.new_taste_buddy(self, tb)

    def filter_tb(self, tbs):
        return SocialCommunity.filter_tb(self, tbs)

    def get_tbs_from_peercache(self, nr, standins):
        return SocialCommunity.get_tbs_from_peercache(self, nr, standins)

    def _dispersy_claim_sync_bloom_filter_modulo(self):
        return SocialCommunity._dispersy_claim_sync_bloom_filter_modulo(self)

    def _select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher=True):
        return SocialCommunity._select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher)

class PoliSocialCommunity(PoliForwardCommunity, SocialCommunity):

    def __init__(self, dispersy, master, my_member, integrate_with_tribler=True, encryption=ENCRYPTION, max_prefs=None, max_fprefs=None, psi_mode=PSI_CARDINALITY, log_text=None, send_simi_reveal=True):
        SocialCommunity.__init__(self, dispersy, master, my_member, integrate_with_tribler, encryption, log_text)
        PoliForwardCommunity.__init__(self, dispersy, integrate_with_tribler, encryption, 10, max_prefs, max_fprefs, max_taste_buddies=sys.maxint, psi_mode=psi_mode, send_simi_reveal=send_simi_reveal)

    def initiate_conversions(self):
        return PoliForwardCommunity.initiate_conversions(self) + [SocialConversion(self)]

    def initiate_meta_messages(self):
        return SocialCommunity.initiate_meta_messages(self) + PoliForwardCommunity.initiate_meta_messages(self)

    def _initialize_meta_messages(self):
        SocialCommunity._initialize_meta_messages(self)
        PoliForwardCommunity._initialize_meta_messages(self)

    def unload_community(self):
        PoliForwardCommunity.unload_community(self)
        SocialCommunity.unload_community(self)

    def add_possible_taste_buddies(self, possibles):
        PoliForwardCommunity.add_possible_taste_buddies(self, possibles)
        SocialCommunity.add_possible_taste_buddies(self)

    def new_taste_buddy(self, tb):
        PoliForwardCommunity.new_taste_buddy(self, tb)
        SocialCommunity.new_taste_buddy(self, tb)

    def filter_tb(self, tbs):
        return SocialCommunity.filter_tb(self, tbs)

    def get_tbs_from_peercache(self, nr, standins):
        return SocialCommunity.get_tbs_from_peercache(self, nr, standins)

    def _dispersy_claim_sync_bloom_filter_modulo(self):
        return SocialCommunity._dispersy_claim_sync_bloom_filter_modulo(self)

    def _select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher=True):
        return SocialCommunity._select_and_fix(self, request_cache, syncable_messages, global_time, to_select, higher)

########NEW FILE########
__FILENAME__ = conversion
# Written by Niels Zeilemaker
from struct import pack, unpack_from

from Tribler.dispersy.conversion import NoDefBinaryConversion
from Tribler.dispersy.message import DropPacket
from Tribler.community.privatesemantic.conversion import long_to_bytes, \
    bytes_to_long

class SocialConversion(NoDefBinaryConversion):

    def __init__(self, community):
        super(SocialConversion, self).__init__(community, "\x02")
        self.define_meta_message(chr(1), community.get_meta_message(u"text"), self._encode_text, self._decode_text)
        self.define_meta_message(chr(2), community.get_meta_message(u"encrypted"), self._encode_encrypted, self._decode_encrypted)

    def _encode_text(self, message):
        assert len(message.payload.text.encode("UTF-8")) < 512
        text = message.payload.text.encode("UTF-8")
        return pack("!B", len(text)), text[:512]

    def _decode_text(self, placeholder, offset, data):
        if len(data) < offset + 1:
            raise DropPacket("Insufficient packet size")

        text_length, = unpack_from("!B", data, offset)
        offset += 1

        try:
            text = data[offset:offset + text_length].decode("UTF-8")
            offset += text_length
        except UnicodeError:
            raise DropPacket("Unable to decode UTF-8")

        return offset, placeholder.meta.payload.implement(text)

    def _encode_encrypted(self, message):
        keyhash = long_to_bytes(message.payload.keyhash, 20)
        return pack("!20s%ds" % len(message.payload.encrypted_message), keyhash, message.payload.encrypted_message),

    def _decode_encrypted(self, placeholder, offset, data):
        if len(data) < offset + 20:
            raise DropPacket("Insufficient packet size")

        keyhash, encrypted_message = unpack_from("!20s%ds" % (len(data) - offset - 20), data, offset)
        offset += len(keyhash) + len(encrypted_message)

        keyhash = bytes_to_long(keyhash)
        return offset, placeholder.meta.payload.implement(keyhash, encrypted_message)

########NEW FILE########
__FILENAME__ = database
from os import path
from time import time

from Tribler.dispersy.database import Database

LATEST_VERSION = 1

schema = u"""
CREATE TABLE friendsync(
 sync_id integer PRIMARY KEY,
 global_time integer,
 keyhash text
);

CREATE TABLE friends(
 id integer PRIMARY KEY AUTOINCREMENT NOT NULL,
 name text,
 key text,
 keyhash text
 );
 
 CREATE TABLE my_keys(
 id integer PRIMARY KEY AUTOINCREMENT NOT NULL,
 key text,
 keyhash text,
 inserted real
 );
 
CREATE TABLE option(key TEXT PRIMARY KEY, value BLOB);
INSERT INTO option(key, value) VALUES('database_version', '""" + str(LATEST_VERSION) + """');
"""

class FriendDatabase(Database):
    if __debug__:
        __doc__ = schema

    def __init__(self, dispersy):
        self._dispersy = dispersy

        if self._dispersy._database._file_path == u":memory:":
            super(FriendDatabase, self).__init__(u":memory:")
        else:
            super(FriendDatabase, self).__init__(path.join(dispersy.working_directory, u"sqlite", u"friendsync.db"))

    def open(self):
        self._dispersy.database.attach_commit_callback(self.commit)
        return super(FriendDatabase, self).open()

    def close(self, commit=True):
        self._dispersy.database.detach_commit_callback(self.commit)
        return super(FriendDatabase, self).close(commit)

    def check_database(self, database_version):
        assert isinstance(database_version, unicode)
        assert database_version.isdigit()
        assert int(database_version) >= 0
        database_version = int(database_version)

        # setup new database with current database_version
        if database_version < 1:
            self.executescript(schema)
            self.commit()

        else:
            # upgrade to version 2
            if database_version < 2:
                # there is no version 2 yet...
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2)
                # self.executescript(u"""UPDATE option SET value = '2' WHERE key = 'database_version';""")
                # self.commit()
                # if __debug__: dprint("upgrade database ", database_version, " -> ", 2, " (done)")
                pass

        return LATEST_VERSION

    def get_database_stats(self):
        stats_dict = {}

        for tablename, in list(self.execute(u'SELECT name FROM sqlite_master WHERE type = "table"')):
            count, = self.execute(u"SELECT COUNT(*) FROM " + tablename).next()
            stats_dict[str(tablename)] = count
        return stats_dict

    def add_message(self, sync_id, global_time, keyhash):
        _keyhash = buffer(str(keyhash))
        self.execute(u"INSERT INTO friendsync (sync_id, global_time, keyhash) VALUES (?,?,?) ", (sync_id, global_time, _keyhash))

    def add_friend(self, name, key, keyhash):
        _name = unicode(name)
        _key = buffer(self._dispersy.crypto.key_to_bin(key.pub()))
        _keyhash = buffer(str(keyhash))
        self.execute(u"INSERT INTO friends (name, key, keyhash) VALUES (?,?,?)", (_name, _key, _keyhash))

    def get_friend(self, name):
        return self._converted_keys(self.execute(u"SELECT key, keyhash FROM friends WHERE name = ?", (unicode(name),))).next()

    def get_friend_by_hash(self, keyhash):
        _keyhash = buffer(str(keyhash))
        return self._converted_keys(self.execute(u"SELECT key, keyhash FROM friends WHERE keyhash = ?", (_keyhash,))).next()

    def get_friend_keys(self):
        return list(self._converted_keys(self.execute(u"SELECT name, key, keyhash FROM friends")))

    def add_my_key(self, key, keyhash):
        _key = buffer(self._dispersy.crypto.key_to_bin(key))
        _keyhash = buffer(str(keyhash))
        self.execute(u"INSERT INTO my_keys (key, keyhash, inserted) VALUES (?,?,?)", (_key, _keyhash, time()))

    def get_my_keys(self):
        return list(self._converted_keys(self.execute(u"SELECT key, keyhash FROM my_keys ORDER BY inserted DESC"), mykeys=True))

    def _converted_keys(self, keylist, mykeys=False):
        did_yield = False
        for keytuple in keylist:
            if len(keytuple) == 3:
                yield keytuple[0], (self._dispersy.crypto.key_from_private_bin(str(keytuple[1])) if mykeys else self._dispersy.crypto.key_from_public_bin(str(keytuple[1]))), long(str(keytuple[2]))
            else:
                yield (self._dispersy.crypto.key_from_private_bin(str(keytuple[0])) if mykeys else self._dispersy.crypto.key_from_public_bin(str(keytuple[0]))), long(str(keytuple[1]))
            did_yield = True

        if not did_yield:
            yield None, None

########NEW FILE########
__FILENAME__ = payload
# Written by Niels Zeilemaker
from Tribler.dispersy.payload import Payload

class TextPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, text):
            assert isinstance(text, unicode)
            assert len(text.encode("UTF-8")) < 512
            super(TextPayload.Implementation, self).__init__(meta)
            self._text = text

        @property
        def text(self):
            return self._text

class EncryptedPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, keyhash, encrypted_message):
            assert isinstance(keyhash, long), type(keyhash)
            assert isinstance(encrypted_message, str), type(encrypted_message)

            super(EncryptedPayload.Implementation, self).__init__(meta)
            self._keyhash = keyhash
            self._encrypted_message = encrypted_message

        @property
        def keyhash(self):
            return self._keyhash

        @property
        def encrypted_message(self):
            return self._encrypted_message

########NEW FILE########
__FILENAME__ = community
# Written by Niels Zeilemaker
import logging
from os import path
from random import shuffle
from time import time
from traceback import print_exc

from twisted.internet.task import LoopingCall

from Tribler.Core.CacheDB.sqlitecachedb import bin2str
from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.community.channel.payload import TorrentPayload
from Tribler.community.channel.preview import PreviewChannelCommunity
from Tribler.community.search.conversion import SearchConversion
from Tribler.community.search.payload import (SearchRequestPayload, SearchResponsePayload, TorrentRequestPayload,
                                              TorrentCollectRequestPayload, TorrentCollectResponsePayload,
                                              TasteIntroPayload)
from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.bloomfilter import BloomFilter
from Tribler.dispersy.candidate import CANDIDATE_WALK_LIFETIME, WalkCandidate
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.database import IgnoreCommits
from Tribler.dispersy.destination import CandidateDestination, CommunityDestination
from Tribler.dispersy.distribution import DirectDistribution, FullSyncDistribution
from Tribler.dispersy.exception import CommunityNotFoundException
from Tribler.dispersy.message import Message
from Tribler.dispersy.requestcache import RandomNumberCache, IntroductionRequestCache
from Tribler.dispersy.resolution import PublicResolution


logger = logging.getLogger(__name__)


DEBUG = False
SWIFT_INFOHASHES = 0
CREATE_TORRENT_COLLECT_INTERVAL = 5

class SearchCommunity(Community):

    """
    A single community that all Tribler members join and use to disseminate .torrent files.
    """
    @classmethod
    def get_master_members(cls, dispersy):
# generated: Mon May  7 17:43:59 2012
# curve: high <<< NID_sect571r1 >>>
# len: 571 bits ~ 144 bytes signature
# pub: 170 3081a7301006072a8648ce3d020106052b81040027038192000405c09348b2243e53fa190f17fc8c9843d61fc67e8ea22d7b031913ffc912897b57be780c06213dbf937d87e3ef1d48bf8f76e03d5ec40b1cdb877d9fa1ec1f133a412601c262d9ef01840ffc49d6131b1df9e1eac41a8ff6a1730d4541a64e733ed7cee415b220e4a0d2e8ace5099520bf8896e09cac3800a62974f5574910d75166d6529dbaf016e78090afbfaf8373
# pub-sha1 2782dc9253cef6cc9272ee8ed675c63743c4eb3a
#-----BEGIN PUBLIC KEY-----
# MIGnMBAGByqGSM49AgEGBSuBBAAnA4GSAAQFwJNIsiQ+U/oZDxf8jJhD1h/Gfo6i
# LXsDGRP/yRKJe1e+eAwGIT2/k32H4+8dSL+PduA9XsQLHNuHfZ+h7B8TOkEmAcJi
# 2e8BhA/8SdYTGx354erEGo/2oXMNRUGmTnM+187kFbIg5KDS6KzlCZUgv4iW4Jys
# OACmKXT1V0kQ11Fm1lKduvAW54CQr7+vg3M=
#-----END PUBLIC KEY-----
        master_key = "3081a7301006072a8648ce3d020106052b81040027038192000405c09348b2243e53fa190f17fc8c9843d61fc67e8ea22d7b031913ffc912897b57be780c06213dbf937d87e3ef1d48bf8f76e03d5ec40b1cdb877d9fa1ec1f133a412601c262d9ef01840ffc49d6131b1df9e1eac41a8ff6a1730d4541a64e733ed7cee415b220e4a0d2e8ace5099520bf8896e09cac3800a62974f5574910d75166d6529dbaf016e78090afbfaf8373".decode("HEX")
        master = dispersy.get_member(public_key=master_key)
        return [master]

    def initialize(self, integrate_with_tribler=True, log_incomming_searches=False):
        super(SearchCommunity, self).initialize()

        self._logger = logging.getLogger(self.__class__.__name__)

        self.integrate_with_tribler = integrate_with_tribler
        self.log_incomming_searches = log_incomming_searches
        self.taste_buddies = []
        # To always connect to a peer uncomment/modify the following line
        # self.taste_buddies.append([1, time(), Candidate(("127.0.0.1", 1234), False))

        if self.integrate_with_tribler:
            from Tribler.Core.CacheDB.SqliteCacheDBHandler import ChannelCastDBHandler, TorrentDBHandler, MyPreferenceDBHandler, MiscDBHandler
            from Tribler.Core.CacheDB.Notifier import Notifier

            # tribler channelcast database
            self._channelcast_db = ChannelCastDBHandler.getInstance()
            self._misc_db = MiscDBHandler.getInstance()
            self._torrent_db = TorrentDBHandler.getInstance()
            self._mypref_db = MyPreferenceDBHandler.getInstance()
            self._notifier = Notifier.getInstance()

            # torrent collecting
            self._rtorrent_handler = RemoteTorrentHandler.getInstance()
        else:
            self._channelcast_db = ChannelCastDBStub(self._dispersy)
            self._torrent_db = None
            self._mypref_db = None
            self._notifier = None

        self.taste_bloom_filter = None
        self.taste_bloom_filter_key = None

        self.torrent_cache = None

        self._pending_tasks["create torrent collect requests"] = lc = LoopingCall(self.create_torrent_collect_requests)
        lc.start(CREATE_TORRENT_COLLECT_INTERVAL, now=True)

    @property
    def dispersy_enable_fast_candidate_walker(self):
        return True

    def initiate_meta_messages(self):
        return super(SearchCommunity, self).initiate_meta_messages() + [
            Message(self, u"search-request",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    SearchRequestPayload(),
                    self.check_search,
                    self.on_search),
            Message(self, u"search-response",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    SearchResponsePayload(),
                    self.check_search_response,
                    self.on_search_response),
            Message(self, u"torrent-request",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    TorrentRequestPayload(),
                    self.check_torrent_request,
                    self.on_torrent_request),
            Message(self, u"torrent-collect-request",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    TorrentCollectRequestPayload(),
                    self.check_torrent_collect_request,
                    self.on_torrent_collect_request),
            Message(self, u"torrent-collect-response",
                    MemberAuthentication(),
                    PublicResolution(),
                    DirectDistribution(),
                    CandidateDestination(),
                    TorrentCollectResponsePayload(),
                    self.check_torrent_collect_response,
                    self.on_torrent_collect_response),
            Message(self, u"torrent",
                    MemberAuthentication(),
                    PublicResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"ASC", priority=128),
                    CommunityDestination(node_count=0),
                    TorrentPayload(),
                    self.check_torrent,
                    self.on_torrent),
        ]

    def _initialize_meta_messages(self):
        Community._initialize_meta_messages(self)

        ori = self._meta_messages[u"dispersy-introduction-request"]
        new = Message(self, ori.name, ori.authentication, ori.resolution, ori.distribution, ori.destination, TasteIntroPayload(), ori.check_callback, ori.handle_callback)
        self._meta_messages[u"dispersy-introduction-request"] = new

    def initiate_conversions(self):
        return [DefaultConversion(self), SearchConversion(self)]

    @property
    def dispersy_auto_download_master_member(self):
        # there is no dispersy-identity for the master member, so don't try to download
        return False

    @property
    def dispersy_enable_bloom_filter_sync(self):
        # 1. disable bloom filter sync in walker
        # 2. accept messages in any global time range
        return False

    def add_taste_buddies(self, new_taste_buddies):
        for new_tb_tuple in new_taste_buddies[:]:
            for tb_tuple in self.taste_buddies:
                if tb_tuple[-1].sock_addr == new_tb_tuple[-1].sock_addr:

                    # update similarity
                    tb_tuple[0] = max(new_tb_tuple[0], tb_tuple[0])
                    new_taste_buddies.remove(new_tb_tuple)
                    break
            else:
                self.taste_buddies.append(new_tb_tuple)

        self.taste_buddies.sort(reverse=True)
        self.taste_buddies = self.taste_buddies[:10]

        # Send ping to all new candidates
        if len(new_taste_buddies) > 0:
            self._create_torrent_collect_requests([tb_tuple[-1] for tb_tuple in new_taste_buddies])

    def get_nr_connections(self):
        return len(self.get_connections())

    def get_connections(self):
        # add 10 taste buddies and 20 - len(taste_buddies) to candidates
        candidates = set(candidate for _, _, candidate in self.taste_buddies)
        sock_addresses = set(candidate.sock_addr for _, _, candidate in self.taste_buddies)

        for candidate in self.dispersy_yield_candidates():
            if candidate.sock_addr not in sock_addresses:
                candidates.add(candidate)
                sock_addresses.add(candidate.sock_addr)

            if len(candidates) == 20:
                break
        return candidates

    def __calc_similarity(self, candidate, myPrefs, hisPrefs, overlap):
        if myPrefs > 0 and hisPrefs > 0:
            myRoot = 1.0 / (myPrefs ** .5)
            sim = overlap * (myRoot * (1.0 / (hisPrefs ** .5)))
            return [sim, time(), candidate]

        return [0, time(), candidate]

    def create_introduction_request(self, destination, allow_sync, is_fast_walker=False):
        assert isinstance(destination, WalkCandidate), [type(destination), destination]

        if DEBUG:
            self._logger.debug("SearchCommunity: sending introduction request to %s", destination)

        advice = True
        if not is_fast_walker:
            myPreferences = sorted(self._mypref_db.getMyPrefListInfohash(limit=500))
            num_preferences = len(myPreferences)

            myPref_key = ",".join(map(bin2str, myPreferences))
            if myPref_key != self.taste_bloom_filter_key:
                if num_preferences > 0:
                    # no prefix changing, we want false positives (make sure it is a single char)
                    self.taste_bloom_filter = BloomFilter(0.005, len(myPreferences), prefix=' ')
                    self.taste_bloom_filter.add_keys(myPreferences)
                else:
                    self.taste_bloom_filter = None

                self.taste_bloom_filter_key = myPref_key

            taste_bloom_filter = self.taste_bloom_filter

            cache = self._request_cache.add(IntroductionRequestCache(self, destination))
            payload = (destination.sock_addr, self._dispersy._lan_address, self._dispersy._wan_address, advice, self._dispersy._connection_type, None, cache.number, num_preferences, taste_bloom_filter)
        else:
            cache = self._request_cache.add(IntroductionRequestCache(self, destination))
            payload = (destination.sock_addr, self._dispersy._lan_address, self._dispersy._wan_address, advice, self._dispersy._connection_type, None, cache.number, 0, None)

        destination.walk(time())
        self.add_candidate(destination)

        meta_request = self.get_meta_message(u"dispersy-introduction-request")
        request = meta_request.impl(authentication=(self.my_member,),
                                   distribution=(self.global_time,),
                                destination=(destination,),
                                payload=payload)

        logger.debug("%s %s sending introduction request to %s", self.cid.encode("HEX"), type(self), destination)

        self._dispersy._forward([request])
        return request

    def on_introduction_request(self, messages):
        super(SearchCommunity, self).on_introduction_request(messages)

        if any(message.payload.taste_bloom_filter for message in messages):
            myPreferences = self._mypref_db.getMyPrefListInfohash(limit=500)
        else:
            myPreferences = []

        newTasteBuddies = []
        for message in messages:
            taste_bloom_filter = message.payload.taste_bloom_filter
            num_preferences = message.payload.num_preferences
            if taste_bloom_filter:
                overlap = sum(infohash in taste_bloom_filter for infohash in myPreferences)
            else:
                overlap = 0

            newTasteBuddies.append(self.__calc_similarity(message.candidate, len(myPreferences), num_preferences, overlap))

        if len(newTasteBuddies) > 0:
            self.add_taste_buddies(newTasteBuddies)

        if self._notifier:
            from Tribler.Core.simpledefs import NTFY_ACT_MEET, NTFY_ACTIVITIES, NTFY_INSERT
            for message in messages:
                self._notifier.notify(NTFY_ACTIVITIES, NTFY_INSERT, NTFY_ACT_MEET, "%s:%d" % message.candidate.sock_addr)

    class SearchRequest(RandomNumberCache):

        def __init__(self, request_cache, keywords, callback):
            super(SearchCommunity.SearchRequest, self).__init__(request_cache, u"search")
            self.keywords = keywords
            self.callback = callback

        @property
        def timeout_delay(self):
            return 30.0

        def on_timeout(self):
            pass

    def create_search(self, keywords, callback):
        candidates = self.get_connections()
        if len(candidates) > 0:
            if DEBUG:
                self._logger.debug("SearchCommunity: sending search request for %s to %s", keywords, map(str, candidates))

            # register callback/fetch identifier
            cache = self._request_cache.add(SearchCommunity.SearchRequest(self._request_cache, keywords, callback))

            # create search request message
            meta = self.get_meta_message(u"search-request")
            message = meta.impl(authentication=(self._my_member,),
                                distribution=(self.global_time,), payload=(cache.number, keywords))

            self._dispersy._send(candidates, [message])

        return len(candidates)

    def check_search(self, messages):
        return messages

    def on_search(self, messages):
        for message in messages:
            keywords = message.payload.keywords

            if DEBUG:
                self._logger.debug("SearchCommunity: got search request for %s", keywords)

            if self.log_incomming_searches:
                self.log_incomming_searches(message.candidate.sock_addr, keywords)

            results = []
            dbresults = self._torrent_db.searchNames(keywords, local=False, keys=['infohash', 'T.name', 'T.length', 'T.num_files', 'T.category_id', 'T.creation_date', 'T.num_seeders', 'T.num_leechers', 'swift_hash', 'swift_torrent_hash'])
            if len(dbresults) > 0:
                for dbresult in dbresults:
                    channel_details = dbresult[-10:]

                    dbresult = list(dbresult[:10])
                    dbresult[2] = long(dbresult[2])
                    dbresult[3] = int(dbresult[3])
                    dbresult[4] = [self._misc_db.categoryId2Name(dbresult[4]), ]
                    dbresult[5] = long(dbresult[5])
                    dbresult[6] = int(dbresult[6] or 0)
                    dbresult[7] = int(dbresult[7] or 0)
                    if dbresult[8]:
                        dbresult[8] = str(dbresult[8])
                    if dbresult[9]:
                        dbresult[9] = str(dbresult[9])

                    if channel_details[1]:
                        channel_details[1] = str(channel_details[1])
                    dbresult.append(channel_details[1])

                    results.append(tuple(dbresult))
            elif DEBUG:
                self._logger.debug("SearchCommunity: no results")

            self._create_search_response(message.payload.identifier, results, message.candidate)

    def _create_search_response(self, identifier, results, candidate):
        # create search-response message
        meta = self.get_meta_message(u"search-response")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), destination=(candidate,), payload=(identifier, results))
        self._dispersy._forward([message])

        if DEBUG:
            self._logger.debug("SearchCommunity: returning %s results to %s", len(results), candidate)

    def check_search_response(self, messages):
        return messages

    def on_search_response(self, messages):
        # _get_channel_community could cause multiple commits, using this with clause this is reduced to only one.
        with self._dispersy.database:
            for message in messages:
                # fetch callback using identifier
                search_request = self._request_cache.get(u"search", message.payload.identifier)
                if search_request:
                    if DEBUG:
                        self._logger.debug("SearchCommunity: got search response for %s %s %s", search_request.keywords, len(message.payload.results), message.candidate)

                    if len(message.payload.results) > 0:
                        self._torrent_db.on_search_response(message.payload.results)

                    search_request.callback(search_request.keywords, message.payload.results, message.candidate)

                    # see if we need to join some channels
                    channels = set([result[10] for result in message.payload.results if result[10]])
                    if channels:
                        channels = self._get_unknown_channels(channels)

                        if DEBUG:
                            self._logger.debug("SearchCommunity: joining %d preview communities" % len(channels))

                        for cid in channels:
                            community = self._get_channel_community(cid)
                            community.disp_create_missing_channel(message.candidate, includeSnapshot=False)
                else:
                    if DEBUG:
                        self._logger.debug("SearchCommunity: got search response identifier not found %s", message.payload.identifier)

            # ensure that no commits occur
            raise IgnoreCommits()

    def create_torrent_request(self, infohash, candidate):
        torrentdict = {}
        torrentdict[self._master_member.mid] = set([infohash, ])

        # create torrent-request message
        meta = self.get_meta_message(u"torrent-request")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.global_time,), destination=(candidate,), payload=(torrentdict,))
        self._dispersy._forward([message])

        if DEBUG:
            nr_requests = sum([len(cid_torrents) for cid_torrents in torrentdict.values()])
            self._logger.debug("SearchCommunity: requesting %s TorrentMessages from %s", nr_requests, candidate)

    def check_torrent_request(self, messages):
        return messages

    def on_torrent_request(self, messages):
        for message in messages:
            requested_packets = []
            for cid, torrents in message.payload.torrents.iteritems():
                requested_packets.extend(self._get_packets_from_infohashes(cid, torrents))

            if requested_packets:
                self._dispersy._send_packets([message.candidate], requested_packets,
                    self, "-caused by on-torrent-request-")

            if DEBUG:
                self._logger.debug("SearchCommunity: got request for %s torrents from %s", len(requested_packets), message.candidate)

    class PingRequestCache(RandomNumberCache):

        def __init__(self, community, candidate):
            super(SearchCommunity.PingRequestCache, self).__init__(community._request_cache, u"ping")

            self._logger = logging.getLogger(self.__class__.__name__)
            self.community = community
            self.candidate = candidate

        @property
        def timeout_delay(self):
            # we will accept the response at most 10.5 seconds after our request
            return 10.5

        def on_timeout(self):
            refreshIf = time() - CANDIDATE_WALK_LIFETIME
            remove = None
            for taste_buddy in self.community.taste_buddies:
                if taste_buddy[2] == self.candidate:
                    if taste_buddy[1] < refreshIf:
                        remove = taste_buddy
                    break

            if remove:
                self._logger.debug("SearchCommunity: no response on ping, removing from taste_buddies %s", self.candidate)
                self.community.taste_buddies.remove(remove)

    def create_torrent_collect_requests(self):
        refreshIf = time() - CANDIDATE_WALK_LIFETIME
        # determine to which peers we need to send a ping
        candidates = [candidate for _, prev, candidate in self.taste_buddies if prev < refreshIf]
        self._create_torrent_collect_requests(candidates)




    def _create_torrent_collect_requests(self, candidates):
        if len(candidates) > 0:
            self._create_pingpong(u"torrent-collect-request", candidates)

    def check_torrent_collect_request(self, messages):
        logger.debug("%d messages received", len(messages))
        return messages

    def on_torrent_collect_request(self, messages):
        logger.debug("%d messages received", len(messages))
        candidates = [message.candidate for message in messages]
        identifiers = [message.payload.identifier for message in messages]

        self._create_pingpong(u"torrent-collect-response", candidates, identifiers)
        self.on_torrent_collect_response(messages, verifyRequest=False)

    def check_torrent_collect_response(self, messages):
        logger.debug("%d messages received", len(messages))
        return messages

    def on_torrent_collect_response(self, messages, verifyRequest=True):
        logger.debug("%d messages received", len(messages))
        toInsert = {}
        toCollect = {}
        toPopularity = {}
        for message in messages:
            if verifyRequest:
                pong_request = self._request_cache.pop(u"ping", message.payload.identifier)
                logger.debug("pop %s", pong_request.candidate if pong_request else "unknown")
            else:
                logger.debug("no-pop")
                pong_request = True

            if pong_request and message.payload.hashtype == SWIFT_INFOHASHES:
                for swift_torrent_hash, infohash, seeders, leechers, ago in message.payload.torrents:
                    toInsert[infohash] = [infohash, swift_torrent_hash]
                    toPopularity[infohash] = [seeders, leechers, time() - (ago * 60)]
                    toCollect.setdefault(infohash, []).append(message.candidate)

        if len(toInsert) > 0:
            toInsert = toInsert.values()
            while toInsert:
                self._torrent_db.on_torrent_collect_response(toInsert[:50])
                toInsert = toInsert[50:]

        hashes = [hash_ for hash_ in toCollect.keys() if hash_]
        if hashes:
            hashesToCollect = self._torrent_db.selectSwiftTorrentsToCollect(hashes)
            for infohash, roothash in hashesToCollect[:5]:
                for candidate in toCollect[infohash]:
                    if DEBUG:
                        from Tribler.Core.CacheDB.sqlitecachedb import bin2str
                        self._logger.debug("SearchCommunity: requesting .torrent after receiving ping/pong %s %s %s", candidate, bin2str(infohash), bin2str(roothash))

                    # low_prio changes, hence we need to import it here
                    from Tribler.Core.RemoteTorrentHandler import LOW_PRIO_COLLECTING
                    self._rtorrent_handler.download_torrent(candidate, infohash, roothash, prio=LOW_PRIO_COLLECTING, timeout=CANDIDATE_WALK_LIFETIME)

    def _create_pingpong(self, meta_name, candidates, identifiers=None):
        max_len = self.dispersy_sync_bloom_filter_bits / 8
        limit = int(max_len / 44)

        torrents = self.__get_torrents(limit)
        for index, candidate in enumerate(candidates):
            if identifiers:
                identifier = identifiers[index]
            else:
                cache = self._request_cache.add(SearchCommunity.PingRequestCache(self, candidate))
                identifier = cache.number

            # create torrent-collect-request/response message
            meta = self.get_meta_message(meta_name)
            message = meta.impl(authentication=(self._my_member,),
                                distribution=(self.global_time,), destination=(candidate,), payload=(identifier, SWIFT_INFOHASHES, torrents))

            self._dispersy._forward([message])
            self._logger.debug("SearchCommunity: send %s to %s", meta_name, candidate)

        addresses = [candidate.sock_addr for candidate in candidates]
        for taste_buddy in self.taste_buddies:
            if taste_buddy[2].sock_addr in addresses:
                taste_buddy[1] = time()

    def __get_torrents(self, limit):
        cache_timeout = CANDIDATE_WALK_LIFETIME
        if self.torrent_cache and self.torrent_cache[0] > (time() - cache_timeout):
            return self.torrent_cache[1]

        # we want roughly 1/3 random, 2/3 recent
        limitRecent = int(limit * 0.66)
        limitRandom = limit - limitRecent

        torrents = self._torrent_db.getRecentlyCollectedSwiftHashes(limit=limitRecent) or []
        if len(torrents) == limitRecent:
            leastRecent = torrents[-1][5]
            randomTorrents = self._torrent_db.getRandomlyCollectedSwiftHashes(leastRecent, limit=limitRandom) or []
        else:
            randomTorrents = []

        # combine random and recent + shuffle to obscure categories
        torrents = [tor[:5] for tor in torrents] + randomTorrents
        shuffle(torrents)

        # fix leechers, seeders to max 2**16 (shift values +2 to accomodate -2 and -1 values)
        max_value = (2 ** 16) - 1
        for torrent in torrents:
            torrent[2] = min(max_value, (torrent[2] or -1) + 2)
            torrent[3] = min(max_value, (torrent[3] or -1) + 2)

            # convert to minutes
            torrent[4] /= 60
            if torrent[4] > max_value or torrent[4] < 0:
                torrent[4] = max_value

        self.torrent_cache = (time(), torrents)
        return torrents

    def create_torrent(self, filename, store=True, update=True, forward=True):
        if path.exists(filename):
            try:
                torrentdef = TorrentDef.load(filename)
                files = torrentdef.get_files_as_unicode_with_length()

                return self._disp_create_torrent(torrentdef.get_infohash(), long(time()), torrentdef.get_name_as_unicode(), tuple(files), torrentdef.get_trackers_as_single_tuple(), store, update, forward)
            except ValueError:
                pass
            except:
                print_exc()
        return False

    def _disp_create_torrent(self, infohash, timestamp, name, files, trackers, store=True, update=True, forward=True):
        meta = self.get_meta_message(u"torrent")
        message = meta.impl(authentication=(self._my_member,),
                            distribution=(self.claim_global_time(),),
                            payload=(infohash, timestamp, name, files, trackers))

        self._dispersy.store_update_forward([message], store, update, forward)
        self._torrent_db.updateTorrent(infohash, notify=False, dispersy_id=message.packet_id)
        return message

    def check_torrent(self, messages):
        return messages

    def on_torrent(self, messages):
        for message in messages:
            self._torrent_db.addExternalTorrentNoDef(message.payload.infohash, message.payload.name, message.payload.files, message.payload.trackers, message.payload.timestamp, "DISP_SC", {'dispersy_id': message.packet_id})

    def _get_channel_id(self, cid):
        assert isinstance(cid, str)
        assert len(cid) == 20

        return self._channelcast_db._db.fetchone(u"SELECT id FROM Channels WHERE dispersy_cid = ?", (buffer(cid),))

    def _get_unknown_channels(self, cids):
        assert all(isinstance(cid, str) for cid in cids)
        assert all(len(cid) == 20 for cid in cids)

        parameters = u",".join(["?"] * len(cids))
        known_cids = self._channelcast_db._db.fetchall(u"SELECT dispersy_cid FROM Channels WHERE dispersy_cid in (" + parameters + ")", map(buffer, cids))
        known_cids = map(str, known_cids)
        return [cid for cid in cids if cid not in known_cids]

    def _get_channel_community(self, cid):
        assert isinstance(cid, str)
        assert len(cid) == 20

        try:
            return self._dispersy.get_community(cid, True)
        except CommunityNotFoundException:
            logger.debug("join preview community %s", cid.encode("HEX"))
            return PreviewChannelCommunity.init_community(self._dispersy, self._dispersy.get_member(mid=cid), self._my_member, self.integrate_with_tribler)

    def _get_packets_from_infohashes(self, cid, infohashes):
        packets = []

        def add_packet(dispersy_id):
            if dispersy_id and dispersy_id > 0:
                try:
                    packet = self._get_packet_from_dispersy_id(dispersy_id, "torrent")
                    if packet:
                        packets.append(packet)
                except RuntimeError:
                    pass

        if cid == self._master_member.mid:
            channel_id = None
        else:
            channel_id = self._get_channel_id(cid)

        for infohash in infohashes:
            dispersy_id = None

            # 1. try to find the torrentmessage for this cid, infohash combination
            if channel_id:
                dispersy_id = self._channelcast_db.getTorrentFromChannelId(channel_id, infohash, ['ChannelTorrents.dispersy_id'])
            else:
                torrent = self._torrent_db.getTorrent(infohash, ['dispersy_id', 'torrent_file_name'], include_mypref=False)
                if torrent:
                    dispersy_id = torrent['dispersy_id']

                    # 2. if still not found, create a new torrentmessage and return this one
                    if not dispersy_id and torrent['torrent_file_name'] and path.isfile(torrent['torrent_file_name']):
                        message = self.create_torrent(torrent['torrent_file_name'], store=True, update=False, forward=False)
                        if message:
                            packets.append(message.packet)
            add_packet(dispersy_id)
        return packets

    def _get_packet_from_dispersy_id(self, dispersy_id, messagename):
        # 1. get the packet
        try:
            packet, packet_id = self._dispersy.database.execute(u"SELECT sync.packet, sync.id FROM community JOIN sync ON sync.community = community.id WHERE sync.id = ?", (dispersy_id,)).next()
        except StopIteration:
            raise RuntimeError("Unknown dispersy_id")

        return str(packet)


class ChannelCastDBStub():

    def __init__(self, dispersy):
        self._dispersy = dispersy

        self.cachedTorrents = None

    def convert_to_messages(self, results):
        messages = self._dispersy.convert_packets_to_messages(str(packet) for packet, _ in results)
        for packet_id, message in zip((packet_id for _, packet_id in results), messages):
            if message:
                message.packet_id = packet_id
                yield message.community.cid, message

    def newTorrent(self, message):
        self._cachedTorrents[message.payload.infohash] = message

    def hasTorrents(self, channel_id, infohashes):
        returnAr = []
        for infohash in infohashes:
            if infohash in self._cachedTorrents:
                returnAr.append(True)
            else:
                returnAr.append(False)
        return returnAr

    def getTorrentFromChannelId(self, channel_id, infohash, keys):
        if infohash in self._cachedTorrents:
            return self._cachedTorrents[infohash].packet_id

    def on_dynamic_settings(self, channel_id):
        pass

    @property
    def _cachedTorrents(self):
        if self.cachedTorrents is None:
            self.cachedTorrents = {}
            self._cacheTorrents()

        return self.cachedTorrents

    def _cacheTorrents(self):
        sql = u"SELECT sync.packet, sync.id FROM sync JOIN meta_message ON sync.meta_message = meta_message.id JOIN community ON community.id = sync.community WHERE meta_message.name = 'torrent'"
        results = list(self._dispersy.database.execute(sql))
        messages = self.convert_to_messages(results)

        for _, message in messages:
            self._cachedTorrents[message.payload.infohash] = message

########NEW FILE########
__FILENAME__ = conversion
# Written by Niels Zeilemaker
from struct import pack, unpack_from
from random import choice, sample
from math import ceil
import logging
import zlib

from Tribler.Core.Utilities.encoding import encode, decode
from Tribler.dispersy.message import DropPacket
from Tribler.dispersy.conversion import BinaryConversion
from Tribler.dispersy.bloomfilter import BloomFilter


class SearchConversion(BinaryConversion):

    def __init__(self, community):
        self._logger = logging.getLogger(self.__class__.__name__)

        super(SearchConversion, self).__init__(community, "\x01")
        self.define_meta_message(chr(1), community.get_meta_message(u"search-request"), lambda message: self._encode_decode(self._encode_search_request, self._decode_search_request, message), self._decode_search_request)
        self.define_meta_message(chr(2), community.get_meta_message(u"search-response"), lambda message: self._encode_decode(self._encode_search_response, self._decode_search_response, message), self._decode_search_response)
        self.define_meta_message(chr(3), community.get_meta_message(u"torrent-request"), lambda message: self._encode_decode(self._encode_torrent_request, self._decode_torrent_request, message), self._decode_torrent_request)
        self.define_meta_message(chr(4), community.get_meta_message(u"torrent-collect-request"), lambda message: self._encode_decode(self._encode_torrent_collect_request, self._decode_torrent_collect_request, message), self._decode_torrent_collect_request)
        self.define_meta_message(chr(5), community.get_meta_message(u"torrent-collect-response"), lambda message: self._encode_decode(self._encode_torrent_collect_response, self._decode_torrent_collect_response, message), self._decode_torrent_collect_response)
        self.define_meta_message(chr(6), community.get_meta_message(u"torrent"), lambda message: self._encode_decode(self._encode_torrent, self._decode_torrent, message), self._decode_torrent)

    def _encode_introduction_request(self, message):
        data = BinaryConversion._encode_introduction_request(self, message)

        if message.payload.taste_bloom_filter:
            data.extend((pack('!IBH', message.payload.num_preferences, message.payload.taste_bloom_filter.functions, message.payload.taste_bloom_filter.size), message.payload.taste_bloom_filter.prefix, message.payload.taste_bloom_filter.bytes))
        return data

    def _decode_introduction_request(self, placeholder, offset, data):
        offset, payload = BinaryConversion._decode_introduction_request(self, placeholder, offset, data)

        # if there's still bytes in this request, treat them as taste_bloom_filter
        has_stuff = len(data) > offset
        if has_stuff:
            if len(data) < offset + 8:
                raise DropPacket("Insufficient packet size")

            num_preferences, functions, size = unpack_from('!IBH', data, offset)
            offset += 7

            prefix = data[offset]
            offset += 1

            if not 0 < num_preferences:
                raise DropPacket("Invalid num_preferences value")
            if not 0 < functions:
                raise DropPacket("Invalid functions value")
            if not 0 < size:
                raise DropPacket("Invalid size value")
            if not size % 8 == 0:
                raise DropPacket("Invalid size value, must be a multiple of eight")

            length = int(ceil(size / 8))
            if not length == len(data) - offset:
                raise DropPacket("Invalid number of bytes available (irq) %d, %d, %d" % (length, len(data) - offset, size))

            taste_bloom_filter = BloomFilter(data[offset:offset + length], functions, prefix=prefix)
            offset += length

            payload.set_num_preferences(num_preferences)
            payload.set_taste_bloom_filter(taste_bloom_filter)

        return offset, payload

    def _encode_decode(self, encode, decode, message):
        result = encode(message)
        try:
            decode(None, 0, result[0])

        except DropPacket:
            raise
        except:
            pass
        return result

    def _encode_search_request(self, message):
        packet = pack('!H', message.payload.identifier), message.payload.keywords
        if message.payload.bloom_filter:
            packet = packet + (message.payload.bloom_filter.functions, message.payload.bloom_filter.prefix, message.payload.bloom_filter.bytes)
        packet = encode(packet)
        return packet,

    def _decode_search_request(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decodr 21, 2012 e the search-payload")

        if len(payload) < 2:
            raise DropPacket("Invalid payload length")

        identifier, keywords = payload[:2]

        if len(identifier) != 2:
            raise DropPacket("Unable to decode the search-payload, got %d bytes expected 2" % (len(identifier)))
        identifier, = unpack_from('!H', identifier)

        if not isinstance(keywords, list):
            raise DropPacket("Invalid 'keywords' type")
        for keyword in keywords:
            if not isinstance(keyword, unicode):
                raise DropPacket("Invalid 'keyword' type")

        if len(payload) > 5:
            functions, prefix, bytes_ = payload[2:6]

            if not isinstance(functions, int):
                raise DropPacket("Invalid functions type")
            if not 0 < functions:
                raise DropPacket("Invalid functions value")

            size = len(bytes_)
            if not 0 < size:
                raise DropPacket("Invalid size of bloomfilter")
            if not size % 8 == 0:
                raise DropPacket("Invalid size of bloomfilter, must be a multiple of eight")

            if not isinstance(prefix, str):
                raise DropPacket("Invalid prefix type")
            if not 0 <= len(prefix) < 256:
                raise DropPacket("Invalid prefix length")

            bloom_filter = BloomFilter(bytes_, functions, prefix=prefix)
        else:
            bloom_filter = None

        return offset, placeholder.meta.payload.implement(identifier, keywords, bloom_filter)

    def _encode_search_response(self, message):
        packet = pack('!H', message.payload.identifier), message.payload.results
        return encode(packet),

    def _decode_search_response(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the search-reponse-payload")

        if len(payload) < 2:
            raise DropPacket("Invalid payload length")

        identifier, results = payload[:2]

        if len(identifier) != 2:
            raise DropPacket("Unable to decode the search-response-payload, got %d bytes expected 2" % (len(identifier)))
        identifier, = unpack_from('!H', identifier)

        if not isinstance(results, list):
            raise DropPacket("Invalid 'results' type")

        for result in results:
            if not isinstance(result, tuple):
                raise DropPacket("Invalid result type")

            if len(result) < 11:
                raise DropPacket("Invalid result length")

            infohash, swarmname, length, nrfiles, categorykeys, creation_date, seeders, leechers, swift_hash, swift_torrent_hash, cid = result[:11]

            if not isinstance(infohash, str):
                raise DropPacket("Invalid infohash type")
            if len(infohash) != 20:
                raise DropPacket("Invalid infohash length")

            if not isinstance(swarmname, unicode):
                raise DropPacket("Invalid swarmname type")

            if not isinstance(length, long):
                raise DropPacket("Invalid length type '%s'" % type(length))

            if not isinstance(nrfiles, int):
                raise DropPacket("Invalid nrfiles type")

            if not isinstance(categorykeys, list):
                raise DropPacket("Invalid categorykeys type")

            if not all(isinstance(key, unicode) for key in categorykeys):
                raise DropPacket("Invalid categorykey type")

            if not isinstance(creation_date, long):
                raise DropPacket("Invalid creation_date type")

            if not isinstance(seeders, int):
                raise DropPacket("Invalid seeders type '%s'" % type(seeders))

            if not isinstance(leechers, int):
                raise DropPacket("Invalid leechers type '%s'" % type(leechers))

            if swift_hash:
                if not isinstance(swift_hash, str):
                    raise DropPacket("Invalid swift_hash type '%s'" % type(swift_hash))

                if len(swift_hash) != 20:
                    raise DropPacket("Invalid swift_hash length")

            if swift_torrent_hash:
                if not isinstance(swift_torrent_hash, str):
                    raise DropPacket("Invalid swift_torrent_hash type")

                if len(swift_torrent_hash) != 20:
                    raise DropPacket("Invalid swift_torrent_hash length")

            if cid:
                if not isinstance(cid, str):
                    raise DropPacket("Invalid cid type")

                if len(cid) != 20:
                    raise DropPacket("Invalid cid length")

        return offset, placeholder.meta.payload.implement(identifier, results)

    def _encode_torrent_request(self, message):
        max_len = self._community.dispersy_sync_bloom_filter_bits / 8

        def create_msg():
            return encode(message.payload.torrents)

        packet = create_msg()
        while len(packet) > max_len:
            community = choice(message.payload.torrents.keys())
            nrTorrents = len(message.payload.torrents[community])
            if nrTorrents == 1:
                del message.payload.torrents[community]
            else:
                message.payload.torrents[community] = set(sample(message.payload.torrents[community], nrTorrents - 1))

            packet = create_msg()
        return packet,

    def _decode_torrent_request(self, placeholder, offset, data):
        try:
            offset, payload = decode(data, offset)
        except ValueError:
            raise DropPacket("Unable to decode the torrent-request")

        if not isinstance(payload, dict):
            raise DropPacket("Invalid payload type")

        for cid, infohashes in payload.iteritems():
            if not (isinstance(cid, str) and len(cid) == 20):
                raise DropPacket("Invalid 'cid' type or value")

            for infohash in infohashes:
                if not (isinstance(infohash, str) and len(infohash) == 20):
                    raise DropPacket("Invalid 'infohash' type or value")
        return offset, placeholder.meta.payload.implement(payload)

    def _encode_torrent_collect_request(self, message):
        import sys
        for torrent in message.payload.torrents:
            if torrent[2] > 2 ** 16 or torrent[2] < 0:
                self._logger.info("seeder value is incorrect %s", torrent[2])
            if torrent[3] > 2 ** 16 or torrent[3] < 0:
                self._logger.info("leecher value is incorrect %s", torrent[3])
            if torrent[4] > 2 ** 16 or torrent[4] < 0:
                self._logger.info("since value is incorrect %s", torrent[4])

        hashpack = '20s20sHHH' * len(message.payload.torrents)
        torrents = [item for sublist in message.payload.torrents for item in sublist]
        return pack('!HH' + hashpack, message.payload.identifier, message.payload.hashtype, *torrents),

    def _decode_torrent_collect_request(self, placeholder, offset, data):
        if len(data) < offset + 4:
            raise DropPacket("Insufficient packet size")

        identifier, hashtype = unpack_from('!HH', data, offset)
        offset += 4

        length = len(data) - offset
        if length % 46 != 0:
            raise DropPacket("Invalid number of bytes available (tcr)")

        if length:
            hashpack = '20s20sHHH' * (length / 46)
            hashes = unpack_from('!' + hashpack, data, offset)
            offset += length

            torrents = []
            for i in range(0, len(hashes), 5):
                torrents.append([hashes[i], hashes[i + 1], hashes[i + 2], hashes[i+3], hashes[i+4]])
        else:
            torrents = []
        return offset, placeholder.meta.payload.implement(identifier, hashtype, torrents)

    def _encode_torrent_collect_response(self, message):
        return self._encode_torrent_collect_request(message)

    def _decode_torrent_collect_response(self, placeholder, offset, data):
        return self._decode_torrent_collect_request(placeholder, offset, data)

    def _encode_torrent(self, message):
        max_len = self._community.dispersy_sync_bloom_filter_bits / 8

        files = message.payload.files
        trackers = message.payload.trackers

        def create_msg():
            normal_msg = pack('!20sQ', message.payload.infohash, message.payload.timestamp), message.payload.name, tuple(files), tuple(trackers)
            normal_msg = encode(normal_msg)
            return zlib.compress(normal_msg)

        compressed_msg = create_msg()
        while len(compressed_msg) > max_len:
            if len(trackers) > 10:
                # only use first 10 trackers, .torrents in the wild have been seen to have 1000+ trackers...
                trackers = trackers[:10]
            else:
                # reduce files by the amount we are currently to big
                reduce_by = max_len / (len(compressed_msg) * 1.0)
                nr_files_to_include = int(len(files) * reduce_by)
                files = sample(files, nr_files_to_include)

            compressed_msg = create_msg()
        return compressed_msg,

    def _decode_torrent(self, placeholder, offset, data):
        uncompressed_data = zlib.decompress(data[offset:])
        offset = len(data)

        try:
            _, values = decode(uncompressed_data)
        except ValueError:
            raise DropPacket("Unable to decode the torrent-payload")

        infohash_time, name, files, trackers = values
        if len(infohash_time) != 28:
            raise DropPacket("Unable to decode the torrent-payload, got %d bytes expected 28" % (len(infohash_time)))
        infohash, timestamp = unpack_from('!20sQ', infohash_time)

        if not isinstance(name, unicode):
            raise DropPacket("Invalid 'name' type")

        if not isinstance(files, tuple):
            raise DropPacket("Invalid 'files' type")

        if len(files) == 0:
            raise DropPacket("Should have at least one file")

        for file in files:
            if len(file) != 2:
                raise DropPacket("Invalid 'file_len' type")

            path, length = file
            if not isinstance(path, unicode):
                raise DropPacket("Invalid 'files_path' type is %s" % type(path))
            if not isinstance(length, (int, long)):
                raise DropPacket("Invalid 'files_length' type is %s" % type(length))

        if not isinstance(trackers, tuple):
            raise DropPacket("Invalid 'trackers' type")
        for tracker in trackers:
            if not isinstance(tracker, str):
                raise DropPacket("Invalid 'tracker' type")

        return offset, placeholder.meta.payload.implement(infohash, timestamp, name, files, trackers)

########NEW FILE########
__FILENAME__ = payload
# Written by Niels Zeilemaker
from Tribler.dispersy.payload import Payload, IntroductionRequestPayload
from Tribler.dispersy.bloomfilter import BloomFilter


class TasteIntroPayload(IntroductionRequestPayload):

    class Implementation(IntroductionRequestPayload.Implementation):

        def __init__(self, meta, destination_address, source_lan_address, source_wan_address, advice, connection_type, sync, identifier, num_preferences=0, taste_bloom_filter=None):
            IntroductionRequestPayload.Implementation.__init__(self, meta, destination_address, source_lan_address, source_wan_address, advice, connection_type, sync, identifier)

            self._num_preferences = num_preferences
            self._taste_bloom_filter = taste_bloom_filter

        def set_num_preferences(self, num_preferences):
            self._num_preferences = num_preferences

        def set_taste_bloom_filter(self, taste_bloom_filter):
            self._taste_bloom_filter = taste_bloom_filter

        @property
        def num_preferences(self):
            return self._num_preferences

        @property
        def taste_bloom_filter(self):
            return self._taste_bloom_filter


class SearchRequestPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, keywords, bloom_filter=None):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(keywords, list), 'keywords should be list'
                for keyword in keywords:
                    assert isinstance(keyword, unicode), '%s is type %s' % (keyword, type(keyword))
                    assert len(keyword) > 0

                assert not bloom_filter or isinstance(bloom_filter, BloomFilter), type(bloom_filter)

            super(SearchRequestPayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._keywords = keywords
            self._bloom_filter = bloom_filter

        @property
        def identifier(self):
            return self._identifier

        @property
        def keywords(self):
            return self._keywords

        @property
        def bloom_filter(self):
            return self._bloom_filter


class SearchResponsePayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, results):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(results, list), type(results)
                for result in results:
                    assert isinstance(result, tuple), type(result)
                    assert len(result) > 10

                    infohash, swarmname, length, nrfiles, categorykeys, creation_date, seeders, leechers, swift_hash, swift_torrent_hash, cid = result[:11]
                    assert isinstance(infohash, str), type(infohash)
                    assert len(infohash) == 20
                    assert isinstance(swarmname, unicode), type(swarmname)
                    assert isinstance(length, long), type(length)
                    assert isinstance(nrfiles, int), type(nrfiles)
                    assert isinstance(categorykeys, list), type(categorykeys)
                    assert all(isinstance(key, unicode) for key in categorykeys), categorykeys
                    assert isinstance(creation_date, long), type(creation_date)
                    assert isinstance(seeders, int), type(seeders)
                    assert isinstance(leechers, int), type(leechers)
                    assert not swift_hash or isinstance(swift_hash, str), type(swift_hash)
                    assert not swift_hash or len(swift_hash) == 20, swift_hash
                    assert not swift_torrent_hash or isinstance(swift_torrent_hash, str), type(swift_torrent_hash)
                    assert not swift_torrent_hash or len(swift_torrent_hash) == 20, swift_torrent_hash
                    assert not cid or isinstance(cid, str), type(cid)
                    assert not cid or len(cid) == 20, cid

            super(SearchResponsePayload.Implementation, self).__init__(meta)
            self._identifier = identifier
            self._results = results

        @property
        def identifier(self):
            return self._identifier

        @property
        def results(self):
            return self._results


class TorrentRequestPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, torrents):
            if __debug__:
                assert isinstance(torrents, dict), type(torrents)
                for cid, infohashes in torrents.iteritems():
                    assert isinstance(cid, str)
                    assert len(cid) == 20
                    assert isinstance(infohashes, set)
                    assert not filter(lambda x: not isinstance(x, str), infohashes)
                    assert not filter(lambda x: not len(x) == 20, infohashes)
                    assert len(infohashes) > 0

            super(TorrentRequestPayload.Implementation, self).__init__(meta)
            self._torrents = torrents

        @property
        def torrents(self):
            return self._torrents


class TorrentCollectRequestPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, identifier, hashtype, torrents):
            if __debug__:
                assert isinstance(identifier, int), type(identifier)
                assert isinstance(torrents, list), type(torrents)
                for hash, infohash, seeders, leechers, ago in torrents:
                    assert isinstance(hash, str)
                    assert len(hash) == 20, "%d, %s" % (len(hash), hash)
                    assert isinstance(infohash, str)
                    assert len(infohash) == 20, "%d, %s" % (len(infohash), infohash)
                    assert isinstance(seeders, int)
                    assert 0 <= seeders < 2 ** 16, seeders
                    assert isinstance(leechers, int)
                    assert 0 <= leechers < 2 ** 16, leechers
                    assert isinstance(leechers, int)
                    assert 0 <= leechers < 2 ** 16, leechers
                    assert isinstance(ago, int)
                    assert 0 <= ago < 2 ** 16, ago

                assert isinstance(hashtype, int), type(hashtype)
                assert 0 <= hashtype < 2 ** 16, hashtype

            super(TorrentCollectRequestPayload.Implementation, self).__init__(meta)

            self._identifier = identifier
            self._hashtype = hashtype
            self._torrents = torrents

        @property
        def identifier(self):
            return self._identifier

        @property
        def hashtype(self):
            return self._hashtype

        @property
        def torrents(self):
            return self._torrents


class TorrentCollectResponsePayload(TorrentCollectRequestPayload):
    pass

########NEW FILE########
__FILENAME__ = community
"""
Example file
"""

import logging
logger = logging.getLogger(__name__)

from .conversion import Conversion
from .payload import TextPayload

from Tribler.dispersy.authentication import MemberAuthentication
from Tribler.dispersy.community import Community
from Tribler.dispersy.conversion import DefaultConversion
from Tribler.dispersy.destination import CommunityDestination
from Tribler.dispersy.distribution import FullSyncDistribution
from Tribler.dispersy.message import BatchConfiguration, Message, DelayMessageByProof
from Tribler.dispersy.resolution import LinearResolution


class TemplateCommunity(Community):

    def initiate_meta_messages(self):
        return super(TemplateCommunity, self).initiate_meta_messages() + [
            Message(self, u"text",
                    MemberAuthentication(),
                    LinearResolution(),
                    FullSyncDistribution(enable_sequence_number=False, synchronization_direction=u"ASC", priority=128),
                    CommunityDestination(node_count=10),
                    TextPayload(),
                    self.check_text,
                    self.on_text,
                    batch=BatchConfiguration(max_window=5.0))
        ]

    def initiate_conversions(self):
        return [DefaultConversion(self), Conversion(self)]

    def check_text(self, messages):
        for message in messages:
            allowed, _ = self._timeline.check(message)
            if allowed:
                yield message
            else:
                yield DelayMessageByProof(message)

    def on_text(self, messages):
        for message in messages:
            logger.debug("someone says '%s'", message.payload.text)

########NEW FILE########
__FILENAME__ = conversion
"""
Example file
"""

from struct import pack, unpack_from

from Tribler.dispersy.conversion import BinaryConversion
from Tribler.dispersy.message import DropPacket


class Conversion(BinaryConversion):

    def __init__(self, community):
        super(Conversion, self).__init__(community, "\x02")
        self.define_meta_message(chr(1), community.get_meta_message(u"text"), self._encode_text, self._decode_text)

    def _encode_text(self, message):
        assert len(message.payload.text.encode("UTF-8")) < 256
        text = message.payload.text.encode("UTF-8")
        return pack("!B", len(text)), text[:255]

    def _decode_text(self, placeholder, offset, data):
        if len(data) < offset + 1:
            raise DropPacket("Insufficient packet size")

        text_length, = unpack_from("!B", data, offset)
        offset += 1

        try:
            text = data[offset:offset + text_length].decode("UTF-8")
            offset += text_length
        except UnicodeError:
            raise DropPacket("Unable to decode UTF-8")

        return offset, placeholder.meta.payload.implement(text)

########NEW FILE########
__FILENAME__ = payload
"""
Example file
"""

from Tribler.dispersy.payload import Payload


class TextPayload(Payload):

    class Implementation(Payload.Implementation):

        def __init__(self, meta, text):
            assert isinstance(text, unicode)
            assert len(text.encode("UTF-8")) <= 255
            super(TextPayload.Implementation, self).__init__(meta)
            self._text = text

        @property
        def text(self):
            return self._text

########NEW FILE########
__FILENAME__ = script
"""
Example file

python Tribler/Main/dispersy.py --script template
"""
import logging
logger = logging.getLogger(__name__)

from Tribler.dispersy.script import ScriptBase


class TestScript(ScriptBase):

    def run(self):
        self.caller(self.test)

    def test(self):
        logger.debug("testing...")
        assert True

########NEW FILE########
__FILENAME__ = LaunchManyCore
# Written by Arno Bakker
# Updated by George Milescu
# see LICENSE.txt for license information
import binascii
import errno
import logging
import os
import sys
import time as timemod
from threading import Event, Thread, enumerate as enumerate_threads, currentThread
from traceback import print_exc

from twisted.internet import reactor
from twisted.internet.threads import blockingCallFromThread

from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.RawServer.RawServer import RawServer
from Tribler.Core.ServerPortHandler import MultiHandler
from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core.TorrentDef import TorrentDef, TorrentDefNoMetainfo
from Tribler.Core.Utilities.configparser import CallbackConfigParser
from Tribler.Core.Video.VideoPlayer import VideoPlayer
from Tribler.Core.exceptions import DuplicateDownloadException, OperationNotEnabledByConfigurationException
from Tribler.Core.osutils import get_readable_torrent_name
from Tribler.Core.simpledefs import (NTFY_DISPERSY, NTFY_STARTED, NTFY_TORRENTS, NTFY_UPDATE, NTFY_INSERT,
                                     NTFY_ACTIVITIES, NTFY_REACHABLE, NTFY_ACT_UPNP)
from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.community.anontunnel.endpoint import DispersyBypassEndpoint
from Tribler.community.privatesemantic.crypto.elgamalcrypto import ElgamalCrypto


try:
    prctlimported = True
    import prctl
except ImportError:
    prctlimported = False


if sys.platform == 'win32':
    SOCKET_BLOCK_ERRORCODE = 10035  # WSAEWOULDBLOCK
else:
    SOCKET_BLOCK_ERRORCODE = errno.EWOULDBLOCK

SPECIAL_VALUE = 481

PROFILE = False

# Internal classes
#

class TriblerLaunchMany(Thread):

    def __init__(self):
        """ Called only once (unless we have multiple Sessions) by MainThread """
        Thread.__init__(self)

        self.setDaemon(True)
        name = "Network" + self.getName()
        self.setName(name)
        self.initComplete = False
        self.registered = False
        self.dispersy = None

        self._logger = logging.getLogger(self.__class__.__name__)

    def register(self, session, sesslock):
        if not self.registered:
            self.registered = True

            self.session = session
            self.sesslock = sesslock

            self.downloads = {}

            self.upnp_ports = []

            # Orig
            self.sessdoneflag = Event()

            self.rawserver = RawServer(self.sessdoneflag,
                                       self.session.get_timeout_check_interval(),
                                       self.session.get_timeout(),
                                       ipv6_enable=self.session.get_ipv6(),
                                       failfunc=self.rawserver_fatalerrorfunc,
                                       errorfunc=self.rawserver_nonfatalerrorfunc)
            self.listen_port = self.session.get_listen_port()
            self.shutdownstarttime = None

            self.multihandler = MultiHandler(self.rawserver, self.sessdoneflag)

            # SWIFTPROC
            swift_exists = self.session.get_swift_proc() and (os.path.exists(self.session.get_swift_path()) or os.path.exists(self.session.get_swift_path() + '.exe'))
            if swift_exists:
                from Tribler.Core.Swift.SwiftProcessMgr import SwiftProcessMgr

                self.spm = SwiftProcessMgr(self.session.get_swift_path(), self.session.get_swift_tunnel_cmdgw_listen_port(), self.session.get_swift_downloads_per_process(), self.session.get_swift_tunnel_listen_port(), self.sesslock)
                try:
                    self.swift_process = self.spm.get_or_create_sp(self.session.get_swift_working_dir(), self.session.get_torrent_collecting_dir(), self.session.get_swift_tunnel_listen_port(), self.session.get_swift_tunnel_httpgw_listen_port(), self.session.get_swift_tunnel_cmdgw_listen_port())
                    self.upnp_ports.append((self.session.get_swift_tunnel_listen_port(), 'UDP'))

                except OSError:
                    # could not find/run swift
                    self._logger.error("lmc: could not start a swift process")

            else:
                self.spm = None
                self.swift_process = None

            # Dispersy
            self.session.dispersy_member = None
            if self.session.get_dispersy():
                from Tribler.dispersy.dispersy import Dispersy
                from Tribler.dispersy.endpoint import RawserverEndpoint, TunnelEndpoint
                from Tribler.dispersy.community import HardKilledCommunity

                self._logger.info("lmc: Starting Dispersy...")
                now = timemod.time()

                # set communication endpoint
                if self.session.get_dispersy_tunnel_over_swift() and self.swift_process:
                    endpoint = TunnelEndpoint(self.swift_process)
                else:
                    endpoint = DispersyBypassEndpoint(self.rawserver, self.session.get_dispersy_port())

                working_directory = unicode(self.session.get_state_dir())

                self.dispersy = Dispersy(endpoint, working_directory, crypto=ElgamalCrypto())

                # TODO(emilon): move this to init() now that we use the reactor
                # TODO: see if we can postpone dispersy.start to improve GUI responsiveness.
                # However, for now we must start self.dispersy.callback before running
                # try_register(nocachedb, self.database_thread)!

                success = blockingCallFromThread(reactor, self.dispersy.start)

                # for debugging purpose
                # from Tribler.dispersy.endpoint import NullEndpoint
                # self.dispersy._endpoint = NullEndpoint()
                # self.dispersy._endpoint.open(self.dispersy)

                diff = timemod.time() - now
                if success:
                    self._logger.info("lmc: Dispersy started successfully in %.2f seconds [port: %d]", diff, self.dispersy.wan_address[1])
                else:
                    self._logger.info("lmc: Dispersy failed to start in %.2f seconds", diff)

                self.upnp_ports.append((self.dispersy.wan_address[1], 'UDP'))


                from Tribler.Core.permid import read_keypair
                keypair = read_keypair(self.session.get_permid_keypair_filename())
                self.session.dispersy_member = blockingCallFromThread(reactor, self.dispersy.get_member,
                                             private_key=self.dispersy.crypto.key_to_bin(keypair))

                blockingCallFromThread(reactor, self.dispersy.define_auto_load, HardKilledCommunity,
                                       self.session.dispersy_member, load=True)

                # notify dispersy finished loading
                self.session.uch.notify(NTFY_DISPERSY, NTFY_STARTED, None)

            # TODO(emilon): move this to a megacache component or smth
            if self.session.get_megacache():
                import Tribler.Core.CacheDB.sqlitecachedb as cachedb
                from Tribler.Core.CacheDB.SqliteCacheDBHandler import PeerDBHandler, TorrentDBHandler, MyPreferenceDBHandler, VoteCastDBHandler, ChannelCastDBHandler, UserEventLogDBHandler, MiscDBHandler, MetadataDBHandler
                from Tribler.Category.Category import Category
                from Tribler.Core.Tag.Extraction import TermExtraction

                self._logger.debug('tlm: Reading Session state from %s', self.session.get_state_dir())

                nocachedb = cachedb.init(self.session.get_state_dir(), self.session.get_install_dir(), self.rawserver_fatalerrorfunc)

                # TODO(emilon): have a function on the new twistified database module that does this on the right thread
                # (we will have a dedicated DB thread again soon)
                blockingCallFromThread(reactor, nocachedb.initialBegin)

                self.cat = Category.getInstance(self.session.get_install_dir())
                self.term = TermExtraction.getInstance(self.session.get_install_dir())

                self.misc_db = MiscDBHandler.getInstance()
                self.metadata_db = MetadataDBHandler.getInstance()

                self.peer_db = PeerDBHandler.getInstance()

                self.torrent_db = TorrentDBHandler.getInstance()
                self.torrent_db.register(os.path.abspath(self.session.get_torrent_collecting_dir()))
                self.mypref_db = MyPreferenceDBHandler.getInstance()
                self.votecast_db = VoteCastDBHandler.getInstance()
                self.votecast_db.registerSession(self.session)
                self.channelcast_db = ChannelCastDBHandler.getInstance()
                self.channelcast_db.registerSession(self.session)
                self.ue_db = UserEventLogDBHandler.getInstance()

                if self.dispersy:
                    self.dispersy.database.attach_commit_callback(self.channelcast_db._db.commitNow)

            self.rtorrent_handler = None
            if self.session.get_torrent_collecting():
                from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler
                self.rtorrent_handler = RemoteTorrentHandler()

            self.videoplayer = None
            if self.session.get_videoplayer():
                self.videoplayer = VideoPlayer(self.session)

            self.mainline_dht = None
            self.ltmgr = None
            self.torrent_checking = None

    def init(self):
        if self.spm:
            from Tribler.Core.DecentralizedTracking import mainlineDHT
            try:
                self.mainline_dht = mainlineDHT.init(('127.0.0.1', self.session.get_mainline_dht_listen_port()), self.session.get_state_dir(), self.session.get_swift_cmd_listen_port())
                self.upnp_ports.append((self.session.get_mainline_dht_listen_port(), 'UDP'))
            except:
                print_exc()

        if self.session.get_libtorrent():
            from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr
            self.ltmgr = LibtorrentMgr(self.session, ignore_singleton=self.session.ignore_singleton)

        # add task for tracker checking
        if self.session.get_torrent_checking():
            try:
                from Tribler.TrackerChecking.TorrentChecking import TorrentChecking
                self.torrent_checking_period = self.session.get_torrent_checking_period()
                self.torrent_checking = TorrentChecking.getInstance(self.torrent_checking_period)
                self.torrent_checking.start()
                self.run_torrent_check()
            except:
                print_exc()

        if self.rtorrent_handler:
            self.rtorrent_handler.register(self.dispersy, self.session, self.session.get_torrent_collecting_max_torrents())

        self.initComplete = True

    def add(self, tdef, dscfg, pstate=None, initialdlstatus=None, setupDelay=0, hidden=False):
        """ Called by any thread """
        d = None
        self.sesslock.acquire()
        try:
            if not isinstance(tdef, TorrentDefNoMetainfo) and not tdef.is_finalized():
                raise ValueError("TorrentDef not finalized")

            infohash = tdef.get_infohash()

            # Check if running or saved on disk
            if infohash in self.downloads:
                raise DuplicateDownloadException()

            from Tribler.Core.Libtorrent.LibtorrentDownloadImpl import LibtorrentDownloadImpl
            d = LibtorrentDownloadImpl(self.session, tdef)

            if pstate is None and not tdef.get_live():  # not already resuming
                pstate = self.load_download_pstate_noexc(infohash)
                if pstate is not None:
                    self._logger.debug("tlm: add: pstate is %s %s", pstate.get('dlstate', 'status'), pstate.get('dlstate', 'progress'))

            # Store in list of Downloads, always.
            self.downloads[infohash] = d
            d.setup(dscfg, pstate, initialdlstatus, self.network_engine_wrapper_created_callback, wrapperDelay=setupDelay)

        finally:
            self.sesslock.release()

        if d and not hidden and self.session.get_megacache():
            @forceDBThread
            def write_my_pref():
                torrent_id = self.torrent_db.getTorrentID(infohash)
                data = {'destination_path': d.get_dest_dir()}
                self.mypref_db.addMyPreference(torrent_id, data)

            if isinstance(tdef, TorrentDefNoMetainfo):
                self.torrent_db.addInfohash(tdef.get_infohash())
                self.torrent_db.updateTorrent(tdef.get_infohash(), name=tdef.get_name_as_unicode())
                write_my_pref()
            elif self.rtorrent_handler:
                self.rtorrent_handler.save_torrent(tdef, write_my_pref)
            else:
                self.torrent_db.addExternalTorrent(tdef, source='', extra_info={'status': 'good'})
                write_my_pref()

        return d

    def network_engine_wrapper_created_callback(self, d, pstate):
        """ Called by network thread """
        try:
            if pstate is None:
                # Checkpoint at startup
                (infohash, pstate) = d.network_checkpoint()
                self.save_download_pstate(infohash, pstate)
        except:
            print_exc()

    def remove(self, d, removecontent=False, removestate=True, hidden=False):
        """ Called by any thread """
        self.sesslock.acquire()
        try:
            d.stop_remove(removestate=removestate, removecontent=removecontent)
            infohash = d.get_def().get_infohash()
            if infohash in self.downloads:
                del self.downloads[infohash]
        finally:
            self.sesslock.release()

        if not hidden:
            self.remove_id(infohash)

    def remove_id(self, hash):
        # this is a bit tricky, as we do not know if this "id" is a roothash or infohash
        # however a restart will re-add the preference to mypreference if we remove the wrong one
        @forceDBThread
        def do_db(torrent_db, mypref_db, hash):
            torrent_id = self.torrent_db.getTorrentID(hash)
            if torrent_id:
                self.mypref_db.updateDestDir(torrent_id, "")

            torrent_id = self.torrent_db.getTorrentIDRoot(hash)
            if torrent_id:
                self.mypref_db.updateDestDir(torrent_id, "")

        if self.session.get_megacache():
            do_db(self.torrent_db, self.mypref_db, hash)

    def get_downloads(self):
        """ Called by any thread """
        self.sesslock.acquire()
        try:
            return self.downloads.values()  # copy, is mutable
        finally:
            self.sesslock.release()

    def get_download(self, hash):
        """ Called by any thread """
        self.sesslock.acquire()
        try:
            return self.downloads.get(hash, None)
        finally:
            self.sesslock.release()

    def download_exists(self, infohash):
        self.sesslock.acquire()
        try:
            return infohash in self.downloads
        finally:
            self.sesslock.release()

    def update_trackers(self, id, trackers):
        """ Update the trackers for a download.
        @param id ID of the download for which the trackers need to be updated
        @param trackers A list of tracker urls.
        """
        dl = self.get_download(id)
        old_def = dl.get_def() if dl else None

        if old_def and old_def.get_def_type() == 'torrent':
            old_trackers = old_def.get_trackers_as_single_tuple()
            new_trackers = list(set(trackers) - set(old_trackers))
            all_trackers = list(old_trackers) + new_trackers

            if new_trackers:
                # Add new trackers to the download
                dl.add_trackers(new_trackers)

                # Create a new TorrentDef
                if isinstance(old_def, TorrentDefNoMetainfo):
                    new_def = TorrentDefNoMetainfo(old_def.get_infohash(), old_def.get_name(), dl.get_magnet_link())
                else:
                    metainfo = old_def.get_metainfo()
                    if len(all_trackers) > 1:
                        metainfo["announce-list"] = [all_trackers]
                    else:
                        metainfo["announce"] = all_trackers[0]
                    new_def = TorrentDef.load_from_dict(metainfo)

                # Set TorrentDef + checkpoint
                dl.set_def(new_def)
                dl.checkpoint()

                if isinstance(old_def, TorrentDefNoMetainfo):
                    @forceDBThread
                    def update_trackers_db(id, new_trackers):
                        torrent_id = self.torrent_db.getTorrentID(id)
                        if torrent_id != None:
                            self.torrent_db.addTorrentTrackerMappingInBatch(torrent_id, new_trackers)
                            self.session.uch.notify(NTFY_TORRENTS, NTFY_UPDATE, id)

                    if self.session.get_megacache():
                        update_trackers_db(id, new_trackers)

                elif not isinstance(old_def, TorrentDefNoMetainfo) and self.rtorrent_handler:
                    # Update collected torrents
                    self.rtorrent_handler._save_torrent(new_def)

    def rawserver_fatalerrorfunc(self, e):
        """ Called by network thread """
        self._logger.debug("tlm: RawServer fatal error func called : %s", e)
        print_exc()

    def rawserver_nonfatalerrorfunc(self, e):
        """ Called by network thread """
        self._logger.debug("tlm: RawServer non fatal error func called: %s", e)
        print_exc()
        # Could log this somewhere, or phase it out

    def _run(self):
        """ Called only once by network thread """

        try:
            try:
                self.start_upnp()
                self.multihandler.listen_forever()
            except:
                print_exc()
        finally:
            self.stop_upnp()
            self.rawserver.shutdown()

    #
    # State retrieval
    #
    def set_download_states_callback(self, usercallback, getpeerlist, when=0.0):
        """ Called by any thread """
        self.sesslock.acquire()
        try:
            # Even if the list of Downloads changes in the mean time this is
            # no problem. For removals, dllist will still hold a pointer to the
            # Download, and additions are no problem (just won't be included
            # in list of states returned via callback.
            #
            dllist = self.downloads.values()
        finally:
            self.sesslock.release()

        for d in dllist:
            # Arno, 2012-05-23: At Niels' request to get total transferred
            # stats. Causes MOREINFO message to be sent from swift proc
            # for every initiated dl.
            # 2012-07-31: Turn MOREINFO on/off on demand for efficiency.
            # 2013-04-17: Libtorrent now uses set_moreinfo_stats as well.
            d.set_moreinfo_stats(True in getpeerlist or d.get_def().get_id() in getpeerlist)

        network_set_download_states_callback_lambda = lambda: self.network_set_download_states_callback(usercallback)
        self.rawserver.add_task(network_set_download_states_callback_lambda, when)

    def network_set_download_states_callback(self, usercallback):
        """ Called by network thread """
        self.sesslock.acquire()
        try:
            # Even if the list of Downloads changes in the mean time this is
            # no problem. For removals, dllist will still hold a pointer to the
            # Download, and additions are no problem (just won't be included
            # in list of states returned via callback.
            #
            dllist = self.downloads.values()
        finally:
            self.sesslock.release()

        dslist = []
        for d in dllist:
            try:
                ds = d.network_get_state(None, False, sessioncalling=True)
                dslist.append(ds)
            except:
                # Niels, 2012-10-18: If Swift connection is crashing, it will raise an exception
                # We're catching it here to continue building the downloadstates
                print_exc()

        # Invoke the usercallback function via a new thread.
        # After the callback is invoked, the return values will be passed to
        # the returncallback for post-callback processing.
        self.session.uch.perform_getstate_usercallback(usercallback, dslist, self.sesscb_set_download_states_returncallback)

    def sesscb_set_download_states_returncallback(self, usercallback, when, newgetpeerlist):
        """ Called by SessionCallbackThread """
        if when > 0.0:
            # reschedule
            self.set_download_states_callback(usercallback, newgetpeerlist, when=when)

    #
    # Persistence methods
    #
    def load_checkpoint(self, initialdlstatus=None, initialdlstatus_dict={}):
        """ Called by any thread """
        if not self.initComplete:
            network_load_checkpoint_callback_lambda = lambda: self.load_checkpoint(initialdlstatus, initialdlstatus_dict)
            self.rawserver.add_task(network_load_checkpoint_callback_lambda, 1.0)

        else:
            self.sesslock.acquire()
            filelist = []
            try:
                dir = self.session.get_downloads_pstate_dir()
                filelist = os.listdir(dir)
                filelist = [os.path.join(dir, filename) for filename in filelist if filename.endswith('.state')]

            finally:
                self.sesslock.release()

            for i, filename in enumerate(filelist):
                self.resume_download(filename, initialdlstatus, initialdlstatus_dict, setupDelay=i * 0.1)

    def load_download_pstate_noexc(self, infohash):
        """ Called by any thread, assume sesslock already held """
        try:
            dir = self.session.get_downloads_pstate_dir()
            basename = binascii.hexlify(infohash) + '.state'
            filename = os.path.join(dir, basename)
            return self.load_download_pstate(filename)
        except Exception as e:
            # TODO: remove saved checkpoint?
            # self.rawserver_nonfatalerrorfunc(e)
            return None

    def resume_download(self, filename, initialdlstatus=None, initialdlstatus_dict={}, setupDelay=0):
        tdef = sdef = dscfg = pstate = None

        try:
            pstate = self.load_download_pstate(filename)

            # SWIFTPROC
            metainfo = pstate.get('state', 'metainfo')
            if SwiftDef.is_swift_url(metainfo):
                sdef = SwiftDef.load_from_url(metainfo)
            elif 'infohash' in metainfo:
                tdef = TorrentDefNoMetainfo(metainfo['infohash'], metainfo['name'], metainfo.get('url', None))
            else:
                tdef = TorrentDef.load_from_dict(metainfo)

            if pstate.has_option('downloadconfig', 'saveas') and isinstance(pstate.get('downloadconfig', 'saveas'), tuple):
                pstate.set('downloadconfig', 'saveas', pstate.get('downloadconfig', 'saveas')[-1])

            if pstate.get('downloadconfig', 'name'):
                sdef.set_name(pstate.get('downloadconfig', 'name'))
            if sdef and sdef.get_tracker().startswith("127.0.0.1:"):
                current_port = int(sdef.get_tracker().split(":")[1])
                if current_port != self.session.get_swift_dht_listen_port():
                    self._logger.info("Modified SwiftDef to new tracker port")
                    sdef.set_tracker("127.0.0.1:%d" % self.session.get_swift_dht_listen_port())

            dscfg = DownloadStartupConfig(pstate)

        except:
            print_exc()
            # pstate is invalid or non-existing
            _, file = os.path.split(filename)

            infohash = binascii.unhexlify(file[:-7])
            torrent = self.torrent_db.getTorrent(infohash, keys=['name', 'torrent_file_name', 'swift_torrent_hash'], include_mypref=False)
            torrentfile = None
            if torrent:
                torrent_dir = self.session.get_torrent_collecting_dir()

                if torrent['swift_torrent_hash']:
                    sdef = SwiftDef(torrent['swift_torrent_hash'])
                    save_name = sdef.get_roothash_as_hex()
                    torrentfile = os.path.join(torrent_dir, save_name)

                if torrentfile and os.path.isfile(torrentfile):
                    # normal torrentfile is not present, see if readable torrent is there
                    save_name = get_readable_torrent_name(infohash, torrent['name'])
                    torrentfile = os.path.join(torrent_dir, save_name)

            if torrentfile and os.path.isfile(torrentfile):
                tdef = TorrentDef.load(torrentfile)

                defaultDLConfig = DefaultDownloadStartupConfig.getInstance()
                dscfg = defaultDLConfig.copy()

                if self.mypref_db != None:
                    preferences = self.mypref_db.getMyPrefStatsInfohash(infohash)
                    if preferences:
                        if os.path.isdir(preferences[2]) or preferences[2] == '':
                            dscfg.set_dest_dir(preferences[2])

        self._logger.debug("tlm: load_checkpoint: pstate is %s %s", pstate.get('dlstate', 'status'), pstate.get('dlstate', 'progress'))
        if pstate.get('state', 'engineresumedata') is None:
            self._logger.debug("tlm: load_checkpoint: resumedata None")
        else:
            self._logger.debug("tlm: load_checkpoint: resumedata len %d", len(pstate.get('state', 'engineresumedata')))

        if (tdef or sdef) and dscfg:
            if dscfg.get_dest_dir() != '':  # removed torrent ignoring
                try:
                    if not self.download_exists((tdef or sdef).get_id()):
                        if tdef:
                            initialdlstatus = initialdlstatus_dict.get(tdef.get_id(), initialdlstatus)
                            self.add(tdef, dscfg, pstate, initialdlstatus, setupDelay=setupDelay)
                        else:
                            initialdlstatus = initialdlstatus_dict.get(sdef.get_id(), initialdlstatus)
                            self.swift_add(sdef, dscfg, pstate, initialdlstatus)
                    else:
                        self._logger.info("tlm: not resuming checkpoint because download has already been added")

                except Exception as e:
                    self.rawserver_nonfatalerrorfunc(e)
            else:
                self._logger.info("tlm: removing checkpoint %s destdir is %s", filename, dscfg.get_dest_dir())
                os.remove(filename)
        else:
            self._logger.info("tlm: could not resume checkpoint %s %s %s", filename, tdef, dscfg)

    def checkpoint(self, stop=False, checkpoint=True, gracetime=2.0):
        """ Called by any thread, assume sesslock already held """
        # Even if the list of Downloads changes in the mean time this is
        # no problem. For removals, dllist will still hold a pointer to the
        # Download, and additions are no problem (just won't be included
        # in list of states returned via callback.
        #
        dllist = self.downloads.values()
        self._logger.debug("tlm: checkpointing %s stopping %s", len(dllist), stop)

        network_checkpoint_callback_lambda = lambda: self.network_checkpoint_callback(dllist, stop, checkpoint, gracetime)
        self.rawserver.add_task(network_checkpoint_callback_lambda, 0.0)
        # TODO: checkpoint overlayapps / friendship msg handler

    def network_checkpoint_callback(self, dllist, stop, checkpoint, gracetime):
        """ Called by network thread """
        if checkpoint:
            for d in dllist:
                try:
                    # Tell all downloads to stop, and save their persistent state
                    # in a infohash -> pstate dict which is then passed to the user
                    # for storage.
                    #
                    if stop:
                        (infohash, pstate) = d.network_stop(False, False)
                    else:
                        (infohash, pstate) = d.network_checkpoint()

                    self._logger.debug("tlm: network checkpointing: %s %s", d.get_def().get_name(), pstate)

                    self.save_download_pstate(infohash, pstate)
                except Exception as e:
                    self.rawserver_nonfatalerrorfunc(e)

        if stop:
            # Some grace time for early shutdown tasks
            if self.shutdownstarttime is not None:
                now = timemod.time()
                diff = now - self.shutdownstarttime
                if diff < gracetime:
                    self._logger.info("tlm: shutdown: delaying for early shutdown tasks %s", gracetime - diff)
                    delay = gracetime - diff
                    network_shutdown_callback_lambda = lambda: self.network_shutdown()
                    self.rawserver.add_task(network_shutdown_callback_lambda, delay)
                    return

            self.network_shutdown()

    def early_shutdown(self):
        """ Called as soon as Session shutdown is initiated. Used to start
        shutdown tasks that takes some time and that can run in parallel
        to checkpointing, etc.
        """
        self._logger.info("tlm: early_shutdown")

        # Note: sesslock not held
        self.shutdownstarttime = timemod.time()
        if self.rtorrent_handler:
            self.rtorrent_handler.shutdown()
            self.rtorrent_handler.delInstance()
        if self.torrent_checking:
            self.torrent_checking.shutdown()
            self.torrent_checking.delInstance()
        if self.videoplayer:
            self.videoplayer.shutdown()
            self.videoplayer.delInstance()

        if self.dispersy:
            self._logger.info("lmc: Shutting down Dispersy...")
            now = timemod.time()
            success = blockingCallFromThread(reactor, self.dispersy.stop, 666.666)
            diff = timemod.time() - now
            if success:
                self._logger.info("lmc: Dispersy successfully shutdown in %.2f seconds", diff)
                delayed_calls = reactor.getDelayedCalls()
                if delayed_calls:
                    self._logger.warning("lmc: The reactor was not clean after stopping dispersy:")
                    for dc in delayed_calls:
                        self._logger.warning("lmc:     %s", dc)
                else:
                    self._logger.info("lmc: The reactor was clean after stopping dispersy. ")

            else:
                self._logger.info("lmc: Dispersy failed to shutdown in %.2f seconds", diff)

        if self.session.get_megacache():
            self.misc_db.delInstance()
            self.metadata_db.delInstance()
            self.peer_db.delInstance()
            self.torrent_db.delInstance()
            self.mypref_db.delInstance()
            self.votecast_db.delInstance()
            self.channelcast_db.delInstance()
            self.ue_db.delInstance()
            self.cat.delInstance()
            self.term.delInstance()

        # SWIFTPROC
        if self.spm is not None:
            self.spm.early_shutdown()

        if self.mainline_dht:
            from Tribler.Core.DecentralizedTracking import mainlineDHT
            mainlineDHT.deinit(self.mainline_dht)

    def network_shutdown(self):
        try:
            self._logger.info("tlm: network_shutdown")

            # Arno, 2012-07-04: Obsolete, each thread must close the DBHandler
            # it uses in its own shutdown procedure. There is no global close
            # of all per-thread cursors/connections.
            #
            # cachedb.done()
            # SWIFTPROC
            if self.spm is not None:
                self.spm.network_shutdown()

            ts = enumerate_threads()
            self._logger.info("tlm: Number of threads still running %d", len(ts))
            for t in ts:
                self._logger.info("tlm: Thread still running=%s, daemon=%s, instance=%s", t.getName(), t.isDaemon(), t)
        except:
            print_exc()

        # Stop network thread
        self.sessdoneflag.set()

        # Arno, 2010-08-09: Stop Session pool threads only after gracetime
        self.session.uch.shutdown()

        # Shutdown libtorrent session after checkpoints have been made
        if self.ltmgr:
            self.ltmgr.shutdown()
            self.ltmgr.delInstance()

    def save_download_pstate(self, infohash, pstate):
        """ Called by network thread """
        basename = binascii.hexlify(infohash) + '.state'
        filename = os.path.join(self.session.get_downloads_pstate_dir(), basename)

        self._logger.debug("tlm: network checkpointing: to file %s", filename)
        pstate.write_file(filename)

    def load_download_pstate(self, filename):
        """ Called by any thread """
        pstate = CallbackConfigParser()
        pstate.read_file(filename)
        return pstate

    def run(self):
        if prctlimported:
            prctl.set_name("Tribler" + currentThread().getName())

        if not self.initComplete:
            self.init()

        if PROFILE:
            fname = "profile-%s" % self.getName()
            import cProfile
            cProfile.runctx("self._run()", globals(), locals(), filename=fname)
            import pstats
            self._logger.info("profile: data for %s", self.getName())
            pstats.Stats(fname, stream=sys.stderr).sort_stats("cumulative").print_stats(20)
        else:
            self._run()

    def start_upnp(self):
        if self.ltmgr:
            self.set_activity(NTFY_ACT_UPNP)

            for port, protocol in self.upnp_ports:
                self._logger.debug("tlm: adding upnp mapping for %d %s", port, protocol)
                self.ltmgr.add_mapping(port, protocol)

    def stop_upnp(self):
        if self.ltmgr:
            self.ltmgr.delete_mappings()

    # Events from core meant for API user
    #
    def dialback_reachable_callback(self):
        """ Called by overlay+network thread """
        self.session.uch.notify(NTFY_REACHABLE, NTFY_INSERT, None, '')

    def set_activity(self, type, str='', arg2=None):
        """ Called by overlay + network thread """
        # print >>sys.stderr,"tlm: set_activity",type,str,arg2
        self.session.uch.notify(NTFY_ACTIVITIES, NTFY_INSERT, type, str, arg2)

    def update_torrent_checking_period(self):
        # dynamically change the interval: update at least every 2h
        if self.rtorrent_handler:
            ntorrents = self.rtorrent_handler.num_torrents
            if ntorrents > 0:
                self.torrent_checking_period = min(max(7200 / ntorrents, 10), 100)
        # print >> sys.stderr, "torrent_checking_period", self.torrent_checking_period

    def run_torrent_check(self):
        """ Called by network thread """

        self.update_torrent_checking_period()
        self.rawserver.add_task(self.run_torrent_check, self.torrent_checking_period)
        try:
            self.torrent_checking.setTorrentSelectionInterval(self.torrent_checking_period)
        except Exception as e:
            print_exc()
            self.rawserver_nonfatalerrorfunc(e)

    # SWIFTPROC
    def swift_add(self, sdef, dscfg, pstate=None, initialdlstatus=None, hidden=False):
        """ Called by any thread """
        d = None
        self.sesslock.acquire()
        try:
            if self.spm is None:
                raise OperationNotEnabledByConfigurationException()

            roothash = sdef.get_roothash()

            # Check if running or saved on disk
            if roothash in self.downloads:
                raise DuplicateDownloadException()

            from Tribler.Core.Swift.SwiftDownloadImpl import SwiftDownloadImpl
            d = SwiftDownloadImpl(self.session, sdef)

            # Store in list of Downloads, always.
            self.downloads[roothash] = d
            d.setup(dscfg, pstate, initialdlstatus, None)

        finally:
            self.sesslock.release()

        @forceDBThread
        def do_db(torrent_db, mypref_db, roothash, sdef, d):
            torrent_id = torrent_db.addOrGetTorrentIDRoot(roothash, sdef.get_name())

            # TODO: if user renamed the dest_path for single-file-torrent
            dest_path = d.get_dest_dir()
            data = {'destination_path': dest_path}
            mypref_db.addMyPreference(torrent_id, data)

        if d and not hidden and self.session.get_megacache():
            do_db(self.torrent_db, self.mypref_db, roothash, sdef, d)

        return d

    def swift_remove(self, d, removecontent=False, removestate=True, hidden=False):
        """ Called by any thread """
        self.sesslock.acquire()
        try:
            # SWIFTPROC: remove before stop_remove, to ensure that content
            # removal works (for torrents, stopping is delegate to network
            # so all this code happens fast before actual removal. For swift not.
            roothash = d.get_def().get_roothash()
            if roothash in self.downloads:
                del self.downloads[roothash]

            d.stop_remove(True, removestate=removestate, removecontent=removecontent)

        finally:
            self.sesslock.release()

        @forceDBThread
        def do_db(torrent_db, my_prefdb, roothash):
            torrent_id = self.torrent_db.getTorrentIDRoot(roothash)

            if torrent_id:
                self.mypref_db.updateDestDir(torrent_id, "")

        if not hidden and self.session.get_megacache():
            do_db(self.torrent_db, self.mypref_db, roothash)

    def get_external_ip(self):
        """ Returns the external IP address of this Session, i.e., by which
        it is reachable from the Internet. This address is determined by libtorrent.
        @return A string. """
        return self.ltmgr.get_external_ip() if self.ltmgr else None

    def sessconfig_changed_callback(self, section, name, new_value, old_value):
        value_changed = new_value != old_value
        if section == 'libtorrent' and name == 'utp':
            if self.ltmgr and value_changed:
                self.ltmgr.set_utp(new_value)
        elif section == 'libtorrent' and name == 'lt_proxyauth':
            if self.ltmgr:
                self.ltmgr.set_proxy_settings(self.ltmgr.ltsession, *self.session.get_libtorrent_proxy_settings())
        elif section == 'torrent_checking' and name == 'torrent_checking_period':
            if self.rtorrent_handler and value_changed:
                self.rtorrent_handler.set_max_num_torrents(new_value)
        # Return True/False, depending on whether or not the config value can be changed at runtime.
        elif (section == 'general' and name in ['nickname', 'mugshot', 'videoanalyserpath']) or \
             (section == 'libtorrent' and name in ['lt_proxytype', 'lt_proxyserver',
                                                   'anon_proxyserver', 'anon_proxytype', 'anon_proxyauth',
                                                   'anon_listen_port']) or \
             (section == 'torrent_collecting' and name in ['stop_collecting_threshold']) or \
             (section == 'proxy_community' and name in ['socks5_listen_port']) or \
             (section == 'swift' and name in ['swiftmetadir']):
            return True
        else:
            return False
        return True


def singledownload_size_cmp(x, y):
    """ Method that compares 2 SingleDownload objects based on the size of the
        content of the BT1Download (if any) contained in them.
    """
    if x is None and y is None:
        return 0
    elif x is None:
        return 1
    elif y is None:
        return -1
    else:
        a = x.get_bt1download()
        b = y.get_bt1download()
        if a is None and b is None:
            return 0
        elif a is None:
            return 1
        elif b is None:
            return -1
        else:
            if a.get_datalength() == b.get_datalength():
                return 0
            elif a.get_datalength() < b.get_datalength():
                return -1
            else:
                return 1

########NEW FILE########
__FILENAME__ = maketorrent
# Written by Arno Bakker, Bram Cohen
# multitracker extensions by John Hoffman
# modified for Merkle hashes and digital signatures by Arno Bakker
# see LICENSE.txt for license information

import sys
import os
from hashlib import md5
import zlib
import logging

from Tribler.Core.Utilities.Crypto import sha
from copy import copy
from time import time
from traceback import print_exc
from types import LongType

from Tribler.Core.Utilities.bencode import bencode
from Tribler.Core.Merkle.merkle import MerkleTree
from Tribler.Core.Utilities.unicode import bin2unicode
from Tribler.Core.APIImplementation.miscutils import parse_playtime_to_secs, offset2piece
from Tribler.Core.osutils import fix_filebasename
from Tribler.Core.defaults import tdefdictdefaults
from Tribler.Core.Utilities.utilities import validTorrentFile


ignore = []  # Arno: was ['core', 'CVS']

logger = logging.getLogger(__name__)

def make_torrent_file(input, userabortflag=None, userprogresscallback=lambda x: None):
    """ Create a torrent file from the supplied input.

    Returns a (infohash,metainfo) pair, or (None,None) on userabort. """

    (info, piece_length) = makeinfo(input, userabortflag, userprogresscallback)
    if userabortflag is not None and userabortflag.isSet():
        return (None, None)
    if info is None:
        return (None, None)

    # if DEBUG:
    #    print >>sys.stderr,"mktorrent: makeinfo returned",`info`

    metainfo = {'info': info, 'encoding': input['encoding'], 'creation date': long(time())}
    validTorrentFile(metainfo)

    # http://www.bittorrent.org/DHT_protocol.html says both announce and nodes
    # are not allowed, but some torrents (Azureus?) apparently violate this.
    if input['nodes'] is None and input['announce'] is None:
        raise ValueError('No tracker set')

    for key in ['announce', 'announce-list', 'nodes', 'comment', 'created by', 'httpseeds', 'url-list']:
        if input[key] is not None and len(input[key]) > 0:
            metainfo[key] = input[key]
            if key == 'comment':
                metainfo['comment.utf-8'] = uniconvert(input['comment'], 'utf-8')

    # Assuming 1 file, Azureus format no support multi-file torrent with diff
    # bitrates
    bitrate = None
    for file in input['files']:
        if file['playtime'] is not None:
            secs = parse_playtime_to_secs(file['playtime'])
            bitrate = file['length'] / secs
            break
        if input.get('bps') is not None:
            bitrate = input['bps']
            break

    if bitrate is not None or input['thumb'] is not None:
        mdict = {}
        mdict['Publisher'] = 'Tribler'
        if input['comment'] is None:
            descr = ''
        else:
            descr = input['comment']
        mdict['Description'] = descr

        if bitrate is not None:
            mdict['Progressive'] = 1
            mdict['Speed Bps'] = int(bitrate)  # bencode fails for float
        else:
            mdict['Progressive'] = 0

        mdict['Title'] = metainfo['info']['name']
        mdict['Creation Date'] = long(time())
        # Azureus client source code doesn't tell what this is, so just put in random value from real torrent
        mdict['Content Hash'] = 'PT3GQCPW4NPT6WRKKT25IQD4MU5HM4UY'
        mdict['Revision Date'] = long(time())
        if input['thumb'] is not None:
            mdict['Thumbnail'] = input['thumb']
        cdict = {}
        cdict['Content'] = mdict
        metainfo['azureus_properties'] = cdict

    if 'url-compat' in input:
        metainfo['info']['url-compat'] = input['url-compat']

    # Arno, 2010-03-02:
    # Theoretically should go into 'info' field, to get infohash protection
    # because the video won't play without them. In the future we'll sign
    # the whole .torrent IMHO so it won't matter. Keeping it out of 'info'
    # at the moment makes the .tstream files more stable (in case you restart
    # the live source, and the Ogg header generated contains some date or
    # what not, we'd need a new .tstream to be distributed to all.
    #
    if 'ogg-headers' in input:
        metainfo['ogg-headers'] = input['ogg-headers']

    # Two places where infohash calculated, here and in TorrentDef.
    # Elsewhere: must use TorrentDef.get_infohash() to allow P2PURLs.
    infohash = sha(bencode(info)).digest()
    return (infohash, metainfo)


def uniconvertl(l, e):
    """ Convert a pathlist to a list of strings encoded in encoding "e" using
    uniconvert. """
    r = []
    try:
        for s in l:
            r.append(uniconvert(s, e))
    except UnicodeError:
        raise UnicodeError('bad filename: ' + os.path.join(l))
    return r


def uniconvert(s, enc):
    """ Convert 's' to a string containing a Unicode sequence encoded using
    encoding "enc". If 's' is not a Unicode object, we first try to convert
    it to one, guessing the encoding if necessary. """
    if not isinstance(s, unicode):
        try:
            s = bin2unicode(s, enc)
        except UnicodeError:
            raise UnicodeError('bad filename: ' + s)
    return s.encode(enc)


def makeinfo(input, userabortflag, userprogresscallback):
    """ Calculate hashes and create torrent file's 'info' part """
    encoding = input['encoding']

    pieces = []
    sh = sha()
    done = 0
    fs = []
    totalsize = 0
    totalhashed = 0

    # 1. Determine which files should go into the torrent (=expand any dirs
    # specified by user in input['files']
    subs = []
    for file in input['files']:
        inpath = file['inpath']
        outpath = file['outpath']

        logger.debug("makeinfo: inpath=%s, outpath=%s", inpath, outpath)

        if os.path.isdir(inpath):
            dirsubs = subfiles(inpath)
            subs.extend(dirsubs)
        else:
            if outpath is None:
                subs.append(([os.path.basename(inpath)], inpath))
            else:
                subs.append((filename2pathlist(outpath, skipfirst=True), inpath))

    subs.sort()

    # 2. Calc total size
    newsubs = []
    for p, f in subs:
        if 'live' in input:
            size = input['files'][0]['length']
        else:
            size = os.path.getsize(f)
        totalsize += size
        newsubs.append((p, f, size))
    subs = newsubs

    # 3. Calc piece length from totalsize if not set
    if input['piece length'] == 0:
        if input['createmerkletorrent']:
            # used to be 15=32K, but this works better with slow python
            piece_length = 2 ** 18
        else:
            # Niels we want roughly between 1000-2000 pieces
            # This results in the following logic:

            # We start with 32K pieces
            piece_length = 2 ** 15

            while totalsize / piece_length > 2000:
                # too many piece, double piece_size
                piece_length *= 2
    else:
        piece_length = input['piece length']

    # 4. Read files and calc hashes, if not live
    if 'live' not in input:
        for p, f, size in subs:
            pos = 0

            h = open(f, 'rb')

            if input['makehash_md5']:
                hash_md5 = md5.new()
            if input['makehash_sha1']:
                hash_sha1 = sha()
            if input['makehash_crc32']:
                hash_crc32 = zlib.crc32('')

            while pos < size:
                a = min(size - pos, piece_length - done)

                # See if the user cancelled
                if userabortflag is not None and userabortflag.isSet():
                    return (None, None)

                readpiece = h.read(a)

                # See if the user cancelled
                if userabortflag is not None and userabortflag.isSet():
                    return (None, None)

                sh.update(readpiece)

                if input['makehash_md5']:
                    # Update MD5
                    hash_md5.update(readpiece)

                if input['makehash_crc32']:
                    # Update CRC32
                    hash_crc32 = zlib.crc32(readpiece, hash_crc32)

                if input['makehash_sha1']:
                    # Update SHA1
                    hash_sha1.update(readpiece)

                done += a
                pos += a
                totalhashed += a

                if done == piece_length:
                    pieces.append(sh.digest())
                    done = 0
                    sh = sha()

                if userprogresscallback is not None:
                    userprogresscallback(float(totalhashed) / float(totalsize))

            newdict = {'length': num2num(size),
                       'path': uniconvertl(p, encoding),
                       'path.utf-8': uniconvertl(p, 'utf-8')}

            # Find and add playtime
            for file in input['files']:
                if file['inpath'] == f:
                    if file['playtime'] is not None:
                        newdict['playtime'] = file['playtime']
                    break

            if input['makehash_md5']:
                newdict['md5sum'] = hash_md5.hexdigest()
            if input['makehash_crc32']:
                newdict['crc32'] = "%08X" % hash_crc32
            if input['makehash_sha1']:
                newdict['sha1'] = hash_sha1.digest()

            fs.append(newdict)

            h.close()

        if done > 0:
            pieces.append(sh.digest())

    # 5. Create info dict
    if len(subs) == 1:
        flkey = 'length'
        flval = num2num(totalsize)
        name = subs[0][0][0]
    else:
        flkey = 'files'
        flval = fs

        if 'name' in input:  # allow someone to overrule the default name if multifile
            name = input['name']
        else:
            outpath = input['files'][0]['outpath']
            l = filename2pathlist(outpath)
            name = l[0]

    infodict = {'piece length': num2num(piece_length), flkey: flval,
            'name': uniconvert(name, encoding),
            'name.utf-8': uniconvert(name, 'utf-8')}

    if 'live' not in input:

        if input['createmerkletorrent']:
            merkletree = MerkleTree(piece_length, totalsize, None, pieces)
            root_hash = merkletree.get_root_hash()
            infodict.update({'root hash': root_hash})
        else:
            infodict.update({'pieces': ''.join(pieces)})
    else:
        # With source auth, live is a dict
        infodict['live'] = input['live']

    if 'cs_keys' in input:
        # This is a closed swarm - add torrent keys
        infodict['cs_keys'] = input['cs_keys']

    if 'ns-metadata' in input:
        # This has P2P-Next metadata, store in info field to make it
        # immutable.
        infodict['ns-metadata'] = input['ns-metadata']

    if len(subs) == 1:
        # Find and add playtime
        for file in input['files']:
            if file['inpath'] == f:
                if file['playtime'] is not None:
                    infodict['playtime'] = file['playtime']

    return (infodict, piece_length)


def subfiles(d):
    """ Return list of (pathlist,local filename) tuples for all the files in
    directory 'd' """
    r = []
    stack = [([], d)]
    while stack:
        p, n = stack.pop()
        if os.path.isdir(n):
            for s in os.listdir(n):
                if s not in ignore and s[:1] != '.':
                    stack.append((copy(p) + [s], os.path.join(n, s)))
        else:
            r.append((p, n))
    return r


def filename2pathlist(path, skipfirst=False):
    """ Convert a filename to a 'path' entry suitable for a multi-file torrent
    file """
    # if DEBUG:
    #    print >>sys.stderr,"mktorrent: filename2pathlist:",path,skipfirst

    h = path
    l = []
    while True:
        # if DEBUG:
        #    print >>sys.stderr,"mktorrent: filename2pathlist: splitting",h

        (h, t) = os.path.split(h)
        if h == '' and t == '':
            break
        if h == '' and skipfirst:
            continue
        if t != '':  # handle case where path ends in / (=path separator)
            l.append(t)

    l.reverse()
    # if DEBUG:
    #    print >>sys.stderr,"mktorrent: filename2pathlist: returning",l

    return l


def pathlist2filename(pathlist):
    """ Convert a multi-file torrent file 'path' entry to a filename. """
    fullpath = ''
    for elem in pathlist:
        fullpath = os.path.join(fullpath, elem)
    return fullpath.decode('utf-8')


def pathlist2savefilename(pathlist, encoding):
    fullpath = u''
    for elem in pathlist:
        u = bin2unicode(elem, encoding)
        b = fix_filebasename(u)
        fullpath = os.path.join(fullpath, b)
    return fullpath


def num2num(num):
    """ Converts long to int if small enough to fit """
    if isinstance(num, LongType) and num < sys.maxsize:
        return int(num)
    else:
        return num


def get_bitrate_from_metainfo(file, metainfo):
    info = metainfo['info']
    if file is None or 'files' not in info:  # if no file is specified or this is a single file torrent
        bitrate = None
        try:
            playtime = None
            if 'playtime' in info:
                # print >>sys.stderr,"TorrentDef: get_bitrate: Bitrate in info field"
                playtime = parse_playtime_to_secs(info['playtime'])
            elif 'playtime' in metainfo:  # HACK: encode playtime in non-info part of existing torrent
                # print >>sys.stderr,"TorrentDef: get_bitrate: Bitrate in metainfo"
                playtime = parse_playtime_to_secs(metainfo['playtime'])
            elif 'azureus_properties' in metainfo:
                azprop = metainfo['azureus_properties']
                if 'Content' in azprop:
                    content = metainfo['azureus_properties']['Content']
                    if 'Speed Bps' in content:
                        bitrate = float(content['Speed Bps'])
                        # print >>sys.stderr,"TorrentDef: get_bitrate: Bitrate in Azureus metainfo",bitrate
            if playtime is not None:
                bitrate = info['length'] / playtime
                logger.debug("TorrentDef: get_bitrate: Found bitrate %s", bitrate)
        except:
            print_exc()

        return bitrate

    else:
        for i in range(len(info['files'])):
            x = info['files'][i]

            intorrentpath = ''
            for elem in x['path']:
                intorrentpath = os.path.join(intorrentpath, elem)
            bitrate = None
            try:
                playtime = None
                if 'playtime' in x:
                    playtime = parse_playtime_to_secs(x['playtime'])
                elif 'playtime' in metainfo:  # HACK: encode playtime in non-info part of existing torrent
                    playtime = parse_playtime_to_secs(metainfo['playtime'])
                elif 'azureus_properties' in metainfo:
                    azprop = metainfo['azureus_properties']
                    if 'Content' in azprop:
                        content = metainfo['azureus_properties']['Content']
                        if 'Speed Bps' in content:
                            bitrate = float(content['Speed Bps'])
                            # print >>sys.stderr,"TorrentDef: get_bitrate: Bitrate in Azureus metainfo",bitrate

                if playtime is not None:
                    bitrate = x['length'] / playtime
            except:
                print_exc()

            if intorrentpath == file:
                return bitrate

        raise ValueError("File not found in torrent")


def get_length_from_metainfo(metainfo, selectedfiles):
    if 'files' not in metainfo['info']:
        # single-file torrent
        return metainfo['info']['length']
    else:
        # multi-file torrent
        files = metainfo['info']['files']

        total = 0
        for i in xrange(len(files)):
            path = files[i]['path']
            length = files[i]['length']
            if length > 0 and (not selectedfiles or pathlist2filename(path) in selectedfiles):
                total += length
        return total


def get_length_filepieceranges_from_metainfo(metainfo, selectedfiles):

    if 'files' not in metainfo['info']:
        # single-file torrent
        return (metainfo['info']['length'], None)
    else:
        # multi-file torrent
        files = metainfo['info']['files']
        piecesize = metainfo['info']['piece length']

        offset = 0
        total = 0
        filepieceranges = []
        for i in xrange(len(files)):
            path = files[i]['path']
            length = files[i]['length']
            filename = pathlist2filename(path)

            if length > 0 and (not selectedfiles or (selectedfiles and filename in selectedfiles)):
                range = (offset2piece(offset, piecesize, False), offset2piece(offset + length, piecesize), (offset - offset2piece(offset, piecesize, False) * piecesize), filename)
                filepieceranges.append(range)
                total += length
            offset += length
        return (total, filepieceranges)


def copy_metainfo_to_input(metainfo, input):

    keys = tdefdictdefaults.keys()
    # Arno: For magnet link support
    keys.append("initial peers")
    for key in keys:
        if key in metainfo:
            input[key] = metainfo[key]

    infokeys = ['name', 'piece length', 'live', 'url-compat']
    for key in infokeys:
        if key in metainfo['info']:
            input[key] = metainfo['info'][key]

    # Note: don't know inpath, set to outpath
    if 'length' in metainfo['info']:
        outpath = metainfo['info']['name']
        if 'playtime' in metainfo['info']:
            playtime = metainfo['info']['playtime']
        else:
            playtime = None
        length = metainfo['info']['length']
        d = {'inpath': outpath, 'outpath': outpath, 'playtime':playtime, 'length':length}
        input['files'].append(d)
    else:  # multi-file torrent
        files = metainfo['info']['files']
        for file in files:
            outpath = pathlist2filename(file['path'])
            if 'playtime' in file:
                playtime = file['playtime']
            else:
                playtime = None
            length = file['length']
            d = {'inpath': outpath, 'outpath': outpath, 'playtime':playtime, 'length':length}
            input['files'].append(d)

    if 'azureus_properties' in metainfo:
        azprop = metainfo['azureus_properties']
        if 'Content' in azprop:
            content = metainfo['azureus_properties']['Content']
            if 'Thumbnail' in content:
                input['thumb'] = content['Thumbnail']

    if 'live' in metainfo['info']:
        input['live'] = metainfo['info']['live']

    if 'cs_keys' in metainfo['info']:
        input['cs_keys'] = metainfo['info']['cs_keys']

    if 'url-compat' in metainfo['info']:
        input['url-compat'] = metainfo['info']['url-compat']

    if 'ogg-headers' in metainfo:
        input['ogg-headers'] = metainfo['ogg-headers']

    if 'ns-metadata' in metainfo['info']:
        input['ns-metadata'] = metainfo['info']['ns-metadata']

    # Diego : we want web seeding
    if 'url-list' in metainfo:
        input['url-list'] = metainfo['url-list']

    if 'httpseeds' in metainfo:
        input['httpseeds'] = metainfo['httpseeds']


def get_files(metainfo, exts):
    # 01/02/10 Boudewijn: now returns (file, length) tuples instead of files

    videofiles = []
    if 'files' in metainfo['info']:
        # Multi-file torrent
        files = metainfo['info']['files']
        for file in files:

            p = file['path']
            # print >>sys.stderr,"TorrentDef: get_files: file is",p
            filename = ''
            for elem in p:
                # print >>sys.stderr,"TorrentDef: get_files: elem is",elem
                filename = os.path.join(filename, elem)

            # print >>sys.stderr,"TorrentDef: get_files: composed filename is",filename
            (prefix, ext) = os.path.splitext(filename)
            if ext != '' and ext[0] == '.':
                ext = ext[1:]
            # print >>sys.stderr,"TorrentDef: get_files: ext",ext
            if exts is None or ext.lower() in exts:
                videofiles.append((filename, file['length']))
    else:
        # print >>sys.stderr,"TorrentDef: get_files: Single-torrent file"

        filename = metainfo['info']['name']  # don't think we need fixed name here
        (prefix, ext) = os.path.splitext(filename)
        if ext != '' and ext[0] == '.':
            ext = ext[1:]
        if exts is None or ext.lower() in exts:
            videofiles.append((filename, metainfo['info']['length']))
    return videofiles

########NEW FILE########
__FILENAME__ = makeurl
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TODO:
# * Test suite
# * Tracker support: how do they determine which files to seed.
#
# * Reverse support for URL-compat: URLs that do use infohash.
#   - Make sure internal tracker understands URL-compat torrentfiles
#   - Make sure internal tracker understands P2P URLs
#
# ISSUE: what if trackers have query parts? Is that officially/practically allowed?


import sys
import urlparse
import urllib
import math
if sys.platform != "win32":
    import curses.ascii
from struct import pack, unpack
from base64 import b64encode, b64decode
from M2Crypto import Rand  # TODO REMOVE FOR LICHT
import logging
from types import IntType

from Tribler.Core.simpledefs import P2PURL_SCHEME
from Tribler.Core.Utilities.Crypto import sha

logger = logging.getLogger(__name__)


def metainfo2p2purl(metainfo):
    """ metainfo must be a Merkle torrent or a live torrent with an
    'encoding' field set.
    @return URL
    """
    info = metainfo['info']

    bitrate = None
    if 'azureus_properties' in metainfo:
        azprops = metainfo['azureus_properties']
        if 'Content' in azprops:
            content = metainfo['azureus_properties']['Content']
            if 'Speed Bps' in content:
                bitrate = content['Speed Bps']

    if 'encoding' not in metainfo:
        encoding = 'utf-8'
    else:
        encoding = metainfo['encoding']

    urldict = {}

    urldict['s'] = p2purl_encode_piecelength(info['piece length'])
    # Warning: mbcs encodings sometimes don't work well under python!
    urldict['n'] = p2purl_encode_name2url(info['name'], encoding)

    if 'length' in info:
        urldict['l'] = p2purl_encode_nnumber(info['length'])
    else:
        raise ValueError("Multi-file torrents currently not supported")
        # list = []
        # for filedict in info['files']:
        #    newdict = {}
        #    newdict['p'] = list_filename_escape(filedict['path'])
        #    newdict['l'] = p2purl_encode_nnumber(filedict['length'])
        #    list.append(newdict)
        # urldict['f'] = '' # TODO bencode(list)
    if 'root hash' in info:
        urldict['r'] = b64urlencode(info['root hash'])
    elif 'live' in info:
        urldict['k'] = b64urlencode(info['live']['pubkey'])
        urldict['a'] = info['live']['authmethod']
    else:
        raise ValueError("url-compat and Merkle torrent must be on to create URL")

    if bitrate is not None:
        urldict['b'] = p2purl_encode_nnumber(bitrate)

    query = ''
    for k in ['n', 'r', 'k', 'l', 's', 'a', 'b']:
        if k in urldict:
            if query != "":
                query += '&'
            v = urldict[k]
            if k == 'n':
                s = v
            else:
                s = k + "=" +v
            query += s

    sidx = metainfo['announce'].find(":")
    hierpart = metainfo['announce'][sidx + 1:]
    url = P2PURL_SCHEME + ':' +hierpart+"?"+query
    return url


def p2purl2metainfo(url):
    """ Returns (metainfo,swarmid) """

    logger.debug("p2purl2metainfo: URL %s", url)

    # Python's urlparse only supports a defined set of schemes, if not
    # recognized, everything becomes path. Handy.
    colidx = url.find(":")
    scheme = url[0:colidx]
    qidx = url.find("?")

    if scheme != P2PURL_SCHEME:
        raise ValueError("Unknown scheme " + P2PURL_SCHEME)

    if qidx == -1:
        if url[2:].find('/') > -1:
            raise ValueError("Malformed compact form URL")
        # Compact form, no authority part and path rootless
        authority = None
        path = None
        query = url[colidx + 1:]
        fragment = None
    else:
        # Long form, with authority
        authoritypath = url[colidx + 3:qidx]
        pidx = authoritypath.find("/")
        authority = authoritypath[0:pidx]
        path = authoritypath[pidx:]
        fidx = url.find("#")
        if fidx == -1:
            # No fragment
            query = url[qidx + 1:]
            fragment = None
        else:
            query = url[qidx + 1:fidx]
            fragment = url[fidx:]

        # Check port no.
        csbidx = authority.find("]")
        if authority.startswith("[") and csbidx != -1:
            # Literal IPv6 address
            if csbidx == len(authority) - 1:
                port = None
            else:
                port = authority[csbidx + 1:]
        else:
            cidx = authority.find(":")
            if cidx != -1:
                port = authority[cidx + 1:]
            else:
                port = None
        if port is not None and not port.isdigit():
            raise ValueError("Port not int")

    metainfo = {}
    if authority and path:
        metainfo['announce'] = 'http://' + authority +path
        # Check for malformedness
        result = urlparse.urlparse(metainfo['announce'])
        if result[0] != "http":
            raise ValueError("Malformed tracker URL")

    reqinfo = p2purl_parse_query(query)
    metainfo.update(reqinfo)

    swarmid = metainfo2swarmid(metainfo)

    logger.debug("p2purl2metainfo: parsed %s", repr(metainfo))

    return (metainfo, swarmid)


def metainfo2swarmid(metainfo):
    if 'live' in metainfo['info']:
        swarmid = pubkey2swarmid(metainfo['info']['live'])
    else:
        swarmid = metainfo['info']['root hash']
    return swarmid


def p2purl_parse_query(query):
    logger.debug("p2purl_parse_query: query %s", query)

    gotname = False
    gotkey = False
    gotrh = False
    gotlen = False
    gotps = False
    gotam = False
    gotbps = False

    reqinfo = {}
    reqinfo['info'] = {}

    # Hmmm... could have used urlparse.parse_qs
    kvs = query.split('&')
    for kv in kvs:
        if '=' not in kv:
            # Must be name
            reqinfo['info']['name'] = p2purl_decode_name2utf8(kv)
            reqinfo['encoding'] = 'UTF-8'
            gotname = True
            continue

        k, v = kv.split('=')

        if k == 'k' or k == 'a' and not ('live' in reqinfo['info']):
            reqinfo['info']['live'] = {}

        if k == 'n':
            reqinfo['info']['name'] = p2purl_decode_name2utf8(v)
            reqinfo['encoding'] = 'UTF-8'
            gotname = True
        elif k == 'r':
            reqinfo['info']['root hash'] = p2purl_decode_base64url(v)
            gotrh = True
        elif k == 'k':
            reqinfo['info']['live']['pubkey'] = p2purl_decode_base64url(v)
            # reqinfo['info']['live']['authmethod'] = pubkey2authmethod(reqinfo['info']['live']['pubkey'])
            gotkey = True
        elif k == 'l':
            reqinfo['info']['length'] = p2purl_decode_nnumber(v)
            gotlen = True
        elif k == 's':
            reqinfo['info']['piece length'] = p2purl_decode_piecelength(v)
            gotps = True
        elif k == 'a':
            reqinfo['info']['live']['authmethod'] = v
            gotam = True
        elif k == 'b':
            bitrate = p2purl_decode_nnumber(v)
            reqinfo['azureus_properties'] = {}
            reqinfo['azureus_properties']['Content'] = {}
            reqinfo['azureus_properties']['Content']['Speed Bps'] = bitrate
            gotbps = True

    if not gotname:
        raise ValueError("Missing name field")
    if not gotrh and not gotkey:
        raise ValueError("Missing root hash or live pub key field")
    if gotrh and gotkey:
        raise ValueError("Found both root hash and live pub key field")
    if not gotlen:
        raise ValueError("Missing length field")
    if not gotps:
        raise ValueError("Missing piece size field")
    if gotkey and not gotam:
        raise ValueError("Missing live authentication method field")
    if gotrh and gotam:
        raise ValueError("Inconsistent: root hash and live authentication method field")

    if not gotbps:
        raise ValueError("Missing bitrate field")

    return reqinfo


def pubkey2swarmid(livedict):
    """ Calculate SHA1 of pubkey (or cert).
    Make X.509 Subject Key Identifier compatible?
    """
    logger.debug("pubkey2swarmid: %s", repr(livedict.keys()))

    if livedict['authmethod'] == "None":
        # No live-source auth
        return Rand.rand_bytes(20)
    else:
        return sha(livedict['pubkey']).digest()


def p2purl_decode_name2utf8(v):
    """ URL decode name to UTF-8 encoding """
    if sys.platform != "win32":
        for c in v:
            if not curses.ascii.isascii(c):
                raise ValueError("Name contains unescaped 8-bit value " + repr(c))
    return urllib.unquote_plus(v)


def p2purl_encode_name2url(name, encoding):
    """ Encode name in specified encoding to URL escaped UTF-8 """

    if encoding.lower() == 'utf-8':
        utf8name = name
    else:
        uname = unicode(name, encoding)
        utf8name = uname.encode('utf-8')
    return urllib.quote_plus(utf8name)


def p2purl_decode_base64url(v):
    return b64urldecode(v)

#
# Convert Python number to binary value of sufficient bytes,
# in network-byte order and BASE64-URL encode that binary value, or vice versa.
#


def p2purl_decode_nnumber(s):
    b = b64urldecode(s)
    if len(b) == 2:
        format = "H"
    elif len(b) == 4:
        format = "l"
    else:
        format = "Q"
    format = "!" + format  # network-byte order
    return unpack(format, b)[0]


def p2purl_encode_nnumber(s):
    if isinstance(s, IntType):
        if s < 2 ** 16:
            format = "H"
        elif s < 2 ** 32:
            format = "l"
    else:
        format = "Q"
    format = "!" + format  # network-byte order
    return b64urlencode(pack(format, s))


#
# Convert Python power-of-two piecelength to text value, or vice versa.
#
def p2purl_decode_piecelength(s):
    return int(math.pow(2.0, float(s)))


def p2purl_encode_piecelength(s):
    return str(int(math.log(float(s), 2.0)))

#
# "Modified BASE64 for URL" as informally specified in
# http://en.wikipedia.org/wiki/Base64#URL_applications
#


def b64urlencode(input):
    output = b64encode(input)
    output = output.rstrip('=')
    output = output.replace('+', '-')
    output = output.replace('/', '_')
    return output


def b64urldecode(input):
    inter = input[:]
    # readd padding.
    padlen = 4 - (len(inter) - ((len(inter) / 4) * 4))
    padstr = '=' * padlen
    inter += padstr
    inter = inter.replace('-', '+')
    inter = inter.replace('_', '/')
    output = b64decode(inter)
    return output

########NEW FILE########
__FILENAME__ = miscutils
# Written by Arno Bakker
# see LICENSE.txt for license information

import re
import logging

logger = logging.getLogger(__name__)

def parse_playtime_to_secs(hhmmss):
    logger.debug("miscutils: Playtime is %s", hhmmss)
    r = re.compile("([0-9\.]+):*")
    occ = r.findall(hhmmss)
    t = None
    if len(occ) > 0:
        if len(occ) == 3:
            # hours as well
            t = int(occ[0]) * 3600 + int(occ[1]) *60 + float(occ[2])
        elif len(occ) == 2:
            # minutes and seconds
            t = int(occ[0]) * 60 + float(occ[1])
        elif len(occ) == 1:
            # seconds
            t = float(occ[0])
    # Arno, 2010-07-05: Bencode doesn't support floats
    return int(t)


def offset2piece(offset, piecesize, endpoint=True):

    p = offset / piecesize
    # Niels: 08-08-2011: included endpoint boolean to specify if we should return an inclusive piece
    if endpoint and offset % piecesize > 0:
        p += 1
    return p

########NEW FILE########
__FILENAME__ = ThreadPool
# Written by Jelle Roozenburg, Arno Bakker
# see LICENSE.txt for license information

import time
from traceback import print_exc
import threading
import logging
from Queue import Queue
try:
    prctlimported = True
    import prctl
except ImportError as e:
    prctlimported = False


class ThreadPool:

    """Flexible thread pool class.  Creates a pool of threads, then
    accepts tasks that will be dispatched to the next available
    thread."""

    def __init__(self, numThreads):
        """Initialize the thread pool with numThreads workers."""

        self._logger = logging.getLogger(self.__class__.__name__)

        self.__threads = []
        self.__resizeLock = threading.Condition(threading.Lock())
        self.__taskCond = threading.Condition(threading.Lock())
        self.__tasks = []
        self.__isJoiningStopQueuing = False
        self.__isJoining = False
        self.setThreadCount(numThreads)

    def setThreadCount(self, newNumThreads):
        """ External method to set the current pool size.  Acquires
        the resizing lock, then calls the internal version to do real
        work."""

        # Can't change the thread count if we're shutting down the pool!
        if self.__isJoining:
            return False

        self.__resizeLock.acquire()
        try:
            self.__setThreadCountNolock(newNumThreads)
        finally:
            self.__resizeLock.release()
        return True

    def __setThreadCountNolock(self, newNumThreads):
        """Set the current pool size, spawning or terminating threads
        if necessary.  Internal use only; assumes the resizing lock is
        held."""

        # If we need to grow the pool, do so
        while newNumThreads > len(self.__threads):
            newThread = ThreadPoolThread(self)
            self.__threads.append(newThread)
            newThread.start()

        # If we need to shrink the pool, do so
        while newNumThreads < len(self.__threads):
            self.__threads[0].goAway()
            del self.__threads[0]

    def getThreadCount(self):
        """Return the number of threads in the pool."""

        self.__resizeLock.acquire()
        try:
            return len(self.__threads)
        finally:
            self.__resizeLock.release()

    def queueTask(self, task, args=(), taskCallback=None):
        """Insert a task into the queue.  task must be callable;
        args and taskCallback can be None."""

        if self.__isJoining == True or self.__isJoiningStopQueuing:
            return False
        if not callable(task):
            return False

        self.__taskCond.acquire()
        try:
            self.__tasks.append((task, args, taskCallback))
            # Arno, 2010-04-07: Use proper notify()+wait()
            self.__taskCond.notifyAll()
            return True
        finally:
            self.__taskCond.release()

    def getNextTask(self):
        """ Retrieve the next task from the task queue.  For use
        only by ThreadPoolThread objects contained in the pool."""
        self._logger.debug('%d', len(self.__tasks))

        self.__taskCond.acquire()
        try:
            while self.__tasks == [] and not self.__isJoining:
                self.__taskCond.wait()
            if self.__isJoining:
                return (None, None, None)
            else:
                return self.__tasks.pop(0)
        finally:
            self.__taskCond.release()

    def joinAll(self, waitForTasks=True, waitForThreads=True):
        """ Clear the task queue and terminate all pooled threads,
        optionally allowing the tasks and threads to finish."""

        # Mark the pool as joining to prevent any more task queueing
        self.__isJoiningStopQueuing = True

        # Wait for tasks to finish
        if waitForTasks:
            while self.__tasks != []:
                time.sleep(.1)

        # Mark the pool as joining to make all threads stop executing tasks
        self.__isJoining = True

        # Tell all the threads to quit
        self.__resizeLock.acquire()
        try:
            currentThreads = self.__threads[:]
            self.__setThreadCountNolock(0)

            # notify all waiting threads that we are quitting
            self.__taskCond.acquire()
            self.__taskCond.notifyAll()
            self.__taskCond.release()

            # Wait until all threads have exited
            if waitForThreads:
                for t in currentThreads:
                    t.join()
                    del t

            # Reset the pool for potential reuse
            self.__isJoining = False
        finally:
            self.__resizeLock.release()


class ThreadNoPool:

    def __init__(self):
        self.prevTask = False
        self.__isJoiningStopQueuing = False

        self.queue = Queue()
        self.thread = ThreadPoolThread(self)
        self.thread.start()

    def getThreadCount(self):
        return 1

    def queueTask(self, task, args=(), taskCallback=None):
        if not self.__isJoiningStopQueuing:
            self.queue.put((task, args, taskCallback))

    def getNextTask(self):
        if self.prevTask:
            self.queue.task_done()
        return self.queue.get()

    def joinAll(self, waitForTasks=False, waitForThreads=True):
        self.__isJoiningStopQueuing = True
        self.queue.put((None, (), None))

        if waitForTasks:
            self.thread.join()


class ThreadPoolThread(threading.Thread):

    """ Pooled thread class. """

    def __init__(self, pool):
        """ Initialize the thread and remember the pool. """

        threading.Thread.__init__(self)
        self.setName('SessionPool' + self.getName())
        self.setDaemon(True)
        self.__pool = pool
        self.__isDying = False

    def run(self):
        """ Until told to quit, retrieve the next task and execute
        it, calling the callback if any.  """

        if prctlimported:
            prctl.set_name("Tribler" + threading.currentThread().getName())

        # Arno, 2010-04-07: Dying only used when shrinking pool now.
        while self.__isDying == False:
            # Arno, 2010-01-28: add try catch block. Sometimes tasks lists grow,
            # could be because all Threads are dying.
            try:
                cmd, args, callback = self.__pool.getNextTask()
                if cmd is None:
                    break
                elif callback is None:
                    cmd(*args)
                else:
                    callback(cmd(args))
            except:
                print_exc()

    def goAway(self):
        """ Exit the run loop next time through."""

        self.__isDying = True

########NEW FILE########
__FILENAME__ = UserCallbackHandler
# Written by Arno Bakker
# see LICENSE.txt for license information

import os
import binascii
from threading import currentThread
import logging

from Tribler.Core.simpledefs import STATEDIR_DLPSTATE_DIR
from Tribler.Core.APIImplementation.ThreadPool import ThreadNoPool
from Tribler.Core.CacheDB.Notifier import Notifier


class UserCallbackHandler(object):

    def __init__(self, session):
        super(UserCallbackHandler, self).__init__()
        self._logger = logging.getLogger(self.__class__.__name__)

        self.session = session
        self.sesslock = session.sesslock

        # Notifier for callbacks to API user
        self.threadpool = ThreadNoPool()

        self.notifier = Notifier.getInstance(self.threadpool)

    def shutdown(self):
        # stop threadpool
        Notifier.delInstance()
        self.threadpool.joinAll()

    def perform_getstate_usercallback(self, usercallback, data, returncallback):
        """ Called by network thread """
        self._logger.debug("Session: perform_getstate_usercallback()")

        def session_getstate_usercallback_target():
            try:
                (when, getpeerlist) = usercallback(data)
                returncallback(usercallback, when, getpeerlist)
            except:
                self._logger.exception('Could not perform usercallback')
        self.perform_usercallback(session_getstate_usercallback_target)

    def perform_removestate_callback(self, infohash, contentdests):
        """ Called by network thread """
        self._logger.debug("Session: perform_removestate_callback()")

        def session_removestate_callback_target():
            self._logger.debug("Session: session_removestate_callback_target called %s", currentThread().getName())
            try:
                self.sesscb_removestate(infohash, contentdests)
            except:
                self._logger.exception("Could not remove state")
        self.perform_usercallback(session_removestate_callback_target)

    def perform_usercallback(self, target):
        # TODO: thread pool, etc.
        self.threadpool.queueTask(target)

    def sesscb_removestate(self, infohash, contentdests):
        """  See DownloadImpl.setup().
        Called by SessionCallbackThread """
        self._logger.debug("Session: sesscb_removestate called %s %s", repr(infohash), contentdests)
        self.sesslock.acquire()
        try:
            if self.session.lm.download_exists(infohash):
                self._logger.info("Session: sesscb_removestate: Download is back, restarted? Canceling removal! %s", repr(infohash))
                return

            dlpstatedir = os.path.join(self.session.get_state_dir(), STATEDIR_DLPSTATE_DIR)
        finally:
            self.sesslock.release()

        # Remove checkpoint
        hexinfohash = binascii.hexlify(infohash)
        try:
            basename = hexinfohash + '.state'
            filename = os.path.join(dlpstatedir, basename)
            self._logger.debug("Session: sesscb_removestate: removing dlcheckpoint entry %s", filename)
            if os.access(filename, os.F_OK):
                os.remove(filename)
        except:
            # Show must go on
            self._logger.exception("Could not remove state")

    def notify(self, subject, changeType, obj_id, *args):
        """
        Notify all interested observers about an event with threads from the pool
        """
        self._logger.debug("ucb: notify called: %s %s %s %s", subject, changeType, repr(obj_id), args)
        self.notifier.notify(subject, changeType, obj_id, *args)

########NEW FILE########
__FILENAME__ = Base
# Written by Arno Bakker
# see LICENSE.txt for license information
""" Base classes for the Core API """

from Tribler.Core.exceptions import NotYetImplementedException

#
# Tribler API base classes
#


class Serializable:

    """
    Interface to signal that the object is pickleable.
    """
    def __init__(self):
        pass


class Copyable:

    """
    Interface for copying an instance (or rather signaling that it can be
    copied)
    """
    def copy(self):
        """
        Copies the instance.
        @param self     an unbound instance of the class
        @return Returns a copy of "self"
        """
        raise NotYetImplementedException()


class ContentDefinition:

    """ Interface for content definition such as torrents and swift swarms """

    def get_def_type(self):
        """ Returns the type of this Definition
        @return string
        """
        raise NotYetImplementedException()

    def get_name(self):
        """ Returns the user-friendly name of this Definition
        @return string
        """
        raise NotYetImplementedException()

    def get_id(self):
        """ Returns a identifier for this Definition
        @return string
        """
        raise NotYetImplementedException()

########NEW FILE########
__FILENAME__ = Notifier
# Written by Jelle Roozenburg
# see LICENSE.txt for license information

import threading

from Tribler.Core.simpledefs import NTFY_MISC, NTFY_PEERS, NTFY_TORRENTS, \
    NTFY_PLAYLISTS, NTFY_COMMENTS, NTFY_MODIFICATIONS, NTFY_MODERATIONS, \
    NTFY_MARKINGS, NTFY_MYPREFERENCES, NTFY_ACTIVITIES, NTFY_REACHABLE, \
    NTFY_CHANNELCAST, NTFY_VOTECAST, NTFY_DISPERSY, NTFY_TRACKERINFO, \
    NTFY_UPDATE, NTFY_INSERT, NTFY_DELETE, NTFY_ANONTUNNEL

import logging

class Notifier:

    SUBJECTS = [NTFY_MISC, NTFY_PEERS, NTFY_TORRENTS, NTFY_PLAYLISTS,
        NTFY_COMMENTS, NTFY_MODIFICATIONS, NTFY_MODERATIONS, NTFY_MARKINGS,
        NTFY_MYPREFERENCES, NTFY_ACTIVITIES, NTFY_REACHABLE, NTFY_CHANNELCAST,
        NTFY_VOTECAST, NTFY_DISPERSY, NTFY_TRACKERINFO, NTFY_ANONTUNNEL]

    # . . .
    # todo: add all datahandler types+other observables
    __single = None

    def __init__(self, pool=None):
        if Notifier.__single:
            raise RuntimeError("Notifier is singleton")

        self._logger = logging.getLogger(self.__class__.__name__)

        self.pool = pool

        self.observers = []
        self.observerscache = {}
        self.observertimers = {}
        self.observerLock = threading.Lock()

        Notifier.__single = self

    def getInstance(*args, **kw):
        if Notifier.__single is None:
            Notifier(*args, **kw)
        return Notifier.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        if Notifier.__single:
            Notifier.__single.remove_observers()
        Notifier.__single = None
    delInstance = staticmethod(delInstance)

    def add_observer(self, func, subject, changeTypes=[NTFY_UPDATE, NTFY_INSERT, NTFY_DELETE], id=None, cache=0):
        """
        Add observer function which will be called upon certain event
        Example:
        addObserver(NTFY_PEERS, [NTFY_INSERT,NTFY_DELETE]) -> get callbacks
                    when peers are added or deleted
        addObserver(NTFY_PEERS, [NTFY_SEARCH_RESULT], 'a_search_id') -> get
                    callbacks when peer-searchresults of of search
                    with id=='a_search_id' come in
        """
        assert isinstance(changeTypes, list)
        assert subject in self.SUBJECTS, 'Subject %s not in SUBJECTS' % subject

        obs = (func, subject, changeTypes, id, cache)
        self.observerLock.acquire()
        self.observers.append(obs)
        self.observerLock.release()

    def remove_observer(self, func):
        """ Remove all observers with function func
        """
        with self.observerLock:
            i = 0
            while i < len(self.observers):
                ofunc = self.observers[i][0]
                if ofunc == func:
                    del self.observers[i]
                else:
                    i += 1

    def remove_observers(self):
        with self.observerLock:
            for timer in self.observertimers.values():
                timer.cancel()
            self.observerscache = {}
            self.observertimers = {}
            self.observers = []

    def notify(self, subject, changeType, obj_id, *args):
        """
        Notify all interested observers about an event with threads from the pool
        """
        tasks = []
        assert subject in self.SUBJECTS, 'Subject %s not in SUBJECTS' % subject

        args = [subject, changeType, obj_id] + list(args)

        self.observerLock.acquire()
        for ofunc, osubject, ochangeTypes, oid, cache in self.observers:
            try:
                if (subject == osubject and
                    changeType in ochangeTypes and
                        (oid is None or oid == obj_id)):

                    if not cache:
                        tasks.append(ofunc)
                    else:
                        if ofunc not in self.observerscache:
                            def doQueue(ofunc):
                                self.observerLock.acquire()
                                if ofunc in self.observerscache:
                                    events = self.observerscache[ofunc]
                                    del self.observerscache[ofunc]
                                    del self.observertimers[ofunc]
                                else:
                                    events = []
                                self.observerLock.release()

                                if events:
                                    if self.pool:
                                        self.pool.queueTask(ofunc, (events,))
                                    else:
                                        ofunc(events)

                            t = threading.Timer(cache, doQueue, (ofunc,))
                            t.setName("Notifier-timer-%s" % subject)
                            t.start()

                            self.observerscache[ofunc] = []
                            self.observertimers[ofunc] = t

                        self.observerscache[ofunc].append(args)
            except:
                self._logger.exception("OIDs were %s %s", repr(oid), repr(obj_id))

        self.observerLock.release()
        for task in tasks:
            if self.pool:
                self.pool.queueTask(task, args)
            else:
                task(*args)  # call observer function in this thread

########NEW FILE########
__FILENAME__ = sqlitecachedb
# Written by Jie Yang
# see LICENSE.txt for license information
import inspect
import logging
import os
import threading
from base64 import encodestring, decodestring
from threading import currentThread, RLock
from time import time
from traceback import print_exc, print_stack

# ONLY USE APSW >= 3.5.9-r1
import apsw
from twisted.internet import reactor
from twisted.python.threadable import isInIOThread
from twisted.internet.threads import blockingCallFromThread

from Tribler import LIBRARYNAME
from Tribler.Core.Utilities.unicode import dunno2unicode
from Tribler.Core.Utilities.utilities import get_collected_torrent_filename
from Tribler.Core.simpledefs import NTFY_DISPERSY, NTFY_STARTED


# support_version = (3,5,9)
# support_version = (3,3,13)
# apsw_version = tuple([int(r) for r in apsw.apswversion().split('-')[0].split('.')])
# print apsw_version
# assert apsw_version >= support_version, "Required APSW Version >= %d.%d.%d."%support_version + " But your version is %d.%d.%d.\n"%apsw_version + \
#                        "Please download and install it from http://code.google.com/p/apsw/"

# Changed from 4 to 5 by andrea for subtitles support
# Changed from 5 to 6 by George Milescu for ProxyService
# Changed from 6 to 7 for Raynor's TermFrequency table
# Changed from 7 to 8 for Raynor's BundlerPreference table
# Changed from 8 to 9 for Niels's Open2Edit tables
# Changed from 9 to 10 for Fix in Open2Edit PlayListTorrent table
# Changed from 10 to 11 add a index on channeltorrent.torrent_id to improve search performance
# Changed from 11 to 12 imposing some limits on the Tribler database
# Changed from 12 to 13 introduced swift-url modification type
# Changed from 13 to 14 introduced swift_hash/swift_torrent_hash torrent columns + upgrade script
# Changed from 14 to 15 added indices on swift_hash/swift_torrent_hash torrent
# Changed from 15 to 16 changed all swift_torrent_hash that was an empty string to NULL
# Changed from 16 to 17 cleaning buddycast, preference, terms, and subtitles tables, removed indices
# Changed from 17 to 18 added swift-thumbnails/video-info metadatatypes
# Changed from 18 to 19 cleaned peer table, added tracker tables.
# Changed from 19 to 20 added metdata message and data tables.

# Arno, 2012-08-01: WARNING You must also update the version number that is
# written to the DB in the schema_sdb_v*.sql file!!!
CURRENT_MAIN_DB_VERSION = 22

config_dir = None
CREATE_SQL_FILE = None

CREATE_SQL_FILE_POSTFIX = os.path.join(LIBRARYNAME, 'schema_sdb_v' + str(CURRENT_MAIN_DB_VERSION) + '.sql')
DB_FILE_NAME = 'tribler.sdb'
DB_DIR_NAME = 'sqlite'  # db file path = DB_DIR_NAME/DB_FILE_NAME
DEFAULT_BUSY_TIMEOUT = 10000
TEST_OVERRIDE = False

INITIAL_UPGRADE_PAUSE = 10
SUCCESIVE_UPGRADE_PAUSE = 5
UPGRADE_BATCH_SIZE = 100

INSERT_MY_TORRENTS_INTERVAL = 10

TRHEADING_DEBUG = False


logger = logging.getLogger(__name__)


class Warning(Exception):
    pass


def init(state_dir, install_dir, db_exception_handler=None):
    """ create sqlite database """
    config_dir = state_dir
    CREATE_SQL_FILE = os.path.join(install_dir, CREATE_SQL_FILE_POSTFIX)

    sqlite_db_path = os.path.join(config_dir, DB_DIR_NAME, DB_FILE_NAME)
    logger.info("cachedb: init: SQL FILE %s", sqlite_db_path)

    sqlitedb = SQLiteCacheDB.getInstance(db_exception_handler)
    sqlitedb.initDB(sqlite_db_path, CREATE_SQL_FILE)  # the first place to create db in Tribler
    return sqlitedb


def bin2str(bin):
    # Full BASE64-encoded
    return encodestring(bin).replace("\n", "")


def str2bin(str):
    return decodestring(str)


class safe_dict(dict):

    def __init__(self, *args, **kw):
        self.lock = threading.RLock()
        dict.__init__(self, *args, **kw)

    def __getitem__(self, key):
        self.lock.acquire()
        try:
            return dict.__getitem__(self, key)
        finally:
            self.lock.release()

    def __setitem__(self, key, value):
        self.lock.acquire()
        try:
            dict.__setitem__(self, key, value)
        finally:
            self.lock.release()

    def __delitem__(self, key):
        self.lock.acquire()
        try:
            dict.__delitem__(self, key)
        finally:
            self.lock.release()

    def __contains__(self, key):
        self.lock.acquire()
        try:
            return dict.__contains__(self, key)
        finally:
            self.lock.release()

    def values(self):
        self.lock.acquire()
        try:
            return dict.values(self)
        finally:
            self.lock.release()


class SQLiteCacheDBBase:
    lock = threading.RLock()

    def __init__(self, db_exception_handler=None):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.exception_handler = db_exception_handler

        self.cursor_lock = RLock()
        self.cursor_table = {}  # {thread_name:cur}
        self.class_variables = safe_dict({'db_path': None, 'busytimeout': DEFAULT_BUSY_TIMEOUT})  # busytimeout is in milliseconds

        # Arno, 2012-08-02: As there is just Dispersy thread here, removing
        # safe_dict() here
        # 24/09/12 Boudewijn: changed into LimitedOrderedDict to limit memory consumption
        self.show_execute = False

        # TODO: All global variables must be protected to be thread safe?
        self.database_update = None

        # for threading problem
        self._pragma_applied = False

    def __del__(self):
        self.close_all()

    def close(self):
        # only close the connection object in this thread, don't close other thread's connection object
        thread_name = threading.currentThread().getName()
        cur = self.getCursor(create=False)
        if cur:
            self._close_cur(thread_name, cur)

    def close_all(self):
        with self.cursor_lock:
            if self.cursor_table:
                for thread_name, cur in self.cursor_table.items():
                    self._close_cur(thread_name, cur)

                self.cursor_table = None

    def _close_cur(self, thread_name, cur):
        con = cur.getconnection()
        cur.close()
        con.close()

        with self.cursor_lock:
            assert self.cursor_table
            del self.cursor_table[thread_name]

    # --------- static functions --------
    def getCursor(self, create=True):
        thread_name = threading.currentThread().getName()

        with self.cursor_lock:
            assert self.cursor_table != None

            cur = self.cursor_table.get(thread_name, None)  # return [cur, cur, lib] or None
            # print >> sys.stderr, '-------------- getCursor::', len(curs), time(), curs.keys()
            assert self.class_variables['db_path'], "No db_path defined"
            if cur is None and create and self.class_variables['db_path']:
                self.openDB(self.class_variables['db_path'], self.class_variables['busytimeout'])  # create a new db obj for this thread
            cur = self.cursor_table.get(thread_name)

        return cur

    def openDB(self, dbfile_path=None, busytimeout=DEFAULT_BUSY_TIMEOUT):
        """
        Open a SQLite database. Only one and the same database can be opened.
        @dbfile_path       The path to store the database file.
                           Set dbfile_path=':memory:' to create a db in memory.
        @busytimeout       Set the maximum time, in milliseconds, that SQLite will wait if the database is locked.
        """

        # already opened a db in this thread, reuse it
        thread_name = threading.currentThread().getName()
        # print >>sys.stderr,"sqlcachedb: openDB",dbfile_path,thread_name
        with self.cursor_lock:
            assert self.cursor_table != None

            if thread_name in self.cursor_table:
                # assert dbfile_path == None or self.class_variables['db_path'] == dbfile_path
                return self.cursor_table[thread_name]

            assert dbfile_path, "You must specify the path of database file"
            self.class_variables['db_path'] = dbfile_path

            if dbfile_path.lower() != ':memory:':
                db_dir = os.path.dirname(dbfile_path)
                if db_dir and not os.path.isdir(db_dir):
                    os.makedirs(db_dir)

            con = apsw.Connection(dbfile_path)
            con.setbusytimeout(busytimeout)

            cur = con.cursor()
            self.cursor_table[thread_name] = cur

        if not self._pragma_applied:
            self._pragma_applied = True
            page_size, = next(cur.execute("PRAGMA page_size"))
            if page_size < 8192:
                # journal_mode and page_size only need to be set once.  because of the VACUUM this
                # is very expensive
                self._logger.info("begin page_size upgrade...")
                cur.execute("PRAGMA journal_mode = DELETE;")
                cur.execute("PRAGMA page_size = 8192;")
                cur.execute("VACUUM;")
                self._logger.info("...end page_size upgrade")

            # http://www.sqlite.org/pragma.html
            # When synchronous is NORMAL, the SQLite database engine will still
            # pause at the most critical moments, but less often than in FULL
            # mode. There is a very small (though non-zero) chance that a power
            # failure at just the wrong time could corrupt the database in
            # NORMAL mode. But in practice, you are more likely to suffer a
            # catastrophic disk failure or some other unrecoverable hardware
            # fault.
            #
            cur.execute("PRAGMA synchronous = NORMAL;")
            cur.execute("PRAGMA cache_size = 10000;")

            # Niels 19-09-2012: even though my database upgraded to increase the pagesize it did not keep wal mode?
            # Enabling WAL on every starup
            cur.execute("PRAGMA journal_mode = WAL;")

        return cur

    def createDBTable(self, sql_create_table, dbfile_path, busytimeout=DEFAULT_BUSY_TIMEOUT):
        """
        Create a SQLite database.
        @sql_create_table  The sql statements to create tables in the database.
                           Every statement must end with a ';'.
        @dbfile_path       The path to store the database file. Set dbfile_path=':memory:' to creates a db in memory.
        @busytimeout       Set the maximum time, in milliseconds, that SQLite will wait if the database is locked.
                           Default = 10000 milliseconds
        """
        cur = self.openDB(dbfile_path, busytimeout)
        self._logger.info(dbfile_path)
        cur.execute(sql_create_table)  # it is suggested to include begin & commit in the script

    def initDB(self, sqlite_filepath,
               create_sql_filename=None,
               busytimeout=DEFAULT_BUSY_TIMEOUT,
               check_version=True,
               current_db_version=CURRENT_MAIN_DB_VERSION):
        """
        Create and initialize a SQLite database given a sql script.
        Only one db can be opened. If the given dbfile_path is different with the opened DB file, warn and exit
        @configure_dir     The directory containing 'bsddb' directory
        @sql_filename      The path of sql script to create the tables in the database
                           Every statement must end with a ';'.
        @busytimeout       Set the maximum time, in milliseconds, to wait and retry
                           if failed to acquire a lock. Default = 5000 milliseconds
        """
        if create_sql_filename is None:
            create_sql_filename = CREATE_SQL_FILE
        try:
            self.lock.acquire()

            # verify db path identity
            class_db_path = self.class_variables['db_path']
            if sqlite_filepath is None:  # reuse the opened db file?
                if class_db_path is not None:  # yes, reuse it
                    # reuse the busytimeout
                    return self.openDB(class_db_path, self.class_variables['busytimeout'])
                else:  # no db file opened
                    raise Exception("You must specify the path of database file when open it at the first time")
            else:
                if class_db_path is None:  # the first time to open db path, store it

                    # print 'quit now'
                    # sys.exit(0)
                    # open the db if it exists (by converting from bsd) and is not broken, otherwise create a new one
                    # it will update the db if necessary by checking the version number
                    self.safelyOpenTriblerDB(sqlite_filepath, create_sql_filename, busytimeout, check_version=check_version, current_db_version=current_db_version)

                    self.class_variables = {'db_path': sqlite_filepath, 'busytimeout': int(busytimeout)}

                    return self.openDB()  # return the cursor, won't reopen the db

                elif sqlite_filepath != class_db_path:  # not the first time to open db path, check if it is the same
                    raise Exception("Only one database file can be opened. You have opened %s and are trying to open %s." % (class_db_path, sqlite_filepath))

        finally:
            self.lock.release()

    def safelyOpenTriblerDB(self, dbfile_path, sql_create, busytimeout=DEFAULT_BUSY_TIMEOUT, check_version=False, current_db_version=None):
        """
        open the db if possible, otherwise create a new one
        update the db if necessary by checking the version number

        safeOpenDB():
            try:
                if sqlite db doesn't exist:
                    raise Error
                open sqlite db
                read sqlite_db_version
                if sqlite_db_version dosen't exist:
                    raise Error
            except:
                close and delete sqlite db if possible
                create new sqlite db file without sqlite_db_version
                write sqlite_db_version at last
                commit
                open sqlite db
                read sqlite_db_version
                # must ensure these steps after except will not fail, otherwise force to exit

            if sqlite_db_version < current_db_version:
                updateDB(sqlite_db_version, current_db_version)
                commit
                update sqlite_db_version at last
                commit
        """
        try:
            if not os.path.isfile(dbfile_path):
                raise Warning("No existing database found. Attempting to create a new database %s" % repr(dbfile_path))

            cur = self.openDB(dbfile_path, busytimeout)
            if check_version:
                sqlite_db_version = self.readDBVersion()
                if sqlite_db_version == None or int(sqlite_db_version) < 1:
                    raise NotImplementedError
        except Exception as exception:
            if isinstance(exception, Warning):
                # user friendly warning to log the creation of a new database
                self._logger.error(exception)

            else:
                # user unfriendly exception message because something went wrong
                print_exc()

            if os.path.isfile(dbfile_path):
                self.close()
                os.remove(dbfile_path)

            if os.path.isfile(sql_create):
                f = open(sql_create)
                sql_create_tables = f.read()
                f.close()
            else:
                raise Exception("Cannot open sql script at %s" % os.path.realpath(sql_create))

            self.createDBTable(sql_create_tables, dbfile_path, busytimeout)
            if check_version:
                sqlite_db_version = self.readDBVersion()

        if check_version:
            self.checkDB(sqlite_db_version, current_db_version)

    def checkDB(self, db_ver, curr_ver):
        # read MyDB and check the version number.
        if not db_ver or not curr_ver:
            self.updateDB(db_ver, curr_ver)
            return
        db_ver = int(db_ver)
        curr_ver = int(curr_ver)

        self.db_diff = max(0, curr_ver - db_ver)
        if not self.db_diff:
            self.db_diff = sum(os.path.exists(os.path.join(config_dir, filename)) if config_dir else 0 for filename in ["upgradingdb.txt", "upgradingdb2.txt", "upgradingdb3.txt", "upgradingdb4.txt"])

        if self.db_diff:
            self.database_update = threading.Semaphore(self.db_diff)
            self.updateDB(db_ver, curr_ver)

    def updateDB(self, db_ver, curr_ver):
        pass  # TODO

    def waitForUpdateComplete(self):
        if self.database_update:
            for _ in range(self.db_diff):
                self.database_update.acquire()

            for _ in range(self.db_diff):
                self.database_update.release()

    def readDBVersion(self):
        cur = self.getCursor()
        sql = u"select value from MyInfo where entry='version'"
        res = self.fetchone(sql)
        if res:
            return res
        else:
            return None

    def writeDBVersion(self, version):
        sql = u"UPDATE MyInfo SET value=? WHERE entry='version'"
        self.execute_write(sql, [version])

    def show_sql(self, switch):
        # temporary show the sql executed
        self.show_execute = switch

    # --------- generic functions -------------

    def _execute(self, sql, args=None):
        cur = self.getCursor()

        if self.show_execute:
            thread_name = threading.currentThread().getName()
            self._logger.info('===%s===\n%s\n-----\n%s\n======\n', thread_name, sql, args)

        try:
            if args is None:
                return cur.execute(sql)
            else:
                return cur.execute(sql, args)

        except Exception as msg:
            if str(msg).startswith("BusyError"):
                self._logger.error("cachedb: busylock error")

            else:
                thread_name = threading.currentThread().getName()
                self._logger.exception('cachedb: ===%s===\nSQL Type: %s\n-----\n%s\n-----\n%s\n======\n', thread_name, type(sql), sql, args)

            raise msg

    def _executemany(self, sql, args=None):
        cur = self.getCursor()

        if self.show_execute:
            thread_name = threading.currentThread().getName()
            self._logger.info('===%s===\n%s\n-----\n%s\n======\n', thread_name, sql, args)

        try:
            if args is None:
                return cur.executemany(sql)
            else:
                return cur.executemany(sql, args)

        except Exception as msg:
            if str(msg).startswith("BusyError"):
                self._logger.error("cachedb: busylock error")
            else:
                thread_name = threading.currentThread().getName()
                self._logger.exception('===%s===\nSQL Type: %s\n-----\n%s\n-----\n%s\n======\n', thread_name, type(sql), sql, args)

            raise msg

    def execute_read(self, sql, args=None):
        return self._execute(sql, args)

    def execute_write(self, sql, args=None):
        self._execute(sql, args)

    def executemany(self, sql, args):
        self._executemany(sql, args)

    def insert_or_ignore(self, table_name, **argv):
        if len(argv) == 1:
            sql = 'INSERT OR IGNORE INTO %s (%s) VALUES (?);' % (table_name, argv.keys()[0])
        else:
            questions = '?,' * len(argv)
            sql = 'INSERT OR IGNORE INTO %s %s VALUES (%s);' % (table_name, tuple(argv.keys()), questions[:-1])
        self.execute_write(sql, argv.values())

    def insert(self, table_name, **argv):
        if len(argv) == 1:
            sql = 'INSERT INTO %s (%s) VALUES (?);' % (table_name, argv.keys()[0])
        else:
            questions = '?,' * len(argv)
            sql = 'INSERT INTO %s %s VALUES (%s);' % (table_name, tuple(argv.keys()), questions[:-1])
        self.execute_write(sql, argv.values())

    # TODO: may remove this, only used by test_sqlitecachedb.py
    def insertMany(self, table_name, values, keys=None):
        """ values must be a list of tuples """

        questions = u'?,' * len(values[0])
        if keys is None:
            sql = u'INSERT INTO %s VALUES (%s);' % (table_name, questions[:-1])
        else:
            sql = u'INSERT INTO %s %s VALUES (%s);' % (table_name, tuple(keys), questions[:-1])
        self.executemany(sql, values)

    def update(self, table_name, where=None, **argv):
        assert len(argv) > 0, 'NO VALUES TO UPDATE SPECIFIED'
        if len(argv) > 0:
            sql = u'UPDATE %s SET ' % table_name
            arg = []
            for k, v in argv.iteritems():
                if isinstance(v, tuple):
                    sql += u'%s %s ?,' % (k, v[0])
                    arg.append(v[1])
                else:
                    sql += u'%s=?,' % k
                    arg.append(v)
            sql = sql[:-1]
            if where != None:
                sql += u' where %s' % where
            self.execute_write(sql, arg)

    def delete(self, table_name, **argv):
        sql = u'DELETE FROM %s WHERE ' % table_name
        arg = []
        for k, v in argv.iteritems():
            if isinstance(v, tuple):
                sql += u'%s %s ? AND ' % (k, v[0])
                arg.append(v[1])
            else:
                sql += u'%s=? AND ' % k
                arg.append(v)
        sql = sql[:-5]
        self.execute_write(sql, argv.values())

    # -------- Read Operations --------
    def size(self, table_name):
        num_rec_sql = u"SELECT count(*) FROM %s LIMIT 1" % table_name
        result = self.fetchone(num_rec_sql)
        return result

    def fetchone(self, sql, args=None):
        find = self.execute_read(sql, args)
        if not find:
            return
        else:
            find = list(find)
            if len(find) > 0:
                if len(find) > 1:
                    self._logger.debug("FetchONE resulted in many more rows than one, consider putting a LIMIT 1 in the sql statement %s, %s", sql, len(find))
                find = find[0]
            else:
                return
        if len(find) > 1:
            return find
        else:
            return find[0]

    def fetchall(self, sql, args=None):
        res = self.execute_read(sql, args)
        if res != None:
            find = list(res)
            return find
        else:
            return []  # should it return None?

    def getOne(self, table_name, value_name, where=None, conj='and', **kw):
        """ value_name could be a string, a tuple of strings, or '*'
        """

        if isinstance(value_name, tuple):
            value_names = u",".join(value_name)
        elif isinstance(value_name, list):
            value_names = u",".join(value_name)
        else:
            value_names = value_name

        if isinstance(table_name, tuple):
            table_names = u",".join(table_name)
        elif isinstance(table_name, list):
            table_names = u",".join(table_name)
        else:
            table_names = table_name

        sql = u'select %s from %s' % (value_names, table_names)

        if where or kw:
            sql += u' where '
        if where:
            sql += where
            if kw:
                sql += u' %s ' % conj
        if kw:
            arg = []
            for k, v in kw.iteritems():
                if isinstance(v, tuple):
                    operator = v[0]
                    arg.append(v[1])
                else:
                    operator = "="
                    arg.append(v)
                sql += u' %s %s ? ' % (k, operator)
                sql += conj
            sql = sql[:-len(conj)]
        else:
            arg = None

        # print >> sys.stderr, 'SQL: %s %s' % (sql, arg)
        return self.fetchone(sql, arg)

    def getAll(self, table_name, value_name, where=None, group_by=None, having=None, order_by=None, limit=None, offset=None, conj='and', **kw):
        """ value_name could be a string, or a tuple of strings
            order by is represented as order_by
            group by is represented as group_by
        """
        if isinstance(value_name, tuple):
            value_names = u",".join(value_name)
        elif isinstance(value_name, list):
            value_names = u",".join(value_name)
        else:
            value_names = value_name

        if isinstance(table_name, tuple):
            table_names = u",".join(table_name)
        elif isinstance(table_name, list):
            table_names = u",".join(table_name)
        else:
            table_names = table_name

        sql = u'select %s from %s' % (value_names, table_names)

        if where or kw:
            sql += u' where '
        if where:
            sql += where
            if kw:
                sql += u' %s ' % conj
        if kw:
            arg = []
            for k, v in kw.iteritems():
                if isinstance(v, tuple):
                    operator = v[0]
                    arg.append(v[1])
                else:
                    operator = "="
                    arg.append(v)

                sql += u' %s %s ?' % (k, operator)
                sql += conj
            sql = sql[:-len(conj)]
        else:
            arg = None

        if group_by != None:
            sql += u' group by ' + group_by
        if having != None:
            sql += u' having ' + having
        if order_by != None:
            sql += u' order by ' + order_by  # you should add desc after order_by to reversely sort, i.e, 'last_seen desc' as order_by
        if limit != None:
            sql += u' limit %d' % limit
        if offset != None:
            sql += u' offset %d' % offset

        try:
            return self.fetchall(sql, arg) or []
        except Exception as msg:
            self._logger.exception(u"Wrong getAll sql statement: %s", sql)
            raise Exception(msg)


class SQLiteCacheDBV5(SQLiteCacheDBBase):

    def updateDB(self, fromver, tover):

        # bring database up to version 2, if necessary
        if fromver < 2:
            sql = """

-- Patch for BuddyCast 4

ALTER TABLE MyPreference ADD COLUMN click_position INTEGER DEFAULT -1;
ALTER TABLE MyPreference ADD COLUMN reranking_strategy INTEGER DEFAULT -1;
ALTER TABLE Preference ADD COLUMN click_position INTEGER DEFAULT -1;
ALTER TABLE Preference ADD COLUMN reranking_strategy INTEGER DEFAULT -1;
CREATE TABLE ClicklogSearch (
                     peer_id INTEGER DEFAULT 0,
                     torrent_id INTEGER DEFAULT 0,
                     term_id INTEGER DEFAULT 0,
                     term_order INTEGER DEFAULT 0
                     );
CREATE INDEX idx_search_term ON ClicklogSearch (term_id);
CREATE INDEX idx_search_torrent ON ClicklogSearch (torrent_id);


CREATE TABLE ClicklogTerm (
                    term_id INTEGER PRIMARY KEY AUTOINCREMENT DEFAULT 0,
                    term VARCHAR(255) NOT NULL,
                    times_seen INTEGER DEFAULT 0 NOT NULL
                    );
CREATE INDEX idx_terms_term ON ClicklogTerm(term);

"""

            self.execute_write(sql)

        if fromver < 3:
            sql = """
-- Patch for Local Peer Discovery

ALTER TABLE Peer ADD COLUMN is_local integer DEFAULT 0;
"""
            self.execute_write(sql)

        if fromver < 4:
            sql = """
-- V2: Patch for VoteCast

DROP TABLE IF EXISTS ModerationCast;
DROP INDEX IF EXISTS moderationcast_idx;

DROP TABLE IF EXISTS Moderators;
DROP INDEX IF EXISTS moderators_idx;

DROP TABLE IF EXISTS VoteCast;
DROP INDEX IF EXISTS votecast_idx;

CREATE TABLE VoteCast (
mod_id text,
voter_id text,
vote integer,
time_stamp integer
);

CREATE INDEX mod_id_idx
on VoteCast
(mod_id);

CREATE INDEX voter_id_idx
on VoteCast
(voter_id);

CREATE UNIQUE INDEX votecast_idx
ON VoteCast
(mod_id, voter_id);

--- patch for BuddyCast 5 : Creation of Popularity table and relevant stuff

CREATE TABLE Popularity (
                         torrent_id INTEGER,
                         peer_id INTEGER,
                         msg_receive_time NUMERIC,
                         size_calc_age NUMERIC,
                         num_seeders INTEGER DEFAULT 0,
                         num_leechers INTEGER DEFAULT 0,
                         num_of_sources INTEGER DEFAULT 0
                     );

CREATE INDEX Message_receive_time_idx
  ON Popularity
   (msg_receive_time);

CREATE INDEX Size_calc_age_idx
  ON Popularity
   (size_calc_age);

CREATE INDEX Number_of_seeders_idx
  ON Popularity
   (num_seeders);

CREATE INDEX Number_of_leechers_idx
  ON Popularity
   (num_leechers);

CREATE UNIQUE INDEX Popularity_idx
  ON Popularity
   (torrent_id, peer_id, msg_receive_time);

-- v4: Patch for ChannelCast, Search

CREATE TABLE ChannelCast (
publisher_id text,
publisher_name text,
infohash text,
torrenthash text,
torrentname text,
time_stamp integer,
signature text
);

CREATE INDEX pub_id_idx
on ChannelCast
(publisher_id);

CREATE INDEX pub_name_idx
on ChannelCast
(publisher_name);

CREATE INDEX infohash_ch_idx
on ChannelCast
(infohash);

----------------------------------------

CREATE TABLE InvertedIndex (
word               text NOT NULL,
torrent_id         integer
);

CREATE INDEX word_idx
on InvertedIndex
(word);

CREATE UNIQUE INDEX invertedindex_idx
on InvertedIndex
(word,torrent_id);

----------------------------------------

-- Set all similarity to zero because we are using a new similarity
-- function and the old values no longer correspond to the new ones
UPDATE Peer SET similarity = 0;
UPDATE Torrent SET relevance = 0;

"""
            self.execute_write(sql)
        if fromver < 5:
            sql = \
                """
--------------------------------------
-- Creating Subtitles (future RichMetadata) DB
----------------------------------
CREATE TABLE Metadata (
  metadata_id integer PRIMARY KEY ASC AUTOINCREMENT NOT NULL,
  publisher_id text NOT NULL,
  infohash text NOT NULL,
  description text,
  timestamp integer NOT NULL,
  signature text NOT NULL,
  UNIQUE (publisher_id, infohash),
  FOREIGN KEY (publisher_id, infohash)
    REFERENCES ChannelCast(publisher_id, infohash)
    ON DELETE CASCADE -- the fk constraint is not enforced by sqlite
);

CREATE INDEX infohash_md_idx
on Metadata(infohash);

CREATE INDEX pub_md_idx
on Metadata(publisher_id);


CREATE TABLE Subtitles (
  metadata_id_fk integer,
  subtitle_lang text NOT NULL,
  subtitle_location text,
  checksum text NOT NULL,
  UNIQUE (metadata_id_fk,subtitle_lang),
  FOREIGN KEY (metadata_id_fk)
    REFERENCES Metadata(metadata_id)
    ON DELETE CASCADE, -- the fk constraint is not enforced by sqlite

  -- ISO639-2 uses 3 characters for lang codes
  CONSTRAINT lang_code_length
    CHECK ( length(subtitle_lang) == 3 )
);


CREATE INDEX metadata_sub_idx
on Subtitles(metadata_id_fk);

-- Stores the subtitles that peers have as an integer bitmask
 CREATE TABLE SubtitlesHave (
    metadata_id_fk integer,
    peer_id text NOT NULL,
    have_mask integer NOT NULL,
    received_ts integer NOT NULL, --timestamp indicating when the mask was received
    UNIQUE (metadata_id_fk, peer_id),
    FOREIGN KEY (metadata_id_fk)
      REFERENCES Metadata(metadata_id)
      ON DELETE CASCADE, -- the fk constraint is not enforced by sqlite

    -- 32 bit unsigned integer
    CONSTRAINT have_mask_length
      CHECK (have_mask >= 0 AND have_mask < 4294967296)
);

CREATE INDEX subtitles_have_idx
on SubtitlesHave(metadata_id_fk);

-- this index can boost queries
-- ordered by timestamp on the SubtitlesHave DB
CREATE INDEX subtitles_have_ts
on SubtitlesHave(received_ts);

"""

            self.execute_write(sql)

        # P2P Services (ProxyService)
        if fromver < 6:
            sql = """
-- Patch for P2P Servivces (ProxyService)

ALTER TABLE Peer ADD COLUMN services integer DEFAULT 0;
"""
            self.execute_write(sql)

        # Channelcast
        if fromver < 6:
            sql = 'Select * from ChannelCast'
            del_sql = 'Delete from ChannelCast where publisher_id = ? and infohash = ?'
            ins_sql = 'Insert into ChannelCast values (?, ?, ?, ?, ?, ?, ?)'

            seen = {}
            rows = self.fetchall(sql)
            for row in rows:
                if row[0] in seen and row[2] in seen[row[0]]:  # duplicate entry
                    self.execute_write(del_sql, (row[0], row[2]))
                    self.execute_write(ins_sql, (row[0], row[1], row[2], row[3], row[4], row[5], row[6]))
                else:
                    seen.setdefault(row[0], set()).add(row[2])

            sql = 'CREATE UNIQUE INDEX publisher_id_infohash_idx on ChannelCast (publisher_id,infohash);'
            self.execute_write(sql)

        if fromver < 7:
            sql = \
                """
            --------------------------------------
            -- Creating TermFrequency DB
            ----------------------------------
            CREATE TABLE TermFrequency (
              term_id        integer PRIMARY KEY AUTOINCREMENT DEFAULT 0,
              term           text NOT NULL,
              freq           integer,
              UNIQUE (term)
            );

            CREATE INDEX termfrequency_freq_idx
              ON TermFrequency
              (freq);

            CREATE TABLE TorrentBiTermPhrase (
              torrent_id     integer PRIMARY KEY NOT NULL,
              term1_id       integer,
              term2_id       integer,
              UNIQUE (torrent_id),
              FOREIGN KEY (torrent_id)
                REFERENCES Torrent(torrent_id),
              FOREIGN KEY (term1_id)
                REFERENCES TermFrequency(term_id),
              FOREIGN KEY (term2_id)
                REFERENCES TermFrequency(term_id)
            );
            CREATE INDEX torrent_biterm_phrase_idx
              ON TorrentBiTermPhrase
              (term1_id, term2_id);


            --------------------------------------
            -- Creating UserEventLog DB
            ----------------------------------
            CREATE TABLE UserEventLog (
              timestamp      numeric,
              type           integer,
              message        text
            );
            """
            self.execute_write(sql)

        if fromver < 8:
            sql = \
            """
            --------------------------------------
            -- Creating BundlerPreference DB
            ----------------------------------
            CREATE TABLE BundlerPreference (
              query         text PRIMARY KEY,
              bundle_mode   integer
            );
            """
            self.execute_write(sql)

        if fromver < 9:
            sql = \
            """
            CREATE TABLE IF NOT EXISTS _Channels (
              id                        integer         PRIMARY KEY ASC,
              dispersy_cid              text,
              peer_id                   integer,
              name                      text            NOT NULL,
              description               text,
              modified                  integer         DEFAULT (strftime('%s','now')),
              inserted                  integer         DEFAULT (strftime('%s','now')),
              deleted_at                integer,
              nr_torrents               integer         DEFAULT 0,
              nr_spam                   integer         DEFAULT 0,
              nr_favorite               integer         DEFAULT 0
            );
            CREATE VIEW Channels AS SELECT * FROM _Channels WHERE deleted_at IS NULL;

            CREATE TABLE IF NOT EXISTS _ChannelTorrents (
              id                        integer         PRIMARY KEY ASC,
              dispersy_id               integer,
              torrent_id                integer         NOT NULL,
              channel_id                integer         NOT NULL,
              peer_id                   integer,
              name                      text,
              description               text,
              time_stamp                integer,
              modified                  integer         DEFAULT (strftime('%s','now')),
              inserted                  integer         DEFAULT (strftime('%s','now')),
              deleted_at                integer,
              FOREIGN KEY (channel_id) REFERENCES Channels(id) ON DELETE CASCADE
            );
            CREATE VIEW ChannelTorrents AS SELECT * FROM _ChannelTorrents WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS TorChannelIndex ON _ChannelTorrents(channel_id);

            CREATE TABLE IF NOT EXISTS _Playlists (
              id                        integer         PRIMARY KEY ASC,
              channel_id                integer         NOT NULL,
              dispersy_id               integer         NOT NULL,
              peer_id                   integer,
              playlist_id               integer,
              name                      text            NOT NULL,
              description               text,
              modified                  integer         DEFAULT (strftime('%s','now')),
              inserted                  integer         DEFAULT (strftime('%s','now')),
              deleted_at                integer,
              UNIQUE (dispersy_id),
              FOREIGN KEY (channel_id) REFERENCES Channels(id) ON DELETE CASCADE
            );
            CREATE VIEW Playlists AS SELECT * FROM _Playlists WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS PlayChannelIndex ON _Playlists(channel_id);

            CREATE TABLE IF NOT EXISTS _PlaylistTorrents (
              dispersy_id           integer         NOT NULL,
              peer_id               integer,
              playlist_id           integer,
              channeltorrent_id     integer,
              deleted_at            integer,
              PRIMARY KEY (playlist_id, channeltorrent_id),
              FOREIGN KEY (playlist_id) REFERENCES Playlists(id) ON DELETE CASCADE,
              FOREIGN KEY (channeltorrent_id) REFERENCES ChannelTorrents(id) ON DELETE CASCADE
            );
            CREATE VIEW PlaylistTorrents AS SELECT * FROM _PlaylistTorrents WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS PlayTorrentIndex ON _PlaylistTorrents(playlist_id);

            CREATE TABLE IF NOT EXISTS _Comments (
              id                    integer         PRIMARY KEY ASC,
              dispersy_id           integer         NOT NULL,
              peer_id               integer,
              channel_id            integer         NOT NULL,
              comment               text            NOT NULL,
              reply_to_id           integer,
              reply_after_id        integer,
              time_stamp            integer,
              inserted              integer         DEFAULT (strftime('%s','now')),
              deleted_at            integer,
              UNIQUE (dispersy_id),
              FOREIGN KEY (channel_id) REFERENCES Channels(id) ON DELETE CASCADE
            );
            CREATE VIEW Comments AS SELECT * FROM _Comments WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS ComChannelIndex ON _Comments(channel_id);

            CREATE TABLE IF NOT EXISTS CommentPlaylist (
              comment_id            integer,
              playlist_id           integer,
              PRIMARY KEY (comment_id,playlist_id),
              FOREIGN KEY (playlist_id) REFERENCES Playlists(id) ON DELETE CASCADE
              FOREIGN KEY (comment_id) REFERENCES Comments(id) ON DELETE CASCADE
            );
            CREATE INDEX IF NOT EXISTS CoPlaylistIndex ON CommentPlaylist(playlist_id);

            CREATE TABLE IF NOT EXISTS CommentTorrent (
              comment_id            integer,
              channeltorrent_id     integer,
              PRIMARY KEY (comment_id, channeltorrent_id),
              FOREIGN KEY (comment_id) REFERENCES Comments(id) ON DELETE CASCADE
              FOREIGN KEY (channeltorrent_id) REFERENCES ChannelTorrents(id) ON DELETE CASCADE
            );
            CREATE INDEX IF NOT EXISTS CoTorrentIndex ON CommentTorrent(channeltorrent_id);

            CREATE TABLE IF NOT EXISTS _Moderations (
              id                    integer         PRIMARY KEY ASC,
              dispersy_id           integer         NOT NULL,
              channel_id            integer         NOT NULL,
              peer_id               integer,
              severity              integer         NOT NULL DEFAULT (0),
              message               text            NOT NULL,
              cause                 integer         NOT NULL,
              by_peer_id            integer,
              time_stamp            integer         NOT NULL,
              inserted              integer         DEFAULT (strftime('%s','now')),
              deleted_at            integer,
              UNIQUE (dispersy_id),
              FOREIGN KEY (channel_id) REFERENCES Channels(id) ON DELETE CASCADE
            );
            CREATE VIEW Moderations AS SELECT * FROM _Moderations WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS MoChannelIndex ON _Moderations(channel_id);

            CREATE TABLE IF NOT EXISTS _ChannelMetaData (
              id                    integer         PRIMARY KEY ASC,
              dispersy_id           integer         NOT NULL,
              channel_id            integer         NOT NULL,
              peer_id               integer,
              type_id               integer         NOT NULL,
              value                 text            NOT NULL,
              prev_modification     integer,
              prev_global_time      integer,
              time_stamp            integer         NOT NULL,
              inserted              integer         DEFAULT (strftime('%s','now')),
              deleted_at            integer,
              UNIQUE (dispersy_id),
              FOREIGN KEY (type_id) REFERENCES MetaDataTypes(id) ON DELETE CASCADE
            );
            CREATE VIEW ChannelMetaData AS SELECT * FROM _ChannelMetaData WHERE deleted_at IS NULL;
            CREATE TABLE IF NOT EXISTS MetaDataTypes (
              id                    integer         PRIMARY KEY ASC,
              name                  text            NOT NULL,
              type                  text            NOT NULL DEFAULT('text')
            );

            CREATE TABLE IF NOT EXISTS MetaDataTorrent (
              metadata_id           integer,
              channeltorrent_id     integer,
              PRIMARY KEY (metadata_id, channeltorrent_id),
              FOREIGN KEY (metadata_id) REFERENCES ChannelMetaData(id) ON DELETE CASCADE
              FOREIGN KEY (channeltorrent_id) REFERENCES ChannelTorrents(id) ON DELETE CASCADE
            );
            CREATE INDEX IF NOT EXISTS MeTorrentIndex ON MetaDataTorrent(channeltorrent_id);

            CREATE TABLE IF NOT EXISTS MetaDataPlaylist (
              metadata_id           integer,
              playlist_id           integer,
              PRIMARY KEY (metadata_id,playlist_id),
              FOREIGN KEY (playlist_id) REFERENCES Playlists(id) ON DELETE CASCADE
              FOREIGN KEY (metadata_id) REFERENCES ChannelMetaData(id) ON DELETE CASCADE
            );
            CREATE INDEX IF NOT EXISTS MePlaylistIndex ON MetaDataPlaylist(playlist_id);

            CREATE TABLE IF NOT EXISTS _ChannelVotes (
              channel_id            integer,
              voter_id              integer,
              dispersy_id           integer,
              vote                  integer,
              time_stamp            integer,
              deleted_at            integer,
              PRIMARY KEY (channel_id, voter_id)
            );
            CREATE VIEW ChannelVotes AS SELECT * FROM _ChannelVotes WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS ChaVotIndex ON _ChannelVotes(channel_id);
            CREATE INDEX IF NOT EXISTS VotChaIndex ON _ChannelVotes(voter_id);

            CREATE TABLE IF NOT EXISTS TorrentFiles (
              torrent_id            integer NOT NULL,
              path                  text    NOT NULL,
              length                integer NOT NULL,
              PRIMARY KEY (torrent_id, path)
            );
            CREATE INDEX IF NOT EXISTS TorFileIndex ON TorrentFiles(torrent_id);

            CREATE TABLE IF NOT EXISTS TorrentCollecting (
              torrent_id            integer NOT NULL,
              source                text    NOT NULL,
              PRIMARY KEY (torrent_id, source)
            );
            CREATE INDEX IF NOT EXISTS TorColIndex ON TorrentCollecting(torrent_id);

            CREATE TABLE IF NOT EXISTS _TorrentMarkings (
              dispersy_id           integer NOT NULL,
              channeltorrent_id     integer NOT NULL,
              peer_id               integer,
              global_time           integer,
              type                  text    NOT NULL,
              time_stamp            integer NOT NULL,
              deleted_at            integer,
              UNIQUE (dispersy_id),
              PRIMARY KEY (channeltorrent_id, peer_id)
            );
            CREATE VIEW TorrentMarkings AS SELECT * FROM _TorrentMarkings WHERE deleted_at IS NULL;
            CREATE INDEX IF NOT EXISTS TorMarkIndex ON _TorrentMarkings(channeltorrent_id);

            CREATE VIRTUAL TABLE FullTextIndex USING fts3(swarmname, filenames, fileextensions);

            INSERT INTO MetaDataTypes ('name') VALUES ('name');
            INSERT INTO MetaDataTypes ('name') VALUES ('description');
            """
            self.execute_write(sql)

        if fromver < 20:
            sql = \
"""
--------------------------------------
-- Creating BundlerPreference DB
----------------------------------
CREATE TABLE MetadataMessage (
  message_id             INTEGER PRIMARY KEY AUTOINCREMENT,
  dispersy_id            INTEGER NOT NULL,
  this_global_time       INTEGER NOT NULL,
  this_mid               TEXT NOT NULL,
  infohash               TEXT NOT NULL,
  roothash               TEXT,
  previous_mid           TEXT,
  previous_global_time   INTEGER
);

CREATE TABLE MetadataData (
  message_id  INTEGER,
  data_key    TEXT NOT NULL,
  data_value  INTEGER,
  FOREIGN KEY (message_id) REFERENCES MetadataMessage(message_id) ON DELETE CASCADE
);
"""
            self.execute_write(sql)

        # updating version stepwise so if this works, we store it
        # regardless of later, potentially failing updates
        self.writeDBVersion(CURRENT_MAIN_DB_VERSION)

        tqueue = None

        def kill_threadqueue_if_empty():
            if tqueue.get_nr_tasks() == 0:
                tqueue.shutdown(True)
            else:
                tqueue.add_task(kill_threadqueue_if_empty, SUCCESIVE_UPGRADE_PAUSE, "kill_if_empty")

        from Tribler.Core.Session import Session
        session = Session.get_instance()
        state_dir = session.get_state_dir()
        torrent_dir = session.get_torrent_collecting_dir()
        my_permid = session.get_permid()
        if my_permid:
            my_permid = bin2str(my_permid)

        tmpfilename = os.path.join(state_dir, "upgradingdb.txt")
        if fromver < 4 or os.path.exists(tmpfilename):
            self.database_update.acquire()

            def upgradeTorrents():
                self._logger.info("Upgrading DB .. inserting into InvertedIndex")

                # fetch some un-inserted torrents to put into the InvertedIndex
                sql = """
                SELECT torrent_id, name, torrent_file_name
                FROM Torrent
                WHERE torrent_id NOT IN (SELECT DISTINCT torrent_id FROM InvertedIndex)
                AND torrent_file_name IS NOT NULL
                LIMIT %d""" % UPGRADE_BATCH_SIZE
                records = self.fetchall(sql)

                if len(records) == 0:
                    # upgradation is complete and hence delete the temp file
                    if os.path.exists(tmpfilename):
                        os.remove(tmpfilename)
                        self._logger.info("DB Upgradation: temp-file deleted %s", tmpfilename)

                    self.database_update.release()
                    return

                for torrent_id, name, torrent_file_name in records:
                    try:
                        abs_filename = os.path.join(session.get_torrent_collecting_dir(), torrent_file_name)
                        if not os.path.exists(abs_filename):
                            raise RuntimeError(".torrent file not found. Use fallback.")
                        torrentdef = TorrentDef.load(abs_filename)
                        torrent_name = torrentdef.get_name_as_unicode()
                        keywords = Set(split_into_keywords(torrent_name))
                        for filename in torrentdef.get_files_as_unicode():
                            keywords.update(split_into_keywords(filename))

                    except Exception:
                        # failure... most likely the .torrent file
                        # is invalid

                        # use keywords from the torrent name
                        # stored in the database
                        torrent_name = dunno2unicode(name)
                        keywords = Set(split_into_keywords(torrent_name))

                    # store the keywords in the InvertedIndex
                    # table in the database
                    if len(keywords) > 0:
                        values = [(keyword, torrent_id) for keyword in keywords]
                        self.executemany(u"INSERT OR REPLACE INTO InvertedIndex VALUES(?, ?)", values)
                        self._logger.debug("DB Upgradation: Extending the InvertedIndex table with %d new keywords for %s", len(values), torrent_name)

                # upgradation not yet complete; comeback after 5 sec
                tqueue.add_task(upgradeTorrents, SUCCESIVE_UPGRADE_PAUSE)

            # Create an empty file to mark the process of upgradation.
            # In case this process is terminated before completion of upgradation,
            # this file remains even though fromver >= 4 and hence indicating that
            # rest of the torrents need to be inserted into the InvertedIndex!
            # ensure the temp-file is created, if it is not already
            try:
                open(tmpfilename, "w")
                self._logger.info("DB Upgradation: temp-file successfully created %s", tmpfilename)
            except:
                self._logger.error("DB Upgradation: failed to create temp-file %s", tmpfilename)

            self._logger.debug("Upgrading DB .. inserting into InvertedIndex")
            from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue
            from sets import Set
            from Tribler.Core.Search.SearchManager import split_into_keywords
            from Tribler.Core.TorrentDef import TorrentDef

            # start the upgradation after 10 seconds
            if not tqueue:
                tqueue = TimedTaskQueue("UpgradeDB")
                tqueue.add_task(kill_threadqueue_if_empty, INITIAL_UPGRADE_PAUSE + 1, "kill_if_empty")
            tqueue.add_task(upgradeTorrents, INITIAL_UPGRADE_PAUSE)

        if fromver < 7:
            self.database_update.acquire()

            # for now, fetch all existing torrents and extract terms
            from Tribler.Core.Tag.Extraction import TermExtraction
            extractor = TermExtraction.getInstance()

            sql = """
                SELECT torrent_id, name
                FROM Torrent
                WHERE name IS NOT NULL
                """
            ins_terms_sql = u"INSERT INTO TermFrequency (term, freq) VALUES(?, ?)"
            ins_phrase_sql = u"""INSERT INTO TorrentBiTermPhrase (torrent_id, term1_id, term2_id)
                                    SELECT ? AS torrent_id, TF1.term_id, TF2.term_id
                                    FROM TermFrequency TF1, TermFrequency TF2
                                    WHERE TF1.term = ? AND TF2.term = ?"""
            dbg_ts1 = time()

            records = self.fetchall(sql)
            termcount = {}
            phrases = []  # torrent_id, term1, term2
            for torrent_id, name in records:
                terms = set(extractor.extractTerms(name))
                phrase = extractor.extractBiTermPhrase(name)

                # count terms
                for term in terms:
                    termcount[term] = termcount.get(term, 0) + 1

                # add bi-term phrase if not None
                if phrase is not None:
                    phrases.append((torrent_id,) + phrase)

            # insert terms and phrases
            self.executemany(ins_terms_sql, termcount.items())
            self.executemany(ins_phrase_sql, phrases)

            dbg_ts2 = time()
            self._logger.debug('DB Upgradation: extracting and inserting terms took %s s', dbg_ts2 - dbg_ts1)

            self.database_update.release()

        if fromver < 8:
            self.database_update.acquire()

            self._logger.debug("STARTING UPGRADE")
            t1 = time()

            from Tribler.Core.Search.SearchManager import split_into_keywords

            # due to a bug, we have to insert all keywords with a length of 2
            sql = "SELECT torrent_id, name FROM CollectedTorrent"
            records = self.fetchall(sql)

            values = []
            for torrent_id, name in records:
                keywords = set(split_into_keywords(name))

                for keyword in keywords:
                    if len(keyword) == 2:
                        values.append((keyword, torrent_id))

            t2 = time()

            self.executemany(u"INSERT OR IGNORE INTO InvertedIndex VALUES(?, ?)", values)
            self._logger.debug("INSERTING NEW KEYWORDS TOOK %s INSERTING took %s", time() - t1, time() - t2)

            self.database_update.release()

        tmpfilename2 = os.path.join(state_dir, "upgradingdb2.txt")
        if fromver < 9 or os.path.exists(tmpfilename2):
            self.database_update.acquire()

            def getPeerID(permid):
                assert isinstance(permid, str), permid

                sql_get_peer_id = "SELECT peer_id FROM Peer WHERE permid==?"
                peer_id = self.fetchone(sql_get_peer_id, (bin2str(permid),))
                return peer_id

            from Tribler.Core.Session import Session
            from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue
            from Tribler.Core.Search.SearchManager import split_into_keywords
            from Tribler.Core.TorrentDef import TorrentDef

            # Create an empty file to mark the process of upgradation.
            # In case this process is terminated before completion of upgradation,
            # this file remains even though fromver >= 4 and hence indicating that
            # rest of the torrents need to be inserted into the InvertedIndex!

            # ensure the temp-file is created, if it is not already
            try:
                open(tmpfilename2, "w")
                self._logger.info("DB Upgradation: temp-file successfully created %s", tmpfilename2)
            except:
                self._logger.error("DB Upgradation: failed to create temp-file %s", tmpfilename2)

            # start converting channelcastdb to new format
            finished_convert = "SELECT name FROM sqlite_master WHERE name='ChannelCast'"
            select_channels = "SELECT publisher_id, min(time_stamp), max(time_stamp) FROM ChannelCast WHERE publisher_name <> '' GROUP BY publisher_id"
            select_channel_name = "SELECT publisher_name FROM ChannelCast WHERE publisher_id = ? AND time_stamp = ? LIMIT 1"

            select_channel_torrent = "SELECT CollectedTorrent.torrent_id, time_stamp FROM ChannelCast, CollectedTorrent WHERE publisher_id = ? AND ChannelCast.infohash = CollectedTorrent.infohash Order By time_stamp DESC"

            select_channel_id = "SELECT id FROM Channels WHERE peer_id = ?"

            insert_channel = "INSERT INTO _Channels (dispersy_cid, peer_id, name, description, inserted, modified) VALUES (?, ?, ?, ?, ?, ?)"
            insert_channel_contents = "INSERT OR IGNORE INTO _ChannelTorrents (dispersy_id, torrent_id, channel_id, time_stamp, inserted) VALUES (?,?,?,?,?)"

            update_channel = "UPDATE _Channels SET nr_torrents = ? WHERE id = ?"

            select_votes = "SELECT mod_id, voter_id, vote, time_stamp FROM VoteCast Order By time_stamp ASC"
            insert_vote = "INSERT OR REPLACE INTO _ChannelVotes (channel_id, voter_id, dispersy_id, vote, time_stamp) VALUES (?,?,?,?,?)"

            if self.fetchone(finished_convert) == 'ChannelCast':

                # placeholders for dispersy channel conversion
                my_channel_name = None

                to_be_inserted = []
                t1 = time()

                # create channels
                permid_peerid = {}
                channel_permid_cid = {}
                channels = self.fetchall(select_channels)
                for publisher_id, mintimestamp, maxtimestamp in channels:
                    channel_name = self.fetchone(select_channel_name, (publisher_id, maxtimestamp))

                    if publisher_id == my_permid:
                        my_channel_name = channel_name
                        continue

                    peer_id = getPeerID(str2bin(publisher_id))
                    if peer_id:
                        permid_peerid[publisher_id] = peer_id
                        to_be_inserted.append((-1, peer_id, channel_name, '', mintimestamp, maxtimestamp))

                self.executemany(insert_channel, to_be_inserted)

                to_be_inserted = []

                # insert torrents
                for publisher_id, peer_id in permid_peerid.iteritems():
                    torrents = self.fetchall(select_channel_torrent, (publisher_id,))

                    channel_id = self.fetchone(select_channel_id, (peer_id,))
                    channel_permid_cid[publisher_id] = channel_id

                    for torrent_id, time_stamp in torrents:
                        to_be_inserted.append((-1, torrent_id, channel_id, long(time_stamp), long(time_stamp)))

                    self.execute_write(update_channel, (len(torrents), channel_id))
                self.executemany(insert_channel_contents, to_be_inserted)

                # convert votes
                to_be_inserted = []
                votes = self.fetchall(select_votes)
                for mod_id, voter_id, vote, time_stamp in votes:
                    if mod_id != my_permid:  # cannot yet convert votes on my channel

                        channel_id = channel_permid_cid.get(mod_id, None)

                        if channel_id:
                            if voter_id == my_permid:
                                to_be_inserted.append((channel_id, None, -1, vote, time_stamp))
                            else:
                                peer_id = getPeerID(str2bin(voter_id))
                                if peer_id:
                                    to_be_inserted.append((channel_id, peer_id, -1, vote, time_stamp))

                self.executemany(insert_vote, to_be_inserted)

                # set cached nr_spam and nr_favorites
                votes = {}
                select_pos_vote = "SELECT channel_id, count(*) FROM ChannelVotes WHERE vote == 2 GROUP BY channel_id"
                select_neg_vote = "SELECT channel_id, count(*) FROM ChannelVotes WHERE vote == -1 GROUP BY channel_id"
                records = self.fetchall(select_pos_vote)
                for channel_id, pos_votes in records:
                    votes[channel_id] = [pos_votes, 0]

                records = self.fetchall(select_neg_vote)
                for channel_id, neg_votes in records:
                    if channel_id not in votes:
                        votes[channel_id] = [0, neg_votes]
                    else:
                        votes[channel_id][1] = neg_votes

                channel_tuples = [(values[1], values[0], channel_id) for channel_id, values in votes.iteritems()]
                update_votes = "UPDATE _Channels SET nr_spam = ?, nr_favorite = ? WHERE id = ?"
                self.executemany(update_votes, channel_tuples)

                self.execute_write('DELETE FROM VoteCast WHERE mod_id <> ?', (my_permid,))
                self.execute_write('DELETE FROM ChannelCast WHERE publisher_id <> ?', (my_permid,))

                select_mychannel_id = "SELECT id FROM Channels WHERE peer_id ISNULL LIMIT 1"
                select_votes_for_me = "SELECT voter_id, vote, time_stamp FROM VoteCast WHERE mod_id = ? Order By time_stamp ASC"
                select_mychannel_torrent = "SELECT CollectedTorrent.infohash, time_stamp, torrent_file_name FROM ChannelCast, CollectedTorrent WHERE publisher_id = ? AND ChannelCast.infohash = CollectedTorrent.infohash AND CollectedTorrent.torrent_id NOT IN (SELECT torrent_id FROM ChannelTorrents WHERE channel_id = ?) ORDER BY time_stamp DESC LIMIT ?"

                if my_channel_name:
                    def dispersy_started(subject, changeType, objectID):
                        self._logger.info("Dispersy started")
                        dispersy = session.lm.dispersy

                        community = None

                        @call_on_reactor_thread
                        def create_my_channel():
                            global community

                            if my_channel_name:
                                channel_id = self.fetchone('SELECT id FROM Channels WHERE peer_id ISNULL LIMIT 1')

                                if channel_id:
                                    self._logger.info("Dispersy started, allready got community")
                                    dispersy_cid = self.fetchone("SELECT dispersy_cid FROM Channels WHERE id = ?", (channel_id,))
                                    dispersy_cid = str(dispersy_cid)

                                    community = dispersy.get_community(dispersy_cid)

                                else:
                                    self._logger.info("Dispersy started, creating community")

                                    community = ChannelCommunity.create_community(session.dispersy_member)
                                    community._disp_create_channel(my_channel_name, u'')

                                    self._logger.info("Dispersy started, community created")

                                # insert votes
                                insert_votes_for_me()

                                # schedule insert torrents
                                insert_my_torrents()

                        @forceDBThread
                        def insert_votes_for_me():
                            self._logger.info("Dispersy started, inserting votes")
                            my_channel_id = self.fetchone(select_mychannel_id)

                            to_be_inserted = []

                            votes = self.fetchall(select_votes_for_me, (my_permid,))
                            for voter_id, vote, time_stamp in votes:
                                peer_id = getPeerID(str2bin(voter_id))
                                if peer_id:
                                    to_be_inserted.append((my_channel_id, peer_id, -1, vote, time_stamp))

                            if len(to_be_inserted) > 0:
                                self.executemany(insert_vote, to_be_inserted)

                                from Tribler.Core.CacheDB.SqliteCacheDBHandler import VoteCastDBHandler
                                votecast = VoteCastDBHandler.getInstance()
                                votecast._updateVotes(my_channel_id)

                        @call_on_reactor_thread
                        def insert_my_torrents():
                            global community

                            self._logger.info("Dispersy started, inserting torrents")
                            channel_id = self.fetchone(select_mychannel_id)
                            if channel_id:
                                batch_insert = 50

                                to_be_inserted = []
                                to_be_removed = []
                                torrents = self.fetchall(select_mychannel_torrent, (my_permid, channel_id, batch_insert))
                                for infohash, timestamp, torrent_file_name in torrents:
                                    timestamp = long(timestamp)
                                    infohash = str2bin(infohash)

                                    torrent_file_name = os.path.join(torrent_dir, torrent_file_name)
                                    if not os.path.isfile(torrent_file_name):
                                        _, tail = os.path.split(torrent_file_name)
                                        torrent_file_name = os.path.join(torrent_dir, tail)

                                    if os.path.isfile(torrent_file_name):
                                        try:
                                            torrentdef = TorrentDef.load(torrent_file_name)

                                            files = torrentdef.get_files_as_unicode_with_length()
                                            to_be_inserted.append((infohash, timestamp, torrentdef.get_name_as_unicode(), tuple(files), torrentdef.get_trackers_as_single_tuple()))
                                        except ValueError:
                                            to_be_removed.append((bin2str(infohash),))
                                    else:
                                        to_be_removed.append((bin2str(infohash),))

                                if len(torrents) > 0:
                                    if len(to_be_inserted) > 0:
                                        community._disp_create_torrents(to_be_inserted, forward=False)

                                    if len(to_be_removed) > 0:
                                        self.executemany("DELETE FROM ChannelCast WHERE infohash = ?", to_be_removed)
                                    self._pending_tasks.append(reactor.callLater(INSERT_MY_TORRENTS_INTERVAL, insert_my_torrents))

                                else:  # done
                                    drop_channelcast = "DROP TABLE ChannelCast"
                                    self.execute_write(drop_channelcast)

                                    drop_votecast = "DROP TABLE VoteCast"
                                    self.execute_write(drop_votecast)
                            else:
                                self._pending_tasks.append(reactor.callLater(SUCCESIVE_UPGRADE_PAUSE, insert_my_torrents))

                        from Tribler.community.channel.community import ChannelCommunity
                        from Tribler.Core.TorrentDef import TorrentDef

                        self._pending_tasks.append(reactor.callLater(INITIAL_UPGRADE_PAUSE, create_my_channel))
                        session.remove_observer(dispersy_started)

                    session.add_observer(dispersy_started, NTFY_DISPERSY, [NTFY_STARTED])
                else:
                    drop_channelcast = "DROP TABLE ChannelCast"
                    self.execute_write(drop_channelcast)

                    drop_votecast = "DROP TABLE VoteCast"
                    self.execute_write(drop_votecast)

            def upgradeTorrents2():
                if not os.path.exists(tmpfilename):
                    self._logger.info("Upgrading DB .. inserting into FullTextIndex")

                    # fetch some un-inserted torrents to put into the FullTextIndex
                    sql = """
                    SELECT torrent_id, name, infohash, num_files, torrent_file_name
                    FROM CollectedTorrent
                    WHERE torrent_id NOT IN (SELECT rowid FROM FullTextIndex)
                    LIMIT %d""" % UPGRADE_BATCH_SIZE
                    records = self.fetchall(sql)

                    if len(records) == 0:
                        self.execute_write("DROP TABLE InvertedIndex")

                        if os.path.exists(tmpfilename2):
                            # upgradation is complete and hence delete the temp file
                            os.remove(tmpfilename2)
                            self._logger.info("DB Upgradation: temp-file deleted %s", tmpfilename2)

                        self.database_update.release()
                        return

                    values = []
                    for torrent_id, name, infohash, num_files, torrent_filename in records:
                        try:
                            torrent_filename = os.path.join(torrent_dir, torrent_filename)

                            # .torrent found, return complete filename
                            if not os.path.isfile(torrent_filename):
                                # .torrent not found, possibly a new torrent_collecting_dir
                                torrent_filename = get_collected_torrent_filename(str2bin(infohash))
                                torrent_filename = os.path.join(torrent_dir, torrent_filename)

                            if not os.path.isfile(torrent_filename):
                                raise RuntimeError(".torrent file not found. Use fallback.")

                            torrentdef = TorrentDef.load(torrent_filename)

                            # Making sure that swarmname does not include extension for single file torrents
                            swarmname = torrentdef.get_name_as_unicode()
                            if not torrentdef.is_multifile_torrent():
                                swarmname, _ = os.path.splitext(swarmname)

                            filedict = {}
                            fileextensions = set()
                            for filename in torrentdef.get_files_as_unicode():
                                filename, extension = os.path.splitext(filename)
                                for keyword in split_into_keywords(filename, filterStopwords=True):
                                    filedict[keyword] = filedict.get(keyword, 0) + 1

                                fileextensions.add(extension[1:])

                            filenames = filedict.keys()
                            if len(filenames) > 1000:
                                def popSort(a, b):
                                    return filedict[a] - filedict[b]
                                filenames.sort(cmp=popSort, reverse=True)
                                filenames = filenames[:1000]

                        except (RuntimeError, ValueError):
                            swarmname = dunno2unicode(name)
                            fileextensions = set()
                            filenames = []

                            if num_files == 1:
                                swarmname, extension = os.path.splitext(swarmname)
                                fileextensions.add(extension[1:])

                                filenames.extend(split_into_keywords(swarmname, filterStopwords=True))

                        values.append((torrent_id, swarmname, " ".join(filenames), " ".join(fileextensions)))

                    if len(values) > 0:
                        self.executemany(u"INSERT INTO FullTextIndex (rowid, swarmname, filenames, fileextensions) VALUES(?,?,?,?)", values)

                # upgradation not yet complete; comeback after 5 sec
                tqueue.add_task(upgradeTorrents2, SUCCESIVE_UPGRADE_PAUSE)

            # start the upgradation after 10 seconds
            if not tqueue:
                tqueue = TimedTaskQueue("UpgradeDB")
                tqueue.add_task(kill_threadqueue_if_empty, INITIAL_UPGRADE_PAUSE + 1, "kill_if_empty")
            tqueue.add_task(upgradeTorrents2, INITIAL_UPGRADE_PAUSE)

        if fromver < 10:
            self.database_update.acquire()

            rename_table = "ALTER TABLE _PlaylistTorrents RENAME TO _PlaylistTorrents2"
            self.execute_write(rename_table)

            improved_table = """
            CREATE TABLE IF NOT EXISTS _PlaylistTorrents (
              id                    integer         PRIMARY KEY ASC,
              dispersy_id           integer         NOT NULL,
              peer_id               integer,
              playlist_id           integer,
              channeltorrent_id     integer,
              deleted_at            integer,
              FOREIGN KEY (playlist_id) REFERENCES Playlists(id) ON DELETE CASCADE,
              FOREIGN KEY (channeltorrent_id) REFERENCES ChannelTorrents(id) ON DELETE CASCADE
            );"""
            self.execute_write(improved_table)

            copy_data = "INSERT INTO _PlaylistTorrents (dispersy_id, peer_id, playlist_id, channeltorrent_id, deleted_at) SELECT dispersy_id, peer_id, playlist_id, channeltorrent_id, deleted_at FROM _PlaylistTorrents2"
            self.execute_write(copy_data)

            drop_table = "DROP TABLE _PlaylistTorrents2"
            self.execute_write(drop_table)

            self.database_update.release()

        if fromver < 11:
            self.database_update.acquire()

            index = "CREATE INDEX IF NOT EXISTS ChannelTorIndex ON _ChannelTorrents(torrent_id)"
            self.execute_write(index)

            self.database_update.release()

        if fromver < 12:
            self.database_update.acquire()

            remove_indexes = ["Message_receive_time_idx", "Size_calc_age_idx", "Number_of_seeders_idx", "Number_of_leechers_idx", "Torrent_length_idx", "Torrent_num_seeders_idx", "Torrent_num_leechers_idx"]
            for index in remove_indexes:
                self.execute_write("DROP INDEX %s" % index)

            self.execute_write("CREATE INDEX Peer_local_oversion_idx ON Peer(is_local, oversion)")
            self.execute_write("CREATE INDEX torrent_tracker_last_idx ON TorrentTracker (tracker, last_check)")
            self.execute_write("CREATE INDEX IF NOT EXISTS ChannelTorChanIndex ON _ChannelTorrents(torrent_id, channel_id)")


            self.database_update.release()

        if fromver < 13:
            self.database_update.acquire()
            self.execute_write("INSERT INTO MetaDataTypes ('name') VALUES ('swift-url');")
            self.database_update.release()

        tmpfilename3 = os.path.join(state_dir, "upgradingdb3.txt")
        if fromver < 14 or os.path.exists(tmpfilename3):
            self.database_update.acquire()

            if fromver < 14:
                self.execute_write("ALTER TABLE Torrent ADD COLUMN dispersy_id integer;")
                self.execute_write("ALTER TABLE Torrent ADD COLUMN swift_hash text;")
                self.execute_write("ALTER TABLE Torrent ADD COLUMN swift_torrent_hash text;")
                self.execute_write("CREATE INDEX Torrent_insert_idx ON Torrent (insert_time, swift_torrent_hash);")
                self.execute_write("CREATE INDEX Torrent_info_roothash_idx ON Torrent (infohash, swift_torrent_hash);")

            # Create an empty file to mark the process of upgradation.
            # In case this process is terminated before completion of upgradation,
            # this file remains even though fromver >= 14 and hence indicating that
            # rest of the collected torrents need to be swiftroothashed!

            from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue
            from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler

            # ensure the temp-file is created, if it is not already
            try:
                open(tmpfilename3, "w")
                self._logger.info("DB Upgradation: temp-file successfully created %s", tmpfilename3)
            except:
                self._logger.error("DB Upgradation: failed to create temp-file %s", tmpfilename3)

            def upgradeTorrents3():
                if not (os.path.exists(tmpfilename2) or os.path.exists(tmpfilename)):
                    self._logger.info("Upgrading DB .. hashing torrents")

                    rth = RemoteTorrentHandler.getInstance()
                    if rth.registered or TEST_OVERRIDE:
                        if not TEST_OVERRIDE:
                            sql = "SELECT infohash, torrent_file_name FROM CollectedTorrent WHERE swift_torrent_hash IS NULL or swift_torrent_hash = '' LIMIT %d" % UPGRADE_BATCH_SIZE
                            records = self.fetchall(sql)
                        else:
                            records = []

                        found = []
                        not_found = []

                        if len(records) == 0:
                            if os.path.exists(tmpfilename3):
                                os.remove(tmpfilename3)
                                self._logger.info("DB Upgradation: temp-file deleted %s", tmpfilename3)

                            self.database_update.release()
                            return

                        for infohash, torrent_filename in records:
                            if not os.path.isfile(torrent_filename):
                                torrent_filename = os.path.join(torrent_dir, torrent_filename)

                            # .torrent found, return complete filename
                            if not os.path.isfile(torrent_filename):
                                # .torrent not found, use default collected_torrent_filename
                                torrent_filename = get_collected_torrent_filename(str2bin(infohash))
                                torrent_filename = os.path.join(torrent_dir, torrent_filename)

                            if not os.path.isfile(torrent_filename):
                                not_found.append((infohash,))
                            else:
                                sdef, swiftpath = rth._move_to_collected(torrent_filename)
                                found.append((bin2str(sdef.get_roothash()), swiftpath, infohash))

                                os.remove(torrent_filename)

                        update = "UPDATE Torrent SET swift_torrent_hash = ?, torrent_file_name = ? WHERE infohash = ?"
                        self.executemany(update, found)

                        remove = "UPDATE Torrent SET torrent_file_name = NULL WHERE infohash = ?"
                        self.executemany(remove, not_found)

                # upgradation not yet complete; comeback after 5 sec
                tqueue.add_task(upgradeTorrents3, SUCCESIVE_UPGRADE_PAUSE)

            # start the upgradation after 10 seconds
            if not tqueue:
                tqueue = TimedTaskQueue("UpgradeDB")
                tqueue.add_task(kill_threadqueue_if_empty, INITIAL_UPGRADE_PAUSE + 1, "kill_if_empty")
            tqueue.add_task(upgradeTorrents3, INITIAL_UPGRADE_PAUSE)

        # Arno, 2012-07-30: Speed up
        if fromver < 15:
            self.database_update.acquire()

            self.execute_write("UPDATE Torrent SET swift_hash = NULL WHERE swift_hash = '' OR swift_hash = 'None'")
            duplicates = [(id_,) for id_, count in self.execute_read("SELECT torrent_id, count(*) FROM Torrent WHERE swift_hash NOT NULL GROUP BY swift_hash") if count > 1]
            if duplicates:
                self.executemany("UPDATE Torrent SET swift_hash = NULL WHERE torrent_id = ?", duplicates)
            self.execute_write("CREATE UNIQUE INDEX IF NOT EXISTS Torrent_swift_hash_idx ON Torrent(swift_hash)")

            self.execute_write("UPDATE Torrent SET swift_torrent_hash = NULL WHERE swift_torrent_hash = '' OR swift_torrent_hash = 'None'")
            duplicates = [(id_,) for id_, count in self.execute_read("SELECT torrent_id, count(*) FROM Torrent WHERE swift_torrent_hash NOT NULL GROUP BY swift_torrent_hash") if count > 1]
            if duplicates:
                self.executemany("UPDATE Torrent SET swift_torrent_hash = NULL WHERE torrent_id = ?", duplicates)
            self.execute_write("CREATE UNIQUE INDEX IF NOT EXISTS Torrent_swift_torrent_hash_idx ON Torrent(swift_torrent_hash)")

            self.database_update.release()

        # 02/08/2012 Boudewijn: the code allowed swift_torrent_hash to be an empty string
        if fromver < 16:
            self.database_update.acquire()

            self.execute_write("UPDATE Torrent SET swift_torrent_hash = NULL WHERE swift_torrent_hash = '' OR swift_torrent_hash = 'None'")

            self.database_update.release()

        if fromver < 17:
            self.database_update.acquire()

            self.execute_write("DROP TABLE IF EXISTS PREFERENCE")
            self.execute_write("DROP INDEX IF EXISTS Preference_peer_id_idx")
            self.execute_write("DROP INDEX IF EXISTS Preference_torrent_id_idx")
            self.execute_write("DROP INDEX IF EXISTS pref_idx")

            self.execute_write("DROP TABLE IF EXISTS Popularity")
            self.execute_write("DROP INDEX IF EXISTS Popularity_idx")

            self.execute_write("DROP TABLE IF EXISTS Metadata")
            self.execute_write("DROP INDEX IF EXISTS infohash_md_idx")
            self.execute_write("DROP INDEX IF EXISTS pub_md_idx")

            self.execute_write("DROP TABLE IF EXISTS Subtitles")
            self.execute_write("DROP INDEX IF EXISTS metadata_sub_idx")

            self.execute_write("DROP TABLE IF EXISTS SubtitlesHave")
            self.execute_write("DROP INDEX IF EXISTS subtitles_have_idx")
            self.execute_write("DROP INDEX IF EXISTS subtitles_have_ts")

            update = list(self.execute_read("SELECT peer_id, torrent_id, term_id, term_order FROM ClicklogSearch"))
            results = self.execute_read("SELECT ClicklogTerm.term_id, TermFrequency.term_id FROM TermFrequency, ClicklogTerm WHERE TermFrequency.term == ClicklogTerm.term")
            updateDict = {}
            for old_termid, new_termid in results:
                updateDict[old_termid] = new_termid

            self.execute_write("DELETE FROM ClicklogSearch")
            for peer_id, torrent_id, term_id, term_order in update:
                if term_id in updateDict:
                    self.execute_write("INSERT INTO ClicklogSearch (peer_id, torrent_id, term_id, term_order) VALUES (?,?,?,?)", (peer_id, torrent_id, updateDict[term_id], term_order))

            self.execute_write("DROP TABLE IF EXISTS ClicklogTerm")
            self.execute_write("DROP INDEX IF EXISTS idx_terms_term")

            self.execute_write("DELETE FROM Peer WHERE superpeer = 1")
            self.execute_write("DROP VIEW IF EXISTS SuperPeer")

            self.execute_write("DROP INDEX IF EXISTS Peer_name_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_ip_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_similarity_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_last_seen_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_last_connected_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_num_peers_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_num_torrents_idx")
            self.execute_write("DROP INDEX IF EXISTS Peer_local_oversion_idx")
            self.execute_write("DROP INDEX IF EXISTS Torrent_creation_date_idx")
            self.execute_write("DROP INDEX IF EXISTS Torrent_relevance_idx")
            self.execute_write("DROP INDEX IF EXISTS Torrent_name_idx")

            self.database_update.release()

        if fromver < 18:
            self.database_update.acquire()

            self.execute_write("DROP TABLE IF EXISTS BarterCast")
            self.execute_write("DROP INDEX IF EXISTS bartercast_idx")
            self.execute_write("INSERT INTO MetaDataTypes ('name') VALUES ('swift-thumbnails')")
            self.execute_write("INSERT INTO MetaDataTypes ('name') VALUES ('video-info')")

            self.database_update.release()

        tmpfilename4 = os.path.join(state_dir, "upgradingdb4.txt")
        if fromver < 19 or os.path.exists(tmpfilename4):
            self.database_update.acquire()

            all_found_tracker_dict = dict()
            def getTrackerID(tracker):
                sql = 'SELECT tracker_id FROM TrackerInfo WHERE tracker = ?'
                return self.fetchone(sql, [tracker, ])

            # only perform these changes once
            if fromver < 19:
                # Niels: removing unique clause from swift_hash
                # single file torrents with the same content but different filenames will cause the swift_hash to be equal
                # while the infohash is not
                self.execute_write("DROP INDEX IF EXISTS Torrent_swift_hash_idx")

                from Tribler.TrackerChecking.TrackerUtility import getUniformedURL

                self.execute_write('BEGIN')

                # drop Peer columns
                drop_table = "DROP VIEW Friend"
                self.execute_write(drop_table)

                rename_table = "ALTER TABLE Peer RENAME TO __Peer_tmp"
                self.execute_write(rename_table)

                improved_peer_table = """
                CREATE TABLE Peer (
                    peer_id    integer PRIMARY KEY AUTOINCREMENT NOT NULL,
                    permid     text NOT NULL,
                    name       text,
                    thumbnail  text
                );"""
                self.execute_write(improved_peer_table)

                copy_data = """
                INSERT INTO Peer (peer_id, permid, name, thumbnail)
                SELECT peer_id, permid, name, thumbnail FROM __Peer_tmp
                """
                self.execute_write(copy_data)

                drop_table = "DROP TABLE __Peer_tmp"
                self.execute_write(drop_table)

                # new columns in Torrent table
                self.execute_write(
                    "ALTER TABLE Torrent ADD COLUMN last_tracker_check integer DEFAULT 0")
                self.execute_write(
                    "ALTER TABLE Torrent ADD COLUMN tracker_check_retries integer DEFAULT 0")
                self.execute_write(
                    "ALTER TABLE Torrent ADD COLUMN next_tracker_check integer DEFAULT 0")

                create_new_table = """
                    CREATE TABLE TrackerInfo (
                      tracker_id  integer PRIMARY KEY AUTOINCREMENT,
                      tracker     text    UNIQUE NOT NULL,
                      last_check  numeric DEFAULT 0,
                      failures    integer DEFAULT 0,
                      is_alive    integer DEFAULT 1
                    );"""
                self.execute_write(create_new_table)

                create_new_table = """
                    CREATE TABLE TorrentTrackerMapping (
                      torrent_id  integer NOT NULL,
                      tracker_id  integer NOT NULL,
                      FOREIGN KEY (torrent_id) REFERENCES Torrent(torrent_id),
                      FOREIGN KEY (tracker_id) REFERENCES TrackerInfo(tracker_id),
                      PRIMARY KEY (torrent_id, tracker_id)
                    );"""
                self.execute_write(create_new_table)

                insert_dht_tracker = 'INSERT INTO TrackerInfo(tracker) VALUES(?)'
                default_tracker_list = [ ('no-DHT',), ('DHT',) ]
                self.executemany(insert_dht_tracker, default_tracker_list)

                self._logger.info('Importing information from TorrentTracker ...')
                sql = 'SELECT torrent_id, tracker FROM TorrentTracker'\
                    + ' WHERE torrent_id NOT IN (SELECT torrent_id FROM CollectedTorrent)'

                insert_tracker_set = set()
                insert_mapping_set = set()
                try:
                    raw_mapping_cur = self.execute_read(sql)
                    for torrent_id, tracker in raw_mapping_cur:
                        tracker_url = getUniformedURL(tracker)
                        if tracker_url:
                            insert_tracker_set.add((tracker_url,))
                            insert_mapping_set.add((torrent_id, tracker_url))

                except Exception as e:
                    self._logger.error('fetching tracker from TorrentTracker %s', e)

                insert = 'INSERT INTO TrackerInfo(tracker) VALUES(?)'
                self.executemany(insert, list(insert_tracker_set))

                # get tracker IDs
                for tracker, in insert_tracker_set:
                    all_found_tracker_dict[tracker] = getTrackerID(tracker)

                # insert mapping
                mapping_set = set()
                for torrent_id, tracker in insert_mapping_set:
                    mapping_set.add((torrent_id, all_found_tracker_dict[tracker]))

                insert = 'INSERT OR IGNORE INTO TorrentTrackerMapping(torrent_id, tracker_id) VALUES(?, ?)'
                self.executemany(insert, list(mapping_set))

                self.execute_write('DROP TABLE IF EXISTS TorrentTracker')

                self.execute_write('COMMIT')

            all_found_tracker_dict['no-DHT'] = getTrackerID('no-DHT')
            all_found_tracker_dict['DHT'] = getTrackerID('DHT')

            # ensure the temp-file is created, if it is not already
            try:
                open(tmpfilename4, "w")
                self._logger.info("DB v19 Upgradation: temp-file successfully created %s", tmpfilename4)
            except:
                self._logger.error("DB v19 Upgradation: failed to create temp-file %s", tmpfilename4)

            from Tribler.TrackerChecking.TrackerUtility import getUniformedURL
            from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue
            from Tribler.Core.TorrentDef import TorrentDef

            def upgradeDBV19():
                if not (os.path.exists(tmpfilename3) or os.path.exists(tmpfilename2) or os.path.exists(tmpfilename)):
                    self._logger.info('Upgrading DB to v19 ...')

                    if not TEST_OVERRIDE:
                        self._logger.info('Importing information from CollectedTorrent ...')
                        sql = 'SELECT torrent_id, infohash, torrent_file_name FROM CollectedTorrent'\
                            + ' WHERE torrent_id NOT IN (SELECT torrent_id FROM TorrentTrackerMapping)'\
                            + ' AND torrent_file_name IS NOT NULL'\
                            + ' LIMIT %d' % UPGRADE_BATCH_SIZE

                        records = self.fetchall(sql)
                    else:
                        records = None

                    if not records:
                        self.execute_write('DROP TABLE IF EXISTS TorrentTracker')
                        self.execute_write('DROP INDEX IF EXISTS torrent_tracker_idx')
                        self.execute_write('DROP INDEX IF EXISTS torrent_tracker_last_idx')

                        if os.path.exists(tmpfilename4):
                            os.remove(tmpfilename4)
                            self._logger.info('DB v19 Upgrade: temp-file deleted %s', tmpfilename4)

                        self._logger.info('DB v19 upgrade complete.')
                        self.database_update.release()
                        return

                    found_torrent_tracker_map_set = set()
                    newly_found_tracker_set = set()
                    not_found_torrent_file_set = set()
                    update_secret_set = set()

                    for torrent_id, infohash, torrent_filename in records:
                        if not os.path.isfile(torrent_filename):
                            torrent_filename = os.path.join(torrent_dir, torrent_filename)

                        # .torrent found, return complete filename
                        if not os.path.isfile(torrent_filename):
                            # .torrent not found, use default collected_torrent_filename
                            torrent_filename = get_collected_torrent_filename(str2bin(infohash))
                            torrent_filename = os.path.join(torrent_dir, torrent_filename)

                        if os.path.isfile(torrent_filename):
                            try:
                                torrent = TorrentDef.load(torrent_filename)

                                # check DHT
                                if torrent.is_private():
                                    found_torrent_tracker_map_set.add((torrent_id, 'no-DHT'))
                                    update_secret_set.add((1, torrent_id))
                                else:
                                    found_torrent_tracker_map_set.add((torrent_id, 'DHT'))
                                    update_secret_set.add((0, torrent_id))

                                # check trackers
                                tracker_tuple = torrent.get_trackers_as_single_tuple()
                                for tracker in tracker_tuple:
                                    tracker_url = getUniformedURL(tracker)
                                    if tracker_url:
                                        if tracker_url not in all_found_tracker_dict:
                                            newly_found_tracker_set.add((tracker_url,))
                                        found_torrent_tracker_map_set.add((torrent_id, tracker_url))

                                else:
                                    not_found_torrent_file_set.add((torrent_id,))

                            except ValueError:
                                not_found_torrent_file_set.add((torrent_id,))

                        else:
                            not_found_torrent_file_set.add((torrent_id,))

                    if not_found_torrent_file_set:
                        remove = 'UPDATE Torrent SET torrent_file_name = NULL WHERE torrent_id = ?'
                        self.executemany(remove, list(not_found_torrent_file_set))

                    if update_secret_set:
                        update_secret = 'UPDATE Torrent SET secret = ? WHERE torrent_id = ?'
                        self.executemany(update_secret, list(update_secret_set))

                    if newly_found_tracker_set:
                        insert = 'INSERT OR IGNORE INTO TrackerInfo(tracker) VALUES(?)'
                        self.executemany(insert, list(newly_found_tracker_set))

                        from Tribler.Core.CacheDB.Notifier import Notifier, NTFY_TRACKERINFO, NTFY_INSERT
                        notifier = Notifier.getInstance()
                        notifier.notify(NTFY_TRACKERINFO, NTFY_INSERT, list(newly_found_tracker_set))

                    # load tracker dictionary
                    for tracker, in newly_found_tracker_set:
                        all_found_tracker_dict[tracker] = getTrackerID(tracker)

                    if found_torrent_tracker_map_set:
                        insert_list = list()
                        for torrent_id, tracker in found_torrent_tracker_map_set:
                            insert_list.append((torrent_id, all_found_tracker_dict[tracker]))
                        insert = 'INSERT OR IGNORE INTO TorrentTrackerMapping(torrent_id, tracker_id)'\
                            + ' VALUES(?, ?)'
                        self.executemany(insert, insert_list)

                # upgradation not yet complete; comeback after 5 sec
                tqueue.add_task(upgradeDBV19, SUCCESIVE_UPGRADE_PAUSE)

            # start the upgradation after 10 seconds
            if not tqueue:
                tqueue = TimedTaskQueue('UpgradeDB')
                tqueue.add_task(kill_threadqueue_if_empty, INITIAL_UPGRADE_PAUSE + 1, 'kill_if_empty')
            tqueue.add_task(upgradeDBV19, INITIAL_UPGRADE_PAUSE)

        if fromver < 21:
            self.database_update.acquire()
            self.execute_write("DROP INDEX IF EXISTS torrent_biterm_phrase_idx")
            self.execute_write("DROP TABLE IF EXISTS TorrentBiTermPhrase")
            self.execute_write("DROP INDEX IF EXISTS termfrequency_freq_idx")
            self.execute_write("DROP TABLE IF EXISTS TermFrequency")
            self.execute_write("DROP INDEX IF EXISTS Torrent_insert_idx")
            self.execute_write("DROP INDEX IF EXISTS Torrent_info_roothash_idx")
            self.database_update.release()

        if fromver < 22:
            self.database_update.acquire()
            self.execute_write("DROP TABLE IF EXISTS ClicklogSearch")
            self.execute_write("DROP INDEX IF EXISTS idx_search_term")
            self.execute_write("DROP INDEX IF EXISTS idx_search_torrent")
            self.database_update.release()

    def clean_db(self, vacuum=False):
        self.execute_write("DELETE FROM TorrentFiles where torrent_id in (select torrent_id from CollectedTorrent)")
        self.execute_write("DELETE FROM Torrent where name is NULL and torrent_id not in (select torrent_id from _ChannelTorrents)")

        if vacuum:
            self.execute_read("VACUUM")

_shouldCommit = False

def onDBThread():
    return isInIOThread()


def forceDBThread(func):
    def invoke_func(*args, **kwargs):
        if not onDBThread():
            if TRHEADING_DEBUG:
                stack = inspect.stack()
                callerstr = ""
                for i in range(1, min(10, len(stack))):
                    caller = stack[i]
                    callerstr += "%s %s:%s " % (caller[3], caller[1], caller[2])
                logger.info("%d SWITCHING TO DBTHREAD %s %s:%s called by %s", long(time()), func.__name__, func.func_code.co_filename, func.func_code.co_firstlineno, callerstr)

            reactor.callFromThread(func, *args, **kwargs)
        else:
            func(*args, **kwargs)

    invoke_func.__name__ = func.__name__
    return invoke_func

def forceAndReturnDBThread(func):
    def invoke_func(*args, **kwargs):
        if not onDBThread():
            if TRHEADING_DEBUG:
                stack = inspect.stack()
                callerstr = ""
                for i in range(1, min(10, len(stack))):
                    caller = stack[i]
                    callerstr += "%s %s:%s" % (caller[3], caller[1], caller[2])
                logger.error("%d BLOCKING ON DBTHREAD %s %s:%s called by %s", long(time()), func.__name__, func.func_code.co_filename, func.func_code.co_firstlineno, callerstr)

            return blockingCallFromThread(reactor, func, *args, **kwargs)
        else:
            return func(*args, **kwargs)

    invoke_func.__name__ = func.__name__
    return invoke_func


class SQLiteNoCacheDB(SQLiteCacheDBV5):

    def __init__(self, *args, **kargs):
        SQLiteCacheDBBase.__init__(self, *args, **kargs)

    @forceDBThread
    def initialBegin(self):
        global _shouldCommit
        try:
            self._logger.info("SQLiteNoCacheDB.initialBegin: BEGIN")
            self._execute("BEGIN;")

        except:
            self._logger.exception("INITIAL BEGIN FAILED")
            raise
        _shouldCommit = False

    @forceDBThread
    def commitNow(self, vacuum=False, exiting=False):
        global _shouldCommit
        if _shouldCommit and onDBThread():
            try:
                self._logger.info("SQLiteNoCacheDB.commitNow: COMMIT")
                self._execute("COMMIT;")
            except:
                self._logger.exception("COMMIT FAILED")
                raise
            _shouldCommit = False

            if vacuum:
                self._execute("VACUUM;")

            if not exiting:
                try:
                    self._logger.info("SQLiteNoCacheDB.commitNow: BEGIN")
                    self._execute("BEGIN;")
                except:
                    self._logger.exception("BEGIN FAILED")
                    raise
            else:
                self._logger.info("SQLiteNoCacheDB.commitNow: not calling BEGIN exiting")

        elif vacuum:
            self._execute("VACUUM;")

    def execute_write(self, sql, args=None):
        global _shouldCommit
        if not _shouldCommit:
            _shouldCommit = True

        self._execute(sql, args)

    def executemany(self, sql, args):
        global _shouldCommit
        if not _shouldCommit:
            _shouldCommit = True

        return self._executemany(sql, args)

    def clean_db(self, vacuum=False, exiting=False):
        SQLiteCacheDBV5.clean_db(self, False)

        if vacuum:
            self.commitNow(vacuum, exiting=exiting)

    @forceAndReturnDBThread
    def fetchone(self, sql, args=None):
        return SQLiteCacheDBV5.fetchone(self, sql, args)

    @forceAndReturnDBThread
    def fetchall(self, sql, args=None):
        return SQLiteCacheDBV5.fetchall(self, sql, args)

    @forceAndReturnDBThread
    def _execute(self, sql, args=None):
        cur = self.getCursor()

        if self.show_execute:
            thread_name = threading.currentThread().getName()
            self._logger.info('===%s===\n%s\n-----\n%s\n======\n', thread_name, sql, args)

        try:
            if args is None:
                result = cur.execute(sql)
            else:
                result = cur.execute(sql, args)

            return result

        except Exception as msg:
            thread_name = threading.currentThread().getName()
            self._logger.exception('===%s===\nSQL Type: %s\n-----\n%s\n-----\n%s\n======\n', thread_name, type(sql), sql, args)
            raise msg

    @forceAndReturnDBThread
    def _executemany(self, sql, args=None):
        cur = self.getCursor()

        if self.show_execute:
            thread_name = threading.currentThread().getName()
            self._logger.info('===%s===\n%s\n-----\n%s\n======\n', thread_name, sql, args)

        try:
            if args is None:
                result = cur.executemany(sql)
            else:
                result = cur.executemany(sql, args)

            return result

        except Exception as msg:
            thread_name = threading.currentThread().getName()
            self._logger.exception('===%s===\nSQL Type: %s\n-----\n%s\n-----\n%s\n======\n', thread_name, type(sql), sql, args)
            raise msg

    @forceAndReturnDBThread
    def createDBTable(self, *argv, **kwargs):
        return SQLiteCacheDBV5.createDBTable(self, *argv, **kwargs)

# Arno, 2012-08-02: If this becomes multithreaded again, reinstate safe_dict() in caches


class SQLiteCacheDB(SQLiteNoCacheDB):
    __single = None  # used for multithreaded singletons pattern

    def __init__(self, *args, **kargs):
        # always use getInstance() to create this object
        if self.__single != None:
            raise RuntimeError("SQLiteCacheDB is singleton")
        SQLiteNoCacheDB.__init__(self, *args, **kargs)
        self._pending_tasks = []

    @classmethod
    def getInstance(cls, *args, **kw):
        # Singleton pattern with double-checking to ensure that it can only create one object
        if cls.__single is None:
            cls.lock.acquire()
            try:
                if cls.__single is None:
                    cls.__single = cls(*args, **kw)
                    # print >>sys.stderr,"SqliteCacheDB: getInstance: created is",cls,cls.__single
            finally:
                cls.lock.release()
        return cls.__single

    @classmethod
    def delInstance(cls, *args, **kw):
        for task in cls.__single._pending_tasks:
            if task.active():
                task.cancel()
        cls.__single = None

    @classmethod
    def hasInstance(cls, *args, **kw):
        return cls.__single != None

    @forceDBThread
    def schedule_task(self, task, delay=0.0):
        self._pending_tasks.append(reactor.callLater(delay, task))

########NEW FILE########
__FILENAME__ = SqliteCacheDBHandler
# Written by Jie Yang
# Modified by George Milescu
# see LICENSE.txt for license information
# Note for Developers: Please write a unittest in Tribler/Test/test_sqlitecachedbhandler.py
# for any function you add to database.
# Please reuse the functions in sqlitecachedb as much as possible
import binascii
import logging
import os
import threading
import urllib
from binascii import hexlify
from copy import deepcopy
from random import sample
from struct import unpack_from
from threading import RLock, Lock
from time import time
from traceback import print_exc

from twisted.internet.base import DelayedCall
from twisted.internet.defer import Deferred
from twisted.internet.task import LoopingCall

from Notifier import Notifier
from Tribler.Category.Category import Category
from Tribler.Core.CacheDB.sqlitecachedb import SQLiteCacheDB, bin2str, str2bin
from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler
from Tribler.Core.Search.SearchManager import split_into_keywords, filter_keywords
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Utilities.unicode import dunno2unicode
from Tribler.Core.simpledefs import (INFOHASH_LENGTH, NTFY_PEERS, NTFY_UPDATE, NTFY_INSERT, NTFY_DELETE, NTFY_CREATE,
                                     NTFY_MODIFIED, NTFY_TRACKERINFO, NTFY_MYPREFERENCES, NTFY_VOTECAST, NTFY_TORRENTS,
                                     NTFY_CHANNELCAST, NTFY_COMMENTS, NTFY_PLAYLISTS, NTFY_MODIFICATIONS,
                                     NTFY_MODERATIONS, NTFY_MARKINGS, NTFY_STATE)


try:
    # python 2.7 only...
    from collections import OrderedDict
except ImportError:
    from Tribler.dispersy.python27_ordereddict import OrderedDict

try:
    WindowsError
except NameError:
    WindowsError = Exception

SHOW_ERROR = False

MAX_KEYWORDS_STORED = 5
MAX_KEYWORD_LENGTH = 50

# Rahim:
MAX_POPULARITY_REC_PER_TORRENT = 5  # maximum number of records in popularity table for each torrent
MAX_POPULARITY_REC_PER_TORRENT_PEER = 3  # maximum number of records per each combination of torrent and peer


DEFAULT_ID_CACHE_SIZE = 1024 * 5

class LimitedOrderedDict(OrderedDict):

    def __init__(self, limit, *args, **kargs):
        super(LimitedOrderedDict, self).__init__(*args, **kargs)
        self._limit = limit

    def __setitem__(self, *args, **kargs):
        super(LimitedOrderedDict, self).__setitem__(*args, **kargs)
        if len(self) > self._limit:
            self.popitem(last=False)


class BasicDBHandler:
    _singleton_lock = RLock()
    _single = None

    def __init__(self, db, table_name):  # # self, table_name
        self._logger = logging.getLogger(self.__class__.__name__)

        self._db = db  # # SQLiteCacheDB.getInstance()
        self.table_name = table_name
        self.notifier = Notifier.getInstance()

        self._pending_tasks = {}

    @classmethod
    def getInstance(cls, *args, **kargs):
        with cls._singleton_lock:
            if not cls._single:
                cls._single = cls(*args, **kargs)
            return cls._single

    @classmethod
    def delInstance(cls):
        if cls._single:
            # cancel all pending tasks
            for key in cls._single._pending_tasks.keys():
                cls._single.cancel_pending_task(key)
                cls._single._pending_tasks.clear()
        with cls._singleton_lock:
            cls._single = None

    @classmethod
    def hasInstance(cls):
        return cls._single != None

    def close(self):
        # cancel all pending tasks
        for key in self._pending_tasks.keys():
            self.cancel_pending_task(key)
        self._pending_tasks.clear()

        try:
            self._db.close()
        except:
            if SHOW_ERROR:
                print_exc()

    def cancel_pending_task(self, key):
        task = self._pending_tasks.pop(key)
        if isinstance(task, Deferred) and not task.called:
            # Have in mind that any deferred in the pending tasks list should have been constructed with a
            # canceller function.
            task.cancel()
        elif isinstance(task, DelayedCall) and task.active():
            task.cancel()
        elif isinstance(task, LoopingCall) and task.running:
            task.stop()

    def size(self):
        return self._db.size(self.table_name)

    def getOne(self, value_name, where=None, conj='and', **kw):
        return self._db.getOne(self.table_name, value_name, where=where, conj=conj, **kw)

    def getAll(self, value_name, where=None, group_by=None, having=None, order_by=None, limit=None, offset=None, conj='and', **kw):
        return self._db.getAll(self.table_name, value_name, where=where, group_by=group_by, having=having, order_by=order_by, limit=limit, offset=offset, conj=conj, **kw)


class MiscDBHandler(BasicDBHandler):

    def __init__(self):
        if MiscDBHandler._single:
            raise RuntimeError("MiscDBHandler is singleton")
        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, None)

        self.initialize()

    def initialize(self):
        # initialize TorrentStatus name-ID tables
        self._torrent_status_name2id_dict = {u'unknown': 0, u'good': 1, u'dead': 2}
        sql = u'SELECT LOWER(name), status_id FROM TorrentStatus'
        st = self._db.fetchall(sql)
        self._torrent_status_name2id_dict.update(dict(st))

        self._torrent_status_id2name_dict = \
            dict([(x, y) for (y, x) in self._torrent_status_name2id_dict.iteritems()])
        self._torrent_status_id2name_dict[None] = 'unknown'

        # initialize Category name-ID tables
        self._category_name2id_dict = { u'Video': 1, u'VideoClips': 2,
            u'Audio': 3, u'Compressed': 4, u'Document': 5,
            u'Picture': 6, u'xxx': 7, u'other': 8, }
        sql = u'SELECT LOWER(name), category_id FROM Category'
        ct = self._db.fetchall(sql)
        self._category_name2id_dict.update(dict(ct))
        self._category_name2id_dict[u'unknown'] = 0

        self._category_id2name_dict = \
            dict([(x, y) for (y, x) in self._category_name2id_dict.iteritems()])
        self._category_id2name_dict[None] = u'unknown'

        # initialize TorrentSource name-ID tables
        sql = u'SELECT name, source_id FROM TorrentSource'
        st = self._db.fetchall(sql)
        self._torrent_source_name2id_dict = dict(st)
        self._torrent_source_id2name_dict = \
            dict([(x, y) for (y, x) in self._torrent_source_name2id_dict.iteritems()])
        self._torrent_source_id2name_dict[None] = u'unknown'

    def torrentStatusName2Id(self, status_name):
        return self._torrent_status_name2id_dict.get(status_name.lower(), 0)

    def torrentStatusId2Name(self, status_id):
        return self._torrent_status_id2name_dict.get(status_id, None)

    def categoryName2Id(self, category_name):
        category_id = 0
        if category_name is not None and len(category_name) > 0:
            category = category_name[0].lower()
            category_id = self._category_name2id_dict[category]
        return category_id

    def categoryId2Name(self, category_id):
        return self._category_id2name_dict[category_id]

    def torrentSourceName2Id(self, source_name):
        if source_name in self._torrent_source_name2id_dict:
            source_id = self._torrent_source_name2id_dict[source_name]
        else:
            source_id = self._addSource(source_name)
            self._torrent_source_name2id_dict[source_name] = source_id
            self._torrent_source_id2name_dict[source_id] = source_name
        return source_id

    def torrentSourceId2Name(self, source_id):
        return self._torrent_source_id2name_dict.get(source_id, None)

    def _addSource(self, source):
        desc = u''
        if source.startswith('http') and source.endswith('xml'):
            desc = u'RSS'
        self._db.insert(u'TorrentSource', name=source, description=desc)
        source_id = self._db.getOne(u'TorrentSource', u'source_id', name=source)
        return source_id


class MetadataDBHandler(BasicDBHandler):

    def __init__(self):
        if MetadataDBHandler._single:
            raise RuntimeError("MetadataDBHandler is singleton")
        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, None)
        self.category = Category.getInstance()
        self.misc_db = MiscDBHandler.getInstance()
        self.torrent_db = TorrentDBHandler.getInstance()

    def getMetadataMessageList(self, infohash, roothash, columns):
        """
        Gets a list of metadata messages with the given hash-type and
        hash-value.
        """
        infohash_str = bin2str(infohash) if infohash else None
        roothash_str = bin2str(roothash) if roothash else None

        column_str = ",".join(columns)
        sql = "SELECT %s FROM MetadataMessage WHERE infohash = ? OR roothash = ?" % column_str
        raw_result_list = self._db.fetchall(sql, (infohash_str, roothash_str))

        processed_result_list = []
        if raw_result_list:
            for raw_result in raw_result_list:
                this_result = []

                for idx, column in enumerate(columns):
                    if raw_result[idx] == None:
                        this_result.append(None)

                    elif column == "infohash":
                        this_result.append(str2bin(raw_result[idx]))
                    elif column == "roothash":
                        this_result.append(str2bin(raw_result[idx]))
                    elif column == "this_mid":
                        this_result.append(str(raw_result[idx]))
                    elif column == "previous_mid":
                        this_result.append(str(raw_result[idx]))
                    else:
                        this_result.append(raw_result[idx])

                processed_result_list.append(tuple(this_result))

        return processed_result_list

    def addAndGetIDMetadataMessage(self, dispersy_id, this_global_time, this_mid,
            infohash, roothash, prev_mid=None, prev_global_time=None):
        """
        Adds a Metadata message and get its message ID.
        """
        this_mid_str = buffer(this_mid) if this_mid else None
        prev_mid_str = buffer(prev_mid) if prev_mid else None

        infohash_str = bin2str(infohash) if infohash else None
        roothash_str = bin2str(roothash) if roothash else None

        sql = """INSERT INTO MetadataMessage(dispersy_id, this_global_time,
                this_mid, infohash, roothash, previous_mid, previous_global_time)
            VALUES(?, ?, ?, ?, ?, ?, ?);
            SELECT last_insert_rowid();
        """
        values = (dispersy_id, this_global_time, this_mid_str,
            infohash_str, roothash_str,
            prev_mid_str, prev_global_time)

        result = self._db.fetchone(sql, values)
        self.notifier.notify(NTFY_TORRENTS, NTFY_UPDATE, infohash)
        return result

    def addMetadataDataInBatch(self, value_tuple_list):
        """
        Adds metadata data in batch.
        """
        sql = "INSERT INTO MetadataData(message_id, data_key, data_value) VALUES(?, ?, ?)"
        self._db.executemany(sql, value_tuple_list)

    def deleteMetadataMessage(self, dispersy_id):
        sql = "DELETE FROM MetadataMessage WHERE dispersy_id = ?"
        self._db.execute_write(sql, (dispersy_id,))

    def getMetdataDateByInfohash(self, infohash):
        sql = """
        SELECT data.data_key, data.data_value
        FROM MetadataMessage as msg, MetadataData as data
        WHERE msg.infohash = ? AND msg.message_id = data.message_id
        """
        result = self._db.fetchall(sql, (bin2str(infohash),))
        return result

    def getMetadataData(self, message_id):
        sql = "SELECT data_key, data_value FROM MetadataData WHERE message_id = ?"
        result = self._db.fetchall(sql, (message_id,))
        return result

    def getThumbnailTorrents(self, keys, limit=20):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, MetadataData, MetadataMessage WHERE MetadataData.message_id = MetadataMessage.message_id AND MetadataMessage.infohash = Torrent.infohash AND data_key='swift-thumbs' AND Torrent.name <> '' AND Torrent.name IS NOT NULL " + self.category.get_family_filter_sql(self.misc_db.categoryName2Id) + " ORDER BY this_global_time DESC LIMIT ?"
        results = self._db.fetchall(sql, (limit,)) or []
        for key_index, key in enumerate(keys):
            if key.endswith('hash'):
                for i in range(len(results)):
                    result = list(results[i])
                    if result[key_index]:
                        result[key_index] = str2bin(result[key_index])
                        results[i] = result
        return results

class PeerDBHandler(BasicDBHandler):

    def __init__(self):
        if PeerDBHandler._single:
            raise RuntimeError("PeerDBHandler is singleton")
        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, 'Peer')

        self.permid_id = LimitedOrderedDict(DEFAULT_ID_CACHE_SIZE)

    def __len__(self):
        return self.size()

    def getPeerID(self, permid):
        return self.getPeerIDS([permid, ])[0]

    def getPeerIDS(self, permids):
        to_select = []

        for permid in permids:
            assert isinstance(permid, str), permid

            if permid not in self.permid_id:
                to_select.append(bin2str(permid))

        if len(to_select) > 0:
            parameters = ", ".join('?' * len(to_select))
            sql_get_peer_ids = "SELECT peer_id, permid FROM Peer WHERE permid IN (" + parameters + ")"
            peerids = self._db.fetchall(sql_get_peer_ids, to_select)
            for peer_id, permid in peerids:
                self.permid_id[str2bin(permid)] = peer_id

        to_return = []
        for permid in permids:
            if permid in self.permid_id:
                to_return.append(self.permid_id[permid])
            else:
                to_return.append(None)
        return to_return

    def addOrGetPeerID(self, permid):
        peer_id = self.getPeerID(permid)
        if peer_id is None:
            self.addPeer(permid, {})
            peer_id = self.getPeerID(permid)

        return peer_id

    def getPeer(self, permid, keys=None):
        if keys is not None:
            res = self.getOne(keys, permid=bin2str(permid))
            return res
        else:
            # return a dictionary
            # make it compatible for calls to old bsddb interface
            value_name = (u'peer_id', u'permid', u'name')

            item = self.getOne(value_name, permid=bin2str(permid))
            if not item:
                return None
            peer = dict(zip(value_name, item))
            peer['permid'] = str2bin(peer['permid'])
            return peer

    def getPeerById(self, peer_id, keys=None):
        if keys is not None:
            res = self.getOne(keys, peer_id=peer_id)
            return res
        else:
            # return a dictionary
            # make it compatible for calls to old bsddb interface
            value_name = (u'peer_id', u'permid', u'name')

            item = self.getOne(value_name, peer_id=peer_id)
            if not item:
                return None
            peer = dict(zip(value_name, item))
            peer['permid'] = str2bin(peer['permid'])
            return peer

    def addPeer(self, permid, value):
        # add or update a peer
        # ARNO: AAARGGH a method that silently changes the passed value param!!!
        # Jie: deepcopy(value)?

        _permid = _last_seen = _ip = _port = None
        if 'permid' in value:
            _permid = value.pop('permid')

        peer_id = self.getPeerID(permid)
        peer_existed = False
        if 'name' in value:
            value['name'] = dunno2unicode(value['name'])
        if peer_id != None:
            peer_existed = True
            where = u'peer_id=%d' % peer_id
            self._db.update('Peer', where, **value)
        else:
            self._db.insert_or_ignore('Peer', permid=bin2str(permid), **value)

        if _permid is not None:
            value['permid'] = permid

        if peer_existed:
            self.notifier.notify(NTFY_PEERS, NTFY_UPDATE, permid)
        else:
            self.notifier.notify(NTFY_PEERS, NTFY_INSERT, permid)

    def hasPeer(self, permid, check_db=False):
        if not check_db:
            return bool(self.getPeerID(permid))
        else:
            permid_str = bin2str(permid)
            sql_get_peer_id = "SELECT peer_id FROM Peer WHERE permid==?"
            peer_id = self._db.fetchone(sql_get_peer_id, (permid_str,))
            if peer_id is None:
                return False
            else:
                return True

    def updatePeer(self, permid, **argv):
        self._db.update(self.table_name, 'permid=' + repr(bin2str(permid)), **argv)
        self.notifier.notify(NTFY_PEERS, NTFY_UPDATE, permid)

    def deletePeer(self, permid=None, peer_id=None):
        # don't delete friend of superpeers, except that force is True
        if peer_id is None:
            peer_id = self.getPeerID(permid)
        if peer_id is None:
            return

        deleted = False
        if peer_id != None:
            self._db.delete('Peer', peer_id=peer_id)
            deleted = not self.hasPeer(permid, check_db=True)
            if deleted and permid in self.permid_id:
                self.permid_id.pop(permid)

        self.notifier.notify(NTFY_PEERS, NTFY_DELETE, permid)


class TorrentDBHandler(BasicDBHandler):

    def __init__(self):
        if TorrentDBHandler._single is not None:
            raise RuntimeError("TorrentDBHandler is singleton")

        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, 'Torrent')  # # self,db,torrent

        self.torrent_dir = None

        self.keys = ['torrent_id', 'name', 'torrent_file_name',
                'length', 'creation_date', 'num_files', 'thumbnail',
                'insert_time', 'secret', 'relevance',
                'source_id', 'category_id', 'status_id',
                'num_seeders', 'num_leechers', 'comment', 'swift_hash', 'swift_torrent_hash',
                'last_tracker_check']
        self.existed_torrents = set()

        self.value_name = ['C.torrent_id', 'category_id', 'status_id', 'name', 'creation_date', 'num_files',
                      'num_leechers', 'num_seeders', 'length',
                      'secret', 'insert_time', 'source_id', 'torrent_file_name',
                      'relevance', 'infohash', 'last_tracker_check']

        self.value_name_for_channel = ['C.torrent_id', 'infohash', 'name',
                'torrent_file_name', 'length', 'creation_date', 'num_files',
                'thumbnail', 'insert_time', 'secret', 'relevance', 'source_id',
                'category_id', 'status_id', 'num_seeders', 'num_leechers', 'comment']
        self.category = Category.getInstance()

        self.misc_db = MiscDBHandler.getInstance()
        self.mypref_db = self.votecast_db = self.channelcast_db = self._rtorrent_handler = None

        self.infohash_id = LimitedOrderedDict(DEFAULT_ID_CACHE_SIZE)

    def register(self, torrent_dir):
        self.torrent_dir = torrent_dir

        self.misc_db = MiscDBHandler.getInstance()
        self.mypref_db = MyPreferenceDBHandler.getInstance()
        self.votecast_db = VoteCastDBHandler.getInstance()
        self.channelcast_db = ChannelCastDBHandler.getInstance()
        self._rtorrent_handler = RemoteTorrentHandler.getInstance()

    def getTorrentID(self, infohash):
        return self.getTorrentIDS([infohash, ])[0]

    def getTorrentIDS(self, infohashes):
        to_select = []

        for infohash in infohashes:
            assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
            assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)

            if not infohash in self.infohash_id:
                to_select.append(bin2str(infohash))

        while len(to_select) > 0:
            nrToQuery = min(len(to_select), 50)
            parameters = '?,' * nrToQuery
            sql_get_torrent_ids = "SELECT torrent_id, infohash FROM Torrent WHERE infohash IN (" + parameters[:-1] + ")"

            torrents = self._db.fetchall(sql_get_torrent_ids, to_select[:nrToQuery])
            for torrent_id, infohash in torrents:
                self.infohash_id[str2bin(infohash)] = torrent_id

            to_select = to_select[nrToQuery:]

        to_return = []
        for infohash in infohashes:
            if infohash in self.infohash_id:
                to_return.append(self.infohash_id[infohash])
            else:
                to_return.append(None)
        return to_return

    def getTorrentIDRoot(self, roothash):
        assert isinstance(roothash, str), "roothash has invalid type: %s" % type(roothash)
        assert len(roothash) == INFOHASH_LENGTH, "roothash has invalid length: %d" % len(roothash)

        sql_get_torrent_id = "SELECT torrent_id FROM Torrent WHERE swift_hash==?"
        tid = self._db.fetchone(sql_get_torrent_id, (bin2str(roothash),))
        return tid

    def getInfohash(self, torrent_id):
        sql_get_infohash = "SELECT infohash FROM Torrent WHERE torrent_id==?"
        ret = self._db.fetchone(sql_get_infohash, (torrent_id,))
        if ret:
            ret = str2bin(ret)
        return ret

    def hasTorrent(self, infohash):
        assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)
        if infohash in self.existed_torrents:  # to do: not thread safe
            return True
        infohash_str = bin2str(infohash)
        existed = self._db.getOne('CollectedTorrent', 'torrent_id', infohash=infohash_str)
        if existed is None:
            return False
        else:
            self.existed_torrents.add(infohash)
            return True

    def addExternalTorrent(self, torrentdef, source="BC", extra_info={}):
        assert isinstance(torrentdef, TorrentDef), "TORRENTDEF has invalid type: %s" % type(torrentdef)
        assert torrentdef.is_finalized(), "TORRENTDEF is not finalized"
        if torrentdef.is_finalized():
            infohash = torrentdef.get_infohash()
            if not self.hasTorrent(infohash):
                self._addTorrentToDB(torrentdef, source, extra_info)
                self.notifier.notify(NTFY_TORRENTS, NTFY_INSERT, infohash)

    def addExternalTorrentNoDef(self, infohash, name, files, trackers, timestamp, source, extra_info={}):
        if not self.hasTorrent(infohash):
            metainfo = {'info': {}, 'encoding': 'utf_8'}
            metainfo['info']['name'] = name.encode('utf_8')
            metainfo['info']['piece length'] = -1
            metainfo['info']['pieces'] = ''

            if len(files) > 1:
                files_as_dict = []
                for filename, file_lenght in files:
                    filename = filename.encode('utf_8')
                    files_as_dict.append({'path': [filename], 'length': file_lenght})
                metainfo['info']['files'] = files_as_dict

            elif len(files) == 1:
                metainfo['info']['length'] = files[0][1]
            else:
                return

            if len(trackers) > 0:
                metainfo['announce'] = trackers[0]
            else:
                metainfo['nodes'] = []

            metainfo['creation date'] = timestamp

            try:
                torrentdef = TorrentDef.load_from_dict(metainfo)
                torrentdef.infohash = infohash

                torrent_id = self._addTorrentToDB(torrentdef, source, extra_info)
                self._rtorrent_handler.notify_possible_torrent_infohash(infohash)

                insert_files = [(torrent_id, unicode(path), length) for path, length in files]
                if len(insert_files) > 0:
                    sql_insert_files = "INSERT OR IGNORE INTO TorrentFiles (torrent_id, path, length) VALUES (?,?,?)"
                    self._db.executemany(sql_insert_files, insert_files)

                magnetlink = u"magnet:?xt=urn:btih:" + hexlify(infohash)
                for tracker in trackers:
                    magnetlink += "&tr=" + urllib.quote_plus(tracker)
                insert_collecting = [(torrent_id, magnetlink)]

                if len(insert_collecting) > 0:
                    sql_insert_collecting = "INSERT OR IGNORE INTO TorrentCollecting (torrent_id, source) VALUES (?,?)"
                    self._db.executemany(sql_insert_collecting, insert_collecting)
            except:
                self._logger.error("Could not create a TorrentDef instance %s %s %s %s %s %s %s", infohash, timestamp, name, files, trackers, source, extra_info)
                print_exc()

    def addInfohash(self, infohash):
        assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)
        if self.getTorrentID(infohash) is None:
            status_id = self.misc_db.torrentStatusName2Id(u'unknown')
            self._db.insert_or_ignore('Torrent', infohash=bin2str(infohash), status_id=status_id)

    def addOrGetTorrentID(self, infohash):
        assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)

        torrent_id = self.getTorrentID(infohash)
        if torrent_id is None:
            status_id = self.misc_db.torrentStatusName2Id(u'unknown')
            self._db.insert('Torrent', infohash=bin2str(infohash), status_id=status_id)
            torrent_id = self.getTorrentID(infohash)
        return torrent_id

    def addOrGetTorrentIDRoot(self, roothash, name):
        assert isinstance(roothash, str), "roothash has invalid type: %s" % type(roothash)
        assert len(roothash) == INFOHASH_LENGTH, "roothash has invalid length: %d" % len(roothash)

        torrent_id = self.getTorrentIDRoot(roothash)
        if torrent_id is None:
            infohash = 'swift' + bin2str(roothash)[5:]
            status_id = self.misc_db.torrentStatusName2Id(u'unknown')
            self._db.insert('Torrent', infohash=infohash,
                swift_hash=bin2str(roothash), name=name, status_id=status_id)
            torrent_id = self.getTorrentIDRoot(roothash)
        return torrent_id

    def addOrGetTorrentIDS(self, infohashes):
        torrentIds, _ = self.addOrGetTorrentIDSReturn(infohashes)
        return torrentIds

    def addOrGetTorrentIDSReturn(self, infohashes):
        to_be_inserted = set()
        torrent_ids = self.getTorrentIDS(infohashes)
        for i in range(len(torrent_ids)):
            torrent_id = torrent_ids[i]
            if torrent_id is None:
                to_be_inserted.add(infohashes[i])

        status_id = self.misc_db.torrentStatusName2Id(u'unknown')
        sql = "INSERT INTO Torrent (infohash, status_id) VALUES (?, ?)"
        self._db.executemany(sql, [(bin2str(infohash), status_id) for infohash in to_be_inserted])

        torrent_ids = self.getTorrentIDS(infohashes)
        assert all(torrent_id for torrent_id in torrent_ids), torrent_ids
        return torrent_ids, to_be_inserted

    def _get_database_dict(self, torrentdef, source="BC", extra_info={}):
        assert isinstance(torrentdef, TorrentDef), "TORRENTDEF has invalid type: %s" % type(torrentdef)
        assert torrentdef.is_finalized(), "TORRENTDEF is not finalized"

        dict = {"infohash": bin2str(torrentdef.get_infohash()),
                "name": torrentdef.get_name_as_unicode(),
                "length": torrentdef.get_length(),
                "creation_date": torrentdef.get_creation_date(),
                "num_files": len(torrentdef.get_files()),
                "insert_time": long(time()),
                "secret": 1 if torrentdef.is_private() else 0,
                "relevance": 0.0,
                "source_id": self.misc_db.torrentSourceName2Id(source),
                # todo: the category_id is calculated directly from
                # torrentdef.metainfo, the category checker should use
                # the proper torrentdef api
                "category_id": self.misc_db.categoryName2Id(self.category.calculateCategory(torrentdef.metainfo, torrentdef.get_name_as_unicode())),
                "status_id": self.misc_db.torrentStatusName2Id(extra_info.get("status", "unknown")),
                "comment": torrentdef.get_comment_as_unicode()
                }

        if extra_info.get("filename", None):
            dict["torrent_file_name"] = extra_info["filename"]
        if extra_info.get("seeder", -1) != -1:
            dict["num_seeders"] = extra_info["seeder"]
        if extra_info.get("leecher", -1) != -1:
            dict["num_leechers"] = extra_info["leecher"]
        if extra_info.get('swift_hash', ''):
            dict['swift_hash'] = bin2str(extra_info['swift_hash'])
        if extra_info.get('swift_torrent_hash', ''):
            dict['swift_torrent_hash'] = bin2str(extra_info['swift_torrent_hash'])

        return dict

    def _addTorrentToDB(self, torrentdef, source, extra_info):
        assert isinstance(torrentdef, TorrentDef), "TORRENTDEF has invalid type: %s" % type(torrentdef)
        assert torrentdef.is_finalized(), "TORRENTDEF is not finalized"

        infohash = torrentdef.get_infohash()
        swarmname = torrentdef.get_name_as_unicode()
        database_dict = self._get_database_dict(torrentdef, source, extra_info)

        # see if there is already a torrent in the database with this infohash
        torrent_id = self.getTorrentID(infohash)
        if torrent_id is None:  # not in database
            self._db.insert("Torrent", **database_dict)
            torrent_id = self.getTorrentID(infohash)

        else:  # infohash in db
            del database_dict["infohash"]  # no need for infohash, its already stored
            where = "torrent_id = %d" % torrent_id
            self._db.update('Torrent', where=where, **database_dict)

        if not torrentdef.is_multifile_torrent():
            swarmname, _ = os.path.splitext(swarmname)
        self._indexTorrent(torrent_id, swarmname, torrentdef.get_files_as_unicode(), source in ['BC', 'SWIFT', 'DISP_SC'])

        self._addTorrentTracker(torrent_id, torrentdef, extra_info)
        return torrent_id

    def _indexTorrent(self, torrent_id, swarmname, files, collected):
        existed = self._db.getOne('CollectedTorrent', 'infohash', torrent_id=torrent_id)
        if existed and not collected:
            return

        # Niels: new method for indexing, replaces invertedindex
        # Making sure that swarmname does not include extension for single file torrents
        swarm_keywords = " ".join(split_into_keywords(swarmname, filterStopwords=False))

        filedict = {}
        fileextensions = set()
        for filename in files:
            filename, extension = os.path.splitext(filename)
            for keyword in split_into_keywords(filename, filterStopwords=True):
                filedict[keyword] = filedict.get(keyword, 0) + 1

            fileextensions.add(extension[1:])

        filenames = filedict.keys()
        if len(filenames) > 1000:
            def popSort(a, b):
                return filedict[a] - filedict[b]
            filenames.sort(cmp=popSort, reverse=True)
            filenames = filenames[:1000]

        values = (torrent_id, swarm_keywords, " ".join(filenames), " ".join(fileextensions))
        try:
            # INSERT OR REPLACE not working for fts3 table
            self._db.execute_write(u"DELETE FROM FullTextIndex WHERE rowid = ?", (torrent_id,))
            self._db.execute_write(u"INSERT INTO FullTextIndex (rowid, swarmname, filenames, fileextensions) VALUES(?,?,?,?)", values)
        except:
            # this will fail if the fts3 module cannot be found
            print_exc()

    # ------------------------------------------------------------
    # Adds the trackers of a given torrent into the database.
    # ------------------------------------------------------------
    def _addTorrentTracker(self, torrent_id, torrentdef, extra_info={}):
        # Set add_all to True if you want to put all multi-trackers into db.
        # In the current version (4.2) only the main tracker is used.

        announce = torrentdef.get_tracker()
        announce_list = torrentdef.get_tracker_hierarchy()

        # check if to use DHT
        new_tracker_set = set()
        if torrentdef.is_private():
            new_tracker_set.add('no-DHT')
        else:
            new_tracker_set.add('DHT')

        # get rid of junk trackers
        from Tribler.TrackerChecking.TrackerUtility import getUniformedURL
        # prepare the tracker list to add
        if announce:
            tracker_url = getUniformedURL(announce)
            if tracker_url:
                new_tracker_set.add(tracker_url)
        if announce_list:
            for tier in announce_list:
                for tracker in tier:
                    # TODO: check this. a limited tracker list
                    if len(new_tracker_set) >= 25:
                        break
                    tracker_url = getUniformedURL(tracker)
                    if tracker_url:
                        new_tracker_set.add(tracker_url)

        # add trackers in batch
        self.addTorrentTrackerMappingInBatch(torrent_id, list(new_tracker_set))

    def updateTorrent(self, infohash, notify=True, **kw):  # watch the schema of database
        if 'category' in kw:
            cat_id = self.misc_db.categoryName2Id(kw.pop('category'))
            kw['category_id'] = cat_id
        if 'status' in kw:
            status_id = self.misc_db.torrentStatusName2Id(kw.pop('status'))
            kw['status_id'] = status_id

        if 'progress' in kw:
            torrent_id = self.getTorrentID(infohash)
            if infohash:
                self.mypref_db.updateProgress(torrent_id, kw.pop('progress'))  # commit at end of function
        if 'seeder' in kw:
            kw['num_seeders'] = kw.pop('seeder')
        if 'leecher' in kw:
            kw['num_leechers'] = kw.pop('leecher')

        if 'swift_hash' in kw:
            kw['swift_hash'] = bin2str(kw['swift_hash'])

        if 'swift_torrent_hash' in kw:
            kw['swift_torrent_hash'] = bin2str(kw['swift_torrent_hash'])

        for key in kw.keys():
            if key not in self.keys:
                kw.pop(key)

        if len(kw) > 0:
            infohash_str = bin2str(infohash)
            where = "infohash='%s'" % infohash_str
            self._db.update(self.table_name, where, **kw)

        if notify:
            self.notifier.notify(NTFY_TORRENTS, NTFY_UPDATE, infohash)

    def on_torrent_collect_response(self, torrents):
        torrents = [(bin2str(torrent[0]), bin2str(torrent[1])) for torrent in torrents]

        infohashes = [infohash for infohash, _ in torrents if infohash]
        roothashes = [roothash for _, roothash in torrents if roothash]

        i_parameters = '?,' * len(infohashes)
        i_parameters = i_parameters[:-1]

        r_parameters = '?,' * len(roothashes)
        r_parameters = r_parameters[:-1]

        sql = "SELECT torrent_id, infohash, swift_torrent_hash FROM Torrent WHERE infohash in (" + i_parameters + ") or swift_torrent_hash in (" + r_parameters + ")"
        results = self._db.fetchall(sql, infohashes + roothashes)

        info_dict = {}
        root_dict = {}
        for torrent_id, infohash, roothash in results:
            if infohash.startswith('swift'):
                infohash = ''

            if infohash:
                info_dict[infohash] = torrent_id
            if roothash:
                root_dict[roothash] = torrent_id

        to_be_inserted = []
        update_infohash = []
        update_roothash = []
        for infohash, roothash in torrents:
            if infohash in info_dict and roothash in root_dict:
                continue
            elif infohash in info_dict:
                update_roothash.append((roothash, info_dict[infohash]))
            elif roothash in root_dict:
                update_infohash.append((infohash, root_dict[roothash]))
            else:
                to_be_inserted.append((infohash, roothash))

        if len(to_be_inserted) > 0:
            sql = "INSERT OR IGNORE INTO Torrent (infohash, swift_torrent_hash) VALUES (?, ?)"
            self._db.executemany(sql, to_be_inserted)

        if len(update_infohash) > 0:
            sql = "UPDATE Torrent SET infohash = ? WHERE torrent_id = ?"
            self._db.executemany(sql, update_infohash)

        if len(update_roothash) > 0:
            sql = "UPDATE Torrent SET swift_torrent_hash = ? WHERE torrent_id = ?"
            self._db.executemany(sql, update_roothash)

    def on_search_response(self, torrents):
        source_id = self.misc_db.torrentSourceName2Id(u'DISP_SEARCH')
        status_id = self.misc_db.torrentStatusName2Id(u'unknown')

        torrents = [(bin2str(torrent[0]), torrent[1], torrent[2], torrent[3], self.misc_db.categoryName2Id(torrent[4]), torrent[5], bin2str(torrent[8]) if torrent[8] else '', bin2str(torrent[9]) if torrent[9] else '') for torrent in torrents]
        info_root = [(torrent[0], torrent[6] or '--') for torrent in torrents]

        sql = "SELECT torrent_id, infohash, swift_hash, torrent_file_name, name FROM Torrent WHERE infohash = ? or swift_hash = ?"
        results = self._db.executemany(sql, info_root) or []

        infohash_tid = {}
        roothash_tid = {}

        tid_collected = set()
        tid_name = {}
        for torrent_id, infohash, roothash, torrent_filename, name in results:
            infohash = str(infohash)
            roothash = str(roothash)

            if infohash.startswith('swift'):
                infohash = ''

            if infohash:
                infohash_tid[infohash] = torrent_id
            if roothash:
                roothash_tid[roothash] = torrent_id
            if torrent_filename:
                tid_collected.add(torrent_id)
            tid_name[torrent_id] = name

        insert = []
        update = []
        update_roothash = []
        update_infohash = []
        to_be_indexed = []
        for infohash, swarmname, length, nrfiles, categoryid, creation_date, swift_hash, swift_torrent_hash in torrents:
            # 12/07/12 Boudewijn: swift_hash must be unique in the database, hence empty strings
            # must be stored as None
            if swift_hash == "":
                swift_hash = None
            # 02/08/12 Boudewijn: swift_torrent_hash has the same issue as swift_hash above
            if swift_torrent_hash == "":
                swift_torrent_hash = None

            tid = infohash_tid.get(infohash, None) or roothash_tid.get(swift_hash, None)

            if tid:  # we know this torrent
                if tid not in tid_collected and swarmname != tid_name.get(tid, ''):  # if not collected and name not equal then do fullupdate
                    update.append((swarmname, length, nrfiles, categoryid, creation_date, infohash, swift_hash, swift_torrent_hash, source_id, status_id, tid))
                    to_be_indexed.append((tid, swarmname))

                elif swift_hash and swift_hash not in roothash_tid:  # else check if we need to update swift
                    update_roothash.append((swift_hash, tid))

                elif infohash and infohash not in infohash_tid:  # or infohash
                    update_infohash.append((infohash, tid))
            else:
                insert.append((swarmname, length, nrfiles, categoryid, creation_date, infohash, swift_hash, swift_torrent_hash, source_id, status_id))

        if len(update) > 0:
            sql = "UPDATE Torrent SET name = ?, length = ?, num_files = ?, category_id = ?, creation_date = ?, infohash = ?, swift_hash = ?, swift_torrent_hash = ?, source_id = ?, status_id = ? WHERE torrent_id = ?"
            self._db.executemany(sql, update)

        if len(update_roothash) > 0:
            sql = "UPDATE Torrent SET swift_hash = ? WHERE torrent_id = ?"
            self._db.executemany(sql, update_roothash)

        if len(update_infohash) > 0:
            sql = "UPDATE Torrent SET infohash = ? WHERE torrent_id = ?"
            self._db.executemany(sql, update_infohash)

        if len(insert) > 0:
            sql = "INSERT INTO Torrent (name, length, num_files, category_id, creation_date, infohash, swift_hash, swift_torrent_hash, source_id, status_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
            try:
                self._db.executemany(sql, insert)

                were_inserted = [(inserted[5], inserted[7]) for inserted in insert]
                sql = "SELECT torrent_id, name FROM Torrent WHERE infohash = ? or swift_hash = ?"
                to_be_indexed = to_be_indexed + list(self._db.executemany(sql, were_inserted))
            except:
                print_exc()
                self._logger.error("infohashes: %s", insert)

        for torrent_id, swarmname in to_be_indexed:
            self._indexTorrent(torrent_id, swarmname, [], False)

    def deleteTorrent(self, infohash, delete_file=False):
        if not self.hasTorrent(infohash):
            return False

        torrent_id = self.getTorrentID(infohash)
        if self.mypref_db.hasMyPreference(torrent_id):  # don't remove torrents in my pref
            return False

        if delete_file:
            deleted = self.eraseTorrentFile(infohash)
        else:
            deleted = True

        if deleted:
            self._deleteTorrent(infohash)

        self.notifier.notify(NTFY_TORRENTS, NTFY_DELETE, infohash)
        return deleted

    def _deleteTorrent(self, infohash, keep_infohash=True):
        torrent_id = self.getTorrentID(infohash)
        if torrent_id is not None:
            if keep_infohash:
                self._db.update(self.table_name, where="torrent_id=%d" % torrent_id, torrent_file_name=None)
            else:
                self._db.delete(self.table_name, torrent_id=torrent_id)
            if infohash in self.existed_torrents:
                self.existed_torrents.remove(infohash)

            self._db.delete('TorrentTrackerMapping', torrent_id=torrent_id)
            # print '******* delete torrent', torrent_id, `infohash`, self.hasTorrent(infohash)

    def eraseTorrentFile(self, infohash):
        torrent_id = self.getTorrentID(infohash)
        if torrent_id is not None:
            torrent_dir = self.getTorrentDir()
            torrent_name = self.getOne('torrent_file_name', torrent_id=torrent_id)
            src = os.path.join(torrent_dir, torrent_name)
            if not os.path.exists(src):  # already removed
                return True

            try:
                os.remove(src)
            except Exception as msg:
                self._logger.error("cachedbhandler: failed to erase torrent %s %s %s", src, Exception, msg)
                return False

        return True

    def getTorrentCheckRetries(self, torrent_id):
        sql = 'SELECT tracker_check_retries FROM Torrent WHERE torrent_id = ?'
        result = self._db.fetchone(sql, (torrent_id,))
        return result

    def updateTorrentCheckResult(self, torrent_id, infohash,
                seeders, leechers, last_check, next_check, status, retries):
        sql = 'UPDATE Torrent SET num_seeders = ?, num_leechers = ?'\
              + ', last_tracker_check = ?, next_tracker_check = ?'\
              + ', status_id = ?, tracker_check_retries = ?'\
              + ' WHERE torrent_id = ?'

        status_id = self.misc_db.torrentStatusName2Id(status)
        self._db.execute_write(sql,
            (seeders, leechers, last_check, next_check,
             status_id, retries, torrent_id))

        self._logger.debug("cachedbhandler: update result %d/%d for %s/%d", seeders, leechers, bin2str(infohash), torrent_id)

        # notify
        self.notifier.notify(NTFY_TORRENTS, NTFY_UPDATE, infohash)

    # ------------------------------------------------------------
    # Updates the TorrentTrackerMapping table.
    # ------------------------------------------------------------
    def addTorrentTrackerMapping(self, torrent_id, tracker):
        self.addTorrentTrackerMappingInBatch(torrent_id, [tracker, ])

    # ------------------------------------------------------------
    # Updates the TorrentTrackerMapping table in batch.
    # ------------------------------------------------------------
    def addTorrentTrackerMappingInBatch(self, torrent_id, tracker_list):
        if not tracker_list:
            return

        parameters = '?,' * len(tracker_list)
        sql = 'SELECT tracker FROM TrackerInfo WHERE tracker IN (' + parameters[:-1] + ')'
        found_tracker_list = self._db.fetchall(sql, tuple(tracker_list))
        found_tracker_list = [ tracker[0] for tracker in found_tracker_list ]

        # update tracker info
        not_found_tracker_list = [tracker for tracker in tracker_list if tracker not in found_tracker_list]
        if not_found_tracker_list:
            self.addTrackerInfoInBatch(not_found_tracker_list)

        # update torrent-tracker mapping
        sql = 'INSERT OR IGNORE INTO TorrentTrackerMapping(torrent_id, tracker_id)'\
            + ' VALUES(?, (SELECT tracker_id FROM TrackerInfo WHERE tracker = ?))'
        new_mapping_list = [(torrent_id, tracker) for tracker in tracker_list]
        if new_mapping_list:
            self._db.executemany(sql, new_mapping_list)

    # ------------------------------------------------------------
    # Gets all the torrents that has a specific tracker.
    # ------------------------------------------------------------
    def getTorrentsOnTracker(self, tracker, current_time):
        sql = """
            SELECT T.torrent_id, T.infohash, T.last_tracker_check
              FROM Torrent T, TrackerInfo TI, TorrentTrackerMapping TTM
              WHERE TI.tracker = ?
              AND TI.tracker_id = TTM.tracker_id AND T.torrent_id = TTM.torrent_id
              AND next_tracker_check < ?
            """
        infohash_list = self._db.fetchall(sql, (tracker, current_time))
        return [(torrent_id, str2bin(infohash), last_tracker_check) for torrent_id, infohash, last_tracker_check in infohash_list]

    # ------------------------------------------------------------
    # Gets a list of trackers of a given torrent ID.
    # (from TorrentTrackerMapping table)
    # ------------------------------------------------------------
    def getTrackerListByTorrentID(self, torrent_id):
        sql = 'SELECT TR.tracker FROM TrackerInfo TR, TorrentTrackerMapping MP'\
            + ' WHERE MP.torrent_id = ?'\
            + ' AND TR.tracker_id = MP.tracker_id'
        tracker_list = self._db.fetchall(sql, (torrent_id,))
        return [ tracker[0] for tracker in tracker_list ]

    # ------------------------------------------------------------
    # Gets a list of trackers of a given infohash.
    # (from TorrentTrackerMapping table)
    # ------------------------------------------------------------
    def getTrackerListByInfohash(self, infohash):
        torrent_id = self.getTorrentID(infohash)
        return self.getTrackerListByTorrentID(torrent_id)

    # ------------------------------------------------------------
    # Adds a new tracker into the TrackerInfo table.
    # ------------------------------------------------------------
    def addTrackerInfo(self, tracker, to_notify=True):
        self.addTrackerInfoInBatch([tracker, ], to_notify)

    # ------------------------------------------------------------
    # Adds a new trackers in batch into the TrackerInfo table.
    # ------------------------------------------------------------
    def addTrackerInfoInBatch(self, tracker_list, to_notify=True):
        sql = 'INSERT INTO TrackerInfo(tracker) VALUES(?)'
        self._db.executemany(sql, [(tracker,) for tracker in tracker_list])

        if to_notify:
            self.notifier.notify(NTFY_TRACKERINFO, NTFY_INSERT, tracker_list)

    # ------------------------------------------------------------
    # Gets all tracker information from the TrackerInfo table.
    # ------------------------------------------------------------
    def getTrackerInfoList(self):
        sql = 'SELECT tracker, last_check, failures, is_alive FROM TrackerInfo'
        tracker_info_list = self._db.fetchall(sql)
        return tracker_info_list

    # ------------------------------------------------------------
    # Updates a list of tracker status into the TrackerInfo table.
    # ------------------------------------------------------------
    def updateTrackerInfo(self, args):
        sql = 'UPDATE TrackerInfo SET'\
            + ' last_check = ?, failures = ?, is_alive = ?'\
            + ' WHERE tracker = ?'
        self._db.executemany(sql, args)

    # ------------------------------------------------------------
    # Gets a list of trackers that have been checked to be alive recently.
    # ------------------------------------------------------------
    def getRecentlyAliveTrackers(self, limit=10):
        sql = """
            SELECT DISTINCT tracker FROM TrackerInfo
              WHERE is_alive = 1
              AND tracker != 'no-DHT' AND tracker != 'DHT'
              ORDER BY last_check DESC LIMIT ?
            """
        trackers = self._db.fetchall(sql, (limit,))
        return [tracker[0] for tracker in trackers]

    def getTorrentDir(self):
        return self.torrent_dir

    def updateTorrentDir(self, torrent_dir):
        sql = "SELECT torrent_id, torrent_file_name FROM Torrent WHERE torrent_file_name not NULL"
        results = self._db.fetchall(sql)

        updates = []
        for result in results:
            head, tail = os.path.split(result[1])
            new_file_name = os.path.join(torrent_dir, tail)

            updates.append((new_file_name, result[0]))
        sql = "UPDATE TORRENT SET torrent_file_name = ? WHERE torrent_id = ?"
        self._db.executemany(sql, updates)

        self.torrent_dir = torrent_dir

    def getTorrent(self, infohash, keys=None, include_mypref=True):
        assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)
        # to do: replace keys like source -> source_id and status-> status_id ??

        if keys is None:
            keys = deepcopy(self.value_name)
        else:
            keys = list(keys)

        res = self._db.getOne('Torrent C', keys, infohash=bin2str(infohash))

        if not res:
            return None
        torrent = dict(zip(keys, res))
        if 'source_id' in torrent:
            torrent['source'] = self.misc_db.torrentSourceId2Name(torrent['source_id'])

        if 'category_id' in torrent:
            torrent['category'] = [self.misc_db.categoryId2Name(torrent['category_id'])]

        if 'status_id' in torrent:
            torrent['status'] = self.misc_db.torrentStatusId2Name(torrent['status_id'])

        if 'swift_hash' in torrent and torrent['swift_hash']:
            torrent['swift_hash'] = str2bin(torrent['swift_hash'])

        if 'swift_torrent_hash' in torrent and torrent['swift_torrent_hash']:
            torrent['swift_torrent_hash'] = str2bin(torrent['swift_torrent_hash'])

        torrent['infohash'] = infohash

        if include_mypref:
            tid = torrent['C.torrent_id']
            stats = self.mypref_db.getMyPrefStats(tid)

            if stats:
                torrent['myDownloadHistory'] = True
                torrent['creation_time'] = stats[tid][0]
                torrent['progress'] = stats[tid][1]
                torrent['destination_path'] = stats[tid][2]
            else:
                torrent['myDownloadHistory'] = False

        return torrent

    def getTorrents(self, category_name='all', range=None, library=False, sort=None, reverse=False):
        """
        get Torrents of some category and with alive status (opt. not in family filter)

        if library == True: only torrents with destination_path != '' are returned
        else: return only good torrents, accepted by family filter

        @return Returns a list of dicts with keys:
            torrent_id, infohash, name, category, status, creation_date, num_files, num_leechers, num_seeders,
            length, secret, insert_time, source, torrent_filename, relevance, simRank, tracker, last_check
            (if in library: myDownloadHistory, download_started, progress, dest_dir)

        niels 25-10-2010: changed behaviour to left join TorrentTracker, due to magnet links
        """

        # print >> sys.stderr, 'TorrentDBHandler: getTorrents(%s, %s, %s, %s, %s)' % (category_name, range, library, sort, reverse)
        s = time()

        value_name = deepcopy(self.value_name)
        sql = 'Select ' + ','.join(value_name)
        sql += ' From CollectedTorrent C'
        # sql += ' From CollectedTorrent C LEFT JOIN TorrentTrackerMapping TTM ON C.torrent_id = TTM.torrent_id'

        where = ''
        if category_name != 'all':
            category_id = self.misc_db._category_name2id_dict.get(category_name.lower(), -1)
            where += 'category_id = %d AND' % category_id  # unkown category_name returns no torrents

        if library:
            where += 'C.torrent_id in (select torrent_id from MyPreference where destination_path != "")'
        else:
            where += 'status_id=%d ' % self.misc_db.torrentStatusName2Id(u'good')  # if not library, show only good files
            where += self.category.get_family_filter_sql(self.misc_db.categoryName2Id)  # add familyfilter

        sql += ' Where ' + where

        if 'infohash' in value_name:
            sql += " GROUP BY infohash"

        if range:
            offset = range[0]
            limit = range[1] - range[0]
            sql += ' Limit %d Offset %d' % (limit, offset)

        if sort:
            # Arno, 2008-10-6: buggy: not reverse???
            desc = (reverse) and 'desc' or ''
            if sort == 'name':
                sql += ' Order By lower(%s) %s' % (sort, desc)
            else:
                sql += ' Order By %s %s' % (sort, desc)

        # print >>sys.stderr,"TorrentDBHandler: GET TORRENTS val",value_name,"where",where,"limit",limit,"offset",offset,"order",order_by
        # print_stack

        # Must come before query
        ranks = self.getRanks()
        res_list = self._db.fetchall(sql)
        mypref_stats = self.mypref_db.getMyPrefStats() if self.mypref_db else None

        torrent_list = self.valuelist2torrentlist(value_name, res_list, ranks, mypref_stats)
        del res_list
        del mypref_stats
        return torrent_list

    def getLibraryTorrents(self, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM MyPreference, Torrent LEFT JOIN ChannelTorrents ON Torrent.torrent_id = ChannelTorrents.torrent_id WHERE destination_path != '' AND MyPreference.torrent_id = Torrent.torrent_id"
        data = self._db.fetchall(sql)

        fixed = self.__fixTorrents(keys, data)
        return fixed

    def valuelist2torrentlist(self, value_name, res_list, ranks, mypref_stats):
        torrent_list = []
        for item in res_list:
            value_name[0] = 'torrent_id'
            torrent = dict(zip(value_name, item))

            try:
                torrent['source'] = self.misc_db.torrentSourceId2Name(torrent['source_id'])
            except:
                print_exc()
                # Arno: RSS subscription and id2src issue
                torrent['source'] = 'http://some/RSS/feed'

            torrent['category'] = [self.misc_db.categoryId2Name(torrent['category_id'])]
            torrent['status'] = self.misc_db.torrentStatusId2Name(torrent['status_id'])
            torrent['simRank'] = ranksfind(ranks, torrent['infohash'])
            torrent['infohash'] = str2bin(torrent['infohash'])

            # Niels: we now convert category and status in gui
            # del torrent['category_id']
            # del torrent['status_id']
            torrent_id = torrent['torrent_id']
            if mypref_stats is not None and torrent_id in mypref_stats:
                # add extra info for torrent in mypref
                torrent['myDownloadHistory'] = True
                data = mypref_stats[torrent_id]  # (create_time,progress,destdir)
                torrent['download_started'] = data[0]
                torrent['progress'] = data[1]
                torrent['destdir'] = data[2]

            # print >>sys.stderr,"TorrentDBHandler: GET TORRENTS",`torrent`

            torrent_list.append(torrent)
        return torrent_list

    def __fixTorrents(self, keys, results):
        def fix_value(key):
            if key in keys:
                key_index = keys.index(key)
                for i in range(len(results)):
                    result = list(results[i])
                    if result[key_index]:
                        result[key_index] = str2bin(result[key_index])
                        results[i] = result
        fix_value('infohash')
        fix_value('swift_hash')
        fix_value('swift_torrent_hash')
        return results

    def getRanks(self):
        value_name = 'infohash'
        order_by = 'relevance desc'
        rankList_size = 20
        where = 'status_id=%d ' % self.misc_db.torrentStatusName2Id(u'good')
        res_list = self._db.getAll('Torrent', value_name, where=where, limit=rankList_size, order_by=order_by)
        return [a[0] for a in res_list]

    def getNumberCollectedTorrents(self):
        # return self._db.size('CollectedTorrent')
        return self._db.getOne('CollectedTorrent', 'count(torrent_id)')

    def getRecentlyCollectedSwiftHashes(self, limit=50):
        sql = """
            SELECT CT.swift_torrent_hash, CT.infohash, CT.num_seeders, CT.num_leechers, T.last_tracker_check, CT.insert_time
             FROM Torrent T, CollectedTorrent CT
             WHERE CT.torrent_id = T.torrent_id
             AND CT.swift_torrent_hash IS NOT NULL AND CT.swift_torrent_hash <> ''
             AND T.secret is not 1 ORDER BY CT.insert_time DESC LIMIT ?
             """
        results = self._db.fetchall(sql, (limit,))
        return [[str2bin(result[0]), str2bin(result[1]), result[2], result[3], result[4] or 0, result[5]] for result in results]

    def getRandomlyCollectedSwiftHashes(self, insert_time, limit=50):
        sql = """
            SELECT CT.swift_torrent_hash, CT.infohash, CT.num_seeders, CT.num_leechers, T.last_tracker_check
             FROM Torrent T, CollectedTorrent CT
             WHERE CT.torrent_id = T.torrent_id
             AND CT.insert_time < ?
             AND CT.swift_torrent_hash IS NOT NULL
             AND CT.swift_torrent_hash <> ''
             AND T.secret is not 1 ORDER BY RANDOM() DESC LIMIT ?
            """
        results = self._db.fetchall(sql, (insert_time, limit))
        return [[str2bin(result[0]), str2bin(result[1]), result[2], result[3], result[4] or 0] for result in results]

    def selectSwiftTorrentsToCollect(self, hashes):
        parameters = '?,' * len(hashes)
        parameters = parameters[:-1]

        # TODO: bias according to votecast, popular first

        sql = "SELECT infohash, swift_torrent_hash FROM Torrent WHERE torrent_file_name is NULL and infohash in (" + parameters + ")"
        results = self._db.fetchall(sql, map(bin2str, hashes))
        return [(str2bin(hash), str2bin(roothash)) for hash, roothash in results]

    def getTorrentsStats(self):
        return self._db.getOne('CollectedTorrent', ['count(torrent_id)', 'sum(length)', 'sum(num_files)'])

    def freeSpace(self, torrents2del):
# if torrents2del > 100:  # only delete so many torrents each time
#            torrents2del = 100
        if self.channelcast_db and self.channelcast_db._channel_id:
            sql = """
                select torrent_file_name, torrent_id, swift_torrent_hash, relevance,
                    min(relevance,2500) +  min(500,num_leechers) + 4*min(500,num_seeders) - (max(0,min(500,(%d-creation_date)/86400)) ) as weight
                from CollectedTorrent
                where torrent_id not in (select torrent_id from MyPreference)
                and torrent_id not in (select torrent_id from ChannelTorrents where channel_id = %d)
                order by weight
                limit %d
            """ % (int(time()), self.channelcast_db._channel_id, torrents2del)
        else:
            sql = """
                select torrent_file_name, torrent_id, swift_torrent_hash, relevance,
                    min(relevance,2500) +  min(500,num_leechers) + 4*min(500,num_seeders) - (max(0,min(500,(%d-creation_date)/86400)) ) as weight
                from CollectedTorrent
                where torrent_id not in (select torrent_id from MyPreference)
                order by weight
                limit %d
            """ % (int(time()), torrents2del)

        res_list = self._db.fetchall(sql)
        if len(res_list) == 0:
            return False

        # delete torrents from db
        sql_del_torrent = "update Torrent set torrent_file_name = null where torrent_id=?"
        # sql_del_tracker = "delete from TorrentTracker where torrent_id=?"
        # sql_del_pref = "delete from Preference where torrent_id=?"
        tids = [(torrent_id,) for torrent_file_name, torrent_id, swift_torrent_hash, relevance, weight in res_list]

        self._db.executemany(sql_del_torrent, tids)
        # self._db.executemany(sql_del_tracker, tids)
        # self._db.executemany(sql_del_pref, tids)

        # but keep the infohash in db to maintain consistence with preference db
        # torrent_id_infohashes = [(torrent_id,infohash_str,relevance) for torrent_file_name, torrent_id, infohash_str, relevance, weight in res_list]
        # sql_insert =  "insert into Torrent (torrent_id, infohash, relevance) values (?,?,?)"
        # self._db.executemany(sql_insert, torrent_id_infohashes)

        torrent_dir = self.getTorrentDir()
        deleted = 0  # deleted any file?
        insert_files = []
        for torrent_file_name, torrent_id, swift_torrent_hash, relevance, weight in res_list:

            torrent_path = os.path.join(torrent_dir, torrent_file_name)
            if not os.path.exists(torrent_path):
                roothash_as_hex = binascii.hexlify(swift_torrent_hash)
                torrent_path = os.path.join(torrent_dir, roothash_as_hex)

            if os.path.exists(torrent_path):
                try:
                    tdef = TorrentDef.load(torrent_path)
                    files = [(torrent_id, unicode(path), length) for path, length in tdef.get_files_as_unicode_with_length()]
                    files = sample(files, 25)
                    insert_files.extend(files)
                except:
                    pass

            mhash_path = torrent_path + '.mhash'
            mbinmap_path = torrent_path + '.mbinmap'
            try:
                if os.path.exists(torrent_path):
                    os.remove(torrent_path)

                if os.path.exists(mhash_path):
                    os.remove(mhash_path)

                if os.path.exists(mbinmap_path):
                    os.remove(mbinmap_path)

                deleted += 1
            except WindowsError:
                pass
            except Exception:
                print_exc()
                # print >> sys.stderr, "Error in erase torrent", Exception, msg
                pass

        if len(insert_files) > 0:
            sql_insert_files = "INSERT OR IGNORE INTO TorrentFiles (torrent_id, path, length) VALUES (?,?,?)"
            self._db.executemany(sql_insert_files, insert_files)

        self._logger.info("Erased %d torrents", deleted)
        return deleted

    def hasMetaData(self, infohash):
        return self.hasTorrent(infohash)

    def searchNames(self, kws, local=True, keys=['torrent_id', 'infohash', 'name', 'torrent_file_name', 'length', 'creation_date', 'num_files', 'insert_time', 'category_id', 'status_id', 'num_seeders', 'num_leechers', 'dispersy_id', 'swift_hash', 'swift_torrent_hash'], doSort=True):
        #        if local:
#            mainsql += "C.id, C.dispersy_id, C.name, C.description, C.time_stamp, inserted, "
#            value_name += ['channeltorrent_id', 'dispersy_id', 'chant_name', 'description', 'time_stamp', 'inserted']
#
        assert 'infohash' in keys
        assert not doSort or ('num_seeders' in keys or 'T.num_seeders' in keys)

        infohash_index = keys.index('infohash')
        swift_hash_index = keys.index('swift_hash') if 'swift_hash' in keys else -1
        swift_torrent_hash_index = keys.index('swift_torrent_hash') if 'swift_torrent_hash' in keys else -1
        num_seeders_index = keys.index('num_seeders') if 'num_seeders' in keys else -1

        if num_seeders_index == -1:
            doSort = False

        t1 = time()
        values = ", ".join(keys)
        mainsql = "SELECT " + values + ", C.channel_id, Matchinfo(FullTextIndex) FROM"
        if local:
            mainsql += " Torrent T"
        else:
            mainsql += " CollectedTorrent T"

        mainsql += """, FullTextIndex
                    LEFT OUTER JOIN _ChannelTorrents C ON T.torrent_id = C.torrent_id
                    WHERE t.torrent_id = FullTextIndex.rowid AND C.deleted_at IS NULL AND FullTextIndex MATCH ?
                    """

        if not local:
            mainsql += "AND T.secret is not 1 LIMIT 250"

        query = " ".join(filter_keywords(kws))
        not_negated = [kw for kw in filter_keywords(kws) if kw[0] != '-']

        results = self._db.fetchall(mainsql, (query,))

        t2 = time()

        channels = set()
        channel_dict = {}
        for result in results:
            if result[-2]:
                channels.add(result[-2])

        if len(channels) > 0:
            # Channels consist of a tuple (id, dispersy_cid, name, description, nr_torrents, nr_favorites, nr_spam, my_vote, modified)
            for channel in self.channelcast_db.getChannels(channels):
                if channel[1] != '-1':
                    channel_dict[channel[0]] = channel

        t3 = time()
        myChannelId = self.channelcast_db._channel_id or 0

        result_dict = {}

        # step 1, merge torrents keep one with best channel
        for result in results:
            channel_id = result[-2]
            channel = channel_dict.get(channel_id, False)

            infohash = result[infohash_index]
            if channel:
                # ignoring spam channels
                if channel[7] < 0:
                    continue

                # see if we have a better channel in torrents_dict
                if infohash in result_dict:
                    old_channel = channel_dict.get(result_dict[infohash][-2], False)
                    if old_channel:

                        # allways prefer my channel
                        if old_channel[0] == myChannelId:
                            continue

                        # allways prefer channel with higher vote
                        if channel[7] < old_channel[7]:
                            continue

                        votes = (channel[5] or 0) - (channel[6] or 0)
                        oldvotes = (old_channel[5] or 0) - (old_channel[6] or 0)
                        if votes < oldvotes:
                            continue

                result_dict[infohash] = result

            elif infohash not in result_dict:
                result_dict[infohash] = result

        t4 = time()

        # step 2, fix all dict fields
        dont_sort_list = []
        results = [list(result) for result in result_dict.values()]
        for i in xrange(len(results) - 1, -1, -1):
            result = results[i]

            result[infohash_index] = str2bin(result[infohash_index])
            if swift_hash_index >= 0 and result[swift_hash_index]:
                result[swift_hash_index] = str2bin(result[swift_hash_index])
            if swift_torrent_hash_index >= 0 and result[swift_torrent_hash_index]:
                result[swift_torrent_hash_index] = str2bin(result[swift_torrent_hash_index])

            matches = {'swarmname': set(), 'filenames': set(), 'fileextensions': set()}

            # Matchinfo is documented at: http://www.sqlite.org/fts3.html#matchinfo
            matchinfo = str(result[-1])
            num_phrases, num_cols = unpack_from('II', matchinfo)
            unpack_str = 'I' * (3 * num_cols * num_phrases)
            matchinfo = unpack_from('II' + unpack_str, matchinfo)

            swarmnames, filenames, fileextensions = [
                [matchinfo[3 * (i + p * num_cols) + 2] for p in range(num_phrases)]
                for i in range(num_cols)
            ]

            for i, keyword in enumerate(not_negated):
                if swarmnames[i]:
                    matches['swarmname'].add(keyword)
                if filenames[i]:
                    matches['filenames'].add(keyword)
                if fileextensions[i]:
                    matches['fileextensions'].add(keyword)
            result[-1] = matches

            channel = channel_dict.get(result[-2], (result[-2], None, '', '', 0, 0, 0, 0, 0, False))
            result.extend(channel)

            if doSort and result[num_seeders_index] <= 0:
                dont_sort_list.append(result)
                results.pop(i)

        t5 = time()

        if doSort:
            def compare(a, b):
                return cmp(a[num_seeders_index], b[num_seeders_index])
            results.sort(compare, reverse=True)
        results.extend(dont_sort_list)

        if not local:
            results = results[:25]

        # print >> sys.stderr, "# hits:%d (%d from db, %d not sorted); search time:%.3f,%.3f,%.3f,%.3f,%.3f,%.3f" % (len(results),len(results),len(dont_sort_list),t2-t1, t3-t2, t4-t3, t5-t4, time()-t5, time()-t1)
        return results

    def getAutoCompleteTerms(self, keyword, max_terms, limit=100):
        sql = "SELECT swarmname FROM FullTextIndex WHERE swarmname MATCH ? LIMIT ?"
        result = self._db.fetchall(sql, (keyword + '*', limit))

        all_terms = set()
        for line, in result:
            if len(all_terms) >= max_terms:
                break
            i1 = line.find(keyword)
            i2 = line.find(' ', i1 + len(keyword))
            all_terms.add(line[i1:i2] if i2 >= 0 else line[i1:])

        if keyword in all_terms:
            all_terms.remove(keyword)
        if '' in all_terms:
            all_terms.remove('')

        return list(all_terms)

    def getSearchSuggestion(self, keywords, limit=1):
        match = [keyword.lower() for keyword in keywords if len(keyword) > 3]

        def lev(a, b):
            "Calculates the Levenshtein distance between a and b."
            n, m = len(a), len(b)
            if n > m:
                # Make sure n <= m, to use O(min(n,m)) space
                a, b = b, a
                n, m = m, n

            current = range(n + 1)
            for i in range(1, m + 1):
                previous, current = current, [i] + [0] * n
                for j in range(1, n + 1):
                    add, delete = previous[j] + 1, current[j - 1] + 1
                    change = previous[j - 1]
                    if a[j - 1] != b[i - 1]:
                        change = change + 1
                    current[j] = min(add, delete, change)

            return current[n]

        def levcollate(s1, s2):
            l1 = sum(sorted([lev(a, b) for a in s1.split() for b in match])[:len(match)])
            l2 = sum(sorted([lev(a, b) for a in s2.split() for b in match])[:len(match)])

            # return -1 if s1<s2, +1 if s1>s2 else 0
            if l1 < l2:
                return -1
            if l1 > l2:
                return 1
            return 0

        cursor = self._db.getCursor()
        connection = cursor.getconnection()
        connection.createcollation("leven", levcollate)

        sql = "SELECT swarmname FROM FullTextIndex WHERE swarmname MATCH ? ORDER By swarmname collate leven ASC LIMIT ?"
        results = self._db.fetchall(sql, (' OR '.join(['*%s*' % m for m in match]), limit))
        connection.createcollation("leven", None)
        return [result[0] for result in results]

    def getTorrentFiles(self, torrent_id):
        sql = "SELECT path, length FROM TorrentFiles WHERE torrent_id = ?"
        return self._db.fetchall(sql, (torrent_id,))

    def getTorrentCollecting(self, torrent_id):
        sql = "SELECT source FROM TorrentCollecting WHERE torrent_id = ?"
        return self._db.fetchall(sql, (torrent_id,))

    def setSecret(self, infohash, secret):
        kw = {'secret': secret}
        self.updateTorrent(infohash, **kw)


class MyPreferenceDBHandler(BasicDBHandler):

    def __init__(self):
        if MyPreferenceDBHandler._single is not None:
            raise RuntimeError("MyPreferenceDBHandler is singleton")
        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, 'MyPreference')  # # self,db,'MyPreference'

        self.status_good = MiscDBHandler.getInstance().torrentStatusName2Id(u'good')
        self.rlock = threading.RLock()
        self.loadData()

        self._torrent_db = TorrentDBHandler.getInstance()

    def loadData(self):
        """ Arno, 2010-02-04: Brute force update method for the self.recent_
        caches, because people don't seem to understand that caches need
        to be kept consistent with the database. Caches are evil in the first place.
        """
        self.recent_preflist = self.recent_preflist_with_clicklog = self.recent_preflist_with_swarmsize = None

    def getMyPrefList(self, order_by=None):
        res = self.getAll('torrent_id', order_by=order_by)
        return [p[0] for p in res]

    def getMyPrefListInfohash(self, returnDeleted=True, limit=None):
        # Arno, 2012-08-01: having MyPreference (the shorter list) first makes
        # this faster.
        sql = 'select infohash, swift_hash from MyPreference, Torrent where Torrent.torrent_id == MyPreference.torrent_id'
        if not returnDeleted:
            sql += ' AND destination_path != ""'

        if limit:
            sql += ' ORDER BY creation_time DESC LIMIT %d' % limit

        res = self._db.fetchall(sql)
        res = [item for sublist in res for item in sublist]
        return [str2bin(p) if p else '' for p in res]

    def getMyPrefStats(self, torrent_id=None):
        # get the full {torrent_id:(create_time,progress,destdir)}
        value_name = ('torrent_id', 'creation_time', 'progress', 'destination_path')
        if torrent_id is not None:
            where = 'torrent_id=%s' % torrent_id
        else:
            where = None
        res = self.getAll(value_name, where)
        mypref_stats = {}
        for pref in res:
            torrent_id, creation_time, progress, destination_path = pref
            mypref_stats[torrent_id] = (creation_time, progress, destination_path)
        return mypref_stats

    def getMyPrefStatsInfohash(self, infohash):
        torrent_id = self._torrent_db.getTorrentID(infohash)
        if torrent_id is not None:
            return self.getMyPrefStats(torrent_id)[torrent_id]

    def getRecentLivePrefList(self, num=0):
        if self.recent_preflist is None:
            self.rlock.acquire()
            try:
                if self.recent_preflist is None:
                    sql = """SELECT infohash from MyPreference m, Torrent t
                        WHERE m.torrent_id == t.torrent_id AND status_id == %d
                        ORDER BY creation_time DESC""" % self.status_good
                    recent_preflist = self._db.fetchall(sql)
                    self.recent_preflist = [str2bin(t[0]) for t in recent_preflist] if recent_preflist else []
            finally:
                self.rlock.release()
        if num > 0:
            return self.recent_preflist[:num]
        else:
            return self.recent_preflist

    def addClicklogToMyPreference(self, infohash, clicklog_data):
        torrent_id = self._torrent_db.getTorrentID(infohash)
        clicklog_already_stored = False  # equivalent to hasMyPreference TODO
        if torrent_id is None or clicklog_already_stored:
            return False

        d = {}
        # copy those elements of the clicklog data which are used in the update command
        for clicklog_key in ["click_position", "reranking_strategy"]:
            if clicklog_key in clicklog_data:
                d[clicklog_key] = clicklog_data[clicklog_key]

        if d == {}:
            self._logger.debug("no updatable information given to addClicklogToMyPreference")
        else:
            self._logger.debug("addClicklogToMyPreference: updatable clicklog data: %s", d)
            self._db.update(self.table_name, 'torrent_id=%d' % torrent_id, **d)

    def hasMyPreference(self, torrent_id):
        res = self.getOne('torrent_id', torrent_id=torrent_id)
        if res is not None:
            return True
        else:
            return False

    def addMyPreference(self, torrent_id, data):
        # keys in data: destination_path, progress, creation_time, torrent_id
        if self.hasMyPreference(torrent_id):
            # Arno, 2009-03-09: Torrent already exists in myrefs.
            # Hack for hiding from lib while keeping in myprefs.
            # see standardOverview.removeTorrentFromLibrary()
            #
            self.updateDestDir(torrent_id, data.get('destination_path'))
            infohash = self._torrent_db.getInfohash(torrent_id)
            if infohash:
                self.notifier.notify(NTFY_MYPREFERENCES, NTFY_UPDATE, infohash)
            return False

        d = {}
        d['destination_path'] = data.get('destination_path')
        d['progress'] = data.get('progress', 0)
        d['creation_time'] = data.get('creation_time', int(time()))
        d['torrent_id'] = torrent_id

        self._db.insert(self.table_name, **d)

        infohash = self._torrent_db.getInfohash(torrent_id)
        if infohash:
            self.notifier.notify(NTFY_MYPREFERENCES, NTFY_INSERT, infohash)

        # Arno, 2010-02-04: Update self.recent_ caches :-(
        # self.loadData()
        return True

    def deletePreference(self, torrent_id):
        self._db.delete(self.table_name, **{'torrent_id': torrent_id})

        infohash = self._torrent_db.getInfohash(torrent_id)
        if infohash:
            self.notifier.notify(NTFY_MYPREFERENCES, NTFY_DELETE, infohash)

        # Arno, 2010-02-04: Update self.recent_ caches :-(
        # self.loadData()

    def updateProgress(self, torrent_id, progress):
        self._db.update(self.table_name, 'torrent_id=%d' % torrent_id, progress=progress)

    def updateProgressByHash(self, hash, progress):
        torrent_id = self._torrent_db.getTorrentID(hash)
        if not torrent_id:
            torrent_id = self._torrent_db.getTorrentIDRoot(hash)

        if torrent_id:
            self.updateProgress(torrent_id, progress)

    def updateDestDir(self, torrent_id, destdir):
        if not isinstance(destdir, basestring):
            self._logger.info('DESTDIR IS NOT STRING: %s', destdir)
            return
        self._db.update(self.table_name, 'torrent_id=%d' % torrent_id, destination_path=destdir)


class VoteCastDBHandler(BasicDBHandler):

    def __init__(self):
        try:
            db = SQLiteCacheDB.getInstance()
            BasicDBHandler.__init__(self, db, 'VoteCast')
            self._logger.debug("votecast: DB made")
        except:
            self._logger.error("votecast: couldn't make the table")

        self.my_votes = None

        self.voteLock = Lock()
        self.updatedChannels = set()
        db.schedule_task(self._flush_to_database, delay=5.0)

    def registerSession(self, session):
        self.session = session

        self.peer_db = PeerDBHandler.getInstance()
        self.channelcast_db = ChannelCastDBHandler.getInstance()

    def on_votes_from_dispersy(self, votes):
        insert_vote = "INSERT OR REPLACE INTO _ChannelVotes (channel_id, voter_id, dispersy_id, vote, time_stamp) VALUES (?,?,?,?,?)"
        self._db.executemany(insert_vote, votes)

        for channel_id, voter_id, _, _, _ in votes:
            if voter_id == None:
                self.notifier.notify(NTFY_VOTECAST, NTFY_UPDATE, channel_id, voter_id == None)
            self._scheduleUpdateChannelVotes(channel_id)

    def on_remove_votes_from_dispersy(self, votes, contains_my_vote):
        remove_vote = "UPDATE _ChannelVotes SET deleted_at = ? WHERE channel_id = ? AND dispersy_id = ?"
        self._db.executemany(remove_vote, votes)

        if contains_my_vote:
            for _, channel_id, _ in votes:
                self.notifier.notify(NTFY_VOTECAST, NTFY_UPDATE, channel_id, contains_my_vote)

        for _, channel_id, _ in votes:
            self._scheduleUpdateChannelVotes(channel_id)

    def _scheduleUpdateChannelVotes(self, channel_id):
        with self.voteLock:
            self.updatedChannels.add(channel_id)

    def _flush_to_database(self):
        while True:
            with self.voteLock:
                channel_ids = list(self.updatedChannels)
                self.updatedChannels.clear()

            if channel_ids:
                parameters = ",".join("?" * len(channel_ids))
                sql = "Select channel_id, vote FROM ChannelVotes WHERE channel_id in (" + parameters + ")"
                positive_votes = {}
                negative_votes = {}
                for channel_id, vote in self._db.fetchall(sql, channel_ids):
                    if vote == 2:
                        positive_votes[channel_id] = positive_votes.get(channel_id, 0) + 1
                    elif vote == -1:
                        negative_votes[channel_id] = negative_votes.get(channel_id, 0) + 1

                updates = [(positive_votes.get(channel_id, 0), negative_votes.get(channel_id, 0), channel_id) for channel_id in channel_ids]
                self._db.executemany("UPDATE OR IGNORE _Channels SET nr_favorite = ?, nr_spam = ? WHERE id = ?", updates)

                for channel_id in channel_ids:
                    self.notifier.notify(NTFY_VOTECAST, NTFY_UPDATE, channel_id)

            yield 15.0

    def get_latest_vote_dispersy_id(self, channel_id, voter_id):
        if voter_id:
            select_vote = "SELECT dispersy_id FROM ChannelVotes WHERE channel_id = ? AND voter_id = ? AND dispersy_id != -1 ORDER BY time_stamp DESC Limit 1"
            return self._db.fetchone(select_vote, (channel_id, voter_id))

        select_vote = "SELECT dispersy_id FROM ChannelVotes WHERE channel_id = ? AND voter_id ISNULL AND dispersy_id != -1 ORDER BY time_stamp DESC Limit 1"
        return self._db.fetchone(select_vote, (channel_id,))

    def getPosNegVotes(self, channel_id):
        sql = 'select nr_favorite, nr_spam from Channels where id = ?'
        result = self._db.fetchone(sql, (channel_id,))
        if result:
            return result
        return 0, 0

    def getVoteOnChannel(self, channel_id, voter_id):
        """ return the vote status if such record exists, otherwise None  """
        if voter_id:
            sql = "select vote from ChannelVotes where channel_id = ? and voter_id = ?"
            return self._db.fetchone(sql, (channel_id, voter_id))
        sql = "select vote from ChannelVotes where channel_id = ? and voter_id ISNULL"
        return self._db.fetchone(sql, (channel_id,))

    def getVoteForMyChannel(self, voter_id):
        return self.getVoteOnChannel(self.channelcast_db._channel_id, voter_id)

    def getDispersyId(self, channel_id, voter_id):
        """ return the dispersy_id for this vote """
        if voter_id:
            sql = "select dispersy_id from ChannelVotes where channel_id = ? and voter_id = ?"
            return self._db.fetchone(sql, (channel_id, voter_id))
        sql = "select dispersy_id from ChannelVotes where channel_id = ? and voter_id ISNULL"
        return self._db.fetchone(sql, (channel_id,))

    def getTimestamp(self, channel_id, voter_id):
        """ return the timestamp for this vote """
        if voter_id:
            sql = "select time_stamp from ChannelVotes where channel_id = ? and voter_id = ?"
            return self._db.fetchone(sql, (channel_id, voter_id))
        sql = "select time_stamp from ChannelVotes where channel_id = ? and voter_id ISNULL"
        return self._db.fetchone(sql, (channel_id,))

    def getMyVotes(self):
        if not self.my_votes:
            sql = "SELECT channel_id, vote FROM ChannelVotes WHERE voter_id ISNULL"

            self.my_votes = {}
            for channel_id, vote in self._db.fetchall(sql):
                self.my_votes[channel_id] = vote
        return self.my_votes


class ChannelCastDBHandler(BasicDBHandler):

    def __init__(self):
        try:
            db = SQLiteCacheDB.getInstance()
            BasicDBHandler.__init__(self, db, '_Channels')
            self._logger.debug("Channels: DB made")
        except:
            self._logger.error("Channels: couldn't make the table")

        self._channel_id = None
        self.my_dispersy_cid = None

        self.modification_types = dict(self._db.fetchall("SELECT name, id FROM MetaDataTypes"))
        self.id2modification = dict([(v, k) for k, v in self.modification_types.iteritems()])

        self._channel_id = self.getMyChannelId()
        self._logger.debug("Channels: my channel is %s", self._channel_id)

    def registerSession(self, session):
        self.session = session

        self.peer_db = PeerDBHandler.getInstance()
        self.votecast_db = VoteCastDBHandler.getInstance()
        self.torrent_db = TorrentDBHandler.getInstance()

        def updateNrTorrents():
            rows = self.getChannelNrTorrents(50)
            update = "UPDATE _Channels SET nr_torrents = ? WHERE id = ?"
            self._db.executemany(update, rows)

            rows = self.getChannelNrTorrentsLatestUpdate(50)
            update = "UPDATE _Channels SET nr_torrents = ?, modified = ? WHERE id = ?"
            self._db.executemany(update, rows)

        self._pending_tasks["updateNrTorrents"] = lc = LoopingCall(updateNrTorrents)
        lc.start(300, now=False)

    # dispersy helper functions
    def _get_my_dispersy_cid(self):
        if not self.my_dispersy_cid:
            from Tribler.community.channel.community import ChannelCommunity

            for community in self.session.lm.dispersy.get_communities():
                if isinstance(community, ChannelCommunity) and community.master_member and community.master_member.private_key:
                    self.my_dispersy_cid = community.cid
                    break

        return self.my_dispersy_cid

    def getDispersyCIDFromChannelId(self, channel_id):
        return self._db.fetchone(u"SELECT dispersy_cid FROM Channels WHERE id = ?", (channel_id,))

    def getChannelIdFromDispersyCID(self, dispersy_cid):
        return self._db.fetchone(u"SELECT id FROM Channels WHERE dispersy_cid = ?", (dispersy_cid,))

    def getCountMaxFromChannelId(self, channel_id):
        sql = u"SELECT COUNT(*), MAX(inserted) FROM ChannelTorrents WHERE channel_id = ? LIMIT 1"
        return self._db.fetchone(sql, (channel_id,))

    def drop_all_newer(self, dispersy_id):
        sql = "DELETE FROM _TorrentMarkings WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _ChannelVotes WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _ChannelMetaData WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _Moderations WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _Comments WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _PlaylistTorrents WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _Playlists WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

        sql = "DELETE FROM _ChannelTorrents WHERE dipsersy_id > ?"
        self._db.execute_write(sql, (dispersy_id))

    def on_channel_from_dispersy(self, dispersy_cid, peer_id, name, description):
        if isinstance(dispersy_cid, (str)):
            _dispersy_cid = buffer(dispersy_cid)
        else:
            _dispersy_cid = dispersy_cid

        # merge channels if we detect upgrade from old-channelcast to new-dispersy-channelcast
        get_channel = "SELECT id FROM Channels Where peer_id = ? and dispersy_cid == -1"
        channel_id = self._db.fetchone(get_channel, (peer_id,))

        if channel_id:  # update this channel
            update_channel = "UPDATE _Channels SET dispersy_cid = ?, name = ?, description = ? WHERE id = ?"
            self._db.execute_write(update_channel, (_dispersy_cid, name, description, channel_id))

            self.notifier.notify(NTFY_CHANNELCAST, NTFY_UPDATE, channel_id)

        else:
            get_channel = "SELECT id FROM Channels Where dispersy_cid = ?"
            channel_id = self._db.fetchone(get_channel, (_dispersy_cid,))

            if channel_id:
                update_channel = "UPDATE _Channels SET name = ?, description = ?, peer_id = ? WHERE dispersy_cid = ?"
                self._db.execute_write(update_channel, (name, description, peer_id, _dispersy_cid))

            else:
                # insert channel
                insert_channel = "INSERT INTO _Channels (dispersy_cid, peer_id, name, description) VALUES (?, ?, ?, ?); SELECT last_insert_rowid();"
                channel_id = self._db.fetchone(insert_channel, (_dispersy_cid, peer_id, name, description))

            self.notifier.notify(NTFY_CHANNELCAST, NTFY_INSERT, channel_id)

        if not self._channel_id and self._get_my_dispersy_cid() == dispersy_cid:
            self._channel_id = channel_id
            self.notifier.notify(NTFY_CHANNELCAST, NTFY_CREATE, channel_id)
        return channel_id

    def on_channel_modification_from_dispersy(self, channel_id, modification_type, modification_value):
        if modification_type in ['name', 'description']:
            update_channel = "UPDATE _Channels Set " + modification_type + " = ?, modified = ? WHERE id = ?"
            self._db.execute_write(update_channel, (modification_value, long(time()), channel_id))

            self.notifier.notify(NTFY_CHANNELCAST, NTFY_MODIFIED, channel_id)

    def on_torrents_from_dispersy(self, torrentlist):
        infohashes = [torrent[3] for torrent in torrentlist]
        torrent_ids, inserted = self.torrent_db.addOrGetTorrentIDSReturn(infohashes)

        insert_data = []
        updated_channels = {}
        for i, torrent in enumerate(torrentlist):
            channel_id, dispersy_id, peer_id, infohash, timestamp, name, files, trackers = torrent
            torrent_id = torrent_ids[i]

            # if new or not yet collected
            if infohash in inserted:
                self.torrent_db.addExternalTorrentNoDef(infohash, name, files, trackers, timestamp, "DISP", {'dispersy_id': dispersy_id})

            insert_data.append((dispersy_id, torrent_id, channel_id, peer_id, name, timestamp))
            updated_channels[channel_id] = updated_channels.get(channel_id, 0) + 1

        if len(insert_data) > 0:
            sql_insert_torrent = "INSERT INTO _ChannelTorrents (dispersy_id, torrent_id, channel_id, peer_id, name, time_stamp) VALUES (?,?,?,?,?,?)"
            self._db.executemany(sql_insert_torrent, insert_data)

        sql_update_channel = "UPDATE _Channels SET modified = strftime('%s','now'), nr_torrents = nr_torrents+? WHERE id = ?"
        update_channels = [(new_torrents, channel_id) for channel_id, new_torrents in updated_channels.iteritems()]
        self._db.executemany(sql_update_channel, update_channels)

        for channel_id in updated_channels.keys():
            self.notifier.notify(NTFY_CHANNELCAST, NTFY_UPDATE, channel_id)

    def on_remove_torrent_from_dispersy(self, channel_id, dispersy_id, redo):
        sql = "UPDATE _ChannelTorrents SET deleted_at = ? WHERE channel_id = ? and dispersy_id = ?"

        if redo:
            deleted_at = None
        else:
            deleted_at = long(time())
        self._db.execute_write(sql, (deleted_at, channel_id, dispersy_id))

        self.notifier.notify(NTFY_CHANNELCAST, NTFY_UPDATE, channel_id)

    def on_torrent_modification_from_dispersy(self, channeltorrent_id, modification_type, modification_value):
        if modification_type in ['name', 'description']:
            update_torrent = "UPDATE _ChannelTorrents SET " + modification_type + " = ?, modified = ? WHERE id = ?"
            self._db.execute_write(update_torrent, (modification_value, long(time()), channeltorrent_id))

            sql = "Select infohash From Torrent, ChannelTorrents Where Torrent.torrent_id = ChannelTorrents.torrent_id And ChannelTorrents.id = ?"
            infohash = self._db.fetchone(sql, (channeltorrent_id,))

            if infohash:
                infohash = str2bin(infohash)
                self.notifier.notify(NTFY_TORRENTS, NTFY_UPDATE, infohash)

        elif modification_type in ['swift-url']:
            sql = "Select infohash From Torrent, ChannelTorrents Where Torrent.torrent_id = ChannelTorrents.torrent_id And ChannelTorrents.id = ?"
            infohash = self._db.fetchone(sql, (channeltorrent_id,))

            if infohash:
                from Tribler.Core.Swift.SwiftDef import SwiftDef

                sdef = SwiftDef.load_from_url(modification_value)
                roothash = bin2str(sdef.get_roothash())
                # If a user created two .torrents from the same set of files with different swarmnames we have two infohashes pointing to the same roothash.
                update_torrent = "UPDATE or IGNORE Torrent SET swift_hash = ? WHERE infohash = ?"
                self._db.execute_write(update_torrent, (roothash, infohash))

    def addOrGetChannelTorrentID(self, channel_id, infohash):
        torrent_id = self.torrent_db.addOrGetTorrentID(infohash)

        sql = "SELECT id FROM _ChannelTorrents WHERE torrent_id = ? AND channel_id = ?"
        channeltorrent_id = self._db.fetchone(sql, (torrent_id, channel_id))
        if not channeltorrent_id:
            insert_torrent = "INSERT OR IGNORE INTO _ChannelTorrents (dispersy_id, torrent_id, channel_id, time_stamp) VALUES (?,?,?,?);"
            self._db.execute_write(insert_torrent, (-1, torrent_id, channel_id, -1))

            channeltorrent_id = self._db.fetchone(sql, (torrent_id, channel_id))
        return channeltorrent_id

    def hasTorrent(self, channel_id, infohash):
        torrent_id = self.torrent_db.getTorrentID(infohash)
        if torrent_id:
            sql = "SELECT id FROM ChannelTorrents WHERE torrent_id = ? and channel_id = ?"
            channeltorrent_id = self._db.fetchone(sql, (torrent_id, channel_id))
            if channeltorrent_id:
                return True
        return False

    def hasTorrents(self, channel_id, infohashes):
        returnAr = []
        torrent_ids = self.torrent_db.getTorrentIDS(infohashes)

        for i in range(len(infohashes)):
            if torrent_ids[i] == None:
                returnAr.append(False)

            else:
                sql = "SELECT id FROM ChannelTorrents WHERE torrent_id = ? AND channel_id = ? AND dispersy_id <> -1"
                channeltorrent_id = self._db.fetchone(sql, (torrent_ids[i], channel_id))
                returnAr.append(True if channeltorrent_id else False)
        return returnAr

    def playlistHasTorrent(self, playlist_id, channeltorrent_id):
        sql = "SELECT id FROM PlaylistTorrents WHERE playlist_id = ? AND channeltorrent_id = ?"
        playlisttorrent_id = self._db.fetchone(sql, (playlist_id, channeltorrent_id))
        if playlisttorrent_id:
            return True
        return False

    # dispersy receiving comments
    def on_comment_from_dispersy(self, channel_id, dispersy_id, mid_global_time, peer_id, comment, timestamp, reply_to, reply_after, playlist_dispersy_id, infohash):
        # both reply_to and reply_after could be loose pointers to not yet received dispersy message
        if isinstance(reply_to, (str)):
            reply_to = buffer(reply_to)

        if isinstance(reply_after, (str)):
            reply_after = buffer(reply_after)
        mid_global_time = buffer(mid_global_time)

        sql = "INSERT OR REPLACE INTO _Comments (channel_id, dispersy_id, peer_id, comment, reply_to_id, reply_after_id, time_stamp) VALUES (?, ?, ?, ?, ?, ?, ?); SELECT last_insert_rowid();"
        comment_id = self._db.fetchone(sql, (channel_id, dispersy_id, peer_id, comment, reply_to, reply_after, timestamp))

        if playlist_dispersy_id or infohash:
            if playlist_dispersy_id:
                sql = "SELECT id FROM Playlists WHERE dispersy_id = ?"
                playlist_id = self._db.fetchone(sql, (playlist_dispersy_id,))

                sql = "INSERT INTO CommentPlaylist (comment_id, playlist_id) VALUES (?, ?)"
                self._db.execute_write(sql, (comment_id, playlist_id))

            if infohash:
                channeltorrent_id = self.addOrGetChannelTorrentID(channel_id, infohash)

                sql = "INSERT INTO CommentTorrent (comment_id, channeltorrent_id) VALUES (?, ?)"
                self._db.execute_write(sql, (comment_id, channeltorrent_id))

        # try fo fix loose reply_to and reply_after pointers
        sql = "UPDATE _Comments SET reply_to_id = ? WHERE reply_to_id = ?"
        self._db.execute_write(sql, (dispersy_id, mid_global_time))
        sql = "UPDATE _Comments SET reply_after_id = ? WHERE reply_after_id = ?"
        self._db.execute_write(sql, (dispersy_id, mid_global_time))

        self.notifier.notify(NTFY_COMMENTS, NTFY_INSERT, channel_id)
        if playlist_dispersy_id:
            self.notifier.notify(NTFY_COMMENTS, NTFY_INSERT, playlist_id)
        if infohash:
            self.notifier.notify(NTFY_COMMENTS, NTFY_INSERT, infohash)

    # dispersy removing comments
    def on_remove_comment_from_dispersy(self, channel_id, dispersy_id, infohash=None, redo=False):
        sql = "UPDATE _Comments SET deleted_at = ? WHERE dispersy_id = ?"

        if redo:
            deleted_at = None
            self._db.execute_write(sql, (deleted_at, dispersy_id))

            self.notifier.notify(NTFY_COMMENTS, NTFY_INSERT, channel_id)
            if infohash:
                self.notifier.notify(NTFY_COMMENTS, NTFY_INSERT, infohash)
        else:
            deleted_at = long(time())
            self._db.execute_write(sql, (deleted_at, dispersy_id))

            self.notifier.notify(NTFY_COMMENTS, NTFY_DELETE, channel_id)
            if infohash:
                self.notifier.notify(NTFY_COMMENTS, NTFY_DELETE, infohash)

    # dispersy receiving, modifying playlists
    def on_playlist_from_dispersy(self, channel_id, dispersy_id, peer_id, name, description):
        sql = "INSERT OR REPLACE INTO _Playlists (channel_id, dispersy_id,  peer_id, name, description) VALUES (?, ?, ?, ?, ?)"
        self._db.execute_write(sql, (channel_id, dispersy_id, peer_id, name, description))

        self.notifier.notify(NTFY_PLAYLISTS, NTFY_INSERT, channel_id)

    def on_remove_playlist_from_dispersy(self, channel_id, dispersy_id, redo):
        sql = "UPDATE _Playlists SET deleted_at = ? WHERE channel_id = ? and dispersy_id = ?"

        if redo:
            deleted_at = None
            self._db.execute_write(sql, (deleted_at, channel_id, dispersy_id))
            self.notifier.notify(NTFY_PLAYLISTS, NTFY_INSERT, channel_id)

        else:
            deleted_at = long(time())
            self._db.execute_write(sql, (deleted_at, channel_id, dispersy_id))
            self.notifier.notify(NTFY_PLAYLISTS, NTFY_DELETE, channel_id)

    def on_playlist_modification_from_dispersy(self, playlist_id, modification_type, modification_value):
        if modification_type in ['name', 'description']:
            update_playlist = "UPDATE _Playlists Set " + modification_type + " = ?, modified = ? WHERE id = ?"
            self._db.execute_write(update_playlist, (modification_value, long(time()), playlist_id))

            self.notifier.notify(NTFY_PLAYLISTS, NTFY_UPDATE, playlist_id)

    def on_playlist_torrent(self, dispersy_id, playlist_dispersy_id, peer_id, infohash):
        get_playlist = "SELECT id, channel_id FROM _Playlists WHERE dispersy_id = ?"
        playlist_id, channel_id = self._db.fetchone(get_playlist, (playlist_dispersy_id,))

        channeltorrent_id = self.addOrGetChannelTorrentID(channel_id, infohash)
        sql = "INSERT INTO _PlaylistTorrents (dispersy_id, playlist_id, peer_id, channeltorrent_id) VALUES (?,?,?,?)"
        self._db.execute_write(sql, (dispersy_id, playlist_id, peer_id, channeltorrent_id))

        self.notifier.notify(NTFY_PLAYLISTS, NTFY_UPDATE, playlist_id, infohash)

    def on_remove_playlist_torrent(self, channel_id, playlist_dispersy_id, infohash, redo):
        get_playlist = "SELECT id FROM _Playlists WHERE dispersy_id = ? AND channel_id = ?"
        playlist_id = self._db.fetchone(get_playlist, (playlist_dispersy_id, channel_id))

        if playlist_id:
            get_channeltorent_id = "SELECT id FROM _ChannelTorrents, Torrent WHERE _ChannelTorrents.torrent_id = Torrent.torrent_id AND Torrent.infohash = ?"
            channeltorrent_id = self._db.fetchone(get_channeltorent_id, (bin2str(infohash),))

            if channeltorrent_id:
                sql = "UPDATE _PlaylistTorrents SET deleted_at = ? WHERE playlist_id = ? AND channeltorrent_id = ?"

                if redo:
                    deleted_at = None
                else:
                    deleted_at = long(time())
                self._db.execute_write(sql, (deleted_at, playlist_id, channeltorrent_id))

            self.notifier.notify(NTFY_PLAYLISTS, NTFY_UPDATE, playlist_id)

    def on_metadata_from_dispersy(self, type, channeltorrent_id, playlist_id, channel_id, dispersy_id, peer_id, mid_global_time, modification_type_id, modification_value, timestamp, prev_modification_id, prev_modification_global_time):
        if isinstance(prev_modification_id, (str)):
            prev_modification_id = buffer(prev_modification_id)

        sql = "INSERT OR REPLACE INTO _ChannelMetaData (dispersy_id, channel_id, peer_id, type_id, value, time_stamp, prev_modification, prev_global_time) VALUES (?, ?, ?, ?, ?, ?, ?, ?); SELECT last_insert_rowid();"
        metadata_id = self._db.fetchone(sql, (dispersy_id, channel_id, peer_id, modification_type_id, modification_value, timestamp, prev_modification_id, prev_modification_global_time))

        if channeltorrent_id:
            sql = "INSERT INTO MetaDataTorrent (metadata_id, channeltorrent_id) VALUES (?,?)"
            self._db.execute_write(sql, (metadata_id, channeltorrent_id))

            self.notifier.notify(NTFY_MODIFICATIONS, NTFY_INSERT, channeltorrent_id)

        if playlist_id:
            sql = "INSERT INTO MetaDataPlaylist (metadata_id, playlist_id) VALUES (?,?)"
            self._db.execute_write(sql, (metadata_id, playlist_id))

            self.notifier.notify(NTFY_MODIFICATIONS, NTFY_INSERT, playlist_id)
        self.notifier.notify(NTFY_MODIFICATIONS, NTFY_INSERT, channel_id)

        # try fo fix loose reply_to and reply_after pointers
        sql = "UPDATE _ChannelMetaData SET prev_modification = ? WHERE prev_modification = ?;"
        self._db.execute_write(sql, (dispersy_id, buffer(mid_global_time)))

    def on_remove_metadata_from_dispersy(self, channel_id, dispersy_id, redo):
        sql = "UPDATE _ChannelMetaData SET deleted_at = ? WHERE dispersy_id = ? AND channel_id = ?"

        if redo:
            deleted_at = None
        else:
            deleted_at = long(time())
        self._db.execute_write(sql, (deleted_at, dispersy_id, channel_id))

    def on_moderation(self, channel_id, dispersy_id, peer_id, by_peer_id, cause, message, timestamp, severity):
        sql = "INSERT OR REPLACE INTO _Moderations (dispersy_id, channel_id, peer_id, by_peer_id, message, cause, time_stamp, severity) VALUES (?,?,?,?,?,?,?,?)"
        self._db.execute_write(sql, (dispersy_id, channel_id, peer_id, by_peer_id, message, cause, timestamp, severity))

        self.notifier.notify(NTFY_MODERATIONS, NTFY_INSERT, channel_id)

    def on_remove_moderation(self, channel_id, dispersy_id, redo):
        sql = "UPDATE _Moderations SET deleted_at = ? WHERE dispersy_id = ? AND channel_id = ?"
        if redo:
            deleted_at = None
        else:
            deleted_at = long(time())
        self._db.execute_write(sql, (deleted_at, dispersy_id, channel_id))

    def on_mark_torrent(self, channel_id, dispersy_id, global_time, peer_id, infohash, type, timestamp):
        channeltorrent_id = self.addOrGetChannelTorrentID(channel_id, infohash)

        if peer_id:
            select = "SELECT global_time FROM TorrentMarkings WHERE channeltorrent_id = ? AND peer_id = ?"
            prev_global_time = self._db.fetchone(select, (channeltorrent_id, peer_id))
        else:
            select = "SELECT global_time FROM TorrentMarkings WHERE channeltorrent_id = ? AND peer_id IS NULL"
            prev_global_time = self._db.fetchone(select, (channeltorrent_id,))

        if prev_global_time:
            if global_time > prev_global_time:
                if peer_id:
                    sql = "DELETE FROM _TorrentMarkings WHERE channeltorrent_id = ? AND peer_id = ?"
                    self._db.execute_write(sql, (channeltorrent_id, peer_id))
                else:
                    sql = "DELETE FROM _TorrentMarkings WHERE channeltorrent_id = ? AND peer_id IS NULL"
                    self._db.execute_write(sql, (channeltorrent_id,))
            else:
                return

        sql = "INSERT INTO _TorrentMarkings (dispersy_id, global_time, channeltorrent_id, peer_id, type, time_stamp) VALUES (?,?,?,?,?,?)"
        self._db.execute_write(sql, (dispersy_id, global_time, channeltorrent_id, peer_id, type, timestamp))
        self.notifier.notify(NTFY_MARKINGS, NTFY_INSERT, channeltorrent_id)

    def on_remove_mark_torrent(self, channel_id, dispersy_id, redo):
        sql = "UPDATE _TorrentMarkings SET deleted_at = ? WHERE dispersy_id = ?"

        if redo:
            deleted_at = None
        else:
            deleted_at = long(time())
        self._db.execute_write(sql, (deleted_at, dispersy_id))

    def on_dynamic_settings(self, channel_id):
        self.notifier.notify(NTFY_CHANNELCAST, NTFY_STATE, channel_id)

    def getNrTorrentsDownloaded(self, channel_id):
        sql = "select count(*) from MyPreference, ChannelTorrents where MyPreference.torrent_id = ChannelTorrents.torrent_id and ChannelTorrents.channel_id = ? LIMIT 1"
        return self._db.fetchone(sql, (channel_id,))

    def getChannelNrTorrents(self, limit=None):
        if limit:
            sql = "select count(torrent_id), channel_id from Channels, ChannelTorrents WHERE Channels.id = ChannelTorrents.channel_id AND dispersy_cid <>  -1 GROUP BY channel_id ORDER BY RANDOM() LIMIT ?"
            return self._db.fetchall(sql, (limit,))

        sql = "select count(torrent_id), channel_id from Channels, ChannelTorrents WHERE Channels.id = ChannelTorrents.channel_id AND dispersy_cid <>  -1 GROUP BY channel_id"
        return self._db.fetchall(sql)

    def getChannelNrTorrentsLatestUpdate(self, limit=None):
        if limit:
            sql = "select count(CollectedTorrent.torrent_id), max(ChannelTorrents.time_stamp), channel_id from Channels, ChannelTorrents, CollectedTorrent WHERE ChannelTorrents.torrent_id = CollectedTorrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND dispersy_cid == -1 GROUP BY channel_id ORDER BY RANDOM() LIMIT ?"
            return self._db.fetchall(sql, (limit,))

        sql = "select count(CollectedTorrent.torrent_id), max(ChannelTorrents.time_stamp), channel_id from Channels, ChannelTorrents, CollectedTorrent WHERE ChannelTorrents.torrent_id = CollectedTorrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND dispersy_cid == -1 GROUP BY channel_id"
        return self._db.fetchall(sql)

    def getNrChannels(self):
        sql = "select count(DISTINCT id) from Channels LIMIT 1"
        return self._db.fetchone(sql)

    def getPermidForChannel(self, channel_id):
        sql = "SELECT permid FROM Peer, Channels WHERE Channels.peer_id = Peer.peer_id AND Channels.id = ?"
        return self._db.fetchone(sql, (channel_id,))

    def getRecentAndRandomTorrents(self, NUM_OWN_RECENT_TORRENTS=15, NUM_OWN_RANDOM_TORRENTS=10, NUM_OTHERS_RECENT_TORRENTS=15, NUM_OTHERS_RANDOM_TORRENTS=10, NUM_OTHERS_DOWNLOADED=5):
        torrent_dict = {}

        least_recent = -1
        sql = "select dispersy_cid, infohash, time_stamp from ChannelTorrents, Channels, Torrent where ChannelTorrents.torrent_id = Torrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND ChannelTorrents.channel_id==? and ChannelTorrents.dispersy_id <> -1 order by time_stamp desc limit ?"
        myrecenttorrents = self._db.fetchall(sql, (self._channel_id, NUM_OWN_RECENT_TORRENTS))
        for cid, infohash, timestamp in myrecenttorrents:
            torrent_dict.setdefault(str(cid), set()).add(str2bin(infohash))
            least_recent = timestamp

        if len(myrecenttorrents) == NUM_OWN_RECENT_TORRENTS and least_recent != -1:
            sql = "select dispersy_cid, infohash from ChannelTorrents, Channels, Torrent where ChannelTorrents.torrent_id = Torrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND ChannelTorrents.channel_id==? and time_stamp<? and ChannelTorrents.dispersy_id <> -1 order by random() limit ?"
            myrandomtorrents = self._db.fetchall(sql, (self._channel_id, least_recent, NUM_OWN_RANDOM_TORRENTS))
            for cid, infohash, _ in myrecenttorrents:
                torrent_dict.setdefault(str(cid), set()).add(str2bin(infohash))

            for cid, infohash in myrandomtorrents:
                torrent_dict.setdefault(str(cid), set()).add(str2bin(infohash))

        nr_records = sum(len(torrents) for torrents in torrent_dict.values())
        additionalSpace = (NUM_OWN_RECENT_TORRENTS + NUM_OWN_RANDOM_TORRENTS) - nr_records

        if additionalSpace > 0:
            NUM_OTHERS_RECENT_TORRENTS += additionalSpace / 2
            NUM_OTHERS_RANDOM_TORRENTS += additionalSpace - (additionalSpace / 2)

            # Niels 6-12-2011: we should substract additionalspace from recent and random, otherwise the totals will not be correct.
            NUM_OWN_RECENT_TORRENTS -= additionalSpace / 2
            NUM_OWN_RANDOM_TORRENTS -= additionalSpace - (additionalSpace / 2)

        least_recent = -1
        sql = "select dispersy_cid, infohash, time_stamp from ChannelTorrents, Channels, Torrent where ChannelTorrents.torrent_id = Torrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND ChannelTorrents.channel_id in (select channel_id from ChannelVotes where voter_id ISNULL and vote=2) and ChannelTorrents.dispersy_id <> -1 order by time_stamp desc limit ?"
        othersrecenttorrents = self._db.fetchall(sql, (NUM_OTHERS_RECENT_TORRENTS,))
        for cid, infohash, timestamp in othersrecenttorrents:
            torrent_dict.setdefault(str(cid), set()).add(str2bin(infohash))
            least_recent = timestamp

        if othersrecenttorrents and len(othersrecenttorrents) == NUM_OTHERS_RECENT_TORRENTS and least_recent != -1:
            sql = "select dispersy_cid, infohash from ChannelTorrents, Channels, Torrent where ChannelTorrents.torrent_id = Torrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND ChannelTorrents.channel_id in (select channel_id from ChannelVotes where voter_id ISNULL and vote=2) and time_stamp < ? and ChannelTorrents.dispersy_id <> -1 order by random() limit ?"
            othersrandomtorrents = self._db.fetchall(sql, (least_recent, NUM_OTHERS_RANDOM_TORRENTS))
            for cid, infohash in othersrandomtorrents:
                torrent_dict.setdefault(str(cid), set()).add(str2bin(infohash))

        twomonthsago = long(time() - 5259487)
        nr_records = sum(len(torrents) for torrents in torrent_dict.values())
        additionalSpace = (NUM_OWN_RECENT_TORRENTS + NUM_OWN_RANDOM_TORRENTS + NUM_OTHERS_RECENT_TORRENTS + NUM_OTHERS_RANDOM_TORRENTS) - nr_records
        NUM_OTHERS_DOWNLOADED += additionalSpace

        sql = "select dispersy_cid, infohash from ChannelTorrents, Channels, Torrent where ChannelTorrents.torrent_id = Torrent.torrent_id AND Channels.id = ChannelTorrents.channel_id AND ChannelTorrents.channel_id in (select distinct channel_id from ChannelTorrents where torrent_id in (select torrent_id from MyPreference)) and ChannelTorrents.dispersy_id <> -1 and Channels.modified > ? order by time_stamp desc limit ?"
        interesting_records = self._db.fetchall(sql, (twomonthsago, NUM_OTHERS_DOWNLOADED))
        for cid, infohash in interesting_records:
            torrent_dict.setdefault(str(cid), set()).add(str2bin(infohash))

        return torrent_dict

    def getRandomTorrents(self, channel_id, limit=15):
        sql = "select infohash from ChannelTorrents, Torrent where ChannelTorrents.torrent_id = Torrent.torrent_id AND channel_id = ? ORDER BY RANDOM() LIMIT ?"

        returnar = []
        for infohash, in self._db.fetchall(sql, (channel_id, limit)):
            returnar.append(str2bin(infohash))
        return returnar

    def getTorrentFromChannelId(self, channel_id, infohash, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND channel_id = ? AND infohash = ?"
        result = self._db.fetchone(sql, (channel_id, bin2str(infohash)))

        return self.__fixTorrent(keys, result)

    def getChannelTorrents(self, infohash, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND infohash = ?"
        results = self._db.fetchall(sql, (bin2str(infohash),))

        return self.__fixTorrents(keys, results)

    def getTorrentFromChannelTorrentId(self, channeltorrent_id, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND ChannelTorrents.id = ?"
        result = self._db.fetchone(sql, (channeltorrent_id,))
        if not result:
            self._logger.info("COULD NOT FIND CHANNELTORRENT_ID %s", channeltorrent_id)
        else:
            return self.__fixTorrent(keys, result)

    def getTorrentsFromChannelId(self, channel_id, isDispersy, keys, limit=None):
        if isDispersy:
            sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id"
        else:
            sql = "SELECT " + ", ".join(keys) + " FROM CollectedTorrent as Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id"

        if channel_id:
            sql += " AND channel_id = ?"
        sql += " ORDER BY time_stamp DESC"

        if limit:
            sql += " LIMIT %d" % limit

        if channel_id:
            results = self._db.fetchall(sql, (channel_id,))
        else:
            results = self._db.fetchall(sql)

        if limit is None and channel_id:
            # use this possibility to update nrtorrent in channel

            if 'time_stamp' in keys and len(results) > 0:
                update = "UPDATE _Channels SET nr_torrents = ?, modified = ? WHERE id = ?"
                self._db.execute_write(update, (len(results), results[0][keys.index('time_stamp')], channel_id))
            else:
                # use this possibility to update nrtorrent in channel
                update = "UPDATE _Channels SET nr_torrents = ? WHERE id = ?"
                self._db.execute_write(update, (len(results), channel_id))

        return self.__fixTorrents(keys, results)

    def getRecentReceivedTorrentsFromChannelId(self, channel_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND channel_id = ? ORDER BY inserted DESC"
        if limit:
            sql += " LIMIT %d" % limit
        results = self._db.fetchall(sql, (channel_id,))
        return self.__fixTorrents(keys, results)

    def getRecentModificationsFromChannelId(self, channel_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM ChannelMetaData LEFT JOIN MetaDataTorrent ON ChannelMetaData.id = MetaDataTorrent.metadata_id LEFT JOIN Moderations ON Moderations.cause = ChannelMetaData.dispersy_id WHERE ChannelMetaData.channel_id = ? ORDER BY -Moderations.time_stamp ASC, ChannelMetaData.inserted DESC"
        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (channel_id,))

    def getRecentModerationsFromChannel(self, channel_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Moderations, MetaDataTorrent, ChannelMetaData WHERE Moderations.cause = ChannelMetaData.dispersy_id AND ChannelMetaData.id = MetaDataTorrent.metadata_id AND Moderations.channel_id = ? ORDER BY Moderations.inserted DESC"
        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (channel_id,))

    def getRecentMarkingsFromChannel(self, channel_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM TorrentMarkings, ChannelTorrents WHERE TorrentMarkings.channeltorrent_id = ChannelTorrents.id AND ChannelTorrents.channel_id = ? ORDER BY TorrentMarkings.time_stamp DESC"
        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (channel_id,))

    def getMostPopularTorrentsFromChannel(self, channel_id, isDispersy, keys, limit=None):
        if isDispersy:
            sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND channel_id = ? GROUP BY Torrent.torrent_id ORDER BY ChannelTorrents.time_stamp DESC"
        else:
            sql = "SELECT " + ", ".join(keys) + " FROM CollectedTorrent as Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND channel_id = ? GROUP BY Torrent.torrent_id ORDER BY ChannelTorrents.time_stamp DESC"

        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (channel_id,))

    def getTorrentsFromPlaylist(self, playlist_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents, PlaylistTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND ChannelTorrents.id = PlaylistTorrents.channeltorrent_id AND playlist_id = ? ORDER BY time_stamp DESC"
        if limit:
            sql += " LIMIT %d" % limit
        results = self._db.fetchall(sql, (playlist_id,))
        return self.__fixTorrents(keys, results)

    def getTorrentFromPlaylist(self, playlist_id, infohash, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents, PlaylistTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND ChannelTorrents.id = PlaylistTorrents.channeltorrent_id AND playlist_id = ? AND infohash = ?"
        result = self._db.fetchone(sql, (playlist_id, bin2str(infohash)))

        return self.__fixTorrent(keys, result)

    def getRecentTorrentsFromPlaylist(self, playlist_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents, PlaylistTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND ChannelTorrents.id = PlaylistTorrents.channeltorrent_id AND playlist_id = ? ORDER BY inserted DESC"
        if limit:
            sql += " LIMIT %d" % limit
        results = self._db.fetchall(sql, (playlist_id,))
        return self.__fixTorrents(keys, results)

    def getRecentModificationsFromPlaylist(self, playlist_id, keys, limit=None):
        playlistKeys = keys[:]
        if 'MetaDataTorrent.channeltorrent_id' in playlistKeys:
            playlistKeys[playlistKeys.index('MetaDataTorrent.channeltorrent_id')] = '""'

        sql = "SELECT " + ", ".join(playlistKeys) + " FROM MetaDataPlaylist, ChannelMetaData LEFT JOIN Moderations ON Moderations.cause = ChannelMetaData.dispersy_id WHERE MetaDataPlaylist.metadata_id = ChannelMetaData.id AND playlist_id = ?"
        if limit:
            sql += " LIMIT %d" % limit
        playlist_modifications = self._db.fetchall(sql, (playlist_id,))

        sql = "SELECT " + ", ".join(keys) + " FROM MetaDataTorrent, ChannelMetaData, PlaylistTorrents LEFT JOIN Moderations ON Moderations.cause = ChannelMetaData.dispersy_id WHERE MetaDataTorrent.metadata_id = ChannelMetaData.id AND PlaylistTorrents.channeltorrent_id = MetaDataTorrent.channeltorrent_id AND playlist_id = ?"
        if limit:
            sql += " LIMIT %d" % limit
        torrent_modifications = self._db.fetchall(sql, (playlist_id,))

        # merge two lists
        orderIndex = keys.index('ChannelMetaData.time_stamp')
        revertIndex = keys.index('Moderations.time_stamp')
        data = [(row[revertIndex], row[orderIndex], row) for row in playlist_modifications]
        data += [(row[revertIndex], row[orderIndex], row) for row in torrent_modifications]
        data.sort(reverse=True)

        if limit:
            data = data[:limit]
        data = [item for _, _, item in data]
        return data

    def getRecentModerationsFromPlaylist(self, playlist_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Moderations, MetaDataTorrent, ChannelMetaData, PlaylistTorrents WHERE Moderations.cause = ChannelMetaData.dispersy_id AND ChannelMetaData.id = MetaDataTorrent.metadata_id AND MetaDataTorrent.channeltorrent_id = PlaylistTorrents.channeltorrent_id AND PlaylistTorrents.playlist_id = ? ORDER BY Moderations.inserted DESC"
        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (playlist_id,))

    def getRecentMarkingsFromPlaylist(self, playlist_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM TorrentMarkings, PlaylistTorrents, ChannelTorrents WHERE TorrentMarkings.channeltorrent_id = PlaylistTorrents.channeltorrent_id AND ChannelTorrents.id = PlaylistTorrents.channeltorrent_id AND PlaylistTorrents.playlist_id = ? AND ChannelTorrents.dispersy_id <> -1 ORDER BY TorrentMarkings.time_stamp DESC"
        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (playlist_id,))

    def getTorrentsNotInPlaylist(self, channel_id, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND channel_id = ? And ChannelTorrents.id NOT IN (Select channeltorrent_id From PlaylistTorrents) ORDER BY time_stamp DESC"
        results = self._db.fetchall(sql, (channel_id,))
        return self.__fixTorrents(keys, results)

    def getPlaylistForTorrent(self, channeltorrent_id, keys):
        sql = "SELECT " + ", ".join(keys) + ", count(DISTINCT channeltorrent_id) FROM Playlists, PlaylistTorrents WHERE Playlists.id = PlaylistTorrents.playlist_id AND channeltorrent_id = ?"
        result = self._db.fetchone(sql, (channeltorrent_id,))
        # Niels: 29-02-2012 due to the count this always returns one row, check count to return None if playlist was actually not found.
        if result[-1]:
            return result

    def getPlaylistsForTorrents(self, torrent_ids, keys):
        torrent_ids = " ,".join(map(str, torrent_ids))

        sql = "SELECT channeltorrent_id, " + ", ".join(keys) + ", count(DISTINCT channeltorrent_id) FROM Playlists, PlaylistTorrents WHERE Playlists.id = PlaylistTorrents.playlist_id AND channeltorrent_id IN (" + torrent_ids + ") GROUP BY Playlists.id"
        return self._db.fetchall(sql)

    def __fixTorrent(self, keys, torrent):
        if len(keys) == 1:
            if keys[0] == 'infohash':
                return str2bin(torrent)
            return torrent

        def fix_value(key, torrent):
            if key in keys:
                key_index = keys.index(key)
                if torrent[key_index]:
                    torrent[key_index] = str2bin(torrent[key_index])
        if torrent:
            torrent = list(torrent)
            fix_value('infohash', torrent)
            fix_value('swift_hash', torrent)
            fix_value('swift_torrent_hash', torrent)
        return torrent

    def __fixTorrents(self, keys, results):
        def fix_value(key):
            if key in keys:
                key_index = keys.index(key)
                for i in range(len(results)):
                    result = list(results[i])
                    if result[key_index]:
                        result[key_index] = str2bin(result[key_index])
                        results[i] = result
        fix_value('infohash')
        fix_value('swift_hash')
        fix_value('swift_torrent_hash')
        return results

    def getPlaylistsFromChannelId(self, channel_id, keys):
        sql = "SELECT " + ", ".join(keys) + ", count(DISTINCT ChannelTorrents.id) FROM Playlists LEFT JOIN PlaylistTorrents ON Playlists.id = PlaylistTorrents.playlist_id LEFT JOIN ChannelTorrents ON PlaylistTorrents.channeltorrent_id = ChannelTorrents.id WHERE Playlists.channel_id = ? GROUP BY Playlists.id ORDER BY Playlists.name DESC"
        return self._db.fetchall(sql, (channel_id,))

    def getPlaylist(self, playlist_id, keys):
        sql = "SELECT " + ", ".join(keys) + ", count(DISTINCT ChannelTorrents.id) FROM Playlists LEFT JOIN PlaylistTorrents ON Playlists.id = PlaylistTorrents.playlist_id LEFT JOIN ChannelTorrents ON PlaylistTorrents.channeltorrent_id = ChannelTorrents.id WHERE Playlists.id = ? GROUP BY Playlists.id"
        return self._db.fetchone(sql, (playlist_id,))

    def getCommentsFromChannelId(self, channel_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Comments LEFT JOIN Peer ON Comments.peer_id = Peer.peer_id LEFT JOIN CommentPlaylist ON Comments.id = CommentPlaylist.comment_id LEFT JOIN CommentTorrent ON Comments.id = CommentTorrent.comment_id WHERE channel_id = ? ORDER BY time_stamp DESC"
        if limit:
            sql += " LIMIT %d" % limit
        return self._db.fetchall(sql, (channel_id,))

    def getCommentsFromPlayListId(self, playlist_id, keys, limit=None):
        playlistKeys = keys[:]
        if 'CommentTorrent.channeltorrent_id' in playlistKeys:
            playlistKeys[playlistKeys.index('CommentTorrent.channeltorrent_id')] = '""'

        sql = "SELECT " + ", ".join(playlistKeys) + " FROM Comments LEFT JOIN Peer ON Comments.peer_id = Peer.peer_id LEFT JOIN CommentPlaylist ON Comments.id = CommentPlaylist.comment_id WHERE playlist_id = ?"
        if limit:
            sql += " LIMIT %d" % limit

        playlist_comments = self._db.fetchall(sql, (playlist_id,))

        sql = "SELECT " + ", ".join(keys) + " FROM Comments, CommentTorrent, PlaylistTorrents LEFT JOIN Peer ON Comments.peer_id = Peer.peer_id WHERE Comments.id = CommentTorrent.comment_id AND PlaylistTorrents.channeltorrent_id = CommentTorrent.channeltorrent_id AND playlist_id = ?"
        if limit:
            sql += " LIMIT %d" % limit

        torrent_comments = self._db.fetchall(sql, (playlist_id,))

        # merge two lists
        orderIndex = keys.index('time_stamp')
        data = [(row[orderIndex], row) for row in playlist_comments]
        data += [(row[orderIndex], row) for row in torrent_comments]
        data.sort(reverse=True)

        if limit:
            data = data[:limit]
        data = [item for _, item in data]
        return data

    def getCommentsFromChannelTorrentId(self, channeltorrent_id, keys, limit=None):
        sql = "SELECT " + ", ".join(keys) + " FROM Comments, CommentTorrent LEFT JOIN Peer ON Comments.peer_id = Peer.peer_id WHERE Comments.id = CommentTorrent.comment_id AND channeltorrent_id = ? ORDER BY time_stamp DESC"
        if limit:
            sql += " LIMIT %d" % limit

        return self._db.fetchall(sql, (channeltorrent_id,))

    def searchChannelsTorrent(self, keywords, limitChannels=None, limitTorrents=None, dispersyOnly=False):
        # search channels based on keywords
        keywords = split_into_keywords(keywords)
        keywords = [keyword for keyword in keywords if len(keyword) > 1]

        if len(keywords) > 0:
            sql = "SELECT distinct id, dispersy_cid, name FROM Channels WHERE"
            for keyword in keywords:
                sql += " name like '%" + keyword + "%' and"

            if dispersyOnly:
                sql += " dispersy_cid != '-1'"
            else:
                sql = sql[:-3]

            if limitChannels:
                sql += " LIMIT %d" % limitChannels

            channels = self._db.fetchall(sql)
            select_torrents = "SELECT infohash, ChannelTorrents.name, Torrent.name, time_stamp from Torrent, ChannelTorrents WHERE Torrent.torrent_id = ChannelTorrents.torrent_id AND channel_id = ? ORDER BY num_seeders DESC LIMIT ?"

            limitTorrents = limitTorrents or 20

            results = []
            for channel_id, dispersy_cid, name in channels:
                dispersy_cid = str(dispersy_cid)
                torrents = self._db.fetchall(select_torrents, (channel_id, limitTorrents))
                for infohash, ChTname, CoTname, time_stamp in torrents:
                    infohash = str2bin(infohash)
                    results.append((channel_id, dispersy_cid, name, infohash, ChTname or CoTname, time_stamp))
            return results
        return []

    def searchChannels(self, keywords):
        sql = "SELECT id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels WHERE"
        for keyword in keywords:
            sql += " name like '%" + keyword + "%' and"
        sql = sql[:-3]
        return self._getChannels(sql)

    def getChannel(self, channel_id):
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels WHERE id = ?"
        channels = self._getChannels(sql, (channel_id,))
        if len(channels) > 0:
            return channels[0]

    def getChannelByCID(self, channel_cid):
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels WHERE dispersy_cid = ?"
        channels = self._getChannels(sql, (buffer(channel_cid),))
        if len(channels) > 0:
            return channels[0]

    def getChannelFromPermid(self, channel_permid):
        sql = "Select C.id, C.name, C.description, C.dispersy_cid, C.modified, C.nr_torrents, C.nr_favorite, C.nr_spam FROM Channels as C, Peer WHERE C.peer_id = Peer.peer_id AND Peer.permid = ?"
        channels = self._getChannels(sql, (channel_permid,))
        if len(channels) > 0:
            return channels[0]

    def getChannels(self, channel_ids):
        channel_ids = "','".join(map(str, channel_ids))
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels WHERE id IN ('" + channel_ids + "')"
        return self._getChannels(sql)

    def getChannelsByCID(self, channel_cids):
        parameters = '?,' * len(channel_cids)
        parameters = parameters[:-1]

        channel_cids = map(buffer, channel_cids)
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels WHERE dispersy_cid IN (" + parameters + ")"
        return self._getChannels(sql, channel_cids)

    def getAllChannels(self):
        """ Returns all the channels """
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels"
        return self._getChannels(sql)

    def getNewChannels(self, updated_since=0):
        """ Returns all newest unsubscribed channels, ie the ones with no votes (positive or negative)"""
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels WHERE nr_favorite = 0 AND nr_spam = 0 AND modified > ?"
        return self._getChannels(sql, (updated_since,))

    def getLatestUpdated(self, max_nr=20):
        def channel_sort(a, b):
            # first compare local vote, spam -> return -1
            if a[7] == -1:
                return 1
            if b[7] == -1:
                return -1

            # then compare latest update
            if a[8] < b[8]:
                return 1
            if a[8] > b[8]:
                return -1
            # finally compare nr_torrents
            return cmp(a[4], b[4])

        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels Order By modified DESC Limit ?"
        return self._getChannels(sql, (max_nr,), cmpF=channel_sort)

    def getMostPopularChannels(self, max_nr=20):
        sql = "Select id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels ORDER BY nr_favorite DESC, modified DESC LIMIT ?"
        return self._getChannels(sql, (max_nr,), includeSpam=False)

    def getMySubscribedChannels(self, includeDispsersy=False):
        sql = "SELECT id, name, description, dispersy_cid, modified, nr_torrents, nr_favorite, nr_spam FROM Channels, ChannelVotes WHERE Channels.id = ChannelVotes.channel_id AND voter_id ISNULL AND vote == 2"
        if not includeDispsersy:
            sql += " AND dispersy_cid == -1"

        return self._getChannels(sql)

    def _getChannels(self, sql, args=None, cmpF=None, includeSpam=True):
        """Returns the channels based on the input sql, if the number of positive votes is less than maxvotes and the number of torrent > 0"""
        channels = []
        results = self._db.fetchall(sql, args)

        my_votes = self.votecast_db.getMyVotes()
        for id, name, description, dispersy_cid, modified, nr_torrents, nr_favorites, nr_spam in results:
            my_vote = my_votes.get(id, 0)
            if not includeSpam and my_vote < 0:
                continue
            if name.strip() == '':
                continue

            channels.append((id, str(dispersy_cid), name, description, nr_torrents, nr_favorites, nr_spam, my_vote, modified, id == self._channel_id))

        def channel_sort(a, b):
            # first compare local vote, spam -> return -1
            if a[7] == -1:
                return 1
            if b[7] == -1:
                return -1

            # then compare nr_favorites
            if a[5] < b[5]:
                return 1
            if a[5] > b[5]:
                return -1

            # then compare latest update
            if a[8] < b[8]:
                return 1
            if a[8] > b[8]:
                return -1

            # finally compare nr_torrents
            return cmp(a[4], b[4])

        if cmpF == None:
            cmpF = channel_sort
        channels.sort(cmpF)
        return channels

    def getMyChannelId(self):
        if self._channel_id:
            return self._channel_id
        return self._db.fetchone('SELECT id FROM Channels WHERE peer_id ISNULL LIMIT 1')

    def getSubscribersCount(self, channel_id):
        """returns the number of subscribers in integer format"""

        nr_favorites, nr_spam = self.votecast_db.getPosNegVotes(channel_id)
        return nr_favorites

    def getTorrentMarkings(self, channeltorrent_id):
        counts = {}
        sql = "SELECT type, peer_id FROM TorrentMarkings WHERE channeltorrent_id = ?"
        for type, peer_id in self._db.fetchall(sql, (channeltorrent_id,)):
            if type not in counts:
                counts[type] = [type, 0, False]
            counts[type][1] += 1
            if not peer_id:
                counts[type][2] = True
        return counts.values()

    def getTorrentModifications(self, channeltorrent_id, keys):
        sql = "SELECT " + ", ".join(keys) + " FROM MetaDataTorrent, ChannelMetaData LEFT JOIN Moderations ON Moderations.cause = ChannelMetaData.dispersy_id WHERE metadata_id = ChannelMetaData.id AND channeltorrent_id = ? ORDER BY -Moderations.time_stamp ASC, prev_global_time DESC"
        return self._db.fetchall(sql, (channeltorrent_id,))

    def getMostPopularChannelFromTorrent(self, infohash):
        """Returns channel id, name, nrfavorites of most popular channel if any"""
        sql = "select Channels.id, Channels.dispersy_cid, Channels.name, Channels.description, Channels.nr_torrents, Channels.nr_favorite, Channels.nr_spam, Channels.modified, ChannelTorrents.id from Channels, ChannelTorrents, Torrent where Channels.id = ChannelTorrents.channel_id AND ChannelTorrents.torrent_id = Torrent.torrent_id AND infohash = ?"
        channels = self._db.fetchall(sql, (bin2str(infohash),))

        if len(channels) > 0:
            channel_ids = set()
            for result in channels:
                channel_ids.add(result[0])

            myVotes = self.votecast_db.getMyVotes()

            best_channel = None
            for id, dispersy_cid, name, description, nr_torrents, nr_favorites, nr_spam, modified, channeltorrent_id in channels:
                channel = id, dispersy_cid, name, description, nr_torrents, nr_favorites, nr_spam, myVotes.get(id, 0), modified, id == self._channel_id, channeltorrent_id

                # allways prefer mychannel
                if channel[-1]:
                    return channel

                if not best_channel or channel[5] > best_channel[5]:
                    best_channel = channel
                elif channel[5] == best_channel[5] and channel[4] > best_channel[4]:
                    best_channel = channel
            return best_channel


class UserEventLogDBHandler(BasicDBHandler):

    """
    The database handler for logging user events.
    """
    # maximum number of events to store
    # when this maximum is reached, approx. 50% of the entries are deleted.
    MAX_EVENTS = 2 * 10000

    def __init__(self):
        if UserEventLogDBHandler._single is not None:
            raise RuntimeError("UserEventLogDBHandler is singleton")
        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, 'UserEventLog')

        self.count = -1

    def addEvent(self, message, type=1, timestamp=None):
        """
        Log a user event to the database. Commits automatically.

        @param message A message (string) describing the event.
        @param type Optional type of event (default: 1). There is no
        mechanism to register user event types.
        @param timestamp Optional timestamp of the event. If omitted,
        the current time is used.
        """
        if timestamp is None:
            timestamp = time()
        self._db.insert(self.table_name,
                        timestamp=timestamp, type=type, message=message)

        if self.count == -1:
            self.count = self._db.size(self.table_name)
        else:
            self.count += 1

        if self.count > UserEventLogDBHandler.MAX_EVENTS:
            sql = \
                '''
            DELETE FROM UserEventLog
            WHERE timestamp < (SELECT MIN(timestamp)
                               FROM (SELECT timestamp
                                     FROM UserEventLog
                                     ORDER BY timestamp DESC LIMIT %s))
            ''' % (UserEventLogDBHandler.MAX_EVENTS / 2)
            self._db.execute_write(sql)
            self.count = self._db.size(self.table_name)


class BundlerPreferenceDBHandler(BasicDBHandler):

    """
    The Bundler Preference database handler singleton for
    storing a chosen bundle method for a particular query.
    """

    def __init__(self):
        if BundlerPreferenceDBHandler._single is not None:
            raise RuntimeError("BundlerPreferenceDBHandler is singleton")
        db = SQLiteCacheDB.getInstance()
        BasicDBHandler.__init__(self, db, 'BundlerPreference')

    def storePreference(self, keywords, bundle_mode):
        query = ' '.join(sorted(set(keywords)))
        self._db.execute_write('INSERT OR REPLACE INTO BundlerPreference (query, bundle_mode) VALUES (?,?)',
                               (query, bundle_mode))

    def getPreference(self, keywords):
        # returns None if query not in db
        query = ' '.join(sorted(set(keywords)))
        return self.getOne('bundle_mode', query=query)


def ranksfind(ranks, key):
    if ranks is None:
        return -1
    try:
        return ranks.index(key) + 1
    except:
        return -1

########NEW FILE########
__FILENAME__ = mainlineDHT
# written by Fabian van der Werf, Arno Bakker
# Modified by Raul Jimenez to integrate KTH DHT
# see LICENSE.txt for license information

import sys
import logging

logger = logging.getLogger(__name__)

DEBUG = False

DHT_IMPORTED = False
if sys.version.split()[0] >= '2.5':
    try:
        import Tribler.Core.DecentralizedTracking.pymdht.core.pymdht as pymdht
        import Tribler.Core.DecentralizedTracking.pymdht.core.node as node
        import Tribler.Core.DecentralizedTracking.pymdht.plugins.routing_nice_rtt as routing_mod
        import Tribler.Core.DecentralizedTracking.pymdht.plugins.lookup_a4 as lookup_mod
        import Tribler.Core.DecentralizedTracking.pymdht.core.exp_plugin_template as experimental_m_mod
        DHT_IMPORTED = True
    except ImportError:
        logger.exception(u"Could not import pymdht")

def init(addr, conf_path, swift_port):
    if DEBUG:
        log_level = logging.DEBUG
    else:
        log_level = logging.ERROR
    logger.debug('dht: DHT initialization %s', DHT_IMPORTED)

    if DHT_IMPORTED:
        my_node = node.Node(addr, None, version=pymdht.VERSION_LABEL)
        private_dht_name = None
        dht = pymdht.Pymdht(my_node, conf_path,
                            routing_mod,
                            lookup_mod,
                            experimental_m_mod,
                            private_dht_name,
                            log_level,
                            swift_port=swift_port)
        logger.debug('Swift DHT running')
    return dht

def deinit(dht):
    if dht is not None:
        try:
            dht.stop()
        except:
            logger.exception('could not stop Swift DHT')

########NEW FILE########
__FILENAME__ = defaults
# Written by Arno Bakker and Bram Cohen
# Updated by George Milescu
# Updated by Egbert Bouman, added subsection names + using OrderedDict + cleanup
# see LICENSE.txt for license information

""" Default values for all configurarable parameters of the Core"""
#
# For an explanation of each parameter, see SessionConfig/DownloadConfig.py
#
# defaults with comments behind them are not user-setable via the
# *ConfigInterface classes, because they are not currently implemented (IPv6)
# or we only use them internally.
#
# WARNING:
#    As we have release Tribler 4.5.0 you must now take into account that
#    people have stored versions of these params on their disk. Make sure
#    you change the version number of the structure and provide upgrade code
#    such that your code won't barf because we loaded an older version from
#    disk that does not have your new fields.
#

from collections import OrderedDict

from Tribler.Core.Video.defs import PLAYBACKMODE_INTERNAL

DEFAULTPORT = 7760

#
# Session opts
#
# History:
#  Version 2: as released in Tribler 4.5.0
#  Version 3: cleanup unused params
#

SESSDEFAULTS_VERSION = 3
sessdefaults = OrderedDict()

# General Tribler settings
sessdefaults['general'] = OrderedDict()
sessdefaults['general']['version'] = SESSDEFAULTS_VERSION
sessdefaults['general']['state_dir'] = None
sessdefaults['general']['install_dir'] = u'.'
sessdefaults['general']['ip'] = ''
sessdefaults['general']['minport'] = DEFAULTPORT
sessdefaults['general']['maxport'] = DEFAULTPORT
sessdefaults['general']['bind'] = []
sessdefaults['general']['ipv6_enabled'] = 0  # allow the client to connect to peers via IPv6 (currently not supported)
sessdefaults['general']['ipv6_binds_v4'] = None  # set if an IPv6 server socket won't also field IPv4 connections (default = set automatically)
sessdefaults['general']['timeout'] = 300.0
sessdefaults['general']['timeout_check_interval'] = 60.0
sessdefaults['general']['eckeypairfilename'] = None
sessdefaults['general']['megacache'] = True
sessdefaults['general']['nickname'] = '__default_name__'  # is replaced with hostname in LaunchManyCore.py
sessdefaults['general']['mugshot'] = None
sessdefaults['general']['videoanalyserpath'] = None
sessdefaults['general']['peer_icon_path'] = None
sessdefaults['general']['live_aux_seeders'] = []

# Proxy community section
sessdefaults['proxy_community'] = OrderedDict()
sessdefaults['proxy_community']['socks5_listen_port'] = -1

# Mainline DHT settings
sessdefaults['mainline_dht'] = OrderedDict()
sessdefaults['mainline_dht']['enabled'] = True
sessdefaults['mainline_dht']['mainline_dht_port'] = -1

# Torrent checking settings
sessdefaults['torrent_checking'] = OrderedDict()
sessdefaults['torrent_checking']['enabled'] = 1
sessdefaults['torrent_checking']['torrent_checking_period'] = 31  # will be changed to min(max(86400/ntorrents, 15), 300) at runtime

# Torrent collecting settings
sessdefaults['torrent_collecting'] = OrderedDict()
sessdefaults['torrent_collecting']['enabled'] = True
sessdefaults['torrent_collecting']['dht_torrent_collecting'] = True
sessdefaults['torrent_collecting']['torrent_collecting_max_torrents'] = 50000
sessdefaults['torrent_collecting']['torrent_collecting_dir'] = None
sessdefaults['torrent_collecting']['stop_collecting_threshold'] = 200

# Libtorrent settings
sessdefaults['libtorrent'] = OrderedDict()
sessdefaults['libtorrent']['enabled'] = True
sessdefaults['libtorrent']['lt_proxytype'] = 0  # no proxy server is used by default
sessdefaults['libtorrent']['lt_proxyserver'] = None
sessdefaults['libtorrent']['lt_proxyauth'] = None
sessdefaults['libtorrent']['utp'] = True

# Anonymous libtorrent
sessdefaults['libtorrent']['anon_listen_port'] = -1
sessdefaults['libtorrent']['anon_proxytype'] = 0
sessdefaults['libtorrent']['anon_proxyserver'] = None
sessdefaults['libtorrent']['anon_proxyauth'] = None

# SWIFTPROC config
sessdefaults['swift'] = OrderedDict()
sessdefaults['swift']['enabled'] = True
sessdefaults['swift']['swiftpath'] = None
sessdefaults['swift']['swiftworkingdir'] = '.'
sessdefaults['swift']['swiftcmdlistenport'] = -1
sessdefaults['swift']['swiftdlsperproc'] = 1000
sessdefaults['swift']['swiftmetadir'] = None
# Config for tunneling via swift, e.g. dispersy
sessdefaults['swift']['swifttunnellistenport'] = DEFAULTPORT - 2
sessdefaults['swift']['swifttunnelhttpgwlistenport'] = -1
sessdefaults['swift']['swifttunnelcmdgwlistenport'] = -1
sessdefaults['swift']['swiftdhtport'] = -1

# Dispersy config
sessdefaults['dispersy'] = OrderedDict()
sessdefaults['dispersy']['enabled'] = True
sessdefaults['dispersy']['dispersy-tunnel-over-swift'] = False
sessdefaults['dispersy']['dispersy_port'] = DEFAULTPORT - 1

# Video config
sessdefaults['video'] = OrderedDict()
sessdefaults['video']['enabled'] = True
sessdefaults['video']['path'] = None
sessdefaults['video']['port'] = -1
sessdefaults['video']['preferredmode'] = PLAYBACKMODE_INTERNAL



#
# BT per download opts
#
# History:
#  Version 2: as released in Tribler 4.5.0
#  Version 3:
#  Version 4: allow users to specify a download directory every time
#  Version 6: allow users to overwrite the multifile destination
#  Version 7: swift params
#  Version 8: deleted many of the old params that were not used anymore (due to the switch to libtorrent)

DLDEFAULTS_VERSION = 8
dldefaults = OrderedDict()

# General download settings
dldefaults['downloadconfig'] = OrderedDict()
dldefaults['downloadconfig']['version'] = DLDEFAULTS_VERSION
dldefaults['downloadconfig']['saveas'] = None  # Set to get_default_destdir()
dldefaults['downloadconfig']['max_upload_rate'] = 0
dldefaults['downloadconfig']['max_download_rate'] = 0
dldefaults['downloadconfig']['super_seeder'] = 0
dldefaults['downloadconfig']['mode'] = 0
dldefaults['downloadconfig']['selected_files'] = []
dldefaults['downloadconfig']['correctedfilename'] = None
dldefaults['downloadconfig']['swiftlistenport'] = None
dldefaults['downloadconfig']['swiftcmdgwlistenport'] = None
dldefaults['downloadconfig']['swifthttpgwlistenport'] = None
dldefaults['downloadconfig']['swiftmetadir'] = None
dldefaults['downloadconfig']['name'] = None

tdefdictdefaults = {}
tdefdictdefaults['comment'] = None
tdefdictdefaults['created by'] = None
tdefdictdefaults['announce'] = None
tdefdictdefaults['announce-list'] = None
tdefdictdefaults['nodes'] = None  # mainline DHT
tdefdictdefaults['httpseeds'] = None
tdefdictdefaults['url-list'] = None
tdefdictdefaults['encoding'] = None

tdefmetadefaults = {}
tdefmetadefaults['version'] = 1
tdefmetadefaults['piece length'] = 0
tdefmetadefaults['makehash_md5'] = 0
tdefmetadefaults['makehash_crc32'] = 0
tdefmetadefaults['makehash_sha1'] = 0
tdefmetadefaults['createmerkletorrent'] = 0
tdefmetadefaults['torrentsigkeypairfilename'] = None
tdefmetadefaults['thumb'] = None  # JPEG data

TDEF_DEFAULTS = {}
TDEF_DEFAULTS.update(tdefdictdefaults)
TDEF_DEFAULTS.update(tdefmetadefaults)

########NEW FILE########
__FILENAME__ = DownloadConfig
# Written by Arno Bakker
# Updated by George Milescu
# Updated by Egbert Bouman, now using ConfigParser
# see LICENSE.txt for license information

""" Controls how a TorrentDef is downloaded (rate, where on disk, etc.) """

#
# WARNING: When extending this class:
#
# 1. Add a JavaDoc description for each method you add.
# 2. Also add the methods to APIImplementation/DownloadRuntimeConfig.py
# 3. Document your changes in API.py
#
#

import os
from types import StringType

from Tribler.Core.simpledefs import DLMODE_VOD, UPLOAD
from Tribler.Core.defaults import dldefaults
from Tribler.Core.Base import Serializable, Copyable
from Tribler.Core.osutils import get_desktop_dir
from Tribler.Core.Utilities.configparser import CallbackConfigParser


class DownloadConfigInterface(object):

    """
    (key,value) pair config of per-torrent runtime parameters,
    e.g. destdir, file-allocation policy, etc. Also options to advocate
    torrent, e.g. register in DHT, advertise via Buddycast.

    Use DownloadStartupConfig to manipulate download configs before download
    startup time. This is just a parent class.

    cf. libtorrent torrent_handle
    """
    def __init__(self, dlconfig=None):
        super(DownloadConfigInterface, self).__init__()

        self.dlconfig = dlconfig or CallbackConfigParser()

        # Poor man's versioning of DownloadConfig, add missing default values.
        for section, sect_dict in dldefaults.iteritems():
            if not self.dlconfig.has_section(section):
                self.dlconfig.add_section(section)
            for k, v in sect_dict.iteritems():
                if not self.dlconfig.has_option(section, k):
                    self.dlconfig.set(section, k, v)

        if not dlconfig:
            return

        # modify/fix incorrectly saved dlconfigs
        if dlconfig.has_option('downloadconfig', 'saveas') and isinstance(dlconfig.get('downloadconfig', 'saveas'), tuple):
            dlconfig.set('downloadconfig', 'saveas', dlconfig.get('saveas')[-1])

        if not self.get_dest_dir():
            self.set_dest_dir(get_default_dest_dir())

    def set_dest_dir(self, path):
        """ Sets the directory where to save this Download.
        @param path A path of a directory.
        """
        assert isinstance(path, basestring), path
        self.dlconfig.set('downloadconfig', 'saveas', path)

    def get_dest_dir(self):
        """ Gets the directory where to save this Download.
        """
        return self.dlconfig.get('downloadconfig', 'saveas')

    def get_corrected_filename(self):
        """ Gets the directory name where to save this torrent
        """
        return self.dlconfig.get('downloadconfig', 'correctedfilename')

    def set_corrected_filename(self, correctedfilename):
        """ Sets the directory name where to save this torrent
        @param correctedfilename name for multifile directory
        """
        self.dlconfig.set('downloadconfig', 'correctedfilename', correctedfilename)

    def set_mode(self, mode):
        """ Sets the mode of this download.
        @param mode DLMODE_NORMAL/DLMODE_VOD """
        self.dlconfig.set('downloadconfig', 'mode', mode)

    def get_mode(self):
        """ Returns the mode of this download.
        @return DLMODE_NORMAL/DLMODE_VOD """
        return self.dlconfig.get('downloadconfig', 'mode')

    def set_anon_mode(self, anon_mode):
        self.dlconfig.set('downloadconfig', 'anon_mode', anon_mode)

    def get_anon_mode(self):
        return self.dlconfig.get('downloadconfig', 'anon_mode')

    def set_selected_files(self, files):
        """ Select which files in the torrent to download. The filenames must
        be the names as they appear in the content def, including encoding.
        Trivially, when the torrent contains a file 'sjaak.avi' the files
        parameter must be 'sjaak.avi'. When the content def is a torrent def
        and contains multiple files and is named 'filecollection', the files
        parameter must be
            os.path.join('filecollection','sjaak.avi')
        For a swift def, the files must be following the multi-file spec encoding
        (i.e., UTF-8 and /).

        @param files Can be a single filename or a list of filenames (e.g.
        ['harry.avi','sjaak.avi']). Not Unicode strings!
        """
        # TODO: can't check if files exists, don't have tdef here.... bugger
        if isinstance(files, StringType):  # convenience
            files = [files]

        if self.get_mode() == DLMODE_VOD and len(files) > 1:
            raise ValueError("In Video-On-Demand mode only 1 file can be selected for download")

        self.dlconfig.set('downloadconfig', 'selected_files', files)

    def get_selected_files(self):
        """ Returns the list of files selected for download.
        @return A list of strings. """
        return self.dlconfig.get('downloadconfig', 'selected_files')

    def set_max_speed(self, direct, speed):
        """ Sets the maximum upload or download speed for this Download.
        @param direct The direction (UPLOAD/DOWNLOAD)
        @param speed The speed in KB/s.
        """
        if direct == UPLOAD:
            self.dlconfig.set('downloadconfig', 'max_upload_rate', speed)
        else:
            self.dlconfig.set('downloadconfig', 'max_download_rate', speed)

    def get_max_speed(self, direct):
        """ Returns the configured maximum speed.
        Returns the speed in KB/s. """
        if direct == UPLOAD:
            return self.dlconfig.get('downloadconfig', 'max_upload_rate')
        else:
            return self.dlconfig.get('downloadconfig', 'max_download_rate')

    def set_super_seeder(self, value):
        """ whether to use special upload-efficiency-maximizing routines (only
        for dedicated seeds).
        @param value Boolean
        """
        self.dlconfig.set('downloadconfig', 'super_seeder', value)

    def get_super_seeder(self):
        """ Returns hether super seeding is enabled.
        @return Boolean. """
        return self.dlconfig.get('downloadconfig', 'super_seeder')

    # SWIFTPROC
    def set_swift_listen_port(self, port):
        """ Set the UDP port for the swift process
        (download-to-process mapping permitting).
        @param port A port number.
        """
        self.dlconfig.set('downloadconfig', 'swiftlistenport', port)

    def get_swift_listen_port(self):
        """ Returns the UDP port of the swift process.

        @return Port number. """
        return self.dlconfig.get('downloadconfig', 'swiftlistenport')

    def set_swift_cmdgw_listen_port(self, port):
        """ Set the TCP listen port for the CMDGW of the swift process
        (download-to-process mapping permitting).
        @param port A port number.
        """
        self.dlconfig.set('downloadconfig', 'swiftcmdgwlistenport', port)

    def get_swift_cmdgw_listen_port(self):
        """ Returns the TCP listen port for the CMDGW of the swift process
        (download-to-process mapping permitting).

        @return Port number. """
        return self.dlconfig.get('downloadconfig', 'swiftcmdgwlistenport')

    def set_swift_httpgw_listen_port(self, port):
        """ Set the TCP listen port for the CMDGW of the swift process
        (download-to-process mapping permitting).
        @param port A port number.
        """
        self.dlconfig.set('downloadconfig', 'swifthttpgwlistenport', port)

    def get_swift_httpgw_listen_port(self):
        """ Returns the TCP listen port for the CMDGW of the swift process.

        @return Port number. """
        return self.dlconfig.get('downloadconfig', 'swifthttpgwlistenport')

    def set_swift_meta_dir(self, value):
        """ Set the metadir for storing .m* files of this Download.
        @param value An absolutepath.
        """
        self.dlconfig.set('downloadconfig', 'swiftmetadir', value)

    def get_swift_meta_dir(self):
        """ Return the metadir for storing .m* files of this Download.
        @return An absolutepath.
        """
        return self.dlconfig.get('downloadconfig', 'swiftmetadir')

    def set_swift_name(self, value):
        self.dlconfig.set('downloadconfig', 'name', value)

    def get_swift_name(self):
        return self.dlconfig.get('downloadconfig', 'name')


class DownloadStartupConfig(DownloadConfigInterface, Serializable, Copyable):

    """
    (key,value) pair config of per-torrent runtime parameters,
    e.g. destdir, file-allocation policy, etc. Also options to advocate
    torrent, e.g. register in DHT, advertise via Buddycast.

    cf. libtorrent torrent_handle
    """
    def __init__(self, dlconfig=None):
        """ Normal constructor for DownloadStartupConfig (copy constructor
        used internally) """
        DownloadConfigInterface.__init__(self, dlconfig)
    #
    # Class method
    #

    def load(filename):
        """
        Load a saved DownloadStartupConfig from disk.

        @param filename  An absolute Unicode filename
        @return DownloadStartupConfig object
        """
        # Class method, no locking required
        dlconfig = CallbackConfigParser()
        try:
            dlconfig.read_file(filename)
        except:
            raise IOError, "Failed to open download config file"

        return DownloadStartupConfig(dlconfig)

    load = staticmethod(load)

    def save(self, filename):
        """ Save the DownloadStartupConfig to disk.
        @param filename  An absolute Unicode filename
        """
        # Called by any thread
        self.sessconfig.write_file(filename)

    #
    # Copyable interface
    #
    def copy(self):
        return DownloadStartupConfig(self.dlconfig.copy())


def get_default_dest_dir():
    """ Returns the default dir to save content to.
    <pre>
    * For Win32/MacOS: Desktop\TriblerDownloads
    * For UNIX:
        If Desktop exists: Desktop\TriblerDownloads
        else: Home\TriblerDownloads
    </pre>
    """
    downloaddir = 'TriblerDownloads'

    if os.path.isdir(downloaddir):
        return os.path.abspath(downloaddir)

    uhome = get_desktop_dir()
    return os.path.join(uhome, downloaddir)

########NEW FILE########
__FILENAME__ = DownloadState
# Written by Arno Bakker
# Updated by George Milescu
# see LICENSE.txt for license information
""" Contains a snapshot of the state of the Download at a specific point in time. """
import logging

from Tribler.Core.simpledefs import UPLOAD, DLSTATUS_STOPPED_ON_ERROR, \
    DLSTATUS_SEEDING, DLSTATUS_DOWNLOADING, DLSTATUS_WAITING4HASHCHECK, \
    DLSTATUS_STOPPED
from Tribler.Core.Base import Serializable


class DownloadState(Serializable):

    """
    Contains a snapshot of the state of the Download at a specific
    point in time. Using a snapshot instead of providing live data and
    protecting access via locking should be faster.

    cf. libtorrent torrent_status
    """
    def __init__(self, download, status, error, progress, stats=None, seeding_stats=None, filepieceranges=None, logmsgs=None, peerid=None, videoinfo=None):
        """ Internal constructor.
        @param download The Download this state belongs too.
        @param status The status of the Download (DLSTATUS_*)
        @param progress The general progress of the Download.
        @param stats The BT engine statistics for the Download.
        @param filepieceranges The range of pieces that we are interested in.
        The get_pieces_complete() returns only completeness information about
        this range. This is used for playing a video in a multi-torrent file.
        @param logmsgs A list of messages from the BT engine which may be of
        """
        self._logger = logging.getLogger(self.__class__.__name__)

        self.download = download
        self.filepieceranges = filepieceranges  # NEED CONC CONTROL IF selected_files RUNTIME SETABLE
        self.logmsgs = logmsgs
        self.vod_status_msg = None
        self.seedingstats = seeding_stats

        self.haveslice = None
        self.stats = None
        self.length = None

        name = self.download.get_def().get_name()

        if stats is None:
            # No info available yet from download engine
            self._logger.debug("DownloadState.__init__: stats is None '%s'", name)
            self.error = error  # readonly access
            self.progress = progress
            if self.error is not None:
                self.status = DLSTATUS_STOPPED_ON_ERROR
            else:
                self.status = status

        elif error is not None:
            self._logger.debug("DownloadState.__init__: error is not None '%s'", name)
            self.error = error  # readonly access
            self.progress = 0.0  # really want old progress
            self.status = DLSTATUS_STOPPED_ON_ERROR

        elif status is not None and not status in [DLSTATUS_DOWNLOADING, DLSTATUS_SEEDING]:
            # For HASHCHECKING and WAITING4HASHCHECK
            self._logger.debug("DownloadState.__init__: we have status and it is not downloading or seeding '%s'", name)
            self.error = error
            self.status = status
            if self.status == DLSTATUS_WAITING4HASHCHECK:
                self.progress = 0.0
            else:
                self.progress = stats['frac']
                if 'wanted' in stats:
                    self.length = stats['wanted']

        else:
            # Copy info from stats
            self._logger.debug("DownloadState.__init__: copy from stats '%s'", name)
            self.error = None
            self.progress = stats['frac']
            if stats['frac'] == 1.0:
                self.status = DLSTATUS_SEEDING
            else:
                self.status = DLSTATUS_DOWNLOADING
            # print >>sys.stderr,"STATS IS",stats

            # Safe to store the stats dict. The stats dict is created per
            # invocation of the BT1Download returned statsfunc and contains no
            # pointers.
            #
            self.stats = stats

        if stats and stats.get('stats', None):
            # for pieces complete
            if not self.filepieceranges:
                self.haveslice = stats['stats'].have  # is copy of network engine list
            else:
                # For get_files_completion()
                self.haveslice_total = stats['stats'].have

                selected_files = self.download.get_selected_files()
                # Show only pieces complete for the selected ranges of files
                totalpieces = 0
                for t, tl, o, f in self.filepieceranges:
                    if f in selected_files or not selected_files:
                        diff = tl - t
                        totalpieces += diff

                # print >>sys.stderr,"DownloadState: get_pieces_complete",totalpieces
                haveslice = [False] * totalpieces
                have = 0
                index = 0
                for t, tl, o, f in self.filepieceranges:
                    if f in selected_files or not selected_files:
                        for piece in range(t, tl):
                            haveslice[index] = stats['stats'].have[piece]
                            if haveslice[index]:
                                have += 1

                            index += 1
                self.haveslice = haveslice
                if have == len(haveslice) and self.status == DLSTATUS_DOWNLOADING:
                    # we have all pieces of the selected files
                    self.status = DLSTATUS_SEEDING
                    self.progress = 1.0

    def get_download(self):
        """ Returns the Download object of which this is the state """
        return self.download

    def get_progress(self):
        """ The general progress of the Download as a percentage. When status is
         * DLSTATUS_HASHCHECKING it is the percentage of already downloaded
           content checked for integrity.
         * DLSTATUS_DOWNLOADING/SEEDING it is the percentage downloaded.
        @return Progress as a float (0..1).
        """
        return self.progress

    def get_status(self):
        """ Returns the status of the torrent.
        @return DLSTATUS_* """
        return self.status

    def get_error(self):
        """ Returns the Exception that caused the download to be moved to
        DLSTATUS_STOPPED_ON_ERROR status.
        @return Exception
        """
        return self.error

    #
    # Details
    #
    def get_current_speed(self, direct):
        """
        Returns the current up or download speed.
        @return The speed in bytes/s.
        """
        if self.stats is None:
            return 0
        if direct == UPLOAD:
            return self.stats['up']
        else:
            return self.stats['down']

    def get_total_transferred(self, direct):
        """
        Returns the total amount of up or downloaded bytes.
        @return The amount in bytes.
        """
        if self.stats is None:
            return 0
        if direct == UPLOAD:
            return self.stats['stats'].upTotal
        else:
            return self.stats['stats'].downTotal

    def set_seeding_statistics(self, seedingstats):
        self.seedingstats = seedingstats

    def get_seeding_statistics(self):
        """
        Returns the seedings stats for this download. Will only be availible after
        SeedingManager update_download_state is called.
        Contains if not null, version, total_up, total_down, time_seeding
        All values are stored by the seedingmanager, thus will not only contain current download session values
        """
        return self.seedingstats

    def get_eta(self):
        """
        Returns the estimated time to finish of download.
        @return The time in ?, as ?.
        """
        if self.stats is None:
            return 0.0
        else:
            return self.stats['time']

    def get_num_con_candidates(self):
        """
        Returns the download's number of possible connections. This is used
        to see if there is any progress when non-fatal errors have occured
        (e.g. tracker timeout).
        @return An integer.
        """
        if self.stats is None:
            return 0

        # Determine if we need statsobj to be requested, same as for spew
        statsobj = self.stats['stats']
        return statsobj.numConCandidates

    def get_num_con_initiated(self):
        """
        Returns the download's number of initiated connections. This is used
        to see if there is any progress when non-fatal errors have occured
        (e.g. tracker timeout).
        @return An integer.
        """
        if self.stats is None:
            return 0

        # Determine if we need statsobj to be requested, same as for spew
        statsobj = self.stats['stats']
        return statsobj.numConInitiated

    def get_num_peers(self):
        """
        Returns the download's number of active connections. This is used
        to see if there is any progress when non-fatal errors have occured
        (e.g. tracker timeout).
        @return An integer.
        """
        if self.stats is None:
            return 0

        # Determine if we need statsobj to be requested, same as for spew
        statsobj = self.stats['stats']
        return statsobj.numSeeds + statsobj.numPeers

    def get_num_nonseeds(self):
        """
        Returns the download's number of non-seeders.
        @return An integer.
        """
        if self.stats is None:
            return 0

        # Determine if we need statsobj to be requested, same as for spew
        statsobj = self.stats['stats']
        return statsobj.numPeers

    def get_num_seeds_peers(self):
        """
        Returns the sum of the number of seeds and peers. This function
        works only if the Download.set_state_callback() /
        Session.set_download_states_callback() was called with the getpeerlist
        parameter set to True, otherwise returns (None,None)
        @return A tuple (num seeds, num peers)
        """
        if self.stats is None or self.stats.get('spew', None) is None:
            total = self.get_num_peers()
            non_seeds = self.get_num_nonseeds()
            return (total - non_seeds, non_seeds)

        total = len(self.stats['spew'])
        seeds = len([i for i in self.stats['spew'] if i.get('completed', 0) == 1.0])
        return seeds, total - seeds

    def get_pieces_complete(self):
        """ Returns a list of booleans indicating whether we have completely
        received that piece of the content. The list of pieces for which
        we provide this info depends on which files were selected for download
        using DownloadStartupConfig.set_selected_files().
        @return A list of booleans
        """
        if self.haveslice is None:
            return []
        else:
            return self.haveslice

    def get_pieces_total_complete(self):
        """ Returns the number of total and completed pieces
        @return A tuple containing two integers, total and completed nr of pieces
        """
        if self.haveslice is None:
            return (0, 0)
        else:
            return (len(self.haveslice), sum(self.haveslice))

    def get_files_completion(self):
        """ Returns a list of filename, progress tuples indicating the progress
        for every file selected using set_selected_files. Progress is a float
        between 0 and 1
        """
        if len(self.download.get_selected_files()) > 0:
            files = self.download.get_selected_files()
        else:
            files = self.download.get_def().get_files_as_unicode()

        completion = []
        if self.filepieceranges:
            for t, tl, o, f in self.filepieceranges:
                if f in files and self.progress == 1.0:
                    completion.append((f, 1.0))
                else:
                    # niels: ranges are from-to (inclusive ie if a file consists one piece t and tl will be the same)
                    total_pieces = tl - t
                    if total_pieces and getattr(self, 'haveslice_total', False):
                        completed = 0
                        for index in range(t, tl):
                            if self.haveslice_total[index]:
                                completed += 1

                        completion.append((f, completed / (total_pieces * 1.0)))
                    elif f in files:
                        completion.append((f, 0.0))
        elif files:
            # Single file
            completion.append((files[0], self.get_progress()))
        return completion

    def get_selected_files(self):
        selected_files = self.download.get_selected_files()
        if len(selected_files) > 0:
            return selected_files

    def get_length(self):
        # Niels: 28/08/2012 for larger .torrent this methods gets quite expensive, cache the result to prevent us calculating this unnecessarily.
        if not self.length:
            files = self.get_selected_files()

            cdef = self.download.get_def()
            if cdef.get_def_type() == "torrent":
                self.length = cdef.get_length(files)
            else:
                self.length = self.download.get_dynasize()
        return self.length

    def get_availability(self):
        """ Return overall the availability of all pieces, using connected peers
        Availability is defined as the number of complete copies of a piece, thus seeders
        increment the availability by 1. Leechers provide a subset of piece thus we count the
        overall availability of all pieces provided by the connected peers and use the minimum
        of this + the average of all additional pieces.
        """
        nr_seeders_complete = 0
        merged_bitfields = None

        peers = self.get_peerlist()
        for peer in peers:
            completed = peer.get('completed', 0)
            have = peer.get('have', [])

            if completed == 1 or have and all(have):
                nr_seeders_complete += 1
            else:
                if merged_bitfields == None:
                    merged_bitfields = [0] * len(have)

                for i in range(len(have)):
                    if have[i]:
                        merged_bitfields[i] += 1

        if merged_bitfields:
            # count the number of complete copies due to overlapping leecher bitfields
            nr_leechers_complete = min(merged_bitfields)

            # detect remainder of bitfields which are > 0
            nr_more_than_min = len([x for x in merged_bitfields if x > nr_leechers_complete])
            fraction_additonal = float(nr_more_than_min) / len(merged_bitfields)

            return nr_seeders_complete + nr_leechers_complete + fraction_additonal
        return nr_seeders_complete

    def get_vod_prebuffering_progress(self):
        """ Returns the percentage of prebuffering for Video-On-Demand already
        completed.
        @return A float (0..1) """
        if self.stats is None:
            if self.status == DLSTATUS_STOPPED and self.progress == 1.0:
                return 1.0
            else:
                return 0.0
        else:
            return self.stats['vod_prebuf_frac']

    def get_vod_prebuffering_progress_consec(self):
        """ Returns the percentage of consecutive prebuffering for Video-On-Demand already
        completed.
        @return A float (0..1) """
        if self.stats is None:
            if self.status == DLSTATUS_STOPPED and self.progress == 1.0:
                return 1.0
            else:
                return 0.0
        else:
            return self.stats.get('vod_prebuf_frac_consec', -1)

    def is_vod(self):
        """ Returns if this download is currently in vod mode

        @return A Boolean"""
        if self.stats is None:
            return False
        else:
            return self.stats['vod']

    def get_vod_playable(self):
        """ Returns whether or not the Download started in Video-On-Demand
        mode has sufficient prebuffer and download speed to be played out
        to the user.
        @return Boolean.
        """
        if self.stats is None:
            return False
        else:
            return self.stats['vod_playable']

    def get_vod_playable_after(self):
        """ Returns the estimated time until the Download started in Video-On-Demand
        mode can be started to play out to the user.
        @return A number of seconds.
        """
        if self.stats is None:
            return float(2 ** 31)
        else:
            return self.stats['vod_playable_after']

    def get_vod_stats(self):
        """ Returns a dictionary of collected VOD statistics. The keys contained are:
        <pre>
        'played' = number of pieces played. With seeking this may be more than npieces
        'late' = number of pieces arrived after they were due
        'dropped' = number of pieces lost
        'stall' = estimation of time the player stalled, waiting for pieces (seconds)
        'pos' = playback position, as an absolute piece number
        'prebuf' = amount of prebuffering time that was needed (seconds,
                   set when playback starts)
        'firstpiece' = starting absolute piece number of selected file
        'npieces' = number of pieces in selected file
        </pre>, or no keys if no VOD is in progress.
        @return Dict.
        """
        if self.stats is None:
            return {}
        else:
            return self.stats['vod_stats']

    def get_log_messages(self):
        """ Returns the last 10 logged non-fatal error messages.
        @return A list of (time,msg) tuples. Time is Python time() format. """
        if self.logmsgs is None:
            return []
        else:
            return self.logmsgs

    def get_peerlist(self):
        """ Returns a list of dictionaries, one for each connected peer
        containing the statistics for that peer. In particular, the
        dictionary contains the keys:
        <pre>
        'id' = PeerID or 'http seed'
        'extended_version' = Peer client version, as received during the extend handshake message
        'ip' = IP address as string or URL of httpseed
        'port' = Port
        'pex_received' = True/False
        'g2g' = True/False (Tribler peer yes/no)
        'g2g_score' = List
        'optimistic' = True/False
        'direction' = 'L'/'R' (outgoing/incoming)
        'uprate' = Upload rate in KB/s
        'uinterested' = Upload Interested: True/False
        'uchoked' = Upload Choked: True/False
        'uhasqueries' = Upload has requests in buffer and not choked
        'uflushed' = Upload is not flushed
        'downrate' = Download rate in KB/s
        'dinterested' = Download interested: True/Flase
        'dchoked' = Download choked: True/False
        'snubbed' = Download snubbed: True/False
        'utotal' = Total uploaded from peer in KB
        'dtotal' = Total downloaded from peer in KB
        'completed' = Fraction of download completed by peer (0-1.0)
        'have' = Bitfield object for this peer if not complete
        'speed' = The peer's current total download speed (estimated)
        </pre>
        """
        if self.stats is None or 'spew' not in self.stats or self.stats['spew'] is None:
            return []
        else:
            return self.stats['spew']

########NEW FILE########
__FILENAME__ = exceptions
# Written by Arno Bakker
# see LICENSE.txt for license information
""" The Tribler-specifc Exceptions the Core may throw. """

#
# Exceptions
#


class TriblerException(Exception):

    """ Super class for all Tribler-specific Exceptions the Tribler Core
    throws.
    """
    def __init__(self, msg=None):
        Exception.__init__(self, msg)

    def __str__(self):
        return str(self.__class__) + ': ' +Exception.__str__(self)


class OperationNotPossibleAtRuntimeException(TriblerException):

    """ The requested operation is not possible after the Session or Download
    has been started.
    """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class OperationNotPossibleWhenStoppedException(TriblerException):

    """ The requested operation is not possible when the Download
    has been stopped.
    """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class OperationNotEnabledByConfigurationException(TriblerException):

    """ The requested operation is not possible with the current
    Session/Download configuration.
    """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class NotYetImplementedException(TriblerException):

    """ The requested operation is not yet fully implemented. """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class DuplicateDownloadException(TriblerException):

    """ The Download already exists in the Session, i.e., a Download for
    a torrent with the same infohash already exists. """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class VODNoFileSelectedInMultifileTorrentException(TriblerException):

    """ Attempt to download a torrent in Video-On-Demand mode that contains
    multiple video files, but without specifying which one to play. """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class LiveTorrentRequiresUsercallbackException(TriblerException):

    """ Attempt to download a live-stream torrent without specifying a
    callback function to call when the stream is ready to play.
    Use set_video_event_callback(usercallback) to correct this problem. """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class TorrentDefNotFinalizedException(TriblerException):

    """ Attempt to start downloading a torrent from a torrent definition
    that was not finalized. """
    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)


class TriblerLegacyException(TriblerException):

    """ Wrapper around fatal errors that happen in the download engine,
    but which are not reported as Exception objects for legacy reasons,
    just as text (often containing a stringified Exception).
    Will be phased out.
    """

    def __init__(self, msg=None):
        TriblerException.__init__(self, msg)

########NEW FILE########
__FILENAME__ = LibtorrentDownloadImpl
# Based on SwiftDownloadImpl.py by Arno Bakker, modified by Egbert Bouman for the use with libtorrent

import os
import sys
import time
import logging
import libtorrent as lt

from binascii import hexlify
from traceback import print_exc

from Tribler.Core import NoDispersyRLock
from Tribler.Core.simpledefs import DLSTATUS_WAITING4HASHCHECK, DLSTATUS_HASHCHECKING, \
    DLSTATUS_METADATA, DLSTATUS_DOWNLOADING, DLSTATUS_SEEDING, DLSTATUS_ALLOCATING_DISKSPACE, \
    UPLOAD, DOWNLOAD, DLSTATUS_STOPPED, DLMODE_VOD, DLSTATUS_STOPPED_ON_ERROR, DLMODE_NORMAL, \
    PERSISTENTSTATE_CURRENTVERSION, dlstatus_strings
from Tribler.Core.DownloadState import DownloadState
from Tribler.Core.DownloadConfig import DownloadStartupConfig, DownloadConfigInterface
from Tribler.Core.APIImplementation import maketorrent
from Tribler.Core.osutils import fix_filebasename
from Tribler.Core.TorrentDef import TorrentDefNoMetainfo, TorrentDef
from Tribler.Core.Utilities.Crypto import sha
from Tribler.Core.CacheDB.Notifier import Notifier
from Tribler.Core.Libtorrent import checkHandleAndSynchronize, waitForHandleAndSynchronize

if sys.platform == "win32":
    try:
        import ctypes
    except:
        pass


class VODFile(object):

    def __init__(self, f, d):
        self._logger = logging.getLogger(self.__class__.__name__)

        self._file = f
        self._download = d

        pieces = self._download.tdef.get_pieces()
        self.pieces = [pieces[x:x + 20]for x in xrange(0, len(pieces), 20)]
        self.piecesize = self._download.tdef.get_piece_length()

        self.startpiece = self._download.handle.get_torrent_info().map_file(self._download.get_vod_fileindex(), 0, 0)
        self.endpiece = self._download.handle.get_torrent_info().map_file(self._download.get_vod_fileindex(), self._download.get_vod_filesize(), 0)

    def read(self, *args):
        oldpos = self._file.tell()

        self._logger.debug('VODFile: get bytes %s - %s', oldpos, oldpos + args[0])

        while not self._file.closed and self._download.get_byte_progress([(self._download.get_vod_fileindex(), oldpos, oldpos + args[0])]) < 1 and self._download.vod_seekpos != None:
            time.sleep(1)

        if self._file.closed:
            self._logger.debug('VODFile: got no bytes, file is closed')
            return ''

        result = self._file.read(*args)

        newpos = self._file.tell()
        if self._download.vod_seekpos == oldpos:
            self._download.vod_seekpos = newpos

        self._logger.debug('VODFile: got bytes %s - %s', oldpos, newpos)
        # assert self.verify_pieces(result, oldpos, newpos)

        return result

    def seek(self, *args):
        self._file.seek(*args)
        newpos = self._file.tell()

        self._logger.debug('VODFile: seek %s %s', newpos, args)

        if self._download.vod_seekpos == None or abs(newpos - self._download.vod_seekpos) < 1024 * 1024:
            self._download.vod_seekpos = newpos
        self._download.set_byte_priority([(self._download.get_vod_fileindex(), 0, newpos)], 0)
        self._download.set_byte_priority([(self._download.get_vod_fileindex(), newpos, -1)], 1)

        self._logger.debug('VODFile: seek, get pieces %s', self._download.handle.piece_priorities())
        self._logger.debug('VODFile: seek, got pieces %s', [int(piece) for piece in self._download.handle.status().pieces])

    def verify_pieces(self, original_data, frompos, topos):
        allpiecesok = True
        _frompos = frompos
        _topos = topos

        frompiece = self._download.handle.get_torrent_info().map_file(self._download.get_vod_fileindex(), frompos, 0)
        topiece = self._download.handle.get_torrent_info().map_file(self._download.get_vod_fileindex(), topos, 0)
        self._logger.info("VODFile: Libtorrent says we read pieces %s %s", frompiece.piece, topiece.piece)

        if frompiece.start:
            if frompos - frompiece.start < 0:
                self._logger.info("VODFile: Cannot verify %s - %s", frompos, frompos + self.piecesize - frompiece.start)

                # cannot read partial piece, skipping first X bytes
                frompos += self.piecesize - frompiece.start
                frompiece = frompiece.piece + 1
            else:
                # need to read more than this partial piece, extending with X bytes
                frompos -= frompiece.start
                frompiece = frompiece.piece

        if topiece.piece == self.endpiece.piece:
            self._logger.info("VODFile: Cannot verify %s - %s", topos - topiece.start, topos)

            # cannot read partial piece, truncating last X bytes
            topos -= topiece.start
            topiece = topiece.piece - 1

        else:
            if topiece.start:
                topos += self.piecesize - topiece.start
            topiece = topiece.piece

        if topiece >= frompiece:
            oldpos = self._file.tell()
            self._file.seek(frompos)
            read_data = self._file.read(topos - frompos)
            self._file.seek(oldpos)

            assert len(read_data) == topos - frompos

            # align two arrays
            data_offsets = [0, len(read_data)]
            original_data_offsets = [0, (len(original_data))]

            if frompos > _frompos:
                original_data_offsets[0] = frompos - _frompos
            elif frompos < _frompos:
                data_offsets[0] = _frompos - frompos

            if topos > _topos:
                data_offsets[1] -= topos - _topos
            elif topos < _topos:
                original_data_offsets[1] -= _topos - topos

            assert data_offsets[1] - data_offsets[0] == original_data_offsets[1] - original_data_offsets[0], (data_offsets[1] - data_offsets[0], original_data_offsets[1] - original_data_offsets[0])
            assert read_data[data_offsets[0]:data_offsets[1]] == original_data[original_data_offsets[0]:original_data_offsets[1]]

            startindex = 0
            for piece in range(frompiece, topiece + 1):
                piecehash = sha(read_data[startindex:startindex + self.piecesize]).digest()

                if piecehash == self.pieces[piece]:
                    self._logger.info("VODFile: Correct piece read %s", piece)
                else:
                    self._logger.info("VODFile: Incorrect piece read %s %s %s", piece, piecehash, self.pieces[piece])
                    allpiecesok = False
                startindex += self.piecesize

        return allpiecesok

    def close(self, *args):
        self._file.close(*args)

    @property
    def closed(self):
        return self._file.closed


class LibtorrentDownloadImpl(DownloadConfigInterface):
    """ Download subclass that represents a libtorrent download."""

    def __init__(self, session, tdef):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.dllock = NoDispersyRLock()
        self.session = session
        self.tdef = tdef
        self.handle = None
        self.vod_index = None

        self.notifier = Notifier.getInstance()

        # Just enough so error saving and get_state() works
        self.error = None
        # To be able to return the progress of a stopped torrent, how far it got.
        self.progressbeforestop = 0.0
        self.filepieceranges = []

        # Libtorrent session manager, can be None at this point as the core could have
        # not been started. Will set in create_engine wrapper
        self.ltmgr = None

        # Libtorrent status
        self.dlstates = [DLSTATUS_WAITING4HASHCHECK, DLSTATUS_HASHCHECKING, DLSTATUS_METADATA, DLSTATUS_DOWNLOADING, DLSTATUS_SEEDING, DLSTATUS_SEEDING, DLSTATUS_ALLOCATING_DISKSPACE, DLSTATUS_HASHCHECKING]
        self.dlstate = DLSTATUS_WAITING4HASHCHECK
        self.length = 0
        self.progress = 0.0
        self.bufferprogress = 0.0
        self.curspeeds = {DOWNLOAD: 0.0, UPLOAD: 0.0}  # bytes/s
        self.all_time_upload = 0.0
        self.all_time_download = 0.0
        self.finished_time = 0.0
        self.done = False
        self.pause_after_next_hashcheck = False
        self.checkpoint_after_next_hashcheck = False
        self.queue_position = -1

        self.prebuffsize = 5 * 1024 * 1024
        self.endbuffsize = 0
        self.vod_seekpos = 0

        self.pstate_for_restart = None

        self.cew_scheduled = False
        self.askmoreinfo = False

    def get_def(self):
        return self.tdef

    def setup(self, dcfg=None, pstate=None, initialdlstatus=None, lm_network_engine_wrapper_created_callback=None, wrapperDelay=0):
        """
        Create a Download object. Used internally by Session.
        @param dcfg DownloadStartupConfig or None (in which case
        a new DownloadConfig() is created and the result
        becomes the runtime config of this Download.
        """
        # Called by any thread, assume sessionlock is held
        try:
            with self.dllock:
                # Copy dlconfig, from default if not specified
                if dcfg is None:
                    cdcfg = DownloadStartupConfig()
                else:
                    cdcfg = dcfg
                self.dlconfig = cdcfg.dlconfig.copy()
                self.dlconfig.lock = self.dllock
                self.dlconfig.set_callback(self.dlconfig_changed_callback)

                # Things that only exist at runtime
                self.dlruntimeconfig = {}
                self.dlruntimeconfig['max_desired_upload_rate'] = 0
                self.dlruntimeconfig['max_desired_download_rate'] = 0

                if not isinstance(self.tdef, TorrentDefNoMetainfo):
                    self.set_corrected_infoname()
                    self.set_filepieceranges()

                self._logger.debug("LibtorrentDownloadImpl: setup: initialdlstatus %s %s", self.tdef.get_infohash(), initialdlstatus)

                self.create_engine_wrapper(lm_network_engine_wrapper_created_callback, pstate, initialdlstatus=initialdlstatus, wrapperDelay=wrapperDelay)

            self.pstate_for_restart = pstate

        except Exception as e:
            with self.dllock:
                self.error = e
                print_exc()

    def create_engine_wrapper(self, lm_network_engine_wrapper_created_callback, pstate, initialdlstatus=None, wrapperDelay=0):
        with self.dllock:
            if not self.cew_scheduled:
                self.ltmgr = self.session.lm.ltmgr
                if not self.ltmgr or (isinstance(self.tdef, TorrentDefNoMetainfo) and not self.ltmgr.is_dht_ready()) or \
                   (self.get_anon_mode() and not self.ltmgr.is_anon_ready()):
                    self._logger.info("LibtorrentDownloadImpl: LTMGR or DHT not ready, rescheduling create_engine_wrapper")
                    create_engine_wrapper_lambda = lambda: self.create_engine_wrapper(lm_network_engine_wrapper_created_callback, pstate, initialdlstatus=initialdlstatus)
                    self.session.lm.rawserver.add_task(create_engine_wrapper_lambda, 5)
                    self.dlstate = DLSTATUS_METADATA
                else:
                    network_create_engine_wrapper_lambda = lambda: self.network_create_engine_wrapper(lm_network_engine_wrapper_created_callback, pstate, initialdlstatus)
                    self.session.lm.rawserver.add_task(network_create_engine_wrapper_lambda, wrapperDelay)
                    self.cew_scheduled = True

    def network_create_engine_wrapper(self, lm_network_engine_wrapper_created_callback, pstate, initialdlstatus=None):
        # Called by any thread, assume dllock already acquired
        self._logger.debug("LibtorrentDownloadImpl: create_engine_wrapper()")

        atp = {}
        atp["save_path"] = os.path.abspath(self.get_dest_dir())
        atp["storage_mode"] = lt.storage_mode_t.storage_mode_sparse
        atp["paused"] = True
        atp["auto_managed"] = False
        atp["duplicate_is_error"] = True
        atp["anon_mode"] = self.get_anon_mode()

        resume_data = pstate.get('state', 'engineresumedata') if pstate else None
        if not isinstance(self.tdef, TorrentDefNoMetainfo):
            metainfo = self.tdef.get_metainfo()
            torrentinfo = lt.torrent_info(metainfo)

            self.orig_files = [file_entry.path.decode('utf-8') for file_entry in torrentinfo.files()]
            is_multifile = len(self.orig_files) > 1
            commonprefix = os.path.commonprefix(self.orig_files) if is_multifile else ''
            swarmname = commonprefix.partition(os.path.sep)[0]

            if is_multifile and swarmname != self.correctedinfoname:
                for i, filename_old in enumerate(self.orig_files):
                    filename_new = os.path.join(self.correctedinfoname, filename_old[len(swarmname) + 1:])
                    # Path should be unicode if Libtorrent is using std::wstring (on Windows), else we use str (on Linux).
                    try:
                        torrentinfo.rename_file(i, filename_new)
                    except TypeError:
                        torrentinfo.rename_file(i, filename_new.encode("utf-8"))
                    self.orig_files[i] = filename_new

            atp["ti"] = torrentinfo
            if resume_data:
                atp["resume_data"] = lt.bencode(resume_data)
            self._logger.info("%s %s", self.tdef.get_name_as_unicode(), dict((k, v) for k, v in resume_data.iteritems() if k not in ['pieces', 'piece_priority', 'peers']) if resume_data else None)
        else:
            if self.tdef.get_url():
                # We prefer to use an url, since it may contain trackers
                atp["url"] = self.tdef.get_url()
            else:
                atp["info_hash"] = lt.big_number(self.tdef.get_infohash())
            atp["name"] = self.tdef.get_name_as_unicode()

        self.handle = self.ltmgr.add_torrent(self, atp)

        if self.handle:
            self.set_selected_files()

            # If we lost resume_data always resume download in order to force checking
            if initialdlstatus != DLSTATUS_STOPPED or not resume_data:
                self.handle.resume()

                # If we only needed to perform checking, pause download after it is complete
                self.pause_after_next_hashcheck = initialdlstatus == DLSTATUS_STOPPED

            if self.get_mode() == DLMODE_VOD:
                self.set_vod_mode(True)

            self.handle.resolve_countries(True)

        else:
            self._logger.info("Could not add torrent to LibtorrentManager %s", self.tdef.get_name_as_unicode())

        with self.dllock:
            self.cew_scheduled = False

        if lm_network_engine_wrapper_created_callback is not None:
            lm_network_engine_wrapper_created_callback(self, pstate)

    def set_vod_mode(self, enable=True):
        self._logger.debug("LibtorrentDownloadImpl: set_vod_mode for %s (enable = %s)", self.handle.name(), enable)

        if enable:
            self.vod_seekpos = 0

            filename = self.get_selected_files()[0] if self.tdef.is_multifile_torrent() else self.tdef.get_name()
            self.vod_index = self.tdef.get_index_of_file_in_files(filename) if self.tdef.is_multifile_torrent() else 0

            self.prebuffsize = max(int(self.get_vod_filesize() * 0.05), 5 * 1024 * 1024)
            self.endbuffsize = 1 * 1024 * 1024

            self.handle.set_sequential_download(True)
            self.handle.set_priority(255)
            self.set_byte_priority([(self.get_vod_fileindex(), self.prebuffsize, -self.endbuffsize)], 0)
            self.set_byte_priority([(self.get_vod_fileindex(), 0, self.prebuffsize)], 1)
            self.set_byte_priority([(self.get_vod_fileindex(), -self.endbuffsize, -1)], 1)

            self.progress = self.get_byte_progress([(self.get_vod_fileindex(), 0, -1)])
            self._logger.debug("LibtorrentDownloadImpl: going into VOD mode %s", filename)
        else:
            self.handle.set_sequential_download(False)
            self.handle.set_priority(0)
            if self.get_vod_fileindex() >= 0:
                self.set_byte_priority([(self.get_vod_fileindex(), 0, -1)], 1)

    def get_vod_fileindex(self):
        if self.vod_index != None:
            return self.vod_index
        return -1

    @checkHandleAndSynchronize(0)
    def get_vod_filesize(self):
        fileindex = self.get_vod_fileindex()
        if fileindex >= 0:
            file_entry = self.handle.get_torrent_info().file_at(fileindex)
            return file_entry.size
        return 0

    @checkHandleAndSynchronize(0.0)
    def get_piece_progress(self, pieces, consecutive=False):
        if not pieces:
            return 1.0
        elif consecutive:
            pieces.sort()

        status = self.handle.status()
        if status:
            pieces_have = 0
            pieces_all = len(pieces)
            bitfield = status.pieces
            for pieceindex in pieces:
                if pieceindex < len(bitfield) and bitfield[pieceindex]:
                    pieces_have += 1
                elif consecutive:
                    break
            return float(pieces_have) / pieces_all
        return 0.0

    @checkHandleAndSynchronize(0.0)
    def get_byte_progress(self, byteranges, consecutive=False):
        pieces = []
        for fileindex, bytes_begin, bytes_end in byteranges:
            if fileindex >= 0:
                # Ensure the we remain within the file's boundaries
                file_entry = self.handle.get_torrent_info().file_at(fileindex)
                bytes_begin = min(file_entry.size, bytes_begin) if bytes_begin >= 0 else file_entry.size + (bytes_begin + 1)
                bytes_end = min(file_entry.size, bytes_end) if bytes_end >= 0 else file_entry.size + (bytes_end + 1)

                startpiece = self.handle.get_torrent_info().map_file(fileindex, bytes_begin, 0).piece
                endpiece = self.handle.get_torrent_info().map_file(fileindex, bytes_end, 0).piece + 1
                startpiece = max(startpiece, 0)
                endpiece = min(endpiece, self.handle.get_torrent_info().num_pieces())

                pieces += range(startpiece, endpiece)
            else:
                self._logger.info("LibtorrentDownloadImpl: could not get progress for incorrect fileindex")

        pieces = list(set(pieces))
        return self.get_piece_progress(pieces, consecutive)

    @checkHandleAndSynchronize()
    def set_piece_priority(self, pieces_need, priority):
        do_prio = False
        pieces_have = self.handle.status().pieces
        piecepriorities = self.handle.piece_priorities()
        for piece in pieces_need:
            if piece < len(piecepriorities):
                if piecepriorities[piece] != priority and not pieces_have[piece]:
                    piecepriorities[piece] = priority
                    do_prio = True
            else:
                self._logger.info("LibtorrentDownloadImpl: could not set priority for non-existing piece %d / %d", piece, len(piecepriorities))
        if do_prio:
            self.handle.prioritize_pieces(piecepriorities)
        else:
            self._logger.info("LibtorrentDownloadImpl: skipping set_piece_priority")

    @checkHandleAndSynchronize()
    def set_byte_priority(self, byteranges, priority):
        pieces = []
        for fileindex, bytes_begin, bytes_end in byteranges:
            if fileindex >= 0:
                # Ensure the we remain within the file's boundaries
                file_entry = self.handle.get_torrent_info().file_at(fileindex)
                bytes_begin = min(file_entry.size, bytes_begin) if bytes_begin >= 0 else file_entry.size + (bytes_begin + 1)
                bytes_end = min(file_entry.size, bytes_end) if bytes_end >= 0 else file_entry.size + (bytes_end + 1)

                startpiece = self.handle.get_torrent_info().map_file(fileindex, bytes_begin, 0).piece
                endpiece = self.handle.get_torrent_info().map_file(fileindex, bytes_end, 0).piece + 1
                startpiece = max(startpiece, 0)
                endpiece = min(endpiece, self.handle.get_torrent_info().num_pieces())

                pieces += range(startpiece, endpiece)
            else:
                self._logger.info("LibtorrentDownloadImpl: could not set priority for incorrect fileindex")

        if pieces:
            pieces = list(set(pieces))
            self.set_piece_priority(pieces, priority)

    @checkHandleAndSynchronize()
    def process_alert(self, alert, alert_type):
        if alert.category() in [lt.alert.category_t.error_notification, lt.alert.category_t.performance_warning]:
            self._logger.debug("LibtorrentDownloadImpl: alert %s with message %s", alert_type, alert)

        if alert_type == 'metadata_received_alert':
            self.on_metadata_received_alert(alert)
        elif alert_type == 'file_renamed_alert':
            self.on_file_renamed_alert(alert)
        elif alert_type == 'performance_alert':
            self.on_performance_alert(alert)
        elif alert_type == 'torrent_checked_alert':
            self.on_torrent_checked_alert(alert)
        elif alert_type == "torrent_finished_alert":
            self.on_torrent_finished_alert(alert)
        else:
            self.update_lt_stats()

    def on_metadata_received_alert(self, alert):
        self.metadata = {'info': lt.bdecode(self.handle.get_torrent_info().metadata())}

        trackers = [tracker['url'] for tracker in self.handle.trackers()]
        if trackers:
            if len(trackers) > 1:
                self.metadata["announce-list"] = [trackers]
            else:
                self.metadata["announce"] = trackers[0]

        self.tdef = TorrentDef.load_from_dict(self.metadata)
        self.orig_files = [torrent_file.path.decode('utf-8') for torrent_file in lt.torrent_info(self.metadata).files()]
        self.set_corrected_infoname()
        self.set_filepieceranges()

        if self.session.lm.rtorrent_handler:
            self.session.lm.rtorrent_handler.save_torrent(self.tdef)
        elif self.session.lm.torrent_db:
            self.session.lm.torrent_db.addExternalTorrent(self.tdef, source='', extra_info={'status': 'good'})

        self.checkpoint()

    def on_file_renamed_alert(self, alert):
        if os.path.exists(self.unwanteddir_abs) and not os.listdir(self.unwanteddir_abs) and all(self.handle.file_priorities()):
            os.rmdir(self.unwanteddir_abs)

    def on_performance_alert(self, alert):
        if self.get_anon_mode():
            return

        # When the send buffer watermark is too low, double the buffer size to a maximum of 50MiB. This is the same mechanism as Deluge uses.
        if alert.message().endswith("send buffer watermark too low (upload rate will suffer)"):
            settings = self.ltmgr.ltsession.settings()
            if settings.send_buffer_watermark <= 26214400:
                self._logger.info("LibtorrentDownloadImpl: setting send_buffer_watermark to %s", 2 * settings.send_buffer_watermark)
                settings.send_buffer_watermark = 2 * settings.send_buffer_watermark
                self.ltmgr.ltsession.set_settings(settings)
        # When the write cache is too small, double the buffer size to a maximum of 64MiB. Again, this is the same mechanism as Deluge uses.
        elif alert.message().endswith("max outstanding disk writes reached"):
            settings = self.ltmgr.ltsession.settings()
            if settings.max_queued_disk_bytes <= 33554432:
                self._logger.info("LibtorrentDownloadImpl: setting max_queued_disk_bytes to %s", 2 * settings.max_queued_disk_bytes)
                settings.max_queued_disk_bytes = 2 * settings.max_queued_disk_bytes
                self.ltmgr.ltsession.set_settings(settings)

    def on_torrent_checked_alert(self, alert):
        if self.pause_after_next_hashcheck:
            self.pause_after_next_hashcheck = False
            self.handle.pause()
        if self.checkpoint_after_next_hashcheck:
            self.checkpoint_after_next_hashcheck = False
            self.checkpoint()

    def on_torrent_finished_alert(self, alert):
        self.update_lt_stats()
        if self.get_mode() == DLMODE_VOD:
            if self.progress == 1.0:
                self.handle.set_sequential_download(False)
                self.handle.set_priority(0)
                if self.get_vod_fileindex() >= 0:
                    self.set_byte_priority([(self.get_vod_fileindex(), 0, -1)], 1)
            elif self.progress < 1.0:
                # If we are in VOD mode and still need to download pieces and libtorrent says we are finished, reset the piece priorities to 1.
                def reset_priorities():
                    if self.handle.status().progress == 1.0:
                        self.set_byte_priority([(self.get_vod_fileindex(), 0, -1)], 1)
                self.session.lm.rawserver.add_task(reset_priorities, 5)

            if self.endbuffsize:
                self.set_byte_priority([(self.get_vod_fileindex(), 0, -1)], 1)
                self.endbuffsize = 0

    def update_lt_stats(self):
        status = self.handle.status()
        self.dlstate = self.dlstates[status.state] if not status.paused else DLSTATUS_STOPPED
        self.dlstate = DLSTATUS_STOPPED_ON_ERROR if self.dlstate == DLSTATUS_STOPPED and status.error else self.dlstate
        if self.get_mode() == DLMODE_VOD:
            self.progress = self.get_byte_progress([(self.get_vod_fileindex(), 0, -1)])
            self.dlstate = (DLSTATUS_SEEDING if self.progress == 1.0 else self.dlstate) if not status.paused else DLSTATUS_STOPPED
        else:
            self.progress = status.progress
        self.error = status.error.decode('utf-8') if status.error else None
        self.length = float(status.total_wanted)
        self.curspeeds[DOWNLOAD] = float(status.download_payload_rate) if self.dlstate not in [DLSTATUS_STOPPED, DLSTATUS_STOPPED] else 0.0
        self.curspeeds[UPLOAD] = float(status.upload_payload_rate) if self.dlstate not in [DLSTATUS_STOPPED, DLSTATUS_STOPPED] else 0.0
        self.all_time_upload = status.all_time_upload
        self.all_time_download = status.all_time_download
        self.finished_time = status.finished_time

    def set_corrected_infoname(self):
        # H4xor this so the 'name' field is safe
        self.correctedinfoname = fix_filebasename(self.tdef.get_name_as_unicode())

        # Allow correctedinfoname to be overwritten for multifile torrents only
        if self.get_corrected_filename() and self.get_corrected_filename() != '' and 'files' in self.tdef.get_metainfo()['info']:
            self.correctedinfoname = self.get_corrected_filename()

    @checkHandleAndSynchronize()
    def set_selected_files(self, selected_files=None):
        if not isinstance(self.tdef, TorrentDefNoMetainfo):

            if selected_files is None:
                selected_files = self.get_selected_files()
            else:
                DownloadConfigInterface.set_selected_files(self, selected_files)

            is_multifile = len(self.orig_files) > 1
            commonprefix = os.path.commonprefix(self.orig_files) if is_multifile else u''
            swarmname = commonprefix.partition(os.path.sep)[0]
            unwanteddir = os.path.join(swarmname, u'.unwanted')
            unwanteddir_abs = os.path.join(self.handle.save_path().decode('utf-8'), unwanteddir)

            filepriorities = []
            for index, orig_path in enumerate(self.orig_files):
                filename = orig_path[len(swarmname) + 1:] if swarmname else orig_path

                if filename in selected_files or not selected_files:
                    filepriorities.append(1)
                    new_path = orig_path
                else:
                    filepriorities.append(0)
                    new_path = os.path.join(unwanteddir, '%s%d' % (hexlify(self.tdef.get_infohash()), index))

                cur_path = self.handle.get_torrent_info().files()[index].path.decode('utf-8')
                if cur_path != new_path:
                    if not os.path.exists(unwanteddir_abs) and unwanteddir in new_path:
                        try:
                            os.makedirs(unwanteddir_abs)
                            if sys.platform == "win32":
                                ctypes.windll.kernel32.SetFileAttributesW(unwanteddir_abs, 2)  # 2 = FILE_ATTRIBUTE_HIDDEN
                        except:
                            self._logger.error("LibtorrentDownloadImpl: could not create %s" % unwanteddir_abs)
                            # Note: If the destination directory can't be accessed, libtorrent will not be able to store the files.
                            # This will result in a DLSTATUS_STOPPED_ON_ERROR.

                    # Path should be unicode if Libtorrent is using std::wstring (on Windows), else we use str (on Linux).
                    try:
                        self.handle.rename_file(index, new_path)
                    except TypeError:
                        self.handle.rename_file(index, new_path.encode("utf-8"))

            self.handle.prioritize_files(filepriorities)

            self.unwanteddir_abs = unwanteddir_abs

    @checkHandleAndSynchronize(False)
    def move_storage(self, new_dir):
        if not isinstance(self.tdef, TorrentDefNoMetainfo):
            self.handle.move_storage(new_dir)
            self.set_dest_dir(new_dir)
            return True

    @checkHandleAndSynchronize()
    def get_save_path(self):
        if not isinstance(self.tdef, TorrentDefNoMetainfo):
            return self.handle.save_path()

    @checkHandleAndSynchronize()
    def force_recheck(self):
        if not isinstance(self.tdef, TorrentDefNoMetainfo):
            if self.dlstate == DLSTATUS_STOPPED:
                self.pause_after_next_hashcheck = True
            self.checkpoint_after_next_hashcheck = True
            self.handle.resume()
            self.handle.force_recheck()

    def get_status(self):
        """ Returns the status of the download.
        @return DLSTATUS_*
        """
        with self.dllock:
            return self.dlstate

    def get_length(self):
        """ Returns the size of the torrent content.
        @return float
        """
        with self.dllock:
            return self.length

    def get_progress(self):
        """ Return fraction of content downloaded.
        @return float 0..1
        """
        with self.dllock:
            return self.progress

    def get_current_speed(self, dir):
        """ Return last reported speed in bytes/s
        @return float
        """
        with self.dllock:
            return self.curspeeds[dir]

    def set_moreinfo_stats(self, enable):
        """ Called by any thread """

        self.askmoreinfo = enable

    def network_get_stats(self, getpeerlist):
        """
        @return (status, stats, seeding_stats, logmsgs, coopdl_helpers, coopdl_coordinator)
        """
        # Called by any thread, assume dllock already acquired

        stats = {}
        stats['down'] = self.curspeeds[DOWNLOAD]
        stats['up'] = self.curspeeds[UPLOAD]
        stats['frac'] = self.progress
        stats['wanted'] = self.length
        stats['stats'] = self.network_create_statistics_reponse()
        stats['time'] = self.network_calc_eta()
        stats['vod_prebuf_frac'] = self.network_calc_prebuf_frac()
        stats['vod_prebuf_frac_consec'] = self.network_calc_prebuf_frac_consec()
        stats['vod'] = self.get_mode()
        stats['vod_playable'] = self.progress == 1.0 or (stats['vod_prebuf_frac'] == 1.0 and self.curspeeds[DOWNLOAD] > 0.0)
        stats['vod_playable_after'] = self.network_calc_prebuf_eta()
        stats['vod_stats'] = self.network_get_vod_stats()
        stats['spew'] = self.network_create_spew_from_peerlist() if getpeerlist or self.askmoreinfo else None

        seeding_stats = {}
        seeding_stats['total_up'] = self.all_time_upload
        seeding_stats['total_down'] = self.all_time_download
        seeding_stats['time_seeding'] = self.finished_time

        logmsgs = []

        self._logger.debug("Torrent %s PROGRESS %s QUEUEPOS %s DLSTATE %s SEEDTIME %s", self.handle.name(), self.progress, self.queue_position, self.dlstate, self.finished_time)

        return (self.dlstate, stats, seeding_stats, logmsgs)

    @checkHandleAndSynchronize()
    def network_create_statistics_reponse(self):
        status = self.handle.status()
        numTotSeeds = status.num_complete if status.num_complete >= 0 else status.list_seeds
        numTotPeers = status.num_incomplete if status.num_incomplete >= 0 else status.list_peers
        numleech = status.num_peers - status.num_seeds
        numseeds = status.num_seeds
        pieces = status.pieces
        upTotal = status.all_time_upload
        downTotal = status.all_time_download
        return LibtorrentStatisticsResponse(numTotSeeds, numTotPeers, numseeds, numleech, pieces, upTotal, downTotal)

    def network_calc_eta(self):
        bytestogof = (1.0 - self.progress) * float(self.length)
        dlspeed = max(0.000001, self.curspeeds[DOWNLOAD])
        return bytestogof / dlspeed

    def network_calc_prebuf_frac(self):
        if self.get_mode() == DLMODE_VOD and self.get_vod_fileindex() >= 0 and self.vod_seekpos != None:
            if self.endbuffsize:
                return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize), \
                                               (self.get_vod_fileindex(), -self.endbuffsize - 1, -1)])
            else:
                return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize)])
        else:
            return 0.0

    def network_calc_prebuf_frac_consec(self):
        if self.get_mode() == DLMODE_VOD and self.get_vod_fileindex() >= 0 and self.vod_seekpos != None:
            if self.endbuffsize:
                return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize), \
                                               (self.get_vod_fileindex(), -self.endbuffsize - 1, -1)], consecutive=True)
            else:
                return self.get_byte_progress([(self.get_vod_fileindex(), self.vod_seekpos, self.vod_seekpos + self.prebuffsize)], consecutive=True)
        else:
            return 0.0

    def network_calc_prebuf_eta(self):
        bytestogof = (1.0 - self.network_calc_prebuf_frac()) * float(self.prebuffsize)
        dlspeed = max(0.000001, self.curspeeds[DOWNLOAD])
        return bytestogof / dlspeed

    def network_get_vod_stats(self):
        d = {}
        d['played'] = None
        d['late'] = None
        d['dropped'] = None
        d['stall'] = None
        d['pos'] = None
        d['prebuf'] = None
        d['firstpiece'] = 0
        d['npieces'] = ((self.length + 1023) / 1024)
        return d

    def network_create_spew_from_peerlist(self):
        plist = []
        with self.dllock:
            peer_infos = self.handle.get_peer_info()
        for peer_info in peer_infos:
            peer_dict = {}
            peer_dict['id'] = peer_info.pid
            peer_dict['extended_version'] = peer_info.client
            peer_dict['ip'] = peer_info.ip[0]
            peer_dict['port'] = peer_info.ip[1]
            peer_dict['optimistic'] = bool(peer_info.flags & 2048)  # optimistic_unchoke = 0x800 seems unavailable in python bindings
            peer_dict['direction'] = 'L' if bool(peer_info.flags & peer_info.local_connection) else 'R'
            peer_dict['uprate'] = peer_info.payload_up_speed
            peer_dict['uinterested'] = bool(peer_info.flags & peer_info.remote_interested)
            peer_dict['uchoked'] = bool(peer_info.flags & peer_info.remote_choked)
            peer_dict['uhasqueries'] = peer_info.upload_queue_length > 0
            peer_dict['uflushed'] = peer_info.used_send_buffer > 0
            peer_dict['downrate'] = peer_info.payload_down_speed
            peer_dict['dinterested'] = bool(peer_info.flags & peer_info.interesting)
            peer_dict['dchoked'] = bool(peer_info.flags & peer_info.choked)
            peer_dict['snubbed'] = bool(peer_info.flags & 4096)  # snubbed = 0x1000 seems unavailable in python bindings
            peer_dict['utotal'] = peer_info.total_upload
            peer_dict['dtotal'] = peer_info.total_download
            peer_dict['completed'] = peer_info.progress
            peer_dict['have'] = peer_info.pieces
            peer_dict['speed'] = peer_info.remote_dl_rate
            peer_dict['country'] = peer_info.country
            plist.append(peer_dict)

        return plist

    def set_state_callback(self, usercallback, getpeerlist=False, delay=0.0):
        """ Called by any thread """
        with self.dllock:
            network_get_state_lambda = lambda: self.network_get_state(usercallback, getpeerlist)
            self.session.lm.rawserver.add_task(network_get_state_lambda, delay)

    def network_get_state(self, usercallback, getpeerlist, sessioncalling=False):
        """ Called by network thread """
        with self.dllock:
            if self.handle is None:
                self._logger.debug("LibtorrentDownloadImpl: network_get_state: Download not running")
                ds = DownloadState(self, DLSTATUS_WAITING4HASHCHECK, self.error, self.progressbeforestop)
            else:
                (status, stats, seeding_stats, logmsgs) = self.network_get_stats(getpeerlist)
                ds = DownloadState(self, status, self.error, self.get_progress(), stats=stats, seeding_stats=seeding_stats, filepieceranges=self.filepieceranges, logmsgs=logmsgs)
                self.progressbeforestop = ds.get_progress()

            if sessioncalling:
                return ds

            # Invoke the usercallback function via a new thread.
            # After the callback is invoked, the return values will be passed to the returncallback for post-callback processing.
            if not self.done:
                self.session.uch.perform_getstate_usercallback(usercallback, ds, self.sesscb_get_state_returncallback)

    def sesscb_get_state_returncallback(self, usercallback, when, newgetpeerlist):
        """ Called by SessionCallbackThread """
        with self.dllock:
            if when > 0.0:
                # Schedule next invocation, either on general or DL specific
                network_get_state_lambda = lambda: self.network_get_state(usercallback, newgetpeerlist)
                self.session.lm.rawserver.add_task(network_get_state_lambda, when)

    def stop(self):
        """ Called by any thread """
        self.stop_remove(removestate=False, removecontent=False)

    def stop_remove(self, removestate=False, removecontent=False):
        """ Called by any thread. Called on Session.remove_download() """
        self.done = removestate
        self.network_stop(removestate=removestate, removecontent=removecontent)

    def network_stop(self, removestate, removecontent):
        """ Called by network thread, but safe for any """
        with self.dllock:
            self._logger.debug("LibtorrentDownloadImpl: network_stop %s", self.tdef.get_name())

            pstate = self.network_get_persistent_state()
            if self.handle is not None:
                self._logger.debug("LibtorrentDownloadImpl: network_stop: engineresumedata from torrent handle")
                if removestate:
                    self.ltmgr.remove_torrent(self, removecontent)
                    self.handle = None
                else:
                    self.set_vod_mode(False)
                    self.handle.pause()
                    pstate.set('state', 'engineresumedata', self.handle.write_resume_data() if isinstance(self.tdef, TorrentDef) else None)
                self.pstate_for_restart = pstate
            else:
                # This method is also called at Session shutdown, where one may
                # choose to checkpoint its Download. If the Download was
                # stopped before, pstate_for_restart contains its resumedata.
                # and that should be written into the checkpoint.
                #
                if self.pstate_for_restart is not None:
                    self._logger.debug("LibtorrentDownloadImpl: network_stop: Reusing previously saved engineresume data for checkpoint")
                    # Don't copy full pstate_for_restart, as the torrent
                    # may have gone from e.g. HASHCHECK at startup to STOPPED
                    # now, at shutdown. In other words, it was never active
                    # in this session and the pstate_for_restart still says
                    # HASHCHECK.
                    pstate.set('state', 'engineresumedata', self.pstate_for_restart.get('state', 'engineresumedata'))
                else:
                    self._logger.debug("LibtorrentDownloadImpl: network_stop: Could not reuse engineresumedata as pstart_for_restart is None")

            # Offload the removal of the dlcheckpoint to another thread
            if removestate:
                self.session.uch.perform_removestate_callback(self.tdef.get_infohash(), None)

            return (self.tdef.get_infohash(), pstate)

    def get_content_dest(self):
        """ Returns the file to which the downloaded content is saved. """
        return os.path.join(self.get_dest_dir(), self.correctedinfoname)

    def set_filepieceranges(self):
        """ Determine which file maps to which piece ranges for progress info """
        self._logger.debug("LibtorrentDownloadImpl: set_filepieceranges: %s", self.get_selected_files())

        metainfo = self.tdef.get_metainfo()
        self.filepieceranges = maketorrent.get_length_filepieceranges_from_metainfo(metainfo, [])[1]

    def restart(self, initialdlstatus=None):
        """ Restart the Download """
        # Called by any thread
        self._logger.debug("LibtorrentDownloadImpl: restart: %s", self.tdef.get_name())

        with self.dllock:
            if self.handle is None:
                self.error = None
                self.create_engine_wrapper(self.session.lm.network_engine_wrapper_created_callback, self.pstate_for_restart, initialdlstatus=initialdlstatus)
            else:
                self.handle.resume()
                self.set_vod_mode(self.get_mode() == DLMODE_VOD)

    def set_max_desired_speed(self, direct, speed):
        self._logger.debug("LibtorrentDownloadImpl: set_max_desired_speed %s %s", direct, speed)

        with self.dllock:
            if direct == UPLOAD:
                self.dlruntimeconfig['max_desired_upload_rate'] = speed
            else:
                self.dlruntimeconfig['max_desired_download_rate'] = speed

    def get_max_desired_speed(self, direct):
        with self.dllock:
            if direct == UPLOAD:
                return self.dlruntimeconfig['max_desired_upload_rate']
            else:
                return self.dlruntimeconfig['max_desired_download_rate']

    @checkHandleAndSynchronize()
    def get_dest_files(self, exts=None):
        """
        You can give a list of extensions to return. If None: return all dest_files
        @return list of (torrent,disk) filename tuples.
        """

        dest_files = []
        for index, file_entry in enumerate(self.handle.get_torrent_info().files()):
            if self.handle.file_priority(index) > 0:
                filename = file_entry.path
                ext = os.path.splitext(filename)[1].lstrip('.')
                if exts is None or ext in exts:
                    dest_files.append((filename, os.path.join(self.get_dest_dir(), filename.decode('utf-8'))))
        return dest_files

    def checkpoint(self):
        """ Called by any thread """
        (infohash, pstate) = self.network_checkpoint()
        checkpoint = lambda: self.session.lm.save_download_pstate(infohash, pstate)
        self.session.lm.rawserver.add_task(checkpoint, 0)

    def network_checkpoint(self):
        """ Called by network thread """
        with self.dllock:
            pstate = self.network_get_persistent_state()
            resdata = None
            if self.handle == None:
                if self.pstate_for_restart is not None:
                    resdata = self.pstate_for_restart.get('state', 'engineresumedata')
            elif isinstance(self.tdef, TorrentDef):
                resdata = self.handle.write_resume_data()
            pstate.set('state', 'engineresumedata', resdata)
            return (self.tdef.get_infohash(), pstate)

    def network_get_persistent_state(self):
        # Assume sessionlock is held

        pstate = self.dlconfig.copy()

        # Reset unpicklable params
        pstate.set('downloadconfig', 'mode', DLMODE_NORMAL)

        # Add state stuff
        if not pstate.has_section('state'):
            pstate.add_section('state')
        pstate.set('state', 'version', PERSISTENTSTATE_CURRENTVERSION)
        if isinstance(self.tdef, TorrentDefNoMetainfo):
            pstate.set('state', 'metainfo', {'infohash': self.tdef.get_infohash(), 'name': self.tdef.get_name_as_unicode(), 'url': self.tdef.get_url()})
        else:
            pstate.set('state', 'metainfo', self.tdef.get_metainfo())

        ds = self.network_get_state(None, False, sessioncalling=True)
        dlstate = {'status': ds.get_status(), 'progress': ds.get_progress(), 'swarmcache': None}
        pstate.set('state', 'dlstate', dlstate)

        self._logger.debug("LibtorrentDownloadImpl: network_get_persistent_state: status %s progress %s", dlstatus_strings[ds.get_status()], ds.get_progress())

        pstate.set('state', 'engineresumedata', None)
        return pstate

    def set_def(self, tdef):
        with self.dllock:
            self.tdef = tdef

    @checkHandleAndSynchronize()
    def add_trackers(self, trackers):
        if hasattr(self.handle, 'add_tracker'):
            for tracker in trackers:
                self.handle.add_tracker({'url': tracker, 'verified': False})

    @checkHandleAndSynchronize()
    def get_magnet_link(self):
        return lt.make_magnet_uri(self.handle)

    #
    # External addresses
    #
    @waitForHandleAndSynchronize()
    def add_peer(self, addr):
        """ Add a peer address from 3rd source (not tracker, not DHT) to this download.
        @param (hostname_ip,port) tuple
        """
        self.handle.connect_peer(addr, 0)

    @waitForHandleAndSynchronize(True)
    def dlconfig_changed_callback(self, section, name, new_value, old_value):
        if section == 'downloadconfig' and name == 'max_upload_rate':
            self.handle.set_upload_limit(int(new_value * 1024))
        elif section == 'downloadconfig' and name == 'max_download_rate':
            self.handle.set_download_limit(int(new_value * 1024))
        elif section == 'downloadconfig' and name in ['correctedfilename', 'super_seeder']:
            return False
        return True


class LibtorrentStatisticsResponse:

    def __init__(self, numTotSeeds, numTotPeers, numseeds, numleech, have, upTotal, downTotal):
        self.numTotSeeds = numTotSeeds
        self.numTotPeers = numTotPeers
        self.numSeeds = numseeds
        self.numPeers = numleech
        self.have = have
        self.upTotal = upTotal
        self.downTotal = downTotal
        self.numConCandidates = 0
        self.numConInitiated = 0

########NEW FILE########
__FILENAME__ = LibtorrentMgr

# Written by Egbert Bouman
import os
import time
import binascii
import threading
import libtorrent as lt

import logging
from copy import deepcopy
from shutil import rmtree

from Tribler.Core.version import version_id
from Tribler.Core.exceptions import DuplicateDownloadException
from Tribler.Core import NoDispersyRLock
from Tribler.Core.Utilities.utilities import parse_magnetlink
from Tribler.Core.CacheDB.Notifier import Notifier
from Tribler.Core.simpledefs import NTFY_MAGNET_STARTED, NTFY_TORRENTS, NTFY_MAGNET_CLOSE, NTFY_MAGNET_GOT_PEERS

DEBUG = False
DHTSTATE_FILENAME = "ltdht.state"
METAINFO_CACHE_PERIOD = 5 * 60
METAINFO_TMPDIR = 'metadata_tmpdir'

class LibtorrentMgr:
    # Code to make this a singleton
    __single = None

    def __init__(self, trsession, ignore_singleton=False):
        if not ignore_singleton:
            if LibtorrentMgr.__single:
                raise RuntimeError("LibtorrentMgr is singleton")
            LibtorrentMgr.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        self.trsession = trsession
        self.notifier = Notifier.getInstance()
        settings = lt.session_settings()
        settings.user_agent = 'Tribler/' + version_id
        # Elric: Strip out the -rcX, -beta, -whatever tail on the version string.
        fingerprint = ['TL'] + map(int, version_id.split('-')[0].split('.')) + [0]
        # Workaround for libtorrent 0.16.3 segfault (see https://code.google.com/p/libtorrent/issues/detail?id=369)
        self.ltsession = lt.session(lt.fingerprint(*fingerprint), flags=1)
        self.ltsession.set_settings(settings)
        self.ltsession.set_alert_mask(lt.alert.category_t.stats_notification |
                                      lt.alert.category_t.error_notification |
                                      lt.alert.category_t.status_notification |
                                      lt.alert.category_t.storage_notification |
                                      lt.alert.category_t.performance_warning)

        listen_port = self.trsession.get_listen_port()
        self.ltsession.listen_on(listen_port, listen_port + 10)
        if listen_port != self.ltsession.listen_port():
            self.trsession.set_listen_port_runtime(self.ltsession.listen_port())

        self.set_upload_rate_limit(-1)
        self.set_download_rate_limit(-1)
        self.upnp_mapper = self.ltsession.start_upnp()

        self._logger.info("LibtorrentMgr: listening on %d", self.ltsession.listen_port())

        # Start DHT
        self.dht_ready = False
        try:
            dht_state = open(os.path.join(self.trsession.get_state_dir(), DHTSTATE_FILENAME)).read()
            self.ltsession.start_dht(lt.bdecode(dht_state))
        except:
            self._logger.error("LibtorrentMgr: could not restore dht state, starting from scratch")
            self.ltsession.start_dht(None)

        self.ltsession.add_dht_router('router.bittorrent.com', 6881)
        self.ltsession.add_dht_router('router.utorrent.com', 6881)
        self.ltsession.add_dht_router('router.bitcomet.com', 6881)

        # Load proxy settings
        self.set_proxy_settings(self.ltsession, *self.trsession.get_libtorrent_proxy_settings())

        self.set_utp(self.trsession.get_libtorrent_utp())

        self.external_ip = None

        self.torlock = NoDispersyRLock()
        self.torrents = {}

        self.metainfo_requests = {}
        self.metainfo_lock = threading.RLock()
        self.metainfo_cache = {}

        self.trsession.lm.rawserver.add_task(self.process_alerts, 1)
        self.trsession.lm.rawserver.add_task(self.reachability_check, 1)
        self.trsession.lm.rawserver.add_task(self.monitor_dht, 5)

        self.upnp_mappings = {}

        # make tmp-dir to be used for dht collection
        self.metadata_tmpdir = os.path.join(self.trsession.get_state_dir(), METAINFO_TMPDIR)
        if not os.path.exists(self.metadata_tmpdir):
            os.mkdir(self.metadata_tmpdir)

        self.ltsession_anon = None

    def getInstance(*args, **kw):
        if LibtorrentMgr.__single is None:
            LibtorrentMgr(*args, **kw)
        return LibtorrentMgr.__single
    getInstance = staticmethod(getInstance)
    ''' :type : () -> LibtorrentMgr '''

    def delInstance():
        del LibtorrentMgr.__single
        LibtorrentMgr.__single = None
    delInstance = staticmethod(delInstance)

    def hasInstance():
        return LibtorrentMgr.__single != None
    hasInstance = staticmethod(hasInstance)

    def is_anon_ready(self):
        return self.ltsession_anon is not None

    def create_anonymous_session(self):
        settings = lt.session_settings()
        settings.enable_outgoing_utp = True
        settings.enable_incoming_utp = True
        settings.enable_outgoing_tcp = False
        settings.enable_incoming_tcp = False
        settings.anonymous_mode = True
        ltsession = lt.session(flags=1)
        ltsession.set_settings(settings)
        ltsession.set_alert_mask(lt.alert.category_t.stats_notification |
                                 lt.alert.category_t.error_notification |
                                 lt.alert.category_t.status_notification |
                                 lt.alert.category_t.storage_notification |
                                 lt.alert.category_t.performance_warning |
                                 lt.alert.category_t.debug_notification)


        self.set_proxy_settings(ltsession, *self.trsession.get_anon_proxy_settings())
        self.ltsession_anon = ltsession

        ltsession.listen_on(self.trsession.get_anon_listen_port(), self.trsession.get_anon_listen_port()+10)
        self._logger.info("Started ANON LibTorrent session on port %d", ltsession.listen_port())

    def shutdown(self):
        # Save DHT state
        dhtstate_file = open(os.path.join(self.trsession.get_state_dir(), DHTSTATE_FILENAME), 'w')
        dhtstate_file.write(lt.bencode(self.ltsession.dht_state()))
        dhtstate_file.close()

        del self.ltsession
        self.ltsession = None

        # Empty/remove metadata tmp-dir
        if os.path.exists(self.metadata_tmpdir):
            rmtree(self.metadata_tmpdir)

    def set_proxy_settings(self, ltsession, ptype, server=None, auth=None):
        proxy_settings = lt.proxy_settings()
        proxy_settings.type = lt.proxy_type(ptype)
        if server:
            proxy_settings.hostname = server[0]
            proxy_settings.port = server[1]
        if auth:
            proxy_settings.username = auth[0]
            proxy_settings.password = auth[1]
        proxy_settings.proxy_hostnames = True
        proxy_settings.proxy_peer_connections = True
        ltsession.set_proxy(proxy_settings)

    def set_utp(self, enable):
        settings = self.ltsession.settings()
        settings.enable_outgoing_utp = enable
        settings.enable_incoming_utp = enable
        self.ltsession.set_settings(settings)

    def set_max_connections(self, conns):
        self.ltsession.set_max_connections(conns)

    def set_upload_rate_limit(self, rate):
        self.ltsession.set_upload_rate_limit(int(rate))

    def get_upload_rate_limit(self):
        return self.ltsession.upload_rate_limit()

    def set_download_rate_limit(self, rate):
        self.ltsession.set_download_rate_limit(int(rate))

    def get_download_rate_limit(self):
        return self.ltsession.download_rate_limit()

    def get_external_ip(self):
        return self.external_ip

    def get_dht_nodes(self):
        return self.ltsession.status().dht_nodes

    def is_dht_ready(self):
        return self.dht_ready

    def add_torrent(self, torrentdl, atp):
        # If we are collecting the torrent for this infohash, abort this first.
        with self.metainfo_lock:
            anon_mode = atp.pop('anon_mode', False)
            ltsession = self.ltsession_anon if anon_mode else self.ltsession

            if atp.has_key('ti'):
                infohash = str(atp['ti'].info_hash())
            elif atp.has_key('url'):
                infohash = binascii.hexlify(parse_magnetlink(atp['url'])[1])
            else:
                infohash = str(atp["info_hash"])

            if infohash in self.metainfo_requests:
                self._logger.info("LibtorrentMgr: killing get_metainfo request for %s", infohash)
                handle, _, _ = self.metainfo_requests.pop(infohash)
                if handle:
                    ltsession.remove_torrent(handle, 0)

            handle = ltsession.add_torrent(encode_atp(atp))
            infohash = str(handle.info_hash())
            with self.torlock:
                if infohash in self.torrents:
                    raise DuplicateDownloadException()
                self.torrents[infohash] = (torrentdl, ltsession)

            self._logger.debug("LibtorrentMgr: added torrent %s", infohash)

            return handle

    def remove_torrent(self, torrentdl, removecontent=False):
        handle = torrentdl.handle
        if handle and handle.is_valid():
            infohash = str(handle.info_hash())
            with self.torlock:
                if infohash in self.torrents:
                    self.torrents[infohash][1].remove_torrent(handle, int(removecontent))
                    del self.torrents[infohash]
                    self._logger.debug("LibtorrentMgr: remove torrent %s", infohash)
                else:
                    self._logger.debug("LibtorrentMgr: cannot remove torrent %s because it does not exists", infohash)
        else:
            self._logger.debug("LibtorrentMgr: cannot remove invalid torrent")

    def add_mapping(self, port, protocol='TCP'):
        if self.upnp_mapper:
            protocol_type = 2 if protocol == 'TCP' else 1
            self.upnp_mappings[(port, protocol)] = self.upnp_mapper.add_mapping(protocol_type, port, port)

    def delete_mapping(self, port, protocol='TCP'):
        if self.upnp_mapper:
            mapping = self.upnp_mappings[(port, protocol)]
            self.upnp_mapper.delete_mapping(mapping)

    def delete_mappings(self):
        if self.upnp_mapper:
            for mapping in self.upnp_mappings.itervalues():
                self.upnp_mapper.delete_mapping(mapping)

    def process_alerts(self):
        for ltsession in [self.ltsession, self.ltsession_anon]:
            if ltsession:
                alert = ltsession.pop_alert()
                while alert:
                    self.process_alert(alert)
                    alert = ltsession.pop_alert()

        self.trsession.lm.rawserver.add_task(self.process_alerts, 1)

    def process_alert(self, alert):
        alert_type = str(type(alert)).split("'")[1].split(".")[-1]
        if alert_type == 'external_ip_alert':
            external_ip = str(alert).split()[-1]
            if self.external_ip != external_ip:
                self.external_ip = external_ip
                self._logger.info('LibtorrentMgr: external IP is now %s', self.external_ip)
        handle = getattr(alert, 'handle', None)
        if handle:
            if handle.is_valid():
                infohash = str(handle.info_hash())
                with self.torlock:
                    if infohash in self.torrents:
                        self.torrents[infohash][0].process_alert(alert, alert_type)
                    elif infohash in self.metainfo_requests:
                        if type(alert) == lt.metadata_received_alert:
                            self.got_metainfo(infohash)
                    else:
                        self._logger.debug("LibtorrentMgr: could not find torrent %s", infohash)
            else:
                self._logger.debug("LibtorrentMgr: alert for invalid torrent")

    def reachability_check(self):
        if self.ltsession and self.ltsession.status().has_incoming_connections:
            self.trsession.lm.rawserver.add_task(self.trsession.lm.dialback_reachable_callback, 3)
        else:
            self.trsession.lm.rawserver.add_task(self.reachability_check, 10)

    def monitor_dht(self, chances_remaining=1):
        # Sometimes the dht fails to start. To workaround this issue we monitor the #dht_nodes, and restart if needed.
        if self.ltsession:
            if self.get_dht_nodes() <= 25:
                if self.get_dht_nodes() >= 5 and chances_remaining:
                    self._logger.info("LibtorrentMgr: giving the dht a chance (%d, %d)", self.ltsession.status().dht_nodes, chances_remaining)
                    self.trsession.lm.rawserver.add_task(lambda: self.monitor_dht(chances_remaining - 1), 5)
                else:
                    self._logger.info("LibtorrentMgr: restarting dht because not enough nodes are found (%d, %d)" % (self.ltsession.status().dht_nodes, chances_remaining))
                    self.ltsession.start_dht(None)
                    self.trsession.lm.rawserver.add_task(self.monitor_dht, 10)
            else:
                self._logger.info("LibtorrentMgr: dht is working enough nodes are found (%d)", self.ltsession.status().dht_nodes)
                self.dht_ready = True
                return
        else:
            self.trsession.lm.rawserver.add_task(self.monitor_dht, 10)

    def get_peers(self, infohash, callback, timeout=30):
        def on_metainfo_retrieved(metainfo, infohash=infohash, callback=callback):
            callback(infohash, metainfo.get('initial peers', []))
        self.get_metainfo(infohash, on_metainfo_retrieved, timeout, notify=False)

    def get_metainfo(self, infohash_or_magnet, callback, timeout=30, notify=True):
        if not self.is_dht_ready() and timeout > 5:
            self._logger.info("LibtorrentMgr: DHT not ready, rescheduling get_metainfo")
            self.trsession.lm.rawserver.add_task(lambda i=infohash_or_magnet, c=callback, t=timeout - 5, n=notify: self.get_metainfo(i, c, t, n), 5)
            return

        magnet = infohash_or_magnet if infohash_or_magnet.startswith('magnet') else None
        infohash_bin = infohash_or_magnet if not magnet else parse_magnetlink(magnet)[1]
        infohash = binascii.hexlify(infohash_bin)

        with self.torlock:
            if infohash in self.torrents:
                return

        with self.metainfo_lock:
            self._logger.debug('LibtorrentMgr: get_metainfo %s %s %s', infohash_or_magnet, callback, timeout)

            cache_result = self._get_cached_metainfo(infohash)
            if cache_result:
                self.trsession.uch.perform_usercallback(lambda cb=callback, mi=deepcopy(cache_result): cb(mi))

            elif infohash not in self.metainfo_requests:
                # Flags = 4 (upload mode), should prevent libtorrent from creating files
                atp = {'save_path': self.metadata_tmpdir, 'duplicate_is_error': True, 'paused': False, 'auto_managed': False, 'flags': 4}
                if magnet:
                    atp['url'] = magnet
                else:
                    atp['info_hash'] = lt.big_number(infohash_bin)
                handle = self.ltsession.add_torrent(encode_atp(atp))
                if notify:
                    self.notifier.notify(NTFY_TORRENTS, NTFY_MAGNET_STARTED, infohash_bin)

                self.metainfo_requests[infohash] = [handle, [callback], notify]
                self.trsession.lm.rawserver.add_task(lambda: self.got_metainfo(infohash, True), timeout)

            else:
                self.metainfo_requests[infohash][2] = self.metainfo_requests[infohash][2] and notify
                callbacks = self.metainfo_requests[infohash][1]
                if callback not in callbacks:
                    callbacks.append(callback)
                else:
                    self._logger.debug('LibtorrentMgr: get_metainfo duplicate detected, ignoring')

    def got_metainfo(self, infohash, timeout=False):
        with self.metainfo_lock:
            infohash_bin = binascii.unhexlify(infohash)

            if infohash in self.metainfo_requests:
                handle, callbacks, notify = self.metainfo_requests.pop(infohash)

                self._logger.debug('LibtorrentMgr: got_metainfo %s %s %s', infohash, handle, timeout)

                if handle and callbacks and not timeout:
                    metainfo = {"info": lt.bdecode(handle.get_torrent_info().metadata())}
                    trackers = [tracker.url for tracker in handle.get_torrent_info().trackers()]
                    peers = [peer.ip for peer in handle.get_peer_info()]
                    if trackers:
                        if len(trackers) > 1:
                            metainfo["announce-list"] = [trackers]
                        metainfo["announce"] = trackers[0]
                    else:
                        metainfo["nodes"] = []
                    if peers:
                        metainfo["initial peers"] = peers
                        if notify:
                            self.notifier.notify(NTFY_TORRENTS, NTFY_MAGNET_GOT_PEERS, infohash_bin, len(peers))

                    self._add_cached_metainfo(infohash, metainfo)

                    for callback in callbacks:
                        self.trsession.uch.perform_usercallback(lambda cb=callback, mi=deepcopy(metainfo): cb(mi))

                    # let's not print the hashes of the pieces
                    debuginfo = deepcopy(metainfo)
                    del debuginfo['info']['pieces']
                    self._logger.debug('LibtorrentMgr: got_metainfo result %s', debuginfo)

                if handle:
                    self.ltsession.remove_torrent(handle, 1)
                    if notify:
                        self.notifier.notify(NTFY_TORRENTS, NTFY_MAGNET_CLOSE, infohash_bin)

    def _clean_metainfo_cache(self):
        oldest_valid_ts = time.time() - METAINFO_CACHE_PERIOD

        for key, values in self.metainfo_cache.items():
            ts, _ = values
            if ts < oldest_valid_ts:
                del self.metainfo_cache[key]

    def _get_cached_metainfo(self, infohash):
        self._clean_metainfo_cache()

        if infohash in self.metainfo_cache:
            return self.metainfo_cache[infohash][1]

    def _add_cached_metainfo(self, infohash, metainfo):
        self._clean_metainfo_cache()

        if infohash not in self.metainfo_cache:
            self.metainfo_cache[infohash] = (time.time(), metainfo)
        else:
            self.metainfo_cache[infohash][1] = metainfo

def encode_atp(atp):
    for k, v in atp.iteritems():
        if isinstance(v, unicode):
            atp[k] = v.encode('utf-8')
    return atp
########NEW FILE########
__FILENAME__ = merkle
# Written by Arno Bakker
# see LICENSE.txt for license information
"""
Reference Implementation of Merkle hash torrent extension, as now
standardized in http://www.bittorrent.org/beps/bep_0030.html (yay!)
"""

from math import log, floor
from Tribler.Core.Utilities.Crypto import sha
import logging

logger = logging.getLogger(__name__)

# External classes


class MerkleTree:

    def __init__(self, piece_size, total_length, root_hash=None,hashes=None):
        """
        Create a Merkle hash tree

        When creating a .torrent:
            root_hash is None and hashes is not None
        When creating an initial seeder:
            root_hash is None and hashes is not None
            (root_hash is None to allow comparison with the calculated
             root hash and the one in the .torrent)
        When creating a downloader:
            root_hash is not None and hashes is None
        """
        self.npieces = len2npieces(piece_size, total_length)
        self.treeheight = get_tree_height(self.npieces)
        self.tree = create_tree(self.treeheight)
        if hashes is None:
            self.root_hash = root_hash
        else:
            fill_tree(self.tree, self.treeheight, self.npieces, hashes)
            # root_hash is None during .torrent generation
            if root_hash is None:
                self.root_hash = self.tree[0]
            else:
                raise AssertionError("merkle: if hashes not None, root_hash must be")

    def get_root_hash(self):
        return self.root_hash

    def compare_root_hashes(self, other):
        return self.root_hash == other

    def get_hashes_for_piece(self, index):
        return get_hashes_for_piece(self.tree, self.treeheight, index)

    def check_hashes(self, hashlist):
        return check_tree_path(self.root_hash, self.treeheight, hashlist)

    def update_hash_admin(self, hashlist, piece_hashes):
        update_hash_admin(hashlist, self.tree, self.treeheight, piece_hashes)

    def get_piece_hashes(self):
        """
        Get the pieces' hashes from the bottom of the hash tree. Used during
        a graceful restart of a client that already downloaded stuff.
        """
        return get_piece_hashes(self.tree, self.treeheight, self.npieces)


def create_fake_hashes(info):
    total_length = calc_total_length(info)
    npieces = len2npieces(info['piece length'], total_length)
    return ['\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'] * npieces


# Internal functions
# Design choice: all algoritmics have been returned into stateless functions,
# i.e. they operate on the input parameters only. This to keep them extremely
# clear.

def len2npieces(piece_size, total_length):
    npieces = total_length / piece_size
    if piece_size * npieces < total_length:
        npieces += 1
    return npieces


def calc_total_length(info):
    # Merkle: Calculate total length from .torrent info
    if 'length' in info:
        return info['length']
    # multi-file torrent
    files = info['files']
    total_length = 0
    for i in range(0, len(files)):
        total_length += files[i]['length']
    return total_length


def get_tree_height(npieces):
    logger.debug("merkle: number of pieces is %s", npieces)
    height = log(npieces, 2)
    if height - floor(height) > 0.0:
        height = int(height) + 1
    else:
        height = int(height)
    logger.debug("merkle: tree height is %s", height)
    return height


def create_tree(height):
    # Create tree that has enough leaves to hold all hashes
    treesize = int(pow(2, height + 1) -1) # subtract unused tail
    logger.debug("merkle: treesize %s", treesize)
    tree = ['\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'] * treesize
    return tree


def fill_tree(tree, height, npieces, hashes):
    # 1. Fill bottom of tree with hashes
    startoffset = int(pow(2, height) - 1)
    logger.debug("merkle: bottom of tree starts at %s", startoffset)
    for offset in range(startoffset, startoffset + npieces):
        # print >> sys.stderr,"merkle: copying",offset
        # print >> sys.stderr,"merkle: hashes[",offset-startoffset,"]=",str(hashes[offset-startoffset])
        tree[offset] = hashes[offset - startoffset]
    # 2. Note that unused leaves are NOT filled. It may be a good idea to fill
    # them as hashing 0 values may create a security problem. However, the
    # filler values would have to be known to any initial seeder, otherwise it
    # will not be able build the same hash tree as the other initial seeders.
    # Assume anyone should be able to autonomously become a seeder, the filler
    # must be public info. I don't know whether having public info as filler
    # instead of 0s is any safer, cryptographically speaking. Hence, we stick
    # with 0 for the moment

    # 3. Calculate higher level hashes from leaves
    for level in range(height, 0, -1):
        logger.debug("merkle: calculating level %s", level)
        for offset in range(int(pow(2, level) - 1), int(pow(2, level +1)-2), 2):
            # print >> sys.stderr,"merkle: data offset",offset
            [parentstartoffset, parentoffset] = get_parent_offset(offset, level)
            # print >> sys.stderr,"merkle: parent offset",parentoffset
            data = tree[offset] + tree[offset +1]
            digester = sha()
            digester.update(data)
            digest = digester.digest()
            tree[parentoffset] = digest
    # for offset in range(0,treesize-1):
    #        print offset,"HASH",str(tree[offset])
    return tree


def get_hashes_for_piece(tree, height, index):
    startoffset = int(pow(2, height) - 1)
    myoffset = startoffset + index
    logger.debug("merkle: myoffset %s", myoffset)
    # 1. Add piece's own hash
    hashlist = [[myoffset, tree[myoffset]]]
    # 2. Add hash of piece's sibling, left or right
    if myoffset % 2 == 0:
        siblingoffset = myoffset - 1
    else:
        siblingoffset = myoffset + 1
    logger.debug("merkle: siblingoffset %s", siblingoffset)
    if siblingoffset != -1:
        hashlist.append([siblingoffset, tree[siblingoffset]])
    # 3. Add hashes of uncles
    uncleoffset = myoffset
    for level in range(height, 0, -1):
        uncleoffset = get_uncle_offset(uncleoffset, level)
        logger.debug("merkle: uncleoffset %s", uncleoffset)
        hashlist.append([uncleoffset, tree[uncleoffset]])
    return hashlist


def check_tree_path(root_hash, height, hashlist):
    """
    The hashes should be in the right order in the hashlist, otherwise
    the peer will be kicked. The hashlist parameter is assumed to be
    of the right type, and contain values of the right type as well.
    The exact values should be checked for validity here.
    """
    maxoffset = int(pow(2, height + 1) -2)
    mystartoffset = int(pow(2, height) - 1)
    i = 0
    a = hashlist[i]
    if a[0] < 0 or a[0] > maxoffset:
        return False
    i += 1
    b = hashlist[i]
    if b[0] < 0 or b[0] > maxoffset:
        return False
    i += 1
    myindex = a[0] - mystartoffset
    sibindex = b[0] - mystartoffset
    for level in range(height, 0, -1):
        logger.debug("merkle: checking level %s", level)
        a = check_fork(a, b, level)
        b = hashlist[i]
        if b[0] < 0 or b[0] > maxoffset:
            return False
        i += 1
    logger.debug("merkle: ROOT HASH %s == %s", repr(str(root_hash)), repr(str(a[1])))
    if a[1] == root_hash:
        return True
    else:
        return False


def update_hash_admin(hashlist, tree, height, hashes):
    mystartoffset = int(pow(2, height) - 1)
    for i in range(0, len(hashlist)):
        if i < 2:
            # me and sibling real hashes of piece data, save them
            index = hashlist[i][0] - mystartoffset
            # ignore siblings that are just tree filler
            if index < len(hashes):
                logger.debug("merkle: update_hash_admin: saving hash of %s", index)
                hashes[index] = hashlist[i][1]
        # put all hashes in tree, such that we incrementally learn it
        # and can pass them on to others
        tree[hashlist[i][0]] = hashlist[i][1]


def check_fork(a, b, level):
    myoffset = a[0]
    siblingoffset = b[0]
    if myoffset > siblingoffset:
        data = b[1] + a[1]
        logger.debug("merkle: combining %s %s", siblingoffset, myoffset)
    else:
        data = a[1] + b[1]
        logger.debug("merkle: combining %s %s", myoffset, siblingoffset)
    digester = sha()
    digester.update(data)
    digest = digester.digest()
    [parentstartoffset, parentoffset] = get_parent_offset(myoffset, level - 1)
    return [parentoffset, digest]


def get_parent_offset(myoffset, level):
    parentstartoffset = int(pow(2, level) - 1)
    mystartoffset = int(pow(2, level + 1) -1)
    parentoffset = parentstartoffset + (myoffset - mystartoffset) /2
    return [parentstartoffset, parentoffset]


def get_uncle_offset(myoffset, level):
    if level == 1:
        return 0
    [parentstartoffset, parentoffset] = get_parent_offset(myoffset, level - 1)
    logger.debug("merkle: parent offset %s", parentoffset)
    parentindex = parentoffset - parentstartoffset
    if parentoffset % 2 == 0:
        uncleoffset = parentoffset - 1
    else:
        uncleoffset = parentoffset + 1
    return uncleoffset


def get_piece_hashes(tree, height, npieces):
    startoffset = int(pow(2, height) - 1)
    hashes = ['\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'] * npieces
    for offset in range(startoffset, startoffset + npieces):
        hashes[offset - startoffset] = tree[offset]
    return hashes

########NEW FILE########
__FILENAME__ = MessageID
# Written by Jie Yang, Arno Bakker
# Updated by George Milescu
# see LICENSE.txt for license information
#
# All message IDs in BitTorrent Protocol and our extensions
#
#    Arno: please don't define stuff until the spec is ready
#

protocol_name = 'BitTorrent protocol'
# Enable Tribler extensions:
# Left-most bit = Azureus Enhanced Messaging Protocol (AEMP)
# Left+42 bit = Tribler Simple Merkle Hashes extension v0. Outdated, but still sent for compatibility.
# Left+43 bit = Tribler Overlay swarm extension
#               AND uTorrent extended protocol, conflicting. See EXTEND message
# Right-most bit = BitTorrent DHT extension


CHOKE = chr(0)
UNCHOKE = chr(1)
INTERESTED = chr(2)
NOT_INTERESTED = chr(3)

# index
HAVE = chr(4)
# index, bitfield
BITFIELD = chr(5)
# index, begin, length
REQUEST = chr(6)
# index, begin, piece
PIECE = chr(7)
# index, begin, piece
CANCEL = chr(8)
# 2-byte port
PORT = chr(9)

# uTorrent and Bram's BitTorrent now support an extended protocol
EXTEND = chr(20)


#
# Tribler specific message IDs
#

# IDs 255 and 254 are reserved. Tribler extensions number downwards

# PermID /Overlay Swarm Extension
# ctxt
CHALLENGE = chr(253)
# rdata1
RESPONSE1 = chr(252)
# rdata2
RESPONSE2 = chr(251)

# Merkle Hash Extension
# Merkle: PIECE message with hashes
HASHPIECE = chr(250)

# Buddycast Extension
# payload is beencoded dict
BUDDYCAST = chr(249)

# bencoded torrent_hash (Arno,2007-08-14: shouldn't be bencoded, but is)
GET_METADATA = chr(248)
# {'torrent_hash', 'metadata', ... }
METADATA = chr(247)

# ProxyService extension, reused from Cooperative Download (2fast)
# For connectability test
DIALBACK_REQUEST = chr(244)
DIALBACK_REPLY = chr(243)

# Doe sent messages
RELAY_REQUEST = chr(246)  # payload = infohash
STOP_RELAYING = chr(245)  # payload = infohash
DOWNLOAD_PIECE = chr(242)  # payload = infohash + bencode(piece_number)
CANCEL_DOWNLOADING_PIECE = chr(241)  # payload = infohash + bencode(piece_number)
UPLOAD_PIECE = chr(219)  # payload = infohash + bencode(piece_number) + bencode(piece_data)
CANCEL_UPLOADING_PIECE = chr(218)  # payload = infohash + bencode(piece_number)

# Proxy sent messages
RELAY_ACCEPTED = chr(224)  # payload = infohash
RELAY_DROPPED = chr(223)  # payload = infohash
DROPPED_PIECE = chr(222)  # payload = infohash + bencode(piece_number)
PROXY_HAVE = chr(221)  # payload = infohash + bencode(haves_bitstring)
PROXY_UNHAVE = chr(220)  # payload = infohash + bencode(haves_bitstring)
PIECE_DATA = chr(217)  # payload = infohash + bencode(piece_number) + bencode(piece_data)

# SecureOverlay empty payload
KEEP_ALIVE = chr(240)

# Social-Network feature
SOCIAL_OVERLAP = chr(239)

# Remote query extension
QUERY = chr(238)
QUERY_REPLY = chr(237)

# Bartercast, payload is bencoded dict
BARTERCAST = chr(236)

# g2g info (uplink statistics, etc)
G2G_PIECE_XFER = chr(235)

# Friendship messages
FRIENDSHIP = chr(234)

# Generic Crawler messages
CRAWLER_REQUEST = chr(232)
CRAWLER_REPLY = chr(231)

VOTECAST = chr(226)
CHANNELCAST = chr(225)

GET_SUBS = chr(230)
SUBS = chr(229)

# FREE ID = 227/228 + < 217


#
# EXTEND_MSG_CS sub-messages
#
# Closed swarms
# CS  : removed, unused. Using CS_CHALLENGE_A message ID in extend handshake
CS_CHALLENGE_A = chr(227)
CS_CHALLENGE_B = chr(228)
CS_POA_EXCHANGE_A = chr(229)
CS_POA_EXCHANGE_B = chr(230)

#
# Crawler sub-messages
#
CRAWLER_DATABASE_QUERY = chr(1)
CRAWLER_SEEDINGSTATS_QUERY = chr(2)
CRAWLER_NATCHECK = chr(3)
CRAWLER_FRIENDSHIP_STATS = chr(4)
CRAWLER_NATTRAVERSAL = chr(5)
CRAWLER_VIDEOPLAYBACK_INFO_QUERY = chr(6)
CRAWLER_VIDEOPLAYBACK_EVENT_QUERY = chr(7)
CRAWLER_REPEX_QUERY = chr(8)  # RePEX: query a peer's SwarmCache history
CRAWLER_PUNCTURE_QUERY = chr(9)
CRAWLER_CHANNEL_QUERY = chr(10)
CRAWLER_USEREVENTLOG_QUERY = chr(11)


#
# Printing
#

message_map = {
    CHOKE: "CHOKE",
    UNCHOKE: "UNCHOKE",
    INTERESTED: "INTEREST",
    NOT_INTERESTED: "NOT_INTEREST",
    HAVE: "HAVE",
    BITFIELD: "BITFIELD",
    REQUEST: "REQUEST",
    CANCEL: "CANCEL",
    PIECE: "PIECE",
    PORT: "PORT",
    EXTEND: "EXTEND",

    CHALLENGE: "CHALLENGE",
    RESPONSE1: "RESPONSE1",
    RESPONSE2: "RESPONSE2",
    HASHPIECE: "HASHPIECE",
    BUDDYCAST: "BUDDYCAST",
    GET_METADATA: "GET_METADATA",
    METADATA: "METADATA",

    RELAY_REQUEST: "RELAY_REQUEST",
    STOP_RELAYING: "STOP_RELAYING",
    DOWNLOAD_PIECE: "DOWNLOAD_PIECE",
    CANCEL_DOWNLOADING_PIECE: "CANCEL_DOWNLOADING_PIECE",
    UPLOAD_PIECE: "UPLOAD_PIECE",
    CANCEL_UPLOADING_PIECE: "CANCEL_UPLOADING_PIECE",
    RELAY_ACCEPTED: "RELAY_ACCEPTED",
    RELAY_DROPPED: "RELAY_DROPPED",
    DROPPED_PIECE: "DROPPED_PIECE",
    PROXY_HAVE: "PROXY_HAVE",
    PROXY_UNHAVE: "PROXY_UNHAVE",
    PIECE_DATA: "PIECE_DATA",
    DIALBACK_REQUEST: "DIALBACK_REQUEST",
    DIALBACK_REPLY: "DIALBACK_REPLY",

    KEEP_ALIVE: "KEEP_ALIVE",
    SOCIAL_OVERLAP: "SOCIAL_OVERLAP",
    QUERY: "QUERY",
    QUERY_REPLY: "QUERY_REPLY",
    VOTECAST: "VOTECAST",
    BARTERCAST: "BARTERCAST",
    G2G_PIECE_XFER: "G2G_PIECE_XFER",
    FRIENDSHIP: "FRIENDSHIP",
    VOTECAST: "VOTECAST",
    CHANNELCAST: "CHANNELCAST",

    CRAWLER_REQUEST: "CRAWLER_REQUEST",
    CRAWLER_REQUEST + CRAWLER_DATABASE_QUERY: "CRAWLER_DATABASE_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_SEEDINGSTATS_QUERY: "CRAWLER_SEEDINGSTATS_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_NATCHECK: "CRAWLER_NATCHECK_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_NATTRAVERSAL: "CRAWLER_NATTRAVERSAL_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_FRIENDSHIP_STATS: "CRAWLER_FRIENDSHIP_STATS_REQUEST",
    CRAWLER_REQUEST + CRAWLER_VIDEOPLAYBACK_INFO_QUERY: "CRAWLER_VIDEOPLAYBACK_INFO_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_VIDEOPLAYBACK_EVENT_QUERY: "CRAWLER_VIDEOPLAYBACK_EVENT_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_REPEX_QUERY: "CRAWLER_REPEX_QUERY_REQUEST",  # RePEX: query a peer's SwarmCache history
    CRAWLER_REQUEST + CRAWLER_PUNCTURE_QUERY: "CRAWLER_PUNCTURE_QUERY_REQUEST",
    CRAWLER_REQUEST + CRAWLER_CHANNEL_QUERY: "CRAWLER_CHANNEL_QUERY_REQUEST",

    CRAWLER_REPLY: "CRAWLER_REPLY",
    CRAWLER_REPLY + CRAWLER_DATABASE_QUERY: "CRAWLER_DATABASE_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_SEEDINGSTATS_QUERY: "CRAWLER_SEEDINGSTATS_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_NATCHECK: "CRAWLER_NATCHECK_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_NATTRAVERSAL: "CRAWLER_NATTRAVERSAL_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_FRIENDSHIP_STATS: "CRAWLER_FRIENDSHIP_STATS",
    CRAWLER_REPLY + CRAWLER_FRIENDSHIP_STATS: "CRAWLER_FRIENDSHIP_STATS_REPLY",
    CRAWLER_REPLY + CRAWLER_VIDEOPLAYBACK_INFO_QUERY: "CRAWLER_VIDEOPLAYBACK_INFO_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_VIDEOPLAYBACK_EVENT_QUERY: "CRAWLER_VIDEOPLAYBACK_EVENT_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_REPEX_QUERY: "CRAWLER_REPEX_QUERY_REPLY",  # RePEX: query a peer's SwarmCache history
    CRAWLER_REPLY + CRAWLER_PUNCTURE_QUERY: "CRAWLER_PUNCTURE_QUERY_REPLY",
    CRAWLER_REPLY + CRAWLER_CHANNEL_QUERY: "CRAWLER_CHANNEL_QUERY_REPLY"
}


def getMessageName(s):
    """
    Return the message name for message id s. This may be either a one
    or a two byte sting
    """
    if s in message_map:
        return message_map[s]
    else:
        return "Unknown_MessageID_" + "_".join([str(ord(c)) for c in s])

########NEW FILE########
__FILENAME__ = osutils
# Written by Arno Bakker, ABC authors
# see LICENSE.txt for license information
"""
OS-independent utility functions

get_home_dir()      : Returns CSIDL_APPDATA i.e. App data directory on win32
get_picture_dir()
get_free_space(path)
"""

#
# Multiple methods for getting free diskspace
#
import sys
import os
import time
import binascii
import subprocess
import logging

logger = logging.getLogger(__name__)

if sys.platform == "win32":
    try:
        from win32com.shell import shell

        def get_home_dir():
            # http://www.mvps.org/access/api/api0054.htm
            # CSIDL_PROFILE = &H28
            # C:\Documents and Settings\username
            return shell.SHGetSpecialFolderPath(0, 0x28)

        def get_appstate_dir():
            # http://www.mvps.org/access/api/api0054.htm
            # CSIDL_APPDATA = &H1A
            # C:\Documents and Settings\username\Application Data
            return shell.SHGetSpecialFolderPath(0, 0x1a)

        def get_picture_dir():
            # http://www.mvps.org/access/api/api0054.htm
            # CSIDL_MYPICTURES = &H27
            # C:\Documents and Settings\username\My Documents\My Pictures
            return shell.SHGetSpecialFolderPath(0, 0x27)

        def get_desktop_dir():
            # http://www.mvps.org/access/api/api0054.htm
            # CSIDL_DESKTOPDIRECTORY = &H10
            # C:\Documents and Settings\username\Desktop
            return shell.SHGetSpecialFolderPath(0, 0x10)

    except ImportError:
        def get_home_dir():
            try:
                # when there are special unicode characters in the username,
                # the following will fail on python 2.4, 2.5, 2.x this will
                # always succeed on python 3.x
                return os.path.expanduser(u"~")
            except Exception as unicode_error:
                pass

            # non-unicode home
            home = os.path.expanduser("~")
            head, tail = os.path.split(home)

            dirs = os.listdir(head)
            udirs = os.listdir(unicode(head))

            # the character set may be different, but the string length is
            # still the same
            islen = lambda dir: len(dir) == len(tail)
            dirs = filter(islen, dirs)
            udirs = filter(islen, udirs)
            if len(dirs) == 1 and len(udirs) == 1:
                return os.path.join(head, udirs[0])

            # remove all dirs that are equal in unicode and non-unicode. we
            # know that we don't need these dirs because the initial
            # expandusers would not have failed on them
            for dir in dirs[:]:
                if dir in udirs:
                    dirs.remove(dir)
                    udirs.remove(dir)
            if len(dirs) == 1 and len(udirs) == 1:
                return os.path.join(head, udirs[0])

            # assume that the user has write access in her own
            # directory. therefore we can filter out any non-writable
            # directories
            writable_udir = [udir for udir in udirs if os.access(udir, os.W_OK)]
            if len(writable_udir) == 1:
                return os.path.join(head, writable_udir[0])

            # fallback: assume that the order of entries in dirs is the same
            # as in udirs
            for dir, udir in zip(dirs, udirs):
                if dir == tail:
                    return os.path.join(head, udir)

            # failure
            raise unicode_error

        def get_appstate_dir():
            homedir = get_home_dir()
            # 5 = XP, 6 = Vista
            # [E1101] Module 'sys' has no 'getwindowsversion' member
            # pylint: disable-msg=E1101
            winversion = sys.getwindowsversion()
            # pylint: enable-msg=E1101
            if winversion[0] == 6:
                appdir = os.path.join(homedir, u"AppData", u"Roaming")
            else:
                appdir = os.path.join(homedir, u"Application Data")
            return appdir

        def get_picture_dir():
            return get_home_dir()

        def get_desktop_dir():
            home = get_home_dir()
            return os.path.join(home, u"Desktop")

else:
    # linux or darwin (mac)
    def get_home_dir():
        return os.path.expanduser(u"~")

    def get_appstate_dir():
        return get_home_dir()

    def get_picture_dir():
        return get_desktop_dir()

    def get_desktop_dir():
        home = get_home_dir()
        desktop = os.path.join(home, "Desktop")
        if os.path.exists(desktop):
            return desktop
        else:
            return home


def get_free_space(path):
    if not os.path.exists(path):
        return -1

    if sys.platform == 'win32':
        from win32file import GetDiskFreeSpaceEx
        return GetDiskFreeSpaceEx(path)[0]
    else:
        data = os.statvfs(path.encode("utf-8"))
        return data.f_bavail * data.f_frsize


invalidwinfilenamechars = ''
for i in range(32):
    invalidwinfilenamechars += chr(i)
invalidwinfilenamechars += '"*/:<>?\\|'
invalidlinuxfilenamechars = '/'


def fix_filebasename(name, unit=False, maxlen=255):
    """ Check if str is a valid Windows file name (or unit name if unit is true)
     * If the filename isn't valid: returns a corrected name
     * If the filename is valid: returns the filename
    """
    if unit and (len(name) != 2 or name[1] != ':'):
        return 'c:'
    if not name or name == '.' or name == '..':
        return '_'

    if unit:
        name = name[0]
    fixed = False
    if len(name) > maxlen:
        name = name[:maxlen]
        fixed = True

    fixedname = ''
    spaces = 0
    for c in name:
        if sys.platform.startswith('win'):
            invalidchars = invalidwinfilenamechars
        else:
            invalidchars = invalidlinuxfilenamechars

        if c in invalidchars:
            fixedname += '_'
            fixed = True
        else:
            fixedname += c
            if c == ' ':
                spaces += 1

    file_dir, basename = os.path.split(fixedname)
    while file_dir != '':
        fixedname = basename
        file_dir, basename = os.path.split(fixedname)
        fixed = True

    if fixedname == '':
        fixedname = '_'
        fixed = True

    if fixed:
        return last_minute_filename_clean(fixedname)
    elif spaces == len(name):
        # contains only spaces
        return '_'
    else:
        return last_minute_filename_clean(name)


def last_minute_filename_clean(name):
    s = name.strip()  # Arno: remove initial or ending space
    if sys.platform == 'win32' and s.endswith('..'):
        s = s[:-2]
    return s


def get_readable_torrent_name(infohash, raw_filename):
    # return name__infohash.torrent
    hex_infohash = binascii.hexlify(infohash)
    suffix = '__' + hex_infohash + '.torrent'
    save_name = ' ' + fix_filebasename(raw_filename, maxlen=254 - len(suffix)) + suffix
    # use a space ahead to distinguish from previous collected torrents
    return save_name


if sys.platform == "win32":
    import win32pdh

    def getcpuload():
        """ Returns total CPU usage as fraction (0..1).
        Warning: side-effect: sleeps for 0.1 second to do diff """
        # mempath = win32pdh.MakeCounterPath((None, "Memory", None, None, -1, "Available MBytes"))
        cpupath = win32pdh.MakeCounterPath((None, "Processor", "_Total", None, -1, "% Processor Time"))
        query = win32pdh.OpenQuery(None, 0)
        counter = win32pdh.AddCounter(query, cpupath, 0)

        win32pdh.CollectQueryData(query)
        # Collect must be called twice for CPU, see http://support.microsoft.com/kb/262938
        time.sleep(0.1)
        win32pdh.CollectQueryData(query)

        status, value = win32pdh.GetFormattedCounterValue(counter, win32pdh.PDH_FMT_LONG)

        return float(value) / 100.0

elif sys.platform == "linux2":
    def read_proc_stat():
        """ Read idle and total CPU time counters from /proc/stat, see
        man proc """
        f = open("/proc/stat", "rb")
        try:
            while True:
                line = f.readline()
                if len(line) == 0:
                    break
                if line.startswith("cpu "):  # note space
                    words = line.split()
                    total = 0
                    for i in range(1, 5):
                        total += int(words[i])
                    idle = int(words[4])
                    return (total, idle)
        finally:
            f.close()

    def getcpuload():
        """ Returns total CPU usage as fraction (0..1).
        Warning: side-effect: sleeps for 0.1 second to do diff """
        (total1, idle1) = read_proc_stat()
        time.sleep(0.1)
        (total2, idle2) = read_proc_stat()
        total = total2 - total1
        idle = idle2 - idle1
        return 1.0 - (float(idle)) / float(total)
else:
    # Mac
    def getupload():
        raise ValueError("Not yet implemented")


def startfile(filepath):
    if sys.platform == 'darwin':
        subprocess.call(('open', filepath))
    elif sys.platform == 'linux2':
        subprocess.call(('xdg-open', filepath))
    elif hasattr(os, "startfile"):
        os.startfile(filepath)

########NEW FILE########
__FILENAME__ = permid
# Written by Arno Bakker
# see LICENSE.txt for license information
from copy import deepcopy
import os
import logging
from M2Crypto import Rand, EC

from Tribler.Core.Utilities.Crypto import sha
from Tribler.Core.Utilities.bencode import bencode

logger = logging.getLogger(__name__)

# Internal constants
KEYPAIR_ECC_CURVE = EC.NID_sect233k1
NUM_RANDOM_BITS = 1024 * 8  # bits

# Exported functions


def init():
    Rand.rand_seed(os.urandom(NUM_RANDOM_BITS / 8))


def generate_keypair():
    ec_keypair = EC.gen_params(KEYPAIR_ECC_CURVE)
    ec_keypair.gen_key()
    return ec_keypair


def read_keypair(keypairfilename):
    return EC.load_key(keypairfilename)


def save_keypair(keypair, keypairfilename):
    keypair.save_key(keypairfilename, None)


def save_pub_key(keypair, pubkeyfilename):
    keypair.save_pub_key(pubkeyfilename)


# Internal functions

#
# The following methods and ChallengeResponse class implement a
# Challenge/Response identification protocol, notably the
# ISO/IEC 9798-3 protocol, as described in $10.3.3 (ii) (2) of the
# ``Handbook of Applied Cryptography''by  Alfred J. Menezes et al.
#


def sign_response(randomA, randomB, peeridB, keypairA):
    list = [randomA, randomB, peeridB]
    blist = bencode(list)
    digest = sha(blist).digest()
    blob = keypairA.sign_dsa_asn1(digest)
    return blob


def verify_response(randomA, randomB, peeridB, pubA, sigA):
    list = [randomA, randomB, peeridB]
    blist = bencode(list)
    digest = sha(blist).digest()
    return pubA.verify_dsa_asn1(digest, sigA)


# External functions

def create_torrent_signature(metainfo, keypairfilename):
    keypair = EC.load_key(keypairfilename)
    bmetainfo = bencode(metainfo)
    digester = sha(bmetainfo[:])
    digest = digester.digest()
    sigstr = keypair.sign_dsa_asn1(digest)
    metainfo['signature'] = sigstr
    metainfo['signer'] = str(keypair.pub().get_der())


def verify_torrent_signature(metainfo):
    r = deepcopy(metainfo)
    signature = r['signature']
    signer = r['signer']
    del r['signature']
    del r['signer']
    bmetainfo = bencode(r)
    digester = sha(bmetainfo[:])
    digest = digester.digest()
    return do_verify_torrent_signature(digest, signature, signer)


# Internal

def do_verify_torrent_signature(digest, sigstr, permid):
    if permid is None:
        return False
    try:
        ecpub = EC.pub_key_from_der(permid)
        if ecpub is None:
            return False
        intret = ecpub.verify_dsa_asn1(digest, sigstr)
        return intret == 1
    except Exception as e:
        logger.error("permid: Exception in verify_torrent_signature: %s", str(e))
        return False

########NEW FILE########
__FILENAME__ = RawServer
# Written by Bram Cohen and Pawel Garbacki
# see LICENSE.txt for license information
import logging
import socket
import sys
from bisect import insort
from select import error
from thread import get_ident
from threading import Event, RLock
from traceback import print_exc

from SocketHandler import SocketHandler
from Tribler.Core.Utilities.clock import clock
from Tribler.dispersy.util import attach_profiler


try:
    True
except:
    True = 1
    False = 0


def autodetect_ipv6():
    try:
        assert sys.version_info >= (2, 3)
        assert socket.has_ipv6
        socket.socket(socket.AF_INET6, socket.SOCK_STREAM)
    except:
        return 0
    return 1


def autodetect_socket_style():
    if sys.platform.find('linux') < 0:
        return 1
    else:
        try:
            f = open('/proc/sys/net/ipv6/bindv6only', 'r')
            dual_socket_style = int(f.read())
            f.close()
            return int(not dual_socket_style)
        except:
            return 0


READSIZE = 100000


class RawServer:

    def __init__(self, doneflag, timeout_check_interval, timeout, noisy=True,
                 ipv6_enable=True, failfunc= lambda x: None, errorfunc = None,
                 sockethandler=None, excflag= Event()):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.timeout_check_interval = timeout_check_interval
        self.timeout = timeout
        self.servers = {}
        self.single_sockets = {}
        self.dead_from_write = []
        self.doneflag = doneflag
        self.noisy = noisy
        self.failfunc = failfunc
        self.errorfunc = errorfunc
        self.exccount = 0
        self.funcs = []
        self.externally_added = []
        self.finished = Event()
        self.tasks_to_kill = []
        self.excflag = excflag
        self.lock = RLock()

        if sockethandler is None:
            sockethandler = SocketHandler(timeout, ipv6_enable, READSIZE)
        self.sockethandler = sockethandler

        self.thread_ident = None
        self.interrupt_socket = sockethandler.get_interrupt_socket()

        self.add_task(self.scan_for_timeouts, timeout_check_interval)

    def get_exception_flag(self):
        return self.excflag

    def _add_task(self, func, delay, id=None):
        if delay < 0:
            delay = 0
        insort(self.funcs, (clock() + delay, func, id))

    def add_task(self, func, delay=0, id= None):
        # if DEBUG:
        #    print >>sys.stderr,"rawserver: add_task(",func,delay,")"
        if delay < 0:
            delay = 0

        self.lock.acquire()
        self.externally_added.append((func, delay, id))
        self.lock.release()

        if self.thread_ident != get_ident():
            self.interrupt_socket.interrupt()

    def scan_for_timeouts(self):
        self.add_task(self.scan_for_timeouts, self.timeout_check_interval)
        self.sockethandler.scan_for_timeouts()

    def bind(self, port, bind='', reuse= False,
            ipv6_socket_style=1, handler=None):
        self.sockethandler.bind(port, bind, reuse, ipv6_socket_style, handler)

    def find_and_bind(self, first_try, minport, maxport, bind='', reuse = False,
                      ipv6_socket_style=1, randomizer= False, handler=None):
# 2fastbt_
        result = self.sockethandler.find_and_bind(first_try, minport, maxport, bind, reuse,
                                 ipv6_socket_style, randomizer, handler)
# _2fastbt
        return result

    def start_connection_raw(self, dns, socktype=socket.AF_INET, handler= None):
        return self.sockethandler.start_connection_raw(dns, socktype, handler)

    def start_connection(self, dns, handler=None, randomize= False):
        return self.sockethandler.start_connection(dns, handler, randomize)

    def get_stats(self):
        return self.sockethandler.get_stats()

    def pop_external(self):
        self.lock.acquire()
        while self.externally_added:
            (a, b, c) = self.externally_added.pop(0)
            self._add_task(a, b, c)
        self.lock.release()

    @attach_profiler
    def listen_forever(self, handler):
        self._logger.debug("rawserver: listen forever()")
        # handler=btlanuchmany: MultiHandler, btdownloadheadless: Encoder
        self.thread_ident = get_ident()
        self.sockethandler.set_handler(handler)
        try:
            while not self.doneflag.isSet():
                try:
                    self.pop_external()
                    self._kill_tasks()
                    if self.funcs:
                        period = self.funcs[0][0] + 0.001 - clock()
                    else:
                        period = 2 ** 30
                    if period < 0:
                        period = 0

                    # if DEBUG:
                    #    print >>sys.stderr,"rawserver: do_poll",period
                    events = self.sockethandler.do_poll(period)

                    if self.doneflag.isSet():
                        self._logger.debug("rawserver: stopping because done flag set")
                        return

                    # print >>sys.stderr,"RawServer: funcs is",`self.funcs`

                    while self.funcs and self.funcs[0][0] <= clock() and not self.doneflag.isSet():
                        garbage1, func, id = self.funcs.pop(0)
                        if id in self.tasks_to_kill:
                            pass
                        try:
#                            print func.func_name
                            if func.func_name != "_bgalloc":
                                self._logger.debug("RawServer:f %s", func.func_name)
                            # st = time.time()
                            func()
                            # et = time.time()
                            # diff = et - st
                            # print >>sys.stderr,func,"took %.5f" % (diff)

                        except (SystemError, MemoryError) as e:
                            self.failfunc(e)
                            return
                        except KeyboardInterrupt as e:
#                            self.exception(e)
                            return
                        except error:
                            self._logger.debug("rawserver: func: ERROR exception")
                            print_exc()
                            pass
                        except Exception as e:
                            # boudewijn: someone made a big mistake,
                            # the code will not function as expected.
                            # notify someone for *uck sake!  instead
                            # of silently hiding the problem and
                            # continuing...
                            # raise
                            self._logger.debug("rawserver: func: any exception")
                            print_exc()
                            if self.noisy:
                                self.exception(e)

                    self.sockethandler.close_dead()
                    self.sockethandler.handle_events(events)

                except (SystemError, MemoryError) as e:
                    self._logger.debug("rawserver: SYS/MEM exception %s", e)
                    self.failfunc(e)
                    return

                except error:
                    self._logger.debug("rawserver: ERROR exception")
                    print_exc()

                except KeyboardInterrupt as e:
                    self.failfunc(e)
                    return

                except Exception as e:
                    # boudewijn: someone made a big mistake, the code
                    # will not function as expected.  notify someone
                    # for *uck sake!  instead of silently hiding the
                    # problem and continuing...
                    # raise
                    self._logger.debug("rawserver: other exception")
                    print_exc()
                    self.exception(e)
                # Arno: Don't stop till we drop
                # if self.exccount > 10:
                # print >> sys.stderr,"rawserver: stopping because exccount > 10"
                # return
        finally:
#            self.sockethandler.shutdown()
            self.finished.set()

    def is_finished(self):
        return self.finished.isSet()

    def wait_until_finished(self):
        self.finished.wait()

    def _kill_tasks(self):
        if self.tasks_to_kill:
            new_funcs = []
            for (t, func, id) in self.funcs:
                if id not in self.tasks_to_kill:
                    new_funcs.append((t, func, id))
            self.funcs = new_funcs
            self.tasks_to_kill = []

    def kill_tasks(self, id):
        self.tasks_to_kill.append(id)

    def exception(self, e, kbint=False):
        if not kbint:
            self.excflag.set()
        self.exccount += 1
        if self.errorfunc is None:
            print_exc()
        else:
            if not kbint:   # don't report here if it's a keyboard interrupt
                self.errorfunc(e)

    def shutdown(self):
        self.sockethandler.shutdown()

    #
    # Interface for Khashmir
    #
    def create_udpsocket(self, port, host):
        self._logger.debug("rawudp: create_udp_socket %s %s", host, port)
        return self.sockethandler.create_udpsocket(port, host)

    def start_listening_udp(self, serversocket, handler):
        self._logger.debug("rawudp: start_listen: %s %s", serversocket, handler)
        self.sockethandler.start_listening_udp(serversocket, handler)

    def stop_listening_udp(self, serversocket):
        self._logger.debug("rawudp: stop_listen: %s", serversocket)
        self.sockethandler.stop_listening_udp(serversocket)

########NEW FILE########
__FILENAME__ = selectpoll
# Written by Bram Cohen
# see LICENSE.txt for license information
# Arno,2007-02-23: this poll class is used on win32

import logging
from select import select
from time import sleep
from types import IntType
from bisect import bisect
from sets import Set
POLLIN = 1
POLLOUT = 2
POLLERR = 8
POLLHUP = 16


class poll:

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.rlist = []
        self.wlist = []

    def register(self, f, t):
        if not isinstance(f, IntType):
            f = f.fileno()
        if (t & POLLIN):
            insert(self.rlist, f)
        elif f in self.rlist:  # Arno, 2012-07-31: Safety catch
            remove(self.rlist, f)
        if (t & POLLOUT):
            insert(self.wlist, f)
        elif f in self.wlist:  # Arno, 2012-07-31: Safety catch
            remove(self.wlist, f)

    def unregister(self, f):
        if not isinstance(f, IntType):
            f = f.fileno()
        remove(self.rlist, f)
        remove(self.wlist, f)

    def poll(self, timeout=None):
        if self.rlist or self.wlist:
            try:
                # Arno, 2007-02-23: The original code never checked for errors
                # on any file descriptors.
                elist = Set(self.rlist)
                elist = elist.union(self.wlist)
                elist = list(elist)    # in Python2.3, elist must be a list type
                self._logger.debug("selectpoll: elist = %s", elist)

                # print >>sys.stderr,"selectpoll: rlist",self.rlist,"wlist",self.wlist,"elist",elist

                r, w, e = select(self.rlist, self.wlist, elist, timeout)
                self._logger.debug("selectpoll: e = %s", e)
            except ValueError:
                self._logger.debug("selectpoll: select: bad param")
                return None
        else:
            sleep(timeout)
            return []
        result = []
        for s in r:
            result.append((s, POLLIN))
        for s in w:
            result.append((s, POLLOUT))
        for s in e:
            result.append((s, POLLERR))
        return result


def remove(list, item):
    i = bisect(list, item)
    if i > 0 and list[i - 1] == item:
        del list[i - 1]


def insert(list, item):
    i = bisect(list, item)
    if i == 0 or list[i - 1] != item:
        list.insert(i, item)


def test_remove():
    x = [2, 4, 6]
    remove(x, 2)
    assert x == [4, 6]
    x = [2, 4, 6]
    remove(x, 4)
    assert x == [2, 6]
    x = [2, 4, 6]
    remove(x, 6)
    assert x == [2, 4]
    x = [2, 4, 6]
    remove(x, 5)
    assert x == [2, 4, 6]
    x = [2, 4, 6]
    remove(x, 1)
    assert x == [2, 4, 6]
    x = [2, 4, 6]
    remove(x, 7)
    assert x == [2, 4, 6]
    x = [2, 4, 6]
    remove(x, 5)
    assert x == [2, 4, 6]
    x = []
    remove(x, 3)
    assert x == []


def test_insert():
    x = [2, 4]
    insert(x, 1)
    assert x == [1, 2, 4]
    x = [2, 4]
    insert(x, 3)
    assert x == [2, 3, 4]
    x = [2, 4]
    insert(x, 5)
    assert x == [2, 4, 5]
    x = [2, 4]
    insert(x, 2)
    assert x == [2, 4]
    x = [2, 4]
    insert(x, 4)
    assert x == [2, 4]
    x = [2, 3, 4]
    insert(x, 3)
    assert x == [2, 3, 4]
    x = []
    insert(x, 3)
    assert x == [3]

########NEW FILE########
__FILENAME__ = SocketHandler
# Written by Bram Cohen
# see LICENSE.txt for license information

import socket
import errno
import logging
import sys
from time import sleep
from random import shuffle, randrange
from traceback import print_exc
try:
    from select import poll, POLLIN, POLLOUT, POLLERR, POLLHUP
    timemult = 1000
except ImportError:
    from selectpoll import poll, POLLIN, POLLOUT, POLLERR, POLLHUP
    timemult = 1

from Tribler.Core.Utilities.clock import clock

try:
    True
except:
    True = 1
    False = 0

all = POLLIN | POLLOUT

if sys.platform == 'win32':
    SOCKET_BLOCK_ERRORCODE = 10035    # WSAEWOULDBLOCK
else:
    SOCKET_BLOCK_ERRORCODE = errno.EWOULDBLOCK


class InterruptSocketHandler:

    @staticmethod
    def data_came_in(interrupt_socket, data):
        pass


class InterruptSocket:

    """
    When we need the poll to return before the timeout expires, we
    will send some data to the InterruptSocket and discard the data.
    """
    def __init__(self, socket_handler):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.socket_handler = socket_handler
        self.handler = InterruptSocketHandler

        self.ip = "127.0.0.1"
        self.port = None
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.interrupt_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

        self.socket.bind((self.ip, 0))
        self.port = self.socket.getsockname()[1]
        self._logger.debug("Bound InterruptSocket on port %s", self.port)

        # start listening to the InterruptSocket
        self.socket_handler.single_sockets[self.socket.fileno()] = self
        self.socket_handler.poll.register(self.socket, POLLIN)

    def interrupt(self):
        self.interrupt_socket.sendto("+", (self.ip, self.port))

    def get_ip(self):
        return self.ip

    def get_port(self):
        return self.port


class UdpSocket:

    """ Class to hold socket and handler for a UDP socket. """
    def __init__(self, socket, handler):
        self.socket = socket
        self.handler = handler


class SingleSocket:

    """
    There are two places to create SingleSocket:
    incoming connection -- SocketHandler.handle_events
    outgoing connection -- SocketHandler.start_connection_raw
    """

    def __init__(self, socket_handler, sock, handler, ip=None):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.socket_handler = socket_handler
        self.socket = sock
        self.handler = handler
        self.buffer = []
        self.last_hit = clock()
        self.fileno = sock.fileno()
        self.connected = False
        self.skipped = 0
#        self.check = StreamCheck()
        self.myip = None
        self.myport = -1
        self.ip = None
        self.port = -1
        try:
            myname = self.socket.getsockname()
            self.myip = myname[0]
            self.myport = myname[1]
            peername = self.socket.getpeername()
            self.ip = peername[0]
            self.port = peername[1]
        except:
            # print_exc()
            if ip is None:
                self.ip = 'unknown'
            else:
                self.ip = ip

    def get_ip(self, real=False):
        if real:
            try:
                peername = self.socket.getpeername()
                self.ip = peername[0]
                self.port = peername[1]
            except:
                # print_exc()
                pass
        return self.ip

    def get_port(self, real=False):
        if real:
            self.get_ip(True)
        return self.port

    def get_myip(self, real=False):
        if real:
            try:
                myname = self.socket.getsockname()
                self.myip = myname[0]
                self.myport = myname[1]
            except:
                print_exc()
                pass
        return self.myip

    def get_myport(self, real=False):
        if real:
            self.get_myip(True)
        return self.myport

    def close(self):
        '''
        for x in xrange(5,0,-1):
            try:
                f = inspect.currentframe(x).f_code
                print (f.co_filename,f.co_firstlineno,f.co_name)
                del f
            except:
                pass
        print ''
        '''
        assert self.socket
        self.connected = False
        sock = self.socket
        self.socket = None
        self.buffer = []
        del self.socket_handler.single_sockets[self.fileno]

        try:
            self.socket_handler.poll.unregister(sock)
        except Exception as e:
            self._logger.error("SocketHandler: close: sock is %s", sock)
            print_exc()
        sock.close()

    def shutdown(self, val):
        self.socket.shutdown(val)

    def is_flushed(self):
        return not self.buffer

    def write(self, s):
#        self.check.write(s)
        # Arno: fishy concurrency problem, sometimes self.socket is None
        if self.socket is None:
            return
        # assert self.socket is not None
        self.buffer.append(s)
        if len(self.buffer) == 1:
            self.try_write()

    def try_write(self):

        if self.connected:
            dead = False
            try:
                while self.buffer:
                    buf = self.buffer[0]
                    amount = self.socket.send(buf)
                    if amount == 0:
                        self.skipped += 1
                        break
                    self.skipped = 0
                    if amount != len(buf):
                        self.buffer[0] = buf[amount:]
                        break
                    del self.buffer[0]
            except socket.error as e:
                # if DEBUG:
                #    print_exc(file=sys.stderr)
                blocked = False
                try:
                    blocked = (e[0] == SOCKET_BLOCK_ERRORCODE)
                    dead = not blocked
                except:
                    dead = True
                if not blocked:
                    self.skipped += 1
            if self.skipped >= 5:
                dead = True
            if dead:
                self.socket_handler.dead_from_write.append(self)
                return
        if self.buffer:
            self.socket_handler.poll.register(self.socket, all)
        else:
            self.socket_handler.poll.register(self.socket, POLLIN)

    def set_handler(self, handler):    # can be: NewSocketHandler, Encoder, En_Connection
        self.handler = handler


class SocketHandler:

    def __init__(self, timeout, ipv6_enable, readsize=100000):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.timeout = timeout
        self.ipv6_enable = ipv6_enable
        self.readsize = readsize
        self.poll = poll()
        # {socket: SingleSocket}
        self.single_sockets = {}
        self.dead_from_write = []
        self.max_connects = 1000
        self.servers = {}
        self.interfaces = []
        self.btengine_said_reachable = False
        self.interrupt_socket = None
        self.udp_sockets = {}

    def scan_for_timeouts(self):
        t = clock() - self.timeout
        tokill = []
        for s in self.single_sockets.values():
            # Only SingleSockets can be closed because of timeouts
            if isinstance(s, SingleSocket) and s.last_hit < t:
                tokill.append(s)
        for k in tokill:
            if k.socket is not None:
                self._logger.debug("SocketHandler: scan_timeout closing connection %s", k.get_ip())
                self._close_socket(k)

    def bind(self, port, bind=[], reuse= False, ipv6_socket_style = 1, handler=None):
        port = int(port)
        addrinfos = []
        # if bind != [] bind to all specified addresses (can be IPs or hostnames)
        # else bind to default ipv6 and ipv4 address
        if bind:
            if self.ipv6_enable:
                socktype = socket.AF_UNSPEC
            else:
                socktype = socket.AF_INET
            for addr in bind:
                if sys.version_info < (2, 2):
                    addrinfos.append((socket.AF_INET, None, None, None, (addr, port)))
                else:
                    addrinfos.extend(socket.getaddrinfo(addr, port,
                                               socktype, socket.SOCK_STREAM))
        else:
            if self.ipv6_enable:
                addrinfos.append([socket.AF_INET6, None, None, None, ('', port)])
            if not addrinfos or ipv6_socket_style != 0:
                addrinfos.append([socket.AF_INET, None, None, None, ('', port)])
        for addrinfo in addrinfos:
            try:
                server = socket.socket(addrinfo[0], socket.SOCK_STREAM)
                if reuse:
                    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                server.setblocking(0)
                self._logger.debug("SocketHandler: Try to bind socket on %s ...", addrinfo[4])
                server.bind(addrinfo[4])
                self.servers[server.fileno()] = (server, handler)
                if bind:
                    self.interfaces.append(server.getsockname()[0])
                self._logger.debug("SocketHandler: OK")
                server.listen(64)
                self.poll.register(server, POLLIN)
            except socket.error as e:
                for server, _ in self.servers.values():
                    try:
                        server.close()
                    except:
                        pass
                if self.ipv6_enable and ipv6_socket_style == 0 and self.servers:
                    raise socket.error('blocked port (may require ipv6_binds_v4 to be set)')
                raise socket.error(str(e))
        if not self.servers:
            raise socket.error('unable to open server port')
        self.port = port

    def find_and_bind(self, first_try, minport, maxport, bind='', reuse= False,
                      ipv6_socket_style=1, randomizer= False, handler=None):
        e = 'maxport less than minport - no ports to check'
        if maxport - minport < 50 or not randomizer:
            portrange = range(minport, maxport + 1)
            if randomizer:
                shuffle(portrange)
                portrange = portrange[:20]  # check a maximum of 20 ports
        else:
            portrange = []
            while len(portrange) < 20:
                listen_port = randrange(minport, maxport + 1)
                if not listen_port in portrange:
                    portrange.append(listen_port)
        if first_try != 0:    # try 22 first, because TU only opens port 22 for SSH...
            try:
                self.bind(first_try, bind, reuse=reuse,
                         ipv6_socket_style=ipv6_socket_style, handler=handler)
                return first_try
            except socket.error as e:
                pass
        for listen_port in portrange:
            try:
                # print >> sys.stderr, listen_port, bind, reuse
                self.bind(listen_port, bind, reuse=reuse,
                               ipv6_socket_style=ipv6_socket_style, handler=handler)
                return listen_port
            except socket.error as e:
                raise
        raise socket.error(str(e))

    def set_handler(self, handler):
        self.handler = handler

    def start_connection_raw(self, dns, socktype=socket.AF_INET, handler= None):
        # handler = Encoder, self.handler = Multihandler
        if handler is None:
            handler = self.handler
        sock = socket.socket(socktype, socket.SOCK_STREAM)
        sock.setblocking(0)
        try:
            self._logger.debug("SocketHandler: Initiate connection to %s with socket #%s", dns, sock.fileno())
            # Arno,2007-01-23: http://docs.python.org/lib/socket-objects.html
            # says that connect_ex returns an error code (and can still throw
            # exceptions). The original code never checked the return code.
            #
            err = sock.connect_ex(dns)
            if err == 0:
                msg = 'No error'
            else:
                msg = errno.errorcode[err]
            self._logger.debug("SocketHandler: connect_ex on socket #%s returned %s %s", sock.fileno(), err, msg)
            if err != 0:
                if sys.platform == 'win32' and err == 10035:
                    # Arno, 2007-02-23: win32 always returns WSAEWOULDBLOCK, whether
                    # the connect is to a live peer or not. Win32's version
                    # of EINPROGRESS
                    pass
                elif err == errno.EINPROGRESS:  # or err == errno.EALREADY or err == errno.EWOULDBLOCK:
                    # [Stevens98] says that UNICES return EINPROGRESS when the connect
                    # does not immediately succeed, which is almost always the case.
                    pass
                else:
                    raise socket.error((err, errno.errorcode[err]))
        except socket.error as e:
            self._logger.debug("SocketHandler: SocketError in connect_ex %s", e)
            raise
        except Exception as e:
            self._logger.debug("SocketHandler: Exception in connect_ex %s", e)
            raise socket.error(str(e))

        s = SingleSocket(self, sock, handler, dns[0])    # create socket to connect the peers obtained from tracker
        self.single_sockets[sock.fileno()] = s
        self.poll.register(sock, POLLIN)
        # if DEBUG:
        #    print >> sys.stderr,"SocketHandler: Created Socket"
        return s

    def start_connection(self, dns, handler=None, randomize= False):
        if handler is None:
            handler = self.handler
        if sys.version_info < (2, 2):
            s = self.start_connection_raw(dns, socket.AF_INET, handler)
        else:
#            if self.ipv6_enable:
#                socktype = socket.AF_UNSPEC
#            else:
#                socktype = socket.AF_INET
            try:
                try:
                    """
                    Arno: When opening a new connection, the network thread calls the
                    getaddrinfo() function (=DNS resolve), as apparently the input
                    sometimes is a hostname. At the same time the tracker thread uses
                    this same function to resolve the tracker name to an IP address.
                    However, on Python for Windows this method has concurrency control
                    protection that allows only 1 request at a time.

                    In some cases resolving the tracker name takes a very long time,
                    meanwhile blocking the network thread!!!! And that only wanted to
                    resolve some IP address to some IP address, i.e., do nothing!!!

                    Sol: don't call getaddrinfo() is the input is an IP address, and
                    submit a bug to python that it shouldn't lock when the op is
                    a null op
                    """
                    socket.inet_aton(dns[0])  # IPVSIX: change to inet_pton()
                    # print >>sys.stderr,"SockHand: start_conn: after inet_aton",dns[0],"<",dns,">"
                    addrinfos = [(socket.AF_INET, None, None, None, (dns[0], dns[1]))]
                except:
                    # print_exc()
                    try:
                        # Jie: we attempt to use this socktype to connect ipv6 addresses.
                        socktype = socket.AF_UNSPEC
                        addrinfos = socket.getaddrinfo(dns[0], int(dns[1]),
                                                       socktype, socket.SOCK_STREAM)
                    except:
                        socktype = socket.AF_INET
                        addrinfos = socket.getaddrinfo(dns[0], int(dns[1]),
                                                       socktype, socket.SOCK_STREAM)
            except socket.error as e:
                raise
            except Exception as e:
                raise socket.error(str(e))
            if randomize:
                shuffle(addrinfos)
            for addrinfo in addrinfos:
                try:
                    s = self.start_connection_raw(addrinfo[4], addrinfo[0], handler)
                    break
                except Exception as e:
                    print_exc()
                    pass  # FIXME Arno: ???? raise e
            else:
                raise socket.error('unable to connect')
        return s

    def _sleep(self):
        sleep(1)

    def handle_events(self, events):
        for sock, event in events:
            # print >>sys.stderr,"SocketHandler: event on sock#",sock
            s, h = self.servers.get(sock, (None, None))    # socket.socket
            if s:
                if event & (POLLHUP | POLLERR) != 0:
                    self._logger.debug("SocketHandler: Got event, close server socket")
                    self.poll.unregister(s)
                    del self.servers[sock]
                else:
                    try:
                        newsock, addr = s.accept()
                        self._logger.debug("SocketHandler: Got connection from %s", newsock.getpeername())
                        if not self.btengine_said_reachable:
                            self.btengine_said_reachable = True

                        # Only use the new socket if we can spare the
                        # connections. Otherwise we will silently drop
                        # the connection.
                        if len(self.single_sockets) < self.max_connects:
                            newsock.setblocking(0)
                            nss = SingleSocket(self, newsock, (h or self.handler))    # create socket for incoming peers and tracker
                            self.single_sockets[newsock.fileno()] = nss
                            self.poll.register(newsock, POLLIN)
                            (h or self.handler).external_connection_made(nss)
                        else:
                            self._logger.info("SocketHandler: too many connects")
                            newsock.close()

                    except socket.error as e:
                        self._logger.debug("SocketHandler: SocketError while accepting new connection %s", e)
                        self._sleep()
                continue

            s = self.udp_sockets.get(sock)
            if s:
                packets = []
                try:
                    try:
                        while True:
                            (data, addr) = s.socket.recvfrom(65535)
                            if not data:
                                self._logger.debug("SocketHandler: UDP no-data %s", addr)
                                break
                            else:
                                self._logger.debug("SocketHandler: Got UDP data %s len %s", addr, len(data))
                                packets.append((addr, data))

                    except socket.error as e:
                        self._logger.debug("SocketHandler: UDP Socket error %s", e)

                finally:
                    s.handler.data_came_in(packets)

                continue

            s = self.single_sockets.get(sock)
            if s:
                if (event & (POLLHUP | POLLERR)):
                    self._logger.debug("SocketHandler: Got event, connect socket got error %s", sock)
                    self._logger.debug("SocketHandler: Got event, connect socket got error %s %s", s.ip, s.port)
                    self._close_socket(s)
                    continue
                if (event & POLLIN):
                    try:
                        s.last_hit = clock()
                        data = s.socket.recv(100000)
                        if not data:
                            self._logger.debug("SocketHandler: no-data closing connection %s %s", s.get_ip(), s.get_port())
                            self._close_socket(s)
                        else:
                            # if DEBUG:
                            #    print >> sys.stderr,"SocketHandler: Got data",s.get_ip(),s.get_port(),"len",len(data)

                            # btlaunchmany: NewSocketHandler, btdownloadheadless: Encrypter.Connection
                            s.handler.data_came_in(s, data)
                    except socket.error as e:
                        self._logger.debug("SocketHandler: Socket error %s", e)
                        code, msg = e
                        if code != SOCKET_BLOCK_ERRORCODE:
                            self._logger.debug("SocketHandler: closing connection because not WOULDBLOCK %s, error %s", s.get_ip(), code)
                            self._close_socket(s)
                            continue
                if (event & POLLOUT) and s.socket and not s.is_flushed():
                    s.connected = True
                    s.try_write()
                    if s.is_flushed():
                        s.handler.connection_flushed(s)
            else:
                # Arno, 2012-08-1: Extra protection.
                self._logger.info("SocketHandler: got event on unregistered sock %s", sock)
                try:
                    self.poll.unregister(sock)
                except:
                    pass

    def close_dead(self):
        while self.dead_from_write:
            old = self.dead_from_write
            self.dead_from_write = []
            for s in old:
                if s.socket:
                    self._logger.debug("SocketHandler: close_dead closing connection %s", s.get_ip())
                    self._close_socket(s)

    def _close_socket(self, s):
        self._logger.debug("SocketHandler: closing connection to %s", s.get_ip())
        s.close()
        s.handler.connection_lost(s)

    def do_poll(self, t):
        r = self.poll.poll(t * timemult)
        if r is None:
            connects = len(self.single_sockets)
            to_close = int(connects * 0.05) +1 # close 5% of sockets
            self.max_connects = connects - to_close
            closelist = [sock for sock in self.single_sockets.values() if not isinstance(sock, InterruptSocket)]
            shuffle(closelist)
            closelist = closelist[:to_close]
            for sock in closelist:
                self._logger.debug("SocketHandler: do_poll closing connection %s", sock.get_ip())
                self._close_socket(sock)
            return []
        return r

    def get_stats(self):
        return {'interfaces': self.interfaces,
                 'port': self.port}

    def shutdown(self):
        for ss in self.single_sockets.values():
            try:
                ss.close()
            except:
                pass
        for server, _ in self.servers.values():
            try:
                server.close()
            except:
                pass

    #
    # Interface for Khasmir, called from RawServer
    #
    #
    def create_udpsocket(self, port, host):
        server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        server.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 870400)
        server.bind((host, port))
        server.setblocking(0)
        return server

    def start_listening_udp(self, serversocket, handler):
        self.udp_sockets[serversocket.fileno()] = UdpSocket(serversocket, handler)
        self.poll.register(serversocket, POLLIN)

    def stop_listening_udp(self, serversocket):
        self.poll.unregister(serversocket)
        del self.udp_sockets[serversocket.fileno()]

    #
    # Interface for the InterruptSocket
    #
    def get_interrupt_socket(self):
        """
        Create a socket to interrupt the poll when the thread needs to
        continue without waiting for the timeout
        """
        if not self.interrupt_socket:
            self.interrupt_socket = InterruptSocket(self)
        return self.interrupt_socket

########NEW FILE########
__FILENAME__ = RemoteTorrentHandler
# Written by Niels Zeilemaker
# see LICENSE.txt for license information
#
# Handles the case where the user did a remote query and now selected one of the
# returned torrents for download.
import Queue
import atexit
import binascii
import logging
import os
import shutil
import sys
import urllib
from binascii import hexlify
from time import sleep, time
from traceback import print_exc

from twisted.internet import reactor
from twisted.internet.base import DelayedCall
from twisted.internet.defer import inlineCallbacks, Deferred
from twisted.internet.task import deferLater, LoopingCall

from Tribler.Core.CacheDB.sqlitecachedb import bin2str, forceDBThread
from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Utilities.utilities import get_collected_torrent_filename
from Tribler.Core.exceptions import DuplicateDownloadException, OperationNotEnabledByConfigurationException
from Tribler.Core.simpledefs import NTFY_TORRENTS, INFOHASH_LENGTH, DLSTATUS_STOPPED_ON_ERROR
from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.dispersy.util import call_on_reactor_thread, blocking_call_on_reactor_thread


SWIFTFAILED_TIMEOUT = 5 * 60  # 5 minutes
TORRENT_OVERFLOW_CHECKING_INTERVAL = 30 * 60
# TODO(emilon): This is not a constant
LOW_PRIO_COLLECTING = 2

class RemoteTorrentHandler:

    __single = None

    def __init__(self):
        RemoteTorrentHandler.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        self.registered = False
        self._searchcommunity = None

        self.callbacks = {}

        self.trequesters = {}
        self.mrequesters = {}
        self.drequesters = {}
        self.metadata_requester = None

        self.num_torrents = 0

        self._pending_tasks = {}

    def getInstance(*args, **kw):
        if RemoteTorrentHandler.__single is None:
            RemoteTorrentHandler(*args, **kw)
        return RemoteTorrentHandler.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        RemoteTorrentHandler.__single = None
    delInstance = staticmethod(delInstance)

    def register(self, dispersy, session, max_num_torrents):
        self.session = session
        self.dispersy = dispersy
        self.max_num_torrents = max_num_torrents
        self.tor_col_dir = self.session.get_torrent_collecting_dir()

        from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue
        self.tqueue = TimedTaskQueue("RemoteTorrentHandler")
        self.scheduletask = self.tqueue.add_task

        self.torrent_db = None
        if self.session.get_megacache():
            self.torrent_db = session.open_dbhandler(NTFY_TORRENTS)
            self.__check_overflow()

        if session.get_dht_torrent_collecting():
            self.drequesters[0] = MagnetRequester(self, 0)
            self.drequesters[1] = MagnetRequester(self, 1)
        self.metadata_requester = MetadataRequester(self, self.session)
        self.registered = True

    def is_registered(self):
        return self.registered

    def cancel_pending_task(self, key):
        task = self._pending_tasks.pop(key)
        if isinstance(task, Deferred) and not task.called:
            # Have in mind that any deferred in the pending tasks list should have been constructed with a
            # canceller function.
            task.cancel()
        elif isinstance(task, DelayedCall) and task.active():
            task.cancel()
        elif isinstance(task, LoopingCall) and task.running:
            task.stop()

    def shutdown(self):
        # TODO(emilon): have a superclass for classes that keep a pending task dictionary
        for key in self._pending_tasks.keys():
            self.cancel_pending_task(key)

        if self.registered:
            self.tqueue.shutdown(True)

    def set_max_num_torrents(self, max_num_torrents):
        self.max_num_torrents = max_num_torrents

    @call_on_reactor_thread
    def __check_overflow(self):
        global LOW_PRIO_COLLECTING
        def clean_until_done(num_delete, deletions_per_step):
            """
            Delete torrents in steps to avoid too much IO at once.
            """
            if num_delete > 0:
                to_remove = min(num_delete, deletions_per_step)
                num_delete -= to_remove
                self.torrent_db.freeSpace(to_remove)
                reactor.callLater(5, clean_until_done, num_delete, deletions_per_step)

        def torrent_overflow_check():
            """
            Check if we have reached the collected torrent limit and throttle its collection if so.
            """
            self.num_torrents = self.torrent_db.getNumberCollectedTorrents()
            self._logger.debug("rtorrent: check overflow: current %d max %d", self.num_torrents, self.max_num_torrents)

            if self.num_torrents > self.max_num_torrents:
                num_delete = int(self.num_torrents - self.max_num_torrents * 0.95)
                deletions_per_step = max(25, num_delete / 180)
                clean_until_done(num_delete, deletions_per_step)
                self._logger.info("rtorrent: ** limit space:: %d %d %d", self.num_torrents, self.max_num_torrents, num_delete)

                LOW_PRIO_COLLECTING = 20

            elif self.num_torrents > (self.max_num_torrents * .75):
                LOW_PRIO_COLLECTING = 10

            elif self.num_torrents > (self.max_num_torrents * .5):
                LOW_PRIO_COLLECTING = 5

            else:
                LOW_PRIO_COLLECTING = 2

            self._logger.debug("rtorrent: setting low_prio_collection to one .torrent every %.1f seconds", LOW_PRIO_COLLECTING * .5)

        self._pending_tasks["torrent overflow check"] = lc = LoopingCall(torrent_overflow_check)
        lc.start(TORRENT_OVERFLOW_CHECKING_INTERVAL, now=True)

    @property
    @blocking_call_on_reactor_thread
    def searchcommunity(self):
        if self.registered:

            if not self._searchcommunity:
                from Tribler.community.search.community import SearchCommunity
                for community in self.dispersy.get_communities():
                    if isinstance(community, SearchCommunity):
                        self._searchcommunity = community
                        break

            return self._searchcommunity

    def has_metadata(self, metadata_type, infohash, contenthash=None):
        folder_prefix = '%s-' % metadata_type
        metadata_dir = os.path.join(self.tor_col_dir, folder_prefix + binascii.hexlify(infohash))
        if contenthash:
            metadata_dir = os.path.join(metadata_dir, binascii.hexlify(contenthash))
        return os.path.isdir(metadata_dir) and os.listdir(metadata_dir)

    def download_metadata(self, metadata_type, candidate, roothash, infohash, contenthash=None, usercallback=None, timeout=None):
        if self.registered and not self.has_metadata(metadata_type, infohash, contenthash):
            raw_lambda = lambda metadata_type = metadata_type, candidate = candidate, roothash = roothash, infohash = infohash, contenthash = contenthash, usercallback = usercallback, timeout = timeout: self._download_metadata(metadata_type, candidate, roothash, infohash, contenthash, usercallback, timeout)
            self.scheduletask(raw_lambda)

    def _download_metadata(self, metadata_type, candidate, roothash, infohash, contenthash, usercallback, timeout):
        if usercallback:
            self.callbacks.setdefault(roothash, set()).add(usercallback)

        self.metadata_requester.add_request((metadata_type, roothash, infohash, contenthash), candidate, timeout)

        str_roothash = '' if not roothash else binascii.hexlify(roothash)
        self._logger.debug('rtorrent: adding metadata request: %s %s %s', metadata_type, str_roothash, candidate)

    def download_torrent(self, candidate, infohash=None, roothash=None, usercallback=None, prio=1, timeout=None):
        if self.registered:
            raw_lambda = lambda candidate = candidate, infohash = infohash, roothash = roothash, usercallback = usercallback, prio = prio, timeout = timeout: self._download_torrent(candidate, infohash, roothash, usercallback, prio, timeout)
            self.scheduletask(raw_lambda)

    def _download_torrent(self, candidate, infohash, roothash, usercallback, prio, timeout):
        if self.registered:
            assert infohash or roothash, "We need either the info or roothash"

            hashes = (infohash, roothash)

            doSwiftCollect = candidate and roothash
            if doSwiftCollect:
                requesters = self.trequesters

            elif infohash:
                requesters = self.drequesters

                # fix prio levels to 1 and 0
                prio = min(prio, 1)
            else:
                return

            # look for lowest prio requester, which already has this infohash scheduled
            requester = None
            for i in range(0, prio + 1):
                if i in requesters and requesters[i].is_being_requested(hash):
                    requester = requesters[i]
                    break

            # if not found, then used/create this requester
            if not requester:
                if prio not in requesters:
                    if doSwiftCollect:
                        requesters[prio] = TorrentRequester(self, self.drequesters.get(1, None), self.session, prio)
                    elif self.session.get_dht_torrent_collecting():
                        requesters[prio] = MagnetRequester(self, prio)

                requester = requesters[prio]

            # make request
            if requester:
                if usercallback:
                    self.callbacks.setdefault(hashes, set()).add(usercallback)

                requester.add_request(hashes, candidate, timeout)
                self._logger.info('rtorrent: adding torrent request: %s %s %s %s', bin2str(infohash or ''), bin2str(roothash or ''), candidate, prio)

    def download_torrentmessage(self, candidate, infohash, usercallback=None, prio=1):
        if self.registered:
            raw_lambda = lambda candidate = candidate, infohash = infohash, usercallback = usercallback, prio = prio: self._download_torrentmessages(candidate, infohash, usercallback, prio)
            self.scheduletask(raw_lambda)

    def _download_torrentmessages(self, candidate, infohash, usercallback, prio):
        assert isinstance(infohash, str), "INFOHASH has invalid type"
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length:"

        if self.registered:
            hashes = (infohash, None)

            if usercallback:
                callback = lambda infohash = infohash: usercallback(infohash)
                self.callbacks.setdefault(hashes, set()).add(callback)

            if prio not in self.mrequesters:
                self.mrequesters[prio] = TorrentMessageRequester(self, self.searchcommunity, prio)

            requester = self.mrequesters[prio]

            # make request
            requester.add_request(hashes, candidate)
            self._logger.debug('rtorrent: adding torrent messages request: %s %s %s', bin2str(infohash), candidate, prio)

    def has_torrent(self, hashes, callback):
        infohash, roothash = hashes
        assert infohash or roothash, "We need either the info or roothash"
        assert not infohash or isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert not infohash or len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)
        assert not roothash or isinstance(roothash, str), "ROOTHASH has invalid type: %s" % type(roothash)

        if self.torrent_db:
            self._has_torrent(hashes, self.tor_col_dir, callback)
        else:
            callback(False)

    @call_on_reactor_thread
    def _has_torrent(self, hashes, tor_col_dir, callback):
        infohash, roothash = hashes

        torrent_filename = None
        if not roothash:
            torrent = self.torrent_db.getTorrent(infohash, ['torrent_file_name', 'swift_torrent_hash'], include_mypref=False)
            if torrent:
                if torrent.get('torrent_file_name', False) and os.path.isfile(torrent['torrent_file_name']):
                    torrent_filename = torrent['torrent_file_name']

                elif torrent.get('swift_torrent_hash', False):
                    torrent_filename = os.path.join(tor_col_dir, binascii.hexlify(torrent['swift_torrent_hash']))

                    if os.path.isfile(torrent_filename):
                        self.torrent_db.updateTorrent(infohash, notify=False, torrent_file_name=torrent_filename)
        else:
            torrent_filename = os.path.join(tor_col_dir, binascii.hexlify(roothash))

        if torrent_filename and os.path.isfile(torrent_filename):
            raw_lambda = lambda: callback(torrent_filename)
        else:
            raw_lambda = lambda: callback(None)
        self.scheduletask(raw_lambda)

    def save_torrent(self, tdef, callback=None):
        if self.registered:
            def do_schedule(filename):
                if not filename:
                    self._save_torrent(tdef, callback)
                elif callback:
                    @forceDBThread
                    def perform_callback():
                        callback()
                    perform_callback()

            infohash = tdef.get_infohash()
            self.has_torrent((infohash, None), do_schedule)

    def _save_torrent(self, tdef, callback=None):
        tmp_filename = os.path.join(self.session.get_torrent_collecting_dir(), "tmp_" + get_collected_torrent_filename(tdef.get_infohash()))
        filename_index = 0
        while os.path.exists(tmp_filename):
            filename_index += 1
            tmp_filename = os.path.join(self.session.get_torrent_collecting_dir(), ("tmp_%d_" % filename_index) + get_collected_torrent_filename(tdef.get_infohash()))

        tdef.save(tmp_filename)
        sdef, swiftpath = self._move_to_collected(tmp_filename)
        if os.path.exists(tmp_filename):
            try:
                os.remove(tmp_filename)
            except:
                atexit.register(lambda tmp_filename=tmp_filename: os.remove(tmp_filename))

        @forceDBThread
        def do_db(callback):
            # add this new torrent to db
            infohash = tdef.get_infohash()
            if self.torrent_db.hasTorrent(infohash):
                if sdef:
                    self.torrent_db.updateTorrent(infohash, swift_torrent_hash=sdef.get_roothash(), torrent_file_name=swiftpath)
                else:
                    self.torrent_db.updateTorrent(infohash, torrent_file_name=swiftpath)
            else:
                if sdef:
                    self.torrent_db.addExternalTorrent(tdef, extra_info={'filename': swiftpath, 'swift_torrent_hash': sdef.get_roothash(), 'status': 'good'})
                else:
                    self.torrent_db.addExternalTorrent(tdef, extra_info={'filename': swiftpath, 'status': 'good'})

            # notify all
            self.notify_possible_torrent_infohash(infohash, swiftpath)
            if callback:
                callback()

        if self.torrent_db:
            do_db(callback)
        elif callback:
            callback()

    def _move_to_collected(self, filename):
        # if we don't have swift, write to collected using infohash as name
        if os.path.isfile(self.session.get_swift_path()):
            # calculate root-hash
            sdef = SwiftDef()
            sdef.add_content(filename)
            sdef.finalize(self.session.get_swift_path(), destdir=self.session.get_torrent_collecting_dir())

            mfpath = os.path.join(self.session.get_torrent_collecting_dir(), sdef.get_roothash_as_hex())
            if not os.path.exists(mfpath):
                download = self.session.get_download(sdef.get_roothash())
                if download:
                    self.session.remove_download(download, removestate=True)
                    sleep(1)
                elif os.path.exists(mfpath + ".mhash"):  # indicating failed swift download
                    os.remove(mfpath + ".mhash")

                try:
                    shutil.move(filename, mfpath)
                    shutil.move(filename + '.mhash', mfpath + '.mhash')
                    shutil.move(filename + '.mbinmap', mfpath + '.mbinmap')

                except:
                    print_exc()

            return sdef, mfpath

        tdef = TorrentDef.load(filename)
        mfpath = os.path.join(self.session.get_torrent_collecting_dir(), get_collected_torrent_filename(tdef.get_infohash()))
        shutil.copyfile(filename, mfpath)
        return None, mfpath

    def notify_possible_torrent_roothash(self, roothash):
        keys = self.callbacks.keys()
        for key in keys:
            if key[1] == roothash:
                handle_lambda = lambda key = key: self._handleCallback(key, True)
                self.scheduletask(handle_lambda)
        @forceDBThread
        def do_db(tdef):
            if self.torrent_db.hasTorrent(tdef.get_infohash()):
                self.torrent_db.updateTorrent(tdef.get_infohash(), swift_torrent_hash=sdef.get_roothash(), torrent_file_name=swiftpath)
            else:
                self.torrent_db._addTorrentToDB(tdef, source="SWIFT", extra_info={'filename': swiftpath, 'swift_torrent_hash': roothash, 'status': 'good'})

        sdef = SwiftDef(roothash)
        swiftpath = os.path.join(self.session.get_torrent_collecting_dir(), sdef.get_roothash_as_hex())
        if os.path.exists(swiftpath) and self.torrent_db:
            try:
                tdef = TorrentDef.load(swiftpath)
                do_db(tdef)

            except:
                # ignore if tdef loading fails
                pass

    def notify_possible_metadata_roothash(self, roothash):
        keys = self.callbacks.keys()
        for key in keys:
            if key == roothash:
                handle_lambda = lambda key = key: self._handleCallback(key, True)
                self.scheduletask(handle_lambda)
                self._logger.info('rtorrent: finished downloading metadata: %s', binascii.hexlify(roothash))

    def notify_possible_torrent_infohash(self, infohash, actualTorrentFileName=None):
        keys = self.callbacks.keys()
        for key in keys:
            if key[0] == infohash or key == infohash:
                handle_lambda = lambda key = key: self._handleCallback(key, actualTorrentFileName)
                self.scheduletask(handle_lambda)

    def _handleCallback(self, key, actualTorrentFileName=None):
        self._logger.debug('rtorrent: got torrent for: %s', key)

        if key in self.callbacks:
            for usercallback in self.callbacks[key]:
                self.session.uch.perform_usercallback(lambda usercallback=usercallback: usercallback(actualTorrentFileName))

            del self.callbacks[key]

            if actualTorrentFileName:
                for requester in self.trequesters.values():
                    if requester.is_being_requested(key):
                        requester.remove_request(key)

                for requester in self.drequesters.values():
                    if requester.is_being_requested(key):
                        requester.remove_request(key)
            else:
                for requester in self.mrequesters.values():
                    if requester.is_being_requested(key):
                        requester.remove_request(key)

    def getQueueSize(self):
        def getQueueSize(qname, requesters):
            qsize = {}
            for requester in requesters.itervalues():
                if len(requester.sources):
                    qsize[requester.prio] = len(requester.sources)
            items = qsize.items()
            if items:
                items.sort()
                return "%s: " % qname + ",".join(map(lambda a: "%d/%d" % a, items))
            return ''
        return ", ".join([qstring for qstring in [getQueueSize("TQueue", self.trequesters), getQueueSize("DQueue", self.drequesters), getQueueSize("MQueue", self.mrequesters)] if qstring])

    def getQueueSuccess(self):
        def getQueueSuccess(qname, requesters):
            sum_requests = sum_success = sum_fail = sum_on_disk = 0
            print_value = False
            for requester in requesters.itervalues():
                if requester.requests_success >= 0:
                    print_value = True
                    sum_requests += requester.requests_made
                    sum_success += requester.requests_success
                    sum_fail += requester.requests_fail
                    sum_on_disk += requester.requests_on_disk

            if print_value:
                return "%s: %d/%d" % (qname, sum_success, sum_requests), "%s: success %d, pending %d, on disk %d, failed %d" % (qname, sum_success, sum_requests - sum_success - sum_fail - sum_on_disk, sum_on_disk, sum_fail)
            return '', ''
        return [(qstring, qtooltip) for qstring, qtooltip in [getQueueSuccess("TQueue", self.trequesters), getQueueSuccess("DQueue", self.drequesters), getQueueSuccess("MQueue", self.mrequesters)] if qstring]

    def getBandwidthSpent(self):
        def getQueueBW(qname, requesters):
            bw = 0
            for requester in requesters.itervalues():
                bw += requester.bandwidth
            if bw:
                return "%s: " % qname + "%.1f KB" % (bw / 1024.0)
            return ''
        return ", ".join([qstring for qstring in [getQueueBW("TQueue", self.trequesters), getQueueBW("DQueue", self.drequesters)] if qstring])

class Requester:
    REQUEST_INTERVAL = 0.5

    def __init__(self, scheduletask, prio):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.scheduletask = scheduletask
        self.prio = prio

        self.queue = Queue.Queue()
        self.sources = {}
        self.canrequest = True

        self.requests_made = 0
        self.requests_success = 0
        self.requests_fail = 0
        self.requests_on_disk = 0

        self.bandwidth = 0

    def add_request(self, hashes, candidate, timeout=None):
        assert isinstance(hashes, tuple), type(hashes)
        assert len(hashes) >= 2, hashes

        was_empty = self.queue.empty()

        if hash not in self.sources:
            self.sources[hashes] = set()

        if timeout is None:
            timeout = sys.maxsize
        else:
            timeout = timeout + time()

        self.sources[hashes].add(candidate)
        self.queue.put((hashes, timeout))

        if was_empty:
            self.scheduletask(self.doRequest, t=self.REQUEST_INTERVAL * self.prio)

    def is_being_requested(self, hashes):
        return hashes in self.sources

    def remove_request(self, hashes):
        del self.sources[hashes]

    def doRequest(self):
        try:
            madeRequest = False
            if isinstance(self.canrequest, bool):
                canRequest = self.canrequest
            else:
                canRequest = self.canrequest()

            if canRequest:
                # request new infohash from queue
                while True:
                    hashes, timeout = self.queue.get_nowait()

                    # check if still needed
                    if time() > timeout:
                        self._logger.debug("rtorrent: timeout for hash %s", hash)

                        if hashes in self.sources:
                            del self.sources[hashes]

                    elif hashes in self.sources:
                        break

                    self.queue.task_done()

                try:
                    candidates = list(self.sources[hashes])
                    del self.sources[hashes]

                    madeRequest = self.doFetch(hashes, candidates)
                    if madeRequest:
                        self.requests_made += 1

                # Make sure exceptions wont crash this requesting loop
                except:
                    print_exc()

                self.queue.task_done()

            if madeRequest or not canRequest:
                self.scheduletask(self.doRequest, t=self.REQUEST_INTERVAL * self.prio)
            else:
                self.scheduletask(self.doRequest)
        except Queue.Empty:
            pass

    def doFetch(self, hashes, candidates):
        raise NotImplementedError()


class TorrentRequester(Requester):
    MAGNET_TIMEOUT = 5.0
    SWIFT_CANCEL = 30.0

    def __init__(self, remote_th, magnet_requester, session, prio):
        Requester.__init__(self, remote_th.scheduletask, prio)

        self.remote_th = remote_th
        self.magnet_requester = magnet_requester
        self.session = session

        defaultDLConfig = DefaultDownloadStartupConfig.getInstance()
        self.dscfg = defaultDLConfig.copy()
        self.dscfg.set_dest_dir(session.get_torrent_collecting_dir())
        self.dscfg.set_swift_meta_dir(session.get_torrent_collecting_dir())

    def add_request(self, hashes, candidate, timeout=None):
        infohash, roothash = hashes

        assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)

        Requester.add_request(self, hashes, candidate, timeout)

    def doFetch(self, hashes, candidates):
        raw_lambda = lambda filename, hashes = hashes, candidates = candidates: self._doFetch(filename, hashes, candidates)
        self.remote_th.has_torrent(hashes, raw_lambda)
        return True

    def _doFetch(self, filename, hashes, candidates):
        infohash, roothash = hashes
        attempting_download = False

        if filename:
            self.remote_th.notify_possible_torrent_infohash(infohash, filename)
            self.remote_th.notify_possible_torrent_infohash(hash, filename)

            self.requests_on_disk += 1

        elif candidates:
            candidate = candidates[0]
            candidates = candidates[1:]

            ip, port = candidate.sock_addr
            if not candidate.tunnel:
                port = 7758

            self._logger.debug("rtorrent: requesting torrent %s %s %s", hash, ip, port)

            doMagnet = self.prio <= 1
            download = None

            sdef = SwiftDef(roothash, tracker="%s:%d" % (ip, port))
            dcfg = self.dscfg.copy()
            try:
                # hide download from gui
                download = self.session.start_download(sdef, dcfg, hidden=True)

                state_lambda = lambda ds, infohash = infohash, roothash = roothash, doMagnet = doMagnet: self.check_progress(ds, infohash, roothash, doMagnet)
                download.set_state_callback(state_lambda, delay=self.REQUEST_INTERVAL * (self.prio + 1))
                download.started_downloading = time()

            except DuplicateDownloadException:
                download = self.session.get_download(roothash)
                download.add_peer((ip, port))

            except OperationNotEnabledByConfigurationException:
                doMagnet = True

            else:
                self._logger.debug("rtorrent: start swift download for %s %s %s", bin2str(roothash), ip, port)
                attempting_download = True

            if download and candidates:
                try:
                    for candidate in candidates:
                        ip, port = candidate.sock_addr
                        if not candidate.tunnel:
                            port = 7758

                        download.add_peer((ip, port))
                except:
                    print_exc()

            # schedule a magnet lookup after X seconds
            if doMagnet and self.magnet_requester:
                magnet_lambda = lambda hashes = hashes: self.magnet_requester.add_request(hashes, None)
                self.scheduletask(magnet_lambda, t=self.MAGNET_TIMEOUT * (self.prio))

        return attempting_download

    def check_progress(self, ds, infohash, roothash, didMagnet):
        d = ds.get_download()
        cdef = d.get_def()

        if ds.get_progress() == 1:
            remove_lambda = lambda d = d: self._remove_download(d, False)
            self.scheduletask(remove_lambda)

            self._logger.debug("rtorrent: swift finished for %s %s", cdef.get_name(), bin2str(infohash or ''))

            self.remote_th.notify_possible_torrent_roothash(roothash)
            self.requests_success += 1
            self.bandwidth += d.get_total_down()
            return (0, False)
        else:
            diff = time() - getattr(d, 'started_downloading', time())
            if (diff > self.SWIFT_CANCEL and ds.get_progress() == 0) or diff > 45 or ds.get_status() == DLSTATUS_STOPPED_ON_ERROR:
                remove_lambda = lambda d = d: self._remove_download(d)
                self.scheduletask(remove_lambda)

                self._logger.debug("rtorrent: swift failed download for %s %s", cdef.get_name(), bin2str(infohash or ''))

                if not didMagnet and self.magnet_requester:
                    self._logger.debug("rtorrent: switching to magnet for %s %s", cdef.get_name(), bin2str(infohash or ''))
                    self.magnet_requester.add_request((infohash, roothash), None, timeout=SWIFTFAILED_TIMEOUT)

                self.requests_fail += 1
                return (0, False)
        return (self.REQUEST_INTERVAL * (self.prio + 1), True)

    def _remove_download(self, d, removestate=True):
        # Arno, 2012-05-30: Make sure .mbinmap is written
        if not removestate and d.get_def().get_def_type() == 'swift':
            d.checkpoint()
        # Arno+Niels, 2012-09-19: Remove content as well on failed swift dl.
        self.session.remove_download(d, removecontent=removestate, removestate=removestate, hidden=True)


class TorrentMessageRequester(Requester):

    def __init__(self, remote_th, searchcommunity, prio):
        if sys.platform == 'darwin':
            # Arno, 2012-07-25: Mac has just 256 fds per process, be less aggressive
            self.REQUEST_INTERVAL = 1.0

        Requester.__init__(self, remote_th.scheduletask, prio)
        self.searchcommunity = searchcommunity
        self.requests_success = -1

    def doFetch(self, hashes, candidates):
        infohash, roothash = hashes

        attempting_download = False
        if self.searchcommunity:
            self._logger.debug("rtorrent: requesting torrent message %s %s", bin2str(infohash), candidates)

            for candidate in candidates:
                self.searchcommunity.create_torrent_request(infohash, candidate)
                attempting_download = True

        return attempting_download


class MagnetRequester(Requester):
    MAX_CONCURRENT = 1
    MAGNET_RETRIEVE_TIMEOUT = 30.0

    def __init__(self, remote_th, prio):
        if sys.platform == 'darwin':
            # mac has severe problems with closing connections, add additional time to allow it to close connections
            self.REQUEST_INTERVAL = 15.0

        Requester.__init__(self, remote_th.scheduletask, prio)

        self.remote_th = remote_th
        self.requestedInfohashes = set()

        if prio <= 1 and not sys.platform == 'darwin':
            self.MAX_CONCURRENT = 3
        self.canrequest = lambda: len(self.requestedInfohashes) < self.MAX_CONCURRENT

    def doFetch(self, hashes, candidates):
        infohash, roothash = hashes

        if infohash not in self.requestedInfohashes:
            self.requestedInfohashes.add(infohash)

            raw_lambda = lambda filename, infohash = infohash, candidates = candidates: self._doFetch(filename, infohash, candidates)
            self.remote_th.has_torrent(hashes, raw_lambda)
            return True

    def _doFetch(self, filename, infohash, candidates):
        if filename:
            if infohash in self.requestedInfohashes:
                self.requestedInfohashes.remove(infohash)

            self.remote_th.notify_possible_torrent_infohash(infohash, filename)
            self.requests_on_disk += 1

        else:
            @forceDBThread
            def construct_magnet():
                # try magnet link
                magnetlink = "magnet:?xt=urn:btih:" + hexlify(infohash)

                if self.remote_th.torrent_db:
                    # see if we know any trackers for this magnet
                    trackers = self.remote_th.torrent_db.getTrackerListByInfohash(infohash)
                    for tracker in trackers:
                        if tracker != 'no-DHT' and tracker != 'DHT':
                            magnetlink += "&tr=" + urllib.quote_plus(tracker)

                self._logger.debug('%d rtorrent: requesting magnet %s %s %s %d', long(time()), bin2str(infohash), self.prio, magnetlink, len(self.requestedInfohashes))

                TorrentDef.retrieve_from_magnet(magnetlink, self.__torrentdef_retrieved, self.MAGNET_RETRIEVE_TIMEOUT, max_connections=30 if self.prio == 0 else 10, silent=True)
            construct_magnet()

            failed_lambda = lambda infohash = infohash: self.__torrentdef_failed(infohash)
            self.scheduletask(failed_lambda, t=self.MAGNET_RETRIEVE_TIMEOUT)
            return True

    def __torrentdef_retrieved(self, tdef):
        infohash = tdef.get_infohash()
        self._logger.debug('rtorrent: received torrent using magnet %s', bin2str(infohash))

        self.remote_th.save_torrent(tdef)
        if infohash in self.requestedInfohashes:
            self.requestedInfohashes.remove(infohash)

        self.requests_success += 1
        self.bandwidth += tdef.get_torrent_size()

    def __torrentdef_failed(self, infohash):
        if infohash in self.requestedInfohashes:
            self.requestedInfohashes.remove(infohash)

            self.requests_fail += 1

class MetadataRequester(Requester):
    SWIFT_CANCEL = 30.0

    def __init__(self, remote_th, session):
        Requester.__init__(self, remote_th.scheduletask, 0)

        self.remote_th = remote_th
        self.session = session

        self.blacklist_set = set()

        defaultDLConfig = DefaultDownloadStartupConfig.getInstance()
        self.dscfg = defaultDLConfig.copy()
        self.dscfg.set_dest_dir(session.get_torrent_collecting_dir())
        self.dscfg.set_swift_meta_dir(session.get_torrent_collecting_dir())

    def check_blacklist(self, roothash):
        return roothash in self.blacklist_set

    def doFetch(self, hashes, candidates):
        metadata_type, roothash, infohash, contenthash = hashes
        attempting_download = False

        if self.remote_th.has_metadata(metadata_type, infohash, contenthash):
            self.remote_th.notify_possible_metadata_roothash(roothash)

        elif self.check_blacklist(roothash):
            return False

        elif candidates:
            candidate = candidates[0]
            candidates = candidates[1:]

            ip, port = candidate.sock_addr
            if not candidate.tunnel:
                port = 7758

            self._logger.debug("rtorrent: requesting metadata %s %s %s %s",
                metadata_type, binascii.hexlify(roothash), ip, port)

            download = None

            sdef = SwiftDef(roothash, tracker="%s:%d" % (ip, port))
            dcfg = self.dscfg.copy()
            try:
                # hide download from gui
                download = self.session.start_download(sdef, dcfg, hidden=True)

                state_lambda = lambda ds, roothash = roothash: self.check_progress(ds, roothash)
                download.set_state_callback(state_lambda, delay=self.REQUEST_INTERVAL * (self.prio + 1))
                download.started_downloading = time()

            except DuplicateDownloadException:
                download = self.session.get_download(roothash)
                download.add_peer((ip, port))

            except OperationNotEnabledByConfigurationException:
                pass

            else:
                attempting_download = True

            if download and candidates:
                try:
                    for candidate in candidates:
                        ip, port = candidate.sock_addr
                        if not candidate.tunnel:
                            port = 7758

                        download.add_peer((ip, port))
                except:
                    print_exc()

        return attempting_download

    def check_progress(self, ds, roothash):
        d = ds.get_download()
        # do not download metadata larger than 5MB
        if d.get_dynasize() > 5 * 1024 * 1024:
            remove_lambda = lambda d = d: self._remove_download(d, False)
            self.scheduletask(remove_lambda)
            self.blacklist_set.add(roothash)
            return (0, False)

        cdef = d.get_def()
        if ds.get_progress() == 1:
            remove_lambda = lambda d = d: self._remove_download(d, False)
            self.scheduletask(remove_lambda)

            self._logger.debug("rtorrent: swift finished for %s", cdef.get_name())

            self.remote_th.notify_possible_metadata_roothash(roothash)
            self.requests_success += 1
            return (0, False)
        else:
            diff = time() - getattr(d, 'started_downloading', time()) > 45
            if (diff > self.SWIFT_CANCEL and ds.get_progress() == 0) or diff > 45 or ds.get_status() == DLSTATUS_STOPPED_ON_ERROR:
                remove_lambda = lambda d = d: self._remove_download(d)
                self.scheduletask(remove_lambda)
                self.requests_fail += 1
                return (0, False)

        return (self.REQUEST_INTERVAL * (self.prio + 1), True)

    def _remove_download(self, d, removestate=True):
        if not removestate and d.get_def().get_def_type() == 'swift':
            d.checkpoint()
        self.session.remove_download(d, removecontent=removestate, removestate=removestate, hidden=True)

########NEW FILE########
__FILENAME__ = Bundler
# written by Raynor Vliegendhart
# see LICENSE.txt for license information
import re
from itertools import islice
import time
import logging

from Tribler.Core.Search.SearchManager import split_into_keywords

# Flags
USE_PSYCO = False  # Enables Psyco optimization for the Levenshtein algorithm
DEBUG = False  # Enables debug print messages to stderr
class HitsGroup(object):

    """
    A HitsGroup represents a list of similar hits (i.e., search results) grouped together.
    With each group, an identifier is associated. The identifier is used by the GUI
    for refreshing and updating GUI controls.
    In addition to an id, a HitsGroup stores the "key" and "simkey" used by the grouping
    algorithms (see GroupingAlgorithm for more information on these notions).
    """

    last_id = -1  # Counter for automatic id assignment

    @classmethod
    def new_id(cls):
        """
        Get a fresh identifier by autoincrementing the last issued id.
        @return A new HitsGroup identifier.
        """
        cls.last_id += 1
        return cls.last_id

    def __init__(self, id= -1, key=None, simkey=None, prev_group=None):
        """
        Constructs a new HitsGroup object.

        @param id Identifier assigned to this group. If set to -1, a new id
        is automatically assigned and the attribute reassignable_id is set to True.
        @param key The "key" of the representative hit, computed by a GroupingAlgorithm.
        @param simkey The "simkey" of this group, computed by a GroupingAlgorithm.
        @param prev_group The previous version of this group, if any.
        """
        self.hits = []
        self.reassignable_id = id == -1
        if id == -1:
            self.id = HitsGroup.new_id()
        else:
            self.id = id

        self.key = key
        self.simkey = simkey
        self.prev_group = prev_group

    def get_representative(self):
        """
        Gets the representative hit of this group, i.e. the first item.
        Assumes a non-empty group.
        @return Representative hit of this group.
        """
        return self.hits[0]

    def reassign_id(self, newid):
        """
        Changes the identifier of this group. This method should only be called if
        no explicit id was given at construction (i.e. id=-1) and it should only
        be called once. It is the caller's responsibility to check the value of
        the reassignable_id attribute.

        @param newid The new identifier for this group. Should be an identifier
        that has been previously assigned.
        """
        self.id = newid
        self.reassignable_id = False

    def add(self, hit):
        """
        Add a hit to this group.
        @param hit A search result, i.e. hit.
        """
        self.hits.append(hit)

    def __iter__(self):
        """
        Returns an iterator yielding the added hits.
        @return A listiterator yielding added hits.
        """
        return iter(self.hits)

    def __len__(self):
        """
        Returns the length of this group, i.e. the number of added hits.
        @return The number of hits added.
        """
        return len(self.hits)

    def __getitem__(self, i):
        """
        Returns the ith added hit.
        @param i The index of the hit to be returned
        @return The hit with index i.
        """
        return self.hits[i]

    def has_changed(self):
        """
        Returns whether this group has changed since the previous version.
        Note that if this is a new group, it is not considered as a changed group.
        @return True if the group has changed since the previous version, otherwise False.
        """
        return self.prev_group and self.hits != self.prev_group.hits


class GroupsList(object):

    """
    A GroupsList represents a list of grouped hits, i.e., a list of HitsGroups, and
    is responsible for constructing these HitsGroups using a given grouping algorithm
    and, optionally, the state from a previous given list.
    The list of groups is exposed through the groups attribute.

    Note: This class does not expose any methods to mutate an instance (e.g., adding new
    hits). Instead, for each change or set of changes, a new instance must be constructed.
    """
    # The reason why new instances must be constructed:
    # Certain algorithms use a datatstructure that's hard to modify. For example,
    # the size grouping algorithm uses an IntervalTree. Adding new intervals is easy,
    # but removing is not.
    def __init__(self, query, algorithm, hits, prev_grouplist=None, max_bundles=None, two_step=False):
        """
        Constructs a GroupsList.

        @param query The query that was used to retrieve the hits.
        @param algorithm The algorithm to apply to group the hits.
        @param hits The hits retrieved by the query.
        @param prev_grouplist Optionally, a previous version of this GroupsList.
        @param max_bundles The maximum number of bundles to be created. Default: None (no limit).
        @param two_step Constructs the object in two steps. Default: False. See also: finalize().
        """
        self._logger = logging.getLogger(self.__class__.__name__)

        self.query = query
        self.algorithm = algorithm
        self.prev_grouplist = prev_grouplist

        if prev_grouplist is not None:
            self.context_state = prev_grouplist.context_state
        else:
            self.context_state = algorithm.create_context_state()
        self.index = algorithm.create_index()
        self.groups = []
        self.infohashes = set()
        self.representative_hashes = set()

        self.old_representatives, self.old_index, self.reuse = self._compute_diff(hits)

        self.max_bundles = max_bundles
        self.unprocessed_hits = hits

        if not two_step:
            self.finalize()

    def finalize(self):
        """
        Finalizes this GroupsList in case of a two-step construction.
        """
        if self.unprocessed_hits is not None:
            self._add_all(self.unprocessed_hits, max_bundles=self.max_bundles)
            self.unprocessed_hits = None

    def is_finalized(self):
        """
        Returns whether this GroupsList is finalized.
        @return True if this GroupsList is finalized, False otherwise.
        """
        return self.unprocessed_hits is None

    def _compute_diff(self, hits):
        """
        Private auxiliary method to compute the differences since the previous
        GroupsList and updates the context state.

        @param hits The hits to be grouped.
        @return A tuple containing the previous representatives, the previous index
        and whether the old GroupsList can be reused.
        """
        if self.prev_grouplist is not None:
            old_hashes = self.prev_grouplist.infohashes
            old_representatives = self.prev_grouplist.representative_hashes
            old_index = self.prev_grouplist.index
            new_hits = [hit for hit in hits if hit.infohash not in old_hashes]
            missing_hits = len(new_hits) + len(old_hashes) > len(hits)
        else:
            old_representatives = set()
            old_index = {}
            new_hits = hits
            missing_hits = False

        reuse = self.prev_grouplist and not new_hits and not missing_hits
        self.algorithm.update_context_state(new_hits, self.context_state)

        self._logger.debug('>> Bundler.py, new hits: %d', len(new_hits))

        return old_representatives, old_index, reuse

    def _add_all(self, hits, max_bundles=None):
        """
        Private auxiliary method to perform the actual grouping.
        The core, unoptimized and simplified algorithm works as follow:
            grouped_hits = []
            index = algorithm.create_index()
            for hit in hits:
                key = algorithm.key(hit)
                simkey = algorithm.simkey(key)

                group = None
                if key in index:
                    group = index[key]
                else:
                    new_group = GroupsHit(id=-1, key=key, simkey=simkey)
                    index[simkey] = new_group
                    grouped_hits.append(new_group)
                    group = new_group

                group.append(hit)

        @param hits The hits to be grouped.
        @param max_bundles The maximum number of bundles to be created. Default: None (no limit).
        """
        algorithm = self.algorithm
        context_state = self.context_state
        grouped_hits = self.groups

        infohashes = self.infohashes
        old_representatives = self.old_representatives
        old_index = self.old_index

        def create_new_group(hit_infohash, group_id, index, key, context_state):
            # compute simkey for new group
            simkey = algorithm.simkey(key, context_state)

            # create new group and store it in the index
            new_group = HitsGroup(group_id, key, simkey, prev_group=old_group)
            index[simkey] = new_group
            return new_group

        def disabled_bundling(hit_infohash, group_id, index, key, context_state):
            # only create a new group
            new_group = HitsGroup(group_id, key, hit_infohash)
            return new_group

        # Niels: Used bundler.py from 5.4.x, i'll fix it afterwards.
        if self.reuse:
            self._logger.debug('>> Bundler.py: No new hits, no missing hits, reusing the old groupings')

            self.__dict__ = self.prev_grouplist.__dict__
            # self.index = self.prev_grouplist.index
            # self.groups = self.prev_grouplist.groups
            # self.infohashes = self.prev_grouplist.infohashes
            # self.representative_hashes = self.prev_grouplist.representative_hashes
        else:
            index = self.index
            processed_hits = 0
            for hit in hits:
                processed_hits += 1

                key = algorithm.key(hit, context_state)
                hit_infohash = hit.infohash

                # Find or create new group
                group = None
                if key in index:
                    # fetch existing group
                    group = index[key]

                    # A representative hit from the old results is being migrated
                    # to a newer group.
                    # We might want to reuse that old group's id
                    if group.reassignable_id and hit_infohash in old_representatives:
                        self._logger.debug('>> Bundler.py: How often does this situation actually occur?')
                        old_group = old_index[key]
                        group.reassign_id(old_group.id)
                        group.prev_group = old_group
                else:
                    # try to reuse old group_id
                    group_id = -1
                    old_group = None
                    if key in old_index:
                        old_group = old_index[key]
                        group_id = old_group.id

                    # create a new group (and store it in the index)
                    group = create_new_group(hit_infohash, group_id, index, key, context_state)
                    grouped_hits.append(group)

                    # When we reach max_bundles, disable bundling by adjusting
                    # the computation of simkeys
                    if len(grouped_hits) == max_bundles:
                        create_new_group = disabled_bundling
                        self._logger.debug('>> Bundler.py, reached limit of %s bundles,', max_bundles)
                        self._logger.debug('     disabling the computation of simkeys after processing %s hits', processed_hits)

                group.add(hit)
                infohashes.add(hit_infohash)


class GroupingAlgorithm(object):

    """
    Abstract base class for grouping algorithms.
    Grouping algorithms specify to which group a hit should be added and
    are used by the GroupsList class in order to perform the actual grouping.
    """

    def general_description(self):
        """
        Returns a general description which is used to customize a header
        in the GUI. The substring "Similar" in "Similar items" will be replaced
        by the string returned by this method.
        If None is returned (default implementation), the GUI does not perform
        a replacement.

        @return A string or None.
        """
        return None

    def description_for(self, hitsgroup):
        """
        Returns a description for a specific group of hits. The GUI can display
        this as e.g. a tooltip.
        The default implementation returns None.

        @return A string or None.
        """
        return None

    def create_context_state(self):
        """
        Optional method. Creates a new state object (of any type) that is
        updated and threaded between instances of GroupsList.
        See also: update_context_state

        @return A state object.
        """
        return None

    def update_context_state(self, new_hits, context_state):
        """
        Optional method. Updates the given context state based upon a list of
        new hits since the last time this method was called for the given
        context state.

        @param new_hits A list of new hits since the last call.
        @param context_state A context state that needs to be updated.
        """
        pass

    def key(self, hit, context_state):
        """
        Maps a hit onto a key. A key represents certain features of a hit
        corresponding to a particular notion of similarity.

        @param hit The hit to compute the key of.
        @param context_state The previous context state.
        @return The hit's key.
        """
        raise NotImplementedError('key')

    def simkey(self, key, context_state):
        """
        Maps a key to a "simkey". A simkey is a representation of a keys
        that are similar to the given key (including the key itself).

        @param key The key to compute the simkey of.
        @param context_state The previous context state.
        @return The key's simkey.
        """
        raise NotImplementedError('simkey')

    @classmethod
    def create_index(cls):
        """
        Creates a new instance of the GroupingAlgorithm's index datastructure.
        The index datastructure is used to map keys to groups. The datastructure
        depends on the algorithm's choice of representation of the keys and simkeys.

        @return A new instance of the GroupingAlgorithm's index datastructure.
        """
        return cls.Index()

    class Index(object):

        """
        Abstract base class for a GroupingAlgorithm's index datastructure.
        The datastructure supports 3 main operations:
          * Checking whether there's an existing group covering a particular
            key (__contains__ method);
          * Retrieving a group for a particular key (__getitem__ method);
          * Storing a new group under a particular simkey (__setitem__ method).
        """
        __slots__ = []

        def __contains__(self, key):
            """
            Checks whether a group exists that covers hits with a particular
            key.

            @param key The key of a hit that needs to be assigned to a group.
            @return True if a group exists for the key 'key'.
            """
            raise NotImplementedError('__contains__')

        def __getitem__(self, key):
            """
            Checks whether a group exists that covers hits with a particular
            key.

            @param key The key of a hit that needs to be assigned to a group.
            @return True if a group exists for the key 'key'.
            """
            raise NotImplementedError('__getitem__')

        def __setitem__(self, simkey, group):
            """
            Stores a new group under a given simkey.

            @param simkey The simkey of the key of the group's representative hit.
            @param group The group to be stored in the index.
            """
            raise NotImplementedError('__setitem__')


class SimpleExactKeyGrouping(GroupingAlgorithm):

    """
    The SimpleExactKeyGrouping is an abstract base class for algorithms
    that perform exact grouping based on a single key. For these algorithms,
    the simkey of a key is simply the key itself and the Index structure is
    therefore isomorphic to a dict.
    """

    def simkey(self, key, context_state):
        return key

    class Index(GroupingAlgorithm.Index):

        """
        The Index datastructure is isomorphic to a dict.
        """
        __slots__ = ['mapTo']

        def __init__(self):
            self.mapTo = {}

        def __contains__(self, key):
            return key in self.mapTo

        def __getitem__(self, key):
            return self.mapTo[key]

        def __setitem__(self, simkey, group):
            self.mapTo[simkey] = group

class IntGrouping(SimpleExactKeyGrouping):

    """
    The IntGrouping algorithm groups similarly numbered hits together.

    The key of a hit is a sequence (tuple) of numbers appearing in the
    hit's name. The simkey of a key simply the key. Hence, the IntGrouping
    algorithm only groups hits together when their names contain the exact
    same sequence of numbers.
    """

    def __init__(self):
        self.re_extract_ints = re.compile('[0-9]+', re.UNICODE)

    def general_description(self):
        return u'Similarly numbered'

    def description_for(self, hitsgroup):
        return u'Names of these items contain the following numbers: %s' % ', '.join(str(num) for num in hitsgroup.simkey)

    def key(self, hit, context_state):
        key = tuple(int(n) for n in self.re_extract_ints.findall(hit.name))
        if key == ():
            key = hit.infohash
        return key


class CategoryGrouping(SimpleExactKeyGrouping):

    """
    The CategoryGrouping algorithm groups hits from the same category together.
    """

    def general_description(self):
        # return u'Similarly ???'  # Naming of groups needs to be rethought.
        return None

    def description_for(self, hitsgroup):
        return u'Category: %s' % hitsgroup.simkey

    def key(self, hit, context_state):
        cat = hit['category']
        if isinstance(cat, list):
            if cat:
                key = cat[0]
            else:
                key = 'unknown'
        else:
            key = cat
        return key.lower()


class LevGrouping(GroupingAlgorithm):

    """
    The LevGrouping algorithm groups similarly named hits together based
    on a weighted edit distance. Edit costs have a lower weight when they
    occur further in the string.

    The key of a hit is a string representation formed by a simple concatenation
    of the keywords (see Tribler.Core.Search.SearchManager.split_into_keywords)
    extracted from its name. The simkey of a key are all keys (taken from all hits)
    that are within a MAX_COST edit distance.

    In order to efficiently compute a simkey, the LevGrouping algorithm keeps
    track of all keys using a trie as its context state
    (see LevenshteinTrie and LevenshteinTrie_Cached).
    """

    # Parameters:
    MAX_COST = 0.50
    MAX_LEN = 10
    # 10:
    #   works well for unspecific queries
    # 50/100:
    #   works well for specific queries, manages to distinguish different sources and/or languages
    #   (is a bit slow though with long results list + psyco disabled)

    def general_description(self):
        return u'Similarly named'

    def description_for(self, hitsgroup):
        # assert: len(hitsgroup) > 0
        N = LevGrouping.MAX_LEN
        hit = hitsgroup.hits[0]
        key = ' '.join(split_into_keywords(hit.name))

        if len(key) > N:
            # check if we're truncating within a word
            if key[N - 1] != ' ' and key[N] != ' ':
                key = key[:N] + '...'
            else:
                key = key[:N].rstrip()

        return u'Names of these items resemble "%s"' % key

    def create_context_state(self):
        # return LevenshteinTrie(MAX_LEN=LevGrouping.MAX_LEN)
        return LevenshteinTrie_Cached(MAX_LEN=LevGrouping.MAX_LEN)

    def update_context_state(self, new_hits, context_state):
        trie = context_state
        new_words = []
        for hit in new_hits:
            word = self.key(hit, None)
            new_words.append(word)
            trie.add_word(word)

        trie.update_cache(new_words)

    def key(self, hit, context_state):
        return ' '.join(split_into_keywords(hit.name))[:LevGrouping.MAX_LEN]

    def simkey(self, key, context_state):
        # NB: simkey is a list of similar keys in this case, but should also contain key,
        # assuming the context_state is updated appropiately
        trie = context_state
        return trie.search(key, LevGrouping.MAX_COST)

    class Index(GroupingAlgorithm.Index):

        """
        The LevGrouping's index datastructure is quite similar to a dict.
        The only difference is that storing a new group in the index
        corresponds to multiple insertion in a dict, one per key contained
        within the simkey.
        """
        __slots__ = ['mapTo']

        def __init__(self):
            self.mapTo = {}

        def __contains__(self, key):
            return key in self.mapTo

        def __getitem__(self, key):
            return self.mapTo[key]

        def __setitem__(self, simkey, group):
            mapTo = self.mapTo
            for key in simkey:
                if key not in mapTo:
                    mapTo[key] = group


class SizeGrouping(GroupingAlgorithm):

    """
    The SizeGrouping algorithm groups similarly sized hits together based
    on file size.

    The key of a hit is just its file size. The simkey of a key is a range
    of keys, represented by a tuple containing a lower bound and an upper
    bound.
    """

    def general_description(self):
        return u'Similarly sized'

    def description_for(self, hitsgroup):
        lo, hi = hitsgroup.simkey
        to_MB = 1048576.0
        return u'The size of these items ranges from %.0f MB to %.0f MB' % (lo / to_MB, hi / to_MB)

    def key(self, hit, context_state):
        return hit.length

    def simkey(self, key, context_state):
        SIZE_FRAC = 0.10
        center = key
        r = int(round(center * SIZE_FRAC))
        interval = (center - r, center + r)
        return interval

    class Index(GroupingAlgorithm.Index):

        """
        The SizeGrouping's index datastructure is backed by an interval tree
        for storing intervals and quick lookups. In order to speed up the
        common {__contains__;__getitem__} pattern, it prevents duplicate
        IntervalTree.find_first calls by caching the most recent call.
        """
        __slots__ = ['itree', 'cached_contains']

        def __init__(self):
            self.itree = IntervalTree()
            # cache for {__contains__; __getitem__} pattern:
            self.cached_contains = (None, None)

        def __contains__(self, key):
            node = self.itree.find_first(key)
            self.cached_contains = (key, node)
            return node is not None

        def __getitem__(self, key):
            k, n = self.cached_contains
            if key == k and n is not None:
                return n.group
            else:
                return self.itree.find_first(key).group

        def __setitem__(self, simkey, group):
            node = self.itree.insert(simkey, return_node=True)
            node.group = group


# TrieNode and LevenshteinTrie are based on public domain code,
# available at: http://stevehanov.ca/blog/index.php?id=114
class TrieNode(object):
    __slots__ = ['word', 'children']

    def __init__(self):
        self.word = None
        self.children = {}

    def insert(self, word):
        node = self
        for letter in word:
            if letter not in node.children:
                node.children[letter] = TrieNode()

            node = node.children[letter]

        node.word = word

    def width(self, level=0):
        if level:
            return max(1, sum(t.width(level - 1) for t in self.children.itervalues()))
        else:
            return 1

LOG_COSTS = False
LOG_DEPTH = False


class LevenshteinTrie(object):
    if LOG_COSTS:
        __slots__ = ['root', 'MAX_LEN', 'matrix', '_costs']
    else:
        __slots__ = ['root', 'MAX_LEN', 'matrix']

    def __init__(self, MAX_LEN=100):
        self.root = TrieNode()
        self.MAX_LEN = MAX_LEN

        first_row = [0]
        for j in xrange(MAX_LEN):
            first_row.append(first_row[j] + self._dynamic_penalty(j))

        matrix = [first_row]

        for i in xrange(MAX_LEN):
            # first column == dynamic penalty
            row = [matrix[i][0] + self._dynamic_penalty(i + 1)] + [0] * MAX_LEN
            matrix.append(row)

        self.matrix = matrix

    def add_word(self, word):
        self.root.insert(word[:self.MAX_LEN])

    def search(self, word, max_cost):
        word = word[:self.MAX_LEN]
        results = []

        if LOG_COSTS:
            self._costs = []

        for letter in self.root.children:
            self.do_search(self.root.children[letter], letter, word, 1, results, max_cost)

        if LOG_COSTS and len(self._costs) > 1:
            _logfh = open('bundle_lev_costs.txt', 'a')

            _logfh.write(repr(word) + '\n')
            _logfh.write('-' * 76 + '\n')

            for r, c in zip(results, self._costs):
                if c != 0:
                    _logfh.write('%s \t # %s\n' % (c, repr(r)))

            _logfh.write('\n\n')
            _logfh.close()

        return results

    def do_search(self, node, letter, word, row_index, results, max_cost):
        previous_row = self.matrix[row_index - 1]
        current_row = self.matrix[row_index]

        columns = len(word) + 1
        for column in xrange(1, columns):
            penalty = self._dynamic_penalty(max(row_index, column))

            insert_cost = current_row[column - 1] + penalty
            delete_cost = previous_row[column] + penalty

            if word[column - 1] != letter:
                replace_cost = previous_row[column - 1] + penalty
            else:
                replace_cost = previous_row[column - 1]

            current_row[column] = min(insert_cost, delete_cost, replace_cost)

        if current_row[columns - 1] <= max_cost and node.word is not None:
            # results.append( (node.word, current_row[columns-1]) )
            if LOG_COSTS:
                self._costs.append(current_row[columns - 1])
            results.append(node.word)

        if min(islice(current_row, columns)) <= max_cost:
            for letter in node.children:
                self.do_search(node.children[letter], letter, word, row_index + 1, results, max_cost)
        elif LOG_DEPTH:
            _logfh = open('bundle_lev_depth.txt', 'a')
            _logfh.write(repr(row_index))
            _logfh.close()

    def _dynamic_penalty(self, i):
        if i > 2:
            return 1.0 / (i - 1)
        return 1.0


class LevenshteinTrie_Cached(object):

    """
    LevenshteinTrie_Cached is a caching front-end for the LevenshteinTrie
    datastructure. It caches all calls to the search method.

    Calls to add_word, however, possibly invalidate the cache and it is
    imperative that after a series of add_word calls, you must invoke
    the update_cache method before invoking the search method.
    """

    __slots__ = ['cache', 'last_max_cost', 'levtrie', 'new_words']

    def __init__(self, MAX_LEN=100):
        self.levtrie = LevenshteinTrie(MAX_LEN=MAX_LEN)
        self.cache = {}  # word -> similar words
        self.last_max_cost = None
        self.new_words = set()

    def add_word(self, word):
        self.levtrie.add_word(word)
        self.new_words.add(word)

    def update_cache(self, new_words):
        if self.last_max_cost is None:
            return

        new_words = frozenset(new_words)
        cache_keys = frozenset(self.cache.iterkeys())
        processed_words = set()
        for word in new_words:
            if word not in processed_words:
                similar_words = set(self.search(word, self.last_max_cost))
                similar_new_words = new_words.intersection(similar_words)
                for cache_key in cache_keys.intersection(similar_words):
                    self.cache[cache_key].extend(similar_new_words)

                processed_words.update(similar_new_words)

    def search(self, word, max_cost):
        if self.last_max_cost == max_cost and self.new_words and word in self.cache:
            return self.cache[word]
        else:
            res = self.levtrie.search(word, max_cost)
            self.last_max_cost = max_cost
            self.cache[word] = res
            return res


# IntervalTree based on description available at
# http://en.wikipedia.org/wiki/Interval_tree#Augmented_tree
class IntervalTree:

    def __init__(self):
        self.root = None

    def insert(self, interval, return_node=False):
        # interval is a tuple
        self.root, new_node = IntervalTree.do_insert(self.root, interval)
        if return_node:
            return new_node

    @staticmethod
    def do_insert(node, interval):
        if node is None:
            node = new_node = IntervalTree.Node(interval)
        else:
            r = cmp(interval[0], node.interval[0])
            if r < 0:
                node.left, new_node = IntervalTree.do_insert(node.left, interval)
                child_max = node.left.max
            else:
                node.right, new_node = IntervalTree.do_insert(node.right, interval)
                child_max = node.right.max

            node.max = max(node.max, child_max)

        return node, new_node

    def find_first(self, point):
        # returns a Node
        return IntervalTree.do_find_first(self.root, point)

    @staticmethod
    def do_find_first(node, point):
        if node is not None:
            if node.contains(point):
                return node
            elif point < node.interval[0]:
                return IntervalTree.do_find_first(node.left, point)
            else:
                if node.left and point <= node.left.max:
                    return IntervalTree.do_find_first(node.left, point)
                else:
                    return IntervalTree.do_find_first(node.right, point)

        return None

    if DEBUG:
        def as_dict(self):
            return IntervalTree.do_as_dict(self.root)

        @staticmethod
        def do_as_dict(node):
            if node is None:
                return None
            else:
                return dict(
                    interval=node.interval,
                    left=IntervalTree.do_as_dict(node.left),
                    right=IntervalTree.do_as_dict(node.right),
                )

    class Node:

        def __init__(self, interval):
            self.left = None
            self.right = None

            self.interval = interval
            self.max = interval[1]

        def contains(self, point):
            a, b = self.interval
            return a <= point <= b


class Bundler:

    """
    The Bundler class is a facade to the various grouping classes. Its main exposed
    operation is to bundle a ranked list of hits according to a chosen algorithm.

    A Bundler instance holds on to previously created GroupsList to speed up the
    creation of newer GroupsLists.
    """

    GROUP_TOP_N = 2000  # None = all
    MAX_BUNDLES = 50

    GC_ROUNDS = 2  # Number of rounds after which a garbage collection phase starts

    # DO NOT CHANGE THE ORDER, STORED IN DB
    ALG_NUMBERS, ALG_NAME, ALG_SIZE, ALG_OFF, ALG_MAGIC, ALG_CATEGORY = range(6)
    algorithms = [IntGrouping(), LevGrouping(), SizeGrouping(), None, None, CategoryGrouping()]

    # Tag these instances with their code:
    for i, algorithm in enumerate(algorithms):
        if algorithm is not None:
            algorithm.ALG_CODE = i

    PRINTABLE_ALG_CONSTANTS = 'ALG_NUMBERS ALG_NAME ALG_SIZE ALG_OFF ALG_MAGIC ALG_CATEGORY'.split()

    # ALG_MAGIC CONSTANTS
    MIN_LEVTRIE_WIDTH = 50
    LEVTRIE_DEPTH = 2
    REDUCTION_THRESHOLD = 0.8
    REDUCTION_MAX_RESULTS = 100

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.clear()

    def clear(self):
        self.previous_query = None
        self.previous_groups = {}  # bundle_mode -> GroupsList
        self.number_of_calls = 0

    def _benchmark_start(self):
        self._benchmark_ts = time.time()

    def _benchmark_end(self):
        self._logger.debug('>> Bundler.py, benchmark: %s s', time.time() - self._benchmark_ts)

    def bundle(self, hits, bundle_mode, searchkeywords):
        """
        Bundles a ranked list of hits using a selected algorithm. A bundle
        is a dict containing an identifier for the bundle (key),
        two descriptions (bundle_description, bundle_general_description)
        and the bundle (bundle) itself.

        @param hits A ranked list of hits.
        @param bundle_mode The algorithm, selected by one of the
        Bundle.ALG_* constants.
        @param searchkeywords The search keywords used to retrieve
        the list of hits.
        @return A list containing hits and bundles and the actual applied bundle mode.
        """
        bundled_hits = None
        selected_bundle_mode = bundle_mode

        if bundle_mode in [Bundler.ALG_OFF, None] or len(hits) == 0:
            selected_bundle_mode = Bundler.ALG_OFF
            bundled_hits = hits

        else:
            query = ' '.join(searchkeywords)
            if self.previous_query != query:
                self.previous_groups = {}
                self.previous_query = query

            if Bundler.GROUP_TOP_N is not None:
                hits1, hits2 = hits[:Bundler.GROUP_TOP_N], hits[Bundler.GROUP_TOP_N:]
            else:
                hits1 = hits
                hits2 = []

            if bundle_mode == Bundler.ALG_MAGIC:
                success = False

                # try ALG_NAME
                selected_bundle_mode = Bundler.ALG_NAME
                algorithm = Bundler.algorithms[selected_bundle_mode]

                grouped_hits = GroupsList(query, algorithm, hits1,
                                          self.previous_groups.get(selected_bundle_mode, None),
                                          Bundler.MAX_BUNDLES, two_step=True)

                levtrie_root = grouped_hits.context_state.levtrie.root
                levtrie_width = levtrie_root.width(level=Bundler.LEVTRIE_DEPTH)
                self._logger.debug('>> Bundler.py MAGIC: levtrie_width = %s (depth %s)', levtrie_width, Bundler.LEVTRIE_DEPTH)
                self._logger.debug('>> Bundler.py MAGIC: levtrie_width = %s (depth 2)', levtrie_root.width(2))
                self._logger.debug('>> Bundler.py MAGIC: rel_levtrie_width = %s (depth 2)', levtrie_root.width(2) / (len(hits1) * 1.0))

                if levtrie_width >= Bundler.MIN_LEVTRIE_WIDTH:
                    grouped_hits.finalize()
                    self.previous_groups[selected_bundle_mode] = grouped_hits
                    bundled_hits = self._convert_groupslist(grouped_hits, algorithm, hits2)
                    success = True

                # try ALG_SIZE
                if not success:
                    selected_bundle_mode = Bundler.ALG_SIZE
                    bundled_hits, _ = self.bundle(hits, selected_bundle_mode, searchkeywords)

                    reduction = float(len(hits1) - len(bundled_hits) + 1) / len(hits1)
                    success = reduction < Bundler.REDUCTION_THRESHOLD

                # try ALG_NUMBERS
                if not success:
                    selected_bundle_mode = Bundler.ALG_NUMBERS
                    bundled_hits, _ = self.bundle(hits, selected_bundle_mode, searchkeywords)

                # FAILURE => OFF
                if bundled_hits:
                    reduction = float(len(hits1) - len(bundled_hits) + 1) / len(hits1)
                    if len(bundled_hits) < Bundler.REDUCTION_MAX_RESULTS and reduction >= Bundler.REDUCTION_THRESHOLD:
                        self._logger.debug('>> Bundler.py MAGIC: FAILURE; %0.2f reduction rate using %s', reduction, Bundler.PRINTABLE_ALG_CONSTANTS[selected_bundle_mode])
                        selected_bundle_mode = Bundler.ALG_OFF
                        bundled_hits = hits

                # FALLBACK => OFF
                elif not success:
                    self._logger.debug('>> Bundler.py MAGIC: FALLBACK')
                    selected_bundle_mode = Bundler.ALG_OFF
                    bundled_hits = hits

            else:
                algorithm = Bundler.algorithms[bundle_mode]

                self._benchmark_start()
                grouped_hits = GroupsList(query, algorithm, hits1,
                                          self.previous_groups.get(bundle_mode, None),
                                          Bundler.MAX_BUNDLES)
                self._benchmark_end()

                self.previous_groups[bundle_mode] = grouped_hits
                bundled_hits = self._convert_groupslist(grouped_hits, algorithm, hits2)

            self.number_of_calls += 1
            if self.number_of_calls >= Bundler.GC_ROUNDS:
                self.__gc()
                self.number_of_calls = 0

        return bundled_hits, selected_bundle_mode

    def _convert_groupslist(self, groupslist, algorithm, suffix=[]):
        res = []
        for group in groupslist.groups:
            if len(group) > 1:
                d = dict(key='Group%05d' % group.id,
                         bundle=list(group),
                         bundle_description=algorithm.description_for(group),
                         bundle_general_description=algorithm.general_description(),
                         bundle_algorithm=algorithm.ALG_CODE)

                if group.has_changed():
                    d['bundle_changed'] = True

                # Copy channel from head to bundle-dict
                head = group[0]
                d['channel'] = head.get('channel')
                d['length'] = head.get('length')
                res.append(d)
            else:
                res.append(group[0])

        res.extend(suffix)
        return res

    def __gc(self):
        # GC is rather simple. Just cut the links to old versions
        self._logger.debug('>> Bundler.py, garbage collecting...')

        for groupslist in self.previous_groups.itervalues():
            groupslist.prev_grouplist = None
            for group in groupslist.groups:
                group.prev_group = None


if USE_PSYCO:
    # can we use psyco in Tribler? It's only available up to Py2.6!
    import psyco
    psyco.bind(TrieNode)
    psyco.bind(LevenshteinTrie)
    psyco.bind(LevenshteinTrie_Cached)

    # Can give speedups up to 3x

########NEW FILE########
__FILENAME__ = Reranking
# written by Nicolas Neubauer
# see LICENSE.txt for license information

import time
import logging


class Reranker:

    def getID(self):
        """the ID that is stored in the clicklog 'reranking_strategy' field for later comparison"""
        return 0

    def rerank(self, hits, keywords, torrent_db, pref_db, mypref_db, search_db):
        """takes hits and reorders them given the current keywords"""
        return hits


class DefaultTorrentReranker(Reranker):

    """ just leave the hits alone """
    def getID(self):
        return 1

    def rerank(self, hits, keywords, torrent_db, pref_db, mypref_db, search_db):
        return hits


class TestReranker(Reranker):

    """ for testing purposes only """
    def getID(self):
        return 2

    def rerank(self, hits, keywords, torrent_db, pref_db, mypref_db, search_db):
        if len(hits) > 1:
            h = hits[0]
            hits[0] = hits[1]
            hits[1] = h
        return hits


class SwapFirstTwoReranker(Reranker):

    """ swaps first and second place if second place has been frequently selected from bad position """

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.MAX_SEEN_BEFORE_RERANK = 5
        self.MAX_POPULAR_RATIO = 5

    def getID(self):
        return 2

    def rerank(self, hits, keywords, torrent_db, pref_db, mypref_db, search_db):
        if len(hits) < 2:
            return hits

        torrent_id_0 = hits[0].get('torrent_id', None)
        torrent_id_1 = hits[1].get('torrent_id', None)
        if not torrent_id_0 or not torrent_id_1:
            self._logger.debug("reranking: torrent_id=0 in hits, exiting")
            # we got some problems elsewhere, don't add to it
            return hits

        (num_hits_0, position_score_0) = pref_db.getPositionScore(torrent_id_0, keywords)
        (num_hits_1, position_score_1) = pref_db.getPositionScore(torrent_id_1, keywords)
        self._logger.debug("reranking:  first torrent (%d): (num, score)= (%s, %s)", torrent_id_0, num_hits_0, position_score_0)
        self._logger.debug("reranking: second torrent (%d): (num, score)= (%s, %s)", torrent_id_1, num_hits_1, position_score_1)

        if (num_hits_0 < self.MAX_SEEN_BEFORE_RERANK or num_hits_1 < self.MAX_SEEN_BEFORE_RERANK):
            # only start thinking about reranking if we have seen enough samples
            self._logger.debug("reranking: not enough samples, not reranking")
            return hits

        if (num_hits_0 / num_hits_1 > self.MAX_POPULAR_RATIO):
            # if number one is much more popular, keep everything as it is
            self._logger.debug("reranking: first torrent is too popular, not reranking")
            return hits

        # if all these tests are successful, we may swap first and second if second
        # has gotten hits from worse positions than first

        if position_score_0 < position_score_1:
            self._logger.debug("reranking: second torrent has better position score, reranking!")
            h = hits[0]
            hits[0] = hits[1]
            hits[1] = h
        else:
            self._logger.debug("reranking: second torrent does not have better position score, reranking!")

        return hits

_rerankers = [DefaultTorrentReranker(), SwapFirstTwoReranker()]


def getTorrentReranker():
    global _rerankers
    index = int(time.strftime("%H")) % (len(_rerankers))
    return _rerankers[index]

########NEW FILE########
__FILENAME__ = SearchManager
# Written by Jelle Roozenburg, Arno Bakker
# see LICENSE.txt for license information

# ARNOCOMMENT: remove this now it doesn't use KeywordSearch anymore?

import re
import logging

# from Tribler.Core.Search.KeywordSearch import KeywordSearch

re_keywordsplit = re.compile(r"[\W_]", re.UNICODE)
dialog_stopwords = set(['an', 'and', 'by', 'for', 'from', 'of', 'the', 'to', 'with'])


def split_into_keywords(string, filterStopwords=False):
    """
    Takes a (unicode) string and returns a list of (unicode) lowercase
    strings.  No empty strings are returned.

    We currently split on non-alphanumeric characters and the
    underscore.

    If filterStopwords is True a small stopword filter is using to reduce the number of keywords
    """
    if filterStopwords:
        return [keyword for keyword in re_keywordsplit.split(string.lower()) if len(keyword) > 0 and keyword not in dialog_stopwords]

    return [keyword for keyword in re_keywordsplit.split(string.lower()) if len(keyword) > 0]


def filter_keywords(keywords):
    return [keyword for keyword in keywords if len(keyword) > 0 and keyword not in dialog_stopwords]


def fts3_preprocess(keywords):
    fts3_only = []
    normal_keywords = []

    keywords = keywords.split()
    for keyword in keywords:
        if keyword[0] == '-':
            fts3_only.append(keyword)
        elif keyword[0] == '*' or keyword[-1] == "*":
            fts3_only.append(keyword)
        elif keyword.find(':') != -1:
            fts3_only.append(keyword)
        else:
            normal_keywords.append(keyword)

    return fts3_only, " ".join(normal_keywords)


class SearchManager:

    """ Arno: This is DB neutral. All it assumes is a DBHandler with
    a searchNames() method that returns records with at least a 'name' field
    in them.
    """

    def __init__(self, dbhandler):
        self._logger = logging.getLogger(self.__class__.__name__)
        self.dbhandler = dbhandler
        # self.keywordsearch = KeywordSearch()

    def search(self, kws, maxhits=None):
        """ Called by any thread """
        self._logger.debug("SearchManager: search %s", kws)

        hits = self.dbhandler.searchNames(kws)
        if maxhits is None:
            return hits
        else:
            return hits[:maxhits]

    def searchLibrary(self):
        return self.dbhandler.getTorrents(sort="name", library= True)

    def searchChannels(self, query):
        data = self.dbhandler.searchChannels(query)
        return data

########NEW FILE########
__FILENAME__ = ServerPortHandler
# Written by John Hoffman
# see LICENSE.txt for license information

import logging
from cStringIO import StringIO
from Tribler.Core.MessageID import protocol_name

try:
    True
except:
    True = 1
    False = 0


default_task_id = []

class SingleRawServer:

    def __init__(self, info_hash, multihandler, doneflag, protocol):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.info_hash = info_hash
        self.doneflag = doneflag
        self.protocol = protocol
        self.multihandler = multihandler
        self.rawserver = multihandler.rawserver
        self.finished = False
        self.running = False
        self.handler = None
        self.taskqueue = []

    def shutdown(self):
        if not self.finished:
            self.multihandler.shutdown_torrent(self.info_hash)

    def _shutdown(self):
        self._logger.debug("SingleRawServer: _shutdown")
        if not self.finished:
            self.finished = True
            self.running = False
            self.rawserver.kill_tasks(self.info_hash)
            if self.handler:
                self.handler.close_all()

    def _external_connection_made(self, c, options, msg_remainder):
        self._logger.debug("SingleRawServer: _external_conn_made, running? %s", self.running)
        if self.running:
            c.set_handler(self.handler)
            self.handler.externally_handshaked_connection_made(
                c, options, msg_remainder)

    # RawServer functions ###

    def add_task(self, func, delay=0, id=default_task_id):
        if id is default_task_id:
            id = self.info_hash
        if not self.finished:
            self.rawserver.add_task(func, delay, id)

#    def bind(self, port, bind = '', reuse = False):
# pass    # not handled here

    def start_connection(self, dns, handler=None):
        if not handler:
            handler = self.handler
        c = self.rawserver.start_connection(dns, handler)
        return c

#    def listen_forever(self, handler):
# pass    # don't call with this

    def start_listening(self, handler):
        self.handler = handler    # Encoder
        self.running = True
        return self.shutdown    # obviously, doesn't listen forever

    def is_finished(self):
        return self.finished

    def get_exception_flag(self):
        return self.rawserver.get_exception_flag()


class NewSocketHandler:     # hand a new socket off where it belongs

    def __init__(self, multihandler, connection):    # connection: SingleSocket
        self._logger = logging.getLogger(self.__class__.__name__)

        self.multihandler = multihandler
        self.connection = connection
        connection.set_handler(self)
        self.closed = False
        self.buffer = StringIO()
        self.complete = False
        self.next_len, self.next_func = 1, self.read_header_len
        self.multihandler.rawserver.add_task(self._auto_close, 15)

    def _auto_close(self):
        if not self.complete:
            self.close()

    def close(self):
        if not self.closed:
            self.connection.close()
            self.closed = True

    # copied from Encrypter and modified

    def read_header_len(self, s):
        if s == 'G':
            self.protocol = 'HTTP'
            self.firstbyte = s
            self._logger.debug("NewSocketHandler: Got HTTP connection")
            return True
        else:
            l = ord(s)
            return l, self.read_header

    def read_header(self, s):
        self.protocol = s
        return 8, self.read_reserved

    def read_reserved(self, s):
        self.options = s
        return 20, self.read_download_id

    def read_download_id(self, s):
        self._logger.debug("NewSocketHandler: Swarm id is %s %s", s, self.connection.socket.getpeername())
        if s in self.multihandler.singlerawservers:
            if self.multihandler.singlerawservers[s].protocol == self.protocol:
                self._logger.debug("NewSocketHandler: Found rawserver for swarm id")
                return True
        self._logger.debug("NewSocketHandler: No rawserver found for swarm id %s", s)
        return None

    def read_dead(self, s):
        return None

    def data_came_in(self, garbage, s):
#        if DEBUG:
#            print "NewSocketHandler data came in", sha(s).hexdigest()
        while True:
            if self.closed:
                return
            i = self.next_len - self.buffer.tell()
            if i > len(s):
                self.buffer.write(s)
                return
            self.buffer.write(s[:i])
            s = s[i:]
            m = self.buffer.getvalue()
            self.buffer.reset()
            self.buffer.truncate()
            try:
                x = self.next_func(m)
            except:
                self.next_len, self.next_func = 1, self.read_dead
                raise
            if x is None:
                self._logger.debug("NewSocketHandler: %s returned None", self.next_func)
                self.close()
                return
            if x == True:       # ready to process
                if self.protocol == 'HTTP' and self.multihandler.httphandler:
                    self._logger.debug("NewSocketHandler: Reporting HTTP connection")
                    self.multihandler.httphandler.external_connection_made(self.connection)
                    self.multihandler.httphandler.data_came_in(self.connection, self.firstbyte)
                    self.multihandler.httphandler.data_came_in(self.connection, s)
                else:
                    self._logger.debug("NewSocketHandler: Reporting connection via %s", self.multihandler.singlerawservers[m]._external_connection_made)
                    self.multihandler.singlerawservers[m]._external_connection_made(self.connection, self.options, s)
                self.complete = True
                return
            self.next_len, self.next_func = x

    def connection_flushed(self, ss):
        pass

    def connection_lost(self, ss):
        self.closed = True


class MultiHandler:

    def __init__(self, rawserver, doneflag):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.rawserver = rawserver
        self.masterdoneflag = doneflag
        self.singlerawservers = {}
        self.connections = {}
        self.taskqueues = {}
        self.httphandler = None

    def newRawServer(self, info_hash, doneflag, protocol=protocol_name):
        new = SingleRawServer(info_hash, self, doneflag, protocol)
        self.singlerawservers[info_hash] = new
        return new

    def shutdown_torrent(self, info_hash):
        self._logger.debug("MultiHandler: shutdown_torrent %s", info_hash)
        self.singlerawservers[info_hash]._shutdown()
        del self.singlerawservers[info_hash]

    def listen_forever(self):
        self._logger.debug("MultiHandler: listen_forever()")
        self.rawserver.listen_forever(self)
        for srs in self.singlerawservers.values():
            srs.finished = True
            srs.running = False
            srs.doneflag.set()

    def set_httphandler(self, httphandler):
        self.httphandler = httphandler

    # RawServer handler functions ###
    # be wary of name collisions

    def external_connection_made(self, ss):
        # ss: SingleSocket
        NewSocketHandler(self, ss)

########NEW FILE########
__FILENAME__ = Session
# Written by Arno Bakker
# Updated by George Milescu
# see LICENSE.txt for license information
""" A Session is a running instance of the Tribler Core and the Core's central class. """
import copy
import logging
import os
import socket
import sys

from Tribler.Core import NoDispersyRLock
from Tribler.Core.APIImplementation.LaunchManyCore import TriblerLaunchMany
from Tribler.Core.APIImplementation.UserCallbackHandler import UserCallbackHandler
from Tribler.Core.SessionConfig import SessionConfigInterface, SessionStartupConfig
from Tribler.Core.exceptions import NotYetImplementedException, OperationNotEnabledByConfigurationException
from Tribler.Core.osutils import get_appstate_dir
from Tribler.Core.simpledefs import (STATEDIR_TORRENTCOLL_DIR, STATEDIR_PEERICON_DIR, STATEDIR_DLPSTATE_DIR,
                                     STATEDIR_SWIFTRESEED_DIR, STATEDIR_SESSCONFIG, NTFY_MISC, NTFY_PEERS,
                                     NTFY_TORRENTS, NTFY_MYPREFERENCES, NTFY_VOTECAST, NTFY_CHANNELCAST, NTFY_UPDATE,
                                     NTFY_INSERT, NTFY_DELETE, NTFY_METADATA)

GOTM2CRYPTO = False
try:
    import M2Crypto
    import Tribler.Core.permid as permidmod
    GOTM2CRYPTO = True
except ImportError:
    pass


class Session(SessionConfigInterface):

    """

    A Session is a running instance of the Tribler Core and the Core's central
    class. It implements the SessionConfigInterface which can be used to change
    session parameters at runtime (for selected parameters).

    cf. libtorrent session
    """
    __single = None

    def __init__(self, scfg=None, ignore_singleton=False):
        """
        A Session object is created which is configured following a copy of the
        SessionStartupConfig scfg. (copy constructor used internally)

        @param scfg SessionStartupConfig object or None, in which case we
        look for a saved session in the default location (state dir). If
        we can't find it, we create a new SessionStartupConfig() object to
        serve as startup config. Next, the config is saved in the directory
        indicated by its 'state_dir' attribute.

        In the current implementation only a single session instance can exist
        at a time in a process. The ignore_singleton flag is used for testing.
        """
        if not ignore_singleton:
            if Session.__single:
                raise RuntimeError("Session is singleton")
            Session.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        self.ignore_singleton = ignore_singleton
        self.sesslock = NoDispersyRLock()

        # Determine startup config to use
        if scfg is None:  # If no override
            try:
                # Then try to read from default location
                state_dir = Session.get_default_state_dir()
                cfgfilename = Session.get_default_config_filename(state_dir)
                scfg = SessionStartupConfig.load(cfgfilename)
            except:
                # If that fails, create a fresh config with factory defaults
                self._logger.exception(u"Failed to init startup config")
                scfg = SessionStartupConfig()
        else:  # overrides any saved config
            # Work from copy
            scfg = SessionStartupConfig(copy.copy(scfg.sessconfig))

        def create_dir(fullpath):
            if not os.path.isdir(fullpath):
                os.makedirs(fullpath)

        def set_and_create_dir(dirname, setter, default_dir):
            if dirname is None:
                setter(default_dir)
            create_dir(dirname or default_dir)

        set_and_create_dir(scfg.get_state_dir(), scfg.set_state_dir, Session.get_default_state_dir())
        set_and_create_dir(scfg.get_torrent_collecting_dir(), scfg.set_torrent_collecting_dir, os.path.join(scfg.get_state_dir(), STATEDIR_TORRENTCOLL_DIR))
        set_and_create_dir(scfg.get_swift_meta_dir(), scfg.set_swift_meta_dir, os.path.join(scfg.get_state_dir(), STATEDIR_SWIFTRESEED_DIR))
        set_and_create_dir(scfg.get_peer_icon_path(), scfg.set_peer_icon_path, os.path.join(scfg.get_state_dir(), STATEDIR_PEERICON_DIR))

        create_dir(os.path.join(scfg.get_state_dir(), STATEDIR_DLPSTATE_DIR))

        if scfg.get_nickname() == '__default_name__':
            scfg.set_nickname(socket.gethostname())

        # SWIFTPROC
        if scfg.get_swift_path() is None:
            if sys.platform == "win32":
                scfg.set_swift_path(os.path.join(scfg.get_install_dir(), "swift.exe"))
            else:
                scfg.set_swift_path(os.path.join(scfg.get_install_dir(), "swift"))

        if GOTM2CRYPTO:
            permidmod.init()
            # Set params that depend on state_dir
            #
            # 1. keypair
            #
            pairfilename = os.path.join(scfg.get_state_dir(), 'ec.pem')
            if scfg.get_permid_keypair_filename() is None:
                scfg.set_permid_keypair_filename(pairfilename)

            if os.access(scfg.get_permid_keypair_filename(), os.F_OK):
                # May throw exceptions
                self.keypair = permidmod.read_keypair(scfg.get_permid_keypair_filename())
            else:
                self.keypair = permidmod.generate_keypair()

                # Save keypair
                pubfilename = os.path.join(scfg.get_state_dir(), 'ecpub.pem')
                permidmod.save_keypair(self.keypair, pairfilename)
                permidmod.save_pub_key(self.keypair, pubfilename)

        if not scfg.get_megacache():
            scfg.set_torrent_checking(0)

        self.sessconfig = scfg.sessconfig
        self.sessconfig.lock = self.sesslock

        self.selected_ports = scfg.selected_ports

        # Checkpoint startup config
        self.save_pstate_sessconfig()

    #
    # Class methods
    #
    def get_instance(*args, **kw):
        """ Returns the Session singleton if it exists or otherwise
            creates it first, in which case you need to pass the constructor
            params.
            @return Session."""
        if Session.__single is None:
            Session(*args, **kw)
        return Session.__single
    get_instance = staticmethod(get_instance)

    def has_instance():
        return Session.__single != None
    has_instance = staticmethod(has_instance)

    def del_instance():
        Session.__single = None
    del_instance = staticmethod(del_instance)

    def get_default_state_dir(homedirpostfix='.Tribler'):
        """ Returns the factory default directory for storing session state
        on the current platform (Win32,Mac,Unix).
        @return An absolute path name. """

        # Allow override
        statedirvar = '${TSTATEDIR}'
        statedir = os.path.expandvars(statedirvar)
        if statedir and statedir != statedirvar:
            return statedir

        if os.path.isdir(homedirpostfix):
            return os.path.abspath(homedirpostfix)

        appdir = get_appstate_dir()
        statedir = os.path.join(appdir, homedirpostfix)
        return statedir

    get_default_state_dir = staticmethod(get_default_state_dir)

    #
    # Public methods
    #
    def start_download(self, cdef, dcfg=None, initialdlstatus=None, hidden=False):
        """
        Creates a Download object and adds it to the session. The passed
        ContentDef and DownloadStartupConfig are copied into the new Download
        object. The Download is then started and checkpointed.

        If a checkpointed version of the Download is found, that is restarted
        overriding the saved DownloadStartupConfig if "dcfg" is not None.

        @param cdef  A finalized TorrentDef or a SwiftDef
        @param dcfg DownloadStartupConfig or None, in which case
        a new DownloadStartupConfig() is created with its default settings
        and the result becomes the runtime config of this Download.
        @param initialdlstatus The initial download status of this Download
        or None. This enables the caller to create a Download in e.g.
        DLSTATUS_STOPPED state instead.
        @param hidden Whether this torrent should be added to the mypreference table
        @return Download
        """
        # locking by lm
        if cdef.get_def_type() == "torrent":
            return self.lm.add(cdef, dcfg, initialdlstatus=initialdlstatus, hidden=hidden)
        else:
            # SWIFTPROC
            return self.lm.swift_add(cdef, dcfg, initialdlstatus=initialdlstatus, hidden=hidden)

    def resume_download_from_file(self, filename):
        """
        Recreates Download from resume file

        @return a Download object.

        Note: this cannot be made into a method of Download, as the Download
        needs to be bound to a session, it cannot exist independently.
        """
        raise NotYetImplementedException()

    def get_downloads(self):
        """
        Returns a copy of the list of Downloads.
        @return A list of Download objects.
        """
        # locking by lm
        return self.lm.get_downloads()

    def get_download(self, hash):
        """
        Returns the Download object for this hash.
        @return A Donwload Object.
        """
        # locking by lm
        return self.lm.get_download(hash)

    def remove_download(self, d, removecontent=False, removestate=True, hidden=False):
        """
        Stops the download and removes it from the session.
        @param d The Download to remove
        @param removecontent Whether to delete the already downloaded content
        from disk.
        @param removestate    Whether to delete the metadata files of the downloaded
        content from disk.
        @param hidden Whether this torrent is added to the mypreference table and this entry should be
        removed
        """
        # locking by lm
        if d.get_def().get_def_type() == "torrent":
            self.lm.remove(d, removecontent=removecontent, removestate=removestate, hidden=hidden)
        else:
            # SWIFTPROC
            self.lm.swift_remove(d, removecontent=removecontent, removestate=removestate, hidden=hidden)

    def remove_download_by_id(self, id, removecontent=False, removestate=True):
        """
        @param infohash The Download to remove
        @param removecontent Whether to delete the already downloaded content
        from disk.

        !We can only remove content when the download object is found, otherwise only
        the state is removed.
        """
        downloadList = self.get_downloads()
        for download in downloadList:
            if download.get_def().get_id() == id:
                self.remove_download(download, removecontent, removestate)
                return

        self.lm.remove_id(id)
        self.uch.perform_removestate_callback(id, [])

    def set_download_states_callback(self, usercallback, getpeerlist=None):
        """
        See Download.set_state_callback. Calls usercallback with a list of
        DownloadStates, one for each Download in the Session as first argument.
        The usercallback must return a tuple (when,getpeerlist) that indicates
        when to reinvoke the callback again (as a number of seconds from now,
        or < 0.0 if not at all) and whether to also include the details of
        the connected peers in the DownloadStates on that next call.

        The callback will be called by a popup thread which can be used
        indefinitely (within reason) by the higher level code.

        @param usercallback A function adhering to the above spec.
        """
        self.lm.set_download_states_callback(usercallback, getpeerlist or [])

    #
    # Config parameters that only exist at runtime
    #
    def get_permid(self):
        """ Returns the PermID of the Session, as determined by the
        SessionConfig.set_permid() parameter. A PermID is a public key
        @return The PermID encoded in a string in DER format. """
        self.sesslock.acquire()
        try:
            return str(self.keypair.pub().get_der())
        finally:
            self.sesslock.release()

    def get_external_ip(self):
        """ Returns the external IP address of this Session, i.e., by which
        it is reachable from the Internet. This address is determined by libtorrent.
        @return A string. """
        return self.lm.get_external_ip()

    def get_externally_reachable(self):
        """ Returns whether the Session is externally reachable, i.e., its
          listen port is not firewalled. Use add_observer() with NTFY_REACHABLE
          to register to the event of detecting reachablility. Note that due to
          the use of UPnP a Session may become reachable some time after
          startup and due to the Dialback mechanism, this method may return
          False while the Session is actually already reachable. Note that True
          doesn't mean the Session is reachable from the open Internet, could just
          be from the local (otherwise firewalled) LAN.
          @return A boolean. """

        # Arno, LICHT: make it throw exception when used in LITE versie.
        raise NotYetImplementedException()

    def get_current_startup_config_copy(self):
        """ Returns a SessionStartupConfig that is a copy of the current runtime
        SessionConfig.
        @return SessionStartupConfig
        """
        # Called by any thread
        self.sesslock.acquire()
        try:
            sessconfig = copy.copy(self.sessconfig)
            sessconfig.set_callback(None)
            return SessionStartupConfig(sessconfig=sessconfig)
        finally:
            self.sesslock.release()

    #
    # Notification of events in the Session
    #
    def add_observer(self, func, subject, changeTypes=[NTFY_UPDATE, NTFY_INSERT, NTFY_DELETE], objectID=None, cache=0):
        """ Add an observer function function to the Session. The observer
        function will be called when one of the specified events (changeTypes)
        occurs on the specified subject.

        The function will be called by a popup thread which can be used
        indefinitely (within reason) by the higher level code.

        @param func The observer function. It should accept as its first argument
        the subject, as second argument the changeType, as third argument an
        objectID (e.g. the primary key in the observed database) and an
        optional list of arguments.
        @param subject The subject to observe, one of NTFY_* subjects (see
        simpledefs).
        @param changeTypes The list of events to be notified of one of NTFY_*
        events.
        @param objectID The specific object in the subject to monitor (e.g. a
        specific primary key in a database to monitor for updates.)
        @param cache The time to bundle/cache events matching this function

        TODO: Jelle will add per-subject/event description here ;o)

        """
        # Called by any thread
        self.uch.notifier.add_observer(func, subject, changeTypes, objectID, cache=cache)  # already threadsafe

    def remove_observer(self, func):
        """ Remove observer function. No more callbacks will be made.
        @param func The observer function to remove. """
        # Called by any thread
        self.uch.notifier.remove_observer(func)  # already threadsafe

    def open_dbhandler(self, subject):
        """ Opens a connection to the specified database. Only the thread
        calling this method may use this connection. The connection must be
        closed with close_dbhandler() when this thread exits.

        @param subject The database to open. Must be one of the subjects
        specified here.
        @return A reference to a DBHandler class for the specified subject or
        None when the Session was not started with megacaches enabled.
        <pre> NTFY_PEERS -> PeerDBHandler
        NTFY_TORRENTS -> TorrentDBHandler
        NTFY_MYPREFERENCES -> MyPreferenceDBHandler
        NTFY_VOTECAST -> VotecastDBHandler
        NTFY_CHANNELCAST -> ChannelCastDBHandler
        </pre>
        """
        if not self.get_megacache():
            raise OperationNotEnabledByConfigurationException()

        # Called by any thread
        self.sesslock.acquire()
        try:
            if subject == NTFY_MISC:
                return self.lm.misc_db
            elif subject == NTFY_METADATA:
                return self.lm.metadata_db
            elif subject == NTFY_PEERS:
                return self.lm.peer_db
            elif subject == NTFY_TORRENTS:
                return self.lm.torrent_db
            elif subject == NTFY_MYPREFERENCES:
                return self.lm.mypref_db
            elif subject == NTFY_VOTECAST:
                return self.lm.votecast_db
            elif subject == NTFY_CHANNELCAST:
                return self.lm.channelcast_db
            else:
                raise ValueError('Cannot open DB subject: ' + subject)
        finally:
            self.sesslock.release()

    def close_dbhandler(self, dbhandler):
        """ Closes the given database connection """
        dbhandler.close()

    #
    # Persistence and shutdown
    #
    def load_checkpoint(self, initialdlstatus=None, initialdlstatus_dict={}):
        """ Restart Downloads from checkpoint, if any.

        This method allows the API user to manage restoring downloads.
        E.g. a video player that wants to start the torrent the user clicked
        on first, and only then restart any sleeping torrents (e.g. seeding).
        The optional initialdlstatus parameter can be set to DLSTATUS_STOPPED
        to restore all the Downloads in DLSTATUS_STOPPED state.
        The options initialdlstatus_dict parameter can be used to specify a
        state overriding the initaldlstatus parameter per download id.
        """
        self.lm.load_checkpoint(initialdlstatus, initialdlstatus_dict)

    def checkpoint(self):
        """ Saves the internal session state to the Session's state dir. """
        # Called by any thread
        self.checkpoint_shutdown(stop=False, checkpoint=True, gracetime=None, hacksessconfcheckpoint=False)

    def start(self):
        """ Create the LaunchManyCore instance and start it"""

        # Create handler for calling back the user via separate threads
        self.uch = UserCallbackHandler(self)

        # Create engine with network thread
        self.lm = TriblerLaunchMany()
        self.lm.register(self, self.sesslock)
        self.lm.start()

        self.sessconfig.set_callback(self.lm.sessconfig_changed_callback)

    def shutdown(self, checkpoint=True, gracetime=2.0, hacksessconfcheckpoint=True):
        """ Checkpoints the session and closes it, stopping the download engine.
        @param checkpoint Whether to checkpoint the Session state on shutdown.
        @param gracetime Time to allow for graceful shutdown + signoff (seconds).
        """
        # Called by any thread
        self.lm.early_shutdown()
        self.checkpoint_shutdown(stop=True, checkpoint=checkpoint, gracetime=gracetime, hacksessconfcheckpoint=hacksessconfcheckpoint)
        # Arno, 2010-08-09: now shutdown after gracetime
        self.uch.shutdown()

    def has_shutdown(self):
        """ Whether the Session has completely shutdown, i.e., its internal
        threads are finished and it is safe to quit the process the Session
        is running in.
        @return A Boolean.
        """
        return self.lm.sessdoneflag.isSet()

    def get_downloads_pstate_dir(self):
        """ Returns the directory in which to checkpoint the Downloads in this
        Session. """
        # Called by network thread
        self.sesslock.acquire()
        try:
            return os.path.join(self.get_state_dir(), STATEDIR_DLPSTATE_DIR)
        finally:
            self.sesslock.release()

    def download_torrentfile(self, infohash=None, roothash=None, usercallback=None, prio=0):
        """ Try to download the torrentfile without a known source.
        A possible source could be the DHT.
        If the torrent is succesfully
        received, the usercallback method is called with the infohash as first
        and the contents of the torrentfile (bencoded dict) as second parameter.
        If the torrent could not be obtained, the callback is not called.
        The torrent will have been added to the TorrentDBHandler (if enabled)
        at the time of the call.
        @param infohash The infohash of the torrent.
        @param usercallback A function adhering to the above spec.
        """
        if not self.lm.rtorrent_handler:
            raise OperationNotEnabledByConfigurationException()

        self.lm.rtorrent_handler.download_torrent(None, infohash, roothash, usercallback, prio)

    def download_torrentfile_from_peer(self, candidate, infohash=None, roothash=None, usercallback=None, prio=0):
        """ Ask the designated peer to send us the torrentfile for the torrent
        identified by the passed infohash. If the torrent is succesfully
        received, the usercallback method is called with the infohash as first
        and the contents of the torrentfile (bencoded dict) as second parameter.
        If the torrent could not be obtained, the callback is not called.
        The torrent will have been added to the TorrentDBHandler (if enabled)
        at the time of the call.

        @param permid The PermID of the peer to query.
        @param infohash The infohash of the torrent.
        @param usercallback A function adhering to the above spec.
        """
        if not self.lm.rtorrent_handler:
            raise OperationNotEnabledByConfigurationException()

        self.lm.rtorrent_handler.download_torrent(candidate, infohash, roothash, usercallback, prio)

    def download_torrentmessage_from_peer(self, candidate, infohash, usercallback, prio=0):
        """ Ask the designated peer to send us the torrentmessage for the torrent
        identified by the passed infohash. If the torrentmessage is succesfully
        received, the usercallback method is called with the infohash as first
        and the contents of the torrentfile (bencoded dict) as second parameter.
        If the torrent could not be obtained, the callback is not called.
        The torrent will have been added to the TorrentDBHandler (if enabled)
        at the time of the call.

        @param permid The PermID of the peer to query.
        @param infohash The infohash of the torrent.
        @param usercallback A function adhering to the above spec.
        """
        if not self.lm.rtorrent_handler:
            raise OperationNotEnabledByConfigurationException()

        self.lm.rtorrent_handler.download_torrentmessage(candidate, infohash, usercallback, prio)

    def get_dispersy_instance(self):
        if not self.get_dispersy():
            raise OperationNotEnabledByConfigurationException()

        return self.lm.dispersy

    def get_swift_process(self):
        if not self.get_swift_proc():
            raise OperationNotEnabledByConfigurationException()

        return self.lm.swift_process

    #
    # Internal persistence methods
    #
    def checkpoint_shutdown(self, stop, checkpoint, gracetime, hacksessconfcheckpoint):
        """ Checkpoints the Session and optionally shuts down the Session.
        @param stop Whether to shutdown the Session as well.
        @param checkpoint Whether to checkpoint at all, or just to stop.
        @param gracetime Time to allow for graceful shutdown + signoff (seconds).
        """
        # Called by any thread
        self.sesslock.acquire()
        try:
            # Arno: Make checkpoint optional on shutdown. At the moment setting
            # the config at runtime is not possible (see SessionRuntimeConfig)
            # so this has little use, and interferes with our way of
            # changing the startup config, which is to write a new
            # config to disk that will be read at start up.
            if hacksessconfcheckpoint:
                try:
                    self.save_pstate_sessconfig()
                except Exception as e:
                    self.lm.rawserver_nonfatalerrorfunc(e)

            # Checkpoint all Downloads and stop NetworkThread
            if stop:
                self._logger.debug("Session: checkpoint_shutdown")
            self.lm.checkpoint(stop=stop, checkpoint=checkpoint, gracetime=gracetime)
        finally:
            self.sesslock.release()

    def save_pstate_sessconfig(self):
        """ Save the runtime SessionConfig to disk """
        # Called by any thread
        sscfg = self.get_current_startup_config_copy()
        cfgfilename = Session.get_default_config_filename(sscfg.get_state_dir())
        sscfg.save(cfgfilename)

    def get_default_config_filename(state_dir):
        """ Return the name of the file where a session config is saved by default.
        @return A filename
        """
        return os.path.join(state_dir, STATEDIR_SESSCONFIG)
    get_default_config_filename = staticmethod(get_default_config_filename)

    def update_trackers(self, id, trackers):
        """ Update the trackers for a download.
        @param id ID of the download for which the trackers need to be updated
        @param trackers A list of tracker urls.
        """
        return self.lm.update_trackers(id, trackers)

########NEW FILE########
__FILENAME__ = SessionConfig
# Written by Arno Bakker
# Updated by George Milescu
# Updated by Egbert Bouman, now using ConfigParser
# see LICENSE.txt for license information
""" Controls the operation of a Session """

#
# WARNING: When extending this class:
#
# 1. Add a JavaDoc description for each method you add.
# 2. Also add the methods to APIImplementation/SessionRuntimeConfig.py
# 3. Document your changes in API.py
#
#

import sys
import os.path
import socket
import random
import logging

from Tribler.Core.defaults import sessdefaults
from Tribler.Core.Base import Copyable, Serializable
from Tribler.Core.RawServer.RawServer import autodetect_socket_style
from Tribler.Core.Utilities.utilities import find_prog_in_PATH
from Tribler.Core.Utilities.configparser import CallbackConfigParser


class SessionConfigInterface(object):

    """
    (key,value) pair config of global parameters,
    e.g. PermID keypair, listen port, max upload speed, etc.

    Use SessionStartupConfig from creating and manipulation configurations
    before session startup time. This is just a parent class.
    """
    def __init__(self, sessconfig=None):
        """ Constructor.
        @param sessconfig Optional dictionary used internally
        to make this a copy constructor.
        """
        self._logger = logging.getLogger(self.__class__.__name__)

        self.selected_ports = {}
        self.sessconfig = sessconfig or CallbackConfigParser()

        # Poor man's versioning of SessionConfig, add missing default values.
        for section, sect_dict in sessdefaults.iteritems():
            if not self.sessconfig.has_section(section):
                self.sessconfig.add_section(section)
            for k, v in sect_dict.iteritems():
                if not self.sessconfig.has_option(section, k):
                    self.sessconfig.set(section, k, v)

        if not sessconfig:
            return

        # Set video_analyser_path
        if sys.platform == 'win32':
            ffmpegname = u"ffmpeg.exe"
        elif sys.platform == 'darwin':
            ffmpegname = u"ffmpeg"
        else:
            ffmpegname = u"avconv"

        ffmpegpath = find_prog_in_PATH(ffmpegname)
        if ffmpegpath is None:
            if sys.platform == 'darwin':
                self.sessconfig.set(u'general', u'videoanalyserpath', u"vlc/ffmpeg")
            else:
                self.sessconfig.set(u'general', u'videoanalyserpath', ffmpegname)
        else:
            self.sessconfig.set(u'general', u'videoanalyserpath', ffmpegpath)

        # Set videoplayer path
        if sys.platform == 'win32':
            videoplayerpath = os.path.expandvars('${PROGRAMFILES}') + '\\Windows Media Player\\wmplayer.exe'
        elif sys.platform == 'darwin':
            videoplayerpath = find_prog_in_PATH("vlc") or ("/Applications/VLC.app" if os.path.exists("/Applications/VLC.app") else None) or "/Applications/QuickTime Player.app"
        else:
            videoplayerpath = find_prog_in_PATH("vlc") or "vlc"

        self.sessconfig.set(u'video', u'path', videoplayerpath)

        self.sessconfig.set(u'general', u'ipv6_binds_v4', autodetect_socket_style())

    #
    # Auxiliar functions
    #

    def _obtain_port(self, *keys):
        """ Fetch a port setting from the config file and in case it's set to -1 (random), look for a free port and assign it to
                this particular setting.
        """
        settings_port = self.sessconfig.get(*keys)
        path = '~'.join(keys)
        in_selected_ports = path in self.selected_ports

        if in_selected_ports or settings_port == -1:
            if not in_selected_ports:
                random_port = 0

                while True:
                    s = socket.socket()
                    try:
                        s.bind(('', random_port))
                        random_port = s.getsockname()[1]
                        if random_port in self.selected_ports.values():
                            raise Exception(u"port already in random-list.")
                        else:
                            # get unique port
                            self.selected_ports[path] = random_port
                            break
                    except:
                        self._logger.exception(u"Unable to bind port %d", random_port)

                        random_port += 1
                        if random_port < 1000 or random_port > 65535:
                            random_port = random.uniform(5000, 60000)
                    finally:
                        s.close()

                self._logger.debug(u"Get random port %d for [%s]", self.selected_ports[path], path)
            return self.selected_ports[path]
        return settings_port

    def set_state_dir(self, statedir):
        """ Set the directory to store the Session's state in.
        @param statedir  A preferably absolute path name. If the directory
        does not yet exist it will be created at Session create time.
        """
        self.sessconfig.set(u'general', u'state_dir', statedir)

    def get_state_dir(self):
        """ Returns the directory the Session stores its state in.
        @return An absolute path name. """
        return self.sessconfig.get(u'general', u'state_dir')

    def set_install_dir(self, installdir):
        """ Set the directory in which the Tribler Core software is installed.
        @param installdir An absolute path name
        """
        self.sessconfig.set(u'general', u'install_dir', installdir)

    def get_install_dir(self):
        """ Returns the directory the Tribler Core software is installed in.
        @return An absolute path name. """
        return self.sessconfig.get(u'general', u'install_dir')

    def set_permid_keypair_filename(self, keypairfilename):
        """ Set the filename containing the Elliptic Curve keypair to use for
        PermID-based authentication in this Session.

        Note: if a Session is started with a SessionStartupConfig that
        points to an existing state dir and that state dir contains a saved
        keypair, that keypair will be used unless a different keypair is
        explicitly configured via this method.
        """
        self.sessconfig.set(u'general', u'eckeypairfilename', keypairfilename)

    def get_permid_keypair_filename(self):
        """ Returns the filename of the Session's keypair.
        @return An absolute path name. """
        return self.sessconfig.get(u'general', u'eckeypairfilename')

    def set_listen_port(self, port):
        """ Set the UDP and TCP listen port for this Session.
        @param port A port number.
        """
        self.sessconfig.set(u'general', u'minport', port)
        self.sessconfig.set(u'general', u'maxport', port)

    def set_listen_port_runtime(self, port):
        """ Set the UDP and TCP listen port for this Session. This method is non-persistent.
        @param port A port number.
        """
        self.selected_ports['~'.join(('general', 'minport'))] = port

    def set_proxy_community_socks5_listen_port(self, port):
        self.sessconfig.set(u'proxy_community', u'socks5_listen_port', port)

    def get_proxy_community_socks5_listen_port(self):
        return self._obtain_port(u'proxy_community', u'socks5_listen_port')

    def get_listen_port(self):
        """ Returns the current UDP/TCP listen port.
        @return Port number. """
        return self._obtain_port(u'general', u'minport')

    def set_timeout_check_interval(self, timeout):
        self.sessconfig.set(u'general', u'timeout_check_interval', timeout)

    def get_timeout_check_interval(self):
        return self.sessconfig.get(u'general', u'timeout_check_interval')

    def set_timeout(self, timeout):
        self.sessconfig.set(u'general', u'timeout', timeout)

    def get_timeout(self):
        return self.sessconfig.get(u'general', u'timeout')

    def set_ipv6(self, enabled):
        self.sessconfig.set(u'general', u'ipv6_enabled', enabled)

    def get_ipv6(self):
        return self.sessconfig.get(u'general', u'ipv6_enabled')

    #
    # Enable/disable Tribler features
    #
    def set_megacache(self, value):
        """ Enable megacache databases to cache peers, torrent files and
        preferences (default = True).
        @param value Boolean. """
        self.sessconfig.set(u'general', u'megacache', value)

    def get_megacache(self):
        """ Returns whether Megacache is enabled.
        @return Boolean. """
        return self.sessconfig.get(u'general', u'megacache')

    def set_libtorrent(self, value):
        """ Enable or disable LibTorrent (default = True).
        @param value Boolean.
        """
        self.sessconfig.set(u'libtorrent', u'enabled', value)

    def get_libtorrent(self):
        """ Returns whether LibTorrent is enabled.
        @return Boolean.
        """
        return self.sessconfig.get(u'libtorrent', u'enabled')

    def set_libtorrent_proxy_settings(self, ptype, server=None, auth=None):
        """ Set which proxy LibTorrent should use (default = 0).
        @param ptype Integer (0 = no proxy server, 1 = SOCKS4, 2 = SOCKS5, 3 = SOCKS5 + auth, 4 = HTTP, 5 = HTTP + auth)
        @param server (host, port) tuple or None
        @param auth (username, password) tuple or None
        """
        self.sessconfig.set(u'libtorrent', u'lt_proxytype', ptype)
        self.sessconfig.set(u'libtorrent', u'lt_proxyserver', server if ptype else None)
        self.sessconfig.set(u'libtorrent', u'lt_proxyauth', auth if ptype in [3, 5] else None)

    def get_libtorrent_proxy_settings(self):
        """ Returns which proxy LibTorrent is using.
        @return Tuple containing ptype, server, authentication values (as described in set_libtorrent_proxy_settings)
        """
        return (self.sessconfig.get(u'libtorrent', u'lt_proxytype'), \
                self.sessconfig.get(u'libtorrent', u'lt_proxyserver'), \
                self.sessconfig.get(u'libtorrent', u'lt_proxyauth'))

    def set_anon_proxy_settings(self, ptype, server=None, auth=None):
        """
        @param ptype Integer (0 = no proxy server, 1 = SOCKS4, 2 = SOCKS5, 3 = SOCKS5 + auth, 4 = HTTP, 5 = HTTP + auth)
        @param server (host, port) tuple or None
        @param auth (username, password) tuple or None
        """
        self.sessconfig.set(u'libtorrent', u'anon_proxytype', ptype)
        self.sessconfig.set(u'libtorrent', u'anon_proxyserver', server if ptype else None)
        self.sessconfig.set(u'libtorrent', u'anon_proxyauth', auth if ptype in [3, 5] else None)

    def get_anon_proxy_settings(self):
        """
        @return: libtorrent anonymous settings
        """
        return (self.sessconfig.get(u'libtorrent', u'anon_proxytype'),
                self.sessconfig.get(u'libtorrent', u'anon_proxyserver'),
                self.sessconfig.get(u'libtorrent', u'anon_proxyauth'))


    def set_anon_listen_port(self, listen_port=None):
        self.sessconfig.set(u'libtorrent', u'anon_listen_port', listen_port)

    def get_anon_listen_port(self):
        return self._obtain_port(u'libtorrent', u'anon_listen_port')

    def set_libtorrent_utp(self, value):
        """ Enable or disable LibTorrent uTP (default = True).
        @param value Boolean.
        """
        self.sessconfig.set(u'libtorrent', u'utp', value)

    def get_libtorrent_utp(self):
        """ Returns whether LibTorrent uTP is enabled.
        @return Boolean.
        """
        return self.sessconfig.get(u'libtorrent', u'utp')


    #
    # Torrent file collecting
    #
    def set_torrent_collecting(self, value):
        """ Automatically collect torrents from peers in the network (default =
        True).
        @param value Boolean.
        """
        self.sessconfig.set(u'torrent_collecting', u'enabled', value)

    def get_torrent_collecting(self):
        """ Returns whether to automatically collect torrents.
        @return Boolean. """
        return self.sessconfig.get(u'torrent_collecting', u'enabled')

    def set_dht_torrent_collecting(self, value):
        """ Automatically collect torrents from the dht if peers fail to respond
        @param value Boolean.
        """
        self.sessconfig.set(u'torrent_collecting', u'dht_torrent_collecting', value)

    def get_dht_torrent_collecting(self):
        """ Returns whether to automatically collect torrents from the dht if peers fail
        to respond.
        @return Boolean. """
        return self.sessconfig.get(u'torrent_collecting', u'dht_torrent_collecting')

    def set_torrent_collecting_max_torrents(self, value):
        """ Set the maximum number of torrents to collect from other peers.
        @param value A number of torrents.
        """
        self.sessconfig.set(u'torrent_collecting', u'torrent_collecting_max_torrents', value)

    def get_torrent_collecting_max_torrents(self):
        """ Returns the maximum number of torrents to collect.
        @return A number of torrents. """
        return self.sessconfig.get(u'torrent_collecting', u'torrent_collecting_max_torrents')

    def set_torrent_collecting_dir(self, value):
        """ Where to place collected torrents? (default is state_dir + 'collected_torrent_files')
        @param value An absolute path.
        """
        self.sessconfig.set(u'torrent_collecting', u'torrent_collecting_dir', value)

    def get_torrent_collecting_dir(self):
        """ Returns the directory to save collected torrents.
        @return An absolute path name. """
        return self.sessconfig.get(u'torrent_collecting', u'torrent_collecting_dir')

    def set_torrent_checking(self, value):
        """ Whether to automatically check the health of collected torrents by
        contacting their trackers (default = True).
        @param value Boolean
        """
        self.sessconfig.set(u'torrent_checking', u'enabled', value)

    def get_torrent_checking(self):
        """ Returns whether to check health of collected torrents.
        @return Boolean. """
        return self.sessconfig.get(u'torrent_checking', u'enabled')

    def set_torrent_checking_period(self, value):
        """ Interval between automatic torrent health checks.
        @param value An interval in seconds.
        """
        self.sessconfig.set(u'torrent_checking', u'torrent_checking_period', value)

    def get_torrent_checking_period(self):
        """ Returns the check interval.
        @return A number of seconds. """
        return self.sessconfig.get(u'torrent_checking', u'torrent_checking_period')

    def set_stop_collecting_threshold(self, value):
        """ Stop collecting more torrents if the disk has less than this limit
        @param value A limit in MB.
        """
        self.sessconfig.set(u'torrent_collecting', u'stop_collecting_threshold', value)

    def get_stop_collecting_threshold(self):
        """ Returns the disk-space limit when to stop collecting torrents.
        @return A number of megabytes. """
        return self.sessconfig.get(u'torrent_collecting', u'stop_collecting_threshold')

    #
    # Tribler's social networking feature transmits a nickname and picture
    # to all Tribler peers it meets.
    #

    def set_nickname(self, value):
        """ The nickname you want to show to others.
        @param value A Unicode string.
        """
        self.sessconfig.set(u'general', u'nickname', value)

    def get_nickname(self):
        """ Returns the set nickname.
        @return A Unicode string. """
        return self.sessconfig.get(u'general', u'nickname')

    def set_mugshot(self, value, mime='image/jpeg'):
        """ The picture of yourself you want to show to others.
        @param value A string of binary data of your image.
        @param mime A string of the mimetype of the data
        """
        self.sessconfig.set(u'general', u'mugshot', (mime, value))

    def get_mugshot(self):
        """ Returns binary image data and mime-type of your picture.
        @return (String, String) value and mimetype. """
        if self.sessconfig.get(u'general', u'mugshot') is None:
            return None, None
        else:
            return self.sessconfig.get(u'general', u'mugshot')

    def set_peer_icon_path(self, value):
        """ Directory to store received peer icons (Default is statedir +
        STATEDIR_PEERICON_DIR).
        @param value An absolute path. """
        self.sessconfig.set(u'general', u'peer_icon_path', value)

    def get_peer_icon_path(self):
        """ Returns the directory to store peer icons.
        @return An absolute path name. """
        return self.sessconfig.get(u'general', u'peer_icon_path')

    #
    # For Tribler Video-On-Demand
    #
    def set_video_analyser_path(self, value):
        """ Path to video analyser FFMPEG. The analyser is used to guess the
        bitrate of a video if that information is not present in the torrent
        definition. (default = look for it in $PATH)
        @param value An absolute path name.
        """
        self.sessconfig.set(u'general', u'videoanalyserpath', value)

    def get_video_analyser_path(self):
        """ Returns the path of the FFMPEG video analyser.
        @return An absolute path name. """
        return self.sessconfig.get(u'general', u'videoanalyserpath')  # strings immutable

    def set_mainline_dht(self, value):
        """ Enable mainline DHT support (default = True)
        @param value Boolean.
        """
        self.sessconfig.set(u'mainline_dht', u'enabled', value)

    def get_mainline_dht(self):
        """ Returns whether mainline DHT support is enabled.
        @return Boolean. """
        return self.sessconfig.get(u'mainline_dht', u'enabled')

    def set_mainline_dht_listen_port(self, port):
        """ Sets the port that the mainline DHT uses to receive and send UDP
        datagrams.
        @param value int
        """
        self.sessconfig.set(u'mainline_dht', u'mainline_dht_port', port)

    def get_mainline_dht_listen_port(self):
        """ Returns the port that the mainline DHT uses to receive and send
        USP datagrams.
        @return int
        """
        return self._obtain_port(u'mainline_dht', u'mainline_dht_port')

    #
    # Local Peer Discovery using IP Multicast
    #
    def set_multicast_local_peer_discovery(self, value):
        """ Set whether the Session tries to detect local peers
        using a local IP multicast. Only applies to LibTorrent
        @param value Boolean
        """
        self.sessconfig.set(u'general', u'multicast_local_peer_discovery', value)

    def get_multicast_local_peer_discovery(self):
        """
        Returns whether local peer discovery is enabled.
        @return Boolean
        """
        return self.sessconfig.get(u'general', u'multicast_local_peer_discovery')

    #
    # Dispersy
    #
    def set_dispersy(self, value):
        """ Enable or disable Dispersy (default = True).
        @param value Boolean.
        """
        self.sessconfig.set(u'dispersy', u'enabled', value)

    def get_dispersy(self):
        """ Returns whether Dispersy is enabled.
        @return Boolean.
        """
        return self.sessconfig.get(u'dispersy', u'enabled')

    def set_dispersy_tunnel_over_swift(self, value):
        """ Enable or disable Dispersy tunnelling over libswift.
        @param value Boolean.
        """
        assert isinstance(value, bool)
        self.sessconfig.set(u'dispersy', u'dispersy-tunnel-over-swift', value)

    def get_dispersy_tunnel_over_swift(self):
        """ Returns whether Dispersy is tunnelling over libswift.
        @return Boolean.
        """
        return self.sessconfig.get(u'dispersy', u'dispersy-tunnel-over-swift')

    def set_dispersy_port(self, value):
        """ Sets the port that Dispersy uses to receive and send UDP
        datagrams.
        @param value int
        """
        assert isinstance(value, int)
        self.sessconfig.set(u'dispersy', u'dispersy_port', value)

    def get_dispersy_port(self):
        """ Returns the port that Dispersy uses to receive and send
        USP datagrams.
        @return int
        """
        return self._obtain_port(u'dispersy', u'dispersy_port')

    #
    # SWIFTPROC
    #
    def set_swift_proc(self, value):
        """ Enable/disable support for swift Downloads via an external
        swift C++ process.
        @param value  Boolean
        """
        self.sessconfig.set(u'swift', u'enabled', value)

    def get_swift_proc(self):
        """ Return whether support for swift Downloads via an external
        swift C++ process is enabled.
        @return  Boolean
        """
        return self.sessconfig.get(u'swift', u'enabled')

    def set_swift_path(self, value):
        """ Path to swift binary (default = None = <installdir>/swift[.exe])
        @param value An absolute path name.
        """
        self.sessconfig.set(u'swift', u'swiftpath', value)

    def get_swift_path(self):
        """ Returns the path of the swift binary.
        @return An absolute path name. """
        return self.sessconfig.get(u'swift', u'swiftpath')  # strings immutable

    def set_swift_working_dir(self, value):
        """ Current working directory for swift binary (default = '.')
        @param value A path name.
        """
        self.sessconfig.set(u'swift', u'swiftworkingdir', value)

    def get_swift_working_dir(self):
        """ Returns the working directory for the swift binary.
        @return A path name. """
        return self.sessconfig.get(u'swift', u'swiftworkingdir')  # strings immutable

    def set_swift_meta_dir(self, value):
        """ Set the metadir for storing .m* files of downloads.
        @param value An absolutepath.
        """
        self.sessconfig.set(u'swift', u'swiftmetadir', value)

    def get_swift_meta_dir(self):
        """ Return the metadir for storing .m* files of downloads.
        @return An absolutepath.
        """
        return self.sessconfig.get(u'swift', u'swiftmetadir')

    def set_swift_cmd_listen_port(self, port):
        """ Set the local TCP listen port for cmd socket communication to
        the swift processes (unused). CMD listen port of swift process itself
        is set via DownloadConfig.set_swift_cmdgw_listen_port() (download-to-process
        mapping permitting)
        @param port A port number.
        """
        self.sessconfig.set(u'swift', u'swiftcmdlistenport', port)

    def get_swift_cmd_listen_port(self):
        """ Returns the local listen port for swift cmd socket communication.
        @return Port number. """
        return self._obtain_port(u'swift', u'swiftcmdlistenport')

    def set_swift_dht_listen_port(self, port):
        """ Set the local UDP listen port for dht socket communication to
        the swift processes.
        @param port A port number.
        """
        self.sessconfig.set(u'swift', u'swiftdhtport', port)

    def get_swift_dht_listen_port(self):
        """ Returns the local dht port for swift communication.
        @return Port number. """
        return self._obtain_port(u'swift', u'swiftdhtport')

    def set_swift_downloads_per_process(self, value):
        """ Number of downloads per swift process. When exceeded, a new swift
        process is created. Only used when the user did not specify ports
        for the swift process via DownloadConfig.set_swift_*_port()
        @param value A number of downloads.
        """
        self.sessconfig.set(u'swift', u'swiftdlsperproc', value)

    def get_swift_downloads_per_process(self):
        """ Returns the number of downloads per swift process.
        @return A number of downloads. """
        return self.sessconfig.get(u'swift', u'swiftdlsperproc')

    #
    # Config for swift tunneling e.g. dispersy traffic
    #
    def set_swift_tunnel_listen_port(self, port):
        """ Set the UDP port for the swift process
        (download-to-process mapping permitting).
        @param port A port number.
        """
        self.sessconfig.set(u'swift', u'swifttunnellistenport', port)

    def get_swift_tunnel_listen_port(self):
        """ Returns the UDP port of the swift process.

        @return Port number. """
        return self._obtain_port(u'swift', u'swifttunnellistenport')

    def set_swift_tunnel_cmdgw_listen_port(self, port):
        """ Set the TCP listen port for the CMDGW of the swift process
        (download-to-process mapping permitting).
        @param port A port number.
        """
        self.sessconfig.set(u'swift', u'swifttunnelcmdgwlistenport', port)

    def get_swift_tunnel_cmdgw_listen_port(self):
        """ Returns the TCP listen port for the CMDGW of the swift process
        (download-to-process mapping permitting).

        @return Port number. """
        return self._obtain_port(u'swift', u'swifttunnelcmdgwlistenport')

    def set_swift_tunnel_httpgw_listen_port(self, port):
        """ Set the TCP listen port for the CMDGW of the swift process
        (download-to-process mapping permitting).
        @param port A port number.
        """
        self.sessconfig.set(u'swift', u'swifttunnelhttpgwlistenport', port)

    def get_swift_tunnel_httpgw_listen_port(self):
        """ Returns the TCP listen port for the CMDGW of the swift process.

        @return Port number. """
        return self._obtain_port(u'swift', u'swifttunnelhttpgwlistenport')

    def get_videoplayer(self):
        """ Enable or disable VOD functionality (default = True).
        @param value Boolean.
        """
        return self.sessconfig.get(u'video', u'enabled')

    def set_videoplayer(self, value):
        """ Returns whether VOD functionality is enabled.
        @return Boolean.
        """
        self.sessconfig.set(u'video', u'enabled', value)

    def get_videoplayer_path(self):
        """ Get the path of the player that the videoplayer should execute after calling VideoPlayer.play.
        @return path.
        """
        return self.sessconfig.get(u'video', u'path')

    def set_videoplayer_path(self, path):
        """ Set the path of the player that the videoplayer should execute after calling VideoPlayer.play.
        @param path.
        """
        self.sessconfig.set(u'video', u'path', path)

    def get_videoplayer_port(self):
        """ Get the port number that the video http server should use.
        @return integer.
        """
        return self._obtain_port(u'video', u'port')

    def set_videoplayer_port(self, port):
        """ Set the port number that the video http server should use.
        @param port integer (-1 indicates a random port).
        """
        self.sessconfig.set(u'video', u'port', port)

    def get_preferred_playback_mode(self):
        """ Get the preferred playback mode for videos.
        @return integer.
        """
        return self.sessconfig.get(u'video', u'preferredmode')

    def set_preferred_playback_mode(self, mode):
        """ Set the preferred playback mode for videos.
        @param mode integer (0..2, see Tribler.Core.Video.def).
        """
        self.sessconfig.set(u'video', u'preferredmode', mode)


class SessionStartupConfig(SessionConfigInterface, Copyable, Serializable):

    """ Class to configure a Session """

    def __init__(self, sessconfig=None):
        SessionConfigInterface.__init__(self, sessconfig)


    #
    # Class method
    #
    @staticmethod
    def load(filename):
        """
        Load a saved SessionStartupConfig from disk.

        @param filename  An absolute Unicode filename
        @return SessionStartupConfig object
        """
        # Class method, no locking required
        sessconfig = CallbackConfigParser()
        try:
            sessconfig.read_file(filename)
        except:
            raise IOError, "Failed to open session config file"

        return SessionStartupConfig(sessconfig)


    def save(self, filename):
        """ Save the SessionStartupConfig to disk.
        @param filename  An absolute Unicode filename
        """
        # Called by any thread
        self.sessconfig.write_file(filename)

    #
    # Copyable interface
    #
    def copy(self):
        return SessionStartupConfig(self.sessconfig.copy())

########NEW FILE########
__FILENAME__ = simpledefs
# Written by Arno Bakker
# see LICENSE.txt for license information
""" Simple definitions for the Tribler Core. """
import os

DLSTATUS_ALLOCATING_DISKSPACE = 0  # TODO: make sure this get set when in this alloc mode
DLSTATUS_WAITING4HASHCHECK = 1
DLSTATUS_HASHCHECKING = 2
DLSTATUS_DOWNLOADING = 3
DLSTATUS_SEEDING = 4
DLSTATUS_STOPPED = 5
DLSTATUS_STOPPED_ON_ERROR = 6
DLSTATUS_METADATA = 7

dlstatus_strings = ['DLSTATUS_ALLOCATING_DISKSPACE',
    'DLSTATUS_WAITING4HASHCHECK',
    'DLSTATUS_HASHCHECKING',
    'DLSTATUS_DOWNLOADING',
    'DLSTATUS_SEEDING',
    'DLSTATUS_STOPPED',
    'DLSTATUS_STOPPED_ON_ERROR',
    'DLSTATUS_METADATA']

UPLOAD = 'up'
DOWNLOAD = 'down'

DLMODE_NORMAL = 0
DLMODE_VOD = 1

PERSISTENTSTATE_CURRENTVERSION = 5
"""
V1 = SwarmPlayer 1.0.0
V2 = Tribler 4.5.0: SessionConfig: Added NAT fields
V3 = SessionConfig: Added multicast_local_peer_discovery,
     Removed rss_reload_frequency + rss_check_frequency.
V4 = ... + added pickled SwiftDef
V5 = no longer pickling data
For details see API.py
"""

STATEDIR_DLPSTATE_DIR = 'dlcheckpoints'
STATEDIR_PEERICON_DIR = 'icons'
STATEDIR_TORRENTCOLL_DIR = 'collected_torrent_files'
STATEDIR_SWIFTRESEED_DIR = os.path.join(STATEDIR_TORRENTCOLL_DIR, 'swift_reseeds')

STATEDIR_SESSCONFIG = 'libtribler.conf'

# For observer/callback mechanism, see Session.add_observer()

# subjects
NTFY_MISC = 'misc'
NTFY_METADATA = 'metadata'
NTFY_PEERS = 'peers'
NTFY_TORRENTS = 'torrents'
NTFY_PLAYLISTS = 'playlists'
NTFY_COMMENTS = 'comments'
NTFY_MODIFICATIONS = 'modifications'
NTFY_MARKINGS = 'markings'
NTFY_MODERATIONS = 'moderations'
NTFY_MYPREFERENCES = 'mypreferences'
NTFY_SEEDINGSTATS = 'seedingstats'
NTFY_SEEDINGSTATSSETTINGS = 'seedingstatssettings'
NTFY_VOTECAST = 'votecast'
NTFY_CHANNELCAST = 'channelcast'
NTFY_ANONTUNNEL = 'anontunnel'
NTFY_TRACKERINFO = 'trackerinfo'

# non data handler subjects
NTFY_ACTIVITIES = 'activities'  # an activity was set (peer met/dns resolved)
NTFY_REACHABLE = 'reachable'  # the Session is reachable from the Internet
NTFY_DISPERSY = 'dispersy'  # an notification regarding dispersy

# changeTypes
NTFY_UPDATE = 'update'  # data is updated
NTFY_INSERT = 'insert'  # new data is inserted
NTFY_DELETE = 'delete'  # data is deleted
NTFY_CREATE = 'create'  # new data is created, meaning in the case of Channels your own channel is created
NTFY_STARTED = 'started'
NTFY_STATE = 'state'
NTFY_MODIFIED = 'modified'
NTFY_FINISHED = 'finished'
NTFY_MAGNET_STARTED = 'magnet_started'
NTFY_MAGNET_GOT_PEERS = 'magnet_peers'
NTFY_MAGNET_PROGRESS = 'magnet_progress'
NTFY_MAGNET_CLOSE = 'magnet_close'
NTFY_VIDEO_STARTED = 'video_started'
NTFY_VIDEO_STOPPED = 'video_stopped'
NTFY_VIDEO_ENDED = 'video_ended'
NTFY_VIDEO_BUFFERING = 'video_bufering'
NTFY_CREATED = 'created'
NTFY_EXTENDED = 'extended'
NTFY_EXTENDED_FOR = 'extended_for'
NTFY_BROKEN = 'broken'
NTFY_SELECT = 'select'
NTFY_JOINED = 'joined'

# object IDs for NTFY_ACTIVITIES subject
NTFY_ACT_NONE = 0
NTFY_ACT_UPNP = 1
NTFY_ACT_REACHABLE = 2
NTFY_ACT_GET_EXT_IP_FROM_PEERS = 3
NTFY_ACT_MEET = 4
NTFY_ACT_GOT_METADATA = 5
NTFY_ACT_RECOMMEND = 6
NTFY_ACT_DISK_FULL = 7
NTFY_ACT_NEW_VERSION = 8
NTFY_ACT_ACTIVE = 9


# Methods for authentication of the source in live streaming
LIVE_AUTHMETHOD_NONE = "None"  # No auth, also no abs. piece nr. or timestamp.
LIVE_AUTHMETHOD_ECDSA = "ECDSA"  # Elliptic Curve DSA signatures
LIVE_AUTHMETHOD_RSA = "RSA"  # RSA signatures


P2PURL_SCHEME = "tribe"  # No colon
SWIFT_URL_SCHEME = "tswift"  # No colon

TRIBLER_TORRENT_EXT = ".tribe"  # Unused

# Infohashes are always 20 byte binary strings
INFOHASH_LENGTH = 20

########NEW FILE########
__FILENAME__ = LivingLabReporter
# Written by Njaal Borch
# see LICENSE.txt for license information

#
# Arno TODO: Merge with Core/Statistics/Status/*
#

import time
import logging

import httplib

import XmlPrinter
import xml.dom.minidom

import Status
from Tribler.Core.Utilities.timeouturlopen import find_proxy

STRESSTEST = False

logger = logging.getLogger(__name__)


class LivingLabPeriodicReporter(Status.PeriodicStatusReporter):

    """
    This reporter creates an XML report of the status elements
    that are registered and sends them using an HTTP Post at
    the given interval.  Made to work with the P2P-Next lab.
    """

    host = "p2pnext-statistics.comp.lancs.ac.uk"
    # path = "/testpost/"
    path = "/post/"

    def __init__(self, name, frequency, id, error_handler=None,
                 print_post=False):
        """
        Periodically report to the P2P-Next living lab status service

        name: The name of this reporter (ignored)
        frequency: How often (in seconds) to report
        id: The ID of this device (e.g. permid)
        error_handler: Optional error handler that will be called if the
        port fails
        print_post: Print post to stderr when posting to the lab (largely
        useful for debugging)

        """
        self._logger = logging.getLogger(self.__class__.__name__)

        Status.PeriodicStatusReporter.__init__(self,
                                               name,
                                               frequency,
                                               error_handler)
        self.device_id = id
        self.print_post = print_post
        self.num_reports = 0

    def new_element(self, doc, name, value):
        """
        Helper function to save some lines of code
        """

        element = doc.createElement(name)
        value = doc.createTextNode(str(value))
        element.appendChild(value)

        return element

    def report(self):
        """
        Create the report in XML and send it
        """

        # Create the report
        doc = xml.dom.minidom.Document()
        root = doc.createElement("nextsharedata")
        doc.appendChild(root)

        # Create the header
        header = doc.createElement("header")
        root.appendChild(header)
        header.appendChild(self.new_element(doc, "deviceid", self.device_id))
        header.appendChild(self.new_element(doc, "timestamp",
                                            long(round(time.time()))))

        version = "cs_v2a"
        header.appendChild(self.new_element(doc, "swversion", version))

        # Now add the status elements
        elements = self.get_elements()
        if len(elements) > 0:
            report = doc.createElement("event")
            root.appendChild(report)

            report.appendChild(self.new_element(doc, "attribute",
                                               "statusreport"))
            report.appendChild(self.new_element(doc, "timestamp",
                                               long(round(time.time()))))
            for element in elements:
                self._logger.info(repr(element.__class__))
                report.appendChild(self.new_element(doc,
                                                   element.get_name(),
                                                   element.get_value()))

        events = self.get_events()
        if len(events) > 0:
            for event in events:
                report = doc.createElement(event.get_type())
                root.appendChild(report)
                report.appendChild(self.new_element(doc, "attribute",
                                                   event.get_name()))
                if event.__class__ == Status.EventElement:
                    report.appendChild(self.new_element(doc, "timestamp",
                                                       event.get_time()))
                elif event.__class__ == Status.RangeElement:
                    report.appendChild(self.new_element(doc, "starttimestamp",
                                                       event.get_start_time()))

                    report.appendChild(self.new_element(doc, "endtimestamp",
                                                       event.get_end_time()))
                for value in event.get_values():
                    report.appendChild(self.new_element(doc, "value", value))

        if len(elements) == 0 and len(events) == 0:
            return  # Was nothing here for us

        # all done
        xml_printer = XmlPrinter.XmlPrinter(root)
        if self.print_post:
            self._logger.info(repr(xml_printer.to_pretty_xml()))
        xml_str = xml_printer.to_xml()

        # Now we send this to the service using a HTTP POST
        self.post(xml_str)

    def post(self, xml_str):
        """
        Post a status report to the living lab using multipart/form-data
        This is a bit on the messy side, but it does work
        """

        # print >>sys.stderr, xml_str

        self.num_reports += 1

        boundary = "------------------ThE_bOuNdArY_iS_hErE_$"
        # headers = {"Host":self.host,
        #            "User-Agent":"NextShare status reporter 2009.4",
        #            "Content-Type":"multipart/form-data; boundary=" + boundary}

        base = ["--" + boundary + "--"]
        base.append('Content-Disposition: form-data; name="NextShareData"; filename="NextShareData"')
        base.append("Content-Type: text/xml")
        base.append("")
        base.append(xml_str)
        base.append("--" + boundary + "--")
        base.append("")
        base.append("")
        body = "\r\n".join(base)

        # Arno, 2010-03-09: Make proxy aware and use modern httplib classes
        wanturl = 'http://' + self.host +self.path
        proxyhost = find_proxy(wanturl)
        if proxyhost is None:
            desthost = self.host
            desturl = self.path
        else:
            desthost = proxyhost
            desturl = wanturl

        h = httplib.HTTPConnection(desthost)
        h.putrequest("POST", desturl)

        # 08/11/10 Boudewijn: do not send Host, it is automatically
        # generated from h.putrequest.  Sending it twice causes
        # invalid HTTP and Virtual Hosts to
        # fail.
        # h.putheader("Host",self.host)

        h.putheader("User-Agent", "NextShare status reporter 2010.3")
        h.putheader("Content-Type", "multipart/form-data; boundary=" + boundary)
        h.putheader("Content-Length", str(len(body)))
        h.endheaders()
        h.send(body)

        resp = h.getresponse()
        self._logger.debug("LivingLabReporter: %s %s\n %s\n %s", resp.status, resp.reason, resp.getheaders(), resp.read().replace("\\n", "\n"))

        if resp.status != 200:
            if self.error_handler:
                try:
                    self.error_handler(resp.status, resp.read())
                except Exception as e:
                    pass
            else:
                self._logger.info("Error posting but no error handler: %s", resp.status)
                self._logger.info(repr(resp.read()))


if __name__ == "__main__":
    """
    Small test routine to check an actual post (unittest checks locally)
    """

    status = Status.get_status_holder("UnitTest")

    def test_error_handler(code, message):
        """
        Test error-handler
        """
        logger.info("Error: %s %s", code, message)

    reporter = LivingLabPeriodicReporter("Living lab test reporter",
                                         1.0, test_error_handler)
    status.add_reporter(reporter)
    s = status.create_status_element("TestString", "A test string")
    s.set_value("Hi from Njaal")

    time.sleep(2)

    logger.info("Stopping reporter")
    reporter.stop()

    logger.info("Sent %d reports", reporter.num_reports)

########NEW FILE########
__FILENAME__ = NullReporter
import Status


class NullReporter(Status.PeriodicStatusReporter):

    """
    This reporter flushes all events down the drain periodically,
    ensuring that there is no retained memory.
    """

    def add_element(self, element):
        self.report()

    def report(self):
        """
        Create the report in XML and send it
        """
        self.get_events()

########NEW FILE########
__FILENAME__ = ProxyTestReporter
import time
import logging

import XmlPrinter
import xml.dom.minidom

import Status
from Tribler.Core.Utilities.utilities import show_permid_short

from LivingLabReporter import LivingLabPeriodicReporter


class ProxyTestPeriodicReporter(LivingLabPeriodicReporter):
    host = "proxytestreporter.tribler.org"
    path = "/postV2.py"

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

    def report(self):
        """
        Create the report in XML and send it
        """

        # Create the report
        doc = xml.dom.minidom.Document()
        root = doc.createElement("nextsharedata")
        doc.appendChild(root)

        # Create the header
        header = doc.createElement("header")
        root.appendChild(header)
        header.appendChild(self.new_element(doc, "deviceid", self.device_id))
        header.appendChild(self.new_element(doc, "timestamp", long(round(time.time()))))

        # ProxyService 90s Test_
#        try:
#            from Tribler.Core.Session import Session
#            session = Session.get_instance()
#            if session.lm.overlay_apps.proxy_peer_manager.connectable:
#                    connectable = 1
#            else:
#                    connectable = 0
#
#            start_time = long(round(session.start_time))
#
#            my_permid = show_permid_short(session.get_permid())
#        except Exception,e:
#            connectable = 0
#            start_time = 0
#            my_permid = 0
#
#        header.appendChild(self.new_element(doc, "connectable", connectable))
#        header.appendChild(self.new_element(doc, "startuptime", start_time))
#        header.appendChild(self.new_element(doc, "clientpermid", my_permid))
        # _ProxyService 90s Test

        version = "cs_v2a"
        header.appendChild(self.new_element(doc, "swversion", version))

        elements = self.get_elements()
        if len(elements) > 0:

            # Now add the status elements
            if len(elements) > 0:
                report = doc.createElement("event")
                root.appendChild(report)

                report.appendChild(self.new_element(doc, "attribute",
                                                    "statusreport"))
                report.appendChild(self.new_element(doc, "timestamp",
                                                    long(round(time.time()))))
                for element in elements:
                    self._logger.info(repr(element.__class__))
                    report.appendChild(self.new_element(doc,
                                                       element.get_name(),
                                                       element.get_value()))

        events = self.get_events()
        if len(events) > 0:
            for event in events:
                report = doc.createElement(event.get_type())
                root.appendChild(report)
                report.appendChild(self.new_element(doc, "attribute",
                                                   event.get_name()))
                if event.__class__ == Status.EventElement:
                    report.appendChild(self.new_element(doc, "timestamp",
                                                       event.get_time()))
                elif event.__class__ == Status.RangeElement:
                    report.appendChild(self.new_element(doc, "starttimestamp",
                                                       event.get_start_time()))

                    report.appendChild(self.new_element(doc, "endtimestamp",
                                                       event.get_end_time()))
                for value in event.get_values():
                    report.appendChild(self.new_element(doc, "value", value))

        if len(elements) == 0 and len(events) == 0:
            return  # Was nothing here for us

        # all done
        xml_printer = XmlPrinter.XmlPrinter(root)
        if self.print_post:
            self._logger.info(repr(xml_printer.to_pretty_xml()))
        xml_str = xml_printer.to_xml()

        # Now we send this to the service using a HTTP POST
        self.post(xml_str)

# if __name__ == "__main__":
#    from Tribler.Core.Statistics.Status.Status import get_status_holder

#    status = get_status_holder("ProxyTest")
#    status.add_reporter(ProxyTestPeriodicReporter("Test", 5, "test-id"))
#    status.create_and_add_event("foo", ["foo", "bar"])
#    status.create_and_add_event("animals", ["bunnies", "kitties", "doggies"])
#    status.create_and_add_event("numbers", range(255))

#    import time
#    time.sleep(15)

########NEW FILE########
__FILENAME__ = Status
# Written by Njaal Borch
# see LICENSE.txt for license information

import threading
import time
import logging

# Factory vars
global status_holders
status_holders = {}
global status_lock
status_lock = threading.Lock()

logger = logging.getLogger(__name__)

def get_status_holder(name):
    global status_lock
    global status_holders
    status_lock.acquire()
    try:
        if not name in status_holders:
            status_holders[name] = StatusHolder(name)

        return status_holders[name]
    finally:
        status_lock.release()


def delete_status_holders():
    global status_lock
    global status_holders
    status_lock.acquire()
    try:
        status_holders = {}
    finally:
        status_lock.release()


class StatusException(Exception):

    """
    Parent exception for all status based exceptions
    """
    pass


class NoSuchElementException(StatusException):

    """
    No such element found
    """
    pass


class NoSuchReporterException(StatusException):

    """
    Unknown reporter
    """
    pass

# Policies
# ON_CHANGE = 1
# PERIODIC = 2


class StatusHolder:

    """
    A class to hold (and report) status information for an application.
    A status holder can have multiple reporters, that will report status
    information on change or periodically.

    """

    def __init__(self, name):
        """
        Do not create new status objects if you don't know what you're doing.
        Use the getStatusHolder() function to retrieve status objects.
        """
        self._logger = logging.getLogger(self.__class__.__name__)

        self.name = name
        self.elements = {}
        self.reporters = {}
        self.lock = threading.Lock()
        self.events = []

    def reset(self):
        """
        Reset everything to blanks!
        """
        self.elements = {}
        self.reporters = {}
        self.events = []

    def get_name(self):
        """
        Return the name of this status holder
        """
        return self.name

    def get_reporter(self, name):
        """
        Get a given reporter from the status holder, using the name of the
        reporter.
        """
        assert name

        self.lock.acquire()
        try:
            if not name in self.reporters:
                raise Exception("No such reporter '%s'" % name)
            return self.reporters[name]
        finally:
            self.lock.release()

    def add_reporter(self, reporter):
        """
        Add a reporter to this status object.
        """
        assert reporter

        self.lock.acquire()
        try:
            if reporter.name in self.reporters:
                raise Exception("Already have reporter '%s' registered" %
                                reporter.name)
            self.reporters[reporter.name] = reporter

            # The reporter must contact me later
            reporter.add_status_holder(self)

            # If we have any other reporters, copy the elements
            # to the new one
            for element in self.elements.values():
                reporter.add_element(element)
        finally:
            self.lock.release()

    def remove_reporter(self, name):
        """
        Remove a reporter from the status holder, using the name of the reporter.
        """
        assert name

        self.lock.acquire()
        try:
            if not name in self.reporters:
                raise Exception("No such reporter '%s'" % name)
            del self.reporters[name]
        finally:
            self.lock.release()

    def _add_element(self, new_element):
        for reporter in self.reporters.values():
            reporter.add_element(new_element)

    def create_status_element(self, name, initial_value=None):
        assert name

        new_element = StatusElement(name, initial_value)

        self.lock.acquire()
        try:
            if name in self.elements:
                raise Exception("Already have a status element with the given name")
            self.elements[name] = new_element
        finally:
            self.lock.release()

        self._add_element(new_element)
        return new_element

    def get_status_element(self, name):
        """
        Get a status element from the Status Holder by name
        """
        assert name

        self.lock.acquire()
        try:
            if not name in self.elements:
                raise NoSuchElementException(name)
            return self.elements[name]
        finally:
            self.lock.release()

    def get_or_create_status_element(self, name, initial_value=None):
        self.lock.acquire()
        if not name in self.elements:
            self.lock.release()
            return self.create_status_element(name, initial_value)
        try:
            return self.elements[name]
        finally:
            self.lock.release()

    def remove_status_element(self, element):
        """
        Remove a status element
        """
        assert element

        self.lock.acquire()
        try:
            if not element.name in self.elements:
                raise NoSuchElementException(element.name)
            del self.elements[element.name]

            # Also remove this element to the policy
            for reporter in self.reporters.values():
                # TODO: More elegant here
                try:
                    reporter.remove_element(element)
                except:
                    pass

        finally:
            self.lock.release()

    def create_event(self, name, values=[]):
        assert isinstance(values, list)
        return EventElement(name, values)

    def add_event(self, event):
        self.lock.acquire()
        try:
            self.events.append(event)
        finally:
            self.lock.release()
        self._add_element(event)

    def remove_range(self, range):
        self.remove_event(range)

    def remove_event(self, event):
        self.lock.acquire()
        try:
            if event in self.events:
                self.events.remove(event)
        finally:
            self.lock.release()

    def create_and_add_event(self, name, values=[]):
        if len(self.reporters) == 0:
            self._logger.debug("NO REPORTERS FOR THIS STATUSHOLDER (%s), WILL CAUSE MEMORY LEAK", self.name)

        self.add_event(self.create_event(name, values))

    def create_range(self, name, values=[]):
        return RangeElement(name, values)

    def add_range(self, range):
        self.add_event(range)

    def create_and_add_range(self, name, values=[]):
        self.add_range(self.create_range(name, values))

    def get_elements(self):
        """
        Reporters will use this to get a copy of all
        elements that should be reported
        """
        self.lock.acquire()
        try:
            return self.elements.values()[:]
        finally:
            self.lock.release()

    def get_events(self):
        """
        Reporters will use this to get a copy of all
        events that should be reported
        """
        self.lock.acquire()
        try:
            events = self.events
            self.events = []
            return events
        finally:
            self.lock.release()

    def report_now(self):
        """
        Forces all reporters to report now
        """
        for reporter in self.reporters.values():
            reporter.report_now()


class BaseElement:
    type = "BaseElement"

    def __init__(self, name):
        """
        Create a new element.  DO NOT USE THIS - use
        create_status_element() using a Status Holder object
        """
        assert name
        self.name = name
        self.callbacks = []
        self.lock = threading.Lock()

        self._logger = logging.getLogger(self.__class__.__name__)

    def get_type(self):
        return self.type

    def add_callback(self, callback):
        """
        Add a callback that will be executed when this element is changed.
        The callback function will be passed the status element itself
        """
        self.callbacks.append(callback)

    def remove_callback(self, callback):
        """
        Remove an already registered callback
        """
        if not callback in self.callbacks:
            raise Exception("Cannot remove unknown callback")

    def get_name(self):
        return self.name

    def _updated(self):
        """
        When a status element is changed, this method must be called to
        notify any reporters
        """

        # TODO: Lock or make a copy?

        for callback in self.callbacks:
            try:
                callback(self)
            except Exception as e:
                self._logger.error("Exception in callback %s for parameter %s : %s", callback, self.name, e)


class StatusElement(BaseElement):

    """
    Class to hold status information
    """
    type = "status report"

    def __init__(self, name, initial_value=None):
        """
        Create a new element.  DO NOT USE THIS - use
        create_status_element() using a Status Holder object
        """
        BaseElement.__init__(self, name)
        self.value = initial_value

    def set_value(self, value):
        """
        Update the value of this status element
        """

        self.value = value
        self._updated()

    def get_value(self):
        return self.value

    def inc(self, value=1):
        """
        Will only work for numbers!
        """
        self.lock.acquire()
        try:
            self.value += value
            self._updated()
        except:
            raise Exception("Can only increment numbers")
        finally:
            self.lock.release()

    def dec(self, value=1):
        """
        Will only work for numbers!
        """
        self.lock.acquire()
        try:
            self.value -= value
            self._updated()
        except:
            raise Exception("Can only increment numbers")
        finally:
            self.lock.release()


class EventElement(BaseElement):
    type = "event"

    def __init__(self, name, values=[]):
        """
        Create a new element.  DO NOT USE THIS - use
        create_status_element() using a Status Holder object
        """
        self.time = long(time.time())
        BaseElement.__init__(self, name)
        self.values = values

    def get_time(self):
        return self.time

    def add_value(self, value):
        self.lock.acquire()
        try:
            self.values.append(value)
        finally:
            self.lock.release()

    def get_values(self):
        """
        Return the values as a copy to ensure that there are no
        synchronization issues
        """
        self.lock.acquire()
        try:
            return self.values[:]
        finally:
            self.lock.release()


class RangeElement(BaseElement):
    type = "range"

    def __init__(self, name, values=[]):
        self.start_time = self.end_time = long(time.time())
        BaseElement.__init__(self, name, "range")
        self.values = values

    def get_start_time(self):
        return self.start_time

    def get_end_time(self):
        return self.end_time

    def add_value(self, value):
        self.lock()
        try:
            self.end_time = long(time.time())
            self.values.append(value)
        finally:
            self.lock.release()

    def get_values(self):
        """
        Return the values as a copy to ensure that there are no
        synchronization issues
        """
        self.lock()
        try:
            return self.values[:]
        finally:
            self.lock.release()


class StatusReporter:

    """
    This is the basic status reporter class.  It cannot be used
    directly, but provides a base for all status reporters.
    The status reporter is threadsafe
    """

    def __init__(self, name):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.name = name
        self.lock = threading.Lock()
        self.status_holders = []

    def add_status_holder(self, holder):
        if not holder in self.status_holders:
            self.status_holders.append(holder)

    def get_elements(self):
        """
        Return all elements that should be reported
        """
        elements = []
        for holder in self.status_holders:
            elements += holder.get_elements()
        return elements

    def get_events(self):
        """
        Return all elements that should be reported
        """
        events = []
        for holder in self.status_holders:
            events += holder.get_events()
        return events

    def report_now(self):
        """
        Forces the reporter to report now
        """
        pass


class OnChangeStatusReporter(StatusReporter):

    """
    A basic status reporter which calls 'report(element)' whenever
    it is changed
    """
    elements = []

    def add_element(self, element):
        """
        Add element to this reporter
        """
        element.add_callback(self.report)

    def remove_element(self, element):
        """
        Remove an element from this reporter
        """
        element.remove_callback(self.report)

    def report(self, element):
        """
        This function must be implemented by and extending class. Does nothing.
        """
        pass  # To be implemented by the actual reporter


class PeriodicStatusReporter(StatusReporter):

    """
    Base class for a periodic status reporter, calling report(self)
    at given times.  To ensure a nice shutdown, execute stop() when
    stopping.

    """

    def __init__(self, name, frequency, error_handler=None):
        """
        Frequency is a float in seconds
        Error-handler will get an error code and a string as parameters,
        the meaning will be up to the implemenation of the
        PeriodicStatusReporter.
        """

        StatusReporter.__init__(self, name)
        self.frequency = frequency
        self.parameters = []
        self.error_handler = error_handler

        # Set up the timer
        self.running = True
        self.create_timer()

    def create_timer(self):
        if self.frequency and self.frequency > 0:
            self.timer = threading.Timer(self.frequency, self.on_time_event)
            self.timer.setName("PeriodicStatusReporter_" + self.name)
            self.timer.setDaemon(True)
            self.timer.start()

    def stop(self, block=False):
        """
        Stop this reporter.  If block=True this function will not return
        until the reporter has actually stopped
        """
        self.timer.cancel()

        self.on_time_event()

        self.running = False
        self.timer.cancel()
        self.timer.join()

    def report(self):
        """
        This function must be overloaded, does nothing
        """
        raise Exception("Not implemented")

    def add_element(self, element):
        """
        Overload if you want your periodic reporter to only
        report certain elements of a holder. Normally this does
        nothing, but report fetches all elements
        """
        pass

    def on_time_event(self):
        """
        Callback function for timers
        """
        if self.running:
            self.create_timer()
            try:
                self.report()
            except Exception as e:
                self._logger.error("Status: error while reporting: %s", e)
                if self.error_handler:
                    try:
                        self.error_handler(0, str(e))
                    except:
                        pass
                else:
                    self._logger.error("Error but no error handler: %s", e)
                    # import traceback
                    # traceback.print_stack()

    def report_now(self):
        """
        Forces the reporter to report now
        """
        try:
            self.report()
        except Exception as e:
            self._logger.error("Status: error while reporting: %s", e)
            if self.error_handler:
                try:
                    self.error_handler(0, str(e))
                except:
                    pass
            else:
                self._logger.error("Error but no error handler: %s", e)
                # import traceback
                # traceback.print_stack()


if __name__ == "__main__":
    # Some basic testing (full unit tests are in StatusTest.py)

    logger.info("Run unit tests")
    raise SystemExit(-1)

########NEW FILE########
__FILENAME__ = TUDelftReporter
from Tribler.Core.Utilities.encoding import encode
from bz2 import compress
from time import time
import logging

from LivingLabReporter import LivingLabPeriodicReporter


class TUDelftReporter(LivingLabPeriodicReporter):
    host = "dispersyreporter.tribler.org"
    path = "/post.py"

    def __init__(self, name, frequency, public_key):
        LivingLabPeriodicReporter.__init__(self, name, frequency, public_key)
        # note: public_key is set to self.device_id
        self._logger = logging.getLogger(self.__class__.__name__)

    def report(self):
        self._logger.debug("TUDelftReporter: report")
        events = self.get_events()
        if events:
            events = [{"name": event.get_name(), "time": event.get_time(), "values": event.get_values()} for event in events]
            data = (time(), self.device_id.encode("HEX"), events)
            compressed = compress(encode(data))
            self._logger.debug("TUDelftReporter: posting %d bytes payload", len(compressed))
            self.post(compressed)
        else:
            self._logger.debug("TUDelftReporter: Nothing to report")

if __debug__:
    if __name__ == "__main__":
        from Tribler.Core.Statistics.Status.Status import get_status_holder

        status = get_status_holder("dispersy-simple-dispersy-test")
        status.add_reporter(TUDelftReporter("Periodically flush events to TUDelft", 5, "blabla"))
        status.create_and_add_event("foo", ["foo", "bar"])
        status.create_and_add_event("animals", ["bunnies", "kitties", "doggies"])
        status.create_and_add_event("numbers", range(255))

        from time import sleep
        sleep(15)

########NEW FILE########
__FILENAME__ = XmlPrinter
# Written by Njaal Borch
# see LICENSE.txt for license information
import logging

logger = logging.getLogger(__name__)


def to_unicode(string):
    """
    Function to change a string (unicode or not) into a unicode string
    Will try utf-8 first, then latin-1.
    TODO: Is there a better way?  There HAS to be!!!
    """

    if string.__class__ != str:
        return string
    try:
        return unicode(string, "utf-8")
    except:
        pass
    logger.warn("Warning: Fallback to latin-1 for unicode conversion")
    return unicode(string, "latin-1")


class XmlPrinter:

    """
    An XML printer that will print XML *with namespaces*

    Why minidom.toxml() does not do so really makes absolutenly no sense

    """

    def __init__(self, doc):
        """
        doc should be a xml.dom.minidom document

        """
        self._logger = logging.getLogger(self.__class__.__name__)

        self.root = doc
        self.namespace_counter = 0

    def to_xml(self, encoding="UTF8"):
        """
        Like minidom toxml, just using namespaces too
        """
        return self._toxml(self.root, indent='', newl='').encode(encoding, "replace")

    def to_pretty_xml(self, indent=' ', newl='\n', encoding="UTF8"):
        """
        Like minidom toxml, just using namespaces too
        """
        return self._toxml(self.root, indent, newl).encode(encoding, "replace")

    def _make_header(self, encoding):

        return u'<?xml version="1.0" encoding="%s" ?>\n' % encoding

    def _new_namespace(self, namespace):
        # Make new namespace
        ns_short = "ns%d" % self.namespace_counter
        self.namespace_counter += 1
        return ns_short

    def _toxml(self, element, indent=' ', newl='\n', encoding='UTF8', namespaces=None):
        """
        Recursive, internal function - do not use directly
        """

        if not element:
            return ""

        if not namespaces:
            namespaces = {}
        buffer = u""
        define_ns_list = []

        if element == self.root:
            # Print the header
            buffer = self._make_header(encoding)

        if element.nodeType == element.TEXT_NODE:
            buffer += indent + to_unicode(element.nodeValue) + newl
            return buffer
        if element.nodeType == element.ELEMENT_NODE:
            ns = element.namespaceURI
            name = to_unicode(element.localName)
            if name.find(" ") > -1:
                raise Exception("Refusing spaces in tag names")

            if ns in namespaces:
                ns_short = namespaces[ns]
                define_ns = False
            else:
                if ns not in ["", None]:
                    ns_short = self._new_namespace(ns)
                    define_ns_list.append((ns, ns_short))
                else:
                    ns_short = None

                define_ns = True
                namespaces[ns] = ns_short

            # Should we define more namespaces?  Will peak into the
            # children and see if there are any
            for child in element.childNodes:
                if child.nodeType != child.ELEMENT_NODE:
                    continue

                if child.namespaceURI not in namespaces and \
                    child.namespaceURI not in [None, ""]:
                    # Should define this one too!
                    new_ns = self._new_namespace(child.namespaceURI)
                    define_ns_list.append((child.namespaceURI, new_ns))
                    namespaces[child.namespaceURI] = new_ns
            buffer += indent

            # If we have no children, we will write <tag/>
            if not element.hasChildNodes():
                if ns != None:
                    if define_ns:
                        if ns_short:
                            buffer += '<%s:%s xmlns:%s="%s"/>%s' %\
                                      (ns_short, name, ns_short, ns, newl)
                        else:
                            buffer += '<%s xmlns="%s"/>%s' % (name, ns, newl)
                    else:
                        if ns_short:
                            buffer += '<%s:%s/>%s' % (ns_short, name, newl)
                        else:
                            buffer += '<%s/>%s' % (name, newl)

                else:
                    buffer += '<%s/>%s' % (name, newl)

                # Clean up - namespaces is passed as a reference, and is
                # as such not cleaned up.  Let it be so to save some speed
                for (n, short) in define_ns_list:
                    del namespaces[n]
                return buffer

            # Have children
            ns_string = ""
            if len(define_ns_list) > 0:
                for (url, short) in define_ns_list:
                    ns_string += ' xmlns:%s="%s"' % (short, url)

            if ns != None:
                if define_ns:
                    if ns_short:
                        # Define all namespaces of next level children too
                        buffer += '<%s:%s xmlns:%s="%s"%s>%s' %\
                                  (ns_short, name, ns_short, ns, ns_string, newl)
                    else:
                        buffer += '<%s xmlns="%s"%s>%s' % (name, ns, ns_string, newl)
                else:
                    if ns_short:
                        buffer += '<%s:%s%s>%s' % (ns_short, name, ns_string, newl)
                    else:
                        buffer += '<%s%s>%s' % (name, ns_string, newl)
            elif ns_string:
                buffer += '<%s %s>%s' % (name, ns_string, newl)
            else:
                buffer += '<%s>%s' % (name, newl)

            # Recursively process
            for child in element.childNodes:
                new_indent = indent
                if new_indent:
                    new_indent += "  "
                buffer += self._toxml(child, new_indent, newl, encoding, namespaces)
            if ns_short:
                buffer += "%s</%s:%s>%s" % (indent, ns_short, name, newl)
            else:
                buffer += "%s</%s>%s" % (indent, name, newl)

            for (n, short) in define_ns_list:
                del namespaces[n]
            try:
                return buffer
            except Exception as e:
                self._logger.error("-----------------")
                self._logger.error("Exception: %s", e)
                self._logger.error("Buffer: %s", buffer)
                self._logger.error("-----------------")
                raise e

        raise Exception("Could not serialize DOM")

########NEW FILE########
__FILENAME__ = SwiftDef
# Written by Arno Bakker
# see LICENSE.txt for license information

import os
import sys
import urlparse
import binascii
import subprocess
import random
import time
import logging

from Tribler.Core.Base import ContentDefinition
from Tribler.Core.simpledefs import SWIFT_URL_SCHEME
from Tribler.Core.exceptions import OperationNotEnabledByConfigurationException
from Tribler.Core.Swift.util import filelist2swiftspec


class SwiftDef(ContentDefinition):

    """ Definition of a swift swarm, that is, the root hash (video-on-demand)
    and any optional peer-address sources. """

    def __init__(self, roothash=None, tracker=None, chunksize=None,duration=None):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.readonly = False
        self.roothash = roothash
        self.tracker = tracker
        self.chunksize = chunksize
        self.duration = duration
        self.files = []
        self.multifilespec = None
        self.name = None

    #
    # Class methods for creating a SwiftDef from an URL or .spec file (multi-file swarm)
    #
    def load_from_url(url):
        """
        If the URL starts with the swift URL scheme, we convert the URL to a
        SwiftDef.

        Scheme: tswift:/roothash-as-hex
                tswift://tracker/roothash-as-hex
                tswift://tracker/roothash-as-hex$chunk-size-in-bytes
                tswift://tracker/roothash-as-hex@duration-in-secs
                tswift://tracker/roothash-as-hex$chunk-size-in-bytes@duration-in-secs

        Note: swift URLs pointing a file in a multi-file content asset
        cannot be loaded by this method. Load the base URL via this method and
        specify the file you want to download via
        DownloadConfig.set_selected_files().

        @param url URL
        @return SwiftDef.
        """
        # Class method, no locking required
        (roothash, tracker, chunksize, duration) = parse_url(url)
        s = SwiftDef(roothash, tracker, chunksize, duration)
        s.readonly = True
        return s
    load_from_url = staticmethod(load_from_url)

    def is_swift_url(url):
        return isinstance(url, str) and url.startswith(SWIFT_URL_SCHEME)
    is_swift_url = staticmethod(is_swift_url)

    #
    # ContentDefinition interface
    #
    def get_def_type(self):
        """ Returns the type of this Definition
        @return string
        """
        return "swift"

    def get_name(self):
        """ Returns the user-friendly name of this Definition
        @return string
        """
        return self.name or self.get_roothash_as_hex()

    def set_name(self, name):
        """ Sets the user-friendly name of this Definition
        @param name
        """
        self.name = name

    def get_id(self):
        """ Returns a identifier for this Definition
        @return string
        """
        return self.get_roothash()

    def get_live(self):
        """ Whether swift swarm is a live stream
        @return Boolean
        """
        return False

    #
    # Swift specific
    #
    def get_roothash(self):
        """ Returns the roothash of the swift swarm.
        @return A string of length 20. """
        return self.roothash

    def get_roothash_as_hex(self):
        """ Returns the roothash of the swift swarm.
        @return A string of length 40, of 20 concatenated 2-char hex bytes. """

        return binascii.hexlify(self.roothash)

    def set_tracker(self, url):
        """ Sets the tracker
        @param url The tracker URL.
        """
        self.tracker = url

    def get_tracker(self):
        """ Returns the tracker URL.
        @return URL """
        return self.tracker

    def get_url(self):
        """ Return the basic URL representation of this SwiftDef.
        @return URL
        """
        url = SWIFT_URL_SCHEME + ':'
        if self.tracker is not None:
            url += '//' + self.tracker
        url += '/' + binascii.hexlify(self.roothash)
        return url

    def get_url_with_meta(self):
        """ Return the URL representation of this SwiftDef with extra
        metadata, e.g. duration.
        @return URL
        """
        url = self.get_url()
        if self.duration is not None:
            url += '@' + str(self.duration)
        return url

    def get_duration(self):
        """ Return the (optional) duration of this SwiftDef or None
        @return a number of seconds
        """
        return self.duration

    def get_chunksize(self):
        """ Return the (optional) chunksize of this SwiftDef or None
        @return a number of bytes
        """
        return self.chunksize

    def get_multifilespec(self):
        """ Return the multi-file spec of this SwiftDef (only when creating
        a new swift def)
        @return a string in multi-file spec format.
        """
        return self.multifilespec

    # SWIFTSEED/MULTIFILE
    def add_content(self, inpath, outpath=None):
        """
        Add a file or directory to this Swift definition. When adding a
        directory, all files in that directory will be added to the torrent.

        One can add multiple files and directories to a Swift definition.
        In that case the "outpath" parameter must be used to indicate how
        the files/dirs should be named in the multi-file specification.

        To seed the content via the core you will need to start the download
        with the dest_dir set to the top-level directory containing the files
        and directories to seed.

        @param inpath Absolute name of file or directory on local filesystem,
        as Unicode string.
        @param outpath (optional) Name of the content to use in the torrent def
        as Unicode string.
        """
        if self.readonly:
            raise OperationNotEnabledByConfigurationException()

        encoded_outpath = None
        if outpath:
            encoded_outpath = outpath
            if sys.platform == "win32":
                encoded_outpath = encoded_outpath.replace("\\", "/")
            encoded_outpath = encoded_outpath.encode("utf-8")

        s = os.stat(inpath)
        d = {'inpath': inpath, 'outpath': encoded_outpath, 'length': s.st_size}
        self.files.append(d)

    def create_multifilespec(self):
        specfn = None
        if len(self.files) > 1:
            filelist = []
            for d in self.files:
                specpath = d['outpath'].encode("UTF-8")
                if sys.platform == "win32":
                    specpath.replace("\\", "/")
                filelist.append((specpath, d['length']))

            self.multifilespec = filelist2swiftspec(filelist)

            self._logger.info("SwiftDef: multifile %s", self.multifilespec)

            return self.multifilespec
        else:
            return None


    def finalize(self, binpath, userprogresscallback=None, destdir='.',removetemp=False):
        """
        Calculate root hash (time consuming).

        The also userprogresscallback will be called by the calling thread
        periodically, with a progress percentage as argument.

        The userprogresscallback function will be called by the calling thread.

        @param binpath  OS path of swift binary.
        @param userprogresscallback Function accepting a fraction as first
        argument.
        @param destdir OS path of where to store temporary files.
        @param removetemp Boolean, remove temporary files or not
        @return filename of multi-spec definition or None (single-file)
        """
        if userprogresscallback is not None:
            userprogresscallback(0.0)

        specpn = None
        if len(self.files) > 1:
            if self.multifilespec is None:
                self.create_multifilespec()

            if userprogresscallback is not None:
                userprogresscallback(0.2)

            specfn = "multifilespec-p" + str(os.getpid()) +"-r"+str(random.random())+".txt"
            specpn = os.path.join(destdir, specfn)

            f = open(specpn, "wb")
            f.write(self.multifilespec)
            f.close()

            filename = specpn
        else:
            filename = self.files[0]['inpath']

        urlfn = "swifturl-p" + str(os.getpid()) +"-r"+str(random.random())+".txt"
        urlpn = os.path.join(destdir, urlfn)

        args = []
        # Arno, 2012-07-09: Unicode problems with popen
        if sys.platform == "win32":
            args.append(binpath.encode(sys.getfilesystemencoding()))
        else:
            args.append(binpath)

        # Arno, 2012-05-29: Hack. Win32 getopt code eats first arg when Windows app
        # instead of CONSOLE app.
        args.append("-j")
        if self.tracker is not None:
            args.append("-t")
            args.append(self.tracker)
        args.append("--printurl")

        if sys.platform == "win32":
            # Swift on Windows expects command line arguments as UTF-16.
            # popen doesn't allow us to pass params in UTF-16, hence workaround.
            # Format = hex encoded UTF-8
            urlpnsafe = binascii.hexlify(urlpn.encode("UTF-8"))
            args.append("-2")
            args.append(urlpnsafe)  # encoding that swift expects
        else:
            args.append("-r")
            args.append(urlpn)

        if sys.platform == "win32":
            args.append("-1")
            fnsafe = binascii.hexlify(filename.encode("UTF-8"))
            args.append(fnsafe)  # encoding that swift expects
        else:
            args.append("-f")
            args.append(filename)
        # args.append("-B") # DEBUG Hack

        self._logger.debug("SwiftDef: finalize: Running %s", args)

        if sys.platform == "win32":
            creationflags = subprocess.CREATE_NEW_PROCESS_GROUP
        else:
            creationflags = 0
        pobj = subprocess.Popen(args, stdout=subprocess.PIPE, cwd='.', creationflags=creationflags)

        if userprogresscallback is not None:
            userprogresscallback(0.6)

        # Arno, 2012-05-25: When running in binary on windows, swift is a
        # windows app, so no console output. Hence, write swift URL to disk.
        count = 0.0
        while count < 600.0:  # 10 minutes
            pobj.poll()
            if pobj.returncode is not None:
                break
            time.sleep(1)
            count += 1.0
            if userprogresscallback is not None:
                userprogresscallback(0.6 + count / 1000.0)

        f = open(urlpn, "rb")
        url = f.read()
        f.close()

        try:
            os.remove(urlpn)
        except:
            pass

        if url is None or len(url) == 0:
            self.roothash = '0' * 20
            self._logger.info("swift: finalize: Error calculating roothash")
            return None

        if userprogresscallback is not None:
            userprogresscallback(0.9)

        (self.roothash, self.tracker, self.chunksize, self.duration) = parse_url(url)
        self.readonly = True

        if removetemp and specpn is not None:
            try:
                os.remove(specpn)
            except:
                pass

            try:
                mbinmapfn = specpn + ".mbinmap"
                os.remove(mbinmapfn)
            except:
                pass

            try:
                mhashfn = specpn + ".mhash"
                os.remove(mhashfn)
            except:
                pass

        if userprogresscallback is not None:
            userprogresscallback(1.0)

        return specpn

    def save_multifilespec(self, filename):
        """
        Store the multi-file spec generated by finalize() if multiple
        files were added with add_content() to filename.
        @param filename An absolute Unicode path name.
        """
        if not self.readonly:
            raise OperationNotEnabledByConfigurationException()

        f = open(filename, "wb")
        f.write(self.multifilespec)
        f.close()


def parse_url(url):
    p = urlparse.urlparse(url)
    roothash = binascii.unhexlify(p.path[1:41])
    if p.netloc == "":
        tracker = None
    else:
        tracker = p.netloc

    cidx = p.path.find('$')
    didx = p.path.find('@')

    if cidx != -1:
        if didx == -1:
            chunksize = int(p.path[cidx + 1:])
        else:
            chunksize = int(p.path[cidx + 1:didx])
    else:
        chunksize = None

    if didx != -1:
        duration = int(p.path[didx + 1:])
    else:
        duration = None

    return (roothash, tracker, chunksize, duration)

########NEW FILE########
__FILENAME__ = SwiftDownloadImpl
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TODO:
# - set rate limits
#     * Check if current policy of limiting hint_out_size is sane.
#         - test case: start unlimited, wait 10 s, then set to 512 K. In one
#           test speed dropped to few bytes/s then rose again to 512 K.
#     * upload rate limit
#     * test if you get 512K for each swarm when you download two in parallel
#       in one swift proc.
#
# - HASHCHECKING
#     * get progress from swift

#     * Current cmdgw impl will open and thus hashcheck on main thread, halting
#       all network traffic, etc. in all other swarms. BitTornado interleaves
#       on netw thread.
#           - Run cmdgw on separate thread(s)?
#
# - STATS
#     *  store 2 consecutive more info dicts and calc speeds, and convert
#        those to DownloadState.get_peerlist() format.
#
# - BUGS
#     * Try to recv ICMP port unreach on Mac such that we can clean up Channel
#       (Linux done)
#

import os
import time
import shutil
import logging

from traceback import print_exc
from Tribler.Core import NoDispersyRLock

from Tribler.Core.simpledefs import DOWNLOAD, UPLOAD, DLSTATUS_WAITING4HASHCHECK, \
    DLSTATUS_STOPPED, DLSTATUS_SEEDING, DLMODE_VOD, DLMODE_NORMAL, \
    PERSISTENTSTATE_CURRENTVERSION, dlstatus_strings
from Tribler.Core.exceptions import OperationNotEnabledByConfigurationException
from Tribler.Core.DownloadState import DownloadState
from Tribler.Core.DownloadConfig import DownloadConfigInterface
from Tribler.Main.globals import DownloadStartupConfig

# ARNOSMPTODO: MODIFY WITH cmdgw.cpp::CMDGW_PREBUFFER_BYTES_AS_LAYER
# Send PLAY after receiving 2^layer * 1024 bytes
CMDGW_PREBUFFER_BYTES = (2 ** 8) * 1024
SWIFT_ALIVE_CHECK_INTERVAL = 60.0


class SwiftDownloadImpl(DownloadConfigInterface):

    """ Download subclass that represents a swift download.
    The actual swift download takes places in a SwiftProcess.
    """

    def __init__(self, session, sdef):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.dllock = NoDispersyRLock()
        self.session = session
        self.sdef = sdef
        self.old_metadir = self.session.get_swift_meta_dir()

        # just enough so error saving and get_state() works
        self.error = None
        # To be able to return the progress of a stopped torrent, how far it got.
        self.progressbeforestop = 0.0

        # SwiftProcess performing the actual download.
        self.sp = None

        # spstatus
        self.dlstatus = DLSTATUS_WAITING4HASHCHECK
        self.dynasize = 0
        self.progress = 0.0
        self.curspeeds = {DOWNLOAD: 0.0, UPLOAD: 0.0}  # bytes/s
        self.numleech = 0
        self.numseeds = 0
        self.contentbytes = {DOWNLOAD: 0, UPLOAD: 0}  # bytes

        self.done = False  # when set it means this download is being removed
        self.midict = {}
        self.time_seeding = [0, None]
        self.total_up = 0
        self.total_down = 0

        self.askmoreinfo = False
        self.vod_url = None

    #
    # Download Interface
    #
    def get_def(self):
        return self.sdef

    #
    # DownloadImpl
    #

    #
    # Creating a Download
    #
    def setup(self, dcfg=None, pstate=None, initialdlstatus=None, lm_network_engine_wrapper_created_callback=None):
        """
        Create a Download object. Used internally by Session.
        @param dcfg DownloadStartupConfig or None (in which case
        a new DownloadConfig() is created and the result
        becomes the runtime config of this Download.
        """
        # Called by any thread, assume sessionlock is held
        try:
            self.dllock.acquire()  # not really needed, no other threads know of this object

            # Copy dlconfig, from default if not specified
            if dcfg is None:
                cdcfg = DownloadStartupConfig()
            else:
                cdcfg = dcfg
            self.dlconfig = cdcfg.dlconfig.copy()
            self.dlconfig.lock = self.dllock

            # Things that only exist at runtime
            self.dlruntimeconfig = {}
            self.dlruntimeconfig['max_desired_upload_rate'] = 0
            self.dlruntimeconfig['max_desired_download_rate'] = 0

            if pstate and pstate.has_option('state', 'dlstate'):
                dlstate = pstate.get('state', 'dlstate')
                if 'time_seeding' in dlstate:
                    self.time_seeding = [dlstate['time_seeding'], None]
                if 'total_up' in dlstate:
                    self.total_up = dlstate['total_up']
                if 'total_down' in dlstate:
                    self.total_down = dlstate['total_down']

            self._logger.debug("SwiftDownloadImpl: setup: initialdlstatus %s %s", repr(self.sdef.get_roothash_as_hex()), initialdlstatus)

            # Note: initialdlstatus now only works for STOPPED
            if initialdlstatus != DLSTATUS_STOPPED:
                self.create_engine_wrapper(lm_network_engine_wrapper_created_callback, pstate)

            self.dllock.release()
        except Exception as e:
            print_exc()
            self.set_error(e)
            self.dllock.release()

    def create_engine_wrapper(self, lm_network_engine_wrapper_created_callback, pstate, initialdlstatus=None):
        network_create_engine_wrapper_lambda = lambda: self.network_create_engine_wrapper(lm_network_engine_wrapper_created_callback, pstate, initialdlstatus)
        self.session.lm.rawserver.add_task(network_create_engine_wrapper_lambda)

    def network_create_engine_wrapper(self, lm_network_engine_wrapper_created_callback, pstate, initialdlstatus=None):
        """ Called by any thread, assume dllock already acquired """
        self._logger.debug("SwiftDownloadImpl: create_engine_wrapper()")

        self.dlconfig.set_callback(self.dlconfig_changed_callback)

        move_files = (not self.dlconfig.has_option('downloadconfig', 'swiftmetadir')) and not os.path.isdir(self.get_dest_dir())

        metadir = self.get_swift_meta_dir()
        if not metadir:
            metadir = self.session.get_swift_meta_dir()
            self.set_swift_meta_dir(metadir)

        if not os.path.exists(metadir):
            os.makedirs(metadir)

        if move_files:
            # We must be dealing with a checkpoint from a previous release (<6.1.0). Move the swift metadata to the right directory.
            is_multifile = self.get_dest_dir().endswith("." + self.get_def().get_roothash_as_hex())
            path_old = self.get_dest_dir()
            path_new = os.path.join(metadir, self.get_def().get_roothash_as_hex() if is_multifile else os.path.split(self.get_dest_dir())[1])
            try:
                if is_multifile:
                    shutil.move(path_old, path_new + '.mfspec')
                    self.set_dest_dir(os.path.split(self.get_dest_dir())[0])
                shutil.move(path_old + '.mhash', path_new + '.mhash')
                shutil.move(path_old + '.mbinmap', path_new + '.mbinmap')
            except:
                print_exc()

        # Synchronous: starts process if needed
        self.sp = self.session.lm.spm.get_or_create_sp(self.session.get_swift_working_dir(), self.session.get_torrent_collecting_dir(), self.get_swift_listen_port(), self.get_swift_httpgw_listen_port(), self.get_swift_cmdgw_listen_port())
        if self.sp:
            self.sp.start_download(self)

            self.session.lm.rawserver.add_task(self.network_check_swift_alive, SWIFT_ALIVE_CHECK_INTERVAL)

        # Arno: if used, make sure to switch to network thread first!
        # if lm_network_engine_wrapper_created_callback is not None:
        #    sp = self.sp
        #    exc = self.error
        #    lm_network_engine_wrapper_created_callback(self,sp,exc,pstate)

    #
    # SwiftProcess callbacks
    #
    def i2ithread_info_callback(self, dlstatus, progress, dynasize, dlspeed, ulspeed, numleech, numseeds, contentdl, contentul):
        self.dllock.acquire()
        try:
            if dlstatus == DLSTATUS_SEEDING and self.dlstatus != dlstatus:
                # started seeding
                self.time_seeding[0] = self.get_seeding_time()
                self.time_seeding[1] = time.time()
            elif dlstatus != DLSTATUS_SEEDING and self.dlstatus != dlstatus:
                # stopped seeding
                self.time_seeding[0] = self.get_seeding_time()
                self.time_seeding[1] = None

            self.dlstatus = dlstatus
            self.dynasize = dynasize
            # TODO: Temporary fix for very high progress even though nothing has been downloaded yet.
            self.progress = progress if progress <= 1.0 else 0.0
            self.curspeeds[DOWNLOAD] = dlspeed
            self.curspeeds[UPLOAD] = ulspeed
            self.numleech = numleech
            self.numseeds = numseeds
            self.contentbytes = {DOWNLOAD: contentdl, UPLOAD: contentul}
        finally:
            self.dllock.release()

    def i2ithread_vod_event_callback(self, httpurl):
        self._logger.debug("SwiftDownloadImpl: i2ithread_vod_event_callback: ENTER %s mode %s", httpurl, self.get_mode())

        self.dllock.acquire()
        try:
            if self.get_mode() != DLMODE_VOD:
                return

            # Fix firefox idiosyncrasies
            duration = self.sdef.get_duration()
            if duration is not None:
                httpurl += '@' + duration

            self._logger.debug("SwiftDownloadImpl: i2ithread_vod_event_callback %s %s", httpurl)

            self.vod_url = httpurl

        finally:
            self.dllock.release()

    def i2ithread_moreinfo_callback(self, midict):
        self.dllock.acquire()
        try:
            # print >>sys.stderr,"SwiftDownloadImpl: Got moreinfo",midict.keys()
            self.midict = midict
        finally:
            self.dllock.release()

    #
    # Retrieving DownloadState
    #
    def get_status(self):
        """ Returns the status of the download.
        @return DLSTATUS_* """
        self.dllock.acquire()
        try:
            return self.dlstatus
        finally:
            self.dllock.release()

    def get_dynasize(self):
        """ Returns the size of the swift content. Note this may vary
        (generally ~1KiB because of dynamic size determination by the
        swift protocol
        @return long
        """
        self.dllock.acquire()
        try:
            return self.dynasize
        finally:
            self.dllock.release()

    def get_progress(self):
        """ Return fraction of content downloaded.
        @return float 0..1
        """
        self.dllock.acquire()
        try:
            return self.progress
        finally:
            self.dllock.release()

    def get_current_speed(self, dir):
        """ Return last reported speed in bytes/s
        @return float
        """
        self.dllock.acquire()
        try:
            return self.curspeeds[dir]
        finally:
            self.dllock.release()

    def get_moreinfo_stats(self, dir):
        """ Return last reported more info dict
        @return dict
        """
        self.dllock.acquire()
        try:
            return self.midict
        finally:
            self.dllock.release()

    def get_seeding_time(self):
        return self.time_seeding[0] + (time.time() - self.time_seeding[1] if self.time_seeding[1] != None else 0)

    def get_total_up(self):
        return self.total_up + self.contentbytes[UPLOAD]

    def get_total_down(self):
        return self.total_down + self.contentbytes[DOWNLOAD]

    def get_seeding_statistics(self):
        seeding_stats = {}
        seeding_stats['total_up'] = self.get_total_up()
        seeding_stats['total_down'] = self.get_total_down()
        seeding_stats['time_seeding'] = self.get_seeding_time()
        return seeding_stats

    def network_get_stats(self, getpeerlist):
        """
        @return (status,stats,logmsgs,coopdl_helpers,coopdl_coordinator)
        """
        # dllock held
        # ARNOSMPTODO: Have a status for when swift is hashchecking the file on disk

        if self.sp is None:
            status = DLSTATUS_STOPPED
        else:
            status = self.dlstatus

        stats = {}
        stats['down'] = self.curspeeds[DOWNLOAD]
        stats['up'] = self.curspeeds[UPLOAD]
        stats['frac'] = self.progress
        stats['stats'] = self.network_create_statistics_reponse()
        stats['time'] = self.network_calc_eta()
        stats['vod_prebuf_frac'] = self.network_calc_prebuf_frac()
        stats['vod'] = True
        # ARNOSMPTODO: no hard check for suff bandwidth, unlike BT1Download
        stats['vod_playable'] = self.progress == 1.0 or (self.network_calc_prebuf_frac() == 1.0 and self.curspeeds[DOWNLOAD] > 0.0)
        stats['vod_playable_after'] = self.network_calc_prebuf_eta()
        stats['vod_stats'] = self.network_get_vod_stats()
        stats['spew'] = self.network_create_spew_from_peerlist()

        seeding_stats = self.get_seeding_statistics()

        logmsgs = []
        return (status, stats, seeding_stats, logmsgs)

    def network_create_statistics_reponse(self):
        return SwiftStatisticsResponse(self.numleech, self.numseeds, self.midict)

    def network_calc_eta(self):
        bytestogof = (1.0 - self.progress) * float(self.dynasize)
        dlspeed = max(0.000001, self.curspeeds[DOWNLOAD])
        return bytestogof / dlspeed

    def network_calc_prebuf_frac(self):
        gotbytesf = self.progress * float(self.dynasize)
        prebuff = float(CMDGW_PREBUFFER_BYTES)
        return min(1.0, gotbytesf / prebuff)

    def network_calc_prebuf_eta(self):
        bytestogof = (1.0 - self.network_calc_prebuf_frac()) * float(CMDGW_PREBUFFER_BYTES)
        dlspeed = max(0.000001, self.curspeeds[DOWNLOAD])
        return bytestogof / dlspeed

    def network_get_vod_stats(self):
        # More would have to be sent from swift process to set these correctly
        d = {}
        d['played'] = None
        d['late'] = None
        d['dropped'] = None
        d['stall'] = None
        d['pos'] = None
        d['prebuf'] = None
        d['firstpiece'] = 0
        d['npieces'] = ((self.dynasize + 1023) / 1024)
        return d

    def network_create_spew_from_peerlist(self):
        if not 'channels' in self.midict:
            return []

        plist = []
        channels = self.midict['channels']
        for channel in channels:
            d = {}
            d['ip'] = channel['ip']
            d['port'] = channel['port']
            d['utotal'] = channel['bytes_up']
            d['dtotal'] = channel['bytes_down']
            plist.append(d)

        return plist

    #
    # Retrieving DownloadState
    #
    def set_state_callback(self, usercallback, getpeerlist=False, delay=0.0):
        """ Called by any thread """
        self.dllock.acquire()
        try:
            network_get_state_lambda = lambda: self.network_get_state(usercallback, getpeerlist)
            # First time on general rawserver
            self.session.lm.rawserver.add_task(network_get_state_lambda, delay)
        finally:
            self.dllock.release()

    def network_get_state(self, usercallback, getpeerlist, sessioncalling=False):
        """ Called by network thread """
        self.dllock.acquire()
        try:
            if self.sp is None:
                self._logger.debug("SwiftDownloadImpl: network_get_state: Download not running")
                ds = DownloadState(self, DLSTATUS_STOPPED, self.error, self.progressbeforestop, seeding_stats=self.get_seeding_statistics())
            else:
                (status, stats, seeding_stats, logmsgs) = self.network_get_stats(getpeerlist)
                ds = DownloadState(self, status, self.error, self.get_progress(), stats=stats, seeding_stats=seeding_stats, logmsgs=logmsgs)
                self.progressbeforestop = ds.get_progress()

            if sessioncalling:
                return ds

            # Invoke the usercallback function via a new thread.
            # After the callback is invoked, the return values will be passed to
            # the returncallback for post-callback processing.
            if not self.done:
                self.session.uch.perform_getstate_usercallback(usercallback, ds, self.sesscb_get_state_returncallback)
        finally:
            self.dllock.release()

    def sesscb_get_state_returncallback(self, usercallback, when, newgetpeerlist):
        """ Called by SessionCallbackThread """
        self.dllock.acquire()
        try:
            if when > 0.0 and not self.done:
                # Schedule next invocation, either on general or DL specific
                # Note this continues when dl is stopped.
                network_get_state_lambda = lambda: self.network_get_state(usercallback, newgetpeerlist)
                self.session.lm.rawserver.add_task(network_get_state_lambda, when)
        finally:
            self.dllock.release()

    #
    # Download stop/resume
    #
    def stop(self):
        """ Called by any thread """
        self.stop_remove(False, removestate=False, removecontent=False)

    def stop_remove(self, removedl, removestate=False, removecontent=False):
        """ Called by any thread. Called on Session.remove_download() """
        # Arno, 2013-01-29: This download is being removed, not just stopped.
        self.done = removedl
        self.network_stop(removestate=removestate, removecontent=removecontent)

    def network_stop(self, removestate, removecontent):
        """ Called by network thread, but safe for any """
        self.dllock.acquire()
        try:
            self._logger.debug("SwiftDownloadImpl: network_stop %s", repr(self.sdef.get_name()))

            pstate = self.network_get_persistent_state()
            if self.sp is not None:
                self.sp.remove_download(self, removestate, removecontent)
                self.session.lm.spm.release_sp(self.sp)
                self.sp = None

            self.time_seeding = [self.get_seeding_time(), None]

            # Offload the removal of the dlcheckpoint to another thread
            if removestate:
                # To remove:
                # 1. Core checkpoint (if any)
                # 2. .mhash file
                # 3. content (if so desired)

                # content and .mhash file is removed by swift engine if requested
                roothash = self.sdef.get_roothash()
                self.session.uch.perform_removestate_callback(roothash, None)

            return (self.sdef.get_roothash(), pstate)
        finally:
            self.dllock.release()

    def get_content_dest(self):
        """ Returns the file to which the downloaded content is saved. """
        return os.path.join(self.get_dest_dir(), self.sdef.get_roothash_as_hex())

    def restart(self, initialdlstatus=None):
        """ Restart the Download """
        # Called by any thread
        self._logger.debug("SwiftDownloadImpl: restart: %s", self.sdef.get_name())
        self.dllock.acquire()
        try:
            if self.sp is None:
                self.error = None  # assume fatal error is reproducible
                self.create_engine_wrapper(self.session.lm.network_engine_wrapper_created_callback, None, initialdlstatus=initialdlstatus)

            # No exception if already started, for convenience
        finally:
            self.dllock.release()

    #
    # Config parameters that only exists at runtime
    #
    def set_max_desired_speed(self, direct, speed):
        self._logger.debug("Download: set_max_desired_speed %s %s", direct, speed)
        # if speed < 10:
        #    print_stack()

        self.dllock.acquire()
        if direct == UPLOAD:
            self.dlruntimeconfig['max_desired_upload_rate'] = speed
        else:
            self.dlruntimeconfig['max_desired_download_rate'] = speed
        self.dllock.release()

    def get_max_desired_speed(self, direct):
        self.dllock.acquire()
        try:
            if direct == UPLOAD:
                return self.dlruntimeconfig['max_desired_upload_rate']
            else:
                return self.dlruntimeconfig['max_desired_download_rate']
        finally:
            self.dllock.release()

    def get_dest_files(self, exts=None):
        """
        Returns (None,destfilename)
        """
        if exts is not None:
            raise OperationNotEnabledByConfigurationException()

        f2dlist = []
        diskfn = self.get_content_dest()
        f2dtuple = (None, diskfn)
        f2dlist.append(f2dtuple)
        return f2dlist

    #
    # Persistence
    #
    def checkpoint(self):
        """ Called by any thread """
        # Arno, 2012-05-15. Currently this is safe to call from any thread.
        # Need this for torrent collecting via swift.
        self.network_checkpoint()

    def network_checkpoint(self):
        """ Called by network thread """
        self.dllock.acquire()
        try:
            pstate = self.network_get_persistent_state()
            if self.sp is not None:
                self.sp.checkpoint_download(self)
            return (self.sdef.get_roothash(), pstate)
        finally:
            self.dllock.release()

    def network_get_persistent_state(self):
        """ Assume dllock already held """

        pstate = self.dlconfig.copy()

        pstate.set('downloadconfig', 'name', self.sdef.get_name())

        # Reset unpicklable params
        pstate.set('downloadconfig', 'mode', DLMODE_NORMAL)

        # Reset default metadatadir
        if self.get_swift_meta_dir() == self.old_metadir:
            pstate.set('downloadconfig', 'swiftmetadir', None)

        # Add state stuff
        if not pstate.has_section('state'):
            pstate.add_section('state')
        pstate.set('state', 'version', PERSISTENTSTATE_CURRENTVERSION)
        pstate.set('state', 'metainfo', self.sdef.get_url_with_meta())  # assumed immutable

        ds = self.network_get_state(None, False, sessioncalling=True)
        dlstate = {'status': ds.get_status(), 'progress': ds.get_progress(), 'swarmcache': None}
        dlstate.update(ds.get_seeding_statistics())
        pstate.set('state', 'dlstate', dlstate)

        self._logger.debug("SwiftDownloadImpl: netw_get_pers_state: status %s progress %s", dlstatus_strings[ds.get_status()], ds.get_progress())

        # Swift stores own state in .mhash and .mbinmap file
        pstate.set('state', 'engineresumedata', None)
        return pstate


    #
    # MOREINFO
    #
    def set_moreinfo_stats(self, enable):
        """ Called by any thread """

        # Arno, 2012-07-31: slight risk if process killed in between
        if self.askmoreinfo == enable:
            return
        self.askmoreinfo = enable

        if self.sp is not None:
            self.sp.set_moreinfo_stats(self, enable)

    #
    # External addresses
    #
    def add_peer(self, addr):
        """ Add a peer address from 3rd source (not tracker, not DHT) to this
        Download.
        @param (hostname_ip,port) tuple
        """
        if self.sp is not None:
            self.sp.add_peer(self, addr)
        else:
            self.session.lm.rawserver.add_task(lambda addr=addr: self.add_peer(addr), 1)

    #
    # Internal methods
    #
    def set_error(self, e):
        self.dllock.acquire()
        self.error = e
        self.dllock.release()

    #
    # Auto restart after swift crash
    #
    def network_check_swift_alive(self):
        self.dllock.acquire()
        try:
            if self.sp is not None and not self.done:
                if not self.sp.is_alive():
                    self._logger.debug("SwiftDownloadImpl: network_check_swift_alive: Restarting %s", repr(self.sdef.get_name()))
                    self.sp = None
                    self.restart()
        except:
            print_exc()
        finally:
            self.dllock.release()

        if not self.done:
            self.session.lm.rawserver.add_task(self.network_check_swift_alive, SWIFT_ALIVE_CHECK_INTERVAL)

    def dlconfig_changed_callback(self, section, name, new_value, old_value):
        if section == 'downloadconfig' and name in ['max_upload_rate', 'max_download_rate']:
            if self.sp is not None:
                direct = UPLOAD if name == 'max_upload_rate' else DOWNLOAD
                if self.get_max_speed(direct) != new_value:
                    self.sp.set_max_speed(self, direct, new_value)
        elif section == 'downloadconfig' and name in ['selected_files', 'correctedfilename', 'saveas', 'super_seeder']:
            return False
        return True


class SwiftStatisticsResponse:

    def __init__(self, numleech, numseeds, midict):
        # More would have to be sent from swift process to set these correctly
        self.numConCandidates = 0
        self.numConInitiated = 0
        self.have = None
        self.numSeeds = numseeds
        self.numPeers = numleech

        # Arno, 2012-05-23: At Niels' request
        self.upTotal = 0
        self.downTotal = 0
        try:
            self.upTotal = midict['bytes_up']
            self.downTotal = midict['bytes_down']
        except:
            pass

        try:
            self.rawUpTotal = midict['raw_bytes_up']
            self.rawDownTotal = midict['raw_bytes_down']
        except KeyError:
            self.rawUpTotal = 0
            self.rawDownTotal = 0

########NEW FILE########
__FILENAME__ = SwiftProcess
# Written by Arno Bakker
# see LICENSE.txt for license information

import sys
import subprocess
import random
import binascii
import urllib
import json
import logging
from threading import RLock, currentThread, Thread
from traceback import print_exc
from collections import defaultdict

from Tribler.Core.simpledefs import UPLOAD, DOWNLOAD, DLSTATUS_STOPPED_ON_ERROR
from Tribler.Utilities.FastI2I import FastI2IConnection

try:
    WindowsError
except NameError:
    WindowsError = Exception

DONE_STATE_WORKING = 0
DONE_STATE_EARLY_SHUTDOWN = 1
DONE_STATE_SHUTDOWN = 2


class SwiftProcess:

    """ Representation of an operating-system process running the C++ swift engine.
    A swift engine can participate in one or more swarms."""

    def __init__(self, binpath, workdir, zerostatedir, listenport, httpgwport, cmdgwport, spmgr):
        self._logger = logging.getLogger(self.__class__.__name__)

        # Called by any thread, assume sessionlock is held
        self.splock = RLock()
        self.binpath = binpath
        self.workdir = workdir
        self.zerostatedir = zerostatedir
        self.spmgr = spmgr

        # Main UDP listen socket
        if listenport is None:
            self.listenport = random.randint(10001, 10999)
        else:
            self.listenport = listenport
        # NSSA control socket
        if cmdgwport is None:
            self.cmdport = random.randint(11001, 11999)
        else:
            self.cmdport = cmdgwport
        # content web server
        if httpgwport is None:
            self.httpport = random.randint(12001, 12999)
        else:
            self.httpport = httpgwport

        # Security: only accept commands from localhost, enable HTTP gw,
        # no stats/webUI web server
        args = []
        # Arno, 2012-07-09: Unicode problems with popen
        args.append(self.binpath.encode(sys.getfilesystemencoding()))

        # Arno, 2012-05-29: Hack. Win32 getopt code eats first arg when Windows app
        # instead of CONSOLE app.
        args.append("-j")
        args.append("-l")  # listen port
        args.append("0.0.0.0:" + str(self.listenport))
        args.append("-c")  # command port
        args.append("127.0.0.1:" + str(self.cmdport))
        args.append("-g")  # HTTP gateway port
        args.append("127.0.0.1:" + str(self.httpport))

        if zerostatedir is not None:
            if sys.platform == "win32":
                # Swift on Windows expects command line arguments as UTF-16.
                # popen doesn't allow us to pass params in UTF-16, hence workaround.
                # Format = hex encoded UTF-8
                args.append("-3")
                zssafe = binascii.hexlify(zerostatedir.encode("UTF-8"))
                args.append(zssafe)  # encoding that swift expects
            else:
                args.append("-e")
                args.append(zerostatedir)
            args.append("-T")  # zero state connection timeout
            args.append("180")  # seconds
        # args.append("-B")  # Enable debugging on swift

        self._logger.debug("SwiftProcess: __init__: Running %s workdir %s", args, workdir)

        if sys.platform == "win32":
            creationflags = subprocess.CREATE_NEW_PROCESS_GROUP
        else:
            creationflags = 0

        # See also SwiftDef::finalize popen
        # We would really like to get the stdout and stderr without creating a new thread for them.
        # However, windows does not support non-files in the select command, hence we cannot integrate
        # these streams into the FastI2I thread
        # A proper solution would be to switch to twisted for the communication with the swift binary
        self.popen = subprocess.Popen(args, cwd=workdir, creationflags=creationflags, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        def read_and_print(socket):
            prefix = currentThread().getName() + ":"
            while True:
                line = socket.readline()
                if not line:
                    self._logger.info("%s readline returned nothing quitting", prefix)
                    break
                self._logger.info("%s %s", prefix, line.rstrip())
        self.popen_outputthreads = [Thread(target=read_and_print, args=(self.popen.stdout,), name="SwiftProcess_%d_stdout" % self.listenport), Thread(target=read_and_print, args=(self.popen.stderr,), name="SwiftProcess_%d_stderr" % self.listenport)]
        [thread.start() for thread in self.popen_outputthreads]

        self.roothash2dl = {}
        self.donestate = DONE_STATE_WORKING  # shutting down
        self.fastconn = None

        # callbacks for when swift detect a channel close
        self._channel_close_callbacks = defaultdict(list)

        # Only warn once when TUNNELRECV messages are received without us having a Dispersy endpoint.  This occurs after
        # Dispersy shutdown
        self._warn_missing_endpoint = True

    #
    # Instance2Instance
    #
    def start_cmd_connection(self):
        # Called by any thread, assume sessionlock is held

        if self.is_alive():
            self.fastconn = FastI2IConnection(self.cmdport, self.i2ithread_readlinecallback, self.connection_lost)
        else:
            self._logger.info("sp: start_cmd_connection: Process dead? returncode %s pid %s", self.popen.returncode, self.popen.pid)

    def i2ithread_readlinecallback(self, ic, cmd):
        # if DEBUG:
        # print >>sys.stderr,"sp: Got command #"+cmd+"#"

        if self.donestate != DONE_STATE_WORKING:
            return

        words = cmd.split()
        assert all(isinstance(word, str) for word in words)

        if words[0] == "TUNNELRECV":
            address, session = words[1].split("/")
            host, port = address.split(":")
            port = int(port)
            session = session.decode("HEX")
            length = int(words[2])

            # require LENGTH bytes
            if len(ic.buffer) < length:
                return length - len(ic.buffer)

            data = ic.buffer[:length]
            ic.buffer = ic.buffer[length:]

            try:
                self.roothash2dl["dispersy-endpoint"].i2ithread_data_came_in(session, (host, port), data)
            except KeyError:
                if self._warn_missing_endpoint:
                    self._warn_missing_endpoint = False
                    self._logger.error("sp: Dispersy endpoint is not available")

        else:
            roothash = binascii.unhexlify(words[1])

            if words[0] == "ERROR":
                self._logger.info("sp: i2ithread_readlinecallback: %s" % cmd)

            elif words[0] == "CLOSE_EVENT":
                roothash_hex = words[1]
                address = words[2].split(":")
                address = (address[0], int(address[1]))
                raw_bytes_up = int(words[3])
                raw_bytes_down = int(words[4])
                cooked_bytes_up = int(words[5])
                cooked_bytes_down = int(words[6])

                if roothash_hex in self._channel_close_callbacks:
                    for callback in self._channel_close_callbacks[roothash_hex]:
                        try:
                            callback(roothash_hex, address, raw_bytes_up, raw_bytes_down, cooked_bytes_up, cooked_bytes_down)
                        except:
                            pass
                for callback in self._channel_close_callbacks["ALL"]:
                    try:
                        callback(roothash_hex, address, raw_bytes_up, raw_bytes_down, cooked_bytes_up, cooked_bytes_down)
                    except:
                        pass

            self.splock.acquire()
            try:
                if roothash not in self.roothash2dl.keys():
                    self._logger.debug("sp: i2ithread_readlinecallback: unknown roothash %s", words[1])
                    return

                d = self.roothash2dl[roothash]
            except:
                # print >>sys.stderr,"GOT", words
                # print >>sys.stderr,"HAVE", [key.encode("HEX") for key in self.roothash2dl.keys()]
                raise
            finally:
                self.splock.release()

            # Hide NSSA interface for SwiftDownloadImpl
            if words[0] == "INFO":  # INFO HASH status dl/total
                dlstatus = int(words[2])
                pargs = words[3].split("/")
                dynasize = int(pargs[1])
                if dynasize == 0:
                    progress = 0.0
                else:
                    progress = float(pargs[0]) / float(pargs[1])
                dlspeed = float(words[4])
                ulspeed = float(words[5])
                numleech = int(words[6])
                numseeds = int(words[7])
                contentdl = 0  # bytes
                contentul = 0  # bytes
                if len(words) > 8:
                    contentdl = int(words[8])
                    contentul = int(words[9])
                d.i2ithread_info_callback(dlstatus, progress, dynasize, dlspeed, ulspeed, numleech, numseeds, contentdl, contentul)
            elif words[0] == "PLAY":
                # print >>sys.stderr,"sp: i2ithread_readlinecallback: Got PLAY",cmd
                httpurl = words[2]
                d.i2ithread_vod_event_callback(httpurl)
            elif words[0] == "MOREINFO":
                jsondata = cmd[len("MOREINFO ") + 40 + 1:]
                midict = json.loads(jsondata)
                d.i2ithread_moreinfo_callback(midict)
            elif words[0] == "ERROR":
                d.i2ithread_info_callback(DLSTATUS_STOPPED_ON_ERROR, 0.0, 0, 0.0, 0.0, 0, 0, 0, 0)

    #
    # Swift Mgmt interface
    #
    def start_download(self, d):
        self.splock.acquire()
        try:
            if self.donestate != DONE_STATE_WORKING or not self.is_alive():
                return

            roothash = d.get_def().get_roothash()
            roothash_hex = d.get_def().get_roothash_as_hex()

            # Before send to handle INFO msgs
            self.roothash2dl[roothash] = d
            url = d.get_def().get_url()

            # MULTIFILE
            if len(d.get_selected_files()) == 1:
                specpath = d.get_selected_files()[0]
                qpath = urllib.quote(specpath)
                url += "/" + qpath

            # Default is unlimited, so don't send MAXSPEED then
            maxdlspeed = d.get_max_speed(DOWNLOAD)
            if maxdlspeed == 0:
                maxdlspeed = None
            maxulspeed = d.get_max_speed(UPLOAD)
            if maxulspeed == 0:
                maxulspeed = None

            metadir = d.get_swift_meta_dir()

            self.send_start(url, roothash_hex=roothash_hex, maxdlspeed=maxdlspeed, maxulspeed=maxulspeed, destdir=d.get_dest_dir(), metadir=metadir)

        finally:
            self.splock.release()

    def add_download(self, d):
        self.splock.acquire()
        try:
            roothash = d.get_def().get_roothash()

            # Before send to handle INFO msgs
            self.roothash2dl[roothash] = d

        finally:
            self.splock.release()

    def remove_download(self, d, removestate, removecontent):
        self.splock.acquire()
        try:
            if self.donestate != DONE_STATE_WORKING or not self.is_alive():
                return

            roothash_hex = d.get_def().get_roothash_as_hex()

            self.send_remove(roothash_hex, removestate, removecontent)

            # After send to handle INFO msgs
            roothash = d.get_def().get_roothash()

            del self.roothash2dl[roothash]
        finally:
            self.splock.release()

    def get_downloads(self):
        self.splock.acquire()
        try:
            return self.roothash2dl.values()
        finally:
            self.splock.release()

    def get_pid(self):
        if self.popen is not None:
            return self.popen.pid
        else:
            return -1

    def get_listen_port(self):
        return self.listenport

    def set_max_speed(self, d, direct, speed):
        self.splock.acquire()
        try:
            if self.donestate != DONE_STATE_WORKING or not self.is_alive():
                return

            roothash_hex = d.get_def().get_roothash_as_hex()

            # In Tribler Core API  = unlimited. In Swift CMDGW API
            # 0 = none.
            if speed == 0.0:
                speed = 4294967296.0

            self.send_max_speed(roothash_hex, direct, speed)
        finally:
            self.splock.release()

    def checkpoint_download(self, d):
        self.splock.acquire()
        try:
            # Arno, 2012-05-15: Allow during shutdown.
            if not self.is_alive():
                return

            roothash_hex = d.get_def().get_roothash_as_hex()
            self.send_checkpoint(roothash_hex)
        finally:
            self.splock.release()

    def set_moreinfo_stats(self, d, enable):
        self.splock.acquire()
        try:
            if self.donestate != DONE_STATE_WORKING or not self.is_alive():
                return

            roothash_hex = d.get_def().get_roothash_as_hex()
            self.send_setmoreinfo(roothash_hex, enable)
        finally:
            self.splock.release()

    def set_subscribe_channel_close(self, download, enable, callback):
        # Note that CALLBACK is called on the i2ithread, and hence should not lock
        self.splock.acquire()
        try:
            if self.donestate != DONE_STATE_WORKING or not self.is_alive():
                return

            roothash_hex = download.get_def().get_roothash_as_hex() if (download is None or download != "ALL") else "ALL"
            if enable:
                if not self._channel_close_callbacks[roothash_hex]:
                    self.send_subscribe(roothash_hex, "CHANNEL_CLOSE", True)
                self._channel_close_callbacks[roothash_hex].append(callback)

            else:
                self._channel_close_callbacks[roothash_hex].remove(callback)
                if not self._channel_close_callbacks[roothash_hex]:
                    self.send_subscribe(roothash_hex, "CHANNEL_CLOSE", False)
        finally:
            self.splock.release()

    def add_peer(self, d, addr):
        self.splock.acquire()
        try:
            if self.donestate != DONE_STATE_WORKING or not self.is_alive():
                return

            addrstr = addr[0] + ':' + str(addr[1])
            roothash_hex = d.get_def().get_roothash_as_hex()
            self.send_peer_addr(roothash_hex, addrstr)
        finally:
            self.splock.release()

    def early_shutdown(self):
        # Called by any thread, assume sessionlock is held
        # May get called twice, once by spm.release_sp() and spm.shutdown()
        if self.donestate == DONE_STATE_WORKING:
            self.donestate = DONE_STATE_EARLY_SHUTDOWN
        else:
            return

        if self.fastconn:
            # Tell engine to shutdown so it can deregister dls from tracker
            self._logger.info("sp: Telling process to shutdown")
            self.send_shutdown()

    def network_shutdown(self):
        # Called by network thread, assume sessionlock is held
        if self.donestate == DONE_STATE_EARLY_SHUTDOWN:
            self.donestate = DONE_STATE_SHUTDOWN
        else:
            return

        if self.popen is not None:
            try:
                self._logger.info("sp: Terminating process")
                self.popen.terminate()
                self.popen.wait()
                self.popen = None
            except WindowsError:
                pass
            except:
                print_exc()

        if self.fastconn:
            self.fastconn.stop()

    #
    # Internal methods
    #
    def send_start(self, url, roothash_hex=None, maxdlspeed=None, maxulspeed=None, destdir=None, metadir=None):
        # assume splock is held to avoid concurrency on socket
        self._logger.info("sp: send_start: %s, destdir=%s, metadir=%s", url, destdir, metadir)

        cmd = 'START ' + url
        if destdir is not None:
            cmd += ' ' + destdir.encode("UTF-8")
            if metadir is not None:
                cmd += ' ' + metadir.encode("UTF-8")
        cmd += '\r\n'
        if maxdlspeed is not None:
            cmd += 'MAXSPEED ' + roothash_hex + ' DOWNLOAD ' + str(float(maxdlspeed)) + '\r\n'
        if maxulspeed is not None:
            cmd += 'MAXSPEED ' + roothash_hex + ' UPLOAD ' + str(float(maxulspeed)) + '\r\n'

        self.write(cmd)

    def send_remove(self, roothash_hex, removestate, removecontent):
        # assume splock is held to avoid concurrency on socket
        self.write('REMOVE ' + roothash_hex + ' ' + str(int(removestate)) + ' ' + str(int(removecontent)) + '\r\n')

    def send_checkpoint(self, roothash_hex):
        # assume splock is held to avoid concurrency on socket
        self.write('CHECKPOINT ' + roothash_hex + '\r\n')

    def send_shutdown(self):
        # assume splock is held to avoid concurrency on socket
        self.write('SHUTDOWN\r\n')

    def send_max_speed(self, roothash_hex, direct, speed):
        # assume splock is held to avoid concurrency on socket
        cmd = 'MAXSPEED ' + roothash_hex
        if direct == DOWNLOAD:
            cmd += ' DOWNLOAD '
        else:
            cmd += ' UPLOAD '
        cmd += str(float(speed)) + '\r\n'

        self.write(cmd)

    def send_tunnel(self, session, address, data):
        # assume splock is held to avoid concurrency on socket
        self._logger.debug("sp: send_tunnel:" + repr(len(data)) + "bytes -> %s:%d" % address)

        self.write("TUNNELSEND %s:%d/%s %d\r\n" % (address[0], address[1], session.encode("HEX"), len(data)))
        self.write(data)

    def send_setmoreinfo(self, roothash_hex, enable):
        # assume splock is held to avoid concurrency on socket
        onoff = "0"
        if enable:
            onoff = "1"
        self.write('SETMOREINFO ' + roothash_hex + ' ' + onoff + '\r\n')

    def send_subscribe(self, roothash_hex, event_type, enable):
        """
        Subscribe to a libswift event.

        ROOTHASH_HEX can currently only be "ALL"
        EVENT_TYPE can currently only be "CHANNEL_CLOSE"
        ENABLE can be either True or False
        """
        assert roothash_hex == "ALL"
        assert event_type == "CHANNEL_CLOSE"
        assert isinstance(enable, bool), type(enable)
        # assume splock is held to avoid concurrency on socket
        self._logger.debug("sp: send_subscribe: %s %s %s", roothash_hex, event_type, enable)
        self.write("SUBSCRIBE %s %s %d\r\n" % (roothash_hex, event_type, int(enable),))

    def send_peer_addr(self, roothash_hex, addrstr):
        # assume splock is held to avoid concurrency on socket
        self.write('PEERADDR ' + roothash_hex + ' ' + addrstr + '\r\n')

    def is_alive(self):
        if self.popen:
            self.popen.poll()
            return self.popen.returncode is None
        return False

    def write(self, msg):
        self.fastconn.write(msg)

    def get_cmdport(self):
        return self.cmdport

    def connection_lost(self, port):
        self.spmgr.connection_lost(port)

########NEW FILE########
__FILENAME__ = SwiftProcessMgr
# Written by Arno Bakker
# see LICENSE.txt for license information

import sys
import random
import time
from traceback import print_exc
import logging

from Tribler.Core.Swift.SwiftProcess import SwiftProcess


class SwiftProcessMgr:

    """ Class that manages a number of SwiftProcesses """

    def __init__(self, binpath, i2iport, dlsperproc, tunnellistenport, sesslock):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.binpath = binpath
        self.i2iport = i2iport
        # ARNOSMPTODO: Implement such that a new proc is created when needed
        self.dlsperproc = dlsperproc
        self.tunnellistenport = tunnellistenport
        self.sesslock = sesslock
        self.done = False

        self.sps = []

    def get_or_create_sp(self, workdir, zerostatedir, listenport, httpgwport, cmdgwport):
        """ Download needs a process """
        self.sesslock.acquire()
        if not self.done:
            # print >>sys.stderr,"spm: get_or_create_sp"
            try:
                self.clean_sps()

                sp = None
                if listenport is not None:
                    # Reuse the one with the same requested listen port
                    for sp2 in self.sps:
                        if sp2.listenport == listenport:
                            sp = sp2
                            # print >>sys.stderr,"spm: get_or_create_sp: Reusing",sp2.get_pid()

                elif self.dlsperproc > 1:
                    # Find one with room, distribute equally
                    random.shuffle(self.sps)
                    for sp2 in self.sps:
                        if len(sp2.get_downloads()) < self.dlsperproc:
                            sp = sp2
                            self._logger.debug("spm: get_or_create_sp: Reusing %s", sp.get_pid())
                            break

                if sp is None:
                    # Create new process
                    sp = SwiftProcess(self.binpath, workdir, zerostatedir, listenport, httpgwport, cmdgwport, self)
                    self._logger.debug("spm: get_or_create_sp: Creating new %s", sp.get_pid())
                    self.sps.append(sp)

                    # Arno, 2011-10-13: On Linux swift is slow to start and
                    # allocate the cmd listen socket?!
                    # 2012-05-23: connection_lost() will attempt another
                    # connect when the first fails, so not timing dependent,
                    # just ensures no send_()s get lost. Executed by NetworkThread.
                    if sys.platform == "linux2" or sys.platform == "darwin":
                        self._logger.info("spm: Need to sleep 1 second for swift to start on Linux?! FIXME")
                        time.sleep(1)

                    sp.start_cmd_connection()

                return sp
            finally:
                self.sesslock.release()

    def release_sp(self, sp):
        """ Download no longer needs process. Apply process-cleanup policy """
        # ARNOSMPTODO: MULTIPLE: Add policy param on whether to keep process around when no downloads.
        self.sesslock.acquire()
        try:
            # Arno, 2012-05-23: Don't kill tunneling swift process
            if sp.get_listen_port() == self.tunnellistenport:
                return

            # Niels, 2013-05-15: Don't kill at all we want a swift process as a background process
            if False and len(sp.get_downloads()) == 0:
                self.destroy_sp(sp)
        finally:
            self.sesslock.release()

    def destroy_sp(self, sp):
        self._logger.info("spm: destroy_sp: %s", sp.get_pid())
        self.sesslock.acquire()
        try:
            self.sps.remove(sp)
            sp.early_shutdown()
            # Don't need gracetime, no downloads left.
            sp.network_shutdown()
        finally:
            self.sesslock.release()

    def clean_sps(self):
        # lock held
        deads = []
        for sp in self.sps:
            if not sp.is_alive():
                self._logger.info("spm: clean_sps: Garbage collecting dead %s", sp.get_pid())
                deads.append(sp)
        for sp in deads:
            self.sps.remove(sp)

    def early_shutdown(self):
        """ First phase of two phase shutdown. network_shutdown is called after
        gracetime (see Session.shutdown()).
        """
        # Called by any thread, assume sessionlock is held
        self._logger.info("spm: early_shutdown")
        try:
            self.sesslock.acquire()
            self.done = True

            for sp in self.sps:
                try:
                    sp.early_shutdown()
                except:
                    print_exc()
        finally:
            self.sesslock.release()

    def network_shutdown(self):
        """ Gracetime expired, kill procs """
        # Called by network thread
        self._logger.info("spm: network_shutdown")
        for sp in self.sps:
            try:
                sp.network_shutdown()
            except:
                print_exc()

    def connection_lost(self, port):
        if self.done:
            return

        self.sesslock.acquire()
        try:
            for sp in self.sps:
                if sp.get_cmdport() == port:
                    self._logger.info("spm: connection_lost: Restart %s", sp.get_pid())
                    sp.start_cmd_connection()
        finally:
            self.sesslock.release()

########NEW FILE########
__FILENAME__ = util
#
# Convert a .torrent to a swift multi-file spec
#
# Author: Arno Bakker
#

MULTIFILE_PATHNAME = "META-INF-multifilespec.txt"


def filelist2swiftspec(filelist):
    # TODO: verify that this gives same sort as C++ CreateMultiSpec
    filelist.sort()

    specbody = ""
    for pathname, flen in filelist:
        specbody += pathname + " " +str(flen)+"\n"

    specsize = len(MULTIFILE_PATHNAME) + 1 +0+1+len(specbody)
    numstr = str(specsize)
    numstr2 = str(specsize + len(str(numstr)))
    if (len(numstr) == len(numstr2)):
        specsize += len(numstr)
    else:
        specsize += len(numstr) + (len(numstr2) -len(numstr))

    spec = MULTIFILE_PATHNAME + " " +str(specsize)+"\n"
    spec += specbody
    return spec

########NEW FILE########
__FILENAME__ = Extraction
# Written by Raynor Vliegendhart
# see LICENSE.txt for license information

import os

from Tribler import LIBRARYNAME
from Tribler.Core.Search.SearchManager import split_into_keywords
from Tribler.Core.Tag.StopwordsFilter import StopwordsFilter

import re
import threading


class TermExtraction:
    __single = None
    lock = threading.Lock()

    def getInstance(*args, **kw):
        # Singleton pattern with double-checking
        if TermExtraction.__single is None:
            TermExtraction.lock.acquire()
            try:
                if TermExtraction.__single is None:
                    TermExtraction(*args, **kw)
            finally:
                TermExtraction.lock.release()
        return TermExtraction.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        # Singleton pattern with double-checking
        if TermExtraction.__single:
            TermExtraction.lock.acquire()
            TermExtraction.__single = None
            TermExtraction.lock.release()
    delInstance = staticmethod(delInstance)

    def __init__(self, install_dir='.'):
        if TermExtraction.__single is not None:
            raise RuntimeError("TermExtraction is singleton")
        TermExtraction.__single = self

        filterfn = os.path.join(install_dir, LIBRARYNAME, 'Core', 'Tag', 'stop_snowball.filter')
        self.stopwords_filter = StopwordsFilter(stopwordsfilename=filterfn)

        self.containsdigits_filter = re.compile(r'\d', re.UNICODE)
        self.alldigits_filter = re.compile(r'^\d*$', re.UNICODE)
        self.isepisode_filter = re.compile(r'^s\d{2}e\d{2}', re.UNICODE)

        self.domain_terms = set('www net com org'.split())

    def extractTerms(self, name_or_keywords):
        """
        Extracts the terms from a torrent name.

        @param name_or_keywords The name of the torrent. Alternatively, you may
        pass a list of keywords (i.e., the name split into words using split_into_keywords).
        @return A list of extracted terms in order of occurence. The list may contain duplicates
        if a term occurs multiple times in the name.
        """
        if isinstance(name_or_keywords, basestring):
            keywords = split_into_keywords(name_or_keywords)
        else:
            keywords = name_or_keywords

        return [term for term in keywords if self.isSuitableTerm(term)]

    def extractBiTermPhrase(self, name_or_keywords):
        """
        Extracts a bi-term phrase from a torrent name. Currently, this phrase consists
        of the first two terms extracted from it.

        @param name_or_keywords The name of the torrent. Alternatively, you may
        pass a list of keywords (i.e., the name split into words using split_into_keywords).
        @return A tuple containing the two terms of the bi-term phrase. If there is no bi-term,
        i.e. less than two terms were extracted, None is returned.
        """
        terms = [term for term in self.extractTerms(name_or_keywords)
                 if self.containsdigits_filter.search(term) is None]
        if len(terms) > 1:
            return tuple(terms[:2])
        else:
            return None

    def isSuitableTerm(self, term):
        """
        Determines if a term is "suitable". Current rules are:
            1. Length of term is at least 3 characters.
            2. Term is not a stopword.
            3. Fully numeric terms are not suitable, except when they
               describe a year from the 20th or 21st century.
            4. Does not describe an episode (s##e##).
            5. Term is not equal to www, net, com, or org.

        @return True iff a term is suitable.
        """
        if len(term) < 3:
            return False
        elif self.stopwords_filter.isStopWord(term):
            return False
        elif self.alldigits_filter.match(term) is not None:
            if len(term) == 4:
                if term.startswith('19') or term.startswith('20'):
                    return True
            return False
        elif self.isepisode_filter.match(term) is not None:
            return False
        elif term in self.domain_terms:
            return False
        else:
            return True

########NEW FILE########
__FILENAME__ = StopwordsFilter
# Written by Raynor Vliegendhart
# see LICENSE.txt for license information
"""
This module contains a class to read stopwords from files in the Snowball format.
"""

import os

from Tribler import LIBRARYNAME
DEFAULT_STOPWORDS_FILE = os.path.join(LIBRARYNAME, 'Core', 'Tag', 'stop_snowball.filter')


class StopwordsFilter:

    def __init__(self, stopwordsfilename=DEFAULT_STOPWORDS_FILE):
        file_stream = open(stopwordsfilename, 'r')
        self._stopwords = set()
        for line in file_stream:
            word = line.split('|')[0].rstrip()
            if word and not word[0].isspace():
                self._stopwords.add(word)
        file_stream.close()

    def isStopWord(self, word):
        return word in self._stopwords

    def getStopWords(self):
        return set(self._stopwords)  # return a copy

########NEW FILE########
__FILENAME__ = TorrentDef
# Written by Arno Bakker
# see LICENSE.txt for license information
""" Definition of a torrent, that is, a collection of files or a live stream. """
import sys
import os
import logging
from types import StringType, ListType, IntType, LongType
from binascii import hexlify
from urllib2 import URLError

from Tribler.Core.simpledefs import INFOHASH_LENGTH, P2PURL_SCHEME
from Tribler.Core.defaults import TDEF_DEFAULTS
from Tribler.Core.exceptions import OperationNotPossibleAtRuntimeException, \
    TorrentDefNotFinalizedException, NotYetImplementedException
from Tribler.Core.Base import ContentDefinition, Serializable, Copyable
from Tribler.Core.Utilities.bencode import bencode, bdecode
import Tribler.Core.APIImplementation.maketorrent as maketorrent
import Tribler.Core.APIImplementation.makeurl as makeurl
from Tribler.Core.APIImplementation.miscutils import parse_playtime_to_secs
import Tribler.Core.permid

from Tribler.Core.Utilities.utilities import validTorrentFile, isValidURL, parse_magnetlink
from Tribler.Core.Utilities.unicode import dunno2unicode
from Tribler.Core.Utilities.timeouturlopen import urlOpenTimeout
from Tribler.Core.Utilities.Crypto import sha

from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr


class TorrentDef(ContentDefinition, Serializable, Copyable):

    """
    Definition of a torrent, that is, all params required for a torrent file,
    plus optional params such as thumbnail, playtime, etc.

    Note: to add fields to the torrent definition which are not supported
    by its API, first create the torrent def, finalize it, then add the
    fields to the metainfo, and create a new torrent def from that
    upgraded metainfo using TorrentDef.load_from_dict()

    This class can also be used to create P2P URLs, by calling set_url_compat()
    before finalizing. In that case only name, piece length, tracker, bitrate
    and source-authentication parameters (for live) are configurable.

    cf. libtorrent torrent_info
    """
    def __init__(self, input=None, metainfo=None, infohash=None):
        """ Normal constructor for TorrentDef (The input, metainfo and infohash
        parameters are used internally to make this a copy constructor) """
        assert infohash is None or isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert infohash is None or len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)

        self._logger = logging.getLogger(self.__class__.__name__)

        self.readonly = False
        if input is not None:  # copy constructor
            self.input = input
            # self.metainfo_valid set in copy()
            self.metainfo = metainfo
            self.infohash = infohash
            return

        self.input = {}  # fields added by user, waiting to be turned into torrent file
        # Define the built-in default here
        self.input.update(TDEF_DEFAULTS)
        try:
            self.input['encoding'] = sys.getfilesystemencoding()
        except:
            self.input['encoding'] = sys.getdefaultencoding()

        self.input['files'] = []

        self.metainfo_valid = False
        self.metainfo = None  # copy of loaded or last saved torrent dict
        self.infohash = None  # only valid if metainfo_valid

        # We cannot set a built-in default for a tracker here, as it depends on
        # a Session. Alternatively, the tracker will be set to the internal
        # tracker by default when Session::start_download() is called, if the
        # 'announce' field is the empty string.
    #
    # Class methods for creating a TorrentDef from a .torrent file
    #
    def load(filename):
        """
        Load a BT .torrent or Tribler .tribe file from disk and convert
        it into a finalized TorrentDef.

        @param filename  An absolute Unicode filename
        @return TorrentDef
        """
        # Class method, no locking required
        f = open(filename, "rb")
        return TorrentDef._read(f)
    load = staticmethod(load)

    def _read(stream):
        """ Internal class method that reads a torrent file from stream,
        checks it for correctness and sets self.input and self.metainfo
        accordingly. """
        bdata = stream.read()
        stream.close()
        data = bdecode(bdata)
        # print >>sys.stderr,data
        return TorrentDef._create(data)
    _read = staticmethod(_read)

    def _create(metainfo):  # TODO: replace with constructor
        # raises ValueErrors if not good
        validTorrentFile(metainfo)

        t = TorrentDef()
        t.metainfo = metainfo
        t.metainfo_valid = True
        # copy stuff into self.input
        maketorrent.copy_metainfo_to_input(t.metainfo, t.input)

        # For testing EXISTING LIVE, or EXISTING MERKLE: DISABLE, i.e. keep true infohash
        if t.get_url_compat():
            t.infohash = makeurl.metainfo2swarmid(t.metainfo)
        else:
            # Two places where infohash calculated, here and in maketorrent.py
            # Elsewhere: must use TorrentDef.get_infohash() to allow P2PURLs.
            t.infohash = sha(bencode(metainfo['info'])).digest()

        assert isinstance(t.infohash, str), "INFOHASH has invalid type: %s" % type(t.infohash)
        assert len(t.infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(t.infohash)

        # print >>sys.stderr,"INFOHASH",`t.infohash`

        return t

    _create = staticmethod(_create)

    @staticmethod
    def retrieve_from_magnet(url, callback, timeout=30.0, max_connections=30.0, silent=False):
        """
        If the URL conforms to a magnet link, the .torrent info is
        downloaded and converted into a TorrentDef.  The resulting
        TorrentDef is provided through CALLBACK.

        Returns True when attempting to obtain the TorrentDef, in this
        case CALLBACK will always be called.  Otherwise False is
        returned, in this case CALLBACK will not be called.

        The thread making the callback should be used very briefly.
        """
        assert isinstance(url, str), "URL has invalid type: %s" % type(url)
        assert callable(callback), "CALLBACK must be callable"

        def metainfo_retrieved(metadata):
            try:
                tdef = TorrentDef.load_from_dict(metadata)
            except UnicodeDecodeError:
                if not silent:
                    raise
            callback(tdef)
        if LibtorrentMgr.hasInstance():
            LibtorrentMgr.getInstance().get_metainfo(url, metainfo_retrieved, timeout)
            return True
        return False

    @staticmethod
    def retrieve_from_magnet_infohash(infohash, callback, timeout=30.0, max_connections=30.0):
        magnetlink = "magnet:?xt=urn:btih:" + hexlify(infohash)
        return TorrentDef.retrieve_from_magnet(magnetlink, callback, timeout, max_connections)

    @staticmethod
    def load_from_url(url):
        """
        If the URL starts with 'http:' load a BT .torrent or Tribler .tstream
        file from the URL and convert it into a TorrentDef. If the URL starts
        with our URL scheme, we convert the URL to a URL-compatible TorrentDef.

        If we can't download the .torrent file, this method returns None.

        @param url URL
        @return TorrentDef.
        """
        # Class method, no locking required
        if url.startswith(P2PURL_SCHEME):
            (metainfo, swarmid) = makeurl.p2purl2metainfo(url)

            # Metainfo created from URL, so create URL compatible TorrentDef.
            metainfo['info']['url-compat'] = 1

            # For testing EXISTING LIVE: ENABLE, for old EXISTING MERKLE: DISABLE
            # metainfo['info']['name.utf-8'] = metainfo['info']['name']

            t = TorrentDef._create(metainfo)

            return t
        else:
            try:
                f = urlOpenTimeout(url)
                return TorrentDef._read(f)

            except URLError:
                pass

    @staticmethod
    def load_from_dict(metainfo):
        """
        Load a BT .torrent or Tribler .tribe file from the metainfo dictionary
        it into a TorrentDef

        @param metainfo A dictionary following the BT torrent file spec.
        @return TorrentDef.
        """
        # Class method, no locking required
        return TorrentDef._create(metainfo)

    #
    # ContentDefinition interface
    #
    def get_def_type(self):
        """ Returns the type of this Definition
        @return string
        """
        return "torrent"

    def get_id(self):
        """ Returns a identifier for this Definition
        @return string
        """
        return self.get_infohash()

    #
    # Convenience instance methods for publishing new content
    #
    def add_content(self, inpath, outpath=None, playtime=None):
        """
        Add a file or directory to this torrent definition. When adding a
        directory, all files in that directory will be added to the torrent.

        One can add multiple files and directories to a torrent definition.
        In that case the "outpath" parameter must be used to indicate how
        the files/dirs should be named in the torrent. The outpaths used must
        start with a common prefix which will become the "name" field of the
        torrent.

        To seed the torrent via the core (as opposed to e.g. HTTP) you will
        need to start the download with the dest_dir set to the top-level
        directory containing the files and directories to seed. For example,
        a file "c:\Videos\file.avi" is seeded as follows:
        <pre>
            tdef = TorrentDef()
            tdef.add_content("c:\Videos\file.avi",playtime="1:59:20")
            tdef.set_tracker(s.get_internal_tracker_url())
            tdef.finalize()
            dscfg = DownloadStartupConfig()
            dscfg.set_dest_dir("c:\Video")
            s.start_download(tdef,dscfg)
        </pre>
        @param inpath Absolute name of file or directory on local filesystem,
        as Unicode string.
        @param outpath (optional) Name of the content to use in the torrent def
        as Unicode string.
        @param playtime (optional) String representing the duration of the
        multimedia file when played, in [hh:]mm:ss format.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        s = os.stat(inpath)
        d = {'inpath': inpath, 'outpath': outpath, 'playtime': playtime, 'length': s.st_size}
        self.input['files'].append(d)

        self.metainfo_valid = False

    def remove_content(self, inpath):
        """ Remove a file or directory from this torrent definition

        @param inpath Absolute name of file or directory on local filesystem,
        as Unicode string.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        for d in self.input['files']:
            if d['inpath'] == inpath:
                self.input['files'].remove(d)
                break

    def create_live(self, name, bitrate, playtime="1:00:00"):
        """ Create a live streaming multimedia torrent with a specific bitrate.

        @param name The name of the stream.
        @param bitrate The desired bitrate in bytes per second.
        @param playtime The virtual playtime of the stream as a string in
        [hh:]mm:ss format.
        """
        self.input['bps'] = bitrate
        self.input['playtime'] = playtime  # size of virtual content

        d = {'inpath': name, 'outpath': None, 'playtime': None, 'length': None}
        self.input['files'].append(d)

    #
    # Torrent attributes
    #
    def set_encoding(self, enc):
        """ Set the character encoding for e.g. the 'name' field """
        self.input['encoding'] = enc
        self.metainfo_valid = False

    def get_encoding(self):
        return self.input['encoding']

    def set_thumbnail(self, thumbfilename):
        """
        Reads image from file and turns it into a torrent thumbnail
        The file should contain an image in JPEG format, preferably 171x96.

        @param thumbfilename Absolute name of image file, as Unicode string.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        f = open(thumbfilename, "rb")
        data = f.read()
        f.close()
        self.input['thumb'] = data
        self.metainfo_valid = False

    def get_thumbnail(self):
        """ Returns (MIME type,thumbnail data) if present or (None,None)
        @return A tuple. """
        if 'thumb' not in self.input or self.input['thumb'] is None:
            return (None, None)
        else:
            thumb = self.input['thumb']  # buffer/string immutable
            return ('image/jpeg', thumb)

    def set_tracker(self, url):
        """ Sets the tracker (i.e. the torrent file's 'announce' field).
        @param url The announce URL.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        if not isValidURL(url):
            raise ValueError("Invalid URL")

        if url.endswith('/'):
            # Some tracker code can't deal with / at end
            url = url[:-1]
        self.input['announce'] = url
        self.metainfo_valid = False

    def get_tracker(self):
        """ Returns the announce URL.
        @return URL """
        return self.input['announce']

    def set_tracker_hierarchy(self, hier):
        """ Set hierarchy of trackers (announce-list) following the spec
        at http://www.bittornado.com/docs/multitracker-spec.txt
        @param hier A hierarchy of trackers as a list of lists.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        # TODO: check input, in particular remove / at end
        newhier = []
        if not isinstance(hier, ListType):
            raise ValueError("hierarchy is not a list")
        for tier in hier:
            if not isinstance(tier, ListType):
                raise ValueError("tier is not a list")
            newtier = []
            for url in tier:
                if not isValidURL(url):
                    raise ValueError("Invalid URL: " + repr(url))

                if url.endswith('/'):
                    # Some tracker code can't deal with / at end
                    url = url[:-1]
                newtier.append(url)
            newhier.append(newtier)

        self.input['announce-list'] = newhier
        self.metainfo_valid = False

    def get_tracker_hierarchy(self):
        """ Returns the hierarchy of trackers.
        @return A list of lists. """
        return self.input['announce-list']

    def get_trackers_as_single_tuple(self):
        """ Returns a flat tuple of all known trackers
        @return A tuple containing trackers
        """
        if self.get_tracker_hierarchy():
            trackers = []
            for level in self.get_tracker_hierarchy():
                for tracker in level:
                    if tracker and tracker not in trackers:
                        trackers.append(tracker)
            return tuple(trackers)
        tracker = self.get_tracker()
        if tracker:
            return (tracker,)
        return ()

    def has_trackers(self):
        return len(self.get_trackers_as_single_tuple()) > 0

    def set_dht_nodes(self, nodes):
        """ Sets the DHT nodes required by the mainline DHT support,
        See http://www.bittorrent.org/beps/bep_0005.html
        @param nodes A list of [hostname,port] lists.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        # Check input
        if not isinstance(nodes, ListType):
            raise ValueError("nodes not a list")
        else:
            for node in nodes:
                if not isinstance(node, ListType) or len(node) != 2:
                    raise ValueError("node in nodes not a 2-item list: " + repr(node))
                if not isinstance(node[0], StringType):
                    raise ValueError("host in node is not string:" + repr(node))
                if not isinstance(node[1], IntType):
                    raise ValueError("port in node is not int:" + repr(node))

        self.input['nodes'] = nodes
        self.metainfo_valid = False

    def get_dht_nodes(self):
        """ Returns the DHT nodes set.
        @return A list of [hostname,port] lists. """
        return self.input['nodes']

    def set_comment(self, value):
        """ Set comment field.
        @param value A Unicode string.
         """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['comment'] = value
        self.metainfo_valid = False

    def get_comment(self):
        """ Returns the comment field of the def.
        @return A Unicode string. """
        return self.input['comment']

    def get_comment_as_unicode(self):
        """ Returns the comment field of the def as a unicode string.
        @return A Unicode string. """
        return dunno2unicode(self.input['comment'])

    def set_created_by(self, value):
        """ Set 'created by' field.
        @param value A Unicode string.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['created by'] = value
        self.metainfo_valid = False

    def get_created_by(self):
        """ Returns the 'created by' field.
        @return Unicode string. """
        return self.input['created by']

    def set_urllist(self, value):
        """ Set list of HTTP seeds following the BEP 19 spec (GetRight style):
        http://www.bittorrent.org/beps/bep_0019.html
        @param value A list of URLs.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        for url in value:
            if not isValidURL(url):
                raise ValueError("Invalid URL: " + repr(url))

        self.input['url-list'] = value
        self.metainfo_valid = False

    def get_urllist(self):
        """ Returns the list of HTTP seeds.
        @return A list of URLs. """
        return self.input['url-list']

    def set_httpseeds(self, value):
        """ Set list of HTTP seeds following the BEP 17 spec (John Hoffman style):
        http://www.bittorrent.org/beps/bep_0017.html
        @param value A list of URLs.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        for url in value:
            if not isValidURL(url):
                raise ValueError("Invalid URL: " + repr(url))

        self.input['httpseeds'] = value
        self.metainfo_valid = False

    def get_httpseeds(self):
        """ Returns the list of HTTP seeds.
        @return A list of URLs. """
        return self.input['httpseeds']

    def set_piece_length(self, value):
        """ Set the size of the pieces in which the content is traded.
        The piece size must be a multiple of the chunk size, the unit in which
        it is transmitted, which is 16K by default (see
        DownloadConfig.set_download_slice_size()). The default is automatic
        (value 0).
        @param value A number of bytes as per the text.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        if not (isinstance(value, IntType) or isinstance(value, LongType)):
            raise ValueError("Piece length not an int/long")

        self.input['piece length'] = value
        self.metainfo_valid = False

    def get_piece_length(self):
        """ Returns the piece size.
        @return A number of bytes. """
        return self.input['piece length']

    def get_nr_pieces(self):
        """ Returns the number of pieces.
        @return A number of pieces. """
        return len(self.metainfo['info']['pieces']) / 20

    def get_pieces(self):
        """ Returns the pieces"""
        return self.metainfo['info']['pieces'][:]

    def set_add_md5hash(self, value):
        """ Whether to add an end-to-end MD5 checksum to the def.
        @param value Boolean.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['makehash_md5'] = value
        self.metainfo_valid = False

    def get_add_md5hash(self):
        """ Returns whether to add an MD5 checksum. """
        return self.input['makehash_md5']

    def set_add_crc32(self, value):
        """ Whether to add an end-to-end CRC32 checksum to the def.
        @param value Boolean.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['makehash_crc32'] = value
        self.metainfo_valid = False

    def get_add_crc32(self):
        """ Returns whether to add an end-to-end CRC32 checksum to the def.
        @return Boolean. """
        return self.input['makehash_crc32']

    def set_add_sha1hash(self, value):
        """ Whether to add end-to-end SHA1 checksum to the def.
        @param value Boolean.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['makehash_sha1'] = value
        self.metainfo_valid = False

    def get_add_sha1hash(self):
        """ Returns whether to add an end-to-end SHA1 checksum to the def.
        @return Boolean."""
        return self.input['makehash_sha1']

    def set_create_merkle_torrent(self, value):
        """ Create a Merkle torrent instead of a regular BT torrent. A Merkle
        torrent uses a hash tree for checking the integrity of the content
        received. As such it creates much smaller torrent files than the
        regular method. Tribler-specific feature."""
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['createmerkletorrent'] = value
        self.metainfo_valid = False

    def get_create_merkle_torrent(self):
        """ Returns whether to create a Merkle torrent.
        @return Boolean. """
        return self.input['createmerkletorrent']

    def set_signature_keypair_filename(self, value):
        """ Set absolute filename of keypair to be used for signature.
        When set, a signature will be added.
        @param value A filename containing an Elliptic Curve keypair.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['torrentsigkeypairfilename'] = value
        self.metainfo_valid = False

    def get_signature_keypair_filename(self):
        """ Returns the filename containing the signing keypair or None.
        @return Unicode String or None. """
        return self.input['torrentsigkeypairfilename']

    def get_live(self):
        """ Returns whether this definition is for a live torrent.
        @return Boolean. """
        return bool('live' in self.input and self.input['live'])

    def get_live_authmethod(self):
        """ Returns the method for authenticating the source.
        <pre>
        LIVE_AUTHMETHOD_ECDSA
        </pre>
        @return String
        """
        return 'live' in self.input and self.input['live']['authmethod']

    def get_live_pubkey(self):
        """ Returns the public key used for authenticating packets from
        the source.
        @return A public key in DER.
        """
        if 'live' in self.input and 'pubkey' in self.input['live']:
            return self.input['live']['pubkey']
        else:
            return None

    def set_url_compat(self, value):
        """ Set the URL compatible value for this definition. Only possible
        for Merkle torrents and live torrents.
        @param value Integer."""

        self.input['url-compat'] = value

    def get_url_compat(self):
        """ Returns whether this definition is URL compatible.
        @return Boolean. """
        return 'url-compat' in self.input and self.input['url-compat']

    #
    # For P2P-transported Ogg streams
    #
    def set_live_ogg_headers(self, value):
        if self.get_url_compat():
            raise ValueError("Cannot use P2PURLs for Ogg streams")
        self.input['ogg-headers'] = value

    def get_live_ogg_headers(self):
        if 'ogg-headers' in self.input:
            return self.input['ogg-headers']
        else:
            return None

    def set_metadata(self, value):
        """ Set the P2P-Next metadata
        @param value binary string """

        self.input['ns-metadata'] = value

    def get_metadata(self):
        """ Returns the stored P2P-Next metadata or None.
        @return binary string. """
        if 'ns-metadata' in self.input:
            return self.input['ns-metadata']
        else:
            return None

    def set_initial_peers(self, value):
        """ Set the initial peers to connect to.
        @param value List of (IP,port) tuples """
        self.input['initial peers'] = value

    def get_initial_peers(self):
        """ Returns the list of initial peers.
        @return List of (IP,port) tuples. """
        if 'initial peers' in self.input:
            return self.input['initial peers']
        else:
            return []

    def finalize(self, userabortflag=None, userprogresscallback=None):
        """ Create BT torrent file by reading the files added with
        add_content() and calculate the torrent file's infohash.

        Creating the torrent file can take a long time and will be carried out
        by the calling thread. The process can be made interruptable by passing
        a threading.Event() object via the userabortflag and setting it when
        the process should be aborted. The also optional userprogresscallback
        will be called by the calling thread periodically, with a progress
        percentage as argument.

        The userprogresscallback function will be called by the calling thread.

        @param userabortflag threading.Event() object
        @param userprogresscallback Function accepting a fraction as first
        argument.
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        if self.metainfo_valid:
            return

        if 'live' in self.input:
            # Make sure the duration is an integral number of pieces, for
            # security (live source auth).
            secs = parse_playtime_to_secs(self.input['playtime'])
            pl = float(self.get_piece_length())
            length = float(self.input['bps'] * secs)

            self._logger.debug("TorrentDef: finalize: length %s, piecelen %s", length, pl)
            diff = length % pl
            add = (pl - diff) % pl
            newlen = int(length + add)

            # print >>sys.stderr,"CHECK INFO LENGTH",secs,newlen
            d = self.input['files'][0]
            d['length'] = newlen

        # Note: reading of all files and calc of hashes is done by calling
        # thread.
        (infohash, metainfo) = maketorrent.make_torrent_file(self.input, userabortflag=userabortflag, userprogresscallback=userprogresscallback)
        if infohash is not None:

            if self.get_url_compat():
                url = makeurl.metainfo2p2purl(metainfo)
                # Make sure metainfo is preserved, in particular, the url-compat field.
                swarmid = makeurl.metainfo2swarmid(metainfo)
                self.infohash = swarmid
            else:
                self.infohash = infohash
            self.metainfo = metainfo

            self.input['name'] = metainfo['info']['name']
            # May have been 0, meaning auto.
            self.input['piece length'] = metainfo['info']['piece length']
            self.metainfo_valid = True

        assert self.infohash is None or isinstance(self.infohash, str), "INFOHASH has invalid type: %s" % type(self.infohash)
        assert self.infohash is None or len(self.infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(self.infohash)

    def is_finalized(self):
        """ Returns whether the TorrentDef is finalized or not.
        @return Boolean. """
        return self.metainfo_valid

    #
    # Operations on finalized TorrentDefs
    #
    def get_infohash(self):
        """ Returns the infohash of the torrent, for non-URL compatible
        torrents. Otherwise it returns the swarm identifier (either the root hash
        (Merkle torrents) or hash of the live-source authentication key.
        @return A string of length 20. """
        if self.metainfo_valid:
            if self.is_merkle_torrent():
                return self.metainfo['info']['root hash']
            else:
                return self.infohash
        else:
            raise TorrentDefNotFinalizedException()

    def get_metainfo(self):
        """ Returns the torrent definition as a dictionary that follows the BT
        spec for torrent files.
        @return dict
        """
        if self.metainfo_valid:
            return self.metainfo
        else:
            raise TorrentDefNotFinalizedException()

    def get_name(self):
        """ Returns the info['name'] field as raw string of bytes.
        @return String """
        if self.metainfo_valid:
            return self.input['name']  # string immutable
        else:
            raise TorrentDefNotFinalizedException()

    def set_name(self, name):
        """ Set the name of this torrent
        @param name name of torrent as String
        """
        if self.readonly:
            raise OperationNotPossibleAtRuntimeException()

        self.input['name'] = name
        self.metainfo_valid = False

    def get_name_as_unicode(self):
        """ Returns the info['name'] field as Unicode string.
        @return Unicode string. """
        if not self.metainfo_valid:
            raise TorrentDefNotFinalizedException()

        if "name.utf-8" in self.metainfo["info"]:
            # There is an utf-8 encoded name.  We assume that it is
            # correctly encoded and use it normally
            try:
                return unicode(self.metainfo["info"]["name.utf-8"], "UTF-8")
            except UnicodeError:
                pass

        if "name" in self.metainfo["info"]:
            # Try to use the 'encoding' field.  If it exists, it
            # should contain something like 'utf-8'
            if "encoding" in self.metainfo:
                try:
                    return unicode(self.metainfo["info"]["name"], self.metainfo["encoding"])
                except UnicodeError:
                    pass
                except LookupError:
                    # Some encodings are not supported by python.  For
                    # instance, the MBCS codec which is used by
                    # Windows is not supported (Jan 2010)
                    pass

            # Try to convert the names in path to unicode, without
            # specifying the encoding
            try:
                return unicode(self.metainfo["info"]["name"])
            except UnicodeError:
                pass

            # Try to convert the names in path to unicode, assuming
            # that it was encoded as utf-8
            try:
                return unicode(self.metainfo["info"]["name"], "UTF-8")
            except UnicodeError:
                pass

            # Convert the names in path to unicode by replacing out
            # all characters that may -even remotely- cause problems
            # with the '?' character
            try:
                def filter_characters(name):
                    def filter_character(char):
                        if 0 < ord(char) < 128:
                            return char
                        else:
                            self._logger.debug("Bad character filter %s, isalnum? %s", ord(char), char.isalnum())
                            return u"?"
                    return u"".join([filter_character(char) for char in name])
                return unicode(filter_characters(self.metainfo["info"]["name"]))
            except UnicodeError:
                pass

        # We failed.  Returning an empty string
        return u""

    def verify_torrent_signature(self):
        """ Verify the signature on the finalized torrent definition. Returns
        whether the signature was valid.
        @return Boolean.
        """
        if self.metainfo_valid:
            return Tribler.Core.permid.verify_torrent_signature(self.metainfo)
        else:
            raise TorrentDefNotFinalizedException()

    def save(self, filename):
        """
        Finalizes the torrent def and writes a torrent file i.e., bencoded dict
        following BT spec) to the specified filename. Note this may take a
        long time when the torrent def is not yet finalized.

        @param filename An absolute Unicode path name.
        """
        if not self.readonly:
            self.finalize()

        # Boudewijn, 10/09/10: do not save the 'initial peers'.  (1)
        # they should not be saved, as they are unlikely to be there
        # the next time, and (2) bencode does not understand tuples
        # and converts the (addres,port) tuple into a list.
        if 'initial peers' in self.metainfo:
            del self.metainfo['initial peers']

        bdata = bencode(self.metainfo)
        f = open(filename, "wb")
        f.write(bdata)
        f.close()

    def get_torrent_size(self):
        """
        Finalizes the torrent def and converts the metainfo to string, returns the
        number of bytes the string would take on disk.
        """
        if not self.readonly:
            self.finalize()

        # Boudewijn, 10/09/10: do not save the 'initial peers'.  (1)
        # they should not be saved, as they are unlikely to be there
        # the next time, and (2) bencode does not understand tuples
        # and converts the (addres,port) tuple into a list.
        if 'initial peers' in self.metainfo:
            del self.metainfo['initial peers']

        bdata = bencode(self.metainfo)
        return len(bdata)

    def get_bitrate(self, file=None):
        """ Returns the bitrate of the specified file. If no file is specified,
        we assume this is a single-file torrent.

        @param file (Optional) the file in the torrent to retrieve the bitrate of.
        @return The bitrate in bytes per second or None.
        """
        if not self.metainfo_valid:
            raise NotYetImplementedException()  # must save first

        return maketorrent.get_bitrate_from_metainfo(file, self.metainfo)

    def get_files_with_length(self, exts=None):
        """ The list of files in the finalized torrent def.
        @param exts (Optional) list of filename extensions (without leading .)
        to search for.
        @return A list of filenames.
        """
        return maketorrent.get_files(self.metainfo, exts)

    def get_files(self, exts=None):
        """ The list of files in the finalized torrent def.
        @param exts (Optional) list of filename extensions (without leading .)
        to search for.
        @return A list of filenames.
        """
        return [filename for filename, _ in maketorrent.get_files(self.metainfo, exts)]

    def _get_all_files_as_unicode_with_length(self):
        """ Get a generator for files in the torrent def. No filtering
        is possible and all tricks are allowed to obtain a unicode
        list of filenames.
        @return A unicode filename generator.
        """
        assert self.metainfo_valid, "TorrentDef is not finalized"
        if "files" in self.metainfo["info"]:
            # Multi-file torrent
            join = os.path.join
            files = self.metainfo["info"]["files"]

            for file_dict in files:
                if "path.utf-8" in file_dict:
                    # This file has an utf-8 encoded list of elements.
                    # We assume that it is correctly encoded and use
                    # it normally
                    try:
                        yield join(*[unicode(element, "UTF-8") for element in file_dict["path.utf-8"]]), file_dict["length"]
                        continue
                    except UnicodeError:
                        pass

                if "path" in file_dict:
                    # Try to use the 'encoding' field.  If it exists,
                    # it should contain something like 'utf-8'
                    if "encoding" in self.metainfo:
                        encoding = self.metainfo["encoding"]
                        try:
                            yield join(*[unicode(element, encoding) for element in file_dict["path"]]), file_dict["length"]
                            continue
                        except UnicodeError:
                            pass
                        except LookupError:
                            # Some encodings are not supported by
                            # python.  For instance, the MBCS codec
                            # which is used by Windows is not
                            # supported (Jan 2010)
                            pass

                    # Try to convert the names in path to unicode,
                    # without specifying the encoding
                    try:
                        yield join(*[unicode(element) for element in file_dict["path"]]), file_dict["length"]
                        continue
                    except UnicodeError:
                        pass

                    # Try to convert the names in path to unicode,
                    # assuming that it was encoded as utf-8
                    try:
                        yield join(*[unicode(element, "UTF-8") for element in file_dict["path"]]), file_dict["length"]
                        continue
                    except UnicodeError:
                        pass

                    # Convert the names in path to unicode by
                    # replacing out all characters that may -even
                    # remotely- cause problems with the '?' character
                    try:
                        def filter_characters(name):
                            def filter_character(char):
                                if 0 < ord(char) < 128:
                                    return char
                                else:
                                    self._logger.debug("Bad character filter %s, isalnum? %s", ord(char), char.isalnum())
                                    return u"?"
                            return u"".join([filter_character(char) for char in name])
                        yield join(*[unicode(filter_characters(element)) for element in file_dict["path"]]), file_dict["length"]
                        continue
                    except UnicodeError:
                        pass

        else:
            # Single-file torrent
            yield self.get_name_as_unicode(), self.metainfo["info"]["length"]

    def get_files_as_unicode_with_length(self, exts=None):
        """ The list of files in the finalized torrent def.
        @param exts (Optional) list of filename extensions (without leading .)
        to search for.
        @return A list of filenames.
        """
        if not self.metainfo_valid:
            raise NotYetImplementedException()  # must save first

        videofiles = []
        for filename, length in self._get_all_files_as_unicode_with_length():
            prefix, ext = os.path.splitext(filename)
            if ext != "" and ext[0] == ".":
                ext = ext[1:]
            if exts is None or ext.lower() in exts:
                videofiles.append((filename, length))
        return videofiles

    def get_files_as_unicode(self, exts=None):
        return [filename for filename, _ in self.get_files_as_unicode_with_length(exts)]

    def get_length(self, selectedfiles=None):
        """ Returns the total size of the content in the torrent. If the
        optional selectedfiles argument is specified, the method returns
        the total size of only those files.
        @return A length (long)
        """
        if not self.metainfo_valid:
            raise NotYetImplementedException()  # must save first

        return maketorrent.get_length_from_metainfo(self.metainfo, selectedfiles)

    def get_creation_date(self, default=0):
        if not self.metainfo_valid:
            raise NotYetImplementedException()  # must save first

        return self.metainfo.get("creation date", default)

    def is_multifile_torrent(self):
        """ Returns whether this TorrentDef is a multi-file torrent.
        @return Boolean
        """
        if not self.metainfo_valid:
            raise NotYetImplementedException()  # must save first

        return 'files' in self.metainfo['info']

    def is_merkle_torrent(self):
        """ Returns whether this TorrentDef is a Merkle torrent. Use
        get_create_merkle_torrent() to determine this before finalization.
        @return Boolean """
        if self.metainfo_valid:
            return 'root hash' in self.metainfo['info']
        else:
            raise TorrentDefNotFinalizedException()

    def is_private(self):
        """ Returns whether this TorrentDef is a private torrent.
        @return Boolean """
        if not self.metainfo_valid:
            raise NotYetImplementedException()

        return int(self.metainfo['info'].get('private', 0)) == 1

    def get_url(self):
        """ Returns the URL representation of this TorrentDef. The TorrentDef
        must be a Merkle or live torrent and must be set to URL-compatible
        before finalizing."""

        if self.metainfo_valid:
            return makeurl.metainfo2p2purl(self.metainfo)
        else:
            raise TorrentDefNotFinalizedException()

    #
    # Internal methods
    #
    def get_index_of_file_in_files(self, file):
        if not self.metainfo_valid:
            raise NotYetImplementedException()  # must save first

        info = self.metainfo['info']

        if file is not None and 'files' in info:
            for i in range(len(info['files'])):
                x = info['files'][i]

                intorrentpath = maketorrent.pathlist2filename(x['path'])
                if intorrentpath == file:
                    return i
            return ValueError("File not found in torrent")
        else:
            raise ValueError("File not found in single-file torrent")


class TorrentDefNoMetainfo(ContentDefinition, Serializable, Copyable):

    def __init__(self, infohash, name, url=None):
        assert isinstance(infohash, str), "INFOHASH has invalid type: %s" % type(infohash)
        assert len(infohash) == INFOHASH_LENGTH, "INFOHASH has invalid length: %d" % len(infohash)
        self.infohash = infohash
        self.name = name
        self.url = url

    def get_name(self):
        return self.name

    def get_def_type(self):
        return "torrent"

    def get_id(self):
        return self.get_infohash()

    def get_infohash(self):
        return self.infohash

    def get_live(self):
        return False

    def get_length(self, selectedfiles=None):
        return 0

    def get_metainfo(self):
        return None

    def get_url(self):
        return self.url

    def is_multifile_torrent(self):
        return False

    def get_name_as_unicode(self):
        return unicode(self.name) if self.name else u''

    def get_files(self, exts=None):
        return []

    def get_trackers_as_single_tuple(self):
        if self.url and self.url.startswith('magnet:'):
            _, _, trs = parse_magnetlink(self.url)
            return tuple(trs)
        return ()

    def has_trackers(self):
        return False

    def copy(self):
        return TorrentDefNoMetainfo(self.infohash, self.name)

########NEW FILE########
__FILENAME__ = bencode
# Written by Petru Paler, Uoti Urpala, Ross Cohen and John Hoffman
# see LICENSE.txt for license information

from types import IntType, LongType, StringType, ListType, TupleType, DictType
try:
    from types import BooleanType
except ImportError:
    BooleanType = None
try:
    from types import UnicodeType
except ImportError:
    UnicodeType = None

from traceback import print_exc, print_stack
import logging

logger = logging.getLogger(__name__)


def decode_int(x, f):
    f += 1
    newf = x.index('e', f)
    try:
        n = int(x[f:newf])
    except:
        n = long(x[f:newf])
    if x[f] == '-':
        if x[f + 1] == '0':
            raise ValueError
    elif x[f] == '0' and newf != f + 1:
        raise ValueError
    return (n, newf + 1)


def decode_string(x, f):
    colon = x.index(':', f)
    try:
        n = int(x[f:colon])
    except (OverflowError, ValueError):
        n = long(x[f:colon])
    if x[f] == '0' and colon != f + 1:
        raise ValueError
    colon += 1
    return (x[colon:colon + n], colon +n)


def decode_unicode(x, f):
    s, f = decode_string(x, f + 1)
    return (s.decode('UTF-8'), f)


def decode_list(x, f):
    r, f = [], f + 1
    while x[f] != 'e':
        v, f = decode_func[x[f]](x, f)
        r.append(v)
    return (r, f + 1)


def decode_dict(x, f):
    r, f = {}, f + 1
    lastkey = None
    while x[f] != 'e':
        k, f = decode_string(x, f)
        # Arno, 2008-09-12: uTorrent 1.8 violates the bencoding spec, its keys
        # in an EXTEND handshake message are not sorted. Be liberal in what we
        # receive:
        # if lastkey >= k:
        # raise ValueError
        lastkey = k
        r[k], f = decode_func[x[f]](x, f)
    return (r, f + 1)

decode_func = {}
decode_func['l'] = decode_list
decode_func['d'] = decode_dict
decode_func['i'] = decode_int
decode_func['0'] = decode_string
decode_func['1'] = decode_string
decode_func['2'] = decode_string
decode_func['3'] = decode_string
decode_func['4'] = decode_string
decode_func['5'] = decode_string
decode_func['6'] = decode_string
decode_func['7'] = decode_string
decode_func['8'] = decode_string
decode_func['9'] = decode_string
# decode_func['u'] = decode_unicode


def bdecode(x, sloppy=0):
    r, l = sloppy_bdecode(x)
    if not sloppy and l != len(x):
        raise ValueError("bad bencoded data")
    return r


def sloppy_bdecode(x):
    """
    Same as bdecode, except that it returns the decoded data AND the number of bytes read from X.
    """
    try:
        r, l = decode_func[x[0]](x, 0)
#    except (IndexError, KeyError):
    except (IndexError, KeyError, ValueError):
        #print_exc()
        raise ValueError("bad bencoded data")
    return r, l


def test_bdecode():
    try:
        bdecode('0:0:')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('ie')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('i341foo382e')
        assert 0
    except ValueError:
        pass
    assert bdecode('i4e') == 4
    assert bdecode('i0e') == 0
    assert bdecode('i123456789e') == 123456789
    assert bdecode('i-10e') == -10
    try:
        bdecode('i-0e')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('i123')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('i6easd')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('35208734823ljdahflajhdf')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('2:abfdjslhfld')
        assert 0
    except ValueError:
        pass
    assert bdecode('0:') == ''
    assert bdecode('3:abc') == 'abc'
    assert bdecode('10:1234567890') == '1234567890'
    try:
        bdecode('02:xy')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('l')
        assert 0
    except ValueError:
        pass
    assert bdecode('le') == []
    try:
        bdecode('leanfdldjfh')
        assert 0
    except ValueError:
        pass
    assert bdecode('l0:0:0:e') == ['', '', '']
    try:
        bdecode('relwjhrlewjh')
        assert 0
    except ValueError:
        pass
    assert bdecode('li1ei2ei3ee') == [1, 2, 3]
    assert bdecode('l3:asd2:xye') == ['asd', 'xy']
    assert bdecode('ll5:Alice3:Bobeli2ei3eee') == [['Alice', 'Bob'], [2, 3]]
    try:
        bdecode('d')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('defoobar')
        assert 0
    except ValueError:
        pass
    assert bdecode('de') == {}
    assert bdecode('d3:agei25e4:eyes4:bluee') == {'age': 25, 'eyes': 'blue'}
    assert bdecode('d8:spam.mp3d6:author5:Alice6:lengthi100000eee') == {'spam.mp3': {'author': 'Alice', 'length': 100000}}
    try:
        bdecode('d3:fooe')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('di1e0:e')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('d1:b0:1:a0:e')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('d1:a0:1:a0:e')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('i03e')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('l01:ae')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('9999:x')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('l0:')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('d0:0:')
        assert 0
    except ValueError:
        pass
    try:
        bdecode('d0:')
        assert 0
    except ValueError:
        pass

bencached_marker = []


class Bencached:

    def __init__(self, s):
        self.marker = bencached_marker
        self.bencoded = s

BencachedType = type(Bencached(''))  # insufficient, but good as a filter


def encode_bencached(x, r):
    assert x.marker == bencached_marker
    r.append(x.bencoded)


def encode_int(x, r):
    r.extend(('i', str(x), 'e'))


def encode_bool(x, r):
    encode_int(int(x), r)


def encode_string(x, r):
    r.extend((str(len(x)), ':', x))


def encode_unicode(x, r):
    # r.append('u')
    encode_string(x.encode('UTF-8'), r)


def encode_list(x, r):
    r.append('l')
    for e in x:
        encode_func[type(e)](e, r)
    r.append('e')


def encode_dict(x, r):
    r.append('d')
    ilist = x.items()
    ilist.sort()
    for k, v in ilist:
        #logger.debug("bencode: Encoding %s %s", k, v)

        try:
            r.extend((str(len(k)), ':', k))
        except:
            logger.error("k: %s", k)
            raise

        encode_func[type(v)](v, r)
    r.append('e')

encode_func = {}
encode_func[BencachedType] = encode_bencached
encode_func[IntType] = encode_int
encode_func[LongType] = encode_int
encode_func[StringType] = encode_string
encode_func[ListType] = encode_list
encode_func[TupleType] = encode_list
encode_func[DictType] = encode_dict
if BooleanType:
    encode_func[BooleanType] = encode_bool
# Arno, 2010-01-27: No more implicit Unicode support.
# We should disable this now and then to see if the higher layers properly
# UTF-8 encode their fields before calling bencode
if UnicodeType:
    encode_func[UnicodeType] = encode_unicode


def bencode(x):
    r = []
    try:
        encode_func[type(x)](x, r)
    except:
        logger.error("bencode: *** error *** could not encode type %s (value: %s)", type(x), x)
        print_stack()

        print_exc()
        assert 0
    try:
        return ''.join(r)
    except:
        logger.debug("bencode: join error %s", x)
        for elem in r:
            logger.debug("elem %s has type %s", elem, type(elem))
        print_exc()
        return ''


def test_bencode():
    assert bencode(4) == 'i4e'
    assert bencode(0) == 'i0e'
    assert bencode(-10) == 'i-10e'
    assert bencode(12345678901234567890) == 'i12345678901234567890e'
    assert bencode('') == '0:'
    assert bencode('abc') == '3:abc'
    assert bencode('1234567890') == '10:1234567890'
    assert bencode([]) == 'le'
    assert bencode([1, 2, 3]) == 'li1ei2ei3ee'
    assert bencode([['Alice', 'Bob'], [2, 3]]) == 'll5:Alice3:Bobeli2ei3eee'
    assert bencode({}) == 'de'
    assert bencode({'age': 25, 'eyes': 'blue'}) == 'd3:agei25e4:eyes4:bluee'
    assert bencode({'spam.mp3': {'author': 'Alice', 'length': 100000}}) == 'd8:spam.mp3d6:author5:Alice6:lengthi100000eee'
    try:
        bencode({1: 'foo'})
        assert 0
    except AssertionError:
        pass


try:
    import psyco
    psyco.bind(bdecode)
    psyco.bind(bencode)
except ImportError:
    pass

########NEW FILE########
__FILENAME__ = bitfield
# Written by Bram Cohen, Uoti Urpala, and John Hoffman
# see LICENSE.txt for license information

from functools import reduce

try:
    True
except:
    True = 1
    False = 0
    bool = lambda x: not not x

try:
    sum([1])
    negsum = lambda a: len(a) - sum(a)
except:
    negsum = lambda a: reduce(lambda x, y: x + (not y), a, 0)


def _int_to_booleans(x):
    r = []
    for i in range(8):
        r.append(bool(x & 0x80))
        x <<= 1
    return tuple(r)

lookup_table = []
reverse_lookup_table = {}
for i in xrange(256):
    x = _int_to_booleans(i)
    lookup_table.append(x)
    reverse_lookup_table[x] = chr(i)


class Bitfield:

    def __init__(self, length=None, bitstring = None, copyfrom = None, fromarray = None, calcactiveranges=False):
        """
        STBSPEED
        @param calcactivetanges   Calculate which parts of the piece-space
        are non-zero, used an optimization for hooking in whilst live streaming.
        Only works in combination with bitstring parameter.
        """

        self.activeranges = []

        if copyfrom is not None:
            self.length = copyfrom.length
            self.array = copyfrom.array[:]
            self.numfalse = copyfrom.numfalse
            return
        if length is None:
            raise ValueError("length must be provided unless copying from another array")
        self.length = length
        if bitstring is not None:
            extra = len(bitstring) * 8 - length
            if extra < 0 or extra >= 8:
                raise ValueError
            t = lookup_table
            r = []

            chr0 = chr(0)
            inrange = False
            startpiece = 0
            countpiece = 0
            for c in bitstring:
                r.extend(t[ord(c)])

                # STBSPEED
                if calcactiveranges:
                    if c != chr0:
                        # Non-zero value, either start or continuation of range
                        if inrange:
                            # Stay in activerange
                            pass
                        else:
                            # Start activerange
                            startpiece = countpiece
                            inrange = True
                    else:
                        # Zero, either end or continuation of zeroness
                        if inrange:
                            # End of activerange
                            self.activeranges.append((startpiece, countpiece))
                            inrange = False
                        else:
                            # Stay in zero
                            pass
                    countpiece += 8

            if calcactiveranges:
                if inrange:
                    # activerange ended at end of piece space
                    self.activeranges.append((startpiece, min(countpiece, self.length - 1)))

            if extra > 0:
                if r[-extra:] != [0] * extra:
                    raise ValueError
                del r[-extra:]
            self.array = r
            self.numfalse = negsum(r)

        elif fromarray is not None:
            self.array = fromarray
            self.numfalse = negsum(self.array)
        else:
            self.array = [False] * length
            self.numfalse = length

    def __setitem__(self, index, val):
        val = bool(val)
        self.numfalse += self.array[index] - val
        self.array[index] = val

    def __getitem__(self, index):
        return self.array[index]

    def __len__(self):
        return self.length

    def tostring(self):
        booleans = self.array
        t = reverse_lookup_table
        s = len(booleans) % 8
        r = [t[tuple(booleans[x:x +8])] for x in xrange(0, len(booleans)-s, 8)]
        if s:
            r += t[tuple(booleans[-s:] + ([0] * (8 - s)))]
        return ''.join(r)

    def complete(self):
        return not self.numfalse

    def copy(self):
        return self.array[:self.length]

    def toboollist(self):
        bools = [False] * self.length
        for piece in range(0, self.length):
            bools[piece] = self.array[piece]
        return bools

    def get_active_ranges(self):
        # STBSPEED
        return self.activeranges

    def get_numtrue(self):
        return self.length - self.numfalse


def test_bitfield():
    try:
        x = Bitfield(7, 'ab')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(7, 'ab')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(9, 'abc')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(0, 'a')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(1, '')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(7, '')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(8, '')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(9, 'a')
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(7, chr(1))
        assert False
    except ValueError:
        pass
    try:
        x = Bitfield(9, chr(0) + chr(0x40))
        assert False
    except ValueError:
        pass
    assert Bitfield(0, '').tostring() == ''
    assert Bitfield(1, chr(0x80)).tostring() == chr(0x80)
    assert Bitfield(7, chr(0x02)).tostring() == chr(0x02)
    assert Bitfield(8, chr(0xFF)).tostring() == chr(0xFF)
    assert Bitfield(9, chr(0) + chr(0x80)).tostring() == chr(0) + chr(0x80)
    x = Bitfield(1)
    assert x.numfalse == 1
    x[0] = 1
    assert x.numfalse == 0
    x[0] = 1
    assert x.numfalse == 0
    assert x.tostring() == chr(0x80)
    x = Bitfield(7)
    assert len(x) == 7
    x[6] = 1
    assert x.numfalse == 6
    assert x.tostring() == chr(0x02)
    x = Bitfield(8)
    x[7] = 1
    assert x.tostring() == chr(1)
    x = Bitfield(9)
    x[8] = 1
    assert x.numfalse == 8
    assert x.tostring() == chr(0) + chr(0x80)
    x = Bitfield(8, chr(0xC4))
    assert len(x) == 8
    assert x.numfalse == 5
    assert x.tostring() == chr(0xC4)

########NEW FILE########
__FILENAME__ = clock
# Written by John Hoffman
# see LICENSE.txt for license information

import sys

from time import time

_MAXFORWARD = 100
_FUDGE = 1


class RelativeTime:

    def __init__(self):
        self.time = time()
        self.offset = 0

    def get_time(self):
        t = time() + self.offset
        if t < self.time or t > self.time + _MAXFORWARD:
            self.time += _FUDGE
            self.offset += self.time - t
            return self.time
        self.time = t
        return t

if sys.platform != 'win32':
    _RTIME = RelativeTime()

    def clock():
        return _RTIME.get_time()
else:
    from time import clock

########NEW FILE########
__FILENAME__ = configparser
# Written by Egbert Bouman
# see LICENSE.txt for license information

import ast
import codecs

from ConfigParser import RawConfigParser
from multiprocessing.synchronize import RLock

from Tribler.Core.exceptions import OperationNotPossibleAtRuntimeException


class CallbackConfigParser(RawConfigParser):

    def __init__(self, *args, **kwargs):
        RawConfigParser.__init__(self, *args, **kwargs)
        self.callback = None
        self.lock = RLock()

    def set_callback(self, callback):
        with self.lock:
            self.callback = callback

    def read_file(self, filename, encoding='utf-8'):
        with codecs.open(filename, 'rb', encoding) as fp:
            self.readfp(fp)

    def set(self, section, option, new_value):
        with self.lock:
            if self.callback and self.has_section(section) and self.has_option(section, option):
                old_value = self.get(section, option)
                if not self.callback(section, option, new_value, old_value):
                    raise OperationNotPossibleAtRuntimeException
            RawConfigParser.set(self, section, option, new_value)

    def get(self, section, option, literal_eval=True):
        with self.lock:
            value = RawConfigParser.get(self, section, option) if RawConfigParser.has_option(self, section, option) else None
            if literal_eval:
                try:
                    value = ast.literal_eval(value)
                except:
                    pass
            return value

    def copy(self):
        with self.lock:
            copied_config = CallbackConfigParser()
            for section in self.sections():
                copied_config.add_section(section)
                for option, value in self.items(section):
                    copied_config.set(section, option, value)
            return copied_config

    def write_file(self, filename, encoding='utf-8'):
        with codecs.open(filename, 'wb', encoding) as fp:
            self.write(fp)

    def write(self, fp):
        with self.lock:
            """Fixed for Unicode output"""
            if self._defaults:
                fp.write(u"[%s]\n" % DEFAULTSECT)
                for (key, value) in self._defaults.items():
                    fp.write(u"%s = %s\n" % (key, unicode(value).replace(u'\n', u'\n\t')))
                fp.write(u"\n")
            for section in self._sections:
                fp.write(u"[%s]\n" % section)
                for (key, value) in self._sections[section].items():
                    if key != u"__name__":
                        fp.write(u"%s = %s\n" % (key, unicode(value).replace(u'\n', u'\n\t')))
                fp.write(u"\n")

########NEW FILE########
__FILENAME__ = Crypto
# Written by Arno Bakker
# see LICENSE.txt for license information

import base64
from cStringIO import StringIO
from M2Crypto import BIO
from hashlib import sha1 as sha

# Switch between using Python's builtin SHA1 function or M2Crypto/OpenSSL's
# TODO: optimize such that less memory is allocated, e.g. reuse a single
# sha() object instance (hard to do here centrally with multiple threads)
#

# Arno, 2009-06-23: The OpenSSL calls used by M2Crypto's MessageDigest have
# different behaviour than the Python sha class ones. In particular, OpenSSL
# needs to make special calls to incrementally digest data (i.e., update();
# digest();update();digest(). M2Crypto's MessageDigest doesn't make these
# special calls. Due to bad programming, it will actually Segmentation
# Fault when this usage occurs. And this usage occurs during hashchecking
# (so when using VOD repeatedly, not during live), see StorageWrapper.
#
# We'll need to patch M2Crypto to work around this. In the meanwhile, I
# disable the offloading to OpenSSL for all platforms.
#

def RSA_keypair_to_pub_key_in_der(keypair):
    # Cannot use rsapubkey.save_key_der_bio(bio). It calls
    # i2d_RSAPrivateKey_bio() and appears to write just the
    # three RSA parameters, and not the extra ASN.1 stuff that
    # says "rsaEncryption". In detail:
    #
    # * pubkey.save_key_der("orig.der") gives:
    #  0:d=0  hl=3 l= 138 cons: SEQUENCE
    #  3:d=1  hl=2 l=   1 prim: INTEGER           :00
    #  6:d=1  hl=3 l= 129 prim: INTEGER           :A8D3A10FF772E1D5CEA86D88B2B09CE48A8DB2E563008372F4EF02BCB4E498B8BE974F8A7CD1398C7D408DF3B85D58FF0E3835AE96AB003898511D4914DE80008962C46E199276C35E4ABB7F1507F7E9A336CED3AFDC04F4DDA7B6941E8F15C1AD071599007C1F486C1560CBB96B8E07830F8E1849612E532833B55675E1D84B
    # 138:d=1  hl=2 l=   1 prim: INTEGER           :03
    #
    # when run through
    #   $ openssl asn1parse -in origpub.der -inform DER
    #
    # * keypair.save_pub_key("origpub.pem"). If we pass this file through asn1parse
    #         $ openssl asn1parse -in origpub.pem -inform PEM
    # we get:
    #  0:d=0  hl=3 l= 157 cons: SEQUENCE
    #  3:d=1  hl=2 l=  13 cons: SEQUENCE
    #  5:d=2  hl=2 l=   9 prim: OBJECT            :rsaEncryption
    # 16:d=2  hl=2 l=   0 prim: NULL
    # 18:d=1  hl=3 l= 139 prim: BIT STRING
    #
    # where the BIT STRING should contain the three params.
    #
    # EVP.PKey.as_der() also returns the latter, so we use that as our DER format.
    #
    # HOWEVER: The following code, when used inside a function as here, crashes
    # Python, so we can't use it:
    #
    # pkey = EVP.PKey()
    # pkey.assign_rsa(keypair)
    # return pkey.as_der()
    #
    #
    bio = BIO.MemoryBuffer()
    keypair.save_pub_key_bio(bio)
    pem = bio.read_all()
    stream = StringIO(pem)
    lines = stream.readlines()

    str_content = ''
    for i in range(1, len(lines) - 1):
        str_content += lines[i]
    return base64.standard_b64decode(str_content)

########NEW FILE########
__FILENAME__ = encoding
import logging

logger = logging.getLogger(__name__)

def _a_encode_int(value, mapping):
    """
    42 --> ('2', 'i', '42')
    """
    assert isinstance(value, int), "VALUE has invalid type: %s" % type(value)
    value = str(value).encode("UTF-8")
    return (str(len(value)).encode("UTF-8"), "i", value)


def _a_encode_long(value, mapping):
    """
    42 --> ('2', 'J', '42')
    """
    assert isinstance(value, long), "VALUE has invalid type: %s" % type(value)
    value = str(value).encode("UTF-8")
    return (str(len(value)).encode("UTF-8"), "J", value)


def _a_encode_float(value, mapping):
    """
    4.2 --> ('3', 'f', '4.2')
    """
    assert isinstance(value, float), "VALUE has invalid type: %s" % type(value)
    value = str(value).encode("UTF-8")
    return (str(len(value)).encode("UTF-8"), "f", value)


def _a_encode_unicode(value, mapping):
    """
    'foo-bar' --> ('7', 's', 'foo-bar')
    """
    assert isinstance(value, unicode), "VALUE has invalid type: %s" % type(value)
    value = value.encode("UTF-8")
    return (str(len(value)).encode("UTF-8"), "s", value)


def _a_encode_bytes(value, mapping):
    """
    'foo-bar' --> ('7', 'b', 'foo-bar')
    """
    assert isinstance(value, bytes), "VALUE has invalid type: %s" % type(value)
    return (str(len(value)).encode("UTF-8"), "b", value)


def _a_encode_list(values, mapping):
    """
    [1,2,3] --> ['3', 'l', '1', 'i', '1', '1', 'i', '2', '1', 'i', '3']
    """
    assert isinstance(values, list), "VALUE has invalid type: %s" % type(values)
    encoded = [str(len(values)).encode("UTF-8"), "l"]
    extend = encoded.extend
    for value in values:
        extend(mapping[type(value)](value, mapping))
    return encoded


def _a_encode_set(values, mapping):
    """
    [1,2,3] --> ['3', 'l', '1', 'i', '1', '1', 'i', '2', '1', 'i', '3']
    """
    assert isinstance(values, set), "VALUE has invalid type: %s" % type(values)
    encoded = [str(len(values)).encode("UTF-8"), "L"]
    extend = encoded.extend
    for value in values:
        extend(mapping[type(value)](value, mapping))
    return encoded


def _a_encode_tuple(values, mapping):
    """
    (1,2) --> ['2', 't', '1', 'i', '1', '1', 'i', '2']
    """
    assert isinstance(values, tuple), "VALUE has invalid type: %s" % type(values)
    encoded = [str(len(values)).encode("UTF-8"), "t"]
    extend = encoded.extend
    for value in values:
        extend(mapping[type(value)](value, mapping))
    return encoded


def _a_encode_dictionary(values, mapping):
    """
    {'foo':'bar', 'moo':'milk'} --> ['2', 'd', '3', 's', 'foo', '3', 's', 'bar', '3', 's', 'moo', '4', 's', 'milk']
    """
    assert isinstance(values, dict), "VALUE has invalid type: %s" % type(values)
    encoded = [str(len(values)).encode("UTF-8"), "d"]
    extend = encoded.extend
    for key, value in sorted(values.items()):
        assert type(key) in mapping, (key, values)
        assert type(value) in mapping, (value, values)
        extend(mapping[type(key)](key, mapping))
        extend(mapping[type(value)](value, mapping))
    return encoded


def _a_encode_none(value, mapping):
    """
    None --> ['0', 'n']
    """
    return ['0n']


def _a_encode_bool(value, mapping):
    """
    True  --> ['0', 'T']
    False --> ['0', 'F']
    """
    return ['0T' if value else '0F']

_a_encode_mapping = {int: _a_encode_int,
                     long: _a_encode_long,
                     float: _a_encode_float,
                     unicode: _a_encode_unicode,
                     str: _a_encode_bytes,
                     list: _a_encode_list,
                     set: _a_encode_set,
                     tuple: _a_encode_tuple,
                     dict: _a_encode_dictionary,
                     type(None): _a_encode_none,
                     bool: _a_encode_bool}

# def _b_uint_to_bytes(i):
#     assert isinstance(i, (int, long))
#     assert i >= 0
#     if i == 0:
#         return "\x00"

#     else:
#         bit8 = 16*8
#         mask8 = 2**8-1
#         mask7 = 2**7-1
#         l = []
#         while i:
#             l.append(bit8 | mask7 & i)
#             i >>= 7
#         l[0] &= mask7
#         return "".join(chr(k) for k in reversed(l))

# from math import log
# from struct import pack

# def _b_encode_int(value, mapping):
#     """
#     42 --> (_b_uint_to_bytes(2), 'i', struct.pack('>h', 42))
#     """
#     assert isinstance(value, (int, long)), "VALUE has invalid type: %s" % type(value)
#     length = 2 if value == 0 else int(log(value, 2) / 8) + 1
#     return (_b_uint_to_bytes(length), "i", pack({1:">h", 2:">h", 3:">i", 4:">i", 5:">l", 6:">l", 7:">l", 8:">l"}.get(length, ">q"), value))

# def _b_encode_float(value, mapping):
#     """
#     4.2 --> (_b_uint_to_bytes(4), 'f', struct.pack('>f', 4.2))
#     """
#     assert isinstance(value, float), "VALUE has invalid type: %s" % type(value)
#     return (_b_uint_to_bytes(4), "f", pack(">f", value))

# def _b_encode_unicode(value, mapping):
#     """
#     'foo-bar' --> (_b_uint_to_bytes(7), 's', 'foo-bar')
#     """
#     assert isinstance(value, unicode), "VALUE has invalid type: %s" % type(value)
#     value = value.encode("UTF-8")
#     return ("s", _b_uint_to_bytes(len(value)), value)

# def _b_encode_bytes(value, mapping):
#     """
#     'foo-bar' --> (_b_uint_to_bytes(7), 'b', 'foo-bar')
#     """
#     assert isinstance(value, bytes), "VALUE has invalid type: %s" % type(value)
#     return (_b_uint_to_bytes(len(value)), "b", value)

# def _b_encode_list(values, mapping):
#     """
#     [1,2,3] --> [_b_uint_to_bytes(3), 'l'] + _b_encode_int(1) + _b_encode_int(2) + _b_encode_int(3)
#     """
#     assert isinstance(values, list), "VALUE has invalid type: %s" % type(value)
#     encoded = [_b_uint_to_bytes(len(values)), "l"]
#     extend = encoded.extend
#     for value in values:
#         extend(mapping[type(value)](value, mapping))
#     return encoded

# def _b_encode_tuple(values, mapping):
#     """
#     (1,2) --> [_b_uint_to_bytes(3), 't'] + _b_encode_int(1) + _b_encode_int(2)
#     """
#     assert isinstance(values, tuple), "VALUE has invalid type: %s" % type(value)
#     encoded = [_b_uint_to_bytes(len(values)), "t"]
#     extend = encoded.extend
#     for value in values:
#         extend(mapping[type(value)](value, mapping))
#     return encoded

# def _b_encode_dictionary(values, mapping):
#     """
#     {'foo':'bar', 'moo':'milk'} --> [_b_uint_to_bytes(2), 'd'] + _b_encode_bytes('foo') + _b_encode_bytes('bar') + _b_encode_bytes('moo') +_b_encode_bytes('milk')
#     """
#     assert isinstance(values, dict), "VALUE has invalid type: %s" % type(value)
#     encoded = [_b_uint_to_bytes(len(values)), "d"]
#     extend = encoded.extend
#     for key, value in sorted(values.items()):
#         assert type(key) in mapping, (key, values)
#         assert type(value) in mapping, (value, values)
#         extend(mapping[type(key)](key, mapping))
#         extend(mapping[type(value)](value, mapping))
#     return encoded

# def _b_encode_none(value, mapping):
#     """
#     None --> [_b_uint_to_bytes(0), 'n']
#     """
#     return [_b_uint_to_bytes(0), "n"]

# def _b_encode_bool(value, mapping):
#     """
#     True  --> [_b_uint_to_bytes(0), 'T']
#     False --> [_b_uint_to_bytes(0), 'F']
#     """
#     return [_b_uint_to_bytes(0), "T" if value else "F"]

# _b_encode_mapping = {int:_b_encode_int,
#                      long:_b_encode_int,
#                      float:_b_encode_float,
#                      unicode:_b_encode_unicode,
#                      str:_b_encode_bytes,
#                      list:_b_encode_list,
#                      tuple:_b_encode_tuple,
#                      dict:_b_encode_dictionary,
#                      type(None):_b_encode_none,
#                      bool:_b_encode_bool}


def bytes_to_uint(stream, offset=0):
    assert isinstance(stream, str)
    assert isinstance(offset, (int, long))
    assert offset >= 0
    bit8 = 16 * 8
    mask7 = 2 ** 7 -1
    i = 0
    while offset < len(stream):
        c = ord(stream[offset])
        i |= mask7 & c
        if not bit8 & c:
            return i
        offset += 1
        i <<= 7
    raise ValueError()


def encode(data, version="a"):
    """
    Encode DATA into version 'a' binary stream.

    DATA can be any: int, float, string, unicode, list, tuple, or
    dictionary.

    Lists are considered to be tuples.  I.e. when decoding an
    encoded list it will come out as a tuple.

    The encoding process is done using version 'a' which is
    indicated by the first byte of the resulting binary stream.
    """
    assert isinstance(version, str)
    if version == "a":
        return "a" + "".join(_a_encode_mapping[type(data)](data, _a_encode_mapping))
    elif version == "b":
        # raise ValueError("This version is not yet implemented")
        return "b" + "".join(_b_encode_mapping[type(data)](data, _b_encode_mapping))
    else:
        raise ValueError("Unknown encode version")


def _a_decode_int(stream, offset, count, _):
    """
    'a2i42',3,2 --> 5,42
    """
    return offset + count, int(stream[offset:offset +count])


def _a_decode_long(stream, offset, count, _):
    """
    'a2J42',3,2 --> 5,42
    """
    return offset + count, long(stream[offset:offset +count])


def _a_decode_float(stream, offset, count, _):
    """
    'a3f4.2',3,3 --> 6,4.2
    """
    return offset + count, float(stream[offset:offset +count])


def _a_decode_unicode(stream, offset, count, _):
    """
    'a3sbar',3,3 --> 6,u'bar'
    """
    if len(stream) >= offset + count:
        return offset + count, stream[offset:offset +count].decode("UTF-8")
    else:
        raise ValueError("Invalid stream length", len(stream), offset + count)


def _a_decode_bytes(stream, offset, count, _):
    """
    'a3bfoo',3,3 --> 6,'foo'
    """
    if len(stream) >= offset + count:
        return offset + count, stream[offset:offset +count]
    else:
        raise ValueError("Invalid stream length", len(stream), offset + count)


def _a_decode_list(stream, offset, count, mapping):
    """
    'a1l3i123',3,1 --> 8,[123]
    'a2l1i41i2',3,1 --> 8,[4,2]
    """
    container = []
    for _ in range(count):

        index = offset
        while 48 <= ord(stream[index]) <= 57:
            index += 1
        offset, value = mapping[stream[index]](stream, index + 1, int(stream[offset:index]), mapping)
        container.append(value)

    return offset, container


def _a_decode_set(stream, offset, count, mapping):
    """
    'a1L3i123',3,1 --> 8,set(123)
    'a2L1i41i2',3,1 --> 8,set(4,2)
    """
    container = set()
    for _ in range(count):

        index = offset
        while 48 <= ord(stream[index]) <= 57:
            index += 1
        offset, value = mapping[stream[index]](stream, index + 1, int(stream[offset:index]), mapping)
        container.add(value)

    return offset, container


def _a_decode_tuple(stream, offset, count, mapping):
    """
    'a1t3i123',3,1 --> 8,[123]
    'a2t1i41i2',3,1 --> 8,[4,2]
    """
    container = []
    for _ in range(count):

        index = offset
        while 48 <= ord(stream[index]) <= 57:
            index += 1
        offset, value = mapping[stream[index]](stream, index + 1, int(stream[offset:index]), mapping)
        container.append(value)

    return offset, tuple(container)


def _a_decode_dictionary(stream, offset, count, mapping):
    """
    'a2d3sfoo3sbar3smoo4smilk',3,2 -> 24,{'foo':'bar', 'moo':'milk'}
    """
    container = {}
    for _ in range(count):

        index = offset
        while 48 <= ord(stream[index]) <= 57:
            index += 1
        offset, key = mapping[stream[index]](stream, index + 1, int(stream[offset:index]), mapping)

        index = offset
        while 48 <= ord(stream[index]) <= 57:
            index += 1
        offset, value = mapping[stream[index]](stream, index + 1, int(stream[offset:index]), mapping)

        container[key] = value

    if len(container) < count:
        raise ValueError("Duplicate key in dictionary")
    return offset, container


def _a_decode_none(stream, offset, count, mapping):
    """
    'a0n',3,0 -> 3,None
    """
    assert count == 0
    return offset, None


def _a_decode_true(stream, offset, count, mapping):
    """
    'a0T',3,1 -> 3,True
    """
    assert count == 0
    return offset, True


def _a_decode_false(stream, offset, count, mapping):
    """
    'a0F',3,1 -> 3,False
    """
    assert count == 0
    return offset, False

_a_decode_mapping = {"i": _a_decode_int,
                     "J": _a_decode_long,
                     "f": _a_decode_float,
                     "s": _a_decode_unicode,
                     "b": _a_decode_bytes,
                     "l": _a_decode_list,
                     "L": _a_decode_set,
                     "t": _a_decode_tuple,
                     "d": _a_decode_dictionary,
                     "n": _a_decode_none,
                     "T": _a_decode_true,
                     "F": _a_decode_false}


def decode(stream, offset=0):
    """
    Decode STREAM from index OFFSET and further into a python data
    structure.

    Returns the new OFFSET of the stream and the decoded data.

    Only version 'a' decoding is supported.  This version is
    indicated by the first byte in the binary STREAM.
    """
    assert isinstance(stream, bytes), "STREAM has invalid type: %s" % type(stream)
    assert isinstance(offset, int), "OFFSET has invalid type: %s" % type(offset)
    if stream[offset] == "a":
        index = offset + 1
        while 48 <= ord(stream[index]) <= 57:
            index += 1
        return _a_decode_mapping[stream[index]](stream, index + 1, int(stream[offset +1:index]), _a_decode_mapping)

    raise ValueError("Unknown version found")

if __debug__:
    if __name__ == "__main__":
        # def uint_to_bytes(i):
        #     assert isinstance(i, (int, long))
        #     assert i >= 0
        #     if i == 0:
        #         return "\x00"

        #     else:
        #         bit8 = 16*8
        #         mask8 = 2**8-1
        #         mask7 = 2**7-1
        #         l = []
        #         while i:
        #             l.append(bit8 | mask7 & i)
        #             i >>= 7
        #         l[0] &= mask7
        #         return "".join(chr(k) for k in reversed(l))

        # def bytes_to_uint(stream, offset=0):
        #     assert isinstance(stream, str)
        #     assert isinstance(offset, (int, long))
        #     assert offset >= 0
        #     bit8 = 16*8
        #     mask7 = 2**7-1
        #     i = 0
        #     while offset < len(stream):
        #         c = ord(stream[offset])
        #         i |= mask7 & c
        #         if not bit8 & c:
        #             return i
        #         offset += 1
        #         i <<= 7
        #     raise ValueError()

        # def test(i):
        #     s = uint_to_bytes(i)
        #     print "%5d %15s %8s" % (i, bin(i), s.encode("HEX")), [bin(ord(x)) for x in s]
        #     j = bytes_to_uint(s + "kjdhsakdjhkjhsdasa")
        #     assert i == j, (i, j)
        #     return s

        # test(int("10110101010", 2))
        # for i in xrange(-10, 1024*150):
        #     if len(test(i)) > 2:
        #         break
        # exit(0)

        from Tribler.Core.BitTornado.bencode import bencode, bdecode

        def test(in_, verbose=True):
            value = in_
            s = encode(value)
            length, v = decode(s)
            if verbose:
                logger.info("dispersy A %s : %s -> %s", length, value, s)
            else:
                logger.info("dispersy A %s", length)
            assert len(s) == length, (len(s), length)
            assert value == v, (value, v)

            # value = in_
            # s = encode(value, "b")
            # length = len(s)
            # length, v = decode(s)
            # if verbose:
            #     print "dispersy B", length, ":", value, "->", s
            # else:
            #     print "dispersy B", length
            # assert len(s) == length, (len(s), length)
            # assert value == v, (value, v)

            value = in_
            if isinstance(value, (float, type(None), set)):
                logger.info("bittorrent not supported")
            else:
                # exception: tuple types are encoded as list
                if isinstance(value, tuple):
                    value = list(value)

                # exception: dictionary types may only have string for keys
                if isinstance(value, dict):
                    convert = lambda a: str(a) if not isinstance(a, (str, unicode)) else a
                    value = dict((convert(a), b) for a, b in value.iteritems())

                s = bencode(value)
                v = bdecode(s)

                if verbose:
                    logger.info("bittorrent %d : %s -> %s", len(s), value, s)
                else:
                    logger.info("bittorrent %d", len(s))
                assert value == v, (value, v)

        test(4242)
        test(42)
        test(42)
        test(4.2)
        test(0.0000000000000000042)
        test("foo")
        test(u"bar")
        test([123])
        test([4, 2])
        test((4, 2))
        test({'foo': 'bar', 'moo': 'milk'})
        test({u'foo': 'bar'})
        test({4: 2})
        test(None)
        test(range(1000), False)
        test(["F" * 20 for _ in range(1000)], False)
        test(set(['a', 'b']))
        test(True)
        test(False)
        test([True, True, False, True, False, False])

########NEW FILE########
__FILENAME__ = parseargs
# Written by Bill Bumgarner and Bram Cohen
# see LICENSE.txt for license information

from types import IntType, LongType, NoneType, StringType, FloatType, BooleanType
from cStringIO import StringIO
import logging

logger = logging.getLogger(__name__)

def splitLine(line, COLS=80, indent=10):
    indent = " " * indent
    width = COLS - (len(indent) + 1)
    if indent and width < 15:
        width = COLS - 2
        indent = " "
    s = StringIO()
    i = 0
    for word in line.split():
        if i == 0:
            s.write(indent + word)
            i = len(word)
            continue
        if i + len(word) >= width:
            s.write('\n' + indent +word)
            i = len(word)
            continue
        s.write(' ' + word)
        i += len(word) + 1
    return s.getvalue()


def formatDefinitions(options, COLS, presets={}):
    s = StringIO()
    for (longname, default, doc) in options:
        s.write('--' + longname + ' <arg>\n')
        default = presets.get(longname, default)
        if type(default) in (IntType, LongType):
            try:
                default = int(default)
            except:
                pass
        if default is not None:
            doc += ' (defaults to ' + repr(default) + ')'
        s.write(splitLine(doc, COLS, 10))
        s.write('\n\n')
    return s.getvalue()


def usage(string):
    raise ValueError(string)


def defaultargs(options):
    l = {}
    for (longname, default, doc) in options:
        if default is not None:
            l[longname] = default
    return l


def parseargs(argv, options, minargs=None, maxargs= None, presets = {}):
    config = {}
    longkeyed = {}
    for option in options:
        longname, default, doc = option
        longkeyed[longname] = option
        config[longname] = default
    for longname in presets.keys():        # presets after defaults but before arguments
        config[longname] = presets[longname]
    options = []
    args = []
    pos = 0
    while pos < len(argv):
        if argv[pos][:2] != '--':
            args.append(argv[pos])
            pos += 1
        else:
            if pos == len(argv) - 1:
                usage('parameter passed in at end with no value')
            key, value = argv[pos][2:], argv[pos + 1]
            pos += 2
            if key not in longkeyed:
                usage('unknown key --' + key)
            longname, default, doc = longkeyed[key]
            try:
                t = type(config[longname])
                if t is NoneType or t is StringType:
                    config[longname] = value
                elif t is IntType:
                    config[longname] = int(value)
                elif t is LongType:
                    config[longname] = long(value)
                elif t is FloatType:
                    config[longname] = float(value)
                elif t is BooleanType:
                    config[longname] = bool(value)
                else:
                    logger.info('parseargs: unknown type is %s', t)
                    assert 0
            except ValueError as e:
                usage('wrong format of --%s - %s' % (key, str(e)))
    for key, value in config.items():
        if value is None:
            usage("Option --%s is required." % key)
    if minargs is not None and len(args) < minargs:
        usage("Must supply at least %d args." % minargs)
    if maxargs is not None and len(args) > maxargs:
        usage("Too many args - %d max." % maxargs)
    return (config, args)


def test_parseargs():
    assert parseargs(('d', '--a', 'pq', 'e', '--b', '3', '--c', '4.5', 'f'), (('a', 'x', ''), ('b', 1, ''), ('c', 2.3, ''))) == ({'a': 'pq', 'b': 3, 'c': 4.5}, ['d', 'e', 'f'])
    assert parseargs([], [('a', 'x', '')]) == ({'a': 'x'}, [])
    assert parseargs(['--a', 'x', '--a', 'y'], [('a', '', '')]) == ({'a': 'y'}, [])
    try:
        parseargs([], [('a', 'x', '')])
    except ValueError:
        pass
    try:
        parseargs(['--a', 'x'], [])
    except ValueError:
        pass
    try:
        parseargs(['--a'], [('a', 'x', '')])
    except ValueError:
        pass
    try:
        parseargs([], [], 1, 2)
    except ValueError:
        pass
    assert parseargs(['x'], [], 1, 2) == ({}, ['x'])
    assert parseargs(['x', 'y'], [], 1, 2) == ({}, ['x', 'y'])
    try:
        parseargs(['x', 'y', 'z'], [], 1, 2)
    except ValueError:
        pass
    try:
        parseargs(['--a', '2.0'], [('a', 3, '')])
    except ValueError:
        pass
    try:
        parseargs(['--a', 'z'], [('a', 2.1, '')])
    except ValueError:
        pass

########NEW FILE########
__FILENAME__ = timeouturlopen
# Written by Feek Zindel
# see LICENSE.txt for license information

from gzip import GzipFile
from StringIO import StringIO
import httplib
import socket
import urllib2

import urllib
import urlparse
import logging

logger = logging.getLogger(__name__)

def urlOpenTimeout(url, timeout=30, referer='', *data):
    class TimeoutHTTPConnection(httplib.HTTPConnection):

        def connect(self):
            """Connect to the host and port specified in __init__."""
            msg = "getaddrinfo returns an empty list"
            for res in socket.getaddrinfo(self.host, self.port, 0,
                                          socket.SOCK_STREAM):
                af, socktype, proto, canonname, sa = res
                try:
                    self.sock = socket.socket(af, socktype, proto)
                    self.sock.settimeout(timeout)
                    if self.debuglevel > 0:
                        logger.debug("connect: (%s, %s)", self.host, self.port)
                    self.sock.connect(sa)
                except socket.error as msg:
                    if self.debuglevel > 0:
                        logger.debug('connect fail: %s, %s', self.host, self.port)
                    if self.sock:
                        self.sock.close()
                    self.sock = None
                    continue
                break
            if not self.sock:
                raise socket.error(msg)

    class TimeoutHTTPHandler(urllib2.HTTPHandler):

        def http_open(self, req):
            return self.do_open(TimeoutHTTPConnection, req)

    # Boudewijn, 09/09/10: Now accepting gzip compressed HTTP trafic.
    class GZipProcessor(urllib2.BaseHandler):

        def http_request(self, req):
            req.add_header("Accept-Encoding", "gzip")
            return req
        https_request = http_request

        def http_response(self, req, resp):
            if resp.headers.get("content-encoding") == "gzip":
                gzip = GzipFile(fileobj=StringIO(resp.read()), mode="r")
                prev_resp = resp
                resp = urllib2.addinfourl(gzip, prev_resp.headers, prev_resp.url)
                resp.code = prev_resp.code
                resp.msg = prev_resp.msg
            return resp
        https_response = http_response

    # Arno, 2010-03-09: ProxyHandler is implicit, so code already proxy aware.
    opener = urllib2.build_opener(GZipProcessor,
                                  TimeoutHTTPHandler,
                                  urllib2.HTTPDefaultErrorHandler,
                                  urllib2.HTTPRedirectHandler,)
    if referer:
        opener.addheaders = [('Referer', referer)]
    return opener.open(url, *data)


def find_proxy(url):
    """ Returns proxy host as "host:port" string """
    (scheme, netloc, path, pars, query, fragment) = urlparse.urlparse(url)
    proxies = urllib.getproxies()
    proxyhost = None
    if scheme in proxies:
        if '@' in netloc:
            sidx = netloc.find('@') + 1
        else:
            sidx = 0
        # IPVSIX TODO: what if host is IPv6 address
        eidx = netloc.find(':')
        if eidx == -1:
            eidx = len(netloc)
        host = netloc[sidx:eidx]
        if not (host == "127.0.0.1" or urllib.proxy_bypass(host)):
            proxyurl = proxies[scheme]
            proxyelems = urlparse.urlparse(proxyurl)
            proxyhost = proxyelems[1]

    logger.debug("find_proxy: Got proxies %s selected %s URL was %s", proxies, proxyhost, url)
    return proxyhost


# s = urlOpenTimeout("http://torcache.com/torrent/F91DF2C0DC38FF530BB0B90E6FCD9BF0483F7936.torrent", timeout=10)
# print len(s.read())

# s = urlOpenTimeout("http://frayja.com", timeout=10)
# print len(s.read())

########NEW FILE########
__FILENAME__ = twisted_thread
"""
Helpers to run the reactor in a separate thread, adapted from Nose's twistedtools.py
"""
from twisted.internet import reactor
from twisted.python import log

_twisted_thread = None

def threaded_reactor():
    """
    Start the Twisted reactor in a separate thread, if not already done.
    Returns the reactor.
    """
    global _twisted_thread
    if not _twisted_thread:
        from twisted.python import threadable
        from threading import Thread
        def _reactor_runner():
            reactor.suggestThreadPoolSize(1)
            reactor.run(installSignalHandlers=False)

        _twisted_thread = Thread(target=_reactor_runner, name="Twisted")
        _twisted_thread.setDaemon(True)
        _twisted_thread.start()
        def hook_observer():
            observer = log.PythonLoggingObserver()
            observer.start()
            import logging
            log.msg("PythonLoggingObserver hooked up", logLevel=logging.DEBUG)
        reactor.callFromThread(hook_observer)

    return reactor, _twisted_thread

# Export global reactor variable, as Twisted does
reactor, reactor_thread = threaded_reactor()


def stop_reactor():
    """
    Stop the reactor and join the reactor thread until it stops.
    """
    global _twisted_thread

    def stop_reactor():
        """"Helper for calling stop from withing the thread."""
        reactor.stop()

    reactor.callFromThread(stop_reactor)
    reactor_thread.join()
    for p in reactor.getDelayedCalls():
        if p.active():
            p.cancel()
    _twisted_thread = None

########NEW FILE########
__FILENAME__ = unicode
# Written by Arno Bakker
# see LICENSE.txt for license information

import sys


def bin2unicode(bin, possible_encoding='utf_8'):
    sysenc = sys.getfilesystemencoding()
    if possible_encoding is None:
        possible_encoding = sysenc
    try:
        return bin.decode(possible_encoding)
    except:
        try:
            if possible_encoding == sysenc:
                raise
            return bin.decode(sysenc)
        except:
            try:
                return bin.decode('utf_8')
            except:
                try:
                    return bin.decode('iso-8859-1')
                except:
                    try:
                        return bin.decode(sys.getfilesystemencoding())
                    except:
                        return bin.decode(sys.getdefaultencoding(), errors='replace')


def str2unicode(s):
    try:
        s = unicode(s)
    except:
        flag = 0
        for encoding in [sys.getfilesystemencoding(), 'utf_8', 'iso-8859-1', 'unicode-escape']:
            try:
                s = unicode(s, encoding)
                flag = 1
                break
            except:
                pass
        if flag == 0:
            try:
                s = unicode(s, sys.getdefaultencoding(), errors='replace')
            except:
                pass
    return s


def dunno2unicode(dunno):
    newdunno = None
    if isinstance(dunno, unicode):
        newdunno = dunno
    else:
        try:
            newdunno = bin2unicode(dunno)
        except:
            newdunno = str2unicode(dunno)
    return newdunno


def name2unicode(metadata):
    if 'name.utf-8' in metadata['info']:
        namekey = 'name.utf-8'
    else:
        namekey = 'name'
    if 'encoding' in metadata:
        encoding = metadata['encoding']
        metadata['info'][namekey] = bin2unicode(metadata['info'][namekey], encoding)
    else:
        metadata['info'][namekey] = bin2unicode(metadata['info'][namekey])

    # change metainfo['info']['name'] to metainfo['info'][namekey], just in case...
    # roer888 TODO: Never tested the following 2 lines
    if namekey != 'name':
        metadata['info']['name'] = metadata['info'][namekey]

    return namekey


def unicode2str(s):
    if not isinstance(s, unicode):
        return s
    return s.encode(sys.getfilesystemencoding())

########NEW FILE########
__FILENAME__ = utilities
# Written by Jie Yang
# see LICENSE.txt for license information

from base64 import encodestring, b32decode
from Tribler.Core.Utilities.Crypto import sha
import sys
import os
from types import StringType, LongType, IntType, ListType, DictType
import urlparse
from traceback import print_exc
from urlparse import urlsplit, parse_qsl
import binascii
import logging

logger = logging.getLogger(__name__)


def isInteger(str_integer):
    try:
        int(str_integer)
        return True
    except:
        return False


def validTorrentFile(metainfo):
    # Jie: is this function too strict? Many torrents could not be downloaded
    if not isinstance(metainfo, DictType):
        raise ValueError('metainfo not dict')

    if 'info' not in metainfo:
        raise ValueError('metainfo misses key info')

    if 'announce' in metainfo and not isValidURL(metainfo['announce']):
        # Niels: Some .torrent files have a dht:// url in the announce field.
        if not metainfo['announce'].startswith('dht:'):
            raise ValueError('announce URL bad')

    # http://www.bittorrent.org/DHT_protocol.html says both announce and nodes
    # are not allowed, but some torrents (Azureus?) apparently violate this.

    # if 'announce' in metainfo and 'nodes' in metainfo:
    #    raise ValueError('both announce and nodes present')

    if 'nodes' in metainfo:
        nodes = metainfo['nodes']
        if not isinstance(nodes, ListType):
            raise ValueError('nodes not list, but ' + repr(type(nodes)))
        for pair in nodes:
            if not isinstance(pair, ListType) and len(pair) != 2:
                raise ValueError('node not 2-item list, but ' + repr(type(pair)))
            host, port = pair
            if not isinstance(host, StringType):
                raise ValueError('node host not string, but ' + repr(type(host)))
            if not isinstance(port, IntType):
                raise ValueError('node port not int, but ' + repr(type(port)))

    if not ('announce' in metainfo or 'nodes' in metainfo):
        # Niels: 07/06/2012, disabling this check, modifying metainfo to allow for ill-formatted torrents
        metainfo['nodes'] = []
        # raise ValueError('announce and nodes missing')

    # 04/05/10 boudewijn: with the introduction of magnet links we
    # also allow for peer addresses to be (temporarily) stored in the
    # metadata.  Typically these addresses are recently gathered.
    if "initial peers" in metainfo:
        if not isinstance(metainfo["initial peers"], list):
            raise ValueError("initial peers not list, but %s" % type(metainfo["initial peers"]))
        for address in metainfo["initial peers"]:
            if not (isinstance(address, tuple) and len(address) == 2):
                raise ValueError("address not 2-item tuple, but %s" % type(address))
            if not isinstance(address[0], str):
                raise ValueError("address host not string, but %s" % type(address[0]))
            if not isinstance(address[1], int):
                raise ValueError("address port not int, but %s" % type(address[1]))

    info = metainfo['info']
    if not isinstance(info, DictType):
        raise ValueError('info not dict')

    if 'root hash' in info:
        infokeys = ['name', 'piece length', 'root hash']
    elif 'live' in info:
        infokeys = ['name', 'piece length', 'live']
    else:
        infokeys = ['name', 'piece length', 'pieces']
    for key in infokeys:
        if key not in info:
            raise ValueError('info misses key ' + key)
    name = info['name']
    if not isinstance(name, StringType):
        raise ValueError('info name is not string but ' + repr(type(name)))
    pl = info['piece length']
    if not isinstance(pl, IntType) and not isinstance(pl, LongType):
        raise ValueError('info piece size is not int, but ' + repr(type(pl)))
    if 'root hash' in info:
        rh = info['root hash']
        if not isinstance(rh, StringType) or len(rh) != 20:
            raise ValueError('info roothash is not 20-byte string')
    elif 'live' in info:
        live = info['live']
        if not isinstance(live, DictType):
            raise ValueError('info live is not a dict')
        else:
            if 'authmethod' not in live:
                raise ValueError('info live misses key' + 'authmethod')
    else:
        p = info['pieces']
        if not isinstance(p, StringType) or len(p) % 20 != 0:
            raise ValueError('info pieces is not multiple of 20 bytes')

    if 'length' in info:
        # single-file torrent
        if 'files' in info:
            raise ValueError('info may not contain both files and length key')

        l = info['length']
        if not isinstance(l, IntType) and not isinstance(l, LongType):
            raise ValueError('info length is not int, but ' + repr(type(l)))
    else:
        # multi-file torrent
        if 'length' in info:
            raise ValueError('info may not contain both files and length key')

        files = info['files']
        if not isinstance(files, ListType):
            raise ValueError('info files not list, but ' + repr(type(files)))

        filekeys = ['path', 'length']
        for file in files:
            for key in filekeys:
                if key not in file:
                    raise ValueError('info files missing path or length key')

            p = file['path']
            if not isinstance(p, ListType):
                raise ValueError('info files path is not list, but ' + repr(type(p)))
            for dir in p:
                if not isinstance(dir, StringType):
                    raise ValueError('info files path is not string, but ' + repr(type(dir)))

            l = file['length']
            if not isinstance(l, IntType) and not isinstance(l, LongType):
                raise ValueError('info files length is not int, but ' + repr(type(l)))

    # common additional fields
    if 'announce-list' in metainfo:
        al = metainfo['announce-list']
        if not isinstance(al, ListType):
            raise ValueError('announce-list is not list, but ' + repr(type(al)))
        for tier in al:
            if not isinstance(tier, ListType):
                raise ValueError('announce-list tier is not list ' + repr(tier))
        # Jie: this limitation is not necessary
#            for url in tier:
#                if not isValidURL(url):
#                    raise ValueError('announce-list url is not valid '+`url`)

    if 'azureus_properties' in metainfo:
        azprop = metainfo['azureus_properties']
        if not isinstance(azprop, DictType):
            raise ValueError('azureus_properties is not dict, but ' + repr(type(azprop)))
        if 'Content' in azprop:
            content = azprop['Content']
            if not isinstance(content, DictType):
                raise ValueError('azureus_properties content is not dict, but ' + repr(type(content)))
            if 'thumbnail' in content:
                thumb = content['thumbnail']
                if not isinstance(content, StringType):
                    raise ValueError('azureus_properties content thumbnail is not string')

    # Perform check on httpseeds/url-list fields
    if 'url-list' in metainfo:
        if 'files' in metainfo['info']:
            # Only single-file mode allowed for http seeding
            del metainfo['url-list']
            logger.warn("Warning: Only single-file mode supported with HTTP seeding. HTTP seeding disabled")
        elif not isinstance(metainfo['url-list'], ListType):
            del metainfo['url-list']
            logger.warn("Warning: url-list is not of type list. HTTP seeding disabled")
        else:
            for url in metainfo['url-list']:
                if not isValidURL(url):
                    del metainfo['url-list']
                    logger.warn("Warning: url-list url is not valid: %s HTTP seeding disabled", repr(url))
                    break

    if 'httpseeds' in metainfo:
        if not isinstance(metainfo['httpseeds'], ListType):
            del metainfo['httpseeds']
            logger.warn("Warning: httpseeds is not of type list. HTTP seeding disabled")
        else:
            for url in metainfo['httpseeds']:
                if not isValidURL(url):
                    del metainfo['httpseeds']
                    logger.warn("Warning: httpseeds url is not valid: %s HTTP seeding disabled", repr(url))
                    break


def isValidTorrentFile(metainfo):
    try:
        validTorrentFile(metainfo)
        return True
    except:
        print_exc()
        return False


def isValidURL(url):
    if url.lower().startswith('udp'):    # exception for udp
        url = url.lower().replace('udp', 'http', 1)
    r = urlparse.urlsplit(url)
    # if DEBUG:
    #     print >>sys.stderr,"isValidURL:",r

    if r[0] == '' or r[1] == '':
        return False
    return True


def show_permid(permid):
    # Full BASE64-encoded. Must not be abbreviated in any way.
    if not permid:
        return 'None'
    return encodestring(permid).replace("\n", "")
    # Short digest
    # return sha(permid).hexdigest()


def show_permid_short(permid):
    if not permid:
        return 'None'
    s = encodestring(permid).replace("\n", "")
    return s[-10:]
    # return encodestring(sha(s).digest()).replace("\n","")


def find_prog_in_PATH(prog):
    envpath = os.path.expandvars('${PATH}')
    if sys.platform == 'win32':
        splitchar = ';'
    else:
        splitchar = ':'
    paths = envpath.split(splitchar)
    foundat = None
    for path in paths:
        fullpath = os.path.join(path, prog)
        if os.access(fullpath, os.R_OK | os.X_OK):
            foundat = fullpath
            break
    return foundat


def get_collected_torrent_filename(infohash):
    # Arno: Better would have been the infohash in hex.
    filename = sha(infohash).hexdigest() + '.torrent'    # notice: it's sha1-hash of infohash
    return filename
    # exceptions will be handled by got_metadata()


def parse_magnetlink(url):
    # url must be a magnet link
    dn = None
    xt = None
    trs = []

    logger.debug("parse_magnetlink() %s", url)

    schema, netloc, path, query, fragment = urlsplit(url)
    if schema == "magnet":
        # magnet url's do not conform to regular url syntax (they
        # do not have a netloc.)  This causes path to contain the
        # query part.
        if "?" in path:
            pre, post = path.split("?", 1)
            if query:
                query = "&".join((post, query))
            else:
                query = post

        for key, value in parse_qsl(query):
            if key == "dn":
                # convert to unicode
                dn = value.decode() if not isinstance(value, unicode) else value

            elif key == "xt" and value.startswith("urn:btih:"):
                # vliegendhart: Adding support for base32 in magnet links (BEP 0009)
                encoded_infohash = value[9:49]
                if len(encoded_infohash) == 32:
                    xt = b32decode(encoded_infohash)
                else:
                    xt = binascii.unhexlify(encoded_infohash)

            elif key == "tr":
                trs.append(value)

        logger.debug("parse_magnetlink() NAME: %s", dn)
        logger.debug("parse_magnetlink() HASH: %s", xt)
        logger.debug("parse_magnetlink() TRACS: %s", trs)

    return (dn, xt, trs)


if __name__ == '__main__':

    torrenta = {'name': 'a', 'swarmsize': 12}
    torrentb = {'name': 'b', 'swarmsize': 24}
    torrentc = {'name': 'c', 'swarmsize': 18, 'Web2': True}
    torrentd = {'name': 'b', 'swarmsize': 36, 'Web2': True}

    torrents = [torrenta, torrentb, torrentc, torrentd]
    logger.debug(repr(multisort_dictlist(torrents, ["Web2", ("swarmsize", "decrease")])))


    # d = {'a':1,'b':[1,2,3],'c':{'c':2,'d':[3,4],'k':{'c':2,'d':[3,4]}}}
    # print_dict(d)

########NEW FILE########
__FILENAME__ = win32regchecker
# Written by ABC authors and Arno Bakker
# see LICENSE.txt for license information

import sys
import logging

if (sys.platform == 'win32'):
    import _winreg

    # short for PyHKEY from "_winreg" module
    HKCR = _winreg.HKEY_CLASSES_ROOT
    HKLM = _winreg.HKEY_LOCAL_MACHINE
    HKCU = _winreg.HKEY_CURRENT_USER
else:
    HKCR = 0
    HKLM = 1
    HKCU = 2

logger = logging.getLogger(__name__)


class Win32RegChecker:

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

    def readRootKey(self, key_name, value_name=""):
        return self.readKey(HKCR, key_name, value_name)

    def readKey(self, hkey, key_name, value_name=""):
        if (sys.platform != 'win32'):
            return None

        try:
            # test that shell/open association with ABC exist
            self._logger.debug("win32regcheck: Opening %s %s", key_name, value_name)
            full_key = _winreg.OpenKey(hkey, key_name, 0, _winreg.KEY_READ)

            self._logger.debug("win32regcheck: Open returned %s", full_key)

            value_data, value_type = _winreg.QueryValueEx(full_key, value_name)
            self._logger.debug("win32regcheck: Read %s %s", value_data, value_type)
            _winreg.CloseKey(full_key)

            return value_data
        except Exception as ex:
            self._logger.exception("hkey: %s, key_name: %s, value_name: %s", hkey, key_name, value_name)
            # error, test failed, key don't exist
            # (could also indicate a unicode error)
            return None


    def readKeyRecursively(self, hkey, key_name, value_name=""):
        if (sys.platform != 'win32'):
            return None

        lasthkey = hkey
        try:
            toclose = []
            keyparts = key_name.split('\\')
            self._logger.info("win32regcheck: keyparts %s", keyparts)
            for keypart in keyparts:
                if keypart == '':
                    continue
                self._logger.debug("win32regcheck: Opening %s", keypart)
                full_key = _winreg.OpenKey(lasthkey, keypart, 0, _winreg.KEY_READ)
                lasthkey = full_key
                toclose.append(full_key)

            self._logger.debug("win32regcheck: Open returned %s", full_key)

            value_data, value_type = _winreg.QueryValueEx(full_key, value_name)
            self._logger.debug("win32regcheck: Read %s %s", value_data, value_type)
            for hkey in toclose:
                _winreg.CloseKey(hkey)

            return value_data
        except Exception as ex:
            self._logger.exception("hkey: %s, key_name: %s, value_name: %s", hkey, key_name, value_name)
            # error, test failed, key don't exist
            # (could also indicate a unicode error)
            return None

    def writeKey(self, hkey, key_name, value_name, value_data, value_type):
        try:
            # kreate desired key in Windows register
            full_key = _winreg.CreateKey(hkey, key_name)
        except EnvironmentError:
            return False;
        # set desired value in created Windows register key
        _winreg.SetValueEx(full_key, value_name, 0, value_type, value_data)
        # close Windows register key
        _winreg.CloseKey(full_key)

        return True


if __name__ == "__main__":
    w = Win32RegChecker()
    winfiletype = w.readRootKey(".wmv")
    playkey = winfiletype + "\shell\play\command"
    urlplay = w.readRootKey(playkey)
    logger.info(repr(urlplay))
    openkey = winfiletype + "\shell\open\command"
    urlopen = w.readRootKey(openkey)
    logger.info(repr(urlopen))

########NEW FILE########
__FILENAME__ = version
version_id = "6.2.0-GIT"
build_date = "Mon Jan 01 00:00:01 1970"
commit_id = "none"

########NEW FILE########
__FILENAME__ = defs
# Written by Arno Bakker
# see LICENSE.txt for license information

PLAYBACKMODE_INTERNAL = 0
PLAYBACKMODE_EXTERNAL_DEFAULT = 1
PLAYBACKMODE_EXTERNAL_MIME = 2

# Arno: These modes are not what vlc returns, but Fabian's summary of that
MEDIASTATE_PLAYING = 1
MEDIASTATE_PAUSED = 2
MEDIASTATE_STOPPED = 3
MEDIASTATE_ENDED = 4

########NEW FILE########
__FILENAME__ = utils
# Written by Arno Bakker
# see LICENSE.txt for license information

import os
import sys
import logging

from traceback import print_exc

from Tribler.Core.Utilities.unicode import unicode2str

if sys.platform == 'win32':
    from Tribler.Core.Utilities.win32regchecker import Win32RegChecker, HKLM

from Tribler.Core.Video.defs import PLAYBACKMODE_INTERNAL, PLAYBACKMODE_EXTERNAL_MIME, PLAYBACKMODE_EXTERNAL_DEFAULT

videoextdefaults = ['aac', 'asf', 'avi', 'dv', 'divx', 'flac', 'flc', 'flv', 'mkv', 'mpeg', 'mpeg4', 'mpegts', 'mpg4', 'mp3', 'mp4', 'mpg', 'mkv', 'mov', 'm4v', 'ogg', 'ogm', 'ogv', 'oga', 'ogx', 'qt', 'rm', 'swf', 'ts', 'vob', 'wmv', 'wav', 'webm']

logger = logging.getLogger(__name__)


def win32_retrieve_video_play_command(ext, videourl):
    """ Use the specified extension of to find the player in the Windows registry to play the url (or file)"""
    registry = Win32RegChecker()

    logger.debug("videoplay: Looking for player for %s", unicode2str(videourl))
    if ext == '':
        return [None, None]

    winfiletype = registry.readRootKey(ext)
    logger.debug("videoplay: winfiletype is %s %s", winfiletype, type(winfiletype))
    if winfiletype is None or winfiletype == '':
        # Darn.... Try this: (VLC seems to be the one messing the registry up in the
        # first place)
        winfiletype = registry.readRootKey(ext, value_name="VLC.Backup")
        if winfiletype is None or winfiletype == '':
            return [None, None]
        # Get MIME type
    logger.debug("videoplay: Looking for player for ext %s which is type %s", ext, winfiletype)

    contenttype = registry.readRootKey(ext, value_name="Content Type")

    playkey = winfiletype + "\shell\play\command"
    urlopen = registry.readRootKey(playkey)
    if urlopen is None:
        openkey = winfiletype + "\shell\open\command"
        urlopen = registry.readRootKey(openkey)
        if urlopen is None:
            return [None, None]

    # Default is e.g. "C:\Program Files\Windows Media Player\wmplayer.exe" /prefetch:7 /Play "%L"
    # Replace %L
    suo = urlopen.strip()  # spaces
    idx = suo.find('%L')
    if idx == -1:
        # Hrrrr: Quicktime uses %1 instead of %L and doesn't seem to quote the program path
        idx = suo.find('%1')
        if idx == -1:
            return [None, None]
        else:
            replace = '%1'
            idx2 = suo.find('%2', idx)
            if idx2 != -1:
                # Hmmm, a trailer, let's get rid of it
                if suo[idx - 1] == '"':
                    suo = suo[:idx + 3]  # quoted
                else:
                    suo = suo[:idx + 1]
    else:
        replace = '%L'

    # St*pid quicktime doesn't properly quote the program path, e.g.
    # C:\Program Files\Quicktime\bla.exe "%1" instead of
    # "C:\Program Files\Quicktime\bla.exe" "%1"
    if suo[0] != '"':
        if idx > 0 and (len(suo) - 1) >= idx + 2 and suo[idx - 1] == '"' and suo[idx + 2] == '"':
            # %x is quoted
            end = max(0, idx - 2)
        else:
            end = max(0, idx - 1)
        # I assume everthing till end is the program path
        progpath = suo[0:end]
        qprogpath = quote_program_path(progpath)
        if qprogpath is None:
            return [None, None]
        suo = qprogpath + suo[end:]
        logger.debug("videoplay: new urlopen is %s", suo)
    return [contenttype, suo.replace(replace, videourl)]


def quote_program_path(progpath):
    idx = progpath.find(' ')
    if idx != -1:
        # Contains spaces, should quote if it's really path
        if not os.access(progpath, os.R_OK):
            logger.debug("videoplay: Could not find assumed progpath %s", progpath)
            return None
        return '"' + progpath + '"'
    else:
        return progpath

def escape_path(path):
    if path[0] != '"' and path[0] != "'" and path.find(' ') != -1:
        if sys.platform == 'win32':
            # Add double quotes
            path = "\"" + path + "\""
        else:
            path = "\'" + path + "\'"
    return path

def return_feasible_playback_modes():
    if sys.platform == 'darwin':
        return [PLAYBACKMODE_EXTERNAL_DEFAULT]

    l = []
    try:
        import Tribler.vlc as vlc

        # Niels: check version of vlc
        version = vlc.libvlc_get_version()
        subversions = version.split(".")
        if len(subversions) > 2:
            version = subversions[0] + "." + subversions[1]
        version = float(version)
        if version < 0.9:
            raise Exception("Incorrect vlc version. We require at least version 0.9, this is %s" % version)

        l.append(PLAYBACKMODE_INTERNAL)
    except NameError:
        logger.error("libvlc_get_version couldn't be called, no playback possible")
    except Exception:
        print_exc()

    if sys.platform == 'win32':
        l.append(PLAYBACKMODE_EXTERNAL_MIME)
        l.append(PLAYBACKMODE_EXTERNAL_DEFAULT)
    else:
        l.append(PLAYBACKMODE_EXTERNAL_DEFAULT)
    return l


# From: cherrypy.lib.httputil
def get_ranges(headervalue, content_length):
    """Return a list of (start, stop) indices from a Range header, or None.
    
    Each (start, stop) tuple will be composed of two ints, which are suitable
    for use in a slicing operation. That is, the header "Range: bytes=3-6",
    if applied against a Python string, is requesting resource[3:7]. This
    function will return the list [(3, 7)].
    
    If this function returns an empty list, you should return HTTP 416.
    """

    if not headervalue:
        return None

    result = []
    bytesunit, byteranges = headervalue.split("=", 1)
    for brange in byteranges.split(","):
        start, stop = [x.strip() for x in brange.split("-", 1)]
        if start:
            if not stop:
                stop = content_length - 1
            start, stop = int(start), int(stop)
            if start >= content_length:
                # From rfc 2616 sec 14.16:
                # "If the server receives a request (other than one
                # including an If-Range request-header field) with an
                # unsatisfiable Range request-header field (that is,
                # all of whose byte-range-spec values have a first-byte-pos
                # value greater than the current length of the selected
                # resource), it SHOULD return a response code of 416
                # (Requested range not satisfiable)."
                continue
            if stop < start:
                # From rfc 2616 sec 14.16:
                # "If the server ignores a byte-range-spec because it
                # is syntactically invalid, the server SHOULD treat
                # the request as if the invalid Range header field
                # did not exist. (Normally, this means return a 200
                # response containing the full entity)."
                return None
            result.append((start, stop + 1))
        else:
            if not stop:
                # See rfc quote above.
                return None
            # Negative subscript (last N bytes)
            result.append((content_length - int(stop), content_length))

    return result

########NEW FILE########
__FILENAME__ = VideoPlayer
# Written by Arno Bakker
# Heavily modified by Egbert Bouman
# see LICENSE.txt for license information
import os
import sys
import time
import logging

from binascii import hexlify
from traceback import print_exc
from collections import defaultdict
from multiprocessing.synchronize import RLock

from Tribler.Core.CacheDB.Notifier import Notifier
from Tribler.Core.simpledefs import NTFY_TORRENTS, NTFY_VIDEO_STARTED, DLMODE_NORMAL, NTFY_VIDEO_BUFFERING
from Tribler.Core.Libtorrent.LibtorrentDownloadImpl import VODFile

from Tribler.Core.Video.utils import win32_retrieve_video_play_command, quote_program_path, escape_path, return_feasible_playback_modes
from Tribler.Core.Video.defs import PLAYBACKMODE_INTERNAL, PLAYBACKMODE_EXTERNAL_MIME
from Tribler.Core.Video.VideoUtility import get_videoinfo
from Tribler.Core.Video.VideoServer import VideoServer
from Tribler.Core.Video.VLCWrapper import VLCWrapper


logger = logging.getLogger(__name__)


class VideoPlayer:

    __single = None

    def __init__(self, session, httpport=None):
        if VideoPlayer.__single:
            raise RuntimeError("VideoPlayer is singleton")
        VideoPlayer.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        self.session = session
        self.videoplayerpath = self.session.get_videoplayer_path()
        self.internalplayer_callback = None
        self.vod_download = None
        self.vod_fileindex = None
        self.vod_playing = None
        self.vod_info = defaultdict(dict)

        feasible = return_feasible_playback_modes()
        preferredplaybackmode = self.session.get_preferred_playback_mode()
        self.playbackmode = preferredplaybackmode if preferredplaybackmode in feasible else feasible[0]
        self.vlcwrap = VLCWrapper() if self.playbackmode == PLAYBACKMODE_INTERNAL else None

        # Start HTTP server for serving video
        self.videoserver = VideoServer.getInstance(httpport or self.session.get_videoplayer_port(), self.session)
        self.videoserver.start()

        self.notifier = Notifier.getInstance()

    def getInstance(*args, **kw):
        if VideoPlayer.__single is None:
            VideoPlayer(*args, **kw)
        return VideoPlayer.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        if VideoPlayer.__single and VideoPlayer.__single.videoserver:
            VideoPlayer.__single.videoserver.delInstance()
            VideoPlayer.__single = None
    delInstance = staticmethod(delInstance)

    def hasInstance():
        return VideoPlayer.__single and VideoPlayer.__single.vlcwrap and VideoPlayer.__single.vlcwrap.initialized
    hasInstance = staticmethod(hasInstance)

    def shutdown(self):
        if self.videoserver:
            self.videoserver.shutdown()
            self.videoserver.server_close()
        self.set_vod_download(None)

    def get_vlcwrap(self):
        return self.vlcwrap

    def set_internalplayer_callback(self, callback):
        self.internalplayer_callback = callback

    def play(self, download, fileindex):
        url = 'http://127.0.0.1:' + str(self.videoserver.port) + '/' + hexlify(download.get_def().get_id()) + '/' + str(fileindex)
        if self.playbackmode == PLAYBACKMODE_INTERNAL:
            self.launch_video_player(url, download)
        else:
            self.launch_video_player(self.get_video_player(None, url))
        self.vod_playing = None

    def seek(self, pos):
        if self.vod_download:
            self.vod_download.vod_seekpos = None
            self.vod_playing = None

    def monitor_vod(self, ds):
        dl = ds.get_download() if ds else None

        if dl != self.vod_download or not VideoPlayer.hasInstance():
            return (0, False)

        bufferprogress = ds.get_vod_prebuffering_progress_consec()

        dl_def = dl.get_def()
        dl_hash = dl_def.get_id()

        if (bufferprogress >= 1.0 and not self.vod_playing) or (bufferprogress >= 1.0 and self.vod_playing == None):
            self.vod_playing = True
            self.notifier.notify(NTFY_TORRENTS, NTFY_VIDEO_BUFFERING, (dl_hash, self.vod_fileindex, False))
        elif (bufferprogress <= 0.1 and self.vod_playing) or (bufferprogress < 1.0 and self.vod_playing == None):
            self.vod_playing = False
            self.notifier.notify(NTFY_TORRENTS, NTFY_VIDEO_BUFFERING, (dl_hash, self.vod_fileindex, True))

        if bufferprogress >= 1 and not self.vod_info[dl_hash].has_key('bitrate'):
            self.notifier.notify(NTFY_TORRENTS, NTFY_VIDEO_STARTED, (dl_hash, self.vod_fileindex))

            # Attempt to estimate the bitrate and duration of the videofile with ffmpeg.
            videofile = self.get_vod_filename(dl)
            videoanalyser = self.session.get_video_analyser_path()
            duration, bitrate, _ = get_videoinfo(videofile, videoanalyser)
            self.vod_info[dl_hash]['bitrate'] = bitrate
            self.vod_info[dl_hash]['duration'] = duration

        return (1, False)

    def get_vod_stream(self, dl_hash, wait=False):
        if not self.vod_info[dl_hash].has_key('stream') and self.session.get_download(dl_hash):
            download = self.session.get_download(dl_hash)
            vod_filename = self.get_vod_filename(download)
            while wait and not os.path.exists(vod_filename):
                time.sleep(1)
            self.vod_info[dl_hash]['stream'] = (VODFile(open(vod_filename, 'rb'), download), RLock())

        if self.vod_info[dl_hash].has_key('stream'):
            return self.vod_info[dl_hash]['stream']
        return (None, None)

    def get_vod_duration(self, dl_hash):
        return self.vod_info.get(dl_hash, {}).get('duration', 0)

    def get_vod_download(self):
        return self.vod_download

    def set_vod_download(self, download):
        if self.vod_download:
            self.vod_download.set_mode(DLMODE_NORMAL)
            vi_dict = self.vod_info.pop(self.vod_download.get_def().get_id(), None)
            if vi_dict and vi_dict.has_key('stream'):
                vi_dict['stream'][0].close()

        self.vod_download = download
        if self.vod_download:
            self.vod_download.set_state_callback(self.monitor_vod)

    def get_vod_fileindex(self):
        return self.vod_fileindex

    def set_vod_fileindex(self, fileindex):
        self.vod_fileindex = fileindex

    def get_vod_filename(self, download):
        if download.get_def().get_def_type() == 'torrent':
            if download.get_def().is_multifile_torrent():
                return os.path.join(download.get_content_dest(), download.get_selected_files()[0])
            else:
                return download.get_content_dest()

    def launch_video_player(self, cmd, download=None):
        if self.playbackmode == PLAYBACKMODE_INTERNAL:
            if self.internalplayer_callback:
                self.internalplayer_callback(cmd, download)
        else:
            # Launch an external player. Play URL from network or disk.
            try:
                self.player_out, self.player_in = os.popen2(cmd, 'b')
            except:
                print_exc()

    def get_video_player(self, ext, videourl):
        if self.playbackmode == PLAYBACKMODE_INTERNAL:
            self._logger.debug("Videoplayer: using internal player")
            return videourl
        elif self.playbackmode == PLAYBACKMODE_EXTERNAL_MIME and sys.platform == 'win32':
            _, cmd = win32_retrieve_video_play_command(ext, videourl)
            if cmd:
                self._logger.debug("Videoplayer: win32 reg said cmd is %s", cmd)
                return 'start /B "TriblerVideo" ' + cmd

        qprogpath = quote_program_path(self.videoplayerpath)
        if not qprogpath:
            return None

        qvideourl = escape_path(videourl)
        if sys.platform == 'win32':
            cmd = 'start /B "TriblerVideo" ' + qprogpath + ' ' + qvideourl
        elif sys.platform == 'darwin':
            cmd = 'open -a ' + qprogpath + ' --args ' + qvideourl
        else:
            cmd = qprogpath + ' ' + qvideourl

        self._logger.debug("Videoplayer: using external user-defined player by executing %s", cmd)

        return cmd

########NEW FILE########
__FILENAME__ = VideoServer
# Written by Egbert Bouman
# Based on SimpleServer written by Jan David Mol, Arno Bakker
# see LICENSE.txt for license information
#
import socket
import logging
import mimetypes

from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
from SocketServer import ThreadingMixIn
from threading import Event, Thread
from traceback import print_exc
from binascii import unhexlify

from Tribler.Core.simpledefs import DLMODE_VOD
from Tribler.Core.Video.utils import get_ranges


class VideoServer(ThreadingMixIn, HTTPServer):
    __single = None

    def __init__(self, port, session):
        if VideoServer.__single:
            raise RuntimeError("VideoServer is Singleton")
        VideoServer.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        self.port = port
        self.session = session

        from Tribler.Core.Video.VideoPlayer import VideoPlayer
        self.videoplayer = VideoPlayer.getInstance()

        HTTPServer.__init__(self, ("127.0.0.1", self.port), VideoRequestHandler)

        self.daemon_threads = True
        self.allow_reuse_address = True

    def getInstance(*args, **kw):
        if VideoServer.__single is None:
            VideoServer(*args, **kw)
        return VideoServer.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        VideoServer.__single = None
    delInstance = staticmethod(delInstance)

    def start(self):
        self.server_thread = Thread(target=self.serve_forever, name="VideoHTTPServerThread-1")
        self.server_thread.setDaemon(True)
        self.server_thread.start()

    def process_request_thread(self, request, client_address):
        try:
            self.finish_request(request, client_address)
            self.close_request(request)
        except socket.error:
            pass
        except Exception:
            print_exc()


class VideoRequestHandler(BaseHTTPRequestHandler):

    def __init__(self, request, client_address, server):
        self._logger = server._logger
        self.videoplayer = server.videoplayer
        BaseHTTPRequestHandler.__init__(self, request, client_address, server)

    def log_message(self, f, *args):
        pass

    def do_GET(self):
        if self.request_version == 'HTTP/1.1':
            self.protocol_version = 'HTTP/1.1'

        self._logger.debug("VideoServer: VOD request %s %s", self.client_address, self.path)
        downloadhash, fileindex = self.path.strip('/').split('/')
        downloadhash = unhexlify(downloadhash)
        download = self.server.session.get_download(downloadhash)

        if download and download.get_def().get_def_type() == 'swift':
            self._logger.error("VideoServer: ignoring VOD request for swift")
            self.send_error(404, "Not Found")
            return

        if not download or not fileindex.isdigit() or int(fileindex) > len(download.get_def().get_files()):
            self.send_error(404, "Not Found")
            return

        fileindex = int(fileindex)
        filename, length = download.get_def().get_files_as_unicode_with_length()[fileindex]

        requested_range = get_ranges(self.headers.getheader('range'), length)
        if requested_range != None and len(requested_range) != 1:
            self.send_error(416, "Requested Range Not Satisfiable")
            return

        has_changed = self.videoplayer.get_vod_fileindex() != fileindex or self.videoplayer.get_vod_download() != download
        if has_changed:
            # Notify the videoplayer (which will put the old VOD download back in normal mode).
            self.videoplayer.set_vod_fileindex(fileindex)
            self.videoplayer.set_vod_download(download)

            # Put download in sequential mode + trigger initial buffering.
            if download.get_def().get_def_type() != "torrent" or download.get_def().is_multifile_torrent():
                download.set_selected_files([filename])
            download.set_mode(DLMODE_VOD)
            download.restart()

        piecelen = 2 ** 16 if download.get_def().get_def_type() == "swift" else download.get_def().get_piece_length()
        blocksize = piecelen

        if requested_range != None:
            firstbyte, lastbyte = requested_range[0]
            nbytes2send = lastbyte - firstbyte
            self.send_response(206)
            self.send_header('Content-Range', 'bytes %d-%d/%d' % (firstbyte, lastbyte - 1, length))
        else:
            firstbyte = 0
            nbytes2send = length
            self.send_response(200)

        self._logger.debug("VideoServer: requested range %d - %d", firstbyte, firstbyte + nbytes2send)

        mimetype = mimetypes.guess_type(filename)[0]
        if mimetype:
            self.send_header('Content-Type', mimetype)
        self.send_header('Accept-Ranges', 'bytes')

        if length is not None:
            self.send_header('Content-Length', nbytes2send)
        else:
            self.send_header('Transfer-Encoding', 'chunked')

        if self.request_version == 'HTTP/1.1' and self.headers.get('Connection', '').lower() != 'close':
            self.send_header('Connection', 'Keep-Alive')
            self.send_header('Keep-Alive', 'timeout=300, max=1')

        self.end_headers()

        if has_changed:
            self.wait_for_buffer(download)

        stream, lock = self.videoplayer.get_vod_stream(downloadhash, wait=True)

        with lock:
            if stream.closed:
                return

            stream.seek(firstbyte)
            nbyteswritten = 0
            while True:
                data = stream.read(blocksize)

                if len(data) == 0:
                    break
                elif length is not None and nbyteswritten + len(data) > nbytes2send:
                    endlen = nbytes2send - nbyteswritten
                    if endlen != 0:
                        self.wfile.write(data[:endlen])
                        nbyteswritten += endlen
                    break
                else:
                    self.wfile.write(data)
                    nbyteswritten += len(data)

            if nbyteswritten != nbytes2send:
                self._logger.error("VideoServer: sent wrong amount, wanted %s got %s", nbytes2send, nbyteswritten)

            if not requested_range:
                stream.close()

    def wait_for_buffer(self, download):
        self.event = Event()
        def wait_for_buffer(ds):
            if download.vod_seekpos == None or download != self.videoplayer.get_vod_download() or ds.get_vod_prebuffering_progress() == 1.0:
                self.event.set()
                return (0, False)
            return (1.0, False)
        download.set_state_callback(wait_for_buffer)
        self.event.wait()
        self.event.clear()

########NEW FILE########
__FILENAME__ = VideoUtility
# Written by Egbert Bouman
import os
import wx
import sys
import tempfile
import subprocess

from re import search
from math import sqrt

from Tribler.Main.vwxGUI import forceAndReturnWxThread


def get_thumbnail(videofile, thumbfile, resolution, ffmpeg, timecode):
    startupinfo = None
    if sys.platform == "win32":
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
    ffmpeg = subprocess.Popen((ffmpeg.encode('utf-8'), "-ss", str(int(timecode)), "-i", videofile.encode('utf-8'), "-s", "%dx%d" % resolution, thumbfile.encode('utf-8')), stderr=subprocess.PIPE, startupinfo=startupinfo)
    ffmpeg.communicate()
    ffmpeg.stderr.close()


def get_videoinfo(videofile, ffmpeg):
    startupinfo = None
    if sys.platform == "win32":
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
    ffmpeg = subprocess.Popen((ffmpeg.encode('utf-8'), "-i", videofile.encode('utf-8')), stderr=subprocess.PIPE, startupinfo=startupinfo)
    out, err = ffmpeg.communicate()
    info = out or err
    ffmpeg.stderr.close()

    duration = find_duration(info)
    bitrate = find_bitrate(info)
    resolution = find_resolution(info)

    return (duration, bitrate, resolution)


def find_duration(info):
    match = search("Duration: (\\d+):(\\d+):(\\d+)\\.\\d+", info)

    if match == None:
        return 0
    h, m, s = map(int, match.groups()[:3])
    return (h * 60 + m) * 60 + s


def find_bitrate(info):
    match = search("bitrate: (\\d+) kb/s", info)

    if match == None:
        return 0
    bitrate = match.groups()
    return int(bitrate[0])


def find_resolution(info):
    match = search(", (\\d+)x(\\d+)", info)

    if match == None:
        return 0
    w, h = map(int, match.groups()[:2])
    return (w, h)


def limit_resolution(cur_res, max_res):
    if cur_res[0] <= 0 or cur_res[1] <= 0:
        return None
    aspect = cur_res[0] / float(cur_res[1])
    new_res = list(cur_res)
    if new_res[0] > max_res[0]:
        new_res[0] = max_res[0]
        new_res[1] = max_res[0] / aspect
    if new_res[1] > max_res[1]:
        new_res[1] = max_res[1]
        new_res[0] = max_res[1] * aspect
    return tuple(new_res)


def preferred_timecodes(videofile, duration, sample_res, ffmpeg, num_samples=20, k=4):
    results = []
    dest_dir = tempfile.gettempdir()
    num_samples = min(num_samples, duration)

    for timecode in range(0, duration, duration / num_samples):
        outputfile = os.path.join(dest_dir, 'tn%d.jpg' % timecode)
        get_thumbnail(videofile, outputfile, sample_res, ffmpeg, timecode)
        if os.path.exists(outputfile):
            @forceAndReturnWxThread
            def GetImageData():
                return wx.Bitmap(outputfile, wx.BITMAP_TYPE_ANY).ConvertToImage().GetData()
            results.append((colourfulness(GetImageData()), timecode))
            os.remove(outputfile)

    results.sort()
    results.reverse()
    topk = results[:k]
    return [item[1] for item in topk]


def colourfulness(image_data):
    rg_values = []
    yb_values = []

    for index in range(0, len(image_data), 3):
        r, g, b = map(ord, image_data[index:index + 3])
        rg = r - g
        yb = 0.5 * (r + g) - b
        rg_values.append(rg)
        yb_values.append(yb)

    s_rg, m_rg = meanstdv(rg_values)
    s_yb, m_yb = meanstdv(yb_values)

    s_rgyb = sqrt(s_rg ** 2 + s_yb ** 2)
    m_rgyb = sqrt(m_rg ** 2 + m_yb ** 2)

    return s_rgyb + 0.3 * m_rgyb


# Source: http://www.physics.rutgers.edu/~masud/computing/WPark_recipes_in_python.html
def meanstdv(x):
    n, mean, std = len(x), 0, 0
    for a in x:
        mean = mean + a
        mean = mean / float(n)
    for a in x:
        std = std + (a - mean) ** 2
    std = sqrt(std / float(n - 1))
    return mean, std


# def considered_xxx(image):
#    return skinratio(image) > 0.50
#
#
# def skinratio(image):
#    image_data = image.GetData()
#    skin_pixels = total_pixels = 0
#
#    for index in range(0, len(image_data), 3):
#        r, g, b = map(ord, image_data[index:index+3])
#        h, s, v = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)
#        if h >= 0 and h <= 25 and s >= 0.15 and s <= 0.90 and v >= 0.20 and v <= 0.95:
#            skin_pixels += 1
#        total_pixels += 1
#
#    return skin_pixels/float(total_pixels)

########NEW FILE########
__FILENAME__ = VLCWrapper
# Written by Fabian van der Werf and Arno Bakker
# see LICENSE.txt for license information

import sys
import os
import logging
from traceback import print_exc, print_stack
from threading import currentThread

from Tribler.Core.Video.defs import MEDIASTATE_ENDED, MEDIASTATE_STOPPED, \
    MEDIASTATE_PLAYING, MEDIASTATE_PAUSED

VLC_MAXVOLUME = 200  # Also for 0.3

logger = logging.getLogger(__name__)


def check_threading(func):
    def invoke_func(*args, **kwargs):
        if currentThread().getName() != "MainThread":
            raise Exception("VLCWrapper: Thread violation!")

        return func(*args, **kwargs)

    invoke_func.__name__ = func.__name__
    return invoke_func

class VLCWrapper:

    """ Wrapper around the MediaControl API, to hide some of its quirks,
    like the Position() objects.

    At the moment, we create one instance of this class which is reused
    each time to create a VLCWindow.
    """

    @check_threading
    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.window = None
        self.windowpassedtovlc = -1
        self.initialized = False

    def _init_vlc(self):
        """
        To avoid a bug on Ubuntu Intrepid and Jaunty that causes the
        GUI to instantly exit, we need to delay importing vlc and
        setting the window.
        """
        try:
            import Tribler.vlc as vlc
        except:
            print_stack()
            print_exc()

        self.initialized = True
        self.vlc = vlc
        self.media = self.get_vlc_mediactrl()

    def set_window(self, wxwindow):
        self.window = wxwindow

    @check_threading
    def get_vlc_mediactrl(self):
        if not self.initialized:
            self._init_vlc()


        # Arno: 2007-05-11: Don't ask me why but without the "--verbose=0" vlc will ignore the key redef.
        params = ["--verbose=0"]

        """
        # To enable logging to file:
        #[loghandle,logfilename] = mkstemp("vlc-log")
        #os.close(loghandle)
        currwd = os.getcwd()
        logfilename = os.path.join(currwd,"vlc.log")
        params += [""--extraintf=logger""]
        params += ["--logfile",logfilename]
        """

        params += ["--no-drop-late-frames"]  # Arno: 2007-11-19: don't seem to work as expected DEBUG
        params += ["--no-skip-frames"]
        params += ["--quiet-synchro"]
        # JD: avoid "fast catchup" after frame loss by letting VLC have a flexible buffer
        # params += ["--access-filter","timeshift"]
        # params += ["--timeshift-force"]
        # Arno: attempt to improve robustness

        # if sys.platform == 'win32':
        #    params += ["--plugin-path", "c:\\build\\mbvlc100\\vlc\\plugins" ]

        # Arno, 2009-03-30: On my Vista Test Machine (no Aero) video playback
        # doesn't work with our VLC 0.8.6h. The Direct3D vout is chosen and
        # that gives a "Failed to create texture" error. Apparent solution is
        # to set vout to vout_directx (opengl and wingdi also work, but former
        # doesn't work on all tested content and the latter gives poor output
        # quality. On a machine with Aero this unfortunately causes it to
        # switch the color scheme to Windows Vista Basic :-( Need Aero detection.
        #
        if sys.platform == "win32":
            try:
                # 5 = XP, 6 = Vista
                # pylint: disable-msg=E1101
                if sys.getwindowsversion()[0] == 6:
                    # detect if aero is on
                    from ctypes import windll, c_int, byref

                    def isAeroEnabled():
                        S_OK = 0
                        if hasattr(windll, 'dwmapi'):
                            dwmapi = windll.dwmapi
                            if hasattr(dwmapi, 'DwmIsCompositionEnabled'):
                                flag = c_int()
                                res = dwmapi.DwmIsCompositionEnabled(byref(flag))
                                return res == S_OK and bool(flag)
                        return False

                    if not isAeroEnabled():
                        params += ["--vout", "vout_directx"]
                # pylint: enable-msg=E1101
            except:
                print_exc()

        # VLC wiki says: "apply[ing] deinterlacing even if the original is not
        # interlaced, is a really bad idea."
        # params += ["--vout-filter","deinterlace"]
        # params += ["--deinterlace-mode","linear"]
        # params += ["--demux=ts"]
        # params += ["--codec=mp4"]
        #
        params += ["--no-plugins-cache"]

        # must come last somehow on Win32
        params += ["--global-key-toggle-fullscreen", "Esc"]
        params += ["--key-toggle-fullscreen", "Esc"]

        # Arno, 2009-07-22: Not sure whether sys.argv0 gives right dir.
        # if sys.platform == 'darwin':
        #    params += ["--plugin-path", "%s/vlc/plugins" % (self.installdir)]

        params += ["--no-video-title-show"]
        params += ["--no-osd"]

        # print >>sys.stderr,"VLCWrapper: get_vlc_mediactrl: params",params

        media = self.vlc.Instance(params)
        self.player = self.vlc.libvlc_media_player_new(media)

        return media

    @check_threading
    def load(self, url):
        if not self.initialized:
            self._init_vlc()

        if url:
            self._logger.info("VLCWrapper: load: %s", url)
            self._set_xwindow()
            if os.path.exists(url):
                meditem = self.vlc.libvlc_media_new_path(self.media, url)
            else:
                meditem = self.vlc.libvlc_media_new_location(self.media, url)
            self.vlc.libvlc_media_player_set_media(self.player, meditem)

    @check_threading
    def start(self, abspos=0):
        if not self.initialized:
            self._init_vlc()

        self._logger.debug("VLCWrapper: start")
        self._set_xwindow()
        self.vlc.libvlc_media_player_play(self.player)
        self.vlc.libvlc_media_player_set_time(self.player, abspos)

    @check_threading
    def stop(self):
        if self.initialized:
            self._logger.debug("VLCWrapper: stop")
            self.vlc.libvlc_media_player_stop(self.player)
            self._set_xwindow(reset=True)

    def _set_xwindow(self, reset=False):
        xid = 0 if reset else self.window.GetHandle()
        self._logger.debug("VLCWrapper: set_window, XID=%s", xid)

        if self.windowpassedtovlc == xid:
            return

        if sys.platform == 'win32':
            self.vlc.libvlc_media_player_set_hwnd(self.player, xid)
        else:
            self.vlc.libvlc_media_player_set_xwindow(self.player, xid);

        self.windowpassedtovlc = xid

    @check_threading
    def pause(self):
        if self.initialized:
            self._logger.debug("VLCWrapper: pause")
            self.vlc.libvlc_media_player_set_pause(self.player, 1)

    @check_threading
    def resume(self):
        if self.initialized:
            self._logger.debug("VLCWrapper: resume")
            self.vlc.libvlc_media_player_pause(self.player)

    def get_our_state(self):
        """ Returns the state of VLC as summarized by Fabian:
        MEDIASTATE_PLAYING, MEDIASTATE_PAUSED, MEDIASTATE_STOPPED,
        Hiding VLC differences.
        """
        if self.initialized:
            status = self.get_stream_information_status()
            if status == self.vlc.State.Playing:
                return MEDIASTATE_PLAYING
            elif status == self.vlc.State.Paused:
                return MEDIASTATE_PAUSED
            elif status == self.vlc.State.Ended:
                return MEDIASTATE_ENDED
        return MEDIASTATE_STOPPED

    @check_threading
    def get_stream_information_status(self):
        """ Returns the state of VLC. """
        if not self.initialized:
            self._init_vlc()
        return self.vlc.libvlc_media_player_get_state(self.player)

    @check_threading
    def get_stream_information_length(self):
        """ Returns the length in bytes of current item playing.
        For 0.3 API the length in time (in ms), libVLC API provides no byte length """
        if self.initialized:
            return self.vlc.libvlc_media_player_get_length(self.player)
        return 0

    @check_threading
    def get_media_position(self):
        """ Returns absolute position in bytes of current item playing.
        For 0.3 API the position in time (in ms), libVLC API provides no byte length """
        if self.initialized:
            return self.vlc.libvlc_media_player_get_time(self.player)
        return 0

    @check_threading
    def set_media_position(self, where):
        """ Arno: For some files set_media_position() doesn't work. Subsequent
        get_media_position()s then do not always return the right value.
        TODO: seek mode

        For 0.3 API the position must be in time (in ms)
        """
        if self.initialized:
            return self.vlc.libvlc_media_player_set_time(self.player, where)

    @check_threading
    def set_media_position_relative(self, position, start=False):
        if self.initialized:
            self._logger.debug("VLCWrapper: set_position")
            if start:
                self.vlc.libvlc_media_player_play(self.player)
            self.vlc.libvlc_media_player_set_position(self.player, position)

    @check_threading
    def sound_set_volume(self, frac):
        """ frac is float 0..1 """
        if not self.initialized:
            self._init_vlc()

        self._logger.debug("VLCWrapper: sound_set_volume")
        vol = int(frac * VLC_MAXVOLUME)
        self.vlc.libvlc_audio_set_volume(self.player, vol)

    @check_threading
    def sound_get_volume(self):
        """ returns a float 0..1 """
        if self.initialized:
            vol = self.vlc.libvlc_audio_get_volume(self.player)
            return float(vol) / VLC_MAXVOLUME
        return 0

    @check_threading
    def set_fullscreen(self, b):
        """ b is Boolean """
        if self.initialized:
            self._logger.debug("VLCWrapper set_fullscreen")
            self.vlc.libvlc_set_fullscreen(self.player, b)

    @check_threading
    def exit(self):
        if self.initialized:
            self._logger.debug("VLCWrapper: exit")
            self.vlc.libvlc_release(self.player)
            self.initialized = False

########NEW FILE########
__FILENAME__ = console
"""
Alternate stdout and stderr with much more protection
"""

import sys


class SafePrintStream:

    def __init__(self, stream):
        self._stream = stream

    def write(self, arg):
        try:
            self._stream.write(arg.encode("ASCII", "backslashreplace"))
        except Exception as e:
            try:
                s = u"{%s}" % repr(arg)
                self._stream.write(s)
            except:
                self._stream.write("TriblerConsole: ERROR printing\n")
                self._stream.write(repr(e))
                self._stream.write("\n")

    def flush(self):
        self._stream.flush()


class SafeLinePrintStream:

    def __init__(self, stream):
        self._stream = stream
        self._parts = []

    def write(self, arg):
        self._parts.append(arg.encode("ASCII", "backslashreplace"))
        if arg == "\n":
            self._stream.write("".join(self._parts))
            self._parts = []

    def flush(self):
        self._stream.write("".join(self._parts))
        self._parts = []
        self._stream.flush()

sys.stderr = SafePrintStream(sys.stderr)
sys.stdout = sys.stderr

########NEW FILE########
__FILENAME__ = memory
#!/usr/bin/python
# Written by Boudewijn Schoon
# see LICENSE.txt for license information

"""
Use the garbage collector to monitor memory usage
"""

from types import IntType, FloatType, StringType, UnicodeType, \
    TupleType, ListType, DictType, FunctionType, ModuleType, FrameType
import gc
import thread
import time
import logging

logger = logging.getLogger(__name__)

def _get_default_footprint(obj, depth):
    return 4


def _get_int_footprint(obj, depth):
    return 4


def _get_float_footprint(obj, depth):
    return 8


def _get_string_footprint(obj, depth):
    return len(obj)


def _get_unicode_footprint(obj, depth):
    return 2 * len(obj)


def _get_tuple_footprint(obj, depth):
    if depth == 0:
        return 4 + 4 * len(obj)
    else:
        return 4 + 4 * len(obj) + sum(map(lambda obj: get_memory_footprint(obj, depth), obj))


def _get_list_footprint(obj, depth):
    if depth == 0:
        return 8 + 4 * len(obj)
    else:
        if len(obj) in (2, 3):
            logger.info("Len: %s %s", type(obj[0]), type(obj[1]))
            logger.info(repr(obj))
            return 42
        logger.info("Len: %d", len(obj))
        return 8 + 4 * len(obj) + sum(map(lambda obj: get_memory_footprint(obj, depth), obj))


def _get_dict_footprint(obj, depth):
    if depth == 0:
        return 32 + 8 * len(obj)
    else:
        return 32 + 8 * len(obj) + sum(map(lambda obj: get_memory_footprint(obj, depth), obj.iterkeys())) + sum(map(lambda obj: get_memory_footprint(obj, depth), obj.itervalues()))

memory_footprint_map = {IntType: _get_int_footprint,
                        FloatType: _get_float_footprint,
                        StringType: _get_float_footprint,
                        UnicodeType: _get_unicode_footprint,
                        TupleType: _get_tuple_footprint,
                        ListType: _get_list_footprint,
                        DictType: _get_dict_footprint}


def get_memory_footprint(obj, depth=100):
    return memory_footprint_map.get(type(obj), _get_default_footprint)(obj, depth - 1)


def _get_default_description(obj):
    return type(obj)


def _get_function_description(obj):
    return "<function '%s' from '%s'>" % (obj.__name__, obj.__module__)


def _get_module_description(obj):
    return str(obj)


def _get_frame_description(obj):
    return "<frame for '%s' from %s:%d >" % (obj.f_code.co_name, obj.f_code.co_filename, obj.f_code.co_firstlineno)

description_map = {FunctionType: _get_function_description,
                   ModuleType: _get_module_description,
                   FrameType: _get_frame_description}


def get_description(obj):
    return description_map.get(type(obj), _get_default_description)(obj)


def get_datetime():
    return time.strftime("%Y/%m/%d %H:%M:%S")


def byte_uint_to_human(i, format="%(value).1f%(unit)s"):
    """Convert a number into a formatted string.

    format: %(value)d%(unit)s
    1           --> 1B
    1024        --> 1KB
    1048576     --> 1MB
    1073741824  --> 1GB

    format: %(value).1f %(unit-long)s
    1           --> 1.0 byte
    2           --> 2.0 bytes

    todo:
    - uint_to_human(1025, format="%(value)d %(unit-long)s") --> '1 kilobytes'
      however, this should result in '1 kilobyte'

    """
    assert type(i) in (int, long)
    assert i >= 0
    assert isinstance(format, str)
    dic = {}
    if i < 1024:
        dic["value"] = i
        dic["unit"] = "B"
        dic["unit-long"] = (i == 1 and "byte" or "bytes")
    elif i < 1048576:
        dic["value"] = i / 1024.0
        dic["unit"] = "KB"
        dic["unit-long"] = (i == 1024 and "kilobyte" or "kilobytes")
    elif i < 1073741824:
        dic["value"] = i / 1048576.0
        dic["unit"] = "MB"
        dic["unit-long"] = (i == 1048576 and "megabyte" or "megabytes")
    else:
        dic["value"] = i / 1073741824.0
        dic["unit"] = "GB"
        dic["unit-long"] = (i == 1073741824 and "gigabyte" or "gigabytes")

    return format % dic


def monitor(delay=10.0, interval=60.0, min_footprint=100000):
    def parallel():
        time.sleep(delay)

        history = [min_footprint]
        while True:
            high_foot = 0
            history = history[-2:]
            low_foot = min(history)
            datetime = get_datetime()
            logger.info("Memory: %s using minimal footprint: %s", datetime, byte_uint_to_human(low_foot))

            gc.collect()
            for obj in gc.get_objects():
                if type(obj) in (TupleType, ListType, DictType, StringType, UnicodeType):
                    try:
                        footprint = get_memory_footprint(obj)
                    except:
                        logger.error("Memory: %s unable to get footprint for %s", datetime, get_description(obj))
                    else:
                        if footprint > high_foot:
                            high_foot = footprint
                        if footprint >= low_foot:
                            logger.info("Memory: %s, %s footprint: %s", datetime, get_description(obj), byte_uint_to_human(footprint))
                            for referrer in gc.get_referrers(obj):
                                logger.info("Memory: %s REF %s", datetime, get_description(referrer))
                            logger.info("Memory")

            history.append(high_foot)
            time.sleep(interval)

    thread.start_new_thread(parallel, ())


def main():
    """
    Test the memory monitor
    """
    monitor(1.0)
    time.sleep(10)

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = update_version_from_git
#!/usr/bin/env python

from subprocess import Popen, PIPE
from time import ctime
from os import path, linesep
from sys import platform
import logging

logger = logging.getLogger(__name__)

#We aren't using python-git because we don't want to install the dependency on all the builders.

def runCommand(cmd):
    p = Popen(cmd, stdout=PIPE, stderr=PIPE)
    p.wait()
    assert(p.returncode == 0)
    stdout = p.communicate()[0]
    return stdout.strip()

if __name__ == '__main__':
    cmd = ['git', 'describe', '--tags', 'HEAD']
    version_id = runCommand(cmd).strip()[1:]
    logger.info("Version: %s", version_id)
    cmd = ['git', 'rev-parse', 'HEAD']
    commit_id = runCommand(cmd).strip()[1:]
    logger.info("Commit: %s", commit_id)

    build_date = ctime()
    logger.info("Build date: %s", build_date)

    logger.info('Writing runtime version info.')
    f = open(path.join('Tribler', 'Core', 'version.py'), 'w')
    f.write('version_id = "%s"%sbuild_date = "%s"%scommit_id = "%s"%s' % (version_id, linesep, build_date, linesep, commit_id, linesep))
    f.close()

    f = open('.TriblerVersion', 'w')
    f.write(version_id)
    f.close()

    if platform == 'linux2':
        runCommand('dch -v {} New upstream release.'.format(version_id).split())
    elif platform == 'win32':
        logger.info('Replacing NSI string.')
        f = open(path.join('Tribler', 'Main', 'Build', 'Win32', 'tribler.nsi'), 'r+')
        content = f.read().replace('__GIT__', version_id)
        f.seek(0)
        f.write(content)
        f.close()

########NEW FILE########
__FILENAME__ = channelcast_supporter
#!/usr/bin/python
# used to 'support' .torrent files dissemination of different
# channels.  make sure that it gets an existing megacache where it is
# subscribed to one or more channels.

# modify the sys.stderr and sys.stdout for safe output
import Tribler.Debug.console

from traceback import print_exc
import optparse
import os
import sys
import time
import logging

from Tribler.Core.simpledefs import NTFY_TORRENTS, NTFY_INSERT
from Tribler.Core.Session import Session
from Tribler.Core.SessionConfig import SessionStartupConfig

logger = logging.getLogger(__name__)

@call_on_reactor_thread
def define_allchannel(session):
    from Tribler.community.allchannel.community import AllChannelCommunity
    from Tribler.community.channel.community import ChannelCommunity

    dispersy = session.get_dispersy_instance()
    dispersy.define_auto_load(AllChannelCommunity,
                                   (session.dispersy_member,),
                                   {"auto_join_channel": True},
                                   load=True)
    dispersy.define_auto_load(ChannelCommunity, load=True)
    logger.info("tribler: Dispersy communities are ready")

    def on_incoming_torrent(subject, type_, infohash):
        logger.info("Incoming torrent: %s", infohash.encode("HEX"))
    session.add_observer(on_incoming_torrent, NTFY_TORRENTS, [NTFY_INSERT])

def main(define_communities):
    command_line_parser = optparse.OptionParser()
    command_line_parser.add_option("--statedir", action="store", type="string", help="Use an alternate statedir")
    command_line_parser.add_option("--port", action="store", type="int", help="Listen at this port")
    command_line_parser.add_option("--nickname", action="store", type="string", help="The moderator name")

    # parse command-line arguments
    opt, args = command_line_parser.parse_args()

    logger.info("Press Q followed by <ENTER> to stop the channelcast-supporter")

    sscfg = SessionStartupConfig()
    if opt.statedir:
        sscfg.set_state_dir(os.path.realpath(opt.statedir))
    if opt.port:
        sscfg.set_listen_port(opt.port)
    if opt.nickname:
        sscfg.set_nickname(opt.nickname)

    sscfg.set_megacache(True)
    sscfg.set_dispersy(True)
    sscfg.set_torrent_collecting(True)

    session = Session(sscfg)
    session.start()

    dispersy = session.get_dispersy_instance()
    define_communities(session)

    try:
        while True:
            x = sys.stdin.readline()
            logger.info(repr(x))
            if x.strip() == 'Q':
                break
    except:
        print_exc()

    session.shutdown()
    logger.info("Shutting down...")
    time.sleep(5)

if __name__ == "__main__":
    main(define_allchannel)

########NEW FILE########
__FILENAME__ = AddTorrent
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import wx
import os

from Tribler.Main.Dialogs.SaveAs import SaveAs
from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.Main.vwxGUI.widgets import _set_font
from Tribler.Main.Dialogs.CreateTorrent import CreateTorrent
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Core.TorrentDef import TorrentDef, TorrentDefNoMetainfo
from Tribler.Core.Utilities.utilities import parse_magnetlink


class AddTorrent(wx.Dialog):

    def __init__(self, parent, frame, libraryTorrents=None):
        wx.Dialog.__init__(self, parent, -1, 'Add an external .torrent', size=(500, 200), name="AddTorrentDialog")

        self.frame = frame
        self.guiutility = GUIUtility.getInstance()
        self.toChannel = libraryTorrents != None
        self.defaultDLConfig = DefaultDownloadStartupConfig.getInstance()

        vSizer = wx.BoxSizer(wx.VERTICAL)

        firstLine = wx.StaticText(self, -1, 'Please use one of the provided methods to import an external .torrent')
        vSizer.Add(firstLine, 0, wx.EXPAND | wx.BOTTOM, 3)
        vSizer.AddSpacer((-1, 25))

        header = wx.StaticText(self, -1, 'Browse for local .torrent file or files')
        _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM, 3)
        vSizer.Add(wx.StaticText(self, -1, 'Use this option if you have downloaded a .torrent manually'), 0, wx.BOTTOM, 3)

        browseButton = wx.Button(self, -1, 'Browse')
        browseButton.Bind(wx.EVT_BUTTON, self.OnBrowse)

        browseDirectory = wx.Button(self, -1, 'Browse for Directory')
        browseDirectory.Bind(wx.EVT_BUTTON, self.OnBrowseDir)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(browseButton, 0, wx.RIGHT, 3)
        hSizer.Add(browseDirectory)
        vSizer.Add(hSizer, 0, wx.ALIGN_RIGHT | wx.BOTTOM, 3)
        vSizer.Add(wx.StaticLine(self, -1), 0, wx.EXPAND | wx.BOTTOM, 10)

        header = wx.StaticText(self, -1, 'Url')
        _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM | wx.TOP, 3)
        vSizer.Add(wx.StaticText(self, -1, 'This could either be a direct http-link (starting with http://), or a magnet link'), 0, wx.BOTTOM, 3)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.magnet = wx.TextCtrl(self, -1)
        hSizer.Add(self.magnet, 1, wx.ALIGN_CENTER_VERTICAL)
        linkButton = wx.Button(self, -1, "Add")
        linkButton.Bind(wx.EVT_BUTTON, self.OnAdd)
        hSizer.Add(linkButton, 0, wx.LEFT, 3)
        vSizer.Add(hSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

        vSizer.Add(wx.StaticLine(self, -1), 0, wx.EXPAND | wx.BOTTOM, 10)
        if libraryTorrents != None:
            if len(libraryTorrents) > 0:
                header = wx.StaticText(self, -1, 'Choose one from you library')
                _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
                vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM | wx.TOP, 3)

                torrentNames = [torrent.name for torrent in libraryTorrents]

                hSizer = wx.BoxSizer(wx.HORIZONTAL)
                self.libraryChoice = wx.Choice(self, -1, choices=torrentNames)
                self.libraryChoice.torrents = libraryTorrents
                hSizer.Add(self.libraryChoice, 1, wx.ALIGN_CENTER_VERTICAL)

                linkButton = wx.Button(self, -1, "Add")
                linkButton.Bind(wx.EVT_BUTTON, self.OnLibrary)

                hSizer.Add(linkButton, 0, wx.LEFT, 3)
                vSizer.Add(hSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

            vSizer.Add(wx.StaticLine(self, -1), 0, wx.EXPAND | wx.BOTTOM, 10)
            header = wx.StaticText(self, -1, 'Create your own .torrents')
            _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
            vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM | wx.TOP, 3)
            vSizer.Add(wx.StaticText(self, -1, 'Using your own local files'), 0, wx.BOTTOM, 3)

            create = wx.Button(self, -1, 'Create')
            create.Bind(wx.EVT_BUTTON, self.OnCreate)
            vSizer.Add(create, 0, wx.ALIGN_RIGHT | wx.BOTTOM, 3)

            self.choose = None

        else:
            self.choose = wx.CheckBox(self, -1, "Let me choose a downloadlocation for these torrents")
            self.choose.SetValue(self.guiutility.utility.read_config('showsaveas'))
            vSizer.Add(self.choose, 0, wx.EXPAND | wx.TOP | wx.BOTTOM, 3)

        sizer = wx.BoxSizer()
        sizer.Add(vSizer, 1, wx.EXPAND | wx.ALL, 10)
        self.SetSizerAndFit(sizer)

    def OnAdd(self, event):
        input = self.magnet.GetValue().strip()
        if input.startswith("http://"):
            destdir = self.defaultDLConfig.get_dest_dir()
            if self.choose and self.choose.IsChecked():
                destdir, anon_mode, selected_files = self._GetDestPath(torrenturl=input)
                if not destdir:
                    return

            if self.frame.startDownloadFromUrl(str(input), destdir, selectedFiles=selected_files, anon_mode=anon_mode):
                self.EndModal(wx.ID_OK)

        elif input.startswith("magnet:"):
            destdir = self.defaultDLConfig.get_dest_dir()
            if self.choose and self.choose.IsChecked():
                destdir, anon_mode, selected_files = self._GetDestPath(magneturl=input)
                if not destdir:
                    return

            if self.frame.startDownloadFromMagnet(str(input), destdir, selectedFiles=selected_files, anon_mode=anon_mode):
                self.EndModal(wx.ID_OK)

    def OnLibrary(self, event):
        selection = self.libraryChoice.GetCurrentSelection()
        if selection >= 0:
            torrent = self.libraryChoice.torrents[selection]

            if self.frame.startDownloadFromTorrent(torrent):
                self.EndModal(wx.ID_OK)

    def __processPaths(self, paths):
        filenames = []
        for file in paths:
            if file.endswith('.torrent'):
                filenames.append(file)

        cancel = len(filenames) == 0
        if len(filenames) > 10:
            warning = wx.MessageDialog(self, "This will add %d .torrents, are you sure?" % len(filenames), "Please confirm Add", wx.OK | wx.CANCEL | wx.ICON_WARNING)
            if warning.ShowModal() != wx.ID_OK:
                cancel = True

            warning.Destroy()

        if not cancel:
            destdir = self.defaultDLConfig.get_dest_dir()
            if self.choose and self.choose.IsChecked():
                torrentfilename = None
                if len(filenames) == 1:
                    torrentfilename = filenames[0]
                destdir, anon_mode, selected_files = self._GetDestPath(torrentfilename)
                if not destdir:
                    return

            if getattr(self.frame, 'startDownloads', False):
                self.frame.startDownloads(filenames, fixtorrent=True, destdir=destdir)
            else:
                for filename in filenames:
                    self.frame.startDownload(filename, fixtorrent=True, destdir=destdir, selectedFiles=selected_files, anon_mode=anon_mode)

    def OnBrowse(self, event):
        dlg = wx.FileDialog(None, "Please select the .torrent file(s).", wildcard="torrent (*.torrent)|*.torrent", style=wx.FD_OPEN | wx.FD_MULTIPLE)

        path = DefaultDownloadStartupConfig.getInstance().get_dest_dir() + os.sep
        dlg.SetPath(path)

        if dlg.ShowModal() == wx.ID_OK:
            filenames = dlg.GetPaths()
            dlg.Destroy()

            self.__processPaths(filenames)
            self.EndModal(wx.ID_OK)
        else:
            dlg.Destroy()

    def OnBrowseDir(self, event):
        dlg = wx.DirDialog(None, "Please select a directory contain the .torrent files", style=wx.wx.DD_DIR_MUST_EXIST)

        path = DefaultDownloadStartupConfig.getInstance().get_dest_dir() + os.sep
        dlg.SetPath(path)

        if dlg.ShowModal() == wx.ID_OK and os.path.isdir(dlg.GetPath()):
            filenames = [os.path.join(dlg.GetPath(), file) for file in os.listdir(dlg.GetPath())]
            dlg.Destroy()

            self.__processPaths(filenames)
            self.EndModal(wx.ID_OK)

        dlg.Destroy()

    def OnCreate(self, event):
        configfile = os.path.join(self.guiutility.utility.session.get_state_dir(), 'recent_trackers')
        configfile2 = os.path.join(self.guiutility.utility.session.get_state_dir(), 'recent_created')
        trackers = self.guiutility.channelsearch_manager.torrent_db.getRecentlyAliveTrackers()

        dlg = CreateTorrent(None, configfile, configfile2, trackers, self.toChannel)
        if dlg.ShowModal() == wx.ID_OK:
            for destdir, correctedfilename, torrentfilename in dlg.createdTorrents:
                # Niels: important do not pass fixtorrent to startDownload, used to differentiate between created and imported torrents
                self.frame.startDownload(torrentfilename=torrentfilename, destdir=destdir, correctedFilename=correctedfilename)

            dlg.Destroy()
            self.EndModal(wx.ID_OK)

        dlg.Destroy()

    def _GetDestPath(self, torrentfilename=None, torrenturl=None, magneturl=None):
        destdir = None
        anon_mode = False
        selected_files = None
        tdef = None
        if torrentfilename:
            tdef = TorrentDef.load(torrentfilename)
        if torrenturl:
            tdef = TorrentDef.load_from_url(torrenturl)
        if magneturl:
            name, infohash, _ = parse_magnetlink(magneturl)
            tdef = TorrentDefNoMetainfo(infohash, name, url=magneturl)

        if tdef:
            dlg = SaveAs(None, tdef, self.defaultDLConfig.get_dest_dir(), None)
            id = dlg.ShowModal()

            if id == wx.ID_OK:
                destdir = dlg.GetPath()
                anon_mode = dlg.GetAnonMode()
                selected_files = dlg.GetSelectedFiles()
            dlg.Destroy()
        return (destdir, anon_mode, selected_files)

########NEW FILE########
__FILENAME__ = ConfirmationDialog
import wx
from Tribler.Main.vwxGUI.widgets import _set_font
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility


class ConfirmationDialog(wx.Dialog):

    def __init__(self, parent, name, msg_bold='', msg='', title='', center_on_frame=True):
        wx.Dialog.__init__(self, parent=parent, size=(475, 210), name=name)

        self.SetTitle(title)
        self.checkbox = wx.CheckBox(self, label='Don\'t show this dialog again')
        self.checkbox.SetValue(False)
        messageSizer = wx.BoxSizer(wx.VERTICAL)

        if msg_bold:
            messageText1 = wx.StaticText(self, label=msg_bold)
            _set_font(messageText1, fontweight=wx.FONTWEIGHT_BOLD)
            messageSizer.Add(messageText1, 1, wx.EXPAND)
        if msg:
            messageText2 = wx.StaticText(self, label=msg)
            messageSizer.Add(messageText2, 1, wx.EXPAND | wx.TOP, 10 if msg_bold else 0)

        messageSizer.Add(self.checkbox, 0, wx.EXPAND | wx.TOP, 15)
        bodySizer = wx.BoxSizer(wx.HORIZONTAL)
        bodySizer.Add(wx.StaticBitmap(self, -1, wx.ArtProvider.GetBitmap(wx.ART_QUESTION, wx.ART_CMN_DIALOG)), 0, wx.ALIGN_TOP | wx.RIGHT, 15)
        bodySizer.Add(messageSizer, 1, wx.EXPAND)

        buttonSizer = wx.StdDialogButtonSizer()
        confirmButton = wx.Button(self, wx.ID_OK, label='Confirm')
        confirmButton.Bind(wx.EVT_BUTTON, self.OnConfirm)
        cancelButton = wx.Button(self, id=wx.ID_CANCEL)
        cancelButton.Bind(wx.EVT_BUTTON, self.OnCancel)
        buttonSizer.Add(confirmButton)
        buttonSizer.Add(cancelButton)
        buttonSizer.Realize()

        mainSizer = wx.BoxSizer(wx.VERTICAL)
        mainSizer.Add(bodySizer, 1, wx.EXPAND | wx.ALL, 10)
        mainSizer.Add(buttonSizer, 0, wx.ALIGN_RIGHT | wx.ALL, 10)
        self.SetSizerAndFit(mainSizer)
        if center_on_frame:
            x, y, w, h = GUIUtility.getInstance().frame.GetScreenRect()
            self.SetPosition((x + ((w - self.GetSize().x) / 2), y + ((h - self.GetSize().y) / 2)))

    def OnConfirm(self, event):
        if self.checkbox.GetValue():
            GUIUtility.getInstance().WriteGuiSetting('show_%s' % self.GetName(), False)
        self.EndModal(wx.ID_OK)

    def OnCancel(self, event):
        self.EndModal(wx.ID_CANCEL)

########NEW FILE########
__FILENAME__ = CreateTorrent
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import wx
import os
import logging
from threading import Event
from traceback import print_exc

from Tribler.Core.version import version_id
from Tribler.Core.simpledefs import TRIBLER_TORRENT_EXT
from Tribler.Core.TorrentDef import TorrentDef

from Tribler.Main.vwxGUI import forceWxThread
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.widgets import _set_font, BetterText as StaticText
from Tribler.Main.Dialogs.GUITaskQueue import GUITaskQueue

logger = logging.getLogger(__name__)

class CreateTorrent(wx.Dialog):

    def __init__(self, parent, configfile, fileconfigfile, suggestedTrackers, toChannel=False):
        self._logger = logging.getLogger(self.__class__.__name__)

        wx.Dialog.__init__(self, parent, -1, 'Create a .torrent', size=(600, 200), name="CreateTorrentDialog")
        self.guiutility = GUIUtility.getInstance()
        self.toChannel = toChannel

        vSizer = wx.BoxSizer(wx.VERTICAL)

        header = wx.StaticText(self, -1, 'Browse for a file or files')
        _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM, 3)

        self.locationText = StaticText(self, -1, '')
        vSizer.Add(self.locationText, 0, wx.EXPAND | wx.BOTTOM, 3)

        browseButton = wx.Button(self, -1, 'Browse')
        browseButton.Bind(wx.EVT_BUTTON, self.OnBrowse)

        browseDirButton = wx.Button(self, -1, 'Browse for a Directory')
        browseDirButton.Bind(wx.EVT_BUTTON, self.OnBrowseDir)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(browseButton)
        hSizer.Add(browseDirButton)
        vSizer.Add(hSizer, 0, wx.ALIGN_RIGHT | wx.BOTTOM, 3)

        # self.recursive = wx.CheckBox(self, -1, 'Include all subdirectories')
        # self.recursive.Bind(wx.EVT_CHECKBOX, self.OnRecursive)
        # vSizer.Add(self.recursive, 0, wx.ALIGN_RIGHT|wx.BOTTOM, 3)

        vSizer.Add(wx.StaticLine(self, -1), 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.BOTTOM, 10)

        header = wx.StaticText(self, -1, '.Torrent details')
        _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM, 3)

        self.foundFilesText = StaticText(self, -1, 'Please select a file or files first')
        vSizer.Add(self.foundFilesText, 0, wx.EXPAND | wx.BOTTOM, 3)

        self.combineRadio = wx.RadioButton(self, -1, 'Combine files into a single .torrent', style=wx.RB_GROUP)
        self.combineRadio.Bind(wx.EVT_RADIOBUTTON, self.OnCombine)
        self.combineRadio.Enable(False)

        self.sepRadio = wx.RadioButton(self, -1, 'Create separate .torrent for every file')
        self.sepRadio.Bind(wx.EVT_RADIOBUTTON, self.OnCombine)
        self.sepRadio.Enable(False)

        vSizer.Add(self.combineRadio, 0, wx.EXPAND | wx.BOTTOM, 3)
        vSizer.Add(self.sepRadio, 0, wx.EXPAND | wx.BOTTOM, 3)

        self.specifiedName = wx.TextCtrl(self, -1, '')
        self.specifiedName.Enable(False)
        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(wx.StaticText(self, -1, 'Specify a name'), 0, wx.ALIGN_CENTER_VERTICAL)
        hSizer.Add(self.specifiedName, 1, wx.EXPAND)
        vSizer.Add(hSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

        vSizer.Add(StaticText(self, -1, 'Trackers'))
        self.trackerList = wx.TextCtrl(self, -1, '', style=wx.TE_MULTILINE)
        self.trackerList.SetMinSize((500, -1))

        self.trackerHistory = wx.FileHistory(10)
        self.config = wx.FileConfig(appName="Tribler", localFilename=configfile)
        self.trackerHistory.Load(self.config)

        if self.trackerHistory.GetCount() > 0:
            trackers = [self.trackerHistory.GetHistoryFile(i) for i in range(self.trackerHistory.GetCount())]
            if len(trackers) < len(suggestedTrackers):
                trackers.extend(suggestedTrackers[:len(suggestedTrackers) - len(trackers)])
        else:
            trackers = suggestedTrackers

        for tracker in trackers:
            self.trackerList.AppendText(tracker + "\n")

        vSizer.Add(self.trackerList, 0, wx.EXPAND | wx.BOTTOM, 3)

        vSizer.Add(StaticText(self, -1, 'Comment'))
        self.commentList = wx.TextCtrl(self, -1, '', style=wx.TE_MULTILINE)
        vSizer.Add(self.commentList, 0, wx.EXPAND, 3)

        vSizer.Add(wx.StaticLine(self, -1), 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.TOP, 10)

        header = wx.StaticText(self, -1, 'Advanced options')
        _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(header, 0, wx.EXPAND | wx.BOTTOM | wx.TOP, 3)

        abbrev_mb = " MB"
        abbrev_kb = " KB"
        piece_choices = ['Automatic',
                         '4' + abbrev_mb,
                         '2' + abbrev_mb,
                         '1' + abbrev_mb,
                         '512' + abbrev_kb,
                         '256' + abbrev_kb,
                         '128' + abbrev_kb,
                         '64' + abbrev_kb,
                         '32' + abbrev_kb]
        self.pieceChoice = wx.Choice(self, -1, choices=piece_choices)
        self.pieceChoice.SetSelection(0)
        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(StaticText(self, -1, 'Piecesize'), 1)
        hSizer.Add(self.pieceChoice)
        vSizer.Add(hSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

        vSizer.Add(StaticText(self, -1, 'Webseed'))
        self.webSeed = wx.TextCtrl(self, -1, 'Please select a file or files first')
        self.webSeed.Enable(False)
        vSizer.Add(self.webSeed, 0, wx.EXPAND | wx.BOTTOM, 3)

        cancel = wx.Button(self, wx.ID_CANCEL)
        cancel.Bind(wx.EVT_BUTTON, self.OnCancel)

        create = wx.Button(self, wx.ID_OK, 'Create .torrent(s)')
        create.Bind(wx.EVT_BUTTON, self.OnOk)

        bSizer = wx.StdDialogButtonSizer()
        bSizer.AddButton(cancel)
        bSizer.AddButton(create)
        bSizer.Realize()
        vSizer.Add(bSizer, 0, wx.EXPAND)

        sizer = wx.BoxSizer()
        sizer.Add(vSizer, 1, wx.EXPAND | wx.ALL, 10)
        self.SetSizerAndFit(sizer)

        self.selectedPaths = []
        self.createdTorrents = []
        self.cancelEvent = Event()

        self.filehistory = wx.FileHistory(1)
        self.fileconfig = wx.FileConfig(appName="Tribler", localFilename=fileconfigfile)
        self.filehistory.Load(self.fileconfig)

        if self.filehistory.GetCount() > 0:
            self.latestFile = self.filehistory.GetHistoryFile(0)
        else:
            self.latestFile = ''
        self.paths = None

    def OnBrowse(self, event):
        dlg = wx.FileDialog(None, "Please select the file(s).", style=wx.FD_OPEN | wx.FD_MULTIPLE, defaultDir=self.latestFile)
        if dlg.ShowModal() == wx.ID_OK:
            filenames = dlg.GetPaths()
            dlg.Destroy()

            self._browsePaths(filenames)
        else:
            dlg.Destroy()

    def OnBrowseDir(self, event):
        dlg = wx.DirDialog(None, "Please a directory.", style=wx.DD_DIR_MUST_EXIST, defaultPath=self.latestFile)
        if dlg.ShowModal() == wx.ID_OK:
            filenames = [dlg.GetPath()]
            dlg.Destroy()

            self._browsePaths(filenames)
        else:
            dlg.Destroy()

    def OnRecursive(self, event):
        self._browsePaths()

    def OnCombine(self, event=None):
        combine = self.combineRadio.GetValue()
        self.specifiedName.Enable(False)
        if combine:
            path = ''

            nrFiles = len([file for file in self.selectedPaths if os.path.isfile(file)])
            if nrFiles > 1:
                self.specifiedName.Enable(True)
                path = os.path.abspath(os.path.commonprefix(self.selectedPaths))

            elif nrFiles > 0:
                path = self.selectedPaths[0]

            _, name = os.path.split(path)
            self.specifiedName.SetValue(name)

    def OnOk(self, event):
        max = 1 if self.combineRadio.GetValue() else len(self.selectedPaths)
        if self.toChannel:
            dlg = wx.MessageDialog(self, "This will add %d new .torrents to this Channel.\nDo you want to continue?" % max, "Are you sure?", style=wx.YES_NO | wx.ICON_QUESTION)
        else:
            dlg = wx.MessageDialog(self, "This will create %d new .torrents.\nDo you want to continue?" % max, "Are you sure?", style=wx.YES_NO | wx.ICON_QUESTION)

        if dlg.ShowModal() == wx.ID_YES:
            dlg.Destroy()

            params = {}
            params['comment'] = self.commentList.GetValue()
            params['created by'] = '%s version: %s' % ('Tribler', version_id)

            trackers = self.trackerList.GetValue()
            trackers = [tracker for tracker in trackers.split('\n') if tracker]

            for tracker in trackers:
                self.trackerHistory.AddFileToHistory(tracker)
            self.trackerHistory.Save(self.config)
            self.config.Flush()

            self.filehistory.Save(self.fileconfig)
            self.fileconfig.Flush()

            params['announce'] = trackers[0]
            params['announce-list'] = [trackers]

            if self.webSeed.GetValue():
                params['urllist'] = [self.webSeed.GetValue()]

            params['nodes'] = False
            params['httpseeds'] = False
            params['encoding'] = False
            params['makehash_md5'] = False
            params['makehash_crc32'] = False
            params['makehash_sha1'] = True
            params['createmerkletorrent'] = False
            params['torrentsigkeypairfilename'] = False
            params['thumb'] = False

            piece_length_list = [0, 2 ** 22, 2 ** 21, 2 ** 20, 2 ** 19, 2 ** 18, 2 ** 17, 2 ** 16, 2 ** 15]
            if self.pieceChoice.GetSelection() != wx.NOT_FOUND:
                params['piece length'] = piece_length_list[self.pieceChoice.GetSelection()]
            else:
                params['piece length'] = 0

            def do_gui():
                if self.cancelEvent.isSet():
                    self.OnCancel(event)
                else:
                    self.EndModal(wx.ID_OK)

            def create_torrents():
                try:
                    if self.combineRadio.GetValue():
                        params['name'] = self.specifiedName.GetValue()
                        make_meta_file(self.selectedPaths, params, self.cancelEvent, None, self._torrentCreated)
                    else:
                        for path in self.selectedPaths:
                            if os.path.isfile(path):
                                make_meta_file([path], params, self.cancelEvent, None, self._torrentCreated)
                except:
                    print_exc()

                wx.CallAfter(do_gui)

            def start():
                if self.combineRadio.GetValue():
                    self.progressDlg = wx.ProgressDialog("Creating new .torrents", "Please wait while Tribler is creating your .torrents.\nThis could take a while due to creating the required hashes.", maximum=max, parent=self, style=wx.PD_APP_MODAL | wx.PD_AUTO_HIDE)
                else:
                    self.progressDlg = wx.ProgressDialog("Creating new .torrents", "Please wait while Tribler is creating your .torrents.\nThis could take a while due to creating the required hashes.", maximum=max, parent=self, style=wx.PD_CAN_ABORT | wx.PD_APP_MODAL | wx.PD_ELAPSED_TIME | wx.PD_AUTO_HIDE)
                self.progressDlg.Pulse()
                self.progressDlg.cur = 0

                self.guiserver = GUITaskQueue.getInstance()
                self.guiserver.add_task(create_torrents)

            if params['piece length']:
                total_size = 0
                if self.combineRadio.GetValue():
                    for path in self.selectedPaths:
                        total_size += os.path.getsize(path)
                else:
                    for path in self.selectedPaths:
                        total_size = max(total_size, os.path.getsize(path))

                nrPieces = total_size / params['piece length']
                if nrPieces > 2500:
                    dlg2 = wx.MessageDialog(self, "The selected piecesize will cause a torrent to have %d pieces.\nThis is more than the recommended max 2500 pieces.\nDo you want to continue?" % nrPieces, "Are you sure?", style=wx.YES_NO | wx.ICON_QUESTION)
                    if dlg2.ShowModal() == wx.ID_YES:
                        start()
                    dlg2.Destroy()

                else:
                    start()
            else:
                start()
        else:
            dlg.Destroy()

    def OnCancel(self, event):
        self.EndModal(wx.ID_CANCEL)

    def _browsePaths(self, paths=None):
        if paths:
            self.paths = paths
        else:
            paths = self.paths

        if paths:
            label = ";".join(paths)
            self.locationText.SetLabel(label)

            if os.path.isdir(paths[0]):
                def addDir(path, recursive=False):
                    paths = [path]

                    for file in os.listdir(path):
                        absfile = os.path.join(path, file)

                        if os.path.isfile(absfile):
                            if file.lower().endswith('.torrent') or file.lower().endswith('thumbs.db'):
                                continue
                            paths.append(absfile)

                        elif os.path.isdir(absfile) and recursive:
                            paths.extend(addDir(absfile, recursive))

                    return paths
                paths = addDir(paths[0], False)  # self.recursive.GetValue())

            self.selectedPaths = paths
            nrFiles = len([file for file in paths if os.path.isfile(file)])
            self.foundFilesText.SetLabel('Selected %d files' % nrFiles)

            if nrFiles == 1:
                self.webSeed.Enable(True)
                self.webSeed.SetValue('')
            else:
                self.webSeed.SetValue('Webseed will only work for a single file.')
                self.webSeed.Enable(False)

            self.combineRadio.Enable(nrFiles > 0)
            self.sepRadio.Enable(nrFiles > 1)

            self.combineRadio.SetValue(nrFiles == 1)
            self.sepRadio.SetValue(nrFiles > 1)

            self.OnCombine()

            self.Layout()

    @forceWxThread
    def _torrentCreated(self, path, correctedfilename, torrentfilename):
        self.progressDlg.cur += 1
        keepGoing, _ = self.progressDlg.Update(self.progressDlg.cur)
        if not keepGoing:
            self.cancelEvent.Set()

        self.createdTorrents.append((path, correctedfilename, torrentfilename))


def make_meta_file(srcpaths, params, userabortflag, progressCallback, torrentfilenameCallback):
    tdef = TorrentDef()

    basedir = None

    nrFiles = len([file for file in srcpaths if os.path.isfile(file)])
    if nrFiles > 1:
        # outpaths should start with a common prefix, this prefix is the swarmname of the torrent
        # if srcpaths contain c:\a\1, c:\a\2 -> basepath should be c:\ and basedir a and outpaths should be a\1 and a\2
        # if srcpaths contain c:\a\1, c:\a\2, c:\a\b\1, c:\a\b\2 -> basepath should be c:\ and outpaths should be a\1, a\2, a\b\1 and a\b\2
        basepath = os.path.abspath(os.path.commonprefix(srcpaths))
        basepath, basedir = os.path.split(basepath)
        for srcpath in srcpaths:
            if os.path.isfile(srcpath):
                outpath = os.path.relpath(srcpath, basepath)

                # h4x0r playtime
                if 'playtime' in params:
                    tdef.add_content(srcpath, outpath, playtime=params['playtime'])
                else:
                    tdef.add_content(srcpath, outpath)
    else:
        srcpaths = [file for file in srcpaths if os.path.isfile(file)]

        srcpath = srcpaths[0]
        basepath, _ = os.path.split(srcpath)
        if 'playtime' in params:
            tdef.add_content(srcpath, playtime=params['playtime'])
        else:
            tdef.add_content(srcpath)

        if params.get('urllist', False):
            tdef.set_urllist(params['urllist'])

    if params['name']:
        tdef.set_name(params['name'])
    if params['comment']:
        tdef.set_comment(params['comment'])
    if params['created by']:
        tdef.set_created_by(params['created by'])
    if params['announce']:
        tdef.set_tracker(params['announce'])
    if params['announce-list']:
        tdef.set_tracker_hierarchy(params['announce-list'])
    if params['nodes']:  # mainline DHT
        tdef.set_dht_nodesmax(params['nodes'])
    if params['httpseeds']:
        tdef.set_httpseeds(params['httpseeds'])
    if params['encoding']:
        tdef.set_encoding(params['encoding'])
    if params['piece length']:
        tdef.set_piece_length(params['piece length'])
    if params['makehash_md5']:
        logger.info("TorrentMaker: make MD5")
        tdef.set_add_md5hash(params['makehash_md5'])
    if params['makehash_crc32']:
        logger.info("TorrentMaker: make CRC32")
        tdef.set_add_crc32(params['makehash_crc32'])
    if params['makehash_sha1']:
        logger.info("TorrentMaker: make SHA1")
        tdef.set_add_sha1hash(params['makehash_sha1'])
    if params['createmerkletorrent']:
        tdef.set_create_merkle_torrent(params['createmerkletorrent'])
    if params['torrentsigkeypairfilename']:
        tdef.set_signature_keypair_filename(params['torrentsigkeypairfilename'])
    if params['thumb']:
        tdef.set_thumbnail(params['thumb'])

    tdef.finalize(userabortflag=userabortflag, userprogresscallback=progressCallback)

    if params['createmerkletorrent']:
        postfix = TRIBLER_TORRENT_EXT
    else:
        postfix = '.torrent'

    if params.get('target', False):
        torrentfilename = os.path.join(params['target'], os.path.split(os.path.normpath(srcpath))[1] + postfix)
    else:
        torrentfilename = os.path.join(basepath, tdef.get_name() + postfix)
    tdef.save(torrentfilename)

    # Inform higher layer we created torrent
    torrentfilenameCallback(basepath, basedir, torrentfilename)

########NEW FILE########
__FILENAME__ = FeedbackWindow
#   Copyright (c) 2006-2008 Open Source Applications Foundation
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

# 10-10-2011 Niels Zeilemaker: modified version of http://svn.osafoundation.org/chandler/trunk/chandler/application/feedback.py

import sys
import os
import wx
import platform
import httplib
from urllib import urlencode

from Tribler.Core.version import version_id
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.widgets import AutoWidthListCtrl


class FeedbackWindow(wx.PyOnDemandOutputWindow):

    """
    An error dialog that would be shown in case there is an uncaught
    exception. The user can send the error report back to us as well.
    """
    def __call__(self, *args, **kw):
        # Make this a Singleton to avoid the problem of multiple feedback
        # windows popping up at the same time
        return self

    def _fillOptionalSection(self):
        try:
            # columns
            self.sysInfo.InsertColumn(0, 'key')
            self.sysInfo.InsertColumn(1, 'value')

            def add(col, val):
                pos = self.sysInfo.InsertStringItem(sys.maxsize, col)
                self.sysInfo.SetStringItem(pos, 1, val)

            # data
            add('os.getcwd', '%s' % os.getcwd())
            add('sys.executable', '%s' % sys.executable)

            add('os', os.name)
            add('platform', sys.platform)
            add('platform.details', platform.platform())
            add('platform.machine', platform.machine())
            add('python.version', sys.version)
            add('indebug', str(__debug__))

            for argv in sys.argv:
                add('sys.argv', '%s' % argv)

            for path in sys.path:
                add('sys.path', '%s' % path)

            for key in os.environ.keys():
                add('os.environ', '%s: %s' % (key, os.environ[key]))

            # read tribler.log?
#            try:
#
#                f = codecs.open(os.path.join(Globals.options.profileDir,
#                                             'chandler.log'),
#                                encoding='utf-8', mode='r', errors='ignore')
#                for line in f.readlines()[-LOGLINES:]:
#                    self.frame.sysInfo.InsertStringItem(index, 'chandler.log')
#                    self.frame.sysInfo.SetStringItem(index, 1, '%s' % line.strip())
#                    index += 1
#            except:
#                pass

        except:
            pass

        self.sysInfo.SetColumnWidth(0, wx.LIST_AUTOSIZE)
        self.sysInfo.SetColumnWidth(1, wx.LIST_AUTOSIZE)

    def _fillRequiredSection(self, st):
        # Version and other miscellaneous information
        try:
            guiUtility = GUIUtility.getInstance()
            utility = guiUtility.utility

            self.text.AppendText('%s version: %s\n' % ('Tribler', version_id))
        except:
            pass

        # Traceback (actually just the first line of it)
        self.text.AppendText(st)

    def CreateOutputWindow(self, st):
        self.frame = wx.Dialog(None, -1, self.title, style=wx.DEFAULT_DIALOG_STYLE | wx.RESIZE_BORDER, name="FeedbackWindow")

        self.frame.CenterOnParent()
        sizer = wx.BoxSizer(wx.HORIZONTAL)

        icon = wx.StaticBitmap(self.frame, -1, wx.ArtProvider.GetBitmap(wx.ART_ERROR, wx.ART_MESSAGE_BOX))
        sizer.Add(icon)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(wx.StaticText(self.frame, -1, 'Tribler encountered an error, to help us fix this please send an error-report.'))

        self.text = wx.TextCtrl(self.frame, -1, "", style=wx.TE_MULTILINE | wx.TE_READONLY)
        self.text.SetMinSize((600, 150))
        vSizer.Add(self.text, 0, wx.EXPAND)

        self.sysInfo = AutoWidthListCtrl(self.frame, style=wx.LC_REPORT | wx.NO_BORDER)
        self.sysInfo.SetMinSize((-1, 200))
        vSizer.Add(self.sysInfo, 1, wx.EXPAND)

        self.comments = wx.TextCtrl(self.frame, -1, "", style=wx.TE_MULTILINE)
        self.comments.SetMinSize((-1, 100))
        vSizer.Add(wx.StaticText(self.frame, -1, 'Comments: (optional)'))
        vSizer.Add(self.comments, 0, wx.EXPAND)

        self.email = wx.TextCtrl(self.frame, -1, "")
        vSizer.Add(wx.StaticText(self.frame, -1, 'Email: (optional)'))
        vSizer.Add(self.email, 0, wx.EXPAND)

        buttonSizer = wx.BoxSizer(wx.HORIZONTAL)

        self.sendButton = wx.Button(self.frame, -1, 'Send Report')
        self.sendButton.Bind(wx.EVT_BUTTON, self.OnSend)
        buttonSizer.Add(self.sendButton, 0, wx.RIGHT, 3)

        if self.parent:
            self.restartButton = wx.Button(self.frame, -1, 'Restart')
            self.restartButton.Bind(wx.EVT_BUTTON, self.OnRestart)
            buttonSizer.Add(self.restartButton, 0, wx.RIGHT, 3)

        self.closeButton = wx.Button(self.frame, wx.ID_CANCEL)
        self.closeButton.Bind(wx.EVT_BUTTON, self.OnCloseWindow)
        buttonSizer.Add(self.closeButton)

        vSizer.Add(buttonSizer, 0, wx.ALIGN_RIGHT | wx.TOP, 10)
        sizer.Add(vSizer, 1, wx.EXPAND | wx.LEFT, 10)

        self._fillRequiredSection(st)
        self._fillOptionalSection()

        self.frame.Bind(wx.EVT_CHAR, self.OnChar)
        self.frame.Bind(wx.EVT_CLOSE, self.OnCloseWindow)

        border = wx.BoxSizer()
        border.Add(sizer, 1, wx.ALL | wx.EXPAND, 10)

        self.frame.SetSizerAndFit(border)

    def OnChar(self, event):
        # Close the window if an escape is typed
        keycode = event.GetKeyCode()
        if keycode == wx.WXK_ESCAPE:
            self.OnCloseWindow(event)
        else:
            event.Skip()

    def OnRestart(self, event):
        try:
            self.sendButton.Disable()
            self.restartButton.Disable()
            self.closeButton.Disable()
            self.restartButton.SetLabel('Restarting...')

            self.parent.Restart()

        finally:
            self.frame.Show(False)

    def OnSend(self, event):
        self.sendButton.Disable()

        # Disabling the focused button disables keyboard navigation
        # unless we set the focus to something else - let's put it
        # on close button
        self.closeButton.SetFocus()
        self.sendButton.SetLabel('Sending...')

        try:
            c = httplib.HTTPConnection('dispersyreporter.tribler.org')

            email = 'Not provided'
            if self.email.GetValue():
                email = self.email.GetValue()

            comments = 'Not provided'
            if self.comments.GetValue():
                comments = self.comments.GetValue()

            body_dict = {'email': email, 'comments': comments}
            body_dict['stack'] = self.text.GetValue()

            optional = ''
            for i in range(self.sysInfo.GetItemCount()):
                field = self.sysInfo.GetItem(i, 0).GetText()
                value = self.sysInfo.GetItem(i, 1).GetText()
                optional += field + '\t' + value + '\n'
            body_dict['sysinfo'] = optional

            body = urlencode(body_dict)

            c.request('POST', '/exception.py', body)
            response = c.getresponse()

            if response.status != 200:
                raise Exception('response.status=' + response.status)
            c.close()
        except:
            self.sendButton.SetLabel('Failed to send')
        else:
            self.sendButton.SetLabel('Sent')

    def Show(self, show=True):
        return self.frame.Show(show)

    def ShowModal(self):
        return self.frame.ShowModal()

########NEW FILE########
__FILENAME__ = GUITaskQueue
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# GUITaskQueue is a server that executes tasks on behalf of the GUI that are too
# time consuming to be run by the actual GUI Thread (MainThread). Note that
# you still need to delegate the actual updating of the GUI to the MainThread via
# wx.CallAfter
#

from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue


class GUITaskQueue(TimedTaskQueue):

    __single = None

    def __init__(self):
        if GUITaskQueue.__single:
            raise RuntimeError("GUITaskQueue is singleton")
        GUITaskQueue.__single = self

        TimedTaskQueue.__init__(self, nameprefix="GUITaskQueue")

    def getInstance(*args, **kw):
        if GUITaskQueue.__single is None:
            GUITaskQueue(*args, **kw)
        return GUITaskQueue.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        GUITaskQueue.__single = None
    delInstance = staticmethod(delInstance)

    def resetSingleton(self):
        """ For testing purposes """
        GUITaskQueue.__single = None

########NEW FILE########
__FILENAME__ = RemoveTorrent
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import wx

from Tribler.Main.vwxGUI.widgets import _set_font, BetterText as StaticText, EditText
from Tribler.community.channel.community import ChannelCommunity
from wx.lib.wordwrap import wordwrap


class RemoveTorrent(wx.Dialog):

    def __init__(self, parent, torrents):
        canEdit = False
        single = len(torrents) == 1
        if single and torrents[0].hasChannel():
            state = torrents[0].channel.getState()
            canEdit = state >= ChannelCommunity.CHANNEL_OPEN

        wx.Dialog.__init__(self, parent, -1, 'Are you sure you want to remove the selected torrent%s?' % ('' if single else 's'), size=(600, -1), name="RemoveTorrent")
        bitmap = wx.ArtProvider.GetBitmap(wx.ART_QUESTION, wx.ART_MESSAGE_BOX)
        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(wx.StaticBitmap(self, -1, bitmap), 0, wx.RIGHT, 10)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        firstLine = StaticText(self, -1, '')
        _set_font(firstLine, fontweight=wx.FONTWEIGHT_BOLD)
        if single:
            firstLineMsg = "Delete '%s' from disk, or just remove it from your downloads?" % torrents[0].name
        else:
            firstLineMsg = "Delete %s torrents from disk, or just remove them from your downloads?" % len(torrents)
        cdc = wx.ClientDC(firstLine)
        cdc.SetFont(firstLine.GetFont())
        firstLineMsg = wordwrap(firstLineMsg, self.GetSize()[0] - bitmap.GetSize()[0] - 30, cdc, breakLongWords=True, margin=0)
        firstLine.SetLabel(firstLineMsg)
        firstLine.SetMinSize((1, -1))
        vSizer.Add(firstLine, 0, wx.EXPAND | wx.BOTTOM, 3)
        vSizer.Add(StaticText(self, -1, "Removing from disk will move the selected item%s to your trash." % ('' if single else 's')), 0, wx.EXPAND)

        vSizer.AddStretchSpacer()

        self.newName = None
        if single and canEdit:
            vSizer.Add(StaticText(self, -1, "While we're at it, can you improve the name of this torrent?"), 0, wx.EXPAND | wx.BOTTOM, 3)
            self.newName = EditText(self, torrents[0].name)
            vSizer.Add(self.newName, 0, wx.EXPAND)
            vSizer.AddStretchSpacer()

        bSizer = wx.BoxSizer(wx.HORIZONTAL)
        bSizer.AddStretchSpacer()

        bSizer.Add(wx.Button(self, wx.ID_CANCEL), 0, wx.RIGHT, 3)
        bSizer.Add(wx.Button(self, wx.ID_DEFAULT, 'Only delete from downloads'), 0, wx.RIGHT, 3)
        bSizer.Add(wx.Button(self, wx.ID_DELETE, 'Also delete from disk'))

        vSizer.Add(bSizer, 0, wx.ALIGN_RIGHT | wx.TOP, 7)
        hSizer.Add(vSizer, 1, wx.EXPAND)

        border = wx.BoxSizer()
        border.Add(hSizer, 1, wx.ALL | wx.EXPAND, 10)

        self.Bind(wx.EVT_BUTTON, lambda event: self.EndModal(event.GetId()))
        self.SetSizer(border)
        self.SetSize((-1, self.GetBestSize()[1]))
        self.Layout()
        self.CenterOnParent()

########NEW FILE########
__FILENAME__ = SaveAs
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import wx
import os
import sys
import json
import copy
import logging

from Tribler.Main.vwxGUI.widgets import CheckSelectableListCtrl, _set_font
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler import LIBRARYNAME
from Tribler.Core.TorrentDef import TorrentDefNoMetainfo, TorrentDef
from Tribler.Main.Utility.GuiDBTuples import Torrent


class SaveAs(wx.Dialog):

    def __init__(self, parent, tdef, defaultdir, defaultname, selectedFiles=None):
        self._logger = logging.getLogger(self.__class__.__name__)
        wx.Dialog.__init__(self, parent, -1, 'Please specify a target directory', size=(600, 450), name="SaveAsDialog")

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.filehistory = []
        try:
            self.filehistory = json.loads(self.utility.read_config("recent_download_history", literal_eval=False))
        except:
            pass

        self.defaultdir = defaultdir
        self.listCtrl = None
        self.collected = None

        lastUsed = self.filehistory[0] if self.filehistory else defaultdir

        vSizer = wx.BoxSizer(wx.VERTICAL)

        if tdef:
            line = 'Please select a directory where to save:'
        else:
            line = 'Please select a directory where to save this torrent'

        firstLine = wx.StaticText(self, -1, line)
        _set_font(firstLine, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(firstLine, 0, wx.EXPAND | wx.BOTTOM, 3)

        if tdef:
            torrentName = wx.StaticText(self, -1, tdef.get_name_as_unicode())
            torrentName.SetMinSize((1, -1))
            vSizer.Add(torrentName, 0, wx.EXPAND | wx.BOTTOM | wx.RIGHT, 3)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(wx.StaticText(self, -1, 'Save as:'), 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT | wx.BOTTOM, 3)

        choices = copy.copy(self.filehistory)
        if defaultdir not in choices:
            choices.append(defaultdir)

        if defaultname:
            choices.insert(0, os.path.join(lastUsed, defaultname))
            self.dirTextCtrl = wx.ComboBox(self, -1, os.path.join(lastUsed, defaultname), choices=choices, style=wx.CB_DROPDOWN)
        else:
            self.dirTextCtrl = wx.ComboBox(self, -1, lastUsed, choices=choices, style=wx.CB_DROPDOWN)
        self.dirTextCtrl.Select(0)

        hSizer.Add(self.dirTextCtrl, 1, wx.EXPAND | wx.RIGHT | wx.BOTTOM, 3)

        browseButton = wx.Button(self, -1, 'Browse')
        browseButton.Bind(wx.EVT_BUTTON, self.OnBrowseDir)
        hSizer.Add(browseButton)

        vSizer.Add(hSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

        # self.anon_check = wx.CheckBox(self, -1, 'Use anonymous downloading mode')
        # vSizer.Add(self.anon_check, 0, wx.TOP | wx.BOTTOM, 5)

        if tdef and tdef.get_files():
            self.AddFileList(tdef, selectedFiles, vSizer, len(vSizer.GetChildren()))

        elif isinstance(tdef, TorrentDefNoMetainfo):
            text = wx.StaticText(self, -1, "Attempting to retrieve .torrent...")
            _set_font(text, size_increment=1)
            ag = wx.animate.GIFAnimationCtrl(self, -1, os.path.join(self.guiutility.utility.getPath(), LIBRARYNAME, 'Main', 'vwxGUI', 'images', 'search_new.gif'))
            ag.Play()
            sizer = wx.BoxSizer(wx.HORIZONTAL)
            sizer.AddStretchSpacer()
            sizer.Add(text, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 10)
            sizer.Add(ag, 0, wx.ALIGN_CENTER_VERTICAL)
            sizer.AddStretchSpacer()
            vSizer.Add(sizer, 1, wx.EXPAND | wx.BOTTOM, 3)
            self.SetSize((600, 185))

            # convert tdef into guidbtuple, and collect it using torrentsearch_manager.getTorrent
            torrent = Torrent.fromTorrentDef(tdef)
            torrentsearch_manager = self.guiutility.torrentsearch_manager

            def callback(torrent_filename):
                tdef = TorrentDef.load(torrent_filename)
                wx.CallAfter(self.SetCollected, tdef)

            torrentsearch_manager.getTorrent(torrent, callback)

        cancel = wx.Button(self, wx.ID_CANCEL)
        cancel.Bind(wx.EVT_BUTTON, self.OnCancel)

        ok = wx.Button(self, wx.ID_OK)
        ok.Bind(wx.EVT_BUTTON, self.OnOk)

        bSizer = wx.StdDialogButtonSizer()
        bSizer.AddButton(cancel)
        bSizer.AddButton(ok)
        bSizer.Realize()
        vSizer.Add(bSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

        sizer = wx.BoxSizer()
        sizer.Add(vSizer, 1, wx.EXPAND | wx.ALL, 10)
        self.SetSizer(sizer)

    def AddFileList(self, tdef, selectedFiles, vSizer, index=None):
        vSizer.Add(wx.StaticLine(self, -1), 0, wx.EXPAND | wx.BOTTOM, 10)

        firstLine = wx.StaticText(self, -1, "Content:")
        _set_font(firstLine, fontweight=wx.FONTWEIGHT_BOLD)
        vSizer.Add(firstLine, 0, wx.BOTTOM, 3)

        vSizer.Add(wx.StaticText(self, -1, 'Use the checkboxes to choose which files to download.\nUse ctrl+a to select all/deselect all.'), 0, wx.BOTTOM, 3)

        self.listCtrl = CheckSelectableListCtrl(self)
        self.listCtrl.InsertColumn(0, 'Name')
        self.listCtrl.InsertColumn(1, 'Size', wx.LIST_FORMAT_RIGHT)

        # Add files
        def sort_by_size(a, b):
            return cmp(a[1], b[1])

        files = tdef.get_files_as_unicode_with_length()
        files.sort(sort_by_size, reverse=True)

        for filename, size in files:
            try:
                pos = self.listCtrl.InsertStringItem(sys.maxsize, filename)
            except:
                try:
                    pos = self.listCtrl.InsertStringItem(sys.maxsize, filename.decode('utf-8', 'ignore'))
                except:
                    self._logger.error("Could not format filename %s", self.torrent.name)
            self.listCtrl.SetItemData(pos, pos)
            self.listCtrl.SetStringItem(pos, 1, self.guiutility.utility.size_format(size))

            if selectedFiles:
                self.listCtrl.CheckItem(pos, filename in selectedFiles)

        if selectedFiles == None:
            self.listCtrl.doSelectAll()

        self.listCtrl.setResizeColumn(0)
        self.listCtrl.SetColumnWidth(1, wx.LIST_AUTOSIZE)  # autosize only works after adding rows
        vSizer.Add(self.listCtrl, 1, wx.EXPAND | wx.BOTTOM, 3)

        self.listCtrl.SetFocus()

        def OnKeyUp(event):
            if event.GetKeyCode() == wx.WXK_RETURN:
                self.OnOk()
            else:
                event.Skip()
        self.listCtrl.Bind(wx.EVT_KEY_UP, OnKeyUp)

    def SetCollected(self, tdef):
        self.collected = tdef
        self.SetSize((600, 475))
        vSizer = self.GetSizer().GetItem(0).GetSizer()
        hsizer = vSizer.GetItem(len(vSizer.GetChildren()) - 2).GetSizer()
        self.Freeze()
        hsizer.Clear(deleteWindows=True)
        vSizer.Remove(hsizer)
        self.AddFileList(tdef, None, vSizer, len(vSizer.GetChildren()) - 1)
        self.Layout()
        self.Refresh()
        self.Thaw()

    def GetCollected(self):
        return self.collected

    def GetPath(self):
        return self.dirTextCtrl.GetValue().strip().rstrip(os.path.sep)

    def GetSelectedFiles(self):
        if self.listCtrl:
            selected = self.listCtrl.GetSelectedItems()
            nrSelected = len(selected)

            if nrSelected > 0 and nrSelected < self.listCtrl.GetItemCount():
                files = []
                for index in selected:
                    files.append(self.listCtrl.GetItem(index, 0).GetText())
                return files
        return None

    def GetAnonMode(self):
        return False # self.anon_check.GetValue()

    def OnOk(self, event=None):
        if self.listCtrl:
            nrSelected = len(self.listCtrl.GetSelectedItems())
            if nrSelected == 0:
                dlg = wx.MessageDialog(self, "Please select at least one file to be downloaded using the checkboxes.", "Please select a file to be downloaded", wx.ICON_ERROR)
                dlg.ShowModal()
                dlg.Destroy()
                return

        path = self.GetPath()
        if not os.path.exists(path) or os.path.isfile(path):
            path, _ = os.path.split(path)
        if path in self.filehistory:
            self.filehistory.remove(path)
        self.filehistory.insert(0, path)
        self.filehistory = self.filehistory[:25]

        self.utility.write_config("recent_download_history", json.dumps(self.filehistory))
        self.utility.flush_config()

        self.EndModal(wx.ID_OK)

    def OnCancel(self, event=None):
        self.EndModal(wx.ID_CANCEL)

    def OnBrowseDir(self, event):
        dlg = wx.DirDialog(None, "Please select a directory to save this torrent", style=wx.wx.DD_NEW_DIR_BUTTON)
        dlg.SetPath(self.defaultdir)

        if dlg.ShowModal() == wx.ID_OK and os.path.isdir(dlg.GetPath()):
            self.dirTextCtrl.SetValue(dlg.GetPath())
        dlg.Destroy()

########NEW FILE########
__FILENAME__ = systray
# Author : Choopan RATTANAPOKA, Jie Yang, Arno Bakker
# see LICENSE.txt for license information
import wx
from traceback import print_exc

try:
    import win32gui  # , win32con
    WIN32 = True
except:
    WIN32 = False

#
#
# Class : ABCTaskBarIcon
#
# Task Bar Icon
#
#


class ABCTaskBarIcon(wx.TaskBarIcon):

    def __init__(self, parent):
        wx.TaskBarIcon.__init__(self)

        self.parent = parent
        self.utility = parent.utility

        # setup a taskbar icon, and catch some events from it
        self.Bind(wx.EVT_TASKBAR_LEFT_DCLICK, parent.onTaskBarActivate)
        self.Bind(wx.EVT_MENU, parent.onTaskBarActivate, id=wx.NewId())

        self.updateIcon(False)

    def updateIcon(self, iconifying=False):
        remove = True

        mintray = self.utility.read_config('mintray')
        if (mintray >= 2) or ((mintray >= 1) and iconifying):
            remove = False

        if remove and self.IsIconInstalled():
            self.RemoveIcon()
        elif not remove and not self.IsIconInstalled():
            self.SetIcon(self.parent.GetIcon(), "Tribler")

    def CreatePopupMenu(self):
        menu = wx.Menu()

        mi = menu.Append(-1, 'Stop All')
        self.Bind(wx.EVT_MENU, self.OnStopAll, id=mi.GetId())
        menu.AppendSeparator()
        mi = menu.Append(-1, 'Restart All')
        self.Bind(wx.EVT_MENU, self.OnRestartAll, id=mi.GetId())
        menu.AppendSeparator()
        mi = menu.Append(-1, '&Exit')
        self.Bind(wx.EVT_MENU, self.OnExitClient, id=mi.GetId())
        return menu

    def Notify(self, title, msg, icon):
        if WIN32 and self.IsIconInstalled():
            if not msg and title:
                msg = title
                title = ''
            try:
                self.__SetBalloonTip(self.icon.GetHandle(), title, msg, 0, icon)
                return True
            except Exception:
                pass
        return False

    def __SetBalloonTip(self, hicon, title, msg, msec, icon):
        if icon == wx.ART_INFORMATION:
            infoFlags = win32gui.NIIF_INFO
        elif icon == wx.ART_WARNING:
            infoFlags = win32gui.NIIF_WARNING
        elif icon == wx.ART_ERROR:
            infoFlags = win32gui.NIIF_ERROR
        else:
            infoFlags = 0

        lpdata = (self.__GetIconHandle(),
                  99,
                  win32gui.NIF_MESSAGE | win32gui.NIF_TIP | win32gui.NIF_INFO | win32gui.NIF_ICON,
                  0,
                  hicon,
                  '',
                  msg,
                  msec,
                  title,
                  infoFlags)
        win32gui.Shell_NotifyIcon(win32gui.NIM_MODIFY, lpdata)

        self.SetIcon(self.icon, self.tooltip)

    def __GetIconHandle(self):
        if not hasattr(self, "_chwnd"):
            try:
                for handle in wx.GetTopLevelWindows():
                    if handle.GetWindowStyle():
                        continue
                    handle = handle.GetHandle()
                    if len(win32gui.GetWindowText(handle)) == 0:
                        self._chwnd = handle
                        break
                if not hasattr(self, "_chwnd"):
                    pass
            except:
                pass
        return self._chwnd

    def SetIcon(self, icon, tooltip=""):
        self.icon = icon
        self.tooltip = tooltip
        wx.TaskBarIcon.SetIcon(self, icon, tooltip)

    def OnStopAll(self, event=None):
        dlist = self.utility.session.get_downloads()
        for d in dlist:
            try:
                d.stop()
            except:
                print_exc()

    def OnRestartAll(self, event=None):
        dlist = self.utility.session.get_downloads()
        for d in dlist:
            try:
                d.restart()
            except:
                print_exc()

    def OnExitClient(self, event=None):
        self.parent.quit()

########NEW FILE########
__FILENAME__ = ThreadSafeProgressDialog
import wx


class ThreadSafeProgressDialog():

    def __init__(self, title, message, maximum, parent, style):
        wx.CallAfter(self.wx_init, title, message, maximum, parent, style)

    def wx_init(self, title, message, maximum, parent, style):
        self.dlg = wx.ProgressDialog(title=title, message=message, maximum = maximum, parent=parent, style=style)
        self.dlg.Raise()

    def Update(self, value, newmsg=''):
        wx.CallAfter(lambda: self.dlg.Update(value, newmsg))

    def UpdatePulse(self, newmsg=''):
        wx.CallAfter(lambda: self.dlg.UpdatePulse(newmsg))

    def Pulse(self, newmsg=''):
        wx.CallAfter(lambda: self.dlg.Pulse(newmsg))

    def Destroy(self):
        wx.CallAfter(lambda: wx.CallLater(10000, lambda: self.dlg.Destroy()))

########NEW FILE########
__FILENAME__ = globals
# Written by Arno Bakker
# see LICENSE.txt for license information

import os
import logging
import copy

from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Utilities.configparser import CallbackConfigParser

STATEDIR_DLCONFIG = "tribler.conf"


class DefaultDownloadStartupConfig(DownloadStartupConfig):
    __single = None

    def __init__(self, dlconfig=None):

        if DefaultDownloadStartupConfig.__single:
            raise RuntimeError("DefaultDownloadStartupConfig is singleton")
        DefaultDownloadStartupConfig.__single = self

        DownloadStartupConfig.__init__(self, dlconfig=dlconfig)

        self._logger = logging.getLogger(self.__class__.__name__)

    def getInstance(*args, **kw):
        if DefaultDownloadStartupConfig.__single is None:
            DefaultDownloadStartupConfig(*args, **kw)
        return DefaultDownloadStartupConfig.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        DefaultDownloadStartupConfig.__single = None
    delInstance = staticmethod(delInstance)

    def load(filename):
        dlconfig = CallbackConfigParser()
        if not dlconfig.read(filename):
            raise IOError, "Failed to open download config file"
        return DefaultDownloadStartupConfig(dlconfig)
    load = staticmethod(load)

    def copy(self):
        config = CallbackConfigParser()
        config._sections = {'downloadconfig': copy.deepcopy(self.dlconfig._sections['downloadconfig'])}
        return DownloadStartupConfig(config)

def get_default_dscfg_filename(state_dir):
    return os.path.join(state_dir, STATEDIR_DLCONFIG)

########NEW FILE########
__FILENAME__ = metadata-injector
#!/usr/bin/python

# injector.py is used to 'inject' .torrent files into the overlay
# network.
# Currently supported sources:
#  * rss feed;
#  * watched directory.

# modify the sys.stderr and sys.stdout for safe output
import Tribler.Debug.console

from traceback import print_exc
import optparse
import os
import random
import sys
import time
import json
from hashlib import sha1
import logging
import logging.config
import binascii

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Session import Session
from Tribler.Core.SessionConfig import SessionStartupConfig
from Tribler.Main.Utility.Feeds.rssparser import RssParser
from Tribler.Main.Utility.Feeds.dirfeed import DirectoryFeedThread
from Tribler.Main.vwxGUI.SearchGridManager import TorrentManager, LibraryManager, \
    ChannelManager
from Tribler.Main.vwxGUI.TorrentStateManager import TorrentStateManager

from twisted.internet import reactor

logger = logging.getLogger(__name__)

@call_on_reactor_thread
def define_communities(session):
    from Tribler.community.allchannel.community import AllChannelCommunity
    from Tribler.community.channel.community import ChannelCommunity
    from Tribler.community.metadata.community import MetadataCommunity

    dispersy = session.get_dispersy_instance()
    dispersy.define_auto_load(AllChannelCommunity,
                                (session.dispersy_member,),
                                {},
                                load=True)
    dispersy.define_auto_load(ChannelCommunity, load=True)
    dispersy.define_auto_load(MetadataCommunity,
                               (session.dispersy_member,),
                               {},
                               load=True)
    logger.info(u"Dispersy communities are ready")

def dispersy_started(session, opt, torrentManager, channelManager,
        torrentStateManager):
    channelname = opt.channelname if hasattr(opt, 'chanelname') else ''
    nickname = opt.nickname if hasattr(opt, 'nickname') else ''
    my_channel_name = channelname or nickname or 'MetadataInjector-Channel'
    my_channel_name = unicode(my_channel_name)

    new_channel_created = False
    my_channel_id = channelManager.channelcast_db.getMyChannelId()
    if not my_channel_id:
        logger.info(u"Create a new channel")
        channelManager.createChannel(my_channel_name, u'')
        new_channel_created = True
    else:
        logger.info(u"Use existing channel %s", binascii.hexlify(my_channel_id))
        my_channel = channelManager.getChannel(my_channel_id)
        if my_channel.name != my_channel_name:
            logger.info(u"Rename channel to %s", my_channel_name)
            channelManager.modifyChannel(my_channel_id, {'name': my_channel_name})
    my_channel_id = channelManager.channelcast_db.getMyChannelId()
    logger.info(u"Channel ID [%s]", my_channel_id)

    def createTorrentFeed():
        logger.info(u"Creating RSS Feed...")

        torrentfeed = RssParser.getInstance()
        torrentfeed.register(session, my_channel_id)
        torrentfeed.addCallback(my_channel_id, torrentManager.createMetadataModificationFromDef)

        for rss in opt.rss.split(";"):
            torrentfeed.addURL(rss, my_channel_id)

    if hasattr(opt, 'rss') and opt.rss:
        createTorrentFeed()

    def createDirFeed():
        logger.info(u"Creating Dir Feed...")

        def on_torrent_callback(dirpath, infohash, torrent_data):
            torrentdef = TorrentDef.load_from_dict(torrent_data)
            channelManager.createTorrentFromDef(my_channel_id, torrentdef)

            # save torrent to collectedtorrents
            filename = torrentManager.getCollectedFilenameFromDef(torrentdef)
            if not os.path.isfile(filename):
                torrentdef.save(filename)

        dirfeed = DirectoryFeedThread.getInstance()
        for dirpath in opt.dir.split(";"):
            dirfeed.addDir(dirpath, callback=on_torrent_callback)

    if hasattr(opt, 'dir') and opt.dir:
        createDirFeed()

    def createFileFeed():
        logger.info(u"Creating File Feed...")
        community = channelManager._disp_get_community_from_channel_id(my_channel_id)

        logger.info("Using community: %s", community._cid.encode('HEX'))

        items = json.load(open(opt.file, 'rb'))
        for item in items:
            try:
                infohash = sha1(item['name']).digest()
            except:
                infohash = sha1(str(random.randint(0, 1000000))).digest()
            message = community._disp_create_torrent(infohash, long(time.time()), unicode(item['name']), ((u'fake.file', 10),), tuple(), update=False, forward=False)

            logger.info("Created a new torrent")

            latest_review = None
            for modification in item['modifications']:
                reviewmessage = community._disp_create_modification('description', unicode(modification['text']), long(time.time()), message, latest_review, update=False, forward=False)

                logger.info("Created a new modification")

                if modification['revert']:
                    community._disp_create_moderation('reverted', long(time.time()), 0, reviewmessage.packet_id, update=False, forward=False)

                    logger.info("Reverted the last modification")
                else:
                    latest_review = reviewmessage

    if hasattr(opt, 'file') and opt.file and new_channel_created:
        createFileFeed()

def main():
    command_line_parser = optparse.OptionParser()
    command_line_parser.add_option("--statedir", action="store", type="string", help="Use an alternate statedir")
    command_line_parser.add_option("--port", action="store", type="int", help="Listen at this port")
    command_line_parser.add_option("--rss", action="store", type="string", help="Url where to fetch rss feed, or several seperated with ';'")
    command_line_parser.add_option("--dir", action="store", type="string", help="Directory to watch for .torrent files, or several seperated with ';'")
    command_line_parser.add_option("--file", action="store", type="string", help="JSON file which has a community")
    command_line_parser.add_option("--nickname", action="store", type="string", help="The moderator name")
    command_line_parser.add_option("--channelname", action="store", type="string", help="The channel name")

    # parse command-line arguments
    opt, args = command_line_parser.parse_args()

    if not (opt.rss or opt.dir or opt.file):
        command_line_parser.print_help()
        logger.info("\nExample: python Tribler/Main/metadata-injector.py --rss http://frayja.com/rss.php --nickname frayja --channelname goldenoldies")
        sys.exit()

    logger.info("Type Q followed by <ENTER> to stop the metadata-injector")

    sscfg = SessionStartupConfig()
    if opt.statedir:
        sscfg.set_state_dir(unicode(os.path.realpath(opt.statedir)))
    if opt.port:
        sscfg.set_dispersy_port(opt.port)
    if opt.nickname:
        sscfg.set_nickname(opt.nickname)

    sscfg.set_megacache(True)
    sscfg.set_torrent_collecting(True)

    session = Session(sscfg)
    session.start()

    torrentManager = TorrentManager(None)
    libraryManager = LibraryManager(None)
    channelManager = ChannelManager()
    torrentManager.connect(session, libraryManager, channelManager)
    libraryManager.connect(session, torrentManager, channelManager)
    channelManager.connect(session, libraryManager, torrentManager)

    torrentStateManager = TorrentStateManager(None)
    torrentStateManager.connect(torrentManager, libraryManager, channelManager)

    dispersy = session.get_dispersy_instance()
    define_communities()
    reactor.callFromThread(dispersy_started, session, opt, torrentManager, channelManager, torrentStateManager)

    # condition variable would be prettier, but that don't listen to
    # KeyboardInterrupt
    try:
        while True:
            x = sys.stdin.readline()
            logger.info(repr(x))
            if x.strip() == 'Q':
                break
    except:
        print_exc()

    torrentfeed = RssParser.getInstance()
    torrentfeed.shutdown()

    dirfeed = DirectoryFeedThread.getInstance()
    dirfeed.shutdown()

    torrentStateManager.delInstance()
    channelManager.delInstance()
    libraryManager.delInstance()
    torrentManager.delInstance()

    session.shutdown()
    logger.info("Shutting down...")
    time.sleep(5)

if __name__ == "__main__":
    logging.config.fileConfig("logger.conf")
    main()

########NEW FILE########
__FILENAME__ = search_supporter
#!/usr/bin/python
# used to 'support' .torrent files dissemination of different
# channels.  make sure that it gets an existing megacache where it is
# subscribed to one or more channels.

# modify the sys.stderr and sys.stdout for safe output
import Tribler.Debug.console

import os
from datetime import date
from time import time
import logging

from channelcast_supporter import main

logger = logging.getLogger(__name__)

def define_search(session):
    from Tribler.community.search.community import SearchCommunity

    def log_search(sock_addr, keywords):
        d = date.today()
        f = open(os.path.join(session.get_state_dir(), 'incoming-searches-%s' % d.isoformat()), 'a')
        print >> f, "%s %s %s %s" % (time(), sock_addr[0], sock_addr[1], ";".join(keywords))
        f.close()


    dispersy = session.get_dispersy_instance()
    dispersy.define_auto_load(SearchCommunity,
                                     (session.dispersy_member,),
                                     {"log_incomming_searches": log_search},
                                     load=True)
    logger.info("tribler: Dispersy communities are ready")

if __name__ == "__main__":
    main(define_search)

########NEW FILE########
__FILENAME__ = tribler
import logging.config


logger = logging.getLogger(__name__)

try:
    logging.config.fileConfig("logger.conf")
except:
    logger.exception("Unable to load logging config from 'logger.conf' file.")
logging.basicConfig(format="%(asctime)-15s [%(levelname)s] %(message)s")

# This import needs to be before any twisted or dispersy import so it can initalize the reactor in a separate thread
# No need to do reactor.run(), it gets started when imported
from Tribler.Core.Utilities.twisted_thread import reactor, stop_reactor

# set wxpython version
try:
    import wxversion
    wxversion.select("2.8-unicode")
except:
    logger.exception("Unable to use wxversion, Error: %s.")

def run():
    from Tribler.Main.tribler_main import run as run_main
    run_main()

if __name__ == '__main__':
    run()
    stop_reactor()

########NEW FILE########
__FILENAME__ = tribler_lockprofiler
import sys
import logging

from threading import current_thread, local, setprofile
from time import time
from Tribler.Main.tribler import run

stats = {}
threadlocal = local()

logger = logging.getLogger(__name__)

def lock_profile(frame, event, arg):
    global stats, threadlocal

    if not hasattr(threadlocal, "lines"):
        threadlocal.lines = []

    code = frame.f_code
    filename = code.co_filename
    lineno = code.co_firstlineno

    if event in ['call', 'c_call']:
        dataline = "%.3f %s:%d" % (time(), filename, lineno)
        if dataline not in threadlocal.lines:
            threadlocal.lines.append(dataline)
            if len(threadlocal.lines) > 35:
                threadlocal.lines = threadlocal.lines[1:]

    if arg and getattr(arg, '__name__', None):
        callname = arg.__name__

        if callname in ['acquire', 'release', 'wait']:
            lockobj = arg.__self__
            if lockobj not in stats:
                stats[lockobj] = {}

            thread = current_thread()
            name = thread.getName()
            if name not in stats[lockobj]:
                stats[lockobj][name] = [sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize, False]

            index = 0
            if callname == 'release':
                index = 2
            elif callname == 'wait':
                index = 4

            if event == 'c_return':
                index += 1

            stats[lockobj][name][index] = time()
            stats[lockobj][name][6] = index == 1

            doCheck = event == 'c_return' or (event == 'c_call' and callname == 'release')
            if doCheck:
                took = stats[lockobj][name][index] - stats[lockobj][name][index - 1]
                if took > 2:
                    logger.info("%s waited more than %.2f to %s lock %s:%d", name, took, callname, filename, lineno)
                    if hasattr(threadlocal, "lines"):
                        for line in threadlocal.lines:
                            logger.info("\t%s", line)

            if index == 0:
                for otherthread in stats[lockobj]:
                    if otherthread != name:
                        if stats[lockobj][otherthread][6]:
                            logger.info("%s waiting for lock acquired by %s", name, otherthread)
                            if False and hasattr(threadlocal, "lines"):
                                for line in threadlocal.lines:
                                    logger.info("\t%s", line)

if __name__ == '__main__':
    sys.setprofile(lock_profile)
    setprofile(lock_profile)

    run()

########NEW FILE########
__FILENAME__ = tribler_main
#!/usr/bin/python

#
#
# Author : Choopan RATTANAPOKA, Jie Yang, Arno Bakker
#
# Description : Main ABC [Yet Another Bittorrent Client] python script.
#               you can run from source code by using
#               >python abc.py
#               need Python, WxPython in order to run from source code.
#
# see LICENSE.txt for license information
#

import sys
import logging
from Tribler.Main.Utility.compat import convertSessionConfig, convertMainConfig, convertDefaultDownloadConfig, convertDownloadCheckpoints
from Tribler.Core.version import version_id, commit_id, build_date
from Tribler.Core.osutils import fix_filebasename, get_free_space

logger = logging.getLogger(__name__)

# Arno: M2Crypto overrides the method for https:// in the
# standard Python libraries. This causes msnlib to fail and makes Tribler
# freakout when "http://www.tribler.org/version" is redirected to
# "https://www.tribler.org/version/" (which happened during our website
# changeover) Until M2Crypto 0.16 is patched I'll restore the method to the
# original, as follows.
#
# This must be done in the first python file that is started.
#
import urllib
from Tribler.Core.CacheDB.sqlitecachedb import SQLiteCacheDB
import shutil
original_open_https = urllib.URLopener.open_https
import M2Crypto  # Not a useless import! See above.
urllib.URLopener.open_https = original_open_https

# modify the sys.stderr and sys.stdout for safe output
import Tribler.Debug.console

import os
from Tribler.Core.CacheDB.SqliteCacheDBHandler import ChannelCastDBHandler
from Tribler.Main.Utility.GuiDBHandler import startWorker, GUIDBProducer
from Tribler.dispersy.util import attach_profiler, call_on_reactor_thread
from Tribler.community.bartercast3.community import MASTER_MEMBER_PUBLIC_KEY_DIGEST as BARTER_MASTER_MEMBER_PUBLIC_KEY_DIGEST
from Tribler.Core.CacheDB.Notifier import Notifier
import traceback
from random import randint
from threading import currentThread, Thread
try:
    prctlimported = True
    import prctl
except ImportError as e:
    prctlimported = False

# Arno, 2008-03-21: see what happens when we disable this locale thing. Gives
# errors on Vista in "Regional and Language Settings Options" different from
# "English[United Kingdom]"
# import locale

import wx
from Tribler.Main.vwxGUI.gaugesplash import GaugeSplash
from Tribler.Main.vwxGUI.MainFrame import FileDropTarget
from Tribler.Main.Dialogs.FeedbackWindow import FeedbackWindow
# import hotshot

from collections import defaultdict
from traceback import print_exc
import urllib2
import tempfile

from Tribler.Main.vwxGUI.MainFrame import MainFrame  # py2exe needs this import
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility, forceWxThread
from Tribler.Main.vwxGUI.MainVideoFrame import VideoDummyFrame
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.Dialogs.GUITaskQueue import GUITaskQueue
from Tribler.Main.globals import DefaultDownloadStartupConfig, get_default_dscfg_filename

from Tribler.Main.Utility.utility import Utility
from Tribler.Main.Utility.Feeds.rssparser import RssParser

from Tribler.Category.Category import Category
from Tribler.Policies.RateManager import UserDefinedMaxAlwaysOtherwiseDividedOverActiveSwarmsRateManager
from Tribler.Policies.SeedingManager import GlobalSeedingManager
from Tribler.Utilities.Instance2Instance import Instance2InstanceClient, \
    Instance2InstanceServer, InstanceConnectionHandler
from Tribler.Utilities.SingleInstanceChecker import SingleInstanceChecker

from Tribler.Core.simpledefs import UPLOAD, DOWNLOAD, NTFY_MODIFIED, NTFY_INSERT, \
    NTFY_REACHABLE, NTFY_ACTIVITIES, NTFY_UPDATE, NTFY_CREATE, NTFY_CHANNELCAST, \
    NTFY_STATE, NTFY_VOTECAST, NTFY_MYPREFERENCES, NTFY_TORRENTS, NTFY_COMMENTS, \
    NTFY_PLAYLISTS, NTFY_DELETE, NTFY_MODIFICATIONS, NTFY_MODERATIONS, NTFY_PEERS, \
    NTFY_MARKINGS, NTFY_FINISHED, NTFY_MAGNET_GOT_PEERS, NTFY_MAGNET_PROGRESS, \
    NTFY_MAGNET_STARTED, NTFY_MAGNET_CLOSE, STATEDIR_TORRENTCOLL_DIR, \
    STATEDIR_SWIFTRESEED_DIR, \
    dlstatus_strings, \
    DLSTATUS_STOPPED_ON_ERROR, DLSTATUS_DOWNLOADING, \
    DLSTATUS_SEEDING, DLSTATUS_STOPPED
from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core.Session import Session
from Tribler.Core.SessionConfig import SessionStartupConfig
from Tribler.Core.DownloadConfig import get_default_dest_dir

from Tribler.Core.Statistics.Status.Status import get_status_holder, \
    delete_status_holders
from Tribler.Core.Statistics.Status.NullReporter import NullReporter

from Tribler.Core.Video.VideoPlayer import return_feasible_playback_modes, PLAYBACKMODE_INTERNAL

# Arno, 2012-06-20: h4x0t DHT import for py2...
import Tribler.Core.DecentralizedTracking.pymdht.core
import Tribler.Core.DecentralizedTracking.pymdht.core.identifier
import Tribler.Core.DecentralizedTracking.pymdht.core.message
import Tribler.Core.DecentralizedTracking.pymdht.core.node
import Tribler.Core.DecentralizedTracking.pymdht.core.ptime
import Tribler.Core.DecentralizedTracking.pymdht.core.routing_table


# Boudewijn: keep this import BELOW the imports from Tribler.xxx.* as
# one of those modules imports time as a module.
from time import time, sleep

from twisted.python.threadable import isInIOThread
from twisted.internet import reactor

SESSION_CHECKPOINT_INTERVAL = 900.0  # 15 minutes
CHANNELMODE_REFRESH_INTERVAL = 5.0
FREE_SPACE_CHECK_INTERVAL = 300.0

DEBUG = False
DEBUG_DOWNLOADS = False
ALLOW_MULTIPLE = False

#
#
# Class : ABCApp
#
# Main ABC application class that contains ABCFrame Object
#
#


class ABCApp():

    def __init__(self, params, installdir):
        assert not isInIOThread(), "isInIOThread() seems to not be working correctly"
        self._logger = logging.getLogger(self.__class__.__name__)

        self.params = params
        self.installdir = installdir

        self.state_dir = None
        self.error = None
        self.last_update = 0
        self.ready = False
        self.done = False
        self.frame = None

        self.guiserver = GUITaskQueue.getInstance()
        self.said_start_playback = False
        self.decodeprogress = 0

        self.old_reputation = 0

        # DISPERSY will be set when available
        self.dispersy = None
        # BARTER_COMMUNITY will be set when both Dispersy and the EffortCommunity are available
        self.barter_community = None

        self.seedingmanager = None
        self.i2is = None
        self.torrentfeed = None
        self.webUI = None
        self.utility = None

        self.gui_image_manager = GuiImageManager.getInstance(installdir)

        try:
            bm = self.gui_image_manager.getImage(u'splash.png')
            self.splash = GaugeSplash(bm)
            self.splash.setTicks(12)
            self.splash.Show()

            self._logger.info('Client Starting Up.')
            self._logger.info("Tribler is using %s as working directory", self.installdir)

            self.splash.tick('Starting API')
            s = self.startAPI(self.splash.tick)

            self._logger.info("Tribler is expecting swift in %s", self.sconfig.get_swift_path())

            self.dispersy = s.lm.dispersy

            self.utility = Utility(self.installdir, s.get_state_dir())
            self.utility.app = self
            self.utility.session = s
            self.guiUtility = GUIUtility.getInstance(self.utility, self.params, self)
            GUIDBProducer.getInstance()

            self._logger.info('Tribler Version: %s Build: %s', version_id, commit_id)

            self.splash.tick('Loading userdownloadchoice')
            from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice
            UserDownloadChoice.get_singleton().set_utility(self.utility)

            self.splash.tick('Initializing Family Filter')
            cat = Category.getInstance()

            state = self.utility.read_config('family_filter')
            if state in (1, 0):
                cat.set_family_filter(state == 1)
            else:
                self.utility.write_config('family_filter', 1)
                self.utility.flush_config()

                cat.set_family_filter(True)

            # Create global rate limiter
            self.splash.tick('Setting up ratelimiters')
            self.ratelimiter = UserDefinedMaxAlwaysOtherwiseDividedOverActiveSwarmsRateManager()

            # Counter to suppress some event from occurring
            self.ratestatecallbackcount = 0

            # So we know if we asked for peer details last cycle
            self.lastwantpeers = []

            maxup = self.utility.read_config('maxuploadrate')
            self.ratelimiter.set_global_max_speed(UPLOAD, maxup)

            maxdown = self.utility.read_config('maxdownloadrate')
            self.ratelimiter.set_global_max_speed(DOWNLOAD, maxdown)

            self.seedingmanager = GlobalSeedingManager(self.utility.read_config)

            # Only allow updates to come in after we defined ratelimiter
            self.prevActiveDownloads = []
            s.set_download_states_callback(self.sesscb_states_callback)

            # Schedule task for checkpointing Session, to avoid hash checks after
            # crashes.
            self.guiserver.add_task(self.guiservthread_checkpoint_timer, SESSION_CHECKPOINT_INTERVAL)

            if not ALLOW_MULTIPLE:
                # Put it here so an error is shown in the startup-error popup
                # Start server for instance2instance communication
                self.i2iconnhandler = InstanceConnectionHandler(self.i2ithread_readlinecallback)
                self.i2is = Instance2InstanceServer(self.utility.read_config('i2ilistenport'), self.i2iconnhandler)
                self.i2is.start()

            self.splash.tick('GUIUtility register')
            self.guiUtility.register()

            channel_only = os.path.exists(os.path.join(self.installdir, 'joinchannel'))
            if channel_only:
                f = open(os.path.join(self.installdir, 'joinchannel'), 'rb')
                channel_only = f.readline()
                f.close()

            self.frame = MainFrame(None, channel_only, PLAYBACKMODE_INTERNAL in return_feasible_playback_modes(), self.splash.tick)
            self.frame.SetIcon(wx.Icon(os.path.join(self.installdir, 'Tribler', 'Main', 'vwxGUI', 'images', 'tribler.ico'), wx.BITMAP_TYPE_ICO))

            # Arno, 2011-06-15: VLC 1.1.10 pops up separate win, don't have two.
            self.frame.videoframe = None
            if PLAYBACKMODE_INTERNAL in return_feasible_playback_modes():
                vlcwrap = s.lm.videoplayer.get_vlcwrap()
                wx.CallLater(3000, vlcwrap._init_vlc)
                self.frame.videoframe = VideoDummyFrame(self.frame.videoparentpanel, self.utility, vlcwrap)

            if sys.platform == 'win32':
                wx.CallAfter(self.frame.top_bg.Refresh)
                wx.CallAfter(self.frame.top_bg.Layout)
            else:
                self.frame.top_bg.Layout()

            # Arno, 2007-05-03: wxWidgets 2.8.3.0 and earlier have the MIME-type for .bmp
            # files set to 'image/x-bmp' whereas 'image/bmp' is the official one.
            try:
                bmphand = None
                hands = wx.Image.GetHandlers()
                for hand in hands:
                    # print "Handler",hand.GetExtension(),hand.GetType(),hand.GetMimeType()
                    if hand.GetMimeType() == 'image/x-bmp':
                        bmphand = hand
                        break
                # wx.Image.AddHandler()
                if bmphand is not None:
                    bmphand.SetMimeType('image/bmp')
            except:
                # wx < 2.7 don't like wx.Image.GetHandlers()
                print_exc()

            self.splash.Destroy()
            self.frame.Show(True)
            self.guiserver.add_task(self.guiservthread_free_space_check, 0)

            self.torrentfeed = RssParser.getInstance()

            self.webUI = None
            if self.utility.read_config('use_webui'):
                try:
                    from Tribler.Main.webUI.webUI import WebUI
                    self.webUI = WebUI.getInstance(self.guiUtility.library_manager, self.guiUtility.torrentsearch_manager, self.utility.read_config('webui_port'))
                    self.webUI.start()
                except Exception:
                    print_exc()

            wx.CallAfter(self.PostInit2)

            # 08/02/10 Boudewijn: Working from home though console
            # doesn't allow me to press close.  The statement below
            # gracefully closes Tribler after 120 seconds.
            # wx.CallLater(120*1000, wx.GetApp().Exit)

            status = get_status_holder("LivingLab")
            status.add_reporter(NullReporter("Periodically remove all events", 0))
            # TODO(emilon): can we delete this?
            # status.add_reporter(LivingLabPeriodicReporter("Living lab CS reporter", 300, "Tribler client")) # Report every 5 minutes
            # status.add_reporter(LivingLabPeriodicReporter("Living lab CS reporter", 30, "Tribler client")) # Report every 30 seconds - ONLY FOR TESTING

            # report client version
            status.create_and_add_event("client-startup-version", [version_id])
            status.create_and_add_event("client-startup-build", [commit_id])
            status.create_and_add_event("client-startup-build-date", [build_date])

            self.ready = True

        except Exception as e:
            self.onError(e)

    def PostInit2(self):
        self.frame.Raise()
        self.startWithRightView()
        self.set_reputation()

        s = self.utility.session
        s.add_observer(self.sesscb_ntfy_reachable, NTFY_REACHABLE, [NTFY_INSERT])
        s.add_observer(self.sesscb_ntfy_activities, NTFY_ACTIVITIES, [NTFY_INSERT], cache=10)
        s.add_observer(self.sesscb_ntfy_channelupdates, NTFY_CHANNELCAST, [NTFY_INSERT, NTFY_UPDATE, NTFY_CREATE, NTFY_STATE, NTFY_MODIFIED], cache=10)
        s.add_observer(self.sesscb_ntfy_channelupdates, NTFY_VOTECAST, [NTFY_UPDATE], cache=10)
        s.add_observer(self.sesscb_ntfy_myprefupdates, NTFY_MYPREFERENCES, [NTFY_INSERT, NTFY_UPDATE])
        s.add_observer(self.sesscb_ntfy_torrentupdates, NTFY_TORRENTS, [NTFY_UPDATE, NTFY_INSERT], cache=10)
        s.add_observer(self.sesscb_ntfy_playlistupdates, NTFY_PLAYLISTS, [NTFY_INSERT, NTFY_UPDATE])
        s.add_observer(self.sesscb_ntfy_commentupdates, NTFY_COMMENTS, [NTFY_INSERT, NTFY_DELETE])
        s.add_observer(self.sesscb_ntfy_modificationupdates, NTFY_MODIFICATIONS, [NTFY_INSERT])
        s.add_observer(self.sesscb_ntfy_moderationupdats, NTFY_MODERATIONS, [NTFY_INSERT])
        s.add_observer(self.sesscb_ntfy_markingupdates, NTFY_MARKINGS, [NTFY_INSERT])
        s.add_observer(self.sesscb_ntfy_torrentfinished, NTFY_TORRENTS, [NTFY_FINISHED])
        s.add_observer(self.sesscb_ntfy_magnet, NTFY_TORRENTS, [NTFY_MAGNET_GOT_PEERS, NTFY_MAGNET_PROGRESS, NTFY_MAGNET_STARTED, NTFY_MAGNET_CLOSE])

        self.dispersy.attach_progress_handler(self.frame.progressHandler)
        # TODO(emilon): Use the LogObserver I already implemented
        #self.dispersy.callback.attach_exception_handler(self.frame.exceptionHandler)

        startWorker(None, self.loadSessionCheckpoint, delay=5.0, workerType="guiTaskQueue")

        # initialize the torrent feed thread
        channelcast = ChannelCastDBHandler.getInstance()

        def db_thread():
            return channelcast.getMyChannelId()

        def wx_thread(delayedResult):
            my_channel = delayedResult.get()
            if my_channel:
                self.torrentfeed.register(self.utility.session, my_channel)
                self.torrentfeed.addCallback(my_channel, self.guiUtility.channelsearch_manager.createTorrentFromDef)
                self.torrentfeed.addCallback(my_channel, self.guiUtility.torrentsearch_manager.createMetadataModificationFromDef)

        startWorker(wx_thread, db_thread, delay=5.0)

    def startAPI(self, progress):
        # Start Tribler Session
        defaultConfig = SessionStartupConfig()
        state_dir = defaultConfig.get_state_dir()
        if not state_dir:
            state_dir = Session.get_default_state_dir()
        cfgfilename = Session.get_default_config_filename(state_dir)

        progress('Loading sessionconfig')
        self._logger.debug("main: Session config %s", cfgfilename)
        try:
            self.sconfig = SessionStartupConfig.load(cfgfilename)
        except:
            try:
                self.sconfig = convertSessionConfig(os.path.join(state_dir, 'sessconfig.pickle'), cfgfilename)
                convertMainConfig(state_dir, os.path.join(state_dir, 'abc.conf'), os.path.join(state_dir, 'tribler.conf'))
            except:
                self.sconfig = SessionStartupConfig()
                self.sconfig.set_state_dir(state_dir)

        self.sconfig.set_install_dir(self.installdir)

        # Boudewijn, 2013-06-17: Enable Dispersy tunnel (hard-coded)
        # self.sconfig.set_dispersy_tunnel_over_swift(True)
        # Boudewijn, 2013-07-17: Disabling Dispersy tunnel (hard-coded)
        self.sconfig.set_dispersy_tunnel_over_swift(False)

        # Arno, 2010-03-31: Hard upgrade to 50000 torrents collected
        self.sconfig.set_torrent_collecting_max_torrents(50000)

        # Arno, 2012-05-21: Swift part II
        swiftbinpath = os.path.join(self.sconfig.get_install_dir(), "swift")
        if sys.platform == "darwin":
            if not os.path.exists(swiftbinpath):
                swiftbinpath = os.path.join(os.getcwdu(), "..", "MacOS", "swift")
                self.sconfig.set_swift_path(swiftbinpath)

        progress('Loading downloadconfig')
        dlcfgfilename = get_default_dscfg_filename(self.sconfig.get_state_dir())
        self._logger.debug("main: Download config %s", dlcfgfilename)
        try:
            defaultDLConfig = DefaultDownloadStartupConfig.load(dlcfgfilename)
        except:
            try:
                defaultDLConfig = convertDefaultDownloadConfig(os.path.join(state_dir, 'dlconfig.pickle'), dlcfgfilename)
            except:
                defaultDLConfig = DefaultDownloadStartupConfig.getInstance()

        if not defaultDLConfig.get_dest_dir():
            defaultDLConfig.set_dest_dir(get_default_dest_dir())
        if not os.path.isdir(defaultDLConfig.get_dest_dir()):
            try:
                os.makedirs(defaultDLConfig.get_dest_dir())
            except:
                # Could not create directory, ask user to select a different location
                dlg = wx.DirDialog(None, "Could not find download directory, please select a new location to store your downloads", style=wx.DEFAULT_DIALOG_STYLE)
                dlg.SetPath(get_default_dest_dir())
                if dlg.ShowModal() == wx.ID_OK:
                    new_dest_dir = dlg.GetPath()
                    defaultDLConfig.set_dest_dir(new_dest_dir)
                    defaultDLConfig.save(dlcfgfilename)
                    self.sconfig.set_torrent_collecting_dir(os.path.join(new_dest_dir, STATEDIR_TORRENTCOLL_DIR))
                    self.sconfig.set_swift_meta_dir(os.path.join(new_dest_dir, STATEDIR_SWIFTRESEED_DIR))
                    self.sconfig.save(cfgfilename)
                else:
                    # Quit
                    self.onError = lambda e: self._logger.error("tribler: quitting due to non-existing destination directory")
                    raise Exception()

        # Setting torrent collection dir based on default download dir
        if not self.sconfig.get_torrent_collecting_dir():
            self.sconfig.set_torrent_collecting_dir(os.path.join(defaultDLConfig.get_dest_dir(), STATEDIR_TORRENTCOLL_DIR))
        if not self.sconfig.get_swift_meta_dir():
            self.sconfig.set_swift_meta_dir(os.path.join(defaultDLConfig.get_dest_dir(), STATEDIR_SWIFTRESEED_DIR))

        progress('Creating session/Checking database (may take a minute)')
        session = Session(self.sconfig)
        session.start()

        @call_on_reactor_thread
        def define_communities(dispersy):
            assert isInIOThread()
            from Tribler.community.search.community import SearchCommunity
            from Tribler.community.allchannel.community import AllChannelCommunity
            from Tribler.community.channel.community import ChannelCommunity
            from Tribler.community.channel.preview import PreviewChannelCommunity
            from Tribler.community.metadata.community import MetadataCommunity
            from Tribler.community.anontunnel.community import ProxyCommunity
            from Tribler.community.anontunnel import exitstrategies
            from Tribler.community.anontunnel.Socks5.server import Socks5Server

            self._logger.info("tribler: Preparing communities...")
            now = time()

            # must be called on the Dispersy thread
            dispersy.define_auto_load(SearchCommunity, session.dispersy_member, load=True)
            dispersy.define_auto_load(AllChannelCommunity, session.dispersy_member, load=True)

            # load metadata community
            dispersy.define_auto_load(MetadataCommunity, session.dispersy_member, load=True)

            # 17/07/13 Boudewijn: the missing-member message send by the BarterCommunity on the swift port is crashing
            # 6.1 clients.  We will disable the BarterCommunity for version 6.2, giving people some time to upgrade
            # their version before enabling it again.
            # if swift_process:
            #     dispersy.define_auto_load(BarterCommunity,
            #                               s.dispersy_member,
            #                               (swift_process,),
            #                               load=True)

            dispersy.define_auto_load(ChannelCommunity, session.dispersy_member, load=True)
            dispersy.define_auto_load(PreviewChannelCommunity, session.dispersy_member)

            keypair = dispersy.crypto.generate_key(u"NID_secp160k1")
            dispersy_member = dispersy.get_member(
                private_key=dispersy.crypto.key_to_bin(keypair),
            )

            proxy_community = dispersy.define_auto_load(ProxyCommunity, dispersy_member, load=True,
                                                        kargs={'tribler_session': session})[0]

            socks_server = Socks5Server(proxy_community, session.lm.rawserver, session.get_proxy_community_socks5_listen_port())
            socks_server.start()
            exit_strategy = exitstrategies.DefaultExitStrategy(session.lm.rawserver, proxy_community)
            proxy_community.observers.append(exit_strategy)

            diff = time() - now
            self._logger.info("tribler: communities are ready in %.2f seconds", diff)

        session.set_anon_proxy_settings(2, ("127.0.0.1", session.get_proxy_community_socks5_listen_port()))

        swift_process = session.get_swift_proc() and session.get_swift_process()
        dispersy = session.get_dispersy_instance()
        define_communities(session.get_dispersy_instance())
        return session

    @staticmethod
    def determine_install_dir():
        # Niels, 2011-03-03: Working dir sometimes set to a browsers working dir
        # only seen on windows

        # apply trick to obtain the executable location
        # see http://www.py2exe.org/index.cgi/WhereAmI
        # Niels, 2012-01-31: py2exe should only apply to windows
        if sys.platform == 'win32':
            def we_are_frozen():
                """Returns whether we are frozen via py2exe.
                This will affect how we find out where we are located."""
                return hasattr(sys, "frozen")

            def module_path():
                """ This will get us the program's directory,
                even if we are frozen using py2exe"""
                if we_are_frozen():
                    return os.path.dirname(unicode(sys.executable, sys.getfilesystemencoding()))

                filedir = os.path.dirname(unicode(__file__, sys.getfilesystemencoding()))
                return os.path.abspath(os.path.join(filedir, '..', '..'))

            return module_path()
        return os.getcwdu()

    @forceWxThread
    def sesscb_ntfy_myprefupdates(self, subject, changeType, objectID, *args):
        if self.ready and self.frame.ready:
            if changeType == NTFY_INSERT:
                if self.frame.searchlist:
                    manager = self.frame.searchlist.GetManager()
                    manager.downloadStarted(objectID)

                manager = self.frame.selectedchannellist.GetManager()
                manager.downloadStarted(objectID)

            manager = self.frame.librarylist.GetManager()
            manager.downloadStarted(objectID)

    def set_reputation(self):
        def do_db():
            nr_connections = 0
            nr_channel_connections = 0
            if self.dispersy:
                for community in self.dispersy.get_communities():
                    from Tribler.community.search.community import SearchCommunity
                    from Tribler.community.allchannel.community import AllChannelCommunity

                    if isinstance(community, SearchCommunity):
                        nr_connections = community.get_nr_connections()
                    elif isinstance(community, AllChannelCommunity):
                        nr_channel_connections = community.get_nr_connections()

            return nr_connections, nr_channel_connections

        def do_wx(delayedResult):
            nr_connections, nr_channel_connections = delayedResult.get()

            # self.frame.SRstatusbar.set_reputation(myRep, total_down, total_up)

            # bitmap is 16px wide, -> but first and last pixel do not add anything.
            percentage = min(1.0, (nr_connections + 1) / 16.0)
            self.frame.SRstatusbar.SetConnections(percentage, nr_connections, nr_channel_connections)

        """ set the reputation in the GUI"""
        if self.ready and self.frame.ready:
            startWorker(do_wx, do_db, uId=u"tribler.set_reputation")
        startWorker(None, self.set_reputation, delay=5.0, workerType="guiTaskQueue")

    def _dispersy_get_barter_community(self):
        try:
            return self.dispersy.get_community(BARTER_MASTER_MEMBER_PUBLIC_KEY_DIGEST, load=False, auto_load=False)
        except KeyError:
            return None

    def sesscb_states_callback(self, dslist):
        if not self.ready:
            return (5.0, [])

        wantpeers = []
        self.ratestatecallbackcount += 1
        if DEBUG:
            torrentdb = self.utility.session.open_dbhandler(NTFY_TORRENTS)
            peerdb = self.utility.session.open_dbhandler(NTFY_PEERS)
            self._logger.debug("main: Stats: Total torrents found %s peers %s" % \
                (repr(torrentdb.size()), repr(peerdb.size())))

        try:
            # Print stats on Console
            if DEBUG:
                if self.ratestatecallbackcount % 5 == 0:
                    for ds in dslist:
                        safename = repr(ds.get_download().get_def().get_name())
                        self._logger.debug("%s %s %.1f%% dl %.1f ul %.1f n %d", safename, dlstatus_strings[ds.get_status()], 100.0 * ds.get_progress(), ds.get_current_speed(DOWNLOAD), ds.get_current_speed(UPLOAD), ds.get_num_peers())
                        # print >>sys.stderr,"main: Infohash:",`ds.get_download().get_def().get_infohash()`
                        if ds.get_status() == DLSTATUS_STOPPED_ON_ERROR:
                            self._logger.debug("main: Error: %s", repr(ds.get_error()))

            # Pass DownloadStates to libaryView
            no_collected_list = []
            try:
                coldir = os.path.basename(os.path.abspath(self.utility.session.get_torrent_collecting_dir()))
                for ds in dslist:
                    destdir = os.path.basename(ds.get_download().get_dest_dir())
                    if destdir != coldir:
                        no_collected_list.append(ds)
                # Arno, 2012-07-17: Retrieving peerlist for the DownloadStates takes CPU
                # so only do it when needed for display.
                wantpeers.extend(self.guiUtility.library_manager.download_state_callback(no_collected_list))
            except:
                print_exc()

            # Check to see if a download has finished
            newActiveDownloads = []
            doCheckpoint = False
            for ds in dslist:
                state = ds.get_status()
                cdef = ds.get_download().get_def()
                safename = cdef.get_name_as_unicode() if cdef.get_def_type() == 'torrent' else cdef.get_name()

                if state == DLSTATUS_DOWNLOADING:
                    newActiveDownloads.append(safename)

                elif state == DLSTATUS_SEEDING:
                    if safename in self.prevActiveDownloads:
                        download = ds.get_download()
                        cdef = download.get_def()

                        coldir = os.path.basename(os.path.abspath(self.utility.session.get_torrent_collecting_dir()))
                        destdir = os.path.basename(download.get_dest_dir())
                        if destdir != coldir:
                            hash = cdef.get_id()

                            notifier = Notifier.getInstance()
                            notifier.notify(NTFY_TORRENTS, NTFY_FINISHED, hash, safename)

                            # Arno, 2012-05-04: Swift reseeding
                            # if self.utility.read_config('swiftreseed') == 1 and cdef.get_def_type() == 'torrent' and not download.get_selected_files():
                            #    self.sesscb_reseed_via_swift(download)

                            doCheckpoint = True

            self.prevActiveDownloads = newActiveDownloads
            if doCheckpoint:
                self.utility.session.checkpoint()

            self.seedingmanager.apply_seeding_policy(no_collected_list)

            # Adjust speeds once every 4 seconds
            adjustspeeds = False
            if self.ratestatecallbackcount % 4 == 0:
                adjustspeeds = True

            if adjustspeeds:
                swift_dslist = [ds for ds in no_collected_list if ds.get_download().get_def().get_def_type() == 'swift']
                self.ratelimiter.add_downloadstatelist(swift_dslist)
                self.ratelimiter.adjust_speeds()

                if DEBUG_DOWNLOADS:
                    for ds in dslist:
                        cdef = ds.get_download().get_def()
                        state = ds.get_status()
                        if cdef.get_def_type() == 'swift':
                            safename = cdef.get_name()
                            self._logger.debug("tribler: SW %s %s %s", dlstatus_strings[state], safename, ds.get_current_speed(UPLOAD))
                        else:
                            self._logger.debug("tribler: BT %s %s %s", dlstatus_strings[state], cdef.get_name(), ds.get_current_speed(UPLOAD))

        except:
            print_exc()

        self.lastwantpeers = wantpeers
        return (1.0, wantpeers)

    def loadSessionCheckpoint(self):
        # Niels: first remove all "swift" torrent collect checkpoints
        dir = self.utility.session.get_downloads_pstate_dir()
        coldir = os.path.basename(os.path.abspath(self.utility.session.get_torrent_collecting_dir()))

        filelist = os.listdir(dir)
        if any([filename.endswith('.pickle') for filename in filelist]):
            convertDownloadCheckpoints(dir)
            filelist = os.listdir(dir)

        filelist = [os.path.join(dir, filename) for filename in filelist if filename.endswith('.state')]

        for file in filelist:
            try:
                pstate = self.utility.session.lm.load_download_pstate(file)

                saveas = pstate.get('downloadconfig', 'saveas')
                if saveas:
                    destdir = os.path.basename(saveas)
                    if destdir == coldir:
                        os.remove(file)
            except:
                pass

        from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice
        user_download_choice = UserDownloadChoice.get_singleton()
        initialdlstatus_dict = {}
        for id, state in user_download_choice.get_download_states().iteritems():
            if state == 'stop':
                initialdlstatus_dict[id] = DLSTATUS_STOPPED

        self.utility.session.load_checkpoint(initialdlstatus_dict=initialdlstatus_dict)

    def guiservthread_free_space_check(self):
        free_space = get_free_space(DefaultDownloadStartupConfig.getInstance().get_dest_dir())
        self.frame.SRstatusbar.RefreshFreeSpace(free_space)

        storage_locations = defaultdict(list)
        for download in self.utility.session.get_downloads():
            if download.get_def().get_def_type() == 'torrent' and download.get_status() == DLSTATUS_DOWNLOADING:
                storage_locations[download.get_dest_dir()].append(download)

        show_message = False
        low_on_space = [path for path in storage_locations.keys() if get_free_space(path) < self.utility.read_config('free_space_threshold')]
        for path in low_on_space:
            for download in storage_locations[path]:
                download.stop()
                show_message = True

        if show_message:
            wx.CallAfter(wx.MessageBox, "Tribler has detected low disk space. Related downloads have been stopped.", "Error")

        self.guiserver.add_task(self.guiservthread_free_space_check, FREE_SPACE_CHECK_INTERVAL)

    def guiservthread_checkpoint_timer(self):
        """ Periodically checkpoint Session """
        if self.done:
            return
        try:
            self._logger.info("main: Checkpointing Session")
            self.utility.session.checkpoint()

            self.guiserver.add_task(self.guiservthread_checkpoint_timer, SESSION_CHECKPOINT_INTERVAL)
        except:
            print_exc()

    @forceWxThread
    def sesscb_ntfy_activities(self, events):
        if self.ready and self.frame.ready:
            for args in events:
                objectID = args[2]
                args = args[3:]

                self.frame.setActivity(objectID, *args)

    @forceWxThread
    def sesscb_ntfy_reachable(self, subject, changeType, objectID, msg):
        if self.ready and self.frame.ready:
            self.frame.SRstatusbar.onReachable()

    @forceWxThread
    def sesscb_ntfy_channelupdates(self, events):
        if self.ready and self.frame.ready:
            for args in events:
                subject = args[0]
                changeType = args[1]
                objectID = args[2]

                if self.frame.channellist:
                    if len(args) > 3:
                        myvote = args[3]
                    else:
                        myvote = False

                    manager = self.frame.channellist.GetManager()
                    manager.channelUpdated(objectID, subject == NTFY_VOTECAST, myvote=myvote)

                manager = self.frame.selectedchannellist.GetManager()
                manager.channelUpdated(objectID, stateChanged=changeType == NTFY_STATE, modified=changeType == NTFY_MODIFIED)

                if changeType == NTFY_CREATE:
                    if self.frame.channellist:
                        self.frame.channellist.SetMyChannelId(objectID)

                    self.torrentfeed.register(self.utility.session, objectID)
                    self.torrentfeed.addCallback(objectID, self.guiUtility.channelsearch_manager.createTorrentFromDef)
                    self.torrentfeed.addCallback(objectID, self.guiUtility.torrentsearch_manager.createMetadataModificationFromDef)

                self.frame.managechannel.channelUpdated(objectID, created=changeType == NTFY_CREATE, modified=changeType == NTFY_MODIFIED)

    @forceWxThread
    def sesscb_ntfy_torrentupdates(self, events):
        if self.ready and self.frame.ready:
            infohashes = [args[2] for args in events]

            if self.frame.searchlist:
                manager = self.frame.searchlist.GetManager()
                manager.torrentsUpdated(infohashes)

                manager = self.frame.selectedchannellist.GetManager()
                manager.torrentsUpdated(infohashes)

                manager = self.frame.playlist.GetManager()
                manager.torrentsUpdated(infohashes)

                manager = self.frame.librarylist.GetManager()
                manager.torrentsUpdated(infohashes)

            from Tribler.Main.Utility.GuiDBTuples import CollectedTorrent

            if self.frame.torrentdetailspanel.torrent and self.frame.torrentdetailspanel.torrent.infohash in infohashes:
                # If an updated torrent is being shown in the detailspanel, make sure the information gets refreshed.
                t = self.frame.torrentdetailspanel.torrent
                torrent = t.torrent if isinstance(t, CollectedTorrent) else t
                self.frame.torrentdetailspanel.setTorrent(torrent)

            if self.frame.librarydetailspanel.torrent and self.frame.librarydetailspanel.torrent.infohash in infohashes:
                t = self.frame.librarydetailspanel.torrent
                torrent = t.torrent if isinstance(t, CollectedTorrent) else t
                self.frame.librarydetailspanel.setTorrent(torrent)

    def sesscb_ntfy_torrentfinished(self, subject, changeType, objectID, *args):
        self.guiUtility.Notify("Download Completed", "Torrent '%s' has finished downloading. Now seeding." % args[0], icon='seed')

        if self.ready and self.frame.ready:
            self.guiUtility.torrentstate_manager.torrentFinished(objectID)

    def sesscb_ntfy_magnet(self, subject, changetype, objectID, *args):
        if changetype == NTFY_MAGNET_STARTED:
            self.guiUtility.library_manager.magnet_started(objectID)
        elif changetype == NTFY_MAGNET_GOT_PEERS:
            self.guiUtility.library_manager.magnet_got_peers(objectID, args[0])
        elif changetype == NTFY_MAGNET_PROGRESS:
            self.guiUtility.library_manager.magnet_got_piece(objectID, args[0])
        elif changetype == NTFY_MAGNET_CLOSE:
            self.guiUtility.library_manager.magnet_close(objectID)

    @forceWxThread
    def sesscb_ntfy_playlistupdates(self, subject, changeType, objectID, *args):
        if self.ready and self.frame.ready:
            if changeType == NTFY_INSERT:
                self.frame.managechannel.playlistCreated(objectID)

                manager = self.frame.selectedchannellist.GetManager()
                manager.playlistCreated(objectID)

            else:
                self.frame.managechannel.playlistUpdated(objectID, modified=changeType == NTFY_MODIFIED)

                if len(args) > 0:
                    infohash = args[0]
                else:
                    infohash = False
                manager = self.frame.selectedchannellist.GetManager()
                manager.playlistUpdated(objectID, infohash, modified=changeType == NTFY_MODIFIED)

                manager = self.frame.playlist.GetManager()
                manager.playlistUpdated(objectID, modified=changeType == NTFY_MODIFIED)

    @forceWxThread
    def sesscb_ntfy_commentupdates(self, subject, changeType, objectID, *args):
        if self.ready and self.frame.ready:
            self.frame.selectedchannellist.OnCommentCreated(objectID)
            self.frame.playlist.OnCommentCreated(objectID)

    @forceWxThread
    def sesscb_ntfy_modificationupdates(self, subject, changeType, objectID, *args):
        if self.ready and self.frame.ready:
            self.frame.selectedchannellist.OnModificationCreated(objectID)
            self.frame.playlist.OnModificationCreated(objectID)

    @forceWxThread
    def sesscb_ntfy_moderationupdats(self, subject, changeType, objectID, *args):
        if self.ready and self.frame.ready:
            self.frame.selectedchannellist.OnModerationCreated(objectID)
            self.frame.playlist.OnModerationCreated(objectID)

    @forceWxThread
    def sesscb_ntfy_markingupdates(self, subject, changeType, objectID, *args):
        if self.ready and self.frame.ready:
            self.frame.selectedchannellist.OnMarkingCreated(objectID)
            self.frame.playlist.OnModerationCreated(objectID)

    @forceWxThread
    def onError(self, e):
        print_exc()
        type, value, stack = sys.exc_info()
        backtrace = traceback.format_exception(type, value, stack)

        win = FeedbackWindow("Unfortunately, Tribler ran into an internal error")
        win.CreateOutputWindow('')
        for line in backtrace:
            win.write(line)

        win.ShowModal()

    def MacOpenFile(self, filename):
        self._logger.info(repr(filename))
        target = FileDropTarget(self.frame)
        target.OnDropFiles(None, None, [filename])

    def OnExit(self):
        self._logger.info("main: ONEXIT")
        self.ready = False
        self.done = True

        # write all persistent data to disk
        if self.i2is:
            self.i2is.shutdown()
        if self.torrentfeed:
            self.torrentfeed.shutdown()
            self.torrentfeed.delInstance()
        if self.webUI:
            self.webUI.stop()
            self.webUI.delInstance()
        if self.guiserver:
            self.guiserver.shutdown(True)
            self.guiserver.delInstance()

        delete_status_holders()

        if self.frame:
            self.frame.Destroy()
            self.frame = None

        # Don't checkpoint, interferes with current way of saving Preferences,
        # see Tribler/Main/Dialogs/abcoption.py
        if self.utility:
            # Niels: lets add a max waiting time for this session shutdown.
            session_shutdown_start = time()

            self.utility.session.shutdown(hacksessconfcheckpoint=False)

            # Arno, 2012-07-12: Shutdown should be quick
            # Niels, 2013-03-21: However, setting it too low will prevent checkpoints from being written to disk
            waittime = 60
            while not self.utility.session.has_shutdown():
                diff = time() - session_shutdown_start
                if diff > waittime:
                    self._logger.info("main: ONEXIT NOT Waiting for Session to shutdown, took too long")
                    break

                self._logger.info("main: ONEXIT Waiting for Session to shutdown, will wait for an additional %d seconds", waittime - diff)
                sleep(3)
            self._logger.info("main: ONEXIT Session is shutdown")

            try:
                self._logger.info("main: ONEXIT cleaning database")
                peerdb = self.utility.session.open_dbhandler(NTFY_PEERS)
                peerdb._db.clean_db(randint(0, 24) == 0, exiting=True)
            except:
                print_exc()

            self._logger.info("main: ONEXIT deleting instances")

        Session.del_instance()
        GUIUtility.delInstance()
        GUIDBProducer.delInstance()
        DefaultDownloadStartupConfig.delInstance()
        GuiImageManager.delInstance()

        if SQLiteCacheDB.hasInstance():
            SQLiteCacheDB.getInstance().close_all()
            SQLiteCacheDB.delInstance()

        return 0

    def db_exception_handler(self, e):
        self._logger.debug("main: Database Exception handler called %s value %s #", e, e.args)
        try:
            if e.args[1] == "DB object has been closed":
                return  # We caused this non-fatal error, don't show.
            if self.error is not None and self.error.args[1] == e.args[1]:
                return  # don't repeat same error
        except:
            self._logger.error("main: db_exception_handler error %s %s", e, type(e))
            print_exc()
            # print_stack()

        self.onError(e)

    def getConfigPath(self):
        return self.utility.getConfigPath()

    def startWithRightView(self):
        if self.params[0] != "":
            self.guiUtility.ShowPage('my_files')

    def i2ithread_readlinecallback(self, ic, cmd):
        """ Called by Instance2Instance thread """

        self._logger.info("main: Another instance called us with cmd %s", cmd)
        ic.close()

        if cmd.startswith('START '):
            param = cmd[len('START '):].strip()
            torrentfilename = None
            if param.startswith('http:'):
                # Retrieve from web
                f = tempfile.NamedTemporaryFile()
                n = urllib2.urlopen(param)
                data = n.read()
                f.write(data)
                f.close()
                n.close()
                torrentfilename = f.name
            else:
                torrentfilename = param

            # Switch to GUI thread
            # New for 5.0: Start in VOD mode
            def start_asked_download():
                if torrentfilename.startswith("magnet:"):
                    self.frame.startDownloadFromMagnet(torrentfilename)
                elif torrentfilename.startswith("tswift://") or torrentfilename.startswith("ppsp://"):
                    self.frame.startDownloadFromSwift(torrentfilename)
                else:
                    self.frame.startDownload(torrentfilename)
                self.guiUtility.ShowPage('my_files')

            wx.CallAfter(start_asked_download)

    def sesscb_reseed_via_swift(self, td, callback=None):
        # Arno, 2012-05-07: root hash calculation may take long time, halting
        # SessionCallbackThread meaning download statuses won't be updated.
        # Offload to diff thread.
        #
        t = Thread(target=self.workerthread_reseed_via_swift_run, args=(td, callback), name="SwiftRootHashCalculator")
        t.start()
        # apparently daemon by default

    def workerthread_reseed_via_swift_run(self, td, callback=None):
        # Open issues:
        # * how to display these "parallel" downloads in GUI?
        # * make swift reseed user configurable (see 'swiftreseed' in utility.py
        # * roothash calc on separate thread?
        # * Update pymDHT to one with swift interface.
        # * Save (infohash,roothash) pair such that when BT download is removed
        #   the other is (kept/deleted/...) too.
        #
        try:
            if prctlimported:
                prctl.set_name(currentThread().getName())

            # 1. Get torrent info
            tdef = td.get_def()
            destdir = td.get_dest_dir()

            # renaming swarmname for now not supported in swift
            if td.correctedinfoname != fix_filebasename(tdef.get_name_as_unicode()):
                return

            # 2. Convert to swift def
            sdef = SwiftDef()
            # RESEEDTODO: set to swift inf of pymDHT
            sdef.set_tracker("127.0.0.1:%d" % self.sconfig.get_swift_dht_listen_port())
            iotuples = td.get_dest_files()
            for i, o in iotuples:
                # print >>sys.stderr,"python: add_content",i,o
                if len(iotuples) == 1:
                    sdef.add_content(o)  # single file .torrent
                else:
                    xi = os.path.join(tdef.get_name_as_unicode(), i)
                    sdef.add_content(o, xi)  # multi-file .torrent

            specpn = sdef.finalize(self.sconfig.get_swift_path(), destdir=destdir)

            # 3. Save swift files to metadata dir
            metadir = self.sconfig.get_swift_meta_dir()
            if len(iotuples) == 1:
                storagepath = iotuples[0][1]  # Point to file on disk
                metapath = os.path.join(metadir, os.path.split(storagepath)[1])

                try:
                    shutil.move(storagepath + '.mhash', metapath + '.mhash')
                    shutil.move(storagepath + '.mbinmap', metapath + '.mbinmap')
                except:
                    print_exc()

            else:
                storagepath = destdir  # Point to dest dir
                metapath = os.path.join(metadir, sdef.get_roothash_as_hex())

                # Reuse .mhash and .mbinmap (happens automatically for single-file)
                try:
                    shutil.move(specpn, metapath + '.mfspec')
                    shutil.move(specpn + '.mhash', metapath + '.mhash')
                    shutil.move(specpn + '.mbinmap', metapath + '.mbinmap')
                except:
                    print_exc()

            # 4. Start Swift download via GUI Thread
            wx.CallAfter(self.frame.startReseedSwiftDownload, tdef, storagepath, sdef)

            # 5. Call the callback to notify
            if callback:
                callback(sdef)
        except:
            print_exc()
            raise


#
#
# Main Program Start Here
#
#
@attach_profiler
def run(params=None):
    if params is None:
        params = [""]

    if len(sys.argv) > 1:
        params = sys.argv[1:]
    try:
        # Create single instance semaphore
        single_instance_checker = SingleInstanceChecker("tribler")

        installdir = ABCApp.determine_install_dir()

        if not ALLOW_MULTIPLE and single_instance_checker.IsAnotherRunning():
            statedir = SessionStartupConfig().get_state_dir() or Session.get_default_state_dir()

            # Send  torrent info to abc single instance
            if params[0] != "":
                torrentfilename = params[0]
                i2ic = Instance2InstanceClient(Utility(installdir, statedir).read_config('i2ilistenport'), 'START', torrentfilename)

            logger.info("Client shutting down. Detected another instance.")
        else:

            if sys.platform == 'linux2':
                try:
                    import ctypes
                    x11 = ctypes.cdll.LoadLibrary('libX11.so')
                    x11.XInitThreads()
                except OSError as e:
                    logger.debug("Failed to call XInitThreads '%s'", str(e))
                except:
                    logger.exception('Failed to call xInitThreads')

            # Launch first abc single instance
            app = wx.GetApp()
            if not app:
                app = wx.PySimpleApp(redirect=False)
            abc = ABCApp(params, installdir)
            if abc.frame:
                app.SetTopWindow(abc.frame)
                abc.frame.set_wxapp(app)
                app.MainLoop()

            # since ABCApp is not a wx.App anymore, we need to call OnExit explicitly.
            abc.OnExit()

            # Niels: No code should be present here, only executed after gui closes

        logger.info("Client shutting down. Sleeping for a few seconds to allow other threads to finish")
        sleep(5)

    except:
        print_exc()


    # This is the right place to close the database, unfortunately Linux has
    # a problem, see ABCFrame.OnCloseWindow
    #
    # if sys.platform != 'linux2':
    #    tribler_done(configpath)
    # os._exit(0)

if __name__ == '__main__':
    run()

########NEW FILE########
__FILENAME__ = tribler_profiler
# Requires yappi to be installed, use easy_install yappi

import yappi
import sys
from time import time
from tribler import run

if __name__ == '__main__':
    t1 = time()
    yappi.start()
    run()
    yappi.stop()
    print >> sys.stderr, "YAPPI: %s tribler has run for %s seconds" % \
        (yappi.get_clock_type(), time() - t1)
    yappi_stats = yappi.get_func_stats()
    yappi_stats.sort("tsub")
    count = 0
    for func_stat in yappi_stats:
        print >> sys.stderr, "YAPPI: %10dx  %10.3fs %s" % \
            (func_stat.ncall, func_stat.tsub, func_stat.name)
        count += 1
        if count >= 50:
            break

########NEW FILE########
__FILENAME__ = compat
# Written by Egbert Bouman

#
# Things to handle backward compatability for old-style config files
#

import io
import os
import glob
import json
import pickle
import cPickle
import StringIO

from ConfigParser import RawConfigParser

from Tribler.Core.SessionConfig import SessionStartupConfig
from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.Core.simpledefs import PERSISTENTSTATE_CURRENTVERSION


def convertSessionConfig(oldfilename, newfilename):
    # Convert tribler <= 6.2 session config file to tribler 6.3

    # We assume oldfilename exists
    with open(oldfilename, "rb") as f:
        sessconfig = pickle.load(f)

    # Upgrade to new config
    sconfig = SessionStartupConfig()
    for key, value in sessconfig.iteritems():
        if key in ['state_dir', 'install_dir', 'ip', 'minport', 'maxport', 'bind', 'ipv6_enabled', \
                   'ipv6_binds_v4', 'timeout', 'timeout_check_interval', 'eckeypairfilename', 'megacache', \
                   'nickname', 'mugshot', 'videoanalyserpath', 'peer_icon_path', 'live_aux_seeders']:
            sconfig.sessconfig.set('general', key, value)
        if key in ['mainline_dht', 'mainline_dht_port']:
            sconfig.sessconfig.set('mainline_dht', 'enabled' if key == 'mainline_dht' else key, value)
        if key in ['torrent_checking', 'torrent_checking_period']:
            sconfig.sessconfig.set('torrent_checking', 'enabled' if key == 'torrent_checking' else key, value)
        if key in ['torrent_collecting', 'dht_torrent_collecting', 'torrent_collecting_max_torrents', 'torrent_collecting_dir' \
                   'stop_collecting_threshold']:
            sconfig.sessconfig.set('torrent_collecting', 'enabled' if key == 'torrent_collecting' else key, value)
        if key in ['libtorrent', 'lt_proxytype', 'lt_proxyserver', 'lt_proxyauth']:
            sconfig.sessconfig.set('libtorrent', 'enabled' if key == 'libtorrent' else key, value)
        if key in ['swiftproc', 'swiftpath', 'swiftworkingdir', 'swiftcmdlistenport', 'swiftdlsperproc', 'swiftmetadir' \
                   'swifttunnellistenport', 'swifttunnelhttpgwlistenport', 'swifttunnelcmdgwlistenport', 'swiftdhtport']:
            sconfig.sessconfig.set('swift', 'enabled' if key == 'swiftproc' else key, value)
        if key in ['dispersy_port', 'dispersy-tunnel-over-swift', 'dispersy']:
            sconfig.sessconfig.set('dispersy', 'enabled' if key == 'dispersy' else key, value)

    # Save the new file, remove the old one
    sconfig.save(newfilename)
    os.remove(oldfilename)
    return sconfig


def convertMainConfig(state_dir, oldfilename, newfilename):
    # Convert tribler <= 6.2 config files to tribler 6.3

    # We assume oldfilename exists
    with io.open(oldfilename, 'r', encoding='utf_8_sig') as f:
        corrected_config = StringIO.StringIO(f.read().replace('[ABC]', '[Tribler]'))

    config = RawConfigParser()
    config.readfp(corrected_config)

    # Convert user_download_choice.pickle
    udcfilename = os.path.join(state_dir, 'user_download_choice.pickle')
    if os.path.exists(udcfilename):
        with open(udcfilename, "r") as f:
            choices = cPickle.Unpickler(f).load()
            choices = dict([(k.encode('hex'), v) for k, v in choices["download_state"].iteritems()])
            config.set('Tribler', 'user_download_choice', json.dumps(choices))
        os.remove(udcfilename)

    # Convert gui_settings
    guifilename = os.path.join(state_dir, 'gui_settings')
    if os.path.exists(guifilename):
        with open(guifilename, "r") as f:
            for line in f.readlines():
                key, value = line.split('=')
                config.set('Tribler', key, value.strip())
        os.remove(guifilename)

    # Convert recent_download_history
    histfilename = os.path.join(state_dir, 'recent_download_history')
    if os.path.exists(histfilename):
        with open(histfilename, "r") as f:
            history = []
            for line in f.readlines():
                key, value = line.split('=')
                if value != '' and value != '\n':
                    history.append(value.replace('\\\\', '\\').strip())
            config.set('Tribler', 'recent_download_history', json.dumps(history))
        os.remove(histfilename)

    with open(newfilename, "wb") as f:
        config.write(f)
    os.remove(oldfilename)

def convertDefaultDownloadConfig(oldfilename, newfilename):
    # Convert tribler <= 6.2 default download config file to tribler 6.3

    # We assume oldfilename exists
    with open(oldfilename, "rb") as f:
        dlconfig = pickle.load(f)

    # Upgrade to new config
    ddsconfig = DefaultDownloadStartupConfig()
    for key, value in dlconfig.iteritems():
        if key in ['saveas', 'max_upload_rate', 'max_download_rate', \
                   'super_seeder', 'mode', 'selected_files', 'correctedfilename', \
                   'swiftlistenport', 'swiftcmdgwlistenport', 'swifthttpgwlistenport', 'swiftmetadir', 'name']:
            ddsconfig.dlconfig.set('downloadconfig', key, value)

    # Save the new file, remove the old one
    ddsconfig.save(newfilename)
    os.remove(oldfilename)
    return ddsconfig

def convertDownloadCheckpoints(checkpoint_dir):
    # Convert tribler <= 6.2 download checkpoints to tribler 6.3

    if os.path.exists(checkpoint_dir):
        for old_filename in glob.glob(os.path.join(checkpoint_dir, '*.pickle')):
            old_checkpoint = None
            try:
                with open(old_filename, "rb") as old_file:
                    old_checkpoint = pickle.load(old_file)
            except:
                pass

            if old_checkpoint:
                new_checkpoint = RawConfigParser()
                new_checkpoint.add_section('downloadconfig')
                new_checkpoint.add_section('state')
                for key, value in old_checkpoint['dlconfig'].iteritems():
                    if key in ['saveas', 'max_upload_rate', 'max_download_rate', 'super_seeder', 'mode', \
                               'selected_files', 'correctedfilename', 'swiftlistenport', \
                               'swiftcmdgwlistenport', 'swifthttpgwlistenport', 'swiftmetadir', 'name']:
                        new_checkpoint.set('downloadconfig', key, value)
                new_checkpoint.set('state', 'version', PERSISTENTSTATE_CURRENTVERSION)
                new_checkpoint.set('state', 'engineresumedata', old_checkpoint['engineresumedata'])
                new_checkpoint.set('state', 'dlstate', old_checkpoint['dlstate'])
                new_checkpoint.set('state', 'metainfo', old_checkpoint['metainfo'])
                with open(old_filename.replace('.pickle', '.state'), "wb") as new_file:
                    new_checkpoint.write(new_file)

            os.remove(old_filename)

########NEW FILE########
__FILENAME__ = dirfeed
from threading import Thread, Event
import shutil
import os
import time
import logging
from Tribler.Core.TorrentDef import TorrentDef
DIR_CHECK_FREQUENCY = 10  # Check directories every 10 seconds


class DirectoryFeedThread(Thread):
    __single = None

    def __init__(self):
        if DirectoryFeedThread.__single:
            raise RuntimeError("DirectoryFeedThread is singleton")
        DirectoryFeedThread.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        Thread.__init__(self)
        self.setName("DirectoryFeed" + self.getName())
        self.setDaemon(True)

        self.paths = {}
        self.feeds = []

        self.done = Event()

    def getInstance(*args, **kw):
        if DirectoryFeedThread.__single is None:
            DirectoryFeedThread(*args, **kw)
        return DirectoryFeedThread.__single
    getInstance = staticmethod(getInstance)

    def _on_torrent_found(self, dirpath, torrentpath, infohash, torrent_data):
        self._logger.info('DirectoryFeedThread: Adding %s', torrentpath)
        imported_dir = os.path.join(dirpath, 'imported')
        if not os.path.exists(imported_dir):
            os.makedirs(imported_dir)
        shutil.move(torrentpath, os.path.join(imported_dir, os.path.basename(torrentpath)))

    def addDir(self, dirpath, callback=None):
        # callback(dirpath, infohash, torrent_data)

        if dirpath not in self.paths:
            self.paths[dirpath] = 'active'
            feed = DirectoryFeedReader(dirpath)
            self.feeds.append([feed, callback])

        elif callback:  # replace callback
            for tup in self.feeds:
                if tup[0].path == dirpath:
                    tup[2] = callback

    def deleteDir(self, path):
        raise NotImplementedError('TODO')

    def refresh(self):
        for (feed, callback) in self.feeds:
            if self.paths[feed.path] == 'active':
                for torrentpath, infohash, torrent_data in feed.read_torrents():
                    self._on_torrent_found(feed.path, torrentpath, infohash, torrent_data)
                    if callback:
                        callback(feed.path, infohash, torrent_data)

    def run(self):
        time.sleep(60)  # Let other Tribler components, in particular, Session startup

        self._logger.info('*** DirectoryFeedThread: Starting first refresh round')
        while not self.done.isSet():
            self.refresh()
            time.sleep(DIR_CHECK_FREQUENCY)

    def shutdown(self):
        self.done.set()


class DirectoryFeedReader:

    def __init__(self, path):
        self.path = path

    def read_torrents(self):
        files = os.listdir(self.path)
        for file in files:
            full_path = os.path.join(self.path, file)

            tdef = None
            try:
                tdef = TorrentDef.load(full_path)
                yield full_path, tdef.infohash, tdef.get_metainfo()

            except:
                pass

########NEW FILE########
__FILENAME__ = feedparser
#!/usr/bin/env python
"""Universal feed parser

Handles RSS 0.9x, RSS 1.0, RSS 2.0, CDF, Atom 0.3, and Atom 1.0 feeds

Visit http://feedparser.org/ for the latest version
Visit http://feedparser.org/docs/ for the latest documentation

Required: Python 2.4 or later
Recommended: CJKCodecs and iconv_codec <http://cjkpython.i18n.org/>
"""

__version__ = "5.0.1"
__license__ = """Copyright (c) 2002-2008, Mark Pilgrim, All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice,
  this list of conditions and the following disclaimer.
* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS 'AS IS'
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE."""
__author__ = "Mark Pilgrim <http://diveintomark.org/>"
__contributors__ = ["Jason Diamond <http://injektilo.org/>",
                    "John Beimler <http://john.beimler.org/>",
                    "Fazal Majid <http://www.majid.info/mylos/weblog/>",
                    "Aaron Swartz <http://aaronsw.com/>",
                    "Kevin Marks <http://epeus.blogspot.com/>",
                    "Sam Ruby <http://intertwingly.net/>",
                    "Ade Oshineye <http://blog.oshineye.com/>",
                    "Martin Pool <http://sourcefrog.net/>",
                    "Kurt McKee <http://kurtmckee.org/>"]
_debug = 0

# HTTP "User-Agent" header to send to servers when downloading feeds.
# If you are embedding feedparser in a larger application, you should
# change this to your application name and URL.
USER_AGENT = "UniversalFeedParser/%s +http://feedparser.org/" % __version__

# HTTP "Accept" header to send to servers when downloading feeds.  If you don't
# want to send an Accept header, set this to None.
ACCEPT_HEADER = "application/atom+xml,application/rdf+xml,application/rss+xml,application/x-netcdf,application/xml;q=0.9,text/xml;q=0.2,*/*;q=0.1"

# List of preferred XML parsers, by SAX driver name.  These will be tried first,
# but if they're not installed, Python will keep searching through its own list
# of pre-installed parsers until it finds one that supports everything we need.
PREFERRED_XML_PARSERS = ["drv_libxml2"]

# If you want feedparser to automatically run HTML markup through HTML Tidy, set
# this to 1.  Requires mxTidy <http://www.egenix.com/files/python/mxTidy.html>
# or utidylib <http://utidylib.berlios.de/>.
TIDY_MARKUP = 0

# List of Python interfaces for HTML Tidy, in order of preference.  Only useful
# if TIDY_MARKUP = 1
PREFERRED_TIDY_INTERFACES = ["uTidy", "mxTidy"]

# If you want feedparser to automatically resolve all relative URIs, set this
# to 1.
RESOLVE_RELATIVE_URIS = 1

# If you want feedparser to automatically sanitize all potentially unsafe
# HTML content, set this to 1.
SANITIZE_HTML = 1

# ---------- Python 3 modules (make it work if possible) ----------
try:
    import rfc822
except ImportError:
    from email import _parseaddr as rfc822

try:
    # Python 3.1 introduces bytes.maketrans and simultaneously
    # deprecates string.maketrans; use bytes.maketrans if possible
    _maketrans = bytes.maketrans
except (NameError, AttributeError):
    import string
    _maketrans = string.maketrans

# base64 support for Atom feeds that contain embedded binary data
try:
    import base64
    import binascii
    # Python 3.1 deprecates decodestring in favor of decodebytes
    _base64decode = getattr(base64, 'decodebytes', base64.decodestring)
except:
    base64 = binascii = None

import logging

logger = logging.getLogger(__name__)


def _s2bytes(s):
    # Convert a UTF-8 str to bytes if the interpreter is Python 3
    try:
        return bytes(s, 'utf8')
    except (NameError, TypeError):
        # In Python 2.5 and below, bytes doesn't exist (NameError)
        # In Python 2.6 and above, bytes and str are the same (TypeError)
        return s


def _l2bytes(l):
    # Convert a list of ints to bytes if the interpreter is Python 3
    try:
        if bytes is not str:
            # In Python 2.6 and above, this call won't raise an exception
            # but it will return bytes([65]) as '[65]' instead of 'A'
            return bytes(l)
        raise NameError
    except NameError:
        return ''.join(map(chr, l))

# If you want feedparser to allow all URL schemes, set this to ()
# List culled from Python's urlparse documentation at:
#   http://docs.python.org/library/urlparse.html
# as well as from "URI scheme" at Wikipedia:
#   https://secure.wikimedia.org/wikipedia/en/wiki/URI_scheme
# Many more will likely need to be added!
ACCEPTABLE_URI_SCHEMES = (
    'file', 'ftp', 'gopher', 'h323', 'hdl', 'http', 'https', 'imap', 'mailto',
    'mms', 'news', 'nntp', 'prospero', 'rsync', 'rtsp', 'rtspu', 'sftp',
    'shttp', 'sip', 'sips', 'snews', 'svn', 'svn+ssh', 'telnet', 'wais',
    # Additional common-but-unofficial schemes
    'aim', 'callto', 'cvs', 'facetime', 'feed', 'git', 'gtalk', 'irc', 'ircs',
    'irc6', 'itms', 'mms', 'msnim', 'skype', 'ssh', 'smb', 'svn', 'ymsg',
)
# ACCEPTABLE_URI_SCHEMES = ()

# ---------- required modules (should come with any Python distribution) ----------
import sgmllib
import re
import sys
import copy, urlparse, time, types, cgi, urllib, urllib2, datetime
try:
    from io import BytesIO as _StringIO
except ImportError:
    try:
        from cStringIO import StringIO as _StringIO
    except:
        from StringIO import StringIO as _StringIO

# ---------- optional modules (feedparser will work without these, but with reduced functionality) ----------

# gzip is included with most Python distributions, but may not be available if you compiled your own
try:
    import gzip
except:
    gzip = None
try:
    import zlib
except:
    zlib = None

# If a real XML parser is available, feedparser will attempt to use it.  feedparser has
# been tested with the built-in SAX parser, PyXML, and libxml2.  On platforms where the
# Python distribution does not come with an XML parser (such as Mac OS X 10.2 and some
# versions of FreeBSD), feedparser will quietly fall back on regex-based parsing.
try:
    import xml.sax
    xml.sax.make_parser(PREFERRED_XML_PARSERS)  # test for valid parsers
    from xml.sax.saxutils import escape as _xmlescape
    _XML_AVAILABLE = 1
except:
    _XML_AVAILABLE = 0

    def _xmlescape(data, entities={}):
        data = data.replace('&', '&amp;')
        data = data.replace('>', '&gt;')
        data = data.replace('<', '&lt;')
        for char, entity in entities:
            data = data.replace(char, entity)
        return data

# cjkcodecs and iconv_codec provide support for more character encodings.
# Both are available from http://cjkpython.i18n.org/
try:
    import cjkcodecs.aliases
except:
    pass
try:
    import iconv_codec
except:
    pass

# chardet library auto-detects character encodings
# Download from http://chardet.feedparser.org/
try:
    import chardet
    if _debug:
        import chardet.constants
        chardet.constants._debug = 1
except:
    chardet = None

# reversable htmlentitydefs mappings for Python 2.2
try:
    from htmlentitydefs import name2codepoint, codepoint2name
except:
    import htmlentitydefs
    name2codepoint = {}
    codepoint2name = {}
    for (name, codepoint) in htmlentitydefs.entitydefs.iteritems():
        if codepoint.startswith('&#'):
            codepoint = unichr(int(codepoint[2:-1]))
        name2codepoint[name] = ord(codepoint)
        codepoint2name[ord(codepoint)] = name

# BeautifulSoup parser used for parsing microformats from embedded HTML content
# http://www.crummy.com/software/BeautifulSoup/
# feedparser is tested with BeautifulSoup 3.0.x, but it might work with the
# older 2.x series.  If it doesn't, and you can figure out why, I'll accept a
# patch and modify the compatibility statement accordingly.
try:
    import BeautifulSoup
except:
    BeautifulSoup = None

# ---------- don't touch these ----------


class ThingsNobodyCaresAboutButMe(Exception):
    pass


class CharacterEncodingOverride(ThingsNobodyCaresAboutButMe):
    pass


class CharacterEncodingUnknown(ThingsNobodyCaresAboutButMe):
    pass


class NonXMLContentType(ThingsNobodyCaresAboutButMe):
    pass


class UndeclaredNamespace(Exception):
    pass

sgmllib.tagfind = re.compile('[a-zA-Z][-_.:a-zA-Z0-9]*')
sgmllib.special = re.compile('<!')
sgmllib.charref = re.compile('&#(\d+|[xX][0-9a-fA-F]+);')

if sgmllib.endbracket.search(' <').start(0):
    class EndBracketRegEx:

        def __init__(self):
            # Overriding the built-in sgmllib.endbracket regex allows the
            # parser to find angle brackets embedded in element attributes.
            self.endbracket = re.compile('''([^'"<>]|"[^"]*"(?=>|/|\s|\w+=)|'[^']*'(?=>|/|\s|\w+=))*(?=[<>])|.*?(?=[<>])''')

        def search(self, string, index=0):
            match = self.endbracket.match(string, index)
            if match is not None:
                # Returning a new object in the calling thread's context
                # resolves a thread-safety.
                return EndBracketMatch(match)
            return None

    class EndBracketMatch:

        def __init__(self, match):
            self.match = match

        def start(self, n):
            return self.match.end(n)
    sgmllib.endbracket = EndBracketRegEx()

SUPPORTED_VERSIONS = {'': 'unknown',
                      'rss090': 'RSS 0.90',
                      'rss091n': 'RSS 0.91 (Netscape)',
                      'rss091u': 'RSS 0.91 (Userland)',
                      'rss092': 'RSS 0.92',
                      'rss093': 'RSS 0.93',
                      'rss094': 'RSS 0.94',
                      'rss20': 'RSS 2.0',
                      'rss10': 'RSS 1.0',
                      'rss': 'RSS (unknown version)',
                      'atom01': 'Atom 0.1',
                      'atom02': 'Atom 0.2',
                      'atom03': 'Atom 0.3',
                      'atom10': 'Atom 1.0',
                      'atom': 'Atom (unknown version)',
                      'cdf': 'CDF',
                      'hotrss': 'Hot RSS'
                      }

try:
    UserDict = dict
except NameError:
    # Python 2.1 does not have dict
    from UserDict import UserDict

    def dict(aList):
        rc = {}
        for k, v in aList:
            rc[k] = v
        return rc


class FeedParserDict(UserDict):
    keymap = {'channel': 'feed',
              'items': 'entries',
              'guid': 'id',
              'date': 'updated',
              'date_parsed': 'updated_parsed',
              'description': ['summary', 'subtitle'],
              'url': ['href'],
              'modified': 'updated',
              'modified_parsed': 'updated_parsed',
              'issued': 'published',
              'issued_parsed': 'published_parsed',
              'copyright': 'rights',
              'copyright_detail': 'rights_detail',
              'tagline': 'subtitle',
              'tagline_detail': 'subtitle_detail'}

    def __getitem__(self, key):
        if key == 'category':
            return UserDict.__getitem__(self, 'tags')[0]['term']
        if key == 'enclosures':
            norel = lambda link: FeedParserDict([(name, value) for (name, value) in link.items() if name != 'rel'])
            return [norel(link) for link in UserDict.__getitem__(self, 'links') if link['rel'] == 'enclosure']
        if key == 'license':
            for link in UserDict.__getitem__(self, 'links'):
                if link['rel'] == 'license' and 'href' in link:
                    return link['href']
        if key == 'categories':
            return [(tag['scheme'], tag['term']) for tag in UserDict.__getitem__(self, 'tags')]
        realkey = self.keymap.get(key, key)
        if isinstance(realkey, list):
            for k in realkey:
                if UserDict.__contains__(self, k):
                    return UserDict.__getitem__(self, k)
        if UserDict.__contains__(self, key):
            return UserDict.__getitem__(self, key)
        return UserDict.__getitem__(self, realkey)

    def __setitem__(self, key, value):
        for k in self.keymap.keys():
            if key == k:
                key = self.keymap[k]
                if isinstance(key, list):
                    key = key[0]
        return UserDict.__setitem__(self, key, value)

    def get(self, key, default=None):
        if key in self:
            return self[key]
        else:
            return default

    def setdefault(self, key, value):
        if key not in self:
            self[key] = value
        return self[key]

    def has_key(self, key):
        try:
            return hasattr(self, key) or UserDict.__contains__(self, key)
        except AttributeError:
            return False
    # This alias prevents the 2to3 tool from changing the semantics of the
    # __contains__ function below and exhausting the maximum recursion depth
    __has_key = has_key

    def __getattr__(self, key):
        try:
            return self.__dict__[key]
        except KeyError:
            pass
        try:
            assert not key.startswith('_')
            return self.__getitem__(key)
        except:
            raise AttributeError("object has no attribute '%s'" % key)

    def __setattr__(self, key, value):
        if key.startswith('_') or key == 'data':
            self.__dict__[key] = value
        else:
            return self.__setitem__(key, value)

    def __contains__(self, key):
        return self.__has_key(key)


def zopeCompatibilityHack():
    global FeedParserDict
    del FeedParserDict

    def FeedParserDict(aDict=None):
        rc = {}
        if aDict:
            rc.update(aDict)
        return rc

_ebcdic_to_ascii_map = None


def _ebcdic_to_ascii(s):
    global _ebcdic_to_ascii_map
    if not _ebcdic_to_ascii_map:
        emap = (
            0, 1, 2, 3, 156, 9, 134, 127, 151, 141, 142, 11, 12, 13, 14, 15,
            16, 17, 18, 19, 157, 133, 8, 135, 24, 25, 146, 143, 28, 29, 30, 31,
            128, 129, 130, 131, 132, 10, 23, 27, 136, 137, 138, 139, 140, 5, 6, 7,
            144, 145, 22, 147, 148, 149, 150, 4, 152, 153, 154, 155, 20, 21, 158, 26,
            32, 160, 161, 162, 163, 164, 165, 166, 167, 168, 91, 46, 60, 40, 43, 33,
            38, 169, 170, 171, 172, 173, 174, 175, 176, 177, 93, 36, 42, 41, 59, 94,
            45, 47, 178, 179, 180, 181, 182, 183, 184, 185, 124, 44, 37, 95, 62, 63,
            186, 187, 188, 189, 190, 191, 192, 193, 194, 96, 58, 35, 64, 39, 61, 34,
            195, 97, 98, 99, 100, 101, 102, 103, 104, 105, 196, 197, 198, 199, 200, 201,
            202, 106, 107, 108, 109, 110, 111, 112, 113, 114, 203, 204, 205, 206, 207, 208,
            209, 126, 115, 116, 117, 118, 119, 120, 121, 122, 210, 211, 212, 213, 214, 215,
            216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,
            123, 65, 66, 67, 68, 69, 70, 71, 72, 73, 232, 233, 234, 235, 236, 237,
            125, 74, 75, 76, 77, 78, 79, 80, 81, 82, 238, 239, 240, 241, 242, 243,
            92, 159, 83, 84, 85, 86, 87, 88, 89, 90, 244, 245, 246, 247, 248, 249,
            48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 250, 251, 252, 253, 254, 255
            )
        _ebcdic_to_ascii_map = _maketrans(
            _l2bytes(range(256)), _l2bytes(emap))
    return s.translate(_ebcdic_to_ascii_map)

_cp1252 = {
  unichr(128): unichr(8364),  # euro sign
  unichr(130): unichr(8218),  # single low-9 quotation mark
  unichr(131): unichr(402),  # latin small letter f with hook
  unichr(132): unichr(8222),  # double low-9 quotation mark
  unichr(133): unichr(8230),  # horizontal ellipsis
  unichr(134): unichr(8224),  # dagger
  unichr(135): unichr(8225),  # double dagger
  unichr(136): unichr(710),  # modifier letter circumflex accent
  unichr(137): unichr(8240),  # per mille sign
  unichr(138): unichr(352),  # latin capital letter s with caron
  unichr(139): unichr(8249),  # single left-pointing angle quotation mark
  unichr(140): unichr(338),  # latin capital ligature oe
  unichr(142): unichr(381),  # latin capital letter z with caron
  unichr(145): unichr(8216),  # left single quotation mark
  unichr(146): unichr(8217),  # right single quotation mark
  unichr(147): unichr(8220),  # left double quotation mark
  unichr(148): unichr(8221),  # right double quotation mark
  unichr(149): unichr(8226),  # bullet
  unichr(150): unichr(8211),  # en dash
  unichr(151): unichr(8212),  # em dash
  unichr(152): unichr(732),  # small tilde
  unichr(153): unichr(8482),  # trade mark sign
  unichr(154): unichr(353),  # latin small letter s with caron
  unichr(155): unichr(8250),  # single right-pointing angle quotation mark
  unichr(156): unichr(339),  # latin small ligature oe
  unichr(158): unichr(382),  # latin small letter z with caron
  unichr(159): unichr(376)}  # latin capital letter y with diaeresis

_urifixer = re.compile('^([A-Za-z][A-Za-z0-9+-.]*://)(/*)(.*?)')


def _urljoin(base, uri):
    uri = _urifixer.sub(r'\1\3', uri)
    try:
        return urlparse.urljoin(base, uri)
    except:
        uri = urlparse.urlunparse([urllib.quote(part) for part in urlparse.urlparse(uri)])
        return urlparse.urljoin(base, uri)


class _FeedParserMixin:
    namespaces = {'': '',
                  'http://backend.userland.com/rss': '',
                  'http://blogs.law.harvard.edu/tech/rss': '',
                  'http://purl.org/rss/1.0/': '',
                  'http://my.netscape.com/rdf/simple/0.9/': '',
                  'http://example.com/newformat#': '',
                  'http://example.com/necho': '',
                  'http://purl.org/echo/': '',
                  'uri/of/echo/namespace#': '',
                  'http://purl.org/pie/': '',
                  'http://purl.org/atom/ns#': '',
                  'http://www.w3.org/2005/Atom': '',
                  'http://purl.org/rss/1.0/modules/rss091#': '',

                  'http://webns.net/mvcb/': 'admin',
                  'http://purl.org/rss/1.0/modules/aggregation/': 'ag',
                  'http://purl.org/rss/1.0/modules/annotate/': 'annotate',
                  'http://media.tangent.org/rss/1.0/': 'audio',
                  'http://backend.userland.com/blogChannelModule': 'blogChannel',
                  'http://web.resource.org/cc/': 'cc',
                  'http://backend.userland.com/creativeCommonsRssModule': 'creativeCommons',
                  'http://purl.org/rss/1.0/modules/company': 'co',
                  'http://purl.org/rss/1.0/modules/content/': 'content',
                  'http://my.theinfo.org/changed/1.0/rss/': 'cp',
                  'http://purl.org/dc/elements/1.1/': 'dc',
                  'http://purl.org/dc/terms/': 'dcterms',
                  'http://purl.org/rss/1.0/modules/email/': 'email',
                  'http://purl.org/rss/1.0/modules/event/': 'ev',
                  'http://rssnamespace.org/feedburner/ext/1.0': 'feedburner',
                  'http://freshmeat.net/rss/fm/': 'fm',
                  'http://xmlns.com/foaf/0.1/': 'foaf',
                  'http://www.w3.org/2003/01/geo/wgs84_pos#': 'geo',
                  'http://postneo.com/icbm/': 'icbm',
                  'http://purl.org/rss/1.0/modules/image/': 'image',
                  'http://www.itunes.com/DTDs/PodCast-1.0.dtd': 'itunes',
                  'http://example.com/DTDs/PodCast-1.0.dtd': 'itunes',
                  'http://purl.org/rss/1.0/modules/link/': 'l',
                  'http://search.yahoo.com/mrss': 'media',
                  # Version 1.1.2 of the Media RSS spec added the trailing slash on the namespace
                  'http://search.yahoo.com/mrss/': 'media',
                  'http://madskills.com/public/xml/rss/module/pingback/': 'pingback',
                  'http://prismstandard.org/namespaces/1.2/basic/': 'prism',
                  'http://www.w3.org/1999/02/22-rdf-syntax-ns#': 'rdf',
                  'http://www.w3.org/2000/01/rdf-schema#': 'rdfs',
                  'http://purl.org/rss/1.0/modules/reference/': 'ref',
                  'http://purl.org/rss/1.0/modules/richequiv/': 'reqv',
                  'http://purl.org/rss/1.0/modules/search/': 'search',
                  'http://purl.org/rss/1.0/modules/slash/': 'slash',
                  'http://schemas.xmlsoap.org/soap/envelope/': 'soap',
                  'http://purl.org/rss/1.0/modules/servicestatus/': 'ss',
                  'http://hacks.benhammersley.com/rss/streaming/': 'str',
                  'http://purl.org/rss/1.0/modules/subscription/': 'sub',
                  'http://purl.org/rss/1.0/modules/syndication/': 'sy',
                  'http://schemas.pocketsoap.com/rss/myDescModule/': 'szf',
                  'http://purl.org/rss/1.0/modules/taxonomy/': 'taxo',
                  'http://purl.org/rss/1.0/modules/threading/': 'thr',
                  'http://purl.org/rss/1.0/modules/textinput/': 'ti',
                  'http://madskills.com/public/xml/rss/module/trackback/': 'trackback',
                  'http://wellformedweb.org/commentAPI/': 'wfw',
                  'http://purl.org/rss/1.0/modules/wiki/': 'wiki',
                  'http://www.w3.org/1999/xhtml': 'xhtml',
                  'http://www.w3.org/1999/xlink': 'xlink',
                  'http://www.w3.org/XML/1998/namespace': 'xml'
}
    _matchnamespaces = {}

    can_be_relative_uri = ['link', 'id', 'wfw_comment', 'wfw_commentrss', 'docs', 'url', 'href', 'comments', 'icon', 'logo']
    can_contain_relative_uris = ['content', 'title', 'summary', 'info', 'tagline', 'subtitle', 'copyright', 'rights', 'description']
    can_contain_dangerous_markup = ['content', 'title', 'summary', 'info', 'tagline', 'subtitle', 'copyright', 'rights', 'description']
    html_types = ['text/html', 'application/xhtml+xml']

    def __init__(self, baseuri=None, baselang=None, encoding='utf-8'):
        if _debug:
            sys.stderr.write('initializing FeedParser\n')
        if not self._matchnamespaces:
            for k, v in self.namespaces.items():
                self._matchnamespaces[k.lower()] = v
        self.feeddata = FeedParserDict()  # feed-level data
        self.encoding = encoding  # character encoding
        self.entries = []  # list of entry-level data
        self.version = ''  # feed type/version, see SUPPORTED_VERSIONS
        self.namespacesInUse = {}  # dictionary of namespaces defined by the feed

        # the following are used internally to track state;
        # this is really out of control and should be refactored
        self.infeed = 0
        self.inentry = 0
        self.incontent = 0
        self.intextinput = 0
        self.inimage = 0
        self.inauthor = 0
        self.incontributor = 0
        self.inpublisher = 0
        self.insource = 0
        self.sourcedata = FeedParserDict()
        self.contentparams = FeedParserDict()
        self._summaryKey = None
        self.namespacemap = {}
        self.elementstack = []
        self.basestack = []
        self.langstack = []
        self.baseuri = baseuri or ''
        self.lang = baselang or None
        self.svgOK = 0
        self.hasTitle = 0
        if baselang:
            self.feeddata['language'] = baselang.replace('_', '-')

    def unknown_starttag(self, tag, attrs):
        if _debug:
            sys.stderr.write('start %s with %s\n' % (tag, attrs))
        # normalize attrs
        attrs = [(k.lower(), v) for k, v in attrs]
        attrs = [(k, k in ('rel', 'type') and v.lower() or v) for k, v in attrs]
        # the sgml parser doesn't handle entities in attributes, but
        # strict xml parsers do -- account for this difference
        if isinstance(self, _LooseFeedParser):
            attrs = [(k, v.replace('&amp;', '&')) for k, v in attrs]

        # track xml:base and xml:lang
        attrsD = dict(attrs)
        baseuri = attrsD.get('xml:base', attrsD.get('base')) or self.baseuri
        if not isinstance(baseuri, type(u'')):
            try:
                baseuri = unicode(baseuri, self.encoding)
            except:
                baseuri = unicode(baseuri, 'iso-8859-1')
        # ensure that self.baseuri is always an absolute URI that
        # uses a whitelisted URI scheme (e.g. not `javscript:`)
        if self.baseuri:
            self.baseuri = _makeSafeAbsoluteURI(self.baseuri, baseuri) or self.baseuri
        else:
            self.baseuri = _urljoin(self.baseuri, baseuri)
        lang = attrsD.get('xml:lang', attrsD.get('lang'))
        if lang == '':
            # xml:lang could be explicitly set to '', we need to capture that
            lang = None
        elif lang is None:
            # if no xml:lang is specified, use parent lang
            lang = self.lang
        if lang:
            if tag in ('feed', 'rss', 'rdf:RDF'):
                self.feeddata['language'] = lang.replace('_', '-')
        self.lang = lang
        self.basestack.append(self.baseuri)
        self.langstack.append(lang)

        # track namespaces
        for prefix, uri in attrs:
            if prefix.startswith('xmlns:'):
                self.trackNamespace(prefix[6:], uri)
            elif prefix == 'xmlns':
                self.trackNamespace(None, uri)

        # track inline content
        if self.incontent and 'type' in self.contentparams and not self.contentparams.get('type', 'xml').endswith('xml'):
            if tag in ['xhtml:div', 'div']:
                return  # typepad does this 10/2007
            # element declared itself as escaped markup, but it isn't really
            self.contentparams['type'] = 'application/xhtml+xml'
        if self.incontent and self.contentparams.get('type') == 'application/xhtml+xml':
            if tag.find(':') != -1:
                prefix, tag = tag.split(':', 1)
                namespace = self.namespacesInUse.get(prefix, '')
                if tag == 'math' and namespace == 'http://www.w3.org/1998/Math/MathML':
                    attrs.append(('xmlns', namespace))
                if tag == 'svg' and namespace == 'http://www.w3.org/2000/svg':
                    attrs.append(('xmlns', namespace))
            if tag == 'svg':
                self.svgOK += 1
            return self.handle_data('<%s%s>' % (tag, self.strattrs(attrs)), escape=0)

        # match namespaces
        if tag.find(':') != -1:
            prefix, suffix = tag.split(':', 1)
        else:
            prefix, suffix = '', tag
        prefix = self.namespacemap.get(prefix, prefix)
        if prefix:
            prefix = prefix + '_'

        # special hack for better tracking of empty textinput/image elements in illformed feeds
        if (not prefix) and tag not in ('title', 'link', 'description', 'name'):
            self.intextinput = 0
        if (not prefix) and tag not in ('title', 'link', 'description', 'url', 'href', 'width', 'height'):
            self.inimage = 0

        # call special handler (if defined) or default handler
        methodname = '_start_' + prefix + suffix
        try:
            method = getattr(self, methodname)
            return method(attrsD)
        except AttributeError:
            # Since there's no handler or something has gone wrong we explicitly add the element and its attributes
            unknown_tag = prefix + suffix
            if len(attrsD) == 0:
                # No attributes so merge it into the encosing dictionary
                return self.push(unknown_tag, 1)
            else:
                # Has attributes so create it in its own dictionary
                context = self._getContext()
                context[unknown_tag] = attrsD

    def unknown_endtag(self, tag):
        if _debug:
            sys.stderr.write('end %s\n' % tag)
        # match namespaces
        if tag.find(':') != -1:
            prefix, suffix = tag.split(':', 1)
        else:
            prefix, suffix = '', tag
        prefix = self.namespacemap.get(prefix, prefix)
        if prefix:
            prefix = prefix + '_'
        if suffix == 'svg' and self.svgOK:
            self.svgOK -= 1

        # call special handler (if defined) or default handler
        methodname = '_end_' + prefix + suffix
        try:
            if self.svgOK:
                raise AttributeError()
            method = getattr(self, methodname)
            method()
        except AttributeError:
            self.pop(prefix + suffix)

        # track inline content
        if self.incontent and 'type' in self.contentparams and not self.contentparams.get('type', 'xml').endswith('xml'):
            # element declared itself as escaped markup, but it isn't really
            if tag in ['xhtml:div', 'div']:
                return  # typepad does this 10/2007
            self.contentparams['type'] = 'application/xhtml+xml'
        if self.incontent and self.contentparams.get('type') == 'application/xhtml+xml':
            tag = tag.split(':')[-1]
            self.handle_data('</%s>' % tag, escape=0)

        # track xml:base and xml:lang going out of scope
        if self.basestack:
            self.basestack.pop()
            if self.basestack and self.basestack[-1]:
                self.baseuri = self.basestack[-1]
        if self.langstack:
            self.langstack.pop()
            if self.langstack:  # and (self.langstack[-1] is not None):
                self.lang = self.langstack[-1]

    def handle_charref(self, ref):
        # called for each character reference, e.g. for '&#160;', ref will be '160'
        if not self.elementstack:
            return
        ref = ref.lower()
        if ref in ('34', '38', '39', '60', '62', 'x22', 'x26', 'x27', 'x3c', 'x3e'):
            text = '&#%s;' % ref
        else:
            if ref[0] == 'x':
                c = int(ref[1:], 16)
            else:
                c = int(ref)
            text = unichr(c).encode('utf-8')
        self.elementstack[-1][2].append(text)

    def handle_entityref(self, ref):
        # called for each entity reference, e.g. for '&copy;', ref will be 'copy'
        if not self.elementstack:
            return
        if _debug:
            sys.stderr.write('entering handle_entityref with %s\n' % ref)
        if ref in ('lt', 'gt', 'quot', 'amp', 'apos'):
            text = '&%s;' % ref
        elif ref in self.entities.keys():
            text = self.entities[ref]
            if text.startswith('&#') and text.endswith(';'):
                return self.handle_entityref(text)
        else:
            try:
                name2codepoint[ref]
            except KeyError:
                text = '&%s;' % ref
            else:
                text = unichr(name2codepoint[ref]).encode('utf-8')
        self.elementstack[-1][2].append(text)

    def handle_data(self, text, escape=1):
        # called for each block of plain text, i.e. outside of any tag and
        # not containing any character or entity references
        if not self.elementstack:
            return
        if escape and self.contentparams.get('type') == 'application/xhtml+xml':
            text = _xmlescape(text)
        self.elementstack[-1][2].append(text)

    def handle_comment(self, text):
        # called for each comment, e.g. <!-- insert message here -->
        pass

    def handle_pi(self, text):
        # called for each processing instruction, e.g. <?instruction>
        pass

    def handle_decl(self, text):
        pass

    def parse_declaration(self, i):
        # override internal declaration handler to handle CDATA blocks
        if _debug:
            sys.stderr.write('entering parse_declaration\n')
        if self.rawdata[i:i + 9] == '<![CDATA[':
            k = self.rawdata.find(']]>', i)
            if k == -1:
                # CDATA block began but didn't finish
                k = len(self.rawdata)
                return k
            self.handle_data(_xmlescape(self.rawdata[i + 9:k]), 0)
            return k + 3
        else:
            k = self.rawdata.find('>', i)
            if k >= 0:
                return k + 1
            else:
                # We have an incomplete CDATA block.
                return k

    def mapContentType(self, contentType):
        contentType = contentType.lower()
        if contentType == 'text' or contentType == 'plain':
            contentType = 'text/plain'
        elif contentType == 'html':
            contentType = 'text/html'
        elif contentType == 'xhtml':
            contentType = 'application/xhtml+xml'
        return contentType

    def trackNamespace(self, prefix, uri):
        loweruri = uri.lower()
        if (prefix, loweruri) == (None, 'http://my.netscape.com/rdf/simple/0.9/') and not self.version:
            self.version = 'rss090'
        if loweruri == 'http://purl.org/rss/1.0/' and not self.version:
            self.version = 'rss10'
        if loweruri == 'http://www.w3.org/2005/atom' and not self.version:
            self.version = 'atom10'
        if loweruri.find('backend.userland.com/rss') != -1:
            # match any backend.userland.com namespace
            uri = 'http://backend.userland.com/rss'
            loweruri = uri
        if loweruri in self._matchnamespaces:
            self.namespacemap[prefix] = self._matchnamespaces[loweruri]
            self.namespacesInUse[self._matchnamespaces[loweruri]] = uri
        else:
            self.namespacesInUse[prefix or ''] = uri

    def resolveURI(self, uri):
        return _urljoin(self.baseuri or '', uri)

    def decodeEntities(self, element, data):
        return data

    def strattrs(self, attrs):
        return ''.join([' %s="%s"' % (t[0], _xmlescape(t[1], {'"': '&quot;'})) for t in attrs])

    def push(self, element, expectingText):
        self.elementstack.append([element, expectingText, []])

    def pop(self, element, stripWhitespace=1):
        if not self.elementstack:
            return
        if self.elementstack[-1][0] != element:
            return

        element, expectingText, pieces = self.elementstack.pop()

        if self.version == 'atom10' and self.contentparams.get('type', 'text') == 'application/xhtml+xml':
            # remove enclosing child element, but only if it is a <div> and
            # only if all the remaining content is nested underneath it.
            # This means that the divs would be retained in the following:
            #    <div>foo</div><div>bar</div>
            while pieces and len(pieces) > 1 and not pieces[-1].strip():
                del pieces[-1]
            while pieces and len(pieces) > 1 and not pieces[0].strip():
                del pieces[0]
            if pieces and (pieces[0] == '<div>' or pieces[0].startswith('<div ')) and pieces[-1] == '</div>':
                depth = 0
                for piece in pieces[:-1]:
                    if piece.startswith('</'):
                        depth -= 1
                        if depth == 0:
                            break
                    elif piece.startswith('<') and not piece.endswith('/>'):
                        depth += 1
                else:
                    pieces = pieces[1:-1]

        # Ensure each piece is a str for Python 3
        for (i, v) in enumerate(pieces):
            if not isinstance(v, basestring):
                pieces[i] = v.decode('utf-8')

        output = ''.join(pieces)
        if stripWhitespace:
            output = output.strip()
        if not expectingText:
            return output

        # decode base64 content
        if base64 and self.contentparams.get('base64', 0):
            try:
                output = _base64decode(output)
            except binascii.Error:
                pass
            except binascii.Incomplete:
                pass
            except TypeError:
                # In Python 3, base64 takes and outputs bytes, not str
                # This may not be the most correct way to accomplish this
                output = _base64decode(output.encode('utf-8')).decode('utf-8')

        # resolve relative URIs
        if (element in self.can_be_relative_uri) and output:
            output = self.resolveURI(output)

        # decode entities within embedded markup
        if not self.contentparams.get('base64', 0):
            output = self.decodeEntities(element, output)

        if self.lookslikehtml(output):
            self.contentparams['type'] = 'text/html'

        # remove temporary cruft from contentparams
        try:
            del self.contentparams['mode']
        except KeyError:
            pass
        try:
            del self.contentparams['base64']
        except KeyError:
            pass

        is_htmlish = self.mapContentType(self.contentparams.get('type', 'text/html')) in self.html_types
        # resolve relative URIs within embedded markup
        if is_htmlish and RESOLVE_RELATIVE_URIS:
            if element in self.can_contain_relative_uris:
                output = _resolveRelativeURIs(output, self.baseuri, self.encoding, self.contentparams.get('type', 'text/html'))

        # parse microformats
        # (must do this before sanitizing because some microformats
        # rely on elements that we sanitize)
        if is_htmlish and element in ['content', 'description', 'summary']:
            mfresults = _parseMicroformats(output, self.baseuri, self.encoding)
            if mfresults:
                for tag in mfresults.get('tags', []):
                    self._addTag(tag['term'], tag['scheme'], tag['label'])
                for enclosure in mfresults.get('enclosures', []):
                    self._start_enclosure(enclosure)
                for xfn in mfresults.get('xfn', []):
                    self._addXFN(xfn['relationships'], xfn['href'], xfn['name'])
                vcard = mfresults.get('vcard')
                if vcard:
                    self._getContext()['vcard'] = vcard

        # sanitize embedded markup
        if is_htmlish and SANITIZE_HTML:
            if element in self.can_contain_dangerous_markup:
                output = _sanitizeHTML(output, self.encoding, self.contentparams.get('type', 'text/html'))

        if self.encoding and not isinstance(output, type(u'')):
            try:
                output = unicode(output, self.encoding)
            except:
                pass

        # address common error where people take data that is already
        # utf-8, presume that it is iso-8859-1, and re-encode it.
        if self.encoding in ('utf-8', 'utf-8_INVALID_PYTHON_3') and isinstance(output, type(u'')):
            try:
                output = unicode(output.encode('iso-8859-1'), 'utf-8')
            except:
                pass

        # map win-1252 extensions to the proper code points
        if isinstance(output, type(u'')):
            output = u''.join([c in _cp1252.keys() and _cp1252[c] or c for c in output])

        # categories/tags/keywords/whatever are handled in _end_category
        if element == 'category':
            return output

        if element == 'title' and self.hasTitle:
            return output

        # store output in appropriate place(s)
        if self.inentry and not self.insource:
            if element == 'content':
                self.entries[-1].setdefault(element, [])
                contentparams = copy.deepcopy(self.contentparams)
                contentparams['value'] = output
                self.entries[-1][element].append(contentparams)
            elif element == 'link':
                if not self.inimage:
                    # query variables in urls in link elements are improperly
                    # converted from `?a=1&b=2` to `?a=1&b;=2` as if they're
                    # unhandled character references. fix this special case.
                    output = re.sub("&([A-Za-z0-9_]+);", "&\g<1>", output)
                    self.entries[-1][element] = output
                    if output:
                        self.entries[-1]['links'][-1]['href'] = output
            else:
                if element == 'description':
                    element = 'summary'
                self.entries[-1][element] = output
                if self.incontent:
                    contentparams = copy.deepcopy(self.contentparams)
                    contentparams['value'] = output
                    self.entries[-1][element + '_detail'] = contentparams
        elif (self.infeed or self.insource):  # and (not self.intextinput) and (not self.inimage):
            context = self._getContext()
            if element == 'description':
                element = 'subtitle'
            context[element] = output
            if element == 'link':
                # fix query variables; see above for the explanation
                output = re.sub("&([A-Za-z0-9_]+);", "&\g<1>", output)
                context[element] = output
                context['links'][-1]['href'] = output
            elif self.incontent:
                contentparams = copy.deepcopy(self.contentparams)
                contentparams['value'] = output
                context[element + '_detail'] = contentparams
        return output

    def pushContent(self, tag, attrsD, defaultContentType, expectingText):
        self.incontent += 1
        if self.lang:
            self.lang = self.lang.replace('_', '-')
        self.contentparams = FeedParserDict({
            'type': self.mapContentType(attrsD.get('type', defaultContentType)),
            'language': self.lang,
            'base': self.baseuri})
        self.contentparams['base64'] = self._isBase64(attrsD, self.contentparams)
        self.push(tag, expectingText)

    def popContent(self, tag):
        value = self.pop(tag)
        self.incontent -= 1
        self.contentparams.clear()
        return value

    # a number of elements in a number of RSS variants are nominally plain
    # text, but this is routinely ignored.  This is an attempt to detect
    # the most common cases.  As false positives often result in silent
    # data loss, this function errs on the conservative side.
    def lookslikehtml(self, s):
        if self.version.startswith('atom'):
            return
        if self.contentparams.get('type', 'text/html') != 'text/plain':
            return

        # must have a close tag or a entity reference to qualify
        if not (re.search(r'</(\w+)>', s) or re.search("&#?\w+;", s)):
            return

        # all tags must be in a restricted subset of valid HTML tags
        if filter(lambda t: t.lower() not in _HTMLSanitizer.acceptable_elements,
            re.findall(r'</?(\w+)', s)): return

        # all entities must have been defined as valid HTML entities
        from htmlentitydefs import entitydefs
        if filter(lambda e: e not in entitydefs.keys(),
            re.findall(r'&(\w+);', s)): return

        return 1

    def _mapToStandardPrefix(self, name):
        colonpos = name.find(':')
        if colonpos != -1:
            prefix = name[:colonpos]
            suffix = name[colonpos + 1:]
            prefix = self.namespacemap.get(prefix, prefix)
            name = prefix + ':' + suffix
        return name

    def _getAttribute(self, attrsD, name):
        return attrsD.get(self._mapToStandardPrefix(name))

    def _isBase64(self, attrsD, contentparams):
        if attrsD.get('mode', '') == 'base64':
            return 1
        if self.contentparams['type'].startswith('text/'):
            return 0
        if self.contentparams['type'].endswith('+xml'):
            return 0
        if self.contentparams['type'].endswith('/xml'):
            return 0
        return 1

    def _itsAnHrefDamnIt(self, attrsD):
        href = attrsD.get('url', attrsD.get('uri', attrsD.get('href', None)))
        if href:
            try:
                del attrsD['url']
            except KeyError:
                pass
            try:
                del attrsD['uri']
            except KeyError:
                pass
            attrsD['href'] = href
        return attrsD

    def _save(self, key, value, overwrite=False):
        context = self._getContext()
        if overwrite:
            context[key] = value
        else:
            context.setdefault(key, value)

    def _start_rss(self, attrsD):
        versionmap = {'0.91': 'rss091u',
                      '0.92': 'rss092',
                      '0.93': 'rss093',
                      '0.94': 'rss094'}
        # If we're here then this is an RSS feed.
        # If we don't have a version or have a version that starts with something
        # other than RSS then there's been a mistake. Correct it.
        if not self.version or not self.version.startswith('rss'):
            attr_version = attrsD.get('version', '')
            version = versionmap.get(attr_version)
            if version:
                self.version = version
            elif attr_version.startswith('2.'):
                self.version = 'rss20'
            else:
                self.version = 'rss'

    def _start_dlhottitles(self, attrsD):
        self.version = 'hotrss'

    def _start_channel(self, attrsD):
        self.infeed = 1
        self._cdf_common(attrsD)
    _start_feedinfo = _start_channel

    def _cdf_common(self, attrsD):
        if 'lastmod' in attrsD:
            self._start_modified({})
            self.elementstack[-1][-1] = attrsD['lastmod']
            self._end_modified()
        if 'href' in attrsD:
            self._start_link({})
            self.elementstack[-1][-1] = attrsD['href']
            self._end_link()

    def _start_feed(self, attrsD):
        self.infeed = 1
        versionmap = {'0.1': 'atom01',
                      '0.2': 'atom02',
                      '0.3': 'atom03'}
        if not self.version:
            attr_version = attrsD.get('version')
            version = versionmap.get(attr_version)
            if version:
                self.version = version
            else:
                self.version = 'atom'

    def _end_channel(self):
        self.infeed = 0
    _end_feed = _end_channel

    def _start_image(self, attrsD):
        context = self._getContext()
        if not self.inentry:
            context.setdefault('image', FeedParserDict())
        self.inimage = 1
        self.hasTitle = 0
        self.push('image', 0)

    def _end_image(self):
        self.pop('image')
        self.inimage = 0

    def _start_textinput(self, attrsD):
        context = self._getContext()
        context.setdefault('textinput', FeedParserDict())
        self.intextinput = 1
        self.hasTitle = 0
        self.push('textinput', 0)
    _start_textInput = _start_textinput

    def _end_textinput(self):
        self.pop('textinput')
        self.intextinput = 0
    _end_textInput = _end_textinput

    def _start_author(self, attrsD):
        self.inauthor = 1
        self.push('author', 1)
        # Append a new FeedParserDict when expecting an author
        context = self._getContext()
        context.setdefault('authors', [])
        context['authors'].append(FeedParserDict())
    _start_managingeditor = _start_author
    _start_dc_author = _start_author
    _start_dc_creator = _start_author
    _start_itunes_author = _start_author

    def _end_author(self):
        self.pop('author')
        self.inauthor = 0
        self._sync_author_detail()
    _end_managingeditor = _end_author
    _end_dc_author = _end_author
    _end_dc_creator = _end_author
    _end_itunes_author = _end_author

    def _start_itunes_owner(self, attrsD):
        self.inpublisher = 1
        self.push('publisher', 0)

    def _end_itunes_owner(self):
        self.pop('publisher')
        self.inpublisher = 0
        self._sync_author_detail('publisher')

    def _start_contributor(self, attrsD):
        self.incontributor = 1
        context = self._getContext()
        context.setdefault('contributors', [])
        context['contributors'].append(FeedParserDict())
        self.push('contributor', 0)

    def _end_contributor(self):
        self.pop('contributor')
        self.incontributor = 0

    def _start_dc_contributor(self, attrsD):
        self.incontributor = 1
        context = self._getContext()
        context.setdefault('contributors', [])
        context['contributors'].append(FeedParserDict())
        self.push('name', 0)

    def _end_dc_contributor(self):
        self._end_name()
        self.incontributor = 0

    def _start_name(self, attrsD):
        self.push('name', 0)
    _start_itunes_name = _start_name

    def _end_name(self):
        value = self.pop('name')
        if self.inpublisher:
            self._save_author('name', value, 'publisher')
        elif self.inauthor:
            self._save_author('name', value)
        elif self.incontributor:
            self._save_contributor('name', value)
        elif self.intextinput:
            context = self._getContext()
            context['name'] = value
    _end_itunes_name = _end_name

    def _start_width(self, attrsD):
        self.push('width', 0)

    def _end_width(self):
        value = self.pop('width')
        try:
            value = int(value)
        except:
            value = 0
        if self.inimage:
            context = self._getContext()
            context['width'] = value

    def _start_height(self, attrsD):
        self.push('height', 0)

    def _end_height(self):
        value = self.pop('height')
        try:
            value = int(value)
        except:
            value = 0
        if self.inimage:
            context = self._getContext()
            context['height'] = value

    def _start_url(self, attrsD):
        self.push('href', 1)
    _start_homepage = _start_url
    _start_uri = _start_url

    def _end_url(self):
        value = self.pop('href')
        if self.inauthor:
            self._save_author('href', value)
        elif self.incontributor:
            self._save_contributor('href', value)
    _end_homepage = _end_url
    _end_uri = _end_url

    def _start_email(self, attrsD):
        self.push('email', 0)
    _start_itunes_email = _start_email

    def _end_email(self):
        value = self.pop('email')
        if self.inpublisher:
            self._save_author('email', value, 'publisher')
        elif self.inauthor:
            self._save_author('email', value)
        elif self.incontributor:
            self._save_contributor('email', value)
    _end_itunes_email = _end_email

    def _getContext(self):
        if self.insource:
            context = self.sourcedata
        elif self.inimage and 'image' in self.feeddata:
            context = self.feeddata['image']
        elif self.intextinput:
            context = self.feeddata['textinput']
        elif self.inentry:
            context = self.entries[-1]
        else:
            context = self.feeddata
        return context

    def _save_author(self, key, value, prefix='author'):
        context = self._getContext()
        context.setdefault(prefix + '_detail', FeedParserDict())
        context[prefix + '_detail'][key] = value
        self._sync_author_detail()
        context.setdefault('authors', [FeedParserDict()])
        context['authors'][-1][key] = value

    def _save_contributor(self, key, value):
        context = self._getContext()
        context.setdefault('contributors', [FeedParserDict()])
        context['contributors'][-1][key] = value

    def _sync_author_detail(self, key='author'):
        context = self._getContext()
        detail = context.get('%s_detail' % key)
        if detail:
            name = detail.get('name')
            email = detail.get('email')
            if name and email:
                context[key] = '%s (%s)' % (name, email)
            elif name:
                context[key] = name
            elif email:
                context[key] = email
        else:
            author, email = context.get(key), None
            if not author:
                return
            emailmatch = re.search(r'''(([a-zA-Z0-9\_\-\.\+]+)@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.)|(([a-zA-Z0-9\-]+\.)+))([a-zA-Z]{2,4}|[0-9]{1,3})(\]?))(\?subject=\S+)?''', author)
            if emailmatch:
                email = emailmatch.group(0)
                # probably a better way to do the following, but it passes all the tests
                author = author.replace(email, '')
                author = author.replace('()', '')
                author = author.replace('<>', '')
                author = author.replace('&lt;&gt;', '')
                author = author.strip()
                if author and (author[0] == '('):
                    author = author[1:]
                if author and (author[-1] == ')'):
                    author = author[:-1]
                author = author.strip()
            if author or email:
                context.setdefault('%s_detail' % key, FeedParserDict())
            if author:
                context['%s_detail' % key]['name'] = author
            if email:
                context['%s_detail' % key]['email'] = email

    def _start_subtitle(self, attrsD):
        self.pushContent('subtitle', attrsD, 'text/plain', 1)
    _start_tagline = _start_subtitle
    _start_itunes_subtitle = _start_subtitle

    def _end_subtitle(self):
        self.popContent('subtitle')
    _end_tagline = _end_subtitle
    _end_itunes_subtitle = _end_subtitle

    def _start_rights(self, attrsD):
        self.pushContent('rights', attrsD, 'text/plain', 1)
    _start_dc_rights = _start_rights
    _start_copyright = _start_rights

    def _end_rights(self):
        self.popContent('rights')
    _end_dc_rights = _end_rights
    _end_copyright = _end_rights

    def _start_item(self, attrsD):
        self.entries.append(FeedParserDict())
        self.push('item', 0)
        self.inentry = 1
        self.guidislink = 0
        self.hasTitle = 0
        id = self._getAttribute(attrsD, 'rdf:about')
        if id:
            context = self._getContext()
            context['id'] = id
        self._cdf_common(attrsD)
    _start_entry = _start_item
    _start_product = _start_item

    def _end_item(self):
        self.pop('item')
        self.inentry = 0
    _end_entry = _end_item

    def _start_dc_language(self, attrsD):
        self.push('language', 1)
    _start_language = _start_dc_language

    def _end_dc_language(self):
        self.lang = self.pop('language')
    _end_language = _end_dc_language

    def _start_dc_publisher(self, attrsD):
        self.push('publisher', 1)
    _start_webmaster = _start_dc_publisher

    def _end_dc_publisher(self):
        self.pop('publisher')
        self._sync_author_detail('publisher')
    _end_webmaster = _end_dc_publisher

    def _start_published(self, attrsD):
        self.push('published', 1)
    _start_dcterms_issued = _start_published
    _start_issued = _start_published

    def _end_published(self):
        value = self.pop('published')
        self._save('published_parsed', _parse_date(value), overwrite=True)
    _end_dcterms_issued = _end_published
    _end_issued = _end_published

    def _start_updated(self, attrsD):
        self.push('updated', 1)
    _start_modified = _start_updated
    _start_dcterms_modified = _start_updated
    _start_pubdate = _start_updated
    _start_dc_date = _start_updated
    _start_lastbuilddate = _start_updated

    def _end_updated(self):
        value = self.pop('updated')
        parsed_value = _parse_date(value)
        self._save('updated_parsed', parsed_value, overwrite=True)
    _end_modified = _end_updated
    _end_dcterms_modified = _end_updated
    _end_pubdate = _end_updated
    _end_dc_date = _end_updated
    _end_lastbuilddate = _end_updated

    def _start_created(self, attrsD):
        self.push('created', 1)
    _start_dcterms_created = _start_created

    def _end_created(self):
        value = self.pop('created')
        self._save('created_parsed', _parse_date(value), overwrite=True)
    _end_dcterms_created = _end_created

    def _start_expirationdate(self, attrsD):
        self.push('expired', 1)

    def _end_expirationdate(self):
        self._save('expired_parsed', _parse_date(self.pop('expired')), overwrite=True)

    def _start_cc_license(self, attrsD):
        context = self._getContext()
        value = self._getAttribute(attrsD, 'rdf:resource')
        attrsD = FeedParserDict()
        attrsD['rel'] = 'license'
        if value:
            attrsD['href'] = value
        context.setdefault('links', []).append(attrsD)

    def _start_creativecommons_license(self, attrsD):
        self.push('license', 1)
    _start_creativeCommons_license = _start_creativecommons_license

    def _end_creativecommons_license(self):
        value = self.pop('license')
        context = self._getContext()
        attrsD = FeedParserDict()
        attrsD['rel'] = 'license'
        if value:
            attrsD['href'] = value
        context.setdefault('links', []).append(attrsD)
        del context['license']
    _end_creativeCommons_license = _end_creativecommons_license

    def _addXFN(self, relationships, href, name):
        context = self._getContext()
        xfn = context.setdefault('xfn', [])
        value = FeedParserDict({'relationships': relationships, 'href': href, 'name': name})
        if value not in xfn:
            xfn.append(value)

    def _addTag(self, term, scheme, label):
        context = self._getContext()
        tags = context.setdefault('tags', [])
        if (not term) and (not scheme) and (not label):
            return
        value = FeedParserDict({'term': term, 'scheme': scheme, 'label': label})
        if value not in tags:
            tags.append(value)

    def _start_category(self, attrsD):
        if _debug:
            sys.stderr.write('entering _start_category with %s\n' % repr(attrsD))
        term = attrsD.get('term')
        scheme = attrsD.get('scheme', attrsD.get('domain'))
        label = attrsD.get('label')
        self._addTag(term, scheme, label)
        self.push('category', 1)
    _start_dc_subject = _start_category
    _start_keywords = _start_category

    def _start_media_category(self, attrsD):
        attrsD.setdefault('scheme', 'http://search.yahoo.com/mrss/category_schema')
        self._start_category(attrsD)

    def _end_itunes_keywords(self):
        for term in self.pop('itunes_keywords').split():
            self._addTag(term, 'http://www.itunes.com/', None)

    def _start_itunes_category(self, attrsD):
        self._addTag(attrsD.get('text'), 'http://www.itunes.com/', None)
        self.push('category', 1)

    def _end_category(self):
        value = self.pop('category')
        if not value:
            return
        context = self._getContext()
        tags = context['tags']
        if value and len(tags) and not tags[-1]['term']:
            tags[-1]['term'] = value
        else:
            self._addTag(value, None, None)
    _end_dc_subject = _end_category
    _end_keywords = _end_category
    _end_itunes_category = _end_category
    _end_media_category = _end_category

    def _start_cloud(self, attrsD):
        self._getContext()['cloud'] = FeedParserDict(attrsD)

    def _start_link(self, attrsD):
        attrsD.setdefault('rel', 'alternate')
        if attrsD['rel'] == 'self':
            attrsD.setdefault('type', 'application/atom+xml')
        else:
            attrsD.setdefault('type', 'text/html')
        context = self._getContext()
        attrsD = self._itsAnHrefDamnIt(attrsD)
        if 'href' in attrsD:
            attrsD['href'] = self.resolveURI(attrsD['href'])
        expectingText = self.infeed or self.inentry or self.insource
        context.setdefault('links', [])
        if not (self.inentry and self.inimage):
            context['links'].append(FeedParserDict(attrsD))
        if 'href' in attrsD:
            expectingText = 0
            if (attrsD.get('rel') == 'alternate') and (self.mapContentType(attrsD.get('type')) in self.html_types):
                context['link'] = attrsD['href']
        else:
            self.push('link', expectingText)
    _start_producturl = _start_link

    def _end_link(self):
        value = self.pop('link')
        context = self._getContext()
    _end_producturl = _end_link

    def _start_guid(self, attrsD):
        self.guidislink = (attrsD.get('ispermalink', 'true') == 'true')
        self.push('id', 1)

    def _end_guid(self):
        value = self.pop('id')
        self._save('guidislink', self.guidislink and 'link' not in self._getContext())
        if self.guidislink:
            # guid acts as link, but only if 'ispermalink' is not present or is 'true',
            # and only if the item doesn't already have a link element
            self._save('link', value)

    def _start_title(self, attrsD):
        if self.svgOK:
            return self.unknown_starttag('title', attrsD.items())
        self.pushContent('title', attrsD, 'text/plain', self.infeed or self.inentry or self.insource)
    _start_dc_title = _start_title
    _start_media_title = _start_title

    def _end_title(self):
        if self.svgOK:
            return
        value = self.popContent('title')
        if not value:
            return
        context = self._getContext()
        self.hasTitle = 1
    _end_dc_title = _end_title

    def _end_media_title(self):
        hasTitle = self.hasTitle
        self._end_title()
        self.hasTitle = hasTitle

    def _start_description(self, attrsD):
        context = self._getContext()
        if 'summary' in context:
            self._summaryKey = 'content'
            self._start_content(attrsD)
        else:
            self.pushContent('description', attrsD, 'text/html', self.infeed or self.inentry or self.insource)
    _start_dc_description = _start_description
    _start_media_description = _start_description

    def _start_abstract(self, attrsD):
        self.pushContent('description', attrsD, 'text/plain', self.infeed or self.inentry or self.insource)

    def _end_description(self):
        if self._summaryKey == 'content':
            self._end_content()
        else:
            value = self.popContent('description')
        self._summaryKey = None
    _end_abstract = _end_description
    _end_dc_description = _end_description
    _end_media_description = _end_description

    def _start_info(self, attrsD):
        self.pushContent('info', attrsD, 'text/plain', 1)
    _start_feedburner_browserfriendly = _start_info

    def _end_info(self):
        self.popContent('info')
    _end_feedburner_browserfriendly = _end_info

    def _start_generator(self, attrsD):
        if attrsD:
            attrsD = self._itsAnHrefDamnIt(attrsD)
            if 'href' in attrsD:
                attrsD['href'] = self.resolveURI(attrsD['href'])
        self._getContext()['generator_detail'] = FeedParserDict(attrsD)
        self.push('generator', 1)

    def _end_generator(self):
        value = self.pop('generator')
        context = self._getContext()
        if 'generator_detail' in context:
            context['generator_detail']['name'] = value

    def _start_admin_generatoragent(self, attrsD):
        self.push('generator', 1)
        value = self._getAttribute(attrsD, 'rdf:resource')
        if value:
            self.elementstack[-1][2].append(value)
        self.pop('generator')
        self._getContext()['generator_detail'] = FeedParserDict({'href': value})

    def _start_admin_errorreportsto(self, attrsD):
        self.push('errorreportsto', 1)
        value = self._getAttribute(attrsD, 'rdf:resource')
        if value:
            self.elementstack[-1][2].append(value)
        self.pop('errorreportsto')

    def _start_summary(self, attrsD):
        context = self._getContext()
        if 'summary' in context:
            self._summaryKey = 'content'
            self._start_content(attrsD)
        else:
            self._summaryKey = 'summary'
            self.pushContent(self._summaryKey, attrsD, 'text/plain', 1)
    _start_itunes_summary = _start_summary

    def _end_summary(self):
        if self._summaryKey == 'content':
            self._end_content()
        else:
            self.popContent(self._summaryKey or 'summary')
        self._summaryKey = None
    _end_itunes_summary = _end_summary

    def _start_enclosure(self, attrsD):
        attrsD = self._itsAnHrefDamnIt(attrsD)
        context = self._getContext()
        attrsD['rel'] = 'enclosure'
        context.setdefault('links', []).append(FeedParserDict(attrsD))

    def _start_source(self, attrsD):
        if 'url' in attrsD:
            # This means that we're processing a source element from an RSS 2.0 feed
            self.sourcedata['href'] = attrsD[u'url']
        self.push('source', 1)
        self.insource = 1
        self.hasTitle = 0

    def _end_source(self):
        self.insource = 0
        value = self.pop('source')
        if value:
            self.sourcedata['title'] = value
        self._getContext()['source'] = copy.deepcopy(self.sourcedata)
        self.sourcedata.clear()

    def _start_content(self, attrsD):
        self.pushContent('content', attrsD, 'text/plain', 1)
        src = attrsD.get('src')
        if src:
            self.contentparams['src'] = src
        self.push('content', 1)

    def _start_prodlink(self, attrsD):
        self.pushContent('content', attrsD, 'text/html', 1)

    def _start_body(self, attrsD):
        self.pushContent('content', attrsD, 'application/xhtml+xml', 1)
    _start_xhtml_body = _start_body

    def _start_content_encoded(self, attrsD):
        self.pushContent('content', attrsD, 'text/html', 1)
    _start_fullitem = _start_content_encoded

    def _end_content(self):
        copyToSummary = self.mapContentType(self.contentparams.get('type')) in (['text/plain'] + self.html_types)
        value = self.popContent('content')
        if copyToSummary:
            self._save('summary', value)

    _end_body = _end_content
    _end_xhtml_body = _end_content
    _end_content_encoded = _end_content
    _end_fullitem = _end_content
    _end_prodlink = _end_content

    def _start_itunes_image(self, attrsD):
        self.push('itunes_image', 0)
        if attrsD.get('href'):
            self._getContext()['image'] = FeedParserDict({'href': attrsD.get('href')})
    _start_itunes_link = _start_itunes_image

    def _end_itunes_block(self):
        value = self.pop('itunes_block', 0)
        self._getContext()['itunes_block'] = (value == 'yes') and 1 or 0

    def _end_itunes_explicit(self):
        value = self.pop('itunes_explicit', 0)
        # Convert 'yes' -> True, 'clean' to False, and any other value to None
        # False and None both evaluate as False, so the difference can be ignored
        # by applications that only need to know if the content is explicit.
        self._getContext()['itunes_explicit'] = (None, False, True)[(value == 'yes' and 2) or value == 'clean' or 0]

    def _start_media_content(self, attrsD):
        context = self._getContext()
        context.setdefault('media_content', [])
        context['media_content'].append(attrsD)

    def _start_media_thumbnail(self, attrsD):
        context = self._getContext()
        context.setdefault('media_thumbnail', [])
        self.push('url', 1)  # new
        context['media_thumbnail'].append(attrsD)

    def _end_media_thumbnail(self):
        url = self.pop('url')
        context = self._getContext()
        if url != None and len(url.strip()) != 0:
            if 'url' not in context['media_thumbnail'][-1]:
                context['media_thumbnail'][-1]['url'] = url

    def _start_media_player(self, attrsD):
        self.push('media_player', 0)
        self._getContext()['media_player'] = FeedParserDict(attrsD)

    def _end_media_player(self):
        value = self.pop('media_player')
        context = self._getContext()
        context['media_player']['content'] = value

    def _start_newlocation(self, attrsD):
        self.push('newlocation', 1)

    def _end_newlocation(self):
        url = self.pop('newlocation')
        context = self._getContext()
        # don't set newlocation if the context isn't right
        if context is not self.feeddata:
            return
        context['newlocation'] = _makeSafeAbsoluteURI(self.baseuri, url.strip())

if _XML_AVAILABLE:
    class _StrictFeedParser(_FeedParserMixin, xml.sax.handler.ContentHandler):

        def __init__(self, baseuri, baselang, encoding):
            if _debug:
                sys.stderr.write('trying StrictFeedParser\n')
            xml.sax.handler.ContentHandler.__init__(self)
            _FeedParserMixin.__init__(self, baseuri, baselang, encoding)
            self.bozo = 0
            self.exc = None
            self.decls = {}

        def startPrefixMapping(self, prefix, uri):
            self.trackNamespace(prefix, uri)
            if uri == 'http://www.w3.org/1999/xlink':
                self.decls['xmlns:' + prefix] = uri

        def startElementNS(self, name, qname, attrs):
            namespace, localname = name
            lowernamespace = str(namespace or '').lower()
            if lowernamespace.find('backend.userland.com/rss') != -1:
                # match any backend.userland.com namespace
                namespace = 'http://backend.userland.com/rss'
                lowernamespace = namespace
            if qname and qname.find(':') > 0:
                givenprefix = qname.split(':')[0]
            else:
                givenprefix = None
            prefix = self._matchnamespaces.get(lowernamespace, givenprefix)
            if givenprefix and (prefix == None or (prefix == '' and lowernamespace == '')) and givenprefix not in self.namespacesInUse:
                raise UndeclaredNamespace("'%s' is not associated with a namespace" % givenprefix)
            localname = str(localname).lower()

            # qname implementation is horribly broken in Python 2.1 (it
            # doesn't report any), and slightly broken in Python 2.2 (it
            # doesn't report the xml: namespace). So we match up namespaces
            # with a known list first, and then possibly override them with
            # the qnames the SAX parser gives us (if indeed it gives us any
            # at all).  Thanks to MatejC for helping me test this and
            # tirelessly telling me that it didn't work yet.
            attrsD, self.decls = self.decls, {}
            if localname == 'math' and namespace == 'http://www.w3.org/1998/Math/MathML':
                attrsD['xmlns'] = namespace
            if localname == 'svg' and namespace == 'http://www.w3.org/2000/svg':
                attrsD['xmlns'] = namespace

            if prefix:
                localname = prefix.lower() + ':' + localname
            elif namespace and not qname:  # Expat
                for name, value in self.namespacesInUse.items():
                    if name and value == namespace:
                        localname = name + ':' + localname
                        break
            if _debug:
                sys.stderr.write('startElementNS: qname = %s, namespace = %s, givenprefix = %s, prefix = %s, attrs = %s, localname = %s\n' % (qname, namespace, givenprefix, prefix, attrs.items(), localname))

            for (namespace, attrlocalname), attrvalue in attrs._attrs.items():
                lowernamespace = (namespace or '').lower()
                prefix = self._matchnamespaces.get(lowernamespace, '')
                if prefix:
                    attrlocalname = prefix + ':' + attrlocalname
                attrsD[str(attrlocalname).lower()] = attrvalue
            for qname in attrs.getQNames():
                attrsD[str(qname).lower()] = attrs.getValueByQName(qname)
            self.unknown_starttag(localname, attrsD.items())

        def characters(self, text):
            self.handle_data(text)

        def endElementNS(self, name, qname):
            namespace, localname = name
            lowernamespace = str(namespace or '').lower()
            if qname and qname.find(':') > 0:
                givenprefix = qname.split(':')[0]
            else:
                givenprefix = ''
            prefix = self._matchnamespaces.get(lowernamespace, givenprefix)
            if prefix:
                localname = prefix + ':' + localname
            elif namespace and not qname:  # Expat
                for name, value in self.namespacesInUse.items():
                    if name and value == namespace:
                        localname = name + ':' + localname
                        break
            localname = str(localname).lower()
            self.unknown_endtag(localname)

        def error(self, exc):
            self.bozo = 1
            self.exc = exc

        def fatalError(self, exc):
            self.error(exc)
            raise exc


class _BaseHTMLProcessor(sgmllib.SGMLParser):
    special = re.compile('''[<>'"]''')
    bare_ampersand = re.compile("&(?!#\d+;|#x[0-9a-fA-F]+;|\w+;)")
    elements_no_end_tag = [
      'area', 'base', 'basefont', 'br', 'col', 'command', 'embed', 'frame',
      'hr', 'img', 'input', 'isindex', 'keygen', 'link', 'meta', 'param',
      'source', 'track', 'wbr'
    ]

    def __init__(self, encoding, _type):
        self.encoding = encoding
        self._type = _type
        if _debug:
            sys.stderr.write('entering BaseHTMLProcessor, encoding=%s\n' % self.encoding)
        sgmllib.SGMLParser.__init__(self)

    def reset(self):
        self.pieces = []
        sgmllib.SGMLParser.reset(self)

    def _shorttag_replace(self, match):
        tag = match.group(1)
        if tag in self.elements_no_end_tag:
            return '<' + tag + ' />'
        else:
            return '<' + tag + '></' + tag + '>'

    def parse_starttag(self, i):
        j = sgmllib.SGMLParser.parse_starttag(self, i)
        if self._type == 'application/xhtml+xml':
            if j > 2 and self.rawdata[j-2:j] == '/>':
                self.unknown_endtag(self.lasttag)
        return j

    def feed(self, data):
        data = re.compile(r'<!((?!DOCTYPE|--|\[))', re.IGNORECASE).sub(r'&lt;!\1', data)
        # data = re.sub(r'<(\S+?)\s*?/>', self._shorttag_replace, data) # bug [ 1399464 ] Bad regexp for _shorttag_replace
        data = re.sub(r'<([^<>\s]+?)\s*/>', self._shorttag_replace, data)
        data = data.replace('&#39;', "'")
        data = data.replace('&#34;', '"')
        try:
            bytes
            if bytes is str:
                raise NameError
            self.encoding = self.encoding + '_INVALID_PYTHON_3'
        except NameError:
            if self.encoding and isinstance(data, type(u'')):
                data = data.encode(self.encoding)
        sgmllib.SGMLParser.feed(self, data)
        sgmllib.SGMLParser.close(self)

    def normalize_attrs(self, attrs):
        if not attrs:
            return attrs
        # utility method to be called by descendants
        attrs = dict([(k.lower(), v) for k, v in attrs]).items()
        attrs = sorted([(k, k in ('rel', 'type') and v.lower() or v) for k, v in attrs])
        return attrs

    def unknown_starttag(self, tag, attrs):
        # called for each start tag
        # attrs is a list of (attr, value) tuples
        # e.g. for <pre class='screen'>, tag='pre', attrs=[('class', 'screen')]
        if _debug:
            sys.stderr.write('_BaseHTMLProcessor, unknown_starttag, tag=%s\n' % tag)
        uattrs = []
        strattrs = ''
        if attrs:
            for key, value in attrs:
                value = value.replace('>', '&gt;').replace('<', '&lt;').replace('"', '&quot;')
                value = self.bare_ampersand.sub("&amp;", value)
                # thanks to Kevin Marks for this breathtaking hack to deal with (valid) high-bit attribute values in UTF-8 feeds
                if not isinstance(value, type(u'')):
                    try:
                        value = unicode(value, self.encoding)
                    except:
                        value = unicode(value, 'iso-8859-1')
                try:
                    # Currently, in Python 3 the key is already a str, and cannot be decoded again
                    uattrs.append((unicode(key, self.encoding), value))
                except TypeError:
                    uattrs.append((key, value))
            strattrs = u''.join([u' %s="%s"' % (key, value) for key, value in uattrs])
            if self.encoding:
                try:
                    strattrs = strattrs.encode(self.encoding)
                except:
                    pass
        if tag in self.elements_no_end_tag:
            self.pieces.append('<%(tag)s%(strattrs)s />' % locals())
        else:
            self.pieces.append('<%(tag)s%(strattrs)s>' % locals())

    def unknown_endtag(self, tag):
        # called for each end tag, e.g. for </pre>, tag will be 'pre'
        # Reconstruct the original end tag.
        if tag not in self.elements_no_end_tag:
            self.pieces.append("</%(tag)s>" % locals())

    def handle_charref(self, ref):
        # called for each character reference, e.g. for '&#160;', ref will be '160'
        # Reconstruct the original character reference.
        if ref.startswith('x'):
            value = unichr(int(ref[1:], 16))
        else:
            value = unichr(int(ref))

        if value in _cp1252.keys():
            self.pieces.append('&#%s;' % hex(ord(_cp1252[value]))[1:])
        else:
            self.pieces.append('&#%(ref)s;' % locals())

    def handle_entityref(self, ref):
        # called for each entity reference, e.g. for '&copy;', ref will be 'copy'
        # Reconstruct the original entity reference.
        if ref in name2codepoint:
            self.pieces.append('&%(ref)s;' % locals())
        else:
            self.pieces.append('&amp;%(ref)s' % locals())

    def handle_data(self, text):
        # called for each block of plain text, i.e. outside of any tag and
        # not containing any character or entity references
        # Store the original text verbatim.
        if _debug:
            sys.stderr.write('_BaseHTMLProcessor, handle_data, text=%s\n' % text)
        self.pieces.append(text)

    def handle_comment(self, text):
        # called for each HTML comment, e.g. <!-- insert Javascript code here -->
        # Reconstruct the original comment.
        self.pieces.append('<!--%(text)s-->' % locals())

    def handle_pi(self, text):
        # called for each processing instruction, e.g. <?instruction>
        # Reconstruct original processing instruction.
        self.pieces.append('<?%(text)s>' % locals())

    def handle_decl(self, text):
        # called for the DOCTYPE, if present, e.g.
        # <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        #     "http://www.w3.org/TR/html4/loose.dtd">
        # Reconstruct original DOCTYPE
        self.pieces.append('<!%(text)s>' % locals())

    _new_declname_match = re.compile(r'[a-zA-Z][-_.a-zA-Z0-9:]*\s*').match

    def _scan_name(self, i, declstartpos):
        rawdata = self.rawdata
        n = len(rawdata)
        if i == n:
            return None, -1
        m = self._new_declname_match(rawdata, i)
        if m:
            s = m.group()
            name = s.strip()
            if (i + len(s)) == n:
                return None, -1  # end of buffer
            return name.lower(), m.end()
        else:
            self.handle_data(rawdata)
#            self.updatepos(declstartpos, i)
            return None, -1

    def convert_charref(self, name):
        return '&#%s;' % name

    def convert_entityref(self, name):
        return '&%s;' % name

    def output(self):
        '''Return processed HTML as a single string'''
        return ''.join([str(p) for p in self.pieces])

    def parse_declaration(self, i):
        try:
            return sgmllib.SGMLParser.parse_declaration(self, i)
        except sgmllib.SGMLParseError:
            # escape the doctype declaration and continue parsing
            self.handle_data('&lt;')
            return i + 1


class _LooseFeedParser(_FeedParserMixin, _BaseHTMLProcessor):

    def __init__(self, baseuri, baselang, encoding, entities):
        sgmllib.SGMLParser.__init__(self)
        _FeedParserMixin.__init__(self, baseuri, baselang, encoding)
        _BaseHTMLProcessor.__init__(self, encoding, 'application/xhtml+xml')
        self.entities = entities

    def decodeEntities(self, element, data):
        data = data.replace('&#60;', '&lt;')
        data = data.replace('&#x3c;', '&lt;')
        data = data.replace('&#x3C;', '&lt;')
        data = data.replace('&#62;', '&gt;')
        data = data.replace('&#x3e;', '&gt;')
        data = data.replace('&#x3E;', '&gt;')
        data = data.replace('&#38;', '&amp;')
        data = data.replace('&#x26;', '&amp;')
        data = data.replace('&#34;', '&quot;')
        data = data.replace('&#x22;', '&quot;')
        data = data.replace('&#39;', '&apos;')
        data = data.replace('&#x27;', '&apos;')
        if 'type' in self.contentparams and not self.contentparams.get('type', 'xml').endswith('xml'):
            data = data.replace('&lt;', '<')
            data = data.replace('&gt;', '>')
            data = data.replace('&amp;', '&')
            data = data.replace('&quot;', '"')
            data = data.replace('&apos;', "'")
        return data

    def strattrs(self, attrs):
        return ''.join([' %s="%s"' % (n, v.replace('"', '&quot;')) for n, v in attrs])


class _MicroformatsParser:
    STRING = 1
    DATE = 2
    URI = 3
    NODE = 4
    EMAIL = 5

    known_xfn_relationships = ['contact', 'acquaintance', 'friend', 'met', 'co-worker', 'coworker', 'colleague', 'co-resident', 'coresident', 'neighbor', 'child', 'parent', 'sibling', 'brother', 'sister', 'spouse', 'wife', 'husband', 'kin', 'relative', 'muse', 'crush', 'date', 'sweetheart', 'me']
    known_binary_extensions = ['zip', 'rar', 'exe', 'gz', 'tar', 'tgz', 'tbz2', 'bz2', 'z', '7z', 'dmg', 'img', 'sit', 'sitx', 'hqx', 'deb', 'rpm', 'bz2', 'jar', 'rar', 'iso', 'bin', 'msi', 'mp2', 'mp3', 'ogg', 'ogm', 'mp4', 'm4v', 'm4a', 'avi', 'wma', 'wmv']

    def __init__(self, data, baseuri, encoding):
        self.document = BeautifulSoup.BeautifulSoup(data)
        self.baseuri = baseuri
        self.encoding = encoding
        if isinstance(data, type(u'')):
            data = data.encode(encoding)
        self.tags = []
        self.enclosures = []
        self.xfn = []
        self.vcard = None

    def vcardEscape(self, s):
        if type(s) in (type(''), type(u'')):
            s = s.replace(',', '\\,').replace(';', '\\;').replace('\n', '\\n')
        return s

    def vcardFold(self, s):
        s = re.sub(';+$', '', s)
        sFolded = ''
        iMax = 75
        sPrefix = ''
        while len(s) > iMax:
            sFolded += sPrefix + s[:iMax] + '\n'
            s = s[iMax:]
            sPrefix = ' '
            iMax = 74
        sFolded += sPrefix + s
        return sFolded

    def normalize(self, s):
        return re.sub(r'\s+', ' ', s).strip()

    def unique(self, aList):
        results = []
        for element in aList:
            if element not in results:
                results.append(element)
        return results

    def toISO8601(self, dt):
        return time.strftime('%Y-%m-%dT%H:%M:%SZ', dt)

    def getPropertyValue(self, elmRoot, sProperty, iPropertyType=4, bAllowMultiple=0, bAutoEscape=0):
        all = lambda x: 1
        sProperty = sProperty.lower()
        bFound = 0
        bNormalize = 1
        propertyMatch = {'class': re.compile(r'\b%s\b' % sProperty)}
        if bAllowMultiple and (iPropertyType != self.NODE):
            snapResults = []
            containers = elmRoot(['ul', 'ol'], propertyMatch)
            for container in containers:
                snapResults.extend(container('li'))
            bFound = (len(snapResults) != 0)
        if not bFound:
            snapResults = elmRoot(all, propertyMatch)
            bFound = (len(snapResults) != 0)
        if (not bFound) and (sProperty == 'value'):
            snapResults = elmRoot('pre')
            bFound = (len(snapResults) != 0)
            bNormalize = not bFound
            if not bFound:
                snapResults = [elmRoot]
                bFound = (len(snapResults) != 0)
        arFilter = []
        if sProperty == 'vcard':
            snapFilter = elmRoot(all, propertyMatch)
            for node in snapFilter:
                if node.findParent(all, propertyMatch):
                    arFilter.append(node)
        arResults = []
        for node in snapResults:
            if node not in arFilter:
                arResults.append(node)
        bFound = (len(arResults) != 0)
        if not bFound:
            if bAllowMultiple:
                return []
            elif iPropertyType == self.STRING:
                return ''
            elif iPropertyType == self.DATE:
                return None
            elif iPropertyType == self.URI:
                return ''
            elif iPropertyType == self.NODE:
                return None
            else:
                return None
        arValues = []
        for elmResult in arResults:
            sValue = None
            if iPropertyType == self.NODE:
                if bAllowMultiple:
                    arValues.append(elmResult)
                    continue
                else:
                    return elmResult
            sNodeName = elmResult.name.lower()
            if (iPropertyType == self.EMAIL) and (sNodeName == 'a'):
                sValue = (elmResult.get('href') or '').split('mailto:').pop().split('?')[0]
            if sValue:
                sValue = bNormalize and self.normalize(sValue) or sValue.strip()
            if (not sValue) and (sNodeName == 'abbr'):
                sValue = elmResult.get('title')
            if sValue:
                sValue = bNormalize and self.normalize(sValue) or sValue.strip()
            if (not sValue) and (iPropertyType == self.URI):
                if sNodeName == 'a':
                    sValue = elmResult.get('href')
                elif sNodeName == 'img':
                    sValue = elmResult.get('src')
                elif sNodeName == 'object':
                    sValue = elmResult.get('data')
            if sValue:
                sValue = bNormalize and self.normalize(sValue) or sValue.strip()
            if (not sValue) and (sNodeName == 'img'):
                sValue = elmResult.get('alt')
            if sValue:
                sValue = bNormalize and self.normalize(sValue) or sValue.strip()
            if not sValue:
                sValue = elmResult.renderContents()
                sValue = re.sub(r'<\S[^>]*>', '', sValue)
                sValue = sValue.replace('\r\n', '\n')
                sValue = sValue.replace('\r', '\n')
            if sValue:
                sValue = bNormalize and self.normalize(sValue) or sValue.strip()
            if not sValue:
                continue
            if iPropertyType == self.DATE:
                sValue = _parse_date_iso8601(sValue)
            if bAllowMultiple:
                arValues.append(bAutoEscape and self.vcardEscape(sValue) or sValue)
            else:
                return bAutoEscape and self.vcardEscape(sValue) or sValue
        return arValues

    def findVCards(self, elmRoot, bAgentParsing=0):
        sVCards = ''

        if not bAgentParsing:
            arCards = self.getPropertyValue(elmRoot, 'vcard', bAllowMultiple=1)
        else:
            arCards = [elmRoot]

        for elmCard in arCards:
            arLines = []

            def processSingleString(sProperty):
                sValue = self.getPropertyValue(elmCard, sProperty, self.STRING, bAutoEscape=1).decode(self.encoding)
                if sValue:
                    arLines.append(self.vcardFold(sProperty.upper() + ':' + sValue))
                return sValue or u''

            def processSingleURI(sProperty):
                sValue = self.getPropertyValue(elmCard, sProperty, self.URI)
                if sValue:
                    sContentType = ''
                    sEncoding = ''
                    sValueKey = ''
                    if sValue.startswith('data:'):
                        sEncoding = ';ENCODING=b'
                        sContentType = sValue.split(';')[0].split('/').pop()
                        sValue = sValue.split(',', 1).pop()
                    else:
                        elmValue = self.getPropertyValue(elmCard, sProperty)
                        if elmValue:
                            if sProperty != 'url':
                                sValueKey = ';VALUE=uri'
                            sContentType = elmValue.get('type', '').strip().split('/').pop().strip()
                    sContentType = sContentType.upper()
                    if sContentType == 'OCTET-STREAM':
                        sContentType = ''
                    if sContentType:
                        sContentType = ';TYPE=' + sContentType.upper()
                    arLines.append(self.vcardFold(sProperty.upper() + sEncoding + sContentType + sValueKey + ':' + sValue))

            def processTypeValue(sProperty, arDefaultType, arForceType=None):
                arResults = self.getPropertyValue(elmCard, sProperty, bAllowMultiple=1)
                for elmResult in arResults:
                    arType = self.getPropertyValue(elmResult, 'type', self.STRING, 1, 1)
                    if arForceType:
                        arType = self.unique(arForceType + arType)
                    if not arType:
                        arType = arDefaultType
                    sValue = self.getPropertyValue(elmResult, 'value', self.EMAIL, 0)
                    if sValue:
                        arLines.append(self.vcardFold(sProperty.upper() + ';TYPE=' + ','.join(arType) + ':' + sValue))

            # AGENT
            # must do this before all other properties because it is destructive
            # (removes nested class="vcard" nodes so they don't interfere with
            # this vcard's other properties)
            arAgent = self.getPropertyValue(elmCard, 'agent', bAllowMultiple=1)
            for elmAgent in arAgent:
                if re.compile(r'\bvcard\b').search(elmAgent.get('class')):
                    sAgentValue = self.findVCards(elmAgent, 1) + '\n'
                    sAgentValue = sAgentValue.replace('\n', '\\n')
                    sAgentValue = sAgentValue.replace(';', '\\;')
                    if sAgentValue:
                        arLines.append(self.vcardFold('AGENT:' + sAgentValue))
                    # Completely remove the agent element from the parse tree
                    elmAgent.extract()
                else:
                    sAgentValue = self.getPropertyValue(elmAgent, 'value', self.URI, bAutoEscape=1);
                    if sAgentValue:
                        arLines.append(self.vcardFold('AGENT;VALUE=uri:' + sAgentValue))

            # FN (full name)
            sFN = processSingleString('fn')

            # N (name)
            elmName = self.getPropertyValue(elmCard, 'n')
            if elmName:
                sFamilyName = self.getPropertyValue(elmName, 'family-name', self.STRING, bAutoEscape=1)
                sGivenName = self.getPropertyValue(elmName, 'given-name', self.STRING, bAutoEscape=1)
                arAdditionalNames = self.getPropertyValue(elmName, 'additional-name', self.STRING, 1, 1) + self.getPropertyValue(elmName, 'additional-names', self.STRING, 1, 1)
                arHonorificPrefixes = self.getPropertyValue(elmName, 'honorific-prefix', self.STRING, 1, 1) + self.getPropertyValue(elmName, 'honorific-prefixes', self.STRING, 1, 1)
                arHonorificSuffixes = self.getPropertyValue(elmName, 'honorific-suffix', self.STRING, 1, 1) + self.getPropertyValue(elmName, 'honorific-suffixes', self.STRING, 1, 1)
                arLines.append(self.vcardFold('N:' + sFamilyName + ';' +
                                         sGivenName + ';' +
                                         ','.join(arAdditionalNames) + ';' +
                                         ','.join(arHonorificPrefixes) + ';' +
                                         ','.join(arHonorificSuffixes)))
            elif sFN:
                # implied "N" optimization
                # http://microformats.org/wiki/hcard#Implied_.22N.22_Optimization
                arNames = self.normalize(sFN).split()
                if len(arNames) == 2:
                    bFamilyNameFirst = (arNames[0].endswith(',') or
                                        len(arNames[1]) == 1 or
                                        ((len(arNames[1]) == 2) and (arNames[1].endswith('.'))))
                    if bFamilyNameFirst:
                        arLines.append(self.vcardFold('N:' + arNames[0] + ';' + arNames[1]))
                    else:
                        arLines.append(self.vcardFold('N:' + arNames[1] + ';' + arNames[0]))

            # SORT-STRING
            sSortString = self.getPropertyValue(elmCard, 'sort-string', self.STRING, bAutoEscape=1)
            if sSortString:
                arLines.append(self.vcardFold('SORT-STRING:' + sSortString))

            # NICKNAME
            arNickname = self.getPropertyValue(elmCard, 'nickname', self.STRING, 1, 1)
            if arNickname:
                arLines.append(self.vcardFold('NICKNAME:' + ','.join(arNickname)))

            # PHOTO
            processSingleURI('photo')

            # BDAY
            dtBday = self.getPropertyValue(elmCard, 'bday', self.DATE)
            if dtBday:
                arLines.append(self.vcardFold('BDAY:' + self.toISO8601(dtBday)))

            # ADR (address)
            arAdr = self.getPropertyValue(elmCard, 'adr', bAllowMultiple=1)
            for elmAdr in arAdr:
                arType = self.getPropertyValue(elmAdr, 'type', self.STRING, 1, 1)
                if not arType:
                    arType = ['intl', 'postal', 'parcel', 'work']  # default adr types, see RFC 2426 section 3.2.1
                sPostOfficeBox = self.getPropertyValue(elmAdr, 'post-office-box', self.STRING, 0, 1)
                sExtendedAddress = self.getPropertyValue(elmAdr, 'extended-address', self.STRING, 0, 1)
                sStreetAddress = self.getPropertyValue(elmAdr, 'street-address', self.STRING, 0, 1)
                sLocality = self.getPropertyValue(elmAdr, 'locality', self.STRING, 0, 1)
                sRegion = self.getPropertyValue(elmAdr, 'region', self.STRING, 0, 1)
                sPostalCode = self.getPropertyValue(elmAdr, 'postal-code', self.STRING, 0, 1)
                sCountryName = self.getPropertyValue(elmAdr, 'country-name', self.STRING, 0, 1)
                arLines.append(self.vcardFold('ADR;TYPE=' + ','.join(arType) + ':' +
                                         sPostOfficeBox + ';' +
                                         sExtendedAddress + ';' +
                                         sStreetAddress + ';' +
                                         sLocality + ';' +
                                         sRegion + ';' +
                                         sPostalCode + ';' +
                                         sCountryName))

            # LABEL
            processTypeValue('label', ['intl', 'postal', 'parcel', 'work'])

            # TEL (phone number)
            processTypeValue('tel', ['voice'])

            # EMAIL
            processTypeValue('email', ['internet'], ['internet'])

            # MAILER
            processSingleString('mailer')

            # TZ (timezone)
            processSingleString('tz')

            # GEO (geographical information)
            elmGeo = self.getPropertyValue(elmCard, 'geo')
            if elmGeo:
                sLatitude = self.getPropertyValue(elmGeo, 'latitude', self.STRING, 0, 1)
                sLongitude = self.getPropertyValue(elmGeo, 'longitude', self.STRING, 0, 1)
                arLines.append(self.vcardFold('GEO:' + sLatitude + ';' + sLongitude))

            # TITLE
            processSingleString('title')

            # ROLE
            processSingleString('role')

            # LOGO
            processSingleURI('logo')

            # ORG (organization)
            elmOrg = self.getPropertyValue(elmCard, 'org')
            if elmOrg:
                sOrganizationName = self.getPropertyValue(elmOrg, 'organization-name', self.STRING, 0, 1)
                if not sOrganizationName:
                    # implied "organization-name" optimization
                    # http://microformats.org/wiki/hcard#Implied_.22organization-name.22_Optimization
                    sOrganizationName = self.getPropertyValue(elmCard, 'org', self.STRING, 0, 1)
                    if sOrganizationName:
                        arLines.append(self.vcardFold('ORG:' + sOrganizationName))
                else:
                    arOrganizationUnit = self.getPropertyValue(elmOrg, 'organization-unit', self.STRING, 1, 1)
                    arLines.append(self.vcardFold('ORG:' + sOrganizationName + ';' + ';'.join(arOrganizationUnit)))

            # CATEGORY
            arCategory = self.getPropertyValue(elmCard, 'category', self.STRING, 1, 1) + self.getPropertyValue(elmCard, 'categories', self.STRING, 1, 1)
            if arCategory:
                arLines.append(self.vcardFold('CATEGORIES:' + ','.join(arCategory)))

            # NOTE
            processSingleString('note')

            # REV
            processSingleString('rev')

            # SOUND
            processSingleURI('sound')

            # UID
            processSingleString('uid')

            # URL
            processSingleURI('url')

            # CLASS
            processSingleString('class')

            # KEY
            processSingleURI('key')

            if arLines:
                arLines = [u'BEGIN:vCard', u'VERSION:3.0'] + arLines + [u'END:vCard']
                sVCards += u'\n'.join(arLines) + u'\n'

        return sVCards.strip()

    def isProbablyDownloadable(self, elm):
        attrsD = elm.attrMap
        if 'href' not in attrsD:
            return 0
        linktype = attrsD.get('type', '').strip()
        if linktype.startswith('audio/') or \
           linktype.startswith('video/') or \
           (linktype.startswith('application/') and not linktype.endswith('xml')):
            return 1
        path = urlparse.urlparse(attrsD['href'])[2]
        if path.find('.') == -1:
            return 0
        fileext = path.split('.').pop().lower()
        return fileext in self.known_binary_extensions

    def findTags(self):
        all = lambda x: 1
        for elm in self.document(all, {'rel': re.compile(r'\btag\b')}):
            href = elm.get('href')
            if not href:
                continue
            urlscheme, domain, path, params, query, fragment = \
                       urlparse.urlparse(_urljoin(self.baseuri, href))
            segments = path.split('/')
            tag = segments.pop()
            if not tag:
                tag = segments.pop()
            tagscheme = urlparse.urlunparse((urlscheme, domain, '/'.join(segments), '', '', ''))
            if not tagscheme.endswith('/'):
                tagscheme += '/'
            self.tags.append(FeedParserDict({"term": tag, "scheme": tagscheme, "label": elm.string or ''}))

    def findEnclosures(self):
        all = lambda x: 1
        enclosure_match = re.compile(r'\benclosure\b')
        for elm in self.document(all, {'href': re.compile(r'.+')}):
            if not enclosure_match.search(elm.get('rel', '')) and not self.isProbablyDownloadable(elm):
                continue
            if elm.attrMap not in self.enclosures:
                self.enclosures.append(elm.attrMap)
                if elm.string and not elm.get('title'):
                    self.enclosures[-1]['title'] = elm.string

    def findXFN(self):
        all = lambda x: 1
        for elm in self.document(all, {'rel': re.compile('.+'), 'href': re.compile('.+')}):
            rels = elm.get('rel', '').split()
            xfn_rels = []
            for rel in rels:
                if rel in self.known_xfn_relationships:
                    xfn_rels.append(rel)
            if xfn_rels:
                self.xfn.append({"relationships": xfn_rels, "href": elm.get('href', ''), "name": elm.string})


def _parseMicroformats(htmlSource, baseURI, encoding):
    if not BeautifulSoup:
        return
    if _debug:
        sys.stderr.write('entering _parseMicroformats\n')
    try:
        p = _MicroformatsParser(htmlSource, baseURI, encoding)
    except UnicodeEncodeError:
        # sgmllib throws this exception when performing lookups of tags
        # with non-ASCII characters in them.
        return
    p.vcard = p.findVCards(p.document)
    p.findTags()
    p.findEnclosures()
    p.findXFN()
    return {"tags": p.tags, "enclosures": p.enclosures, "xfn": p.xfn, "vcard": p.vcard}


class _RelativeURIResolver(_BaseHTMLProcessor):
    relative_uris = [('a', 'href'),
                     ('applet', 'codebase'),
                     ('area', 'href'),
                     ('blockquote', 'cite'),
                     ('body', 'background'),
                     ('del', 'cite'),
                     ('form', 'action'),
                     ('frame', 'longdesc'),
                     ('frame', 'src'),
                     ('iframe', 'longdesc'),
                     ('iframe', 'src'),
                     ('head', 'profile'),
                     ('img', 'longdesc'),
                     ('img', 'src'),
                     ('img', 'usemap'),
                     ('input', 'src'),
                     ('input', 'usemap'),
                     ('ins', 'cite'),
                     ('link', 'href'),
                     ('object', 'classid'),
                     ('object', 'codebase'),
                     ('object', 'data'),
                     ('object', 'usemap'),
                     ('q', 'cite'),
                     ('script', 'src')]

    def __init__(self, baseuri, encoding, _type):
        _BaseHTMLProcessor.__init__(self, encoding, _type)
        self.baseuri = baseuri

    def resolveURI(self, uri):
        return _makeSafeAbsoluteURI(_urljoin(self.baseuri, uri.strip()))

    def unknown_starttag(self, tag, attrs):
        if _debug:
            sys.stderr.write('tag: [%s] with attributes: [%s]\n' % (tag, str(attrs)))
        attrs = self.normalize_attrs(attrs)
        attrs = [(key, ((tag, key) in self.relative_uris) and self.resolveURI(value) or value) for key, value in attrs]
        _BaseHTMLProcessor.unknown_starttag(self, tag, attrs)


def _resolveRelativeURIs(htmlSource, baseURI, encoding, _type):
    if _debug:
        sys.stderr.write('entering _resolveRelativeURIs\n')

    p = _RelativeURIResolver(baseURI, encoding, _type)
    p.feed(htmlSource)
    return p.output()


def _makeSafeAbsoluteURI(base, rel=None):
    # bail if ACCEPTABLE_URI_SCHEMES is empty
    if not ACCEPTABLE_URI_SCHEMES:
        return _urljoin(base, rel or u'')
    if not base:
        return rel or u''
    if not rel:
        scheme = urlparse.urlparse(base)[0]
        if not scheme or scheme in ACCEPTABLE_URI_SCHEMES:
            return base
        return u''
    uri = _urljoin(base, rel)
    if uri.strip().split(':', 1)[0] not in ACCEPTABLE_URI_SCHEMES:
        return u''
    return uri


class _HTMLSanitizer(_BaseHTMLProcessor):
    acceptable_elements = ['a', 'abbr', 'acronym', 'address', 'area',
        'article', 'aside', 'audio', 'b', 'big', 'blockquote', 'br', 'button',
        'canvas', 'caption', 'center', 'cite', 'code', 'col', 'colgroup',
        'command', 'datagrid', 'datalist', 'dd', 'del', 'details', 'dfn',
        'dialog', 'dir', 'div', 'dl', 'dt', 'em', 'event-source', 'fieldset',
        'figcaption', 'figure', 'footer', 'font', 'form', 'header', 'h1',
        'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img', 'input', 'ins',
        'keygen', 'kbd', 'label', 'legend', 'li', 'm', 'map', 'menu', 'meter',
        'multicol', 'nav', 'nextid', 'ol', 'output', 'optgroup', 'option',
        'p', 'pre', 'progress', 'q', 's', 'samp', 'section', 'select',
        'small', 'sound', 'source', 'spacer', 'span', 'strike', 'strong',
        'sub', 'sup', 'table', 'tbody', 'td', 'textarea', 'time', 'tfoot',
        'th', 'thead', 'tr', 'tt', 'u', 'ul', 'var', 'video', 'noscript']

    acceptable_attributes = ['abbr', 'accept', 'accept-charset', 'accesskey',
      'action', 'align', 'alt', 'autocomplete', 'autofocus', 'axis',
      'background', 'balance', 'bgcolor', 'bgproperties', 'border',
      'bordercolor', 'bordercolordark', 'bordercolorlight', 'bottompadding',
      'cellpadding', 'cellspacing', 'ch', 'challenge', 'char', 'charoff',
      'choff', 'charset', 'checked', 'cite', 'class', 'clear', 'color', 'cols',
      'colspan', 'compact', 'contenteditable', 'controls', 'coords', 'data',
      'datafld', 'datapagesize', 'datasrc', 'datetime', 'default', 'delay',
      'dir', 'disabled', 'draggable', 'dynsrc', 'enctype', 'end', 'face', 'for',
      'form', 'frame', 'galleryimg', 'gutter', 'headers', 'height', 'hidefocus',
      'hidden', 'high', 'href', 'hreflang', 'hspace', 'icon', 'id', 'inputmode',
      'ismap', 'keytype', 'label', 'leftspacing', 'lang', 'list', 'longdesc',
      'loop', 'loopcount', 'loopend', 'loopstart', 'low', 'lowsrc', 'max',
      'maxlength', 'media', 'method', 'min', 'multiple', 'name', 'nohref',
      'noshade', 'nowrap', 'open', 'optimum', 'pattern', 'ping', 'point-size',
      'prompt', 'pqg', 'radiogroup', 'readonly', 'rel', 'repeat-max',
      'repeat-min', 'replace', 'required', 'rev', 'rightspacing', 'rows',
      'rowspan', 'rules', 'scope', 'selected', 'shape', 'size', 'span', 'src',
      'start', 'step', 'summary', 'suppress', 'tabindex', 'target', 'template',
      'title', 'toppadding', 'type', 'unselectable', 'usemap', 'urn', 'valign',
      'value', 'variable', 'volume', 'vspace', 'vrml', 'width', 'wrap',
      'xml:lang']

    unacceptable_elements_with_end_tag = ['script', 'applet', 'style']

    acceptable_css_properties = ['azimuth', 'background-color',
      'border-bottom-color', 'border-collapse', 'border-color',
      'border-left-color', 'border-right-color', 'border-top-color', 'clear',
      'color', 'cursor', 'direction', 'display', 'elevation', 'float', 'font',
      'font-family', 'font-size', 'font-style', 'font-variant', 'font-weight',
      'height', 'letter-spacing', 'line-height', 'overflow', 'pause',
      'pause-after', 'pause-before', 'pitch', 'pitch-range', 'richness',
      'speak', 'speak-header', 'speak-numeral', 'speak-punctuation',
      'speech-rate', 'stress', 'text-align', 'text-decoration', 'text-indent',
      'unicode-bidi', 'vertical-align', 'voice-family', 'volume',
      'white-space', 'width']

    # survey of common keywords found in feeds
    acceptable_css_keywords = ['auto', 'aqua', 'black', 'block', 'blue',
      'bold', 'both', 'bottom', 'brown', 'center', 'collapse', 'dashed',
      'dotted', 'fuchsia', 'gray', 'green', '!important', 'italic', 'left',
      'lime', 'maroon', 'medium', 'none', 'navy', 'normal', 'nowrap', 'olive',
      'pointer', 'purple', 'red', 'right', 'solid', 'silver', 'teal', 'top',
      'transparent', 'underline', 'white', 'yellow']

    valid_css_values = re.compile('^(#[0-9a-f]+|rgb\(\d+%?,\d*%?,?\d*%?\)?|' +
      '\d{0,2}\.?\d{0,2}(cm|em|ex|in|mm|pc|pt|px|%|,|\))?)$')

    mathml_elements = ['annotation', 'annotation-xml', 'maction', 'math',
      'merror', 'mfenced', 'mfrac', 'mi', 'mmultiscripts', 'mn', 'mo', 'mover', 'mpadded',
      'mphantom', 'mprescripts', 'mroot', 'mrow', 'mspace', 'msqrt', 'mstyle',
      'msub', 'msubsup', 'msup', 'mtable', 'mtd', 'mtext', 'mtr', 'munder',
      'munderover', 'none', 'semantics']

    mathml_attributes = ['actiontype', 'align', 'columnalign', 'columnalign',
      'columnalign', 'close', 'columnlines', 'columnspacing', 'columnspan', 'depth',
      'display', 'displaystyle', 'encoding', 'equalcolumns', 'equalrows',
      'fence', 'fontstyle', 'fontweight', 'frame', 'height', 'linethickness',
      'lspace', 'mathbackground', 'mathcolor', 'mathvariant', 'mathvariant',
      'maxsize', 'minsize', 'open', 'other', 'rowalign', 'rowalign', 'rowalign',
      'rowlines', 'rowspacing', 'rowspan', 'rspace', 'scriptlevel', 'selection',
      'separator', 'separators', 'stretchy', 'width', 'width', 'xlink:href',
      'xlink:show', 'xlink:type', 'xmlns', 'xmlns:xlink']

    # svgtiny - foreignObject + linearGradient + radialGradient + stop
    svg_elements = ['a', 'animate', 'animateColor', 'animateMotion',
      'animateTransform', 'circle', 'defs', 'desc', 'ellipse', 'foreignObject',
      'font-face', 'font-face-name', 'font-face-src', 'g', 'glyph', 'hkern',
      'linearGradient', 'line', 'marker', 'metadata', 'missing-glyph', 'mpath',
      'path', 'polygon', 'polyline', 'radialGradient', 'rect', 'set', 'stop',
      'svg', 'switch', 'text', 'title', 'tspan', 'use']

    # svgtiny + class + opacity + offset + xmlns + xmlns:xlink
    svg_attributes = ['accent-height', 'accumulate', 'additive', 'alphabetic',
       'arabic-form', 'ascent', 'attributeName', 'attributeType',
       'baseProfile', 'bbox', 'begin', 'by', 'calcMode', 'cap-height',
       'class', 'color', 'color-rendering', 'content', 'cx', 'cy', 'd', 'dx',
       'dy', 'descent', 'display', 'dur', 'end', 'fill', 'fill-opacity',
       'fill-rule', 'font-family', 'font-size', 'font-stretch', 'font-style',
       'font-variant', 'font-weight', 'from', 'fx', 'fy', 'g1', 'g2',
       'glyph-name', 'gradientUnits', 'hanging', 'height', 'horiz-adv-x',
       'horiz-origin-x', 'id', 'ideographic', 'k', 'keyPoints', 'keySplines',
       'keyTimes', 'lang', 'mathematical', 'marker-end', 'marker-mid',
       'marker-start', 'markerHeight', 'markerUnits', 'markerWidth', 'max',
       'min', 'name', 'offset', 'opacity', 'orient', 'origin',
       'overline-position', 'overline-thickness', 'panose-1', 'path',
       'pathLength', 'points', 'preserveAspectRatio', 'r', 'refX', 'refY',
       'repeatCount', 'repeatDur', 'requiredExtensions', 'requiredFeatures',
       'restart', 'rotate', 'rx', 'ry', 'slope', 'stemh', 'stemv',
       'stop-color', 'stop-opacity', 'strikethrough-position',
       'strikethrough-thickness', 'stroke', 'stroke-dasharray',
       'stroke-dashoffset', 'stroke-linecap', 'stroke-linejoin',
       'stroke-miterlimit', 'stroke-opacity', 'stroke-width', 'systemLanguage',
       'target', 'text-anchor', 'to', 'transform', 'type', 'u1', 'u2',
       'underline-position', 'underline-thickness', 'unicode', 'unicode-range',
       'units-per-em', 'values', 'version', 'viewBox', 'visibility', 'width',
       'widths', 'x', 'x-height', 'x1', 'x2', 'xlink:actuate', 'xlink:arcrole',
       'xlink:href', 'xlink:role', 'xlink:show', 'xlink:title', 'xlink:type',
       'xml:base', 'xml:lang', 'xml:space', 'xmlns', 'xmlns:xlink', 'y', 'y1',
       'y2', 'zoomAndPan']

    svg_attr_map = None
    svg_elem_map = None

    acceptable_svg_properties = ['fill', 'fill-opacity', 'fill-rule',
      'stroke', 'stroke-width', 'stroke-linecap', 'stroke-linejoin',
      'stroke-opacity']

    def reset(self):
        _BaseHTMLProcessor.reset(self)
        self.unacceptablestack = 0
        self.mathmlOK = 0
        self.svgOK = 0

    def unknown_starttag(self, tag, attrs):
        acceptable_attributes = self.acceptable_attributes
        keymap = {}
        if not tag in self.acceptable_elements or self.svgOK:
            if tag in self.unacceptable_elements_with_end_tag:
                self.unacceptablestack += 1

            # add implicit namespaces to html5 inline svg/mathml
            if self._type.endswith('html'):
                if not dict(attrs).get('xmlns'):
                    if tag == 'svg':
                        attrs.append(('xmlns', 'http://www.w3.org/2000/svg'))
                    if tag == 'math':
                        attrs.append(('xmlns', 'http://www.w3.org/1998/Math/MathML'))

            # not otherwise acceptable, perhaps it is MathML or SVG?
            if tag == 'math' and ('xmlns', 'http://www.w3.org/1998/Math/MathML') in attrs:
                self.mathmlOK += 1
            if tag == 'svg' and ('xmlns', 'http://www.w3.org/2000/svg') in attrs:
                self.svgOK += 1

            # chose acceptable attributes based on tag class, else bail
            if self.mathmlOK and tag in self.mathml_elements:
                acceptable_attributes = self.mathml_attributes
            elif self.svgOK and tag in self.svg_elements:
                # for most vocabularies, lowercasing is a good idea.  Many
                # svg elements, however, are camel case
                if not self.svg_attr_map:
                    lower = [attr.lower() for attr in self.svg_attributes]
                    mix = [a for a in self.svg_attributes if a not in lower]
                    self.svg_attributes = lower
                    self.svg_attr_map = dict([(a.lower(), a) for a in mix])

                    lower = [attr.lower() for attr in self.svg_elements]
                    mix = [a for a in self.svg_elements if a not in lower]
                    self.svg_elements = lower
                    self.svg_elem_map = dict([(a.lower(), a) for a in mix])
                acceptable_attributes = self.svg_attributes
                tag = self.svg_elem_map.get(tag, tag)
                keymap = self.svg_attr_map
            elif not tag in self.acceptable_elements:
                return

        # declare xlink namespace, if needed
        if self.mathmlOK or self.svgOK:
            if filter(lambda n_v: n_v[0].startswith('xlink:'), attrs):
                if not ('xmlns:xlink', 'http://www.w3.org/1999/xlink') in attrs:
                    attrs.append(('xmlns:xlink', 'http://www.w3.org/1999/xlink'))

        clean_attrs = []
        for key, value in self.normalize_attrs(attrs):
            if key in acceptable_attributes:
                key = keymap.get(key, key)
                # make sure the uri uses an acceptable uri scheme
                if key == u'href':
                    value = _makeSafeAbsoluteURI(value)
                clean_attrs.append((key, value))
            elif key == 'style':
                clean_value = self.sanitize_style(value)
                if clean_value:
                    clean_attrs.append((key, clean_value))
        _BaseHTMLProcessor.unknown_starttag(self, tag, clean_attrs)

    def unknown_endtag(self, tag):
        if not tag in self.acceptable_elements:
            if tag in self.unacceptable_elements_with_end_tag:
                self.unacceptablestack -= 1
            if self.mathmlOK and tag in self.mathml_elements:
                if tag == 'math' and self.mathmlOK:
                    self.mathmlOK -= 1
            elif self.svgOK and tag in self.svg_elements:
                tag = self.svg_elem_map.get(tag, tag)
                if tag == 'svg' and self.svgOK:
                    self.svgOK -= 1
            else:
                return
        _BaseHTMLProcessor.unknown_endtag(self, tag)

    def handle_pi(self, text):
        pass

    def handle_decl(self, text):
        pass

    def handle_data(self, text):
        if not self.unacceptablestack:
            _BaseHTMLProcessor.handle_data(self, text)

    def sanitize_style(self, style):
        # disallow urls
        style = re.compile('url\s*\(\s*[^\s)]+?\s*\)\s*').sub(' ', style)

        # gauntlet
        if not re.match("""^([:,;#%.\sa-zA-Z0-9!]|\w-\w|'[\s\w]+'|"[\s\w]+"|\([\d,\s]+\))*$""", style):
            return ''
        # This replaced a regexp that used re.match and was prone to pathological back-tracking.
        if re.sub("\s*[-\w]+\s*:\s*[^:;]*;?", '', style).strip():
            return ''

        clean = []
        for prop, value in re.findall("([-\w]+)\s*:\s*([^:;]*)", style):
            if not value:
                continue
            if prop.lower() in self.acceptable_css_properties:
                clean.append(prop + ': ' + value + ';')
            elif prop.split('-')[0].lower() in ['background', 'border', 'margin', 'padding']:
                for keyword in value.split():
                    if not keyword in self.acceptable_css_keywords and \
                        not self.valid_css_values.match(keyword):
                        break
                    else:
                        clean.append(prop + ': ' + value + ';')
            elif self.svgOK and prop.lower() in self.acceptable_svg_properties:
                clean.append(prop + ': ' + value + ';')

        return ' '.join(clean)

    def parse_comment(self, i, report=1):
        ret = _BaseHTMLProcessor.parse_comment(self, i, report)
        if ret >= 0:
            return ret
        # if ret == -1, this may be a malicious attempt to circumvent
        # sanitization, or a page-destroying unclosed comment
        match = re.compile(r'--[^>]*>').search(self.rawdata, i + 4)
        if match:
            return match.end()
        # unclosed comment; deliberately fail to handle_data()
        return len(self.rawdata)


def _sanitizeHTML(htmlSource, encoding, _type):
    p = _HTMLSanitizer(encoding, _type)
    htmlSource = htmlSource.replace('<![CDATA[', '&lt;![CDATA[')
    p.feed(htmlSource)
    data = p.output()
    if TIDY_MARKUP:
        # loop through list of preferred Tidy interfaces looking for one that's installed,
        # then set up a common _tidy function to wrap the interface-specific API.
        _tidy = None
        for tidy_interface in PREFERRED_TIDY_INTERFACES:
            try:
                if tidy_interface == "uTidy":
                    from tidy import parseString as _utidy

                    def _tidy(data, **kwargs):
                        return str(_utidy(data, **kwargs))
                    break
                elif tidy_interface == "mxTidy":
                    from mx.Tidy import Tidy as _mxtidy

                    def _tidy(data, **kwargs):
                        nerrors, nwarnings, data, errordata = _mxtidy.tidy(data, **kwargs)
                        return data
                    break
            except:
                pass
        if _tidy:
            utf8 = isinstance(data, type(u''))
            if utf8:
                data = data.encode('utf-8')
            data = _tidy(data, output_xhtml=1, numeric_entities=1, wrap=0, char_encoding="utf8")
            if utf8:
                data = unicode(data, 'utf-8')
            if data.count('<body'):
                data = data.split('<body', 1)[1]
                if data.count('>'):
                    data = data.split('>', 1)[1]
            if data.count('</body'):
                data = data.split('</body', 1)[0]
    data = data.strip().replace('\r\n', '\n')
    return data


class _FeedURLHandler(urllib2.HTTPDigestAuthHandler, urllib2.HTTPRedirectHandler, urllib2.HTTPDefaultErrorHandler):

    def http_error_default(self, req, fp, code, msg, headers):
        if ((code / 100) == 3) and (code != 304):
            return self.http_error_302(req, fp, code, msg, headers)
        infourl = urllib.addinfourl(fp, headers, req.get_full_url())
        infourl.status = code
        return infourl

    def http_error_302(self, req, fp, code, msg, headers):
        if 'location' in headers.dict:
            infourl = urllib2.HTTPRedirectHandler.http_error_302(self, req, fp, code, msg, headers)
        else:
            infourl = urllib.addinfourl(fp, headers, req.get_full_url())
        if not hasattr(infourl, 'status'):
            infourl.status = code
        return infourl

    def http_error_301(self, req, fp, code, msg, headers):
        if 'location' in headers.dict:
            infourl = urllib2.HTTPRedirectHandler.http_error_301(self, req, fp, code, msg, headers)
        else:
            infourl = urllib.addinfourl(fp, headers, req.get_full_url())
        if not hasattr(infourl, 'status'):
            infourl.status = code
        return infourl

    http_error_300 = http_error_302
    http_error_303 = http_error_302
    http_error_307 = http_error_302

    def http_error_401(self, req, fp, code, msg, headers):
        # Check if
        # - server requires digest auth, AND
        # - we tried (unsuccessfully) with basic auth, AND
        # - we're using Python 2.3.3 or later (digest auth is irreparably broken in earlier versions)
        # If all conditions hold, parse authentication information
        # out of the Authorization header we sent the first time
        # (for the username and password) and the WWW-Authenticate
        # header the server sent back (for the realm) and retry
        # the request with the appropriate digest auth headers instead.
        # This evil genius hack has been brought to you by Aaron Swartz.
        host = urlparse.urlparse(req.get_full_url())[1]
        try:
            assert sys.version.split()[0] >= '2.3.3'
            assert base64 != None
            user, passw = _base64decode(req.headers['Authorization'].split(' ')[1]).split(':')
            realm = re.findall('realm="([^"]*)"', headers['WWW-Authenticate'])[0]
            self.add_password(realm, host, user, passw)
            retry = self.http_error_auth_reqed('www-authenticate', host, req, headers)
            self.reset_retry_count()
            return retry
        except:
            return self.http_error_default(req, fp, code, msg, headers)


def _open_resource(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers):
    """URL, filename, or string --> stream

    This function lets you define parsers that take any input source
    (URL, pathname to local or network file, or actual data as a string)
    and deal with it in a uniform manner.  Returned object is guaranteed
    to have all the basic stdio read methods (read, readline, readlines).
    Just .close() the object when you're done with it.

    If the etag argument is supplied, it will be used as the value of an
    If-None-Match request header.

    If the modified argument is supplied, it can be a tuple of 9 integers
    (as returned by gmtime() in the standard Python time module) or a date
    string in any format supported by feedparser. Regardless, it MUST
    be in GMT (Greenwich Mean Time). It will be reformatted into an
    RFC 1123-compliant date and used as the value of an If-Modified-Since
    request header.

    If the agent argument is supplied, it will be used as the value of a
    User-Agent request header.

    If the referrer argument is supplied, it will be used as the value of a
    Referer[sic] request header.

    If handlers is supplied, it is a list of handlers used to build a
    urllib2 opener.

    if request_headers is supplied it is a dictionary of HTTP request headers
    that will override the values generated by FeedParser.
    """

    if hasattr(url_file_stream_or_string, 'read'):
        return url_file_stream_or_string

    if url_file_stream_or_string == '-':
        return sys.stdin

    if urlparse.urlparse(url_file_stream_or_string)[0] in ('http', 'https', 'ftp', 'file', 'feed'):
        # Deal with the feed URI scheme
        if url_file_stream_or_string.startswith('feed:http'):
            url_file_stream_or_string = url_file_stream_or_string[5:]
        elif url_file_stream_or_string.startswith('feed:'):
            url_file_stream_or_string = 'http:' + url_file_stream_or_string[5:]
        if not agent:
            agent = USER_AGENT
        # test for inline user:password for basic auth
        auth = None
        if base64:
            urltype, rest = urllib.splittype(url_file_stream_or_string)
            realhost, rest = urllib.splithost(rest)
            if realhost:
                user_passwd, realhost = urllib.splituser(realhost)
                if user_passwd:
                    url_file_stream_or_string = '%s://%s%s' % (urltype, realhost, rest)
                    auth = base64.standard_b64encode(user_passwd).strip()

        # iri support
        try:
            if isinstance(url_file_stream_or_string, unicode):
                url_file_stream_or_string = url_file_stream_or_string.encode('idna').decode('utf-8')
            else:
                url_file_stream_or_string = url_file_stream_or_string.decode('utf-8').encode('idna').decode('utf-8')
        except:
            pass

        # try to open with urllib2 (to use optional headers)
        request = _build_urllib2_request(url_file_stream_or_string, agent, etag, modified, referrer, auth, request_headers)
        opener = urllib2.build_opener(*tuple(handlers + [_FeedURLHandler()]))
        opener.addheaders = []  # RMK - must clear so we only send our custom User-Agent
        try:
            return opener.open(request)
        finally:
            opener.close()  # JohnD

    # try to open with native open function (if url_file_stream_or_string is a filename)
    try:
        return open(url_file_stream_or_string, 'rb')
    except:
        pass

    # treat url_file_stream_or_string as string
    return _StringIO(str(url_file_stream_or_string))


def _build_urllib2_request(url, agent, etag, modified, referrer, auth, request_headers):
    request = urllib2.Request(url)
    request.add_header('User-Agent', agent)
    if etag:
        request.add_header('If-None-Match', etag)
    if isinstance(modified, type('')):
        modified = _parse_date(modified)
    elif isinstance(modified, datetime.datetime):
        modified = modified.utctimetuple()
    if modified:
        # format into an RFC 1123-compliant timestamp. We can't use
        # time.strftime() since the %a and %b directives can be affected
        # by the current locale, but RFC 2616 states that dates must be
        # in English.
        short_weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        request.add_header('If-Modified-Since', '%s, %02d %s %04d %02d:%02d:%02d GMT' % (short_weekdays[modified[6]], modified[2], months[modified[1] - 1], modified[0], modified[3], modified[4], modified[5]))
    if referrer:
        request.add_header('Referer', referrer)
    if gzip and zlib:
        request.add_header('Accept-encoding', 'gzip, deflate')
    elif gzip:
        request.add_header('Accept-encoding', 'gzip')
    elif zlib:
        request.add_header('Accept-encoding', 'deflate')
    else:
        request.add_header('Accept-encoding', '')
    if auth:
        request.add_header('Authorization', 'Basic %s' % auth)
    if ACCEPT_HEADER:
        request.add_header('Accept', ACCEPT_HEADER)
    # use this for whatever -- cookies, special headers, etc
    # [('Cookie','Something'),('x-special-header','Another Value')]
    for header_name, header_value in request_headers.items():
        request.add_header(header_name, header_value)
    request.add_header('A-IM', 'feed')  # RFC 3229 support
    return request

_date_handlers = []


def registerDateHandler(func):
    '''Register a date handler function (takes string, returns 9-tuple date in GMT)'''
    _date_handlers.insert(0, func)

# ISO-8601 date parsing routines written by Fazal Majid.
# The ISO 8601 standard is very convoluted and irregular - a full ISO 8601
# parser is beyond the scope of feedparser and would be a worthwhile addition
# to the Python library.
# A single regular expression cannot parse ISO 8601 date formats into groups
# as the standard is highly irregular (for instance is 030104 2003-01-04 or
# 0301-04-01), so we use templates instead.
# Please note the order in templates is significant because we need a
# greedy match.
_iso8601_tmpl = ['YYYY-?MM-?DD', 'YYYY-0MM?-?DD', 'YYYY-MM', 'YYYY-?OOO',
                'YY-?MM-?DD', 'YY-?OOO', 'YYYY',
                '-YY-?MM', '-OOO', '-YY',
                '--MM-?DD', '--MM',
                '---DD',
                'CC', '']
_iso8601_re = [
    tmpl.replace(
    'YYYY', r'(?P<year>\d{4})').replace(
    'YY', r'(?P<year>\d\d)').replace(
    'MM', r'(?P<month>[01]\d)').replace(
    'DD', r'(?P<day>[0123]\d)').replace(
    'OOO', r'(?P<ordinal>[0123]\d\d)').replace(
    'CC', r'(?P<century>\d\d$)')
    + r'(T?(?P<hour>\d{2}):(?P<minute>\d{2})'
    + r'(:(?P<second>\d{2}))?'
    + r'(\.(?P<fracsecond>\d+))?'
    + r'(?P<tz>[+-](?P<tzhour>\d{2})(:(?P<tzmin>\d{2}))?|Z)?)?'
    for tmpl in _iso8601_tmpl]
try:
    del tmpl
except NameError:
    pass
_iso8601_matches = [re.compile(regex).match for regex in _iso8601_re]
try:
    del regex
except NameError:
    pass


def _parse_date_iso8601(dateString):
    '''Parse a variety of ISO-8601-compatible formats like 20040105'''
    m = None
    for _iso8601_match in _iso8601_matches:
        m = _iso8601_match(dateString)
        if m:
            break
    if not m:
        return
    if m.span() == (0, 0):
        return
    params = m.groupdict()
    ordinal = params.get('ordinal', 0)
    if ordinal:
        ordinal = int(ordinal)
    else:
        ordinal = 0
    year = params.get('year', '--')
    if not year or year == '--':
        year = time.gmtime()[0]
    elif len(year) == 2:
        # ISO 8601 assumes current century, i.e. 93 -> 2093, NOT 1993
        year = 100 * int(time.gmtime()[0] / 100) + int(year)
    else:
        year = int(year)
    month = params.get('month', '-')
    if not month or month == '-':
        # ordinals are NOT normalized by mktime, we simulate them
        # by setting month=1, day=ordinal
        if ordinal:
            month = 1
        else:
            month = time.gmtime()[1]
    month = int(month)
    day = params.get('day', 0)
    if not day:
        # see above
        if ordinal:
            day = ordinal
        elif params.get('century', 0) or \
                 params.get('year', 0) or params.get('month', 0):
            day = 1
        else:
            day = time.gmtime()[2]
    else:
        day = int(day)
    # special case of the century - is the first year of the 21st century
    # 2000 or 2001 ? The debate goes on...
    if 'century' in params.keys():
        year = (int(params['century']) - 1) * 100 + 1
    # in ISO 8601 most fields are optional
    for field in ['hour', 'minute', 'second', 'tzhour', 'tzmin']:
        if not params.get(field, None):
            params[field] = 0
    hour = int(params.get('hour', 0))
    minute = int(params.get('minute', 0))
    second = int(float(params.get('second', 0)))
    # weekday is normalized by mktime(), we can ignore it
    weekday = 0
    daylight_savings_flag = -1
    tm = [year, month, day, hour, minute, second, weekday,
          ordinal, daylight_savings_flag]
    # ISO 8601 time zone adjustments
    tz = params.get('tz')
    if tz and tz != 'Z':
        if tz[0] == '-':
            tm[3] += int(params.get('tzhour', 0))
            tm[4] += int(params.get('tzmin', 0))
        elif tz[0] == '+':
            tm[3] -= int(params.get('tzhour', 0))
            tm[4] -= int(params.get('tzmin', 0))
        else:
            return None
    # Python's time.mktime() is a wrapper around the ANSI C mktime(3c)
    # which is guaranteed to normalize d/m/y/h/m/s.
    # Many implementations have bugs, but we'll pretend they don't.
    return time.localtime(time.mktime(tuple(tm)))
registerDateHandler(_parse_date_iso8601)

# 8-bit date handling routines written by ytrewq1.
_korean_year = u'\ub144'  # b3e2 in euc-kr
_korean_month = u'\uc6d4'  # bff9 in euc-kr
_korean_day = u'\uc77c'  # c0cf in euc-kr
_korean_am = u'\uc624\uc804'  # bfc0 c0fc in euc-kr
_korean_pm = u'\uc624\ud6c4'  # bfc0 c8c4 in euc-kr

_korean_onblog_date_re = \
    re.compile('(\d{4})%s\s+(\d{2})%s\s+(\d{2})%s\s+(\d{2}):(\d{2}):(\d{2})' %
               (_korean_year, _korean_month, _korean_day))
_korean_nate_date_re = \
    re.compile(u'(\d{4})-(\d{2})-(\d{2})\s+(%s|%s)\s+(\d{,2}):(\d{,2}):(\d{,2})' %
               (_korean_am, _korean_pm))


def _parse_date_onblog(dateString):
    '''Parse a string according to the OnBlog 8-bit date format'''
    m = _korean_onblog_date_re.match(dateString)
    if not m:
        return
    w3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s:%(second)s%(zonediff)s' % \
                {'year': m.group(1), 'month': m.group(2), 'day': m.group(3),
                 'hour': m.group(4), 'minute': m.group(5), 'second': m.group(6),
                 'zonediff': '+09:00'}
    if _debug:
        sys.stderr.write('OnBlog date parsed as: %s\n' % w3dtfdate)
    return _parse_date_w3dtf(w3dtfdate)
registerDateHandler(_parse_date_onblog)


def _parse_date_nate(dateString):
    '''Parse a string according to the Nate 8-bit date format'''
    m = _korean_nate_date_re.match(dateString)
    if not m:
        return
    hour = int(m.group(5))
    ampm = m.group(4)
    if (ampm == _korean_pm):
        hour += 12
    hour = str(hour)
    if len(hour) == 1:
        hour = '0' + hour
    w3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s:%(second)s%(zonediff)s' % \
                {'year': m.group(1), 'month': m.group(2), 'day': m.group(3),
                 'hour': hour, 'minute': m.group(6), 'second': m.group(7),
                 'zonediff': '+09:00'}
    if _debug:
        sys.stderr.write('Nate date parsed as: %s\n' % w3dtfdate)
    return _parse_date_w3dtf(w3dtfdate)
registerDateHandler(_parse_date_nate)

_mssql_date_re = \
    re.compile('(\d{4})-(\d{2})-(\d{2})\s+(\d{2}):(\d{2}):(\d{2})(\.\d+)?')


def _parse_date_mssql(dateString):
    '''Parse a string according to the MS SQL date format'''
    m = _mssql_date_re.match(dateString)
    if not m:
        return
    w3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s:%(second)s%(zonediff)s' % \
                {'year': m.group(1), 'month': m.group(2), 'day': m.group(3),
                 'hour': m.group(4), 'minute': m.group(5), 'second': m.group(6),
                 'zonediff': '+09:00'}
    if _debug:
        sys.stderr.write('MS SQL date parsed as: %s\n' % w3dtfdate)
    return _parse_date_w3dtf(w3dtfdate)
registerDateHandler(_parse_date_mssql)

# Unicode strings for Greek date strings
_greek_months = \
  {
   u'\u0399\u03b1\u03bd': u'Jan',       # c9e1ed in iso-8859-7
   u'\u03a6\u03b5\u03b2': u'Feb',       # d6e5e2 in iso-8859-7
   u'\u039c\u03ac\u03ce': u'Mar',       # ccdcfe in iso-8859-7
   u'\u039c\u03b1\u03ce': u'Mar',       # cce1fe in iso-8859-7
   u'\u0391\u03c0\u03c1': u'Apr',       # c1f0f1 in iso-8859-7
   u'\u039c\u03ac\u03b9': u'May',       # ccdce9 in iso-8859-7
   u'\u039c\u03b1\u03ca': u'May',       # cce1fa in iso-8859-7
   u'\u039c\u03b1\u03b9': u'May',       # cce1e9 in iso-8859-7
   u'\u0399\u03bf\u03cd\u03bd': u'Jun',  # c9effded in iso-8859-7
   u'\u0399\u03bf\u03bd': u'Jun',       # c9efed in iso-8859-7
   u'\u0399\u03bf\u03cd\u03bb': u'Jul',  # c9effdeb in iso-8859-7
   u'\u0399\u03bf\u03bb': u'Jul',       # c9f9eb in iso-8859-7
   u'\u0391\u03cd\u03b3': u'Aug',       # c1fde3 in iso-8859-7
   u'\u0391\u03c5\u03b3': u'Aug',       # c1f5e3 in iso-8859-7
   u'\u03a3\u03b5\u03c0': u'Sep',       # d3e5f0 in iso-8859-7
   u'\u039f\u03ba\u03c4': u'Oct',       # cfeaf4 in iso-8859-7
   u'\u039d\u03bf\u03ad': u'Nov',       # cdefdd in iso-8859-7
   u'\u039d\u03bf\u03b5': u'Nov',       # cdefe5 in iso-8859-7
   u'\u0394\u03b5\u03ba': u'Dec',       # c4e5ea in iso-8859-7
  }

_greek_wdays = \
  {
   u'\u039a\u03c5\u03c1': u'Sun',  # caf5f1 in iso-8859-7
   u'\u0394\u03b5\u03c5': u'Mon',  # c4e5f5 in iso-8859-7
   u'\u03a4\u03c1\u03b9': u'Tue',  # d4f1e9 in iso-8859-7
   u'\u03a4\u03b5\u03c4': u'Wed',  # d4e5f4 in iso-8859-7
   u'\u03a0\u03b5\u03bc': u'Thu',  # d0e5ec in iso-8859-7
   u'\u03a0\u03b1\u03c1': u'Fri',  # d0e1f1 in iso-8859-7
   u'\u03a3\u03b1\u03b2': u'Sat',  # d3e1e2 in iso-8859-7
  }

_greek_date_format_re = \
    re.compile(u'([^,]+),\s+(\d{2})\s+([^\s]+)\s+(\d{4})\s+(\d{2}):(\d{2}):(\d{2})\s+([^\s]+)')


def _parse_date_greek(dateString):
    '''Parse a string according to a Greek 8-bit date format.'''
    m = _greek_date_format_re.match(dateString)
    if not m:
        return
    try:
        wday = _greek_wdays[m.group(1)]
        month = _greek_months[m.group(3)]
    except:
        return
    rfc822date = '%(wday)s, %(day)s %(month)s %(year)s %(hour)s:%(minute)s:%(second)s %(zonediff)s' % \
                 {'wday': wday, 'day': m.group(2), 'month': month, 'year': m.group(4),
                  'hour': m.group(5), 'minute': m.group(6), 'second': m.group(7),
                  'zonediff': m.group(8)}
    if _debug:
        sys.stderr.write('Greek date parsed as: %s\n' % rfc822date)
    return _parse_date_rfc822(rfc822date)
registerDateHandler(_parse_date_greek)

# Unicode strings for Hungarian date strings
_hungarian_months = \
  {
    u'janu\u00e1r': u'01',  # e1 in iso-8859-2
    u'febru\u00e1ri': u'02',  # e1 in iso-8859-2
    u'm\u00e1rcius': u'03',  # e1 in iso-8859-2
    u'\u00e1prilis': u'04',  # e1 in iso-8859-2
    u'm\u00e1ujus': u'05',  # e1 in iso-8859-2
    u'j\u00fanius': u'06',  # fa in iso-8859-2
    u'j\u00falius': u'07',  # fa in iso-8859-2
    u'augusztus': u'08',
    u'szeptember': u'09',
    u'okt\u00f3ber': u'10',  # f3 in iso-8859-2
    u'november': u'11',
    u'december': u'12',
  }

_hungarian_date_format_re = \
  re.compile(u'(\d{4})-([^-]+)-(\d{,2})T(\d{,2}):(\d{2})((\+|-)(\d{,2}:\d{2}))')


def _parse_date_hungarian(dateString):
    '''Parse a string according to a Hungarian 8-bit date format.'''
    m = _hungarian_date_format_re.match(dateString)
    if not m:
        return
    try:
        month = _hungarian_months[m.group(2)]
        day = m.group(3)
        if len(day) == 1:
            day = '0' + day
        hour = m.group(4)
        if len(hour) == 1:
            hour = '0' + hour
    except:
        return
    w3dtfdate = '%(year)s-%(month)s-%(day)sT%(hour)s:%(minute)s%(zonediff)s' % \
                {'year': m.group(1), 'month': month, 'day': day,
                 'hour': hour, 'minute': m.group(5),
                 'zonediff': m.group(6)}
    if _debug:
        sys.stderr.write('Hungarian date parsed as: %s\n' % w3dtfdate)
    return _parse_date_w3dtf(w3dtfdate)
registerDateHandler(_parse_date_hungarian)

# W3DTF-style date parsing adapted from PyXML xml.utils.iso8601, written by
# Drake and licensed under the Python license.  Removed all range checking
# for month, day, hour, minute, and second, since mktime will normalize
# these later


def _parse_date_w3dtf(dateString):
    def __extract_date(m):
        year = int(m.group('year'))
        if year < 100:
            year = 100 * int(time.gmtime()[0] / 100) + int(year)
        if year < 1000:
            return 0, 0, 0
        julian = m.group('julian')
        if julian:
            julian = int(julian)
            month = julian / 30 + 1
            day = julian % 30 + 1
            jday = None
            while jday != julian:
                t = time.mktime((year, month, day, 0, 0, 0, 0, 0, 0))
                jday = time.gmtime(t)[-2]
                diff = abs(jday - julian)
                if jday > julian:
                    if diff < day:
                        day = day - diff
                    else:
                        month = month - 1
                        day = 31
                elif jday < julian:
                    if day + diff < 28:
                        day = day + diff
                    else:
                        month = month + 1
            return year, month, day
        month = m.group('month')
        day = 1
        if month is None:
            month = 1
        else:
            month = int(month)
            day = m.group('day')
            if day:
                day = int(day)
            else:
                day = 1
        return year, month, day

    def __extract_time(m):
        if not m:
            return 0, 0, 0
        hours = m.group('hours')
        if not hours:
            return 0, 0, 0
        hours = int(hours)
        minutes = int(m.group('minutes'))
        seconds = m.group('seconds')
        if seconds:
            seconds = int(seconds)
        else:
            seconds = 0
        return hours, minutes, seconds

    def __extract_tzd(m):
        '''Return the Time Zone Designator as an offset in seconds from UTC.'''
        if not m:
            return 0
        tzd = m.group('tzd')
        if not tzd:
            return 0
        if tzd == 'Z':
            return 0
        hours = int(m.group('tzdhours'))
        minutes = m.group('tzdminutes')
        if minutes:
            minutes = int(minutes)
        else:
            minutes = 0
        offset = (hours * 60 + minutes) * 60
        if tzd[0] == '+':
            return -offset
        return offset

    __date_re = ('(?P<year>\d\d\d\d)'
                 '(?:(?P<dsep>-|)'
                 '(?:(?P<month>\d\d)(?:(?P=dsep)(?P<day>\d\d))?'
                 '|(?P<julian>\d\d\d)))?')
    __tzd_re = '(?P<tzd>[-+](?P<tzdhours>\d\d)(?::?(?P<tzdminutes>\d\d))|Z)'
    __tzd_rx = re.compile(__tzd_re)
    __time_re = ('(?P<hours>\d\d)(?P<tsep>:|)(?P<minutes>\d\d)'
                 '(?:(?P=tsep)(?P<seconds>\d\d)(?:[.,]\d+)?)?'
                 + __tzd_re)
    __datetime_re = '%s(?:T%s)?' % (__date_re, __time_re)
    __datetime_rx = re.compile(__datetime_re)
    m = __datetime_rx.match(dateString)
    if (m is None) or (m.group() != dateString):
        return
    gmt = __extract_date(m) + __extract_time(m) + (0, 0, 0)
    if gmt[0] == 0:
        return
    return time.gmtime(time.mktime(gmt) + __extract_tzd(m) - time.timezone)
registerDateHandler(_parse_date_w3dtf)


def _parse_date_rfc822(dateString):
    '''Parse an RFC822, RFC1123, RFC2822, or asctime-style date'''
    data = dateString.split()
    if data[0][-1] in (',', '.') or data[0].lower() in rfc822._daynames:
        del data[0]
    if len(data) == 4:
        s = data[3]
        i = s.find('+')
        if i > 0:
            data[3:] = [s[:i], s[i + 1:]]
        else:
            data.append('')
        dateString = " ".join(data)
    # Account for the Etc/GMT timezone by stripping 'Etc/'
    elif len(data) == 5 and data[4].lower().startswith('etc/'):
        data[4] = data[4][4:]
        dateString = " ".join(data)
    if len(data) < 5:
        dateString += ' 00:00:00 GMT'
    tm = rfc822.parsedate_tz(dateString)
    if tm:
        return time.gmtime(rfc822.mktime_tz(tm))
# rfc822.py defines several time zones, but we define some extra ones.
# 'ET' is equivalent to 'EST', etc.
_additional_timezones = {'AT': -400, 'ET': -500, 'CT': -600, 'MT': -700, 'PT': -800}
rfc822._timezones.update(_additional_timezones)
registerDateHandler(_parse_date_rfc822)


def _parse_date_perforce(aDateString):
    """parse a date in yyyy/mm/dd hh:mm:ss TTT format"""
    # Fri, 2006/09/15 08:19:53 EDT
    _my_date_pattern = re.compile(
        r'(\w{,3}), (\d{,4})/(\d{,2})/(\d{2}) (\d{,2}):(\d{2}):(\d{2}) (\w{,3})')

    dow, year, month, day, hour, minute, second, tz = \
        _my_date_pattern.search(aDateString).groups()
    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    dateString = "%s, %s %s %s %s:%s:%s %s" % (dow, day, months[int(month) - 1], year, hour, minute, second, tz)
    tm = rfc822.parsedate_tz(dateString)
    if tm:
        return time.gmtime(rfc822.mktime_tz(tm))
registerDateHandler(_parse_date_perforce)


def _parse_date(dateString):
    '''Parses a variety of date formats into a 9-tuple in GMT'''
    for handler in _date_handlers:
        try:
            date9tuple = handler(dateString)
            if not date9tuple:
                continue
            if len(date9tuple) != 9:
                if _debug:
                    sys.stderr.write('date handler function must return 9-tuple\n')
                raise ValueError
            map(int, date9tuple)
            return date9tuple
        except Exception as e:
            if _debug:
                sys.stderr.write('%s raised %s\n' % (handler.__name__, repr(e)))
            pass
    return None


def _getCharacterEncoding(http_headers, xml_data):
    '''Get the character encoding of the XML document

    http_headers is a dictionary
    xml_data is a raw string (not Unicode)

    This is so much trickier than it sounds, it's not even funny.
    According to RFC 3023 ('XML Media Types'), if the HTTP Content-Type
    is application/xml, application/*+xml,
    application/xml-external-parsed-entity, or application/xml-dtd,
    the encoding given in the charset parameter of the HTTP Content-Type
    takes precedence over the encoding given in the XML prefix within the
    document, and defaults to 'utf-8' if neither are specified.  But, if
    the HTTP Content-Type is text/xml, text/*+xml, or
    text/xml-external-parsed-entity, the encoding given in the XML prefix
    within the document is ALWAYS IGNORED and only the encoding given in
    the charset parameter of the HTTP Content-Type header should be
    respected, and it defaults to 'us-ascii' if not specified.

    Furthermore, discussion on the atom-syntax mailing list with the
    author of RFC 3023 leads me to the conclusion that any document
    served with a Content-Type of text/* and no charset parameter
    must be treated as us-ascii.  (We now do this.)  And also that it
    must always be flagged as non-well-formed.  (We now do this too.)

    If Content-Type is unspecified (input was local file or non-HTTP source)
    or unrecognized (server just got it totally wrong), then go by the
    encoding given in the XML prefix of the document and default to
    'iso-8859-1' as per the HTTP specification (RFC 2616).

    Then, assuming we didn't find a character encoding in the HTTP headers
    (and the HTTP Content-type allowed us to look in the body), we need
    to sniff the first few bytes of the XML data and try to determine
    whether the encoding is ASCII-compatible.  Section F of the XML
    specification shows the way here:
    http://www.w3.org/TR/REC-xml/#sec-guessing-no-ext-info

    If the sniffed encoding is not ASCII-compatible, we need to make it
    ASCII compatible so that we can sniff further into the XML declaration
    to find the encoding attribute, which will tell us the true encoding.

    Of course, none of this guarantees that we will be able to parse the
    feed in the declared character encoding (assuming it was declared
    correctly, which many are not).  CJKCodecs and iconv_codec help a lot;
    you should definitely install them if you can.
    http://cjkpython.i18n.org/
    '''

    def _parseHTTPContentType(content_type):
        '''takes HTTP Content-Type header and returns (content type, charset)

        If no charset is specified, returns (content type, '')
        If no content type is specified, returns ('', '')
        Both return parameters are guaranteed to be lowercase strings
        '''
        content_type = content_type or ''
        content_type, params = cgi.parse_header(content_type)
        return content_type, params.get('charset', '').replace("'", '')

    sniffed_xml_encoding = ''
    xml_encoding = ''
    true_encoding = ''
    http_content_type, http_encoding = _parseHTTPContentType(http_headers.get('content-type', http_headers.get('Content-type')))
    # Must sniff for non-ASCII-compatible character encodings before
    # searching for XML declaration.  This heuristic is defined in
    # section F of the XML specification:
    # http://www.w3.org/TR/REC-xml/#sec-guessing-no-ext-info
    try:
        if xml_data[:4] == _l2bytes([0x4c, 0x6f, 0xa7, 0x94]):
            # EBCDIC
            xml_data = _ebcdic_to_ascii(xml_data)
        elif xml_data[:4] == _l2bytes([0x00, 0x3c, 0x00, 0x3f]):
            # UTF-16BE
            sniffed_xml_encoding = 'utf-16be'
            xml_data = unicode(xml_data, 'utf-16be').encode('utf-8')
        elif (len(xml_data) >= 4) and (xml_data[:2] == _l2bytes([0xfe, 0xff])) and (xml_data[2:4] != _l2bytes([0x00, 0x00])):
            # UTF-16BE with BOM
            sniffed_xml_encoding = 'utf-16be'
            xml_data = unicode(xml_data[2:], 'utf-16be').encode('utf-8')
        elif xml_data[:4] == _l2bytes([0x3c, 0x00, 0x3f, 0x00]):
            # UTF-16LE
            sniffed_xml_encoding = 'utf-16le'
            xml_data = unicode(xml_data, 'utf-16le').encode('utf-8')
        elif (len(xml_data) >= 4) and (xml_data[:2] == _l2bytes([0xff, 0xfe])) and (xml_data[2:4] != _l2bytes([0x00, 0x00])):
            # UTF-16LE with BOM
            sniffed_xml_encoding = 'utf-16le'
            xml_data = unicode(xml_data[2:], 'utf-16le').encode('utf-8')
        elif xml_data[:4] == _l2bytes([0x00, 0x00, 0x00, 0x3c]):
            # UTF-32BE
            sniffed_xml_encoding = 'utf-32be'
            xml_data = unicode(xml_data, 'utf-32be').encode('utf-8')
        elif xml_data[:4] == _l2bytes([0x3c, 0x00, 0x00, 0x00]):
            # UTF-32LE
            sniffed_xml_encoding = 'utf-32le'
            xml_data = unicode(xml_data, 'utf-32le').encode('utf-8')
        elif xml_data[:4] == _l2bytes([0x00, 0x00, 0xfe, 0xff]):
            # UTF-32BE with BOM
            sniffed_xml_encoding = 'utf-32be'
            xml_data = unicode(xml_data[4:], 'utf-32be').encode('utf-8')
        elif xml_data[:4] == _l2bytes([0xff, 0xfe, 0x00, 0x00]):
            # UTF-32LE with BOM
            sniffed_xml_encoding = 'utf-32le'
            xml_data = unicode(xml_data[4:], 'utf-32le').encode('utf-8')
        elif xml_data[:3] == _l2bytes([0xef, 0xbb, 0xbf]):
            # UTF-8 with BOM
            sniffed_xml_encoding = 'utf-8'
            xml_data = unicode(xml_data[3:], 'utf-8').encode('utf-8')
        else:
            # ASCII-compatible
            pass
        xml_encoding_match = re.compile(_s2bytes('^<\?.*encoding=[\'"](.*?)[\'"].*\?>')).match(xml_data)
    except:
        xml_encoding_match = None
    if xml_encoding_match:
        xml_encoding = xml_encoding_match.groups()[0].decode('utf-8').lower()
        if sniffed_xml_encoding and (xml_encoding in ('iso-10646-ucs-2', 'ucs-2', 'csunicode', 'iso-10646-ucs-4', 'ucs-4', 'csucs4', 'utf-16', 'utf-32', 'utf_16', 'utf_32', 'utf16', 'u16')):
            xml_encoding = sniffed_xml_encoding
    acceptable_content_type = 0
    application_content_types = ('application/xml', 'application/xml-dtd', 'application/xml-external-parsed-entity')
    text_content_types = ('text/xml', 'text/xml-external-parsed-entity')
    if (http_content_type in application_content_types) or \
       (http_content_type.startswith('application/') and http_content_type.endswith('+xml')):
        acceptable_content_type = 1
        true_encoding = http_encoding or xml_encoding or 'utf-8'
    elif (http_content_type in text_content_types) or \
         (http_content_type.startswith('text/')) and http_content_type.endswith('+xml'):
        acceptable_content_type = 1
        true_encoding = http_encoding or 'us-ascii'
    elif http_content_type.startswith('text/'):
        true_encoding = http_encoding or 'us-ascii'
    elif http_headers and (not ('content-type' in http_headers or 'Content-type' in http_headers)):
        true_encoding = xml_encoding or 'iso-8859-1'
    else:
        true_encoding = xml_encoding or 'utf-8'
    # some feeds claim to be gb2312 but are actually gb18030.
    # apparently MSIE and Firefox both do the following switch:
    if true_encoding.lower() == 'gb2312':
        true_encoding = 'gb18030'
    return true_encoding, http_encoding, xml_encoding, sniffed_xml_encoding, acceptable_content_type


def _toUTF8(data, encoding):
    '''Changes an XML data stream on the fly to specify a new encoding

    data is a raw sequence of bytes (not Unicode) that is presumed to be in %encoding already
    encoding is a string recognized by encodings.aliases
    '''
    if _debug:
        sys.stderr.write('entering _toUTF8, trying encoding %s\n' % encoding)
    # strip Byte Order Mark (if present)
    if (len(data) >= 4) and (data[:2] == _l2bytes([0xfe, 0xff])) and (data[2:4] != _l2bytes([0x00, 0x00])):
        if _debug:
            sys.stderr.write('stripping BOM\n')
            if encoding != 'utf-16be':
                sys.stderr.write('trying utf-16be instead\n')
        encoding = 'utf-16be'
        data = data[2:]
    elif (len(data) >= 4) and (data[:2] == _l2bytes([0xff, 0xfe])) and (data[2:4] != _l2bytes([0x00, 0x00])):
        if _debug:
            sys.stderr.write('stripping BOM\n')
            if encoding != 'utf-16le':
                sys.stderr.write('trying utf-16le instead\n')
        encoding = 'utf-16le'
        data = data[2:]
    elif data[:3] == _l2bytes([0xef, 0xbb, 0xbf]):
        if _debug:
            sys.stderr.write('stripping BOM\n')
            if encoding != 'utf-8':
                sys.stderr.write('trying utf-8 instead\n')
        encoding = 'utf-8'
        data = data[3:]
    elif data[:4] == _l2bytes([0x00, 0x00, 0xfe, 0xff]):
        if _debug:
            sys.stderr.write('stripping BOM\n')
            if encoding != 'utf-32be':
                sys.stderr.write('trying utf-32be instead\n')
        encoding = 'utf-32be'
        data = data[4:]
    elif data[:4] == _l2bytes([0xff, 0xfe, 0x00, 0x00]):
        if _debug:
            sys.stderr.write('stripping BOM\n')
            if encoding != 'utf-32le':
                sys.stderr.write('trying utf-32le instead\n')
        encoding = 'utf-32le'
        data = data[4:]
    newdata = unicode(data, encoding)
    if _debug:
        sys.stderr.write('successfully converted %s data to unicode\n' % encoding)
    declmatch = re.compile('^<\?xml[^>]*?>')
    newdecl = '''<?xml version='1.0' encoding='utf-8'?>'''
    if declmatch.search(newdata):
        newdata = declmatch.sub(newdecl, newdata)
    else:
        newdata = newdecl + u'\n' + newdata
    return newdata.encode('utf-8')


def _stripDoctype(data):
    '''Strips DOCTYPE from XML document, returns (rss_version, stripped_data)

    rss_version may be 'rss091n' or None
    stripped_data is the same XML document, minus the DOCTYPE
    '''
    start = re.search(_s2bytes('<\w'), data)
    start = start and start.start() or -1
    head, data = data[:start + 1], data[start +1:]

    entity_pattern = re.compile(_s2bytes(r'^\s*<!ENTITY([^>]*?)>'), re.MULTILINE)
    entity_results = entity_pattern.findall(head)
    head = entity_pattern.sub(_s2bytes(''), head)
    doctype_pattern = re.compile(_s2bytes(r'^\s*<!DOCTYPE([^>]*?)>'), re.MULTILINE)
    doctype_results = doctype_pattern.findall(head)
    doctype = doctype_results and doctype_results[0] or _s2bytes('')
    if doctype.lower().count(_s2bytes('netscape')):
        version = 'rss091n'
    else:
        version = None

    # only allow in 'safe' inline entity definitions
    replacement = _s2bytes('')
    if len(doctype_results) == 1 and entity_results:
        safe_pattern = re.compile(_s2bytes('\s+(\w+)\s+"(&#\w+;|[^&"]*)"'))
        safe_entities = filter(lambda e: safe_pattern.match(e), entity_results)
        if safe_entities:
            replacement = _s2bytes('<!DOCTYPE feed [\n  <!ENTITY') + _s2bytes('>\n  <!ENTITY ').join(safe_entities) + _s2bytes('>\n]>')
    data = doctype_pattern.sub(replacement, head) + data

    return version, data, dict(replacement and [(k.decode('utf-8'), v.decode('utf-8')) for k, v in safe_pattern.findall(replacement)])


def parse(url_file_stream_or_string, etag=None, modified=None, agent=None, referrer=None, handlers=[], request_headers={}, response_headers={}):
    '''Parse a feed from a URL, file, stream, or string.

    request_headers, if given, is a dict from http header name to value to add
    to the request; this overrides internally generated values.
    '''
    result = FeedParserDict()
    result['feed'] = FeedParserDict()
    result['entries'] = []
    if _XML_AVAILABLE:
        result['bozo'] = 0
    if not isinstance(handlers, list):
        handlers = [handlers]
    try:
        f = _open_resource(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers)
        data = f.read()
    except Exception as e:
        result['bozo'] = 1
        result['bozo_exception'] = e
        data = None
        f = None

    if hasattr(f, 'headers'):
        result['headers'] = dict(f.headers)
    # overwrite existing headers using response_headers
    if 'headers' in result:
        result['headers'].update(response_headers)
    elif response_headers:
        result['headers'] = copy.deepcopy(response_headers)

    # if feed is gzip-compressed, decompress it
    if f and data and 'headers' in result:
        if gzip and result['headers'].get('content-encoding') == 'gzip':
            try:
                data = gzip.GzipFile(fileobj=_StringIO(data)).read()
            except Exception as e:
                # Some feeds claim to be gzipped but they're not, so
                # we get garbage.  Ideally, we should re-request the
                # feed without the 'Accept-encoding: gzip' header,
                # but we don't.
                result['bozo'] = 1
                result['bozo_exception'] = e
                data = ''
        elif zlib and result['headers'].get('content-encoding') == 'deflate':
            try:
                data = zlib.decompress(data, -zlib.MAX_WBITS)
            except Exception as e:
                result['bozo'] = 1
                result['bozo_exception'] = e
                data = ''

    # save HTTP headers
    if 'headers' in result:
        if 'etag' in result['headers'] or 'ETag' in result['headers']:
            etag = result['headers'].get('etag', result['headers'].get('ETag'))
            if etag:
                result['etag'] = etag
        if 'last-modified' in result['headers'] or 'Last-Modified' in result['headers']:
            modified = result['headers'].get('last-modified', result['headers'].get('Last-Modified'))
            if modified:
                result['modified'] = _parse_date(modified)
    if hasattr(f, 'url'):
        result['href'] = f.url
        result['status'] = 200
    if hasattr(f, 'status'):
        result['status'] = f.status
    if hasattr(f, 'close'):
        f.close()

    # there are four encodings to keep track of:
    # - http_encoding is the encoding declared in the Content-Type HTTP header
    # - xml_encoding is the encoding declared in the <?xml declaration
    # - sniffed_encoding is the encoding sniffed from the first 4 bytes of the XML data
    # - result['encoding'] is the actual encoding, as per RFC 3023 and a variety of other conflicting specifications
    http_headers = result.get('headers', {})
    result['encoding'], http_encoding, xml_encoding, sniffed_xml_encoding, acceptable_content_type = \
        _getCharacterEncoding(http_headers, data)
    if http_headers and (not acceptable_content_type):
        if 'content-type' in http_headers or 'Content-type' in http_headers:
            bozo_message = '%s is not an XML media type' % http_headers.get('content-type', http_headers.get('Content-type'))
        else:
            bozo_message = 'no Content-type specified'
        result['bozo'] = 1
        result['bozo_exception'] = NonXMLContentType(bozo_message)

    if data is not None:
        result['version'], data, entities = _stripDoctype(data)

    # ensure that baseuri is an absolute uri using an acceptable URI scheme
    contentloc = http_headers.get('content-location', http_headers.get('Content-Location', ''))
    href = result.get('href', '')
    baseuri = _makeSafeAbsoluteURI(href, contentloc) or _makeSafeAbsoluteURI(contentloc) or href

    baselang = http_headers.get('content-language', http_headers.get('Content-Language', None))

    # if server sent 304, we're done
    if result.get('status', 0) == 304:
        result['version'] = ''
        result['debug_message'] = 'The feed has not changed since you last checked, ' + \
            'so the server sent no data.  This is a feature, not a bug!'
        return result

    # if there was a problem downloading, we're done
    if data is None:
        return result

    # determine character encoding
    use_strict_parser = 0
    known_encoding = 0
    tried_encodings = []
    # try: HTTP encoding, declared XML encoding, encoding sniffed from BOM
    for proposed_encoding in (result['encoding'], xml_encoding, sniffed_xml_encoding):
        if not proposed_encoding:
            continue
        if proposed_encoding in tried_encodings:
            continue
        tried_encodings.append(proposed_encoding)
        try:
            data = _toUTF8(data, proposed_encoding)
            known_encoding = use_strict_parser = 1
            break
        except:
            pass
    # if no luck and we have auto-detection library, try that
    if (not known_encoding) and chardet:
        try:
            proposed_encoding = chardet.detect(data)['encoding']
            if proposed_encoding and (proposed_encoding not in tried_encodings):
                tried_encodings.append(proposed_encoding)
                data = _toUTF8(data, proposed_encoding)
                known_encoding = use_strict_parser = 1
        except:
            pass
    # if still no luck and we haven't tried utf-8 yet, try that
    if (not known_encoding) and ('utf-8' not in tried_encodings):
        try:
            proposed_encoding = 'utf-8'
            tried_encodings.append(proposed_encoding)
            data = _toUTF8(data, proposed_encoding)
            known_encoding = use_strict_parser = 1
        except:
            pass
    # if still no luck and we haven't tried windows-1252 yet, try that
    if (not known_encoding) and ('windows-1252' not in tried_encodings):
        try:
            proposed_encoding = 'windows-1252'
            tried_encodings.append(proposed_encoding)
            data = _toUTF8(data, proposed_encoding)
            known_encoding = use_strict_parser = 1
        except:
            pass
    # if still no luck and we haven't tried iso-8859-2 yet, try that.
    if (not known_encoding) and ('iso-8859-2' not in tried_encodings):
        try:
            proposed_encoding = 'iso-8859-2'
            tried_encodings.append(proposed_encoding)
            data = _toUTF8(data, proposed_encoding)
            known_encoding = use_strict_parser = 1
        except:
            pass
    # if still no luck, give up
    if not known_encoding:
        result['bozo'] = 1
        result['bozo_exception'] = CharacterEncodingUnknown(
            'document encoding unknown, I tried ' +
            '%s, %s, utf-8, windows-1252, and iso-8859-2 but nothing worked' %
            (result['encoding'], xml_encoding))
        result['encoding'] = ''
    elif proposed_encoding != result['encoding']:
        result['bozo'] = 1
        result['bozo_exception'] = CharacterEncodingOverride(
            'document declared as %s, but parsed as %s' %
            (result['encoding'], proposed_encoding))
        result['encoding'] = proposed_encoding

    if not _XML_AVAILABLE:
        use_strict_parser = 0
    if use_strict_parser:
        # initialize the SAX parser
        feedparser = _StrictFeedParser(baseuri, baselang, 'utf-8')
        saxparser = xml.sax.make_parser(PREFERRED_XML_PARSERS)
        saxparser.setFeature(xml.sax.handler.feature_namespaces, 1)
        saxparser.setContentHandler(feedparser)
        saxparser.setErrorHandler(feedparser)
        source = xml.sax.xmlreader.InputSource()
        source.setByteStream(_StringIO(data))
        if hasattr(saxparser, '_ns_stack'):
            # work around bug in built-in SAX parser (doesn't recognize xml: namespace)
            # PyXML doesn't have this problem, and it doesn't have _ns_stack either
            saxparser._ns_stack.append({'http://www.w3.org/XML/1998/namespace': 'xml'})
        try:
            saxparser.parse(source)
        except Exception as e:
            if _debug:
                import traceback
                traceback.print_stack()
                traceback.print_exc()
                sys.stderr.write('xml parsing failed\n')
            result['bozo'] = 1
            result['bozo_exception'] = feedparser.exc or e
            use_strict_parser = 0
    if not use_strict_parser:
        feedparser = _LooseFeedParser(baseuri, baselang, 'utf-8', entities)
        feedparser.feed(data.decode('utf-8', 'replace'))
    result['feed'] = feedparser.feeddata
    result['entries'] = feedparser.entries
    result['version'] = result['version'] or feedparser.version
    result['namespaces'] = feedparser.namespacesInUse
    return result


class Serializer:

    def __init__(self, results):
        self.results = results


class TextSerializer(Serializer):

    def write(self, stream=sys.stdout):
        self._writer(stream, self.results, '')

    def _writer(self, stream, node, prefix):
        if not node:
            return
        if hasattr(node, 'keys'):
            keys = sorted(node.keys())
            for k in keys:
                if k in ('description', 'link'):
                    continue
                if k + '_detail' in node:
                    continue
                if k + '_parsed' in node:
                    continue
                self._writer(stream, node[k], prefix + k + '.')
        elif isinstance(node, list):
            index = 0
            for n in node:
                self._writer(stream, n, prefix[:-1] + '[' + str(index) + '].')
                index += 1
        else:
            try:
                s = str(node).encode('utf-8')
                s = s.replace('\\', '\\\\')
                s = s.replace('\r', '')
                s = s.replace('\n', r'\n')
                stream.write(prefix[:-1])
                stream.write('=')
                stream.write(s)
                stream.write('\n')
            except:
                pass


class PprintSerializer(Serializer):

    def write(self, stream=sys.stdout):
        if 'href' in self.results:
            stream.write(self.results['href'] + '\n\n')
        from pprint import pprint
        pprint(self.results, stream)
        stream.write('\n')

if __name__ == '__main__':
    try:
        from optparse import OptionParser
    except:
        OptionParser = None

    if OptionParser:
        optionParser = OptionParser(version=__version__, usage="%prog [options] url_or_filename_or_-")
        optionParser.set_defaults(format="pprint")
        optionParser.add_option("-A", "--user-agent", dest="agent", metavar="AGENT", help="User-Agent for HTTP URLs")
        optionParser.add_option("-e", "--referer", "--referrer", dest="referrer", metavar="URL", help="Referrer for HTTP URLs")
        optionParser.add_option("-t", "--etag", dest="etag", metavar="TAG", help="ETag/If-None-Match for HTTP URLs")
        optionParser.add_option("-m", "--last-modified", dest="modified", metavar="DATE", help="Last-modified/If-Modified-Since for HTTP URLs (any supported date format)")
        optionParser.add_option("-f", "--format", dest="format", metavar="FORMAT", help="output results in FORMAT (text, pprint)")
        optionParser.add_option("-v", "--verbose", action="store_true", dest="verbose", default=False, help="write debugging information to stderr")
        (options, urls) = optionParser.parse_args()
        if options.verbose:
            _debug = 1
        if not urls:
            optionParser.print_help()
            sys.exit(0)
    else:
        if not sys.argv[1:]:
            logger.info(repr(__doc__))
            sys.exit(0)

        class _Options:
            etag = modified = agent = referrer = None
            format = 'pprint'
        options = _Options()
        urls = sys.argv[1:]

    zopeCompatibilityHack()

    serializer = globals().get(options.format.capitalize() + 'Serializer', Serializer)
    for url in urls:
        results = parse(url, etag=options.etag, modified=options.modified, agent=options.agent, referrer=options.referrer)
        serializer(results).write(sys.stdout)

########NEW FILE########
__FILENAME__ = rssparser
# Written by Niels Zeilemaker

import os
import sha
import time
import re
import logging
from copy import deepcopy
from shutil import copyfile
from urlparse import urlparse
import imghdr
import tempfile
from traceback import print_exc
from threading import Thread, RLock, Event

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Utilities.timeouturlopen import urlOpenTimeout
from Tribler.Core.Utilities.bencode import bdecode
from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler

try:
    from Tribler.Main.Utility.Feeds import feedparser
except:
    import feedparser  # Feedparser is installed as a package in ubuntu

URLHIST_TIMEOUT = 7 * 24 * 3600.0  # Don't revisit links for this time
RSS_RELOAD_FREQUENCY = 30 * 60  # reload a rss source every n seconds
RSS_CHECK_FREQUENCY = 2  # test a potential .torrent in a rss source every n seconds


class RssParser(Thread):
    __single = None

    def __init__(self):
        if RssParser.__single:
            raise RuntimeError("RssParser is singleton")
        RssParser.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        Thread.__init__(self)
        name = "RssParser" + self.getName()
        self.setName(name)
        self.setDaemon(True)

        self.key_url_lock = RLock()
        self.key_url = {}

        self.key_callbacks = {}

        self.urls_changed = Event()
        self.rss_parser = RSSFeedParser()
        self.url_resourceretriever = URLResourceRetriever()
        self.isRegistered = False

    def getInstance(*args, **kw):
        if RssParser.__single is None:
            RssParser(*args, **kw)
        return RssParser.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        RssParser.__single = None
    delInstance = staticmethod(delInstance)

    def register(self, session, defaultkey):
        if not self.isRegistered:
            self.session = session
            self.defaultkey = defaultkey
            self.remote_th = RemoteTorrentHandler.getInstance()

            dirname = self.getdir()
            if not os.path.exists(dirname):
                os.makedirs(dirname)

            # read any rss feeds that are currently outstanding
            self.readfile()

            self.isRegistered = True
        else:
            self._logger.debug("RssParser is already registered, ignoring")

    def getdir(self):
        return os.path.join(self.session.get_state_dir(), "subscriptions")

    def getfilename(self):
        return os.path.join(self.getdir(), "subscriptions.txt")

    def gethistfilename(self, url, key):
        h = sha.sha(url).hexdigest()

        histfile = os.path.join(self.getdir(), "%s-%s.txt" % (h, key))
        oldhistfile = os.path.join(self.getdir(), h + '.txt')

        if not os.path.exists(histfile):
            # upgrade...
            if os.path.exists(oldhistfile):
                copyfile(oldhistfile, histfile)

        return histfile

    def readfile(self):
        try:
            filename = self.getfilename()
            f = open(filename, "rb")
            for line in f.readlines():

                parts = line.split()
                if len(parts) > 1:
                    state = parts[0]
                    url = parts[1]

                    if len(parts) > 2:
                        key = int(parts[2])
                    else:
                        key = self.defaultkey

                    if state == 'active':
                        self.addURL(url, key, dowrite=False)
                else:
                    self._logger.info("RssParser: Ignoring line %s", line)
            f.close()
        except:
            self._logger.debug("RssParser: subscriptions.txt does not yet exist")

    def writefile(self):
        filename = self.getfilename()
        f = open(filename, "wb")

        for channel_id, urls in self.key_url.iteritems():
            for url in urls:
                f.write('active %s %d\r\n' % (url, channel_id))
        f.close()

    def addURL(self, url, key, dowrite=True):
        try:
            self.key_url_lock.acquire()

            channel_feeds = self.key_url.setdefault(key, set())

            if url not in channel_feeds:
                channel_feeds.add(url)
                self.urls_changed.set()

            if dowrite:
                self.writefile()

            self.doStart()
        finally:
            self.key_url_lock.release()

    def deleteURL(self, url, key):
        try:
            self.key_url_lock.acquire()

            channel_feeds = self.key_url.setdefault(key, set())

            if url in channel_feeds:
                channel_feeds.remove(url)
                self.urls_changed.set()

            self.writefile()
        except:
            pass
        finally:
            self.key_url_lock.release()

    def addCallback(self, key, callback):
        self.key_callbacks.setdefault(key, set()).add(callback)

        self.doStart()

    def getUrls(self, key):
        return list(self.key_url.get(key, set()))

    def doRefresh(self):
        self._logger.debug("RssParser: refresh")

        self.doStart()

    def doStart(self):
        if not self.isAlive():
            if len(self.key_url) and len(self.key_callbacks):
                self.start()
        else:
            self.urls_changed.set()

    def run(self):
        self.urls_changed.wait(60)  # Let other Tribler components, in particular, Session startup

        while self.isRegistered and len(self.key_url) and len(self.key_callbacks):
            self._logger.debug("RssParser: running")

            self._refresh()
            if not self.isRegistered:
                break

            self.urls_changed.clear()
            self._logger.debug("RssParser: finished, waiting %s", RSS_RELOAD_FREQUENCY)
            self.urls_changed.wait(RSS_RELOAD_FREQUENCY)
        else:
            self._logger.debug("RssParser: not registered unable to run or exiting")

    def shutdown(self):
        self.isRegistered = False
        self.urls_changed.set()

    def _refresh(self):
        channel_url = None
        with self.key_url_lock:
            channel_url = deepcopy(self.key_url)

        if channel_url:
            for key, urls in channel_url.iteritems():
                if key in self.key_callbacks:
                    for url in urls:
                        self._logger.debug(u"Getting rss %s", url)

                        historyfile = self.gethistfilename(url, key)
                        urls_already_seen = URLHistory(historyfile)
                        urls_already_seen.read()

                        for title, description, url_list in self.rss_parser.parse(url):
                            tempdir = tempfile.mkdtemp()
                            self._logger.debug(u"-------------------")
                            self._logger.debug(u"TEMPDIR %s for [%s]", tempdir, title)
                            try:
                                torrent_list, image_list, useless_url_list = \
                                    self.url_resourceretriever.retrieve(url_list, tempdir, urls_already_seen)
                            except:
                                self._logger.exception(u"Failed to retrieve data.")
                                continue

                            for useless_url in useless_url_list:
                                urls_already_seen.add(useless_url)
                            urls_already_seen.write()

                            # call callback for everything valid torrent
                            for torrent_url, torrent in torrent_list:
                                urls_already_seen.add(torrent_url)
                                urls_already_seen.write()

                                def processCallbacks(key, torrent, extra_info):
                                    for callback in self.key_callbacks[key]:
                                        try:
                                            callback(key, torrent, extraInfo=extra_info)
                                        except:
                                            self._logger.exception(u"Failed to process torrent callback.")

                                extra_info = {'title': title,
                                    'description': description,
                                    'thumbnail-tempdir': tempdir,
                                    'thumbnail-file-list': [image_path for image_url, image_path in image_list]}
                                if self.remote_th.is_registered():
                                    callback = lambda key = key, torrent=torrent, extra_info=extra_info: processCallbacks(key, torrent, extra_info)
                                    self.remote_th.save_torrent(torrent, callback)
                                else:
                                    processCallbacks(key, torrent, extra_info)

                                time.sleep(RSS_CHECK_FREQUENCY)

                                # Should we stop?
                                if not self.isRegistered:
                                    return

class URLResourceRetriever(object):

    def __init__(self):
        super(URLResourceRetriever, self).__init__()
        self._logger = logging.getLogger(self.__class__.__name__)

    def retrieve(self, url_list, work_dir, urls_already_seen):
        """Retrieves and identifies resources from a list of URLs.
        It returns a list of identified URL and file pair, including:
          (1) .torrent (URL, torrent object)
          (2) pictures (URL, picture-file-path)
        """
        torrent_list = []
        image_list = []
        useless_url_list = []
        image_count = 1
        for url in url_list:
            if urls_already_seen.contains(url):
                self._logger.debug(u"Skip, URL already seen [%s]", url)
                continue

            # download the thing
            stream = None
            self._logger.debug(u"Trying to download [%s]", url)
            try:
                referer = urlparse(url)
                referer = referer.scheme + "://" + referer.netloc + "/"
                stream = urlOpenTimeout(url, referer=referer)
                data = stream.read()
            except:
                self._logger.exception(u"Could not download %s", url)
                useless_url_list.append(url)
                continue
            finally:
                if stream:
                    stream.close()

            self._logger.debug(u"Trying to save [%s]", url)
            tmp_file = None
            tmp_path = None
            try:
                tmp_file_no, tmp_path = tempfile.mkstemp(dir=work_dir)
                tmp_file = os.fdopen(tmp_file_no, 'wb')
                tmp_file.write(data)
            except:
                self._logger.exception(u"Could not save %s -> %s", url, tmp_path)
                continue
            finally:
                if tmp_file:
                    tmp_file.close()

            # check if it is an image
            self._logger.debug(u"Trying to do image check [%s] [%s]", url, tmp_path)
            image_result = self.__try_image(tmp_path, work_dir, image_count)
            if image_result:
                self._logger.debug(u"Got image %s -> %s", url, image_result)
                image_list.append((url, image_result))
                image_count += 1
                continue

            # check if it is a torrent file
            self._logger.debug(u"Trying to do torrent check [%s] [%s]", url, tmp_path)
            torrent_result = self.__try_torrent(tmp_path)
            if torrent_result:
                self._logger.debug(u"Got torrent %s", url)
                torrent_list.append((url, torrent_result))
                os.remove(tmp_path)
                continue

            # useless URL
            self._logger.debug(u"Useless URL %s", url)
            useless_url_list.append(url)
            if tmp_path:
                self._logger.debug(u"Remove file %s", tmp_path)
                os.remove(tmp_path)

        return torrent_list, image_list, useless_url_list

    def __try_image(self, filepath, work_dir, image_count):
        """Checks if a file is an image. If it is an image, the file will be
           renamed with extension and the new file path will be returned.
           Otherwise, the file will be removed.
        """
        image_type = imghdr.what(filepath)
        if image_type:
            # rename the file
            old_filepath = filepath
            new_filename = u"thumbnail-%d.%s" % (image_count, image_type)
            new_filepath = os.path.join(work_dir, new_filename)
            os.rename(old_filepath, new_filepath)

            return new_filepath
        else:
            return None

    def __try_torrent(self, filepath):
        """Checks if a file is a torrent. If it is a torrent, returns the
           parsed torrent.
        """
        filestream = None
        try:
            filestream = open(filepath, 'rb')
            data = filestream.read()
            bddata = bdecode(data, 1)
            return TorrentDef._create(bddata)
        except:
            return None
        finally:
            if filestream:
                filestream.close()

class RSSFeedParser(object):

    def __init__(self):
        super(RSSFeedParser, self).__init__()
        self._logger = logging.getLogger(self.__class__.__name__)

    def __parse_html(self, content):
        """Parses an HTML content and find links.
        """
        if content is None:
            return None
        url_set = set()

        a_list = re.findall(r'<a.+href=[\'"]?([^\'" >]+)', content)
        for a_href in a_list:
            url_set.add(a_href)

        img_list = re.findall(r'<img.+src=[\'"]?([^\'" >]+)', content)
        for img_src in img_list:
            url_set.add(img_src)

        return url_set

    def __html2plaintext(self, html_content):
        """Converts an HTML document to plain text.
        """
        content = html_content.replace('\r\n', '\n')

        content = re.sub('<br[ \t\r\n\v\f]*.*/>', '\n', content)
        content = re.sub('<p[ \t\r\n\v\f]*.*/>', '\n', content)

        content = re.sub('<p>', '', content)
        content = re.sub('</p>', '\n', content)

        content = re.sub('<.+/>', '', content)
        content = re.sub('<.+>', '', content)
        content = re.sub('</.+>', '', content)

        content = re.sub('[\n]+', '\n', content)
        content = re.sub('[ \t\v\f]+', ' ', content)

        parsed_html_content = u''
        for line in content.split('\n'):
            trimed_line = line.strip()
            if trimed_line:
                parsed_html_content += trimed_line + u'\n'

        return parsed_html_content

    def parse(self, url):
        """Parses a RSS feed. This methods supports RSS 2.0 and Media RSS.
        """
        feed = feedparser.parse(url)

        parsed_item_list = []
        for item in feed.entries:
            all_url_set = set()

            # ordinary RSS elements
            title = item.get(u'title', None)
            link = item.get(u'link', None)
            description = item.get(u'description', None)
            # <description> can be an HTML document
            description_url_set = self.__parse_html(description)
            if description_url_set:
                all_url_set.update(description_url_set)

            if link:
                all_url_set.add(link)

            # get urls from enclosures
            for enclosure in item.enclosures:
                enclosure_url = enclosure.get(u'url', None)
                if enclosure_url:
                    all_url_set.add(enclosure_url)

            # media RSS elements
            media_title = item.get(u'media:title', None)
            media_description = item.get(u'media:description', None)
            # <media:description> can be an HTML document
            media_description_url_set = self.__parse_html(media_description)
            if media_description_url_set:
                all_url_set.update(media_description_url_set)

            media_thumbnail_list = item.get(u'media_thumbnail', None)
            if media_thumbnail_list:
                for media_thumbnail in media_thumbnail_list:
                    url = media_thumbnail.get(u'url', None)
                    if url:
                        all_url_set.add(url)

            # sssemble the information, including:
            # use media:title, and media:description as default information
            the_title = media_title if media_title else title
            the_title = the_title if the_title is not None else u''
            the_description = media_description if media_description else description
            the_description = the_description if the_description is not None else u''
            if the_description:
                the_description = self.__html2plaintext(the_description)

            parsed_item = (the_title, the_description, all_url_set)
            parsed_item_list.append(parsed_item)

        return parsed_item_list


# Written by Freek Zindel, Arno Bakker
class URLHistory:

    read_history_expression = re.compile("(\d+(?:[.]\d+)?)\s+(\w+)", re.IGNORECASE)

    def __init__(self, filename):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.urls = {}
        self.filename = filename
        self.readed = False

    def add(self, dirtyurl):
        url = self.clean_link(dirtyurl)
        self.urls[url] = time.time()

    def contains(self, dirtyurl):
        url = self.clean_link(dirtyurl)

        t = self.urls.get(url, None)
        if t is None:
            return False
        else:
            now = time.time()
            return not self.timedout(t, now)  # no need to delete

    def timedout(self, t, now):
        return (t + URLHIST_TIMEOUT) < now

    def read(self):
        self._logger.debug("subscrip: Reading cached %s", self.filename)
        try:
            file_handle = open(self.filename, "rb")
        except IOError:
            # file not found...
            # there is no cache available
            pass
        else:
            re_line = re.compile("^\s*(\d+(?:[.]\d+)?)\s+(.+?)\s*$")
            now = time.time()
            for line in file_handle.readlines():
                match = re_line.match(line)
                if match:
                    timestamp, url = match.groups()
                    timestamp = float(timestamp)
                    if not self.timedout(timestamp, now):
                        self._logger.debug("subscrip: Cached url is %s", url)
                        self.urls[url] = timestamp
                    else:
                        self._logger.debug("subscrip: Timed out cached url is %s", url)

            file_handle.close()

    def write(self):
        try:
            file_handle = open(self.filename, "wb")
        except IOError:
            # can't write file
            print_exc()
        else:
            for url, timestamp in self.urls.iteritems():
                file_handle.write("%f %s\r\n" % (timestamp, url))
            file_handle.close()

    def copy(self):
        return self.urls.copy()

    def clean_link(self, link):
        """ Special vuze case """
        idx = link.find(';jsessionid')
        if idx == -1:
            return link
        else:
            return link[:idx]

if __name__ == '__main__':

    def callback(key, torrent, extraInfo):
        self._logger.info("RssParser: Found torrent %s %s %s", key, torrent, extraInfo)

    class FakeSession:

        def get_state_dir(self):
            return os.path.dirname(__file__)

        def get_torrent_collecting_dir(self):
            return self.get_state_dir()

    r = RssParser.getInstance()
    r.register(FakeSession(), 'test')
    r.addCallback('test', callback)
    r.addURL('http://www.vodo.net/feeds/public', 'test', dowrite=False)

    r.join()

########NEW FILE########
__FILENAME__ = GuiDBHandler
# Written by Niels Zeilemaker
# Extending wx.lib.delayedresult with a startWorker method which uses single producer
# Additionally DelayedResult is returned, allowing a thread to wait for result
import logging
import os
import threading
from collections import namedtuple
from inspect import isgeneratorfunction
from random import randint
from threading import Event, Lock, RLock
from time import time
from traceback import extract_stack, format_exc, print_exc, print_stack

import wx
from twisted.internet import reactor
from twisted.python.threadable import isInIOThread
from wx.lib.delayedresult import SenderWxEvent, SenderCallAfter, AbortedException, SenderNoWx

from Tribler.Main.Dialogs.GUITaskQueue import GUITaskQueue


# Arno, 2012-07-18: Priority for real user visible GUI tasks (e.g. list update)
GUI_PRI_DISPERSY = 99
DEFAULT_PRI_DISPERSY = 0

logger = logging.getLogger(__name__)


class GUIDBProducer():
    # Code to make this a singleton
    __single = None
    __singleton_lock = RLock()

    def __init__(self):
        if GUIDBProducer.__single:
            raise RuntimeError("GuiDBProducer is singleton")

        self._logger = logging.getLogger(self.__class__.__name__)

        self._pending_tasks = {}
        self.guitaskqueue = GUITaskQueue.getInstance()

        # Lets get a reference to utility
        from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
        if GUIUtility.hasInstance():
            self.utility = GUIUtility.getInstance().utility
        else:
            Utility = namedtuple('Utility', ['abcquitting', ])
            self.utility = Utility(False)

        self.uIds = set()
        self.uIdsLock = Lock()

        self.nrCallbacks = {}

    @classmethod
    def getInstance(cls, *args, **kw):
        with cls.__singleton_lock:
            if GUIDBProducer.__single is None:
                GUIDBProducer.__single = GUIDBProducer(*args, **kw)
        return GUIDBProducer.__single

    @classmethod
    def delInstance(cls, *args, **kw):
        GUIDBProducer.__single = None

    @classmethod
    def hasInstance(cls):
        return GUIDBProducer.__single is not None

    def onSameThread(self, type):
        if type == "dbThread" or isInIOThread():
            return isInIOThread()

        return threading.currentThread().getName().startswith('GUITaskQueue')

    def Add(self, sender, workerFn, args=(), kwargs={}, name=None, delay=0.0, uId=None, retryOnBusy=False, priority=0, workerType="dbthread"):
        """The sender will send the return value of
        workerFn(*args, **kwargs) to the main thread.
        """
        if self.utility.abcquitting:
            self._logger.debug("GUIDBHandler: abcquitting ignoring Task(%s)", name)
            return

        assert uId is None or isinstance(uId, unicode), type(uId)
        assert name is None or isinstance(name, unicode), type(name)

        if uId:
            try:
                self.uIdsLock.acquire()
                if uId in self.uIds:
                    self._logger.debug("GUIDBHandler: Task(%s) already scheduled in queue, ignoring uId = %s", name, uId)
                    return
                else:
                    self.uIds.add(uId)
            finally:
                self.uIdsLock.release()

            callbackId = uId
        else:
            callbackId = name

        self._logger.debug("GUIDBHandler: adding Task(%s)", callbackId)

        if __debug__:
            self.uIdsLock.acquire()
            self.nrCallbacks[callbackId] = self.nrCallbacks.get(callbackId, 0) + 1
            if self.nrCallbacks[callbackId] > 10:
                self._logger.debug("GUIDBHandler: Scheduled Task(%s) %d times", callbackId, self.nrCallbacks[callbackId])

            self.uIdsLock.release()

        t1 = time()

        def wrapper():
            if __debug__:
                self.uIdsLock.acquire()
                self.nrCallbacks[callbackId] = self.nrCallbacks.get(callbackId, 0) - 1
                self.uIdsLock.release()

            try:
                t2 = time()
                result = workerFn(*args, **kwargs)

            except (AbortedException, wx.PyDeadObjectError):
                return

            except Exception as exc:
                originalTb = format_exc()
                sender.sendException(exc, originalTb)
                return

            t3 = time()
            self._logger.debug("GUIDBHandler: Task(%s) took to be called %.1f (expected %.1f), actual task took %.1f %s", name, t2 - t1, delay, t3 - t2, workerType)

            if uId:
                try:
                    self.uIdsLock.acquire()
                    if uId in self.uIds:
                        self.uIds.discard(uId)

                    # this callback has been removed during wrapper, cancel now
                    else:
                        return
                finally:
                    self.uIdsLock.release()

            # if we get to this step, send result to callback
            try:
                sender.sendResult(result)
            except:
                print_exc()
                self._logger.error("GUIDBHandler: Could not send result of Task(%s)", name)

        wrapper.__name__ = str(name)

        if not self.onSameThread(workerType) or delay:
            if workerType == "dbThread":
                dc = reactor.callFromThread(reactor.callLater, delay, wrapper)
                if uId:
                    self._pending_tasks[uId] = dc
            elif workerType == "guiTaskQueue":
                self.guitaskqueue.add_task(wrapper, t=delay, id=uId)
        else:
            self._logger.debug("GUIDBHandler: Task(%s) scheduled for thread on same thread, executing immediately", name)
            wrapper()

    def Remove(self, uId):
        if uId in self.uIds:
            self._logger.debug("GUIDBHandler: removing Task(%s)", uId)

            try:
                self.uIdsLock.acquire()
                self.uIds.discard(uId)

                if __debug__:
                    self.nrCallbacks[uId] = self.nrCallbacks.get(uId, 0) - 1

            finally:
                self.uIdsLock.release()

            task = self._pending_tasks.pop(uId, None)
            if task and task.active():
                task.cancel()
            self.guitaskqueue.remove_task(uId)

# Wrapping Senders for new delayedResult impl


class MySender():

    def __init__(self, delayedResult):
        self.delayedResult = delayedResult

    def sendResult(self, result):
        self.delayedResult.setResult(result)
        self._sendImpl(self.delayedResult)

    def sendException(self, exception, originalTb):
        assert exception is not None
        self.delayedResult.setException(exception, originalTb)
        self._sendImpl(self.delayedResult)


class MySenderWxEvent(MySender, SenderWxEvent):

    def __init__(self, handler, eventClass, delayedResult, resultAttr="delayedResult", jobID=None, **kwargs):
        SenderWxEvent.__init__(self, handler, eventClass, resultAttr, jobID, **kwargs)
        MySender.__init__(self, delayedResult)


class MySenderCallAfter(MySender, SenderCallAfter):

    def __init__(self, listener, delayedResult, jobID=None, args=(), kwargs={}):
        SenderCallAfter.__init__(self, listener, jobID, args, kwargs)
        MySender.__init__(self, delayedResult)


class MySenderNoWx(MySender, SenderNoWx):

    def __init__(self, listener, delayedResult, jobID=None, args=(), kwargs={}):
        SenderNoWx.__init__(self, listener, jobID, args, kwargs)
        MySender.__init__(self, delayedResult)

# ASyncDelayedResult, allows a get call before result is set
# This call is blocking, but allows you to specify a timeout


class ASyncDelayedResult():

    def __init__(self, jobID=None):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.__result = None
        self.__exception = None
        self.__jobID = jobID

        self.isFinished = Event()

    def setResult(self, result):
        self.__result = result

        self.isFinished.set()

    def setException(self, exception, original_traceback):
        self.__original_traceback = original_traceback
        self.__exception = exception

        self.isFinished.set()

    def get(self, timeout=100):
        if self.wait(timeout):
            if self.__exception:  # exception was raised!
                self.__exception.originalTraceback = self.__original_traceback
                self._logger.error(repr(self.__original_traceback))
                raise self.__exception

            return self.__result
        else:
            print_stack()
            self._logger.info("TIMEOUT on get %s %s" %
                              (repr(self.__jobID), repr(timeout)))

    def wait(self, timeout=None):
        return self.isFinished.wait(timeout) or self.isFinished.isSet()


def exceptionConsumer(delayedResult, *args, **kwargs):
    try:
        delayedResult.get()
    except Exception as e:
        logger.error(repr(e.originalTraceback))

# Modified startWorker to use our single thread
# group and daemon variables have been removed


def startWorker(
    consumer, workerFn,
    cargs=(), ckwargs={},
    wargs=(), wkwargs={},
    jobID=None, delay=0.0,
    uId=None, retryOnBusy=False,
        priority=DEFAULT_PRI_DISPERSY, workerType="dbThread"):
    """
    Convenience function to send data produced by workerFn(*wargs, **wkwargs)
    running in separate thread, to a consumer(*cargs, **ckwargs) running in
    the main thread. This function merely creates a SenderCallAfter (or a
    SenderWxEvent, if consumer derives from wx.EvtHandler), and a Producer,
    and returns immediately after starting the Producer thread. The jobID
    is used for the Sender and as name for the Producer thread. The uId is
    used to check if such a task is already scheduled, ignores it if it is.
    Returns the delayedResult created, in case caller needs join/etc.
    """
    # TODO(emilon): Deprecate retryOnBusy
    if isgeneratorfunction(workerFn):
        raise Exception("generators are not supported anymore")

    if not consumer:
        consumer = exceptionConsumer

    if not workerFn:
        raise Exception("no worker function specified")

    if jobID is None:
        if __debug__:
            try:
                filename, line, function, text = extract_stack(limit=2)[0]
                _, filename = os.path.split(filename)
                jobID = u"%s:%s (%s)" % (filename, line, function)
            except:
                pass
        else:
            jobID = unicode(randint(1, 10000000))

    result = ASyncDelayedResult(jobID)
    app = wx.GetApp()
    if not app:
        sender = MySenderNoWx(consumer, result, jobID, args=cargs, kwargs=ckwargs)
    elif isinstance(consumer, wx.EvtHandler):
        eventClass = cargs[0]
        sender = MySenderWxEvent(consumer, eventClass, result, jobID=jobID, **ckwargs)
    else:
        sender = MySenderCallAfter(consumer, result, jobID, args=cargs, kwargs=ckwargs)

    if GUIDBProducer.hasInstance():
        thread = GUIDBProducer.getInstance()
        thread.Add(sender, workerFn, args=wargs, kwargs=wkwargs,
                   name=jobID, delay=delay, uId=uId, retryOnBusy=retryOnBusy, priority=priority, workerType=workerType)

        return result


def cancelWorker(uId):
    if GUIDBProducer.hasInstance():
        thread = GUIDBProducer.getInstance()
        thread.Remove(uId)


def onWorkerThread(type):
    if GUIDBProducer.hasInstance():
        dbProducer = GUIDBProducer.getInstance()
        return dbProducer.onSameThread(type)
    return False

########NEW FILE########
__FILENAME__ = GuiDBTuples
# Niels: getValidArgs based on http://stackoverflow.com/questions/196960/can-you-list-the-keyword-arguments-a-python-function-receives
import binascii
import logging
import os.path
import sys
from inspect import getargspec
from time import time

from datetime import date

from Tribler.Core.Search.SearchManager import split_into_keywords
from Tribler.Core.Video.utils import videoextdefaults
from Tribler.Core.simpledefs import (DLSTATUS_DOWNLOADING, DLSTATUS_STOPPED, DLSTATUS_SEEDING, DLSTATUS_HASHCHECKING,
                                     DLSTATUS_WAITING4HASHCHECK, DLSTATUS_ALLOCATING_DISKSPACE,
                                     DLSTATUS_STOPPED_ON_ERROR, DLSTATUS_METADATA)
from Tribler.Main.vwxGUI import VLC_SUPPORTED_SUBTITLES, PLAYLIST_REQ_COLUMNS
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager, SMALL_ICON_MAX_DIM, data2wxBitmap
from Tribler.community.channel.community import ChannelCommunity
from Tribler.dispersy.util import blocking_call_on_reactor_thread


logger = logging.getLogger(__name__)


def getValidArgs(func, argsDict):
    args, _, _, defaults = getargspec(func)
    try:
        args.remove('self')
    except:
        pass

    argsDict = dict((key, value) for key, value in argsDict.iteritems() if key in args)
    if defaults:
        args = args[:-len(defaults)]

    notOk = set(args).difference(argsDict)
    if notOk:
        logger.info("Missing %s arguments for %s", notOk, func)
    return argsDict

# Niels: from http://wiki.python.org/moin/PythonDecoratorLibrary#Memoize


def cache(func):
    def _get(self):
        key = func.__name__
        try:
            return self._cache[key]
        except AttributeError:
            self._cache = {}
            x = self._cache[key] = func(self)
            return x
        except KeyError:
            x = self._cache[key] = func(self)
            return x
    return _get


def cacheProperty(func):

    def _get(self):
        key = func.__name__
        try:
            return self._cache[key]

        except AttributeError:
            self._cache = {}
            x = self._cache[key] = func(self)
            return x

        except KeyError:
            x = self._cache[key] = func(self)
            return x
        return func(self)

    def _del(self):
        key = func.__name__
        try:
            del self._cache[key]
        except:
            pass
    return property(_get, None, _del)


class Helper(object):
    __slots__ = ('_logger', '_cache')

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)
        self._cache = {}

    def get(self, key, default=None):
        return getattr(self, key, default)

    def __contains__(self, key):
        return key in self.__slots__

    def __eq__(self, other):
        if other and hasattr(self, 'id') and hasattr(other, 'id'):
            return self.id == other.id
        return False

    def __ne__(self, other):
        return not self.__eq__(other)

    def __getstate__(self):
        statedict = {}
        for key in self.__slots__:
            statedict[key] = getattr(self, key, None)
        return statedict

    def __setstate__(self, statedict):
        for key, value in statedict.iteritems():
            setattr(self, key, value)


class MergedDs:

    def __init__(self, dslist):
        self.dslist = dslist

    def __getattr__(self, name):
        # print >> sys.stderr, name
        return getattr(self.dslist[0], name)

    def get_status(self):
        order = [DLSTATUS_SEEDING, DLSTATUS_DOWNLOADING, DLSTATUS_HASHCHECKING, DLSTATUS_WAITING4HASHCHECK, DLSTATUS_ALLOCATING_DISKSPACE, DLSTATUS_STOPPED_ON_ERROR, DLSTATUS_STOPPED]
        status1, status2 = self.dslist[0].get_status(), self.dslist[1].get_status()

        def return_in_order(status1, status2, order):
            for status in order:
                if status1 == status or status2 == status:
                    return status

        return return_in_order(status1, status2, order)

    def get_current_speed(self, direct):
        return self.dslist[0].get_current_speed(direct) + self.dslist[1].get_current_speed(direct)

    def get_num_con_initiated(self):
        return self.dslist[0].get_num_con_initiated() + self.dslist[1].get_num_con_initiated()

    def get_num_con_candidates(self):
        return self.dslist[0].get_num_con_candidates() + self.dslist[1].get_num_con_candidates()

    def get_num_seeds_peers(self):
        seeds, peers = self.dslist[0].get_num_seeds_peers()
        s_seeds, s_peers = self.dslist[1].get_num_seeds_peers()
        return seeds + s_seeds, peers + s_peers

    def get_peerlist(self):
        return self.dslist[0].get_peerlist() + self.dslist[1].get_peerlist()


class Torrent(Helper):
    __slots__ = ('infohash', 'swift_hash', 'swift_torrent_hash',
        'name', 'torrent_file_name', 'length', 'category_id', 'status_id',
        'num_seeders', 'num_leechers', '_channel',
        'channeltorrents_id', 'misc_db', 'torrent_db', 'channelcast_db',
        'metadata_db',
        'dslist', '_progress', 'relevance_score', 'query_candidates',
        'magnetstatus')

    def __init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, torrent_file_name, length, category_id, status_id, num_seeders, num_leechers, channel):
        Helper.__init__(self)

        assert isinstance(infohash, str), type(infohash)

        self.infohash = infohash
        self.swift_hash = swift_hash
        self.swift_torrent_hash = swift_torrent_hash
        self.torrent_file_name = torrent_file_name
        self.name = name
        self.length = length or 0
        self.category_id = category_id
        self.status_id = status_id

        self.num_seeders = num_seeders or 0
        self.num_leechers = num_leechers or 0

        self.update_torrent_id(torrent_id)
        self.updateChannel(channel)

        self.channeltorrents_id = None
        self.misc_db = None
        self.torrent_db = None
        self.channelcast_db = None
        self.metadata_db = None

        self.relevance_score = None
        self.query_candidates = None
        self._progress = None
        self.dslist = None
        self.magnetstatus = None

    @cacheProperty
    def categories(self):
        if self.category_id:
            return [self.misc_db.categoryId2Name(self.category_id)]

    @cacheProperty
    def status(self):
        if self.status_id:
            return self.misc_db.torrentStatusId2Name(self.status_id)

    @cacheProperty
    def torrent_id(self):
        self._logger.debug("Torrent: fetching getTorrentID from DB %s", self)
        return self.torrent_db.getTorrentID(self.infohash)

    def update_torrent_id(self, torrent_id):
        self._cache['torrent_id'] = torrent_id

    @cacheProperty
    def infohash_as_hex(self):
        return binascii.hexlify(self.infohash).upper()

    @cacheProperty
    def channel(self):
        self._logger.debug("Torrent: fetching getMostPopularChannelFromTorrent from DB %s", self)

        channel = self.channelcast_db.getMostPopularChannelFromTorrent(self.infohash)
        if channel:
            self.channeltorrents_id = channel[-1]
            return Channel(*channel[:-1])

    def updateChannel(self, c):
        self._cache['channel'] = c

    def hasChannel(self):
        return self.channel

    @cacheProperty
    def metadata(self):
        self._logger.debug("Torrent: fetching metadata from DB %s", self)

        metadata_result = self.metadata_db.getMetdataDateByInfohash(self.infohash)
        if metadata_result:
            metadata_dict = {}
            for key, value in metadata_result:
                metadata_dict[key] = value
            return metadata_dict

    @property
    def swarminfo(self):
        return self.num_seeders, self.num_leechers, sys.maxint

    def updateSwarminfo(self, swarminfo):
        self.num_seeders, self.num_leechers, _ = swarminfo
        self.num_seeders = self.num_seeders or 0
        self.num_leechers = self.num_leechers or 0

    @property
    def state(self):
        stateList = []
        if self.ds:
            status = self.ds.get_status()
            if status == DLSTATUS_STOPPED:
                stateList.append('stopped')

            if status == DLSTATUS_STOPPED_ON_ERROR:
                stateList.append('error')

            if status in [DLSTATUS_DOWNLOADING, DLSTATUS_SEEDING]:
                stateList.append('active')

            if status in [DLSTATUS_METADATA]:
                stateList.append('metadata')

            if status in [DLSTATUS_HASHCHECKING, DLSTATUS_WAITING4HASHCHECK]:
                stateList.append('checking')

            if status == DLSTATUS_ALLOCATING_DISKSPACE:
                stateList.append('allocating')

            if status == DLSTATUS_SEEDING:
                stateList.append('seeding')

            if status == DLSTATUS_DOWNLOADING:
                stateList.append('downloading')

            if self.ds.progress == 1.0:
                stateList.append('completed')

        return stateList

    @property
    def magnetState(self):
        if self.magnetstatus:
            if self.magnetstatus[2]:
                return 3
            if self.magnetstatus[1]:
                return 2
            return 1
        return 0

    @property
    def progress(self):
        if self.ds:
            return self.ds.get_progress()
        return min(1, self._progress)

    @property
    def ds(self):
        if self.dslist:
            if self.dslist[0] and self.dslist[1]:
                return MergedDs(self.dslist)
            return self.dslist[0] or self.dslist[1]

    def addDs(self, ds):
        if ds and not isinstance(ds, MergedDs):
            if self.dslist == None:
                self.dslist = [None, None]

            cdef = ds.get_download().get_def()
            if cdef.get_def_type() == 'torrent':
                if self.infohash and self.infohash == cdef.get_id():
                    self.dslist[0] = ds
                    return True

            elif cdef.get_def_type() == 'swift':
                if self.swift_hash and self.swift_hash == cdef.get_id():
                    self.dslist[1] = ds
                    return True
        return False

    def clearDs(self):
        self.dslist = [None, None]

    def assignRelevance(self, matches):
        """
        Assigns a relevance score to this Torrent.
        @param matches A dict containing sets stored under the keys 'swarmname', 'filenames' and 'fileextensions'.
        """

        # Find the lowest term position of the matching keywords
        pos_score = None
        if matches['swarmname']:
            swarmnameTerms = split_into_keywords(self.name)
            swarmnameMatches = matches['swarmname']

            for i, term in enumerate(swarmnameTerms):
                if term in swarmnameMatches:
                    pos_score = -i
                    break

        self.relevance_score = [len(matches['swarmname']), pos_score, len(matches['filenames']), len(matches['fileextensions']), 0]

    def exactCopy(self, other):
        if other and isinstance(other, Torrent):
            ids = self.torrent_id == other.torrent_id
            hashes = self.infohash == other.infohash and (other.swift_hash and (self.swift_hash == other.swift_hash))
            readableProps = self.name == other.name and self.length == other.length and self.category_id == other.category_id
            return ids and hashes and readableProps
        return False

    def __eq__(self, other):
        if other and isinstance(other, Torrent):
            return self.infohash == other.infohash
        return False

    def __str__(self):
        return self.name

    # Required for drag and drop
    def __getstate__(self):
        statedict = {}
        for key in Torrent.__slots__:
            if key not in ['dslist', 'channelcast_db', 'torrent_db']:
                statedict[key] = getattr(self, key, None)
        return statedict

    @staticmethod
    def fromTorrentDef(tdef):
        return Torrent(-1, tdef.get_infohash(), None, None, tdef.get_name(), None, tdef.get_length(), None, None, 0, 0, False)


class RemoteTorrent(Torrent):
    __slots__ = ()

    def __init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, length=0, category_id=None, status_id=None, num_seeders=0, num_leechers=0, query_candidates=set()):
        Torrent.__init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, False, length, category_id, status_id, num_seeders, num_leechers, channel=False)
        self.query_candidates = query_candidates


class CollectedTorrent(Helper):
    __slots__ = ('comment', 'trackers', 'creation_date', 'files', 'last_check', 'torrent')

    def __init__(self, torrent, torrentdef):
        assert isinstance(torrent, Torrent)

        self.torrent = torrent
        if self.torrent_id <= 0:
            raise RuntimeError("self.torrent_id is too low, %d %s" % (self.torrent_id, self.torrent_file_name))

        self.comment = torrentdef.get_comment_as_unicode()
        self.trackers = torrentdef.get_trackers_as_single_tuple()
        self.creation_date = min(long(time()), torrentdef.get_creation_date())
        self.files = torrentdef.get_files_as_unicode_with_length()
        self.last_check = -1

    def __getattr__(self, name):
        return getattr(self.torrent, name)

    def __setattr__(self, name, value):
        try:
            Helper.__setattr__(self, name, value)
        except:
            setattr(self.torrent, name, value)

    def __delattr__(self, name):
        try:
            Helper.__delattr__(self, name)
        except:
            delattr(self.torrent, name)

    def __contains__(self, key):
        if key in self.__slots__:
            return True
        return key in self.torrent

    @cacheProperty
    def swarminfo(self):
        self._logger.debug("CollectedTorrent: fetching getTorrent from DB %s", self)

        swarminfo = self.torrent_db.getTorrent(self.infohash,
            keys=(u'num_seeders', u'num_leechers', u'last_tracker_check'),
            include_mypref=False)
        swarminfo_tuple = None
        if swarminfo:
            swarminfo_tuple = (swarminfo.get(u'num_seeders', 0),
                swarminfo.get(u'num_leechers', 0),
                swarminfo.get(u'last_tracker_check', 0))
            self.torrent.num_seeders = swarminfo_tuple[0]
            self.torrent.num_leechers = swarminfo_tuple[1]
            self.last_check = swarminfo_tuple[2]
        return swarminfo_tuple

    def updateSwarminfo(self, swarminfo):
        self.torrent.num_seeders, self.torrent.num_leechers, self.last_check = swarminfo
        self.torrent.num_seeders = self.torrent.num_seeders or 0
        self.torrent.num_leechers = self.torrent.num_leechers or 0
        self._cache['swarminfo'] = swarminfo

    @cacheProperty
    def videofiles(self):
        videofiles = []
        for filename, _ in self.files:
            _, ext = os.path.splitext(filename)
            if ext.startswith('.'):
                ext = ext[1:]

            if ext in videoextdefaults:
                videofiles.append(filename)
        return videofiles

    @cacheProperty
    def largestvideofile(self):
        if len(self.videofiles) > 0:
            _, filename = max([(size, filename) for filename, size in self.files if filename in self.videofiles])
            return filename

    @cacheProperty
    def subtitlefiles(self):
        subtitles = []
        for filename, length in self.files:
            prefix, ext = os.path.splitext(filename)
            if not ext.startswith('.'):
                ext = '.' + ext
            if ext in VLC_SUPPORTED_SUBTITLES:
                subtitles.append(filename)
        return subtitles

    @cache
    def isPlayable(self):
        return len(self.videofiles) > 0

    def formatCreationDate(self, format='%Y-%m-%d'):
        if self.creation_date > 0:
            return date.fromtimestamp(self.creation_date).strftime(format)
        return 'Unknown'


class NotCollectedTorrent(CollectedTorrent):
    __slots__ = ()

    def __init__(self, torrent, files, trackers):
        assert isinstance(torrent, Torrent)

        self.torrent = torrent
        self.comment = None
        self.trackers = trackers
        self.creation_date = -1
        self.files = files
        self.last_check = -1

        if self.torrent_id <= 0:
            raise RuntimeError("self.torrent_id is too low, %d %s" % (self.torrent_id, self.torrent_file_name))

class LibraryTorrent(Torrent):
    __slots__ = ()

    def __init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, torrent_file_name, length, category_id, status_id, num_seeders, num_leechers, progress):
        Torrent.__init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, torrent_file_name, length, category_id, status_id, num_seeders, num_leechers, None)
        if progress > 1:
            progress = progress / 100.0

        self._progress = progress


class ChannelTorrent(Torrent):
    __slots__ = ('channeltorrent_id', 'dispersy_id', 'colt_name', 'chant_name', 'description', 'time_stamp', 'inserted', 'playlist')

    def __init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, torrent_file_name, length, category_id, status_id, num_seeders, num_leechers, channeltorrent_id, dispersy_id, chant_name, colt_name, description, time_stamp, inserted, channel, playlist):
        Torrent.__init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, torrent_file_name, length, category_id, status_id, num_seeders, num_leechers, channel)

        self.channeltorrent_id = channeltorrent_id
        self.dispersy_id = dispersy_id
        self.colt_name = colt_name
        self.chant_name = chant_name
        self.description = description
        self.time_stamp = time_stamp
        self.inserted = inserted
        self.playlist = playlist

    # @property
    def __get_name(self):
        return self.chant_name or self.colt_name or self.swift_hash or ''
    # @property

    def __set_name(self, name):
        pass
    # .setter was introduced in Python 2.6
    name = property(__get_name, __set_name)

    @cacheProperty
    def getPlaylist(self):
        self._logger.debug("ChannelTorrent: fetching getPlaylistForTorrent from DB %s", self)

        playlist = self.channelcast_db.getPlaylistForTorrent(self.channeltorrent_id, PLAYLIST_REQ_COLUMNS)
        if playlist:
            return Playlist(*playlist + (self.channel,))

    # Required for drag and drop
    def __getstate__(self):
        statedict = Torrent.__getstate__(self)
        for key in self.__slots__:
            statedict[key] = getattr(self, key, None)
        return statedict


class RemoteChannelTorrent(ChannelTorrent):
    __slots__ = ()

    def __init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, length=0, category_id=None, status_id=None, num_seeders=0, num_leechers=0, channel=False, query_candidates=set()):
        ChannelTorrent.__init__(self, torrent_id, infohash, swift_hash, swift_torrent_hash, name, False, length, category_id, status_id, num_seeders, num_leechers, -1, '-1', '', name, '', None, None, channel, None)
        self.query_candidates = query_candidates


class Channel(Helper):
    __slots__ = ('id', 'dispersy_cid', 'name', 'description', 'nr_torrents', 'nr_favorites', 'nr_spam', 'my_vote', 'modified', 'my_channel', 'torrents', 'popular_torrents')

    def __init__(self, id, dispersy_cid, name, description, nr_torrents, nr_favorites, nr_spam, my_vote, modified, my_channel):
        Helper.__init__(self)

        self.id = id
        self.dispersy_cid = str(dispersy_cid)

        self.name = name[:40]
        self.description = description[:1024]

        self.nr_torrents = nr_torrents
        self.nr_favorites = nr_favorites or 0
        self.nr_spam = nr_spam or 0
        self.my_vote = my_vote
        self.modified = modified
        self.my_channel = my_channel
        self.torrents = None
        self.popular_torrents = None

    def isDispersy(self):
        return len(self.dispersy_cid) == 20

    def isFavorite(self):
        return self.my_vote == 2

    def isSpam(self):
        return self.my_vote == -1

    def isMyChannel(self):
        return self.my_channel

    def isEmpty(self):
        return self.nr_torrents == 0

    def isOpen(self):
        state, myChannel = self.getState()
        return state >= ChannelCommunity.CHANNEL_OPEN

    def isSemiOpen(self):
        state, myChannel = self.getState()
        return state >= ChannelCommunity.CHANNEL_SEMI_OPEN

    @property
    def iamModerator(self):
        return self.getState()[1]

    @cache
    def getState(self):
        if self.isDispersy():
            @blocking_call_on_reactor_thread
            def do_dispersy():
                from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager

                self._logger.debug("Channel: fetching getChannelStateByCID from DB %s", self)

                searchManager = ChannelManager.getInstance()
                result = searchManager.getChannelStateByCID(self.dispersy_cid)
                return result

            return do_dispersy()

        return ChannelCommunity.CHANNEL_CLOSED, self.isMyChannel()

    def setState(self, state, iamModerator):
        self._cache['getState'] = (state, iamModerator)

    def refreshState(self):
        try:
            del self._cache['getState']
        except:
            pass
        return self.getState()

    def addTorrent(self, torrent):
        if not self.torrents:
            self.torrents = set()
        self.torrents.add(torrent)

    def getTorrent(self, infohash):
        if self.torrents:
            for torrent in self.torrents:
                if torrent.infohash == infohash:
                    return torrent

    def loadPopularTorrentNames(self, num_torrents, force_refresh=False):
        if not self.popular_torrents or force_refresh:
            from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
            from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager
            results = ChannelManager.getInstance().getMostPopularTorrentsFromChannel(self.id, ['Torrent.Name'], family_filter=GUIUtility.getInstance().getFamilyFilter(), limit=num_torrents)
            self.popular_torrents = [result[0] for result in results]

    def __eq__(self, other):
        if other:
            if isinstance(other, Channel):
                return self.id == other.id
            if isinstance(other, int):
                return self.id == other
        return False

    def __str__(self):
        return 'Channel name=%s\nid=%d\ndispersy_cid=%s' % (self.name.encode('utf8'), self.id, self.dispersy_cid.encode("HEX"))


class RemoteChannel(Channel):
    __slots__ = ('permid')

    def __init__(self, permid, name):
        Channel.__init__(self, 0, '-1', name, '', 0, 0, 0, 0, 0, False)
        self.permid = permid


class Comment(Helper):
    __slots__ = ('id', 'dispersy_id', 'channeltorrent_id', '_name', 'peer_id', 'comment', 'reply_to_id', 'replies', 'inserted', 'time_stamp', 'playlist', '_torrent', 'channel', 'get_nickname', 'get_mugshot')

    def __init__(self, id, dispersy_id, channeltorrent_id, name, peer_id, comment, reply_to_id, inserted, time_stamp, channel, playlist, torrent):
        Helper.__init__(self)

        self.id = id
        self.dispersy_id = dispersy_id
        self.channeltorrent_id = channeltorrent_id

        self._name = name
        self.peer_id = peer_id
        self.comment = comment
        self.reply_to_id = reply_to_id
        self.replies = []
        self.inserted = inserted
        self.time_stamp = time_stamp

        self.playlist = playlist
        self._torrent = torrent
        self.channel = channel

    @cacheProperty
    def name(self):
        if self.peer_id == None:
            return self.get_nickname()
        if not self._name:
            return 'Peer %d' % self.peer_id
        return self._name

    def isMyComment(self):
        return self.peer_id == None

    @cacheProperty
    def avantar(self):
        gui_image_manager = GuiImageManager.getInstance()

        if self.peer_id == None:
            mime, data = self.get_mugshot()
            if data:
                data = data2wxBitmap(mime, data, SMALL_ICON_MAX_DIM)
        else:
            from Tribler.Core.simpledefs import NTFY_PEERS
            from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
            peer_db = GUIUtility.getInstance().utility.session.open_dbhandler(NTFY_PEERS)
            raw_data = peer_db.getPeerById(self.peer_id, keys=u"thumbnail")
            data = gui_image_manager.getPeerThumbnail(raw_data, SMALL_ICON_MAX_DIM)

        if data is None:
            data = gui_image_manager.getImage(u"PEER_THUMB", SMALL_ICON_MAX_DIM)
        return data

    @cacheProperty
    def torrent(self):
        if self._torrent is not None:
            return self._torrent

        if self.channeltorrent_id:
            from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager

            self._logger.debug("Comment: fetching getTorrentFromChannelTorrentId from DB %s", self)

            searchManager = ChannelManager.getInstance()
            return searchManager.getTorrentFromChannelTorrentId(self.channel, self.channeltorrent_id, False)


class Playlist(Helper):
    __slots__ = ('id', 'dispersy_id', 'channel_id', 'name', 'description', 'nr_torrents', 'channel')

    def __init__(self, id, dispersy_id, channel_id, name, description, nr_torrents, channel):
        Helper.__init__(self)

        self.id = id
        self.dispersy_id = dispersy_id
        self.channel_id = channel_id
        self.name = name
        self.description = description
        self.nr_torrents = nr_torrents

        self.channel = channel

    @cacheProperty
    def extended_description(self):
        if self.description:
            return self.description

        from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager

        # No description, get swarmnames
        searchManager = ChannelManager.getInstance()
        _, _, torrents = searchManager.getTorrentsFromPlaylist(self, limit=3)
        names = [torrent.name for torrent in torrents]
        if len(names) > 0:
            return "Contents: '" + "'    '".join(names) + "'"
        elif self.channel.isOpen():
            return 'This playlist is currently empty, drag and drop any .torrent to add it to this playlist.'
        elif self.channel.isMyChannel():
            return 'This playlist is currently empty, you are the only one who can add torrents to it.'
        return 'This playlist is currently empty, the channel owner has restricted anyone but himself to add torrents to it.'

    def __eq__(self, other):
        if other:
            if isinstance(other, Playlist):
                return self.id == other.id

            if isinstance(other, int):
                return self.id == other
        return False


class MetadataModification(Helper):
    __slots__ = ('torrent', 'message_id', 'key', 'value')


    def __init__(self, torrent, message_id, key, value):
        Helper.__init__(self)

        self.torrent = torrent
        self.message_id = message_id
        self.key = key
        self.value = value

    @property
    def name(self):
        return self.key


class Modification(Helper):
    __slots__ = ('id', 'dispersy_id', 'peer_id', 'type_id', 'value', 'time_stamp', 'inserted', 'moderation', 'channeltorrent_id', 'channelcast_db', 'get_nickname')

    def __init__(self, id, dispersy_id, peer_id, type_id, value, time_stamp, inserted, channeltorrent_id):
        Helper.__init__(self)

        self.id = id
        self.dispersy_id = dispersy_id
        self.peer_id = peer_id
        self.type_id = type_id
        self.value = value
        self.time_stamp = time_stamp
        self.inserted = inserted
        self.channeltorrent_id = channeltorrent_id

        self.moderation = None

    @cacheProperty
    def name(self):
        return self.channelcast_db.id2modification[self.type_id]

    @cacheProperty
    def peer_name(self):
        if self.peer_id == None:
            return self.get_nickname()
        return 'Peer %d' % self.peer_id

    @cacheProperty
    def torrent(self):
        if self.channeltorrent_id:
            from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager

            self._logger.debug("Modification: fetching getTorrentFromChannelTorrentId from DB %s", self)

            searchManager = ChannelManager.getInstance()
            return searchManager.getTorrentFromChannelTorrentId(None, self.channeltorrent_id, False)


class Moderation(Helper):
    __slots__ = ('id', 'channel_id', 'peer_id', 'by_peer_id', 'severity', 'message', 'time_stamp', 'inserted', 'modification', 'channelcast_db', 'get_nickname')

    def __init__(self, id, channel_id, peer_id, by_peer_id, severity, message, time_stamp, inserted):
        Helper.__init__(self)

        self.id = id
        self.channel_id = channel_id
        self.peer_id = peer_id
        self.by_peer_id = by_peer_id
        self.severity = severity
        self.message = message
        self.time_stamp = time_stamp
        self.inserted = inserted
        self.modification = None

    @cacheProperty
    def peer_name(self):
        if self.peer_id == None:
            return self.get_nickname()
        return 'Peer %d' % self.peer_id

    @cacheProperty
    def by_peer_name(self):
        if self.by_peer_id == None:
            return self.get_nickname()
        return 'Peer %d' % self.by_peer_id


class Marking(Helper):
    __slots__ = ('dispersy_id', 'channeltorrent_id', 'peer_id', 'type', 'time_stamp', 'get_nickname')

    def __init__(self, dispersy_id, channeltorrent_id, peer_id, type, time_stamp):
        Helper.__init__(self)

        self.dispersy_id = dispersy_id
        self.channeltorrent_id = channeltorrent_id
        self.peer_id = peer_id
        self.type = type
        self.time_stamp = time_stamp

    @cacheProperty
    def peer_name(self):
        if self.peer_id == None:
            return self.get_nickname()
        return 'Peer %d' % self.peer_id

    @cacheProperty
    def torrent(self):
        if self.channeltorrent_id:
            from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager

            self._logger.debug("Marking: fetching getTorrentFromChannelTorrentId from DB %s", self)

            searchManager = ChannelManager.getInstance()
            return searchManager.getTorrentFromChannelTorrentId(None, self.channeltorrent_id, False)

########NEW FILE########
__FILENAME__ = helpers
# Written by ABC authors
# see LICENSE.txt for license information

import os
import socket
import logging

from time import sleep
from traceback import print_exc
# from cStringIO import StringIO

logger = logging.getLogger(__name__)
#
#
# Helper methods
#
# Contains commonly used helper functions
#
#

#
# Check to see if a file both exists and is readable
#


def existsAndIsReadable(filename):
    return os.access(filename, os.F_OK) and os.access(filename, os.R_OK)

#
# Intersection of two lists (or dictionaries)
#


def intersection(list1, list2):
    if list1 is None or list2 is None:
        return []

    # (Order matters slightly so that has_key is called fewer times)
    if len(list1) < len(list2):
        smaller = list1
        bigger = list2
    else:
        smaller = list2
        bigger = list1

    int_dict = {}
    if isinstance(bigger, dict):
        bigger_dict = bigger
    else:
        bigger_dict = {}
        for e in bigger:
            bigger_dict[e] = 1
    for e in smaller:
        if e in bigger_dict:
            int_dict[e] = bigger_dict[e]
    return int_dict.keys()

#
# Union of two lists (or dictionaries)
#


def union(list1, list2):
    if list1 is None:
        list1 = {}
    if list2 is None:
        list2 = {}

    # (Order matters slightly so that has_key is called fewer times)
    if len(list1) < len(list2):
        smaller = list1
        bigger = list2
    else:
        smaller = list2
        bigger = list1

    if isinstance(bigger, dict):
        union_dict = bigger
    else:
        union_dict = {}
        for e in bigger:
            union_dict[e] = bigger[e]
    for e in smaller:
        union_dict[e] = smaller[e]
    return union_dict

#
# Difference of two dictionaries
# (A - B)
#


def difference(list1, list2):
    if list2 is None:
        return list1
    if list1 is None:
        return {}

    diff_dict = list1.copy()
    for e in list2:
        if e in diff_dict:
            del diff_dict[e]
    return diff_dict

#
# Get a socket to send on
#


def getClientSocket(host, port):
    s = None
    logger.debug('getClientSocket(%s, %d)', host, port)
    for res in socket.getaddrinfo(host, port, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, canonname, sa = res
        try:
            s = socket.socket(af, socktype, proto)
        except socket.error:
            s = None
            continue

        try:
            s.connect(sa)
        except socket.error:
            print_exc()
            s.close()
            s = None
            continue
        break

    return s

#
# Get a socket to listen on
#


def getServerSocket(host, port):
    s = None

    for res in socket.getaddrinfo(host, port, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_PASSIVE):
        af, socktype, proto, canonname, sa = res
        try:
            s = socket.socket(af, socktype, proto)
        except socket.error:
            print_exc()
            s = None
            continue
        try:
            s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            s.bind(sa)
            s.listen(1)
        except socket.error:
            print_exc()
            s.close()
            s = None
            continue
        break

    return s

#
# Get a socket (either client or server)
# Will make up to 5 attempts to get the socket
#


def getSocket(host, port, sockettype="client", attempt = 5):
    s = None

    tries = 0

    while s is None and tries < attempt:
        try:
            if sockettype == "server":
                s = getServerSocket(host, port)
            else:
                s = getClientSocket(host, port)
        except:
            s = None

        if s is None:
            # Try several times, increase in time each try
            sleep(0.01 * tries)
            tries += 1

    return s


def stopTorrentsIfNeeded(torrentlist):
    # Error : all selected torrents must be inactive to get extracted
    showDialog = True

    # See which torrents are active
    activetorrents = [ABCTorrentTemp for ABCTorrentTemp in torrentlist if ABCTorrentTemp.status.isActive()]

    # Ask to stop other torrents if necessary
    if activetorrents > 0:
        singleTorrent = len(activetorrents) == 1
        for ABCTorrentTemp in activetorrents:
            if ABCTorrentTemp.dialogs.stopIfNeeded(showDialog, singleTorrent):
                # Torrent was stopped, don't show the dialog anymore
                showDialog = False
            else:
                # Selected not to stop the torrent, return False
                return False

    # At this point all selected torrents should be stopped
    return True

########NEW FILE########
__FILENAME__ = utility
# Written by ABC authors and Arno Bakker
# see LICENSE.txt for license information
import os
import sys
import socket
import logging
import codecs
from random import gauss

from Tribler.Core.version import version_id
from Tribler.Core.Utilities.utilities import find_prog_in_PATH
from Tribler.Core.Utilities.configparser import CallbackConfigParser
from Tribler.Main.globals import DefaultDownloadStartupConfig

logger = logging.getLogger(__name__)

#
#
# Class: Utility
#
# Generic "glue" class that contains commonly used helper functions
#
#


class Utility:

    def __init__(self, abcpath, configpath):

        self.version = version_id
        self.abcpath = abcpath

        # Find the directory to save config files, etc.
        self.dir_root = configpath

        self.randomly_selected_ports = {}

        self.setupConfig()

        # Is ABC in the process of shutting down?
        self.abcquitting = False

    def setupConfig(self):
        tribler_defaults = {'confirmonclose': 1,
                            # RateLimitPanel
                            'maxuploadrate': 0,
                            'maxdownloadrate': 0,
                            # Misc
                            'torrentassociationwarned': 0,
                            # GUI
                            'window_width': 1024,
                            'window_height': 670,
                            'sash_position':-185,
                            't4t_option': 0,  # Seeding items added by Boxun
                            't4t_ratio': 100,  # T4T seeding ratio added by Niels
                            't4t_hours': 0,
                            't4t_mins': 30,
                            'g2g_option': 1,
                            'g2g_ratio': 75,
                            'g2g_hours': 0,
                            'g2g_mins': 30,
                            'family_filter': 1,
                            'window_x': "",
                            'window_y': "",
                            'use_bundle_magic': 0,
                            # WebUI
                            'use_webui': 0,
                            'webui_port': 8080,
                            # Swift reseed
                            'swiftreseed': 1,
                            'showsaveas': 1,
                            'i2ilistenport': 57891,
                            'mintray': 2 if sys.platform == 'win32' else 0,
                            'free_space_threshold': 100 * 1024 * 1024}

        self.defaults = {'Tribler': tribler_defaults}
        self.configfilepath = os.path.join(self.getConfigPath(), "tribler.conf")
        self.config = CallbackConfigParser()

        # Load the config file.
        if os.path.exists(self.configfilepath):
            self.config.read_file(self.configfilepath, 'utf-8-sig')

        if not self.config.has_section('Tribler'):
            self.config.add_section('Tribler')

        # Tribler.conf also contains the default download config. So we need to merge it now.
        if not self.config.has_section('downloadconfig'):
            self.config.add_section('downloadconfig')
        for k, v in DefaultDownloadStartupConfig.getInstance().dlconfig._sections['downloadconfig'].iteritems():
            self.config.set('downloadconfig', k, v)

        # Make sure we use the same ConfigParser instance for both Utility and DefaultDownloadStartupConfig.
        DefaultDownloadStartupConfig.getInstance().dlconfig = self.config

    def getVersion(self):
        return self.version

    def getConfigPath(self):
        return self.dir_root

    def getPath(self):
        return self.abcpath

    def get_free_random_port(self, option, section='Tribler'):
        key = (option, section)
        if key not in self.randomly_selected_ports:
            s = socket.socket()
            s.bind(('', 0))
            self.randomly_selected_ports[key] = s.getsockname()[1]
            s.close()
        return self.randomly_selected_ports[key]

    def read_config(self, option, section='Tribler', literal_eval=True):
        if not self.config.has_option(section, option):
            return self.defaults.get(section, {}).get(option, None)

        return self.config.get(section, option, literal_eval=literal_eval)

    def write_config(self, option, value, section='Tribler', flush=False):
        self.config.set(section, option, value)
        if flush:
            self.flush_config()

    def flush_config(self):
        self.config.write_file(self.configfilepath)

    def eta_value(self, n, truncate=3):
        if n == -1:
            return '<unknown>'
        if not n:
            return ''
        n = int(n)
        week, r1 = divmod(n, 60 * 60 * 24 * 7)
        day, r2 = divmod(r1, 60 * 60 * 24)
        hour, r3 = divmod(r2, 60 * 60)
        minute, sec = divmod(r3, 60)

        if week > 1000:
            return '<unknown>'

        weekstr = '%d' % (week) + 'w'
        daystr = '%d' % (day) + 'd'
        hourstr = '%d' % (hour) + 'h'
        minutestr = '%d' % (minute) + 'm'
        secstr = '%02d' % (sec) + 's'

        if week > 0:
            text = weekstr
            if truncate > 1:
                text += ":" + daystr
            if truncate > 2:
                text += "-" + hourstr
        elif day > 0:
            text = daystr
            if truncate > 1:
                text += "-" + hourstr
            if truncate > 2:
                text += ":" + minutestr
        elif hour > 0:
            text = hourstr
            if truncate > 1:
                text += ":" + minutestr
            if truncate > 2:
                text += ":" + secstr
        else:
            text = minutestr
            if truncate > 1:
                text += ":" + secstr

        return text

    def speed_format(self, s):
        if s != None:
            if s < 102400:
                text = '%2.1f KB/s' % (s / 1024.0)
            elif s < 1022797:
                text = '%d KB/s' % (s // 1024)
            elif s < 104857600:
                text = '%2.1f MB/s' % (s / 1048576.0)
            elif s < 1047527425:
                text = '%d MB/s' % (s // 1048576)
            elif s < 107374182400:
                text = '%2.1f GB/s' % (s / 1073741824.0)
            elif s < 1072668082177:
                text = '%d GB/s' % (s // 1073741824)
            else:
                text = '%2.1f TB/s' % (s // 1099511627776)

            return text
        return ''

    def size_format(self, s, truncate=None, stopearly=None, applylabel=True, rawsize=False, showbytes=False, labelonly=False, textonly=False):
        size = 0.0

        if truncate is None:
            truncate = 2

        if ((s < 1024) and showbytes and stopearly is None) or stopearly == "Byte":
            truncate = 0
            size = s
            text = "Byte"
        elif ((s < 1048576) and stopearly is None) or stopearly == "KB":
            size = (s / 1024.0)
            text = "KB"
        elif ((s < 1073741824) and stopearly is None) or stopearly == "MB":
            size = (s / 1048576.0)
            text = "MB"
        elif ((s < 1099511627776) and stopearly is None) or stopearly == "GB":
            size = (s / 1073741824.0)
            text = "GB"
        else:
            size = (s / 1099511627776.0)
            text = "TB"

        if textonly:
            return text

        label = "B" if text == "Byte" else text
        if labelonly:
            return label

        if rawsize:
            return size

        # At this point, only accepting 0, 1, or 2
        if truncate == 0:
            text = ('%.0f' % size)
        elif truncate == 1:
            text = ('%.1f' % size)
        else:
            text = ('%.2f' % size)

        if applylabel:
            text += ' ' + label

        return text

    def round_range(self, x):
        returnar = set()
        for _ in range(2500):
            value = int(gauss(x, 100))
            if value < 0:
                continue

            diff = abs(value - x)
            if diff < 2:
                pass
            elif diff < 10 and x < 50:
                value = int(round(value / 3.0) * 3)
            elif diff < 75:
                value = int(round(value / 25.0) * 25)
            elif diff < 450:
                value = int(round(value / 75.0) * 75)
            else:
                value = int(round(value / 150.0) * 150)

            returnar.add(value)
        returnar = sorted(returnar)
        return returnar

########NEW FILE########
__FILENAME__ = arflayout_fb
import random
import math

layout = {}


def arf_remove(toRemove):
    global layout

    for vertexid in toRemove:
        if vertexid in layout:
            layout.pop(vertexid)
        
    new_layout = {}
    for index, vertexid in enumerate(sorted(layout)):
        new_layout[index] = layout[vertexid]
    layout = new_layout  

def arf_layout(toInsert, graph):
    # We just run one iteration, as we want the algorithm to use as little resources as possible.

    numNodes = graph.vcount()
    arf_advance(toInsert, numNodes, graph)

    # Calculate positions in advance
    x, y = zip(*layout.values())
    minX, maxX, minY, maxY = min(x), max(x), min(y), max(y)
    xRange, yRange = maxX - minX, maxY - minY
    
    positions = {}
            
    if xRange != 0 and yRange != 0:
        for vertexid in range(graph.vcount()):
            if not layout.has_key(vertexid):
                continue
            x, y = layout[vertexid][0], layout[vertexid][1]
            x_scaled, y_scaled = (x - minX) / xRange, (y - minY) / yRange
            positions[vertexid] = (x_scaled, y_scaled)
    
    return positions

def arf_advance(toInsert, numNodes, graph):
    global layout
    
    for vertexid in toInsert:
        layout[vertexid] = arf_get_position(vertexid, numNodes, graph)
    toInsert.clear()
    
    for index in range(numNodes):
        pos = layout.get(index, None)
        if pos:
            fX, fY = arf_get_force(index, numNodes, graph)
            layout[index] = [ pos[0] + fX * 2, pos[1] + fY * 2 ]
                
def arf_get_force(vertexid, numNodes, graph):
    global layout
    
    x, y = layout.get(vertexid, (0.0, 0.0))
    
    forceX, forceY = (0, 0)
   
    if x == 0 and y == 0:
        return (forceX, forceY)

    for otherVertexid in range(0, numNodes):
        if vertexid != otherVertexid:
            otherX, otherY = layout.get(otherVertexid, (0, 0))
            if otherX == 0 and otherY == 0:
                continue
            
            tempX = otherX - x
            tempY = otherY - y

            mult = 3 if graph.are_connected(vertexid, otherVertexid) else 1
            mult *= 0.2 / math.sqrt(numNodes)
            addX = tempX * mult
            addY = tempY * mult
            forceX += addX
            forceY += addY

            mult = 8 / math.sqrt(tempX ** 2 + tempY ** 2)
            addX = tempX * mult
            addY = tempY * mult
            forceX -= addX
            forceY -= addY
    
    return (forceX, forceY)

def arf_get_position(vertexid, numNodes, graph):
    global layout
    
    nvertices = []
    if vertexid < numNodes:
        for otherVertexid in graph.neighbors(vertexid):
            if otherVertexid in layout.keys():
                nvertices.append(otherVertexid)

    pos = layout.get(vertexid, None)
    if not pos:
        pos = [random.random(), random.random()]

    if nvertices:
        for otherVertexid in nvertices:
            x2, y2 = layout[otherVertexid]
            pos[0] += x2
            pos[1] += y2
        mult = 1.0 / len(nvertices)
        pos[0] = pos[0] * mult
        pos[1] = pos[1] * mult
    return pos

def CubicHermite(t, p0, p1, m0, m1):
    t2 = t * t
    t3 = t2 * t
    return (2 * t3 - 3 * t2 + 1) * p0 + (t3 - 2 * t2 + t) * m0 + (-2 * t3 + 3 * t2) * p1 + (t3 - t2) * m1

def CubicHermiteInterpolate(t1, t2, t3, x1, x2, t):
    v = (x2 - x1) / (t1 / 2.0 + t2 + t3 / 2.0)
    d1 = v * t1 / 2.0
    d2 = v * t2

    if t <= t1:
        interpolate = CubicHermite(t / t1, x1, x1 + d1, 0, d2 / t2 * t1)
    elif t <= t1 + t2:
        interpolate = x1 + d1 + d2 * (t - t1) / t2
    else:
        interpolate = CubicHermite((t - t1 - t2) / t3, x1 + d1 + d2, x2, d2 / t2 * t3, 0)
    return interpolate

########NEW FILE########
__FILENAME__ = channel
# Written by Niels Zeilemaker
import wx

import os
import sys
import logging
from time import time
import pickle
from shutil import copyfile
from random import sample
from traceback import print_exc
import re

from Tribler.Main.vwxGUI.GuiUtility import GUIUtility, forceWxThread
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.widgets import _set_font, NotebookPanel, SimpleNotebook, \
    EditText, BetterText

from Tribler.Category.Category import Category

from Tribler.Core.simpledefs import NTFY_MISC
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler
from Tribler.Core.Utilities.utilities import get_collected_torrent_filename

from Tribler.Main.vwxGUI import CHANNEL_MAX_NON_FAVORITE, warnWxThread, \
    LIST_GREY, LIST_LIGHTBLUE, LIST_DESELECTED, DEFAULT_BACKGROUND, \
    format_time, showError
from Tribler.Main.vwxGUI.list import BaseManager, GenericSearchList, SizeList, List
from Tribler.Main.vwxGUI.list_body import ListBody
from Tribler.Main.vwxGUI.list_footer import CommentFooter, PlaylistFooter, \
    ManageChannelFilesFooter, ManageChannelPlaylistFooter
from Tribler.Main.vwxGUI.list_header import ChannelHeader, SelectedChannelFilter, \
    SelectedPlaylistFilter, PlaylistHeader, ManageChannelHeader, TitleHeader
from Tribler.Main.vwxGUI.list_item import PlaylistItem, ColumnsManager, DragItem, \
    TorrentListItem, CommentItem, CommentActivityItem, NewTorrentActivityItem, \
    TorrentActivityItem, ModificationActivityItem, ModerationActivityItem, \
    MarkingActivityItem, ModificationItem, ModerationItem, ThumbnailListItem
from Tribler.Main.vwxGUI.list_details import AbstractDetails, SelectedchannelInfoPanel, \
    PlaylistDetails, PlaylistInfoPanel, TorrentDetails, MyChannelPlaylist

from Tribler.Main.Utility.GuiDBHandler import startWorker, cancelWorker, GUI_PRI_DISPERSY
from Tribler.community.channel.community import ChannelCommunity
from Tribler.Main.Utility.GuiDBTuples import Torrent, CollectedTorrent, ChannelTorrent
from Tribler.Main.Utility.Feeds.rssparser import RssParser

from Tribler.Main.Dialogs.AddTorrent import AddTorrent


class ChannelManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self._logger = logging.getLogger(self.__class__.__name__)

        self.channelsearch_manager = self.guiutility.channelsearch_manager
        self.library_manager = self.guiutility.library_manager

        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)
        if self.list.channel:
            cancelWorker("ChannelManager_refresh_list_%d" % self.list.channel.id)

        self.list.SetChannel(None)

    def refreshDirty(self):
        if 'COMPLETE_REFRESH_STATE' in self.dirtyset:
            self._refresh_list(stateChanged=True)
            self.dirtyset.clear()
        else:
            BaseManager.refreshDirty(self)

    @forceDBThread
    def reload(self, channel_id):
        channel = self.channelsearch_manager.getChannel(channel_id)
        self.refresh(channel)

    @forceWxThread
    def refresh(self, channel=None):
        if channel:
            # copy torrents if channel stays the same
            if channel == self.list.channel:
                if self.list.channel.torrents:
                    if channel.torrents:
                        channel.torrents.update(self.list.channel.torrents)
                    else:
                        channel.torrents = self.list.channel.torrents

            self.list.Reset()
            self.list.SetChannel(channel)

        self._refresh_list(channel)

    def refresh_if_required(self, channel):
        if self.list.channel != channel:
            self.refresh(channel)

    def _refresh_list(self, stateChanged=False):
        t1 = time()
        self._logger.debug("SelChannelManager complete refresh %s", t1)

        self.list.dirty = False

        def db_callback():
            channel = self.list.channel
            if channel:
                t2 = time()

                if stateChanged:
                    state, iamModerator = channel.refreshState()
                else:
                    state = iamModerator = None

                if self.list.channel.isDispersy():
                    nr_playlists, playlists = self.channelsearch_manager.getPlaylistsFromChannel(channel)
                    total_items, nrfiltered, torrentList = self.channelsearch_manager.getTorrentsNotInPlaylist(channel, self.guiutility.getFamilyFilter())
                else:
                    playlists = []
                    total_items, nrfiltered, torrentList = self.channelsearch_manager.getTorrentsFromChannel(channel, self.guiutility.getFamilyFilter())

                t3 = time()
                self._logger.debug("SelChannelManager complete refresh took %s %s %s", t3 - t1, t2 - t1, t3)

                return total_items, nrfiltered, torrentList, playlists, state, iamModerator

        def do_gui(delayedResult):
            result = delayedResult.get()
            if result:
                total_items, nrfiltered, torrentList, playlists, state, iamModerator = result
                if state != None:
                    self.list.SetChannelState(state, iamModerator)

                self._on_data(total_items, nrfiltered, torrentList, playlists)

        if self.list.channel:
            startWorker(do_gui, db_callback, uId=u"ChannelManager_refresh_list_%d" % self.list.channel.id, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    @forceWxThread
    def _on_data(self, total_items, nrfiltered, torrents, playlists):
        # only show a small random selection of available content for non-favorite channels
        inpreview = not self.list.channel.isFavorite() and not self.list.channel.isMyChannel()
        if inpreview:
            if len(playlists) > 3:
                playlists = sample(playlists, 3)

            if len(torrents) > CHANNEL_MAX_NON_FAVORITE:
                def cmp_torrent(a, b):
                    return cmp(a.time_stamp, b.time_stamp)

                torrents = sample(torrents, CHANNEL_MAX_NON_FAVORITE)
                torrents.sort(cmp=cmp_torrent, reverse=True)

        # sometimes a channel has some torrents in the torrents variable, merge them here
        if self.list.channel.torrents:
            remoteTorrents = set(torrent.infohash for torrent in self.list.channel.torrents)
            for i in xrange(len(torrents), 0, -1):
                if torrents[i - 1].infohash in remoteTorrents:
                    torrents.pop(i - 1)

            torrents = list(self.list.channel.torrents) + torrents
            if inpreview:
                torrents = torrents[:CHANNEL_MAX_NON_FAVORITE]

        self.list.SetData(playlists, torrents)
        self._logger.debug("SelChannelManager complete refresh done")

    @forceDBThread
    def refresh_partial(self, ids):
        if self.list.channel:
            id_data = {}
            for id in ids:
                if isinstance(id, str) and len(id) == 20:
                    id_data[id] = self.channelsearch_manager.getTorrentFromChannel(self.list.channel, id)
                else:
                    id_data[id] = self.channelsearch_manager.getPlaylist(self.list.channel, id)

            def do_gui():
                for id, data in id_data.iteritems():
                    if data:
                        self.list.RefreshData(id, data)
                    else:
                        self.list.RemoveItem(id)

            wx.CallAfter(do_gui)

    @forceWxThread
    def downloadStarted(self, infohash):
        if self.list.InList(infohash):
            item = self.list.GetItem(infohash)

            torrent_details = item.GetExpandedPanel()
            if torrent_details:
                torrent_details.DownloadStarted()
            else:
                item.DoExpand()

    def torrentUpdated(self, infohash):
        if self.list.InList(infohash):
            self.do_or_schedule_partial([infohash])

    def torrentsUpdated(self, infohashes):
        infohashes = [infohash for infohash in infohashes if self.list.InList(infohash)]
        self.do_or_schedule_partial(infohashes)

    def channelUpdated(self, channel_id, stateChanged=False, modified=False):
        _channel = self.list.channel
        if _channel and _channel == channel_id:
            if _channel.isFavorite() or _channel.isMyChannel():
                # only update favorite or mychannel
                if modified:
                    self.reload(channel_id)
                else:
                    if self.list.ShouldGuiUpdate():
                        self._refresh_list(stateChanged)
                    else:
                        key = 'COMPLETE_REFRESH'
                        if stateChanged:
                            key += '_STATE'
                        self.dirtyset.add(key)
                        self.list.dirty = True

    def playlistCreated(self, channel_id):
        if self.list.channel == channel_id:
            self.do_or_schedule_refresh()

    def playlistUpdated(self, playlist_id, infohash=False, modified=False):
        if self.list.InList(playlist_id):
            if self.list.InList(infohash):  # if infohash is shown, complete refresh is necessary
                self.do_or_schedule_refresh()

            else:  # else, only update this single playlist
                self.do_or_schedule_partial([playlist_id])


class SelectedChannelList(GenericSearchList):

    def __init__(self, parent):
        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.session = self.guiutility.utility.session
        self.channelsearch_manager = self.guiutility.channelsearch_manager

        self.display_grid = False
        self.title = None
        self.channel = None
        self.iamModerator = False
        self.my_channel = False
        self.state = ChannelCommunity.CHANNEL_CLOSED

        columns = [{'name': 'Name', 'sortAsc': True},
                   {'name': 'Torrents', 'width': '14em', 'fmt': lambda x: '?' if x == -1 else str(x)}]

        columns = self.guiutility.SetColumnInfo(PlaylistItem, columns)
        ColumnsManager.getInstance().setColumns(PlaylistItem, columns)

        misc_db = self.session.open_dbhandler(NTFY_MISC)
        self.category_names = {}
        for key, name in Category.getInstance().getCategoryNames(filter=False):
            if key in misc_db._category_name2id_dict:
                self.category_names[misc_db._category_name2id_dict[key]] = name
        self.category_names[8] = 'Other'
        self.category_names[None] = self.category_names[0] = 'Unknown'

        GenericSearchList.__init__(self, None, wx.WHITE, [0, 0], True, borders=False, showChange=True, parent=parent)

        self.list.OnBack = self.OnBack
        self.list.Bind(wx.EVT_SHOW, lambda evt: self.notebook.SetSelection(0))

    @warnWxThread
    def _PostInit(self):
        self.notebook = SimpleNotebook(self.parent, show_single_tab=False, style=wx.NB_NOPAGETHEME)
        self.notebook.SetForegroundColour(self.parent.GetForegroundColour())
        self.notebook.Bind(wx.EVT_NOTEBOOK_PAGE_CHANGED, self.OnChange)

        contentList = wx.Panel(self.notebook)
        contentList.SetForegroundColour(self.notebook.GetForegroundColour())
        contentList.SetFocus = contentList.SetFocusIgnoringChildren

        self.header = self.CreateHeader(contentList)
        self.list = self.CreateList(contentList)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(self.header, 0, wx.EXPAND)
        vSizer.Add(self.list, 1, wx.EXPAND)
        contentList.SetSizer(vSizer)

        self.notebook.AddPage(contentList, "Contents", tab_colour=wx.WHITE)

        self.commentList = NotebookPanel(self.notebook)
        self.commentList.SetList(CommentList(self.commentList, self, canReply=True))
        self.commentList.header.SetBackgroundColour(wx.WHITE)
        self.commentList.Show(False)

        self.activityList = NotebookPanel(self.notebook)
        self.activityList.SetList(ActivityList(self.activityList, self))
        self.activityList.header.SetBackgroundColour(wx.WHITE)
        self.activityList.Show(False)

        self.moderationList = NotebookPanel(self.notebook)
        self.moderationList.SetList(ModerationList(self.moderationList, self))
        self.moderationList.header.SetBackgroundColour(wx.WHITE)
        self.moderationList.Show(False)

        self.leftLine = wx.Panel(self.parent, size=(1, -1))
        self.rightLine = wx.Panel(self.parent, size=(1, -1))

        listSizer = wx.BoxSizer(wx.HORIZONTAL)
        listSizer.Add(self.leftLine, 0, wx.EXPAND)
        listSizer.Add(self.notebook, 1, wx.EXPAND)
        listSizer.Add(self.rightLine, 0, wx.EXPAND)

        self.top_header = self.CreateTopHeader(self.parent)
        self.Add(self.top_header, 0, wx.EXPAND)
        self.Add(listSizer, 1, wx.EXPAND)

        self.SetBackgroundColour(self.background)

        self.Layout()
        self.list.Bind(wx.EVT_SIZE, self.OnSize)

    def _special_icon(self, item):
        if not isinstance(item, PlaylistItem) and self.channel:
            if self.channel.isFavorite():
                return self.favorite, self.normal, "This torrent is part of one of your favorite channels, %s" % self.channel.name
            else:
                return self.normal, self.favorite, "This torrent is not part of one of your favorite channels"

    def CreateList(self, parent=None, listRateLimit=1):
        if not parent:
            parent = self
        return ListBody(parent, self, self.columns, self.spacers[0], self.spacers[1], self.singleSelect, self.showChange, listRateLimit=listRateLimit, grid_columns=4 if self.display_grid else 0)

    @warnWxThread
    def CreateHeader(self, parent):
        return SelectedChannelFilter(parent, self, show_bundle=False)

    @warnWxThread
    def CreateTopHeader(self, parent):
        return ChannelHeader(parent, self)

    @warnWxThread
    def Reset(self):
        self.title = None
        self.channel = None
        self.iamModerator = False
        self.my_channel = False

        if GenericSearchList.Reset(self):
            self.commentList.Reset()
            self.activityList.Reset()
            self.moderationList.Reset()

            return True
        return False

    def SetGrid(self, enable):
        self.display_grid = enable

        new_raw_data = []
        for data in self.list.raw_data:
            if enable and (len(data) < 4 or data[3] == TorrentListItem):
                new_raw_data.append(list(data[:3]) + [ThumbnailListItem])
            elif not enable and data[3] == ThumbnailListItem:
                new_raw_data.append(list(data[:3]) + [TorrentListItem])
        self.list.SetData(new_raw_data)
        self.list.SetGrid(self.display_grid)

    @warnWxThread
    def SetChannel(self, channel):
        self.channel = channel

        self.Freeze()
        self.SetIds(channel)

        if channel:
            self.SetTitle(channel)

        self.Thaw()

    def SetIds(self, channel):
        if channel:
            self.my_channel = channel.isMyChannel()
        else:
            self.my_channel = False

        # Always switch to page 1 after new id
        if self.notebook.GetPageCount() > 0:
            self.notebook.SetSelection(0)

    @warnWxThread
    def SetChannelState(self, state, iamModerator):
        self.iamModerator = iamModerator
        self.state = state
        self.channel.setState(state, iamModerator)

        if state >= ChannelCommunity.CHANNEL_SEMI_OPEN:
            if self.notebook.GetPageCount() == 1:
                self.commentList.Show(True)
                self.activityList.Show(True)

                self.notebook.AddPage(self.commentList, "Comments", tab_colour=wx.WHITE)
                self.notebook.AddPage(self.activityList, "Activity", tab_colour=wx.WHITE)

            if state >= ChannelCommunity.CHANNEL_OPEN and self.notebook.GetPageCount() == 3:
                self.moderationList.Show(True)
                self.notebook.AddPage(self.moderationList, "Moderations", tab_colour=wx.WHITE)
        else:
            for i in range(self.notebook.GetPageCount(), 1, -1):
                page = self.notebook.GetPage(i - 1)
                page.Show(False)
                self.notebook.RemovePage(i - 1)

        # Update header + list ids
        self.ResetBottomWindow()
        self.top_header.SetButtons(self.channel)
        self.commentList.GetManager().SetIds(channel=self.channel)
        self.activityList.GetManager().SetIds(channel=self.channel)
        self.moderationList.GetManager().SetIds(channel=self.channel)

    @warnWxThread
    def SetTitle(self, channel):
        self.title = channel.name
        self.top_header.SetTitle(channel)
        self.Layout()

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ChannelManager(self)
        return self.manager

    @forceWxThread
    def SetData(self, playlists, torrents):
        SizeList.SetData(self, torrents)

        if len(playlists) > 0 or len(torrents) > 0:
            data = [(playlist.id, [playlist.name, playlist.nr_torrents, 0, 0, 0, 0], playlist, PlaylistItem, index) for index, playlist in enumerate(playlists)]

            shouldDrag = len(playlists) > 0 and (self.channel.iamModerator or self.channel.isOpen())
            if shouldDrag:
                data += [(torrent.infohash, [torrent.name, torrent.length, self.category_names[torrent.category_id], torrent.num_seeders, torrent.num_leechers, 0, None], torrent, DragItem) for torrent in torrents]
            elif self.display_grid:
                data += [(torrent.infohash, [torrent.name, torrent.length, self.category_names[torrent.category_id], torrent.num_seeders, torrent.num_leechers, 0, None], torrent, ThumbnailListItem) for torrent in torrents]
            else:
                data += [(torrent.infohash, [torrent.name, torrent.length, self.category_names[torrent.category_id], torrent.num_seeders, torrent.num_leechers, 0, None], torrent, TorrentListItem) for torrent in torrents]
            self.list.SetData(data)

        else:
            header = 'No torrents or playlists found.'

            if self.channel and self.channel.isOpen():
                message = 'As this is an "open" channel, you can add your own torrents to share them with others in this channel'
                self.list.ShowMessage(message, header=header)
            else:
                self.list.ShowMessage(header)
            self.SetNrResults(0)

    @warnWxThread
    def SetNrResults(self, nr):
        SizeList.SetNrResults(self, nr)
        if self.channel and (self.channel.isFavorite() or self.channel.isMyChannel()):
            header = 'Discovered'
        else:
            header = 'Previewing'

        if nr == 1:
            self.header.SetSubTitle(header + ' %d torrent' % nr)
        else:
            if self.channel and self.channel.isFavorite():
                self.header.SetSubTitle(header + ' %d torrents' % nr)
            else:
                self.header.SetSubTitle(header + ' %d torrents' % nr)

    @forceWxThread
    def RefreshData(self, key, data):
        List.RefreshData(self, key, data)

        if data:
            if isinstance(data, Torrent):
                if self.state == ChannelCommunity.CHANNEL_OPEN or self.iamModerator:
                    data = (data.infohash, [data.name, data.length, self.category_names[data.category_id], data.num_seeders, data.num_leechers, 0, None], data, DragItem)
                else:
                    data = (data.infohash, [data.name, data.length, self.category_names[data.category_id], data.num_seeders, data.num_leechers, 0, None], data)
            else:
                data = (data.id, [data.name, data.nr_torrents], data, PlaylistItem)
            self.list.RefreshData(key, data)

        manager = self.activityList.GetManager()
        manager.do_or_schedule_refresh()

    @warnWxThread
    def OnExpand(self, item):
        if isinstance(item, PlaylistItem):
            detailspanel = self.guiutility.SetBottomSplitterWindow(PlaylistDetails)
            detailspanel.showPlaylist(item.original_data)
            item.expandedPanel = detailspanel
        elif isinstance(item, TorrentListItem) or isinstance(item, ThumbnailListItem):
            detailspanel = self.guiutility.SetBottomSplitterWindow(TorrentDetails)
            detailspanel.setTorrent(item.original_data)
            item.expandedPanel = detailspanel

        self.top_header.header_list.DeselectAll()
        return True

    @warnWxThread
    def OnCollapse(self, item, panel, from_expand):
        if not isinstance(item, PlaylistItem) and panel:
            # detect changes
            changes = panel.GetChanged()
            if len(changes) > 0:
                dlg = wx.MessageDialog(None, 'Do you want to save your changes made to this torrent?', 'Save changes?', wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION)
                if dlg.ShowModal() == wx.ID_YES:
                    self.OnSaveTorrent(self.channel, panel)
                dlg.Destroy()
        GenericSearchList.OnCollapse(self, item, panel, from_expand)

    @warnWxThread
    def ResetBottomWindow(self):
        _channel = self.channel

        if _channel:
            detailspanel = self.guiutility.SetBottomSplitterWindow(SelectedchannelInfoPanel)
            num_items = len(self.list.raw_data) if self.list.raw_data else 1
            detailspanel.Set(num_items, _channel.my_vote, self.state, self.iamModerator)
        else:
            self.guiutility.SetBottomSplitterWindow()

    @warnWxThread
    def OnSaveTorrent(self, channel, panel):
        changes = panel.GetChanged()
        if len(changes) > 0:
            self.channelsearch_manager.modifyTorrent(channel.id, panel.torrent.channeltorrent_id, changes)
            panel.Saved()

    @forceDBThread
    def AddTorrent(self, playlist, torrent):
        def gui_call():
            manager = self.GetManager()
            manager._refresh_list()

        self.channelsearch_manager.addPlaylistTorrent(playlist, torrent)
        wx.CallAfter(gui_call)

    @warnWxThread
    def OnRemoveFavorite(self, event):
        self.guiutility.RemoveFavorite(event, self.channel)

    @warnWxThread
    def OnFavorite(self, event=None):
        self.guiutility.MarkAsFavorite(event, self.channel)

    @warnWxThread
    def OnRemoveSpam(self, event):
        self.guiutility.RemoveSpam(event, self.channel)

    @warnWxThread
    def OnSpam(self, event):
        self.guiutility.MarkAsSpam(event, self.channel)

    @warnWxThread
    def OnManage(self, event):
        if self.channel:
            self.guiutility.showManageChannel(self.channel)

    @warnWxThread
    def OnBack(self, event):
        if self.channel:
            self.guiutility.GoBack(self.channel.id)

    @warnWxThread
    def OnSize(self, event):
        event.Skip()

    def OnChange(self, event):
        source = event.GetEventObject()
        if source == self.notebook:
            page = event.GetSelection()
            if page == 1:
                self.commentList.Show()
                self.commentList.Focus()

            elif page == 2:
                self.activityList.Show()
                self.activityList.Focus()

            elif page == 3:
                self.moderationList.Show()
                self.moderationList.Focus()

        self.UpdateSplitter()

        event.Skip()

    def OnDrag(self, dragitem):
        torrent = dragitem.original_data

        tdo = TorrentDO(torrent)
        tds = wx.DropSource(dragitem)
        tds.SetData(tdo)
        tds.DoDragDrop(True)

    @warnWxThread
    def OnCommentCreated(self, channel_id):
        if self.channel == channel_id:
            manager = self.commentList.GetManager()
            manager.new_comment()

            manager = self.activityList.GetManager()
            manager.new_activity()

        else:  # maybe channel_id is a infohash
            panel = self.list.GetExpandedItem()
            if panel:
                torDetails = panel.GetExpandedPanel()
                if torDetails:
                    torDetails.OnCommentCreated(channel_id)

    @warnWxThread
    def OnModificationCreated(self, channel_id):
        if self.channel == channel_id:
            manager = self.activityList.GetManager()
            manager.new_activity()

        else:  # maybe channel_id is a channeltorrent_id
            panel = self.list.GetExpandedItem()
            if panel:
                torDetails = panel.GetExpandedPanel()
                if torDetails:
                    torDetails.OnModificationCreated(channel_id)

    @warnWxThread
    def OnModerationCreated(self, channel_id):
        if self.channel == channel_id:
            manager = self.moderationList.GetManager()
            manager.new_moderation()

    @warnWxThread
    def OnMarkingCreated(self, channeltorrent_id):
        panel = self.list.GetExpandedItem()
        if panel:
            torDetails = panel.GetExpandedPanel()
            if torDetails:
                torDetails.OnMarkingCreated(channeltorrent_id)

    @warnWxThread
    def OnMarkTorrent(self, channel, infohash, type):
        self.channelsearch_manager.markTorrent(channel.id, infohash, type)

    def OnFilter(self, keyword):
        new_filter = keyword.lower().strip()

        self.categoryfilter = None
        if new_filter.find("category=") > -1:
            try:
                start = new_filter.find("category='")
                start = start + 10 if start >= 0 else -1
                end = new_filter.find("'", start)
                if start == -1 or end == -1:
                    category = None
                else:
                    category = new_filter[start:end]

                self.categoryfilter = category
                new_filter = new_filter[:start - 10] + new_filter[end + 1:]
            except:
                pass

        SizeList.OnFilter(self, new_filter)

    def GotFilter(self, keyword=None):
        GenericSearchList.GotFilter(self, keyword)
        self.GetManager().do_or_schedule_refresh()

    @warnWxThread
    def Select(self, key, raise_event=True):
        if isinstance(key, Torrent):
            torrent = key
            key = torrent.infohash

            if torrent.getPlaylist:
                self.guiutility.showPlaylist(torrent.getPlaylist)
                wx.CallLater(0, self.guiutility.frame.playlist.Select, key)
                return

        GenericSearchList.Select(self, key, raise_event)

        if self.notebook.GetPageCount() > 0:
            self.notebook.SetSelection(0)
            self.UpdateSplitter()
        self.ScrollToId(key)

    def UpdateSplitter(self):
        splitter = self.guiutility.frame.splitter
        topwindow = self.guiutility.frame.splitter_top_window
        bottomwindow = self.guiutility.frame.splitter_bottom_window
        if self.notebook.GetPageText(self.notebook.GetSelection()) == 'Contents':
            if not splitter.IsSplit():
                sashpos = getattr(self.parent, 'sashpos', -185)
                splitter.SplitHorizontally(topwindow, bottomwindow, sashpos)
        else:
            if splitter.IsSplit():
                self.parent.sashpos = splitter.GetSashPosition()
                splitter.Unsplit(bottomwindow)

    def StartDownload(self, torrent, files=None):
        def do_gui(delayedResult):
            nrdownloaded = delayedResult.get()
            if nrdownloaded:
                self._ShowFavoriteDialog(nrdownloaded)
                GenericSearchList.StartDownload(self, torrent, files)

        def do_db():
            channel = self.channel
            if channel:
                return self.channelsearch_manager.getNrTorrentsDownloaded(channel.id) + 1

        if not self.channel.isFavorite():
            startWorker(do_gui, do_db, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        else:
            GenericSearchList.StartDownload(self, torrent, files)

    def _ShowFavoriteDialog(self, nrdownloaded):
        def do_db(favorite):
            if favorite:
                self.uelog.addEvent(message="ChannelList: user clicked yes to mark as favorite", type=2)
            else:
                self.uelog.addEvent(message="ChannelList: user clicked no to mark as favorite", type=2)

        dial = wx.MessageDialog(None, "You downloaded %d torrents from this Channel. 'Mark as favorite' will ensure that you will always have access to newest channel content.\n\nDo you want to mark this channel as one of your favorites now?" % nrdownloaded, 'Mark as Favorite?', wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION)
        if dial.ShowModal() == wx.ID_YES:
            self.OnFavorite()
            startWorker(None, do_db, wargs=(True,))
        else:
            startWorker(None, do_db, wargs=(False,))

        dial.Destroy()


class TorrentDO(wx.CustomDataObject):

    def __init__(self, data):
        wx.CustomDataObject.__init__(self, wx.CustomDataFormat("TORRENT"))
        self.setObject(data)

    def setObject(self, obj):
        self.SetData(pickle.dumps(obj))

    def getObject(self):
        return pickle.loads(self.GetData())


class TorrentDT(wx.PyDropTarget):

    def __init__(self, playlist, callback):
        wx.PyDropTarget.__init__(self)
        self.playlist = playlist
        self.callback = callback

        self.cdo = TorrentDO(None)
        self.SetDataObject(self.cdo)

    def OnData(self, x, y, data):
        if self.GetData():
            self.callback(self.playlist, self.cdo.getObject())


class PlaylistManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.library_manager = self.guiutility.library_manager
        self.channelsearch_manager = self.guiutility.channelsearch_manager

    def SetPlaylist(self, playlist):
        if self.list.playlist != playlist:
            self.list.Reset()

            self.list.playlist = playlist
            self.list.SetChannel(playlist.channel)

        self.refresh()

    def Reset(self):
        BaseManager.Reset(self)

        if self.list.playlist:
            cancelWorker("PlaylistManager_refresh_list_%d" % self.list.playlist.id)

    def refresh(self):
        def db_call():
            self.list.dirty = False
            return self.channelsearch_manager.getTorrentsFromPlaylist(self.list.playlist, self.guiutility.getFamilyFilter())

        if self.list.playlist:
            startWorker(self._on_data, db_call, uId=u"PlaylistManager_refresh_list_%d" % self.list.playlist.id, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    @forceDBThread
    def refresh_partial(self, ids):
        if self.list.playlist:
            id_data = {}
            for id in ids:
                if isinstance(id, str) and len(id) == 20:
                    id_data[id] = self.channelsearch_manager.getTorrentFromPlaylist(self.list.playlist, id)

            def do_gui():
                for id, data in id_data.iteritems():
                    self.list.RefreshData(id, data)
            wx.CallAfter(do_gui)

    def _on_data(self, delayedResult):
        total_items, nrfiltered, torrents = delayedResult.get()
        torrents = self.library_manager.addDownloadStates(torrents)

        self.list.SetData([], torrents)

    def torrentUpdated(self, infohash):
        if self.list.InList(infohash):
            self.do_or_schedule_partial([infohash])

    def torrentsUpdated(self, infohashes):
        infohashes = [infohash for infohash in infohashes if self.list.InList(infohash)]
        self.do_or_schedule_partial(infohashes)

    def playlistUpdated(self, playlist_id, modified=False):
        if self.list.playlist == playlist_id:
            if modified:
                self.do_or_schedule_refresh()
            else:
                self.guiutility.GoBack()


class Playlist(SelectedChannelList):

    def __init__(self, *args, **kwargs):
        self.playlist = None
        SelectedChannelList.__init__(self, *args, **kwargs)

    def _special_icon(self, item):
        if not isinstance(item, PlaylistItem) and self.playlist and self.playlist.channel:
            if self.playlist.channel.isFavorite():
                return self.favorite, self.normal, "This torrent is part of one of your favorite channels, %s" % self.playlist.channel.name
            else:
                return self.normal, self.favorite, "This torrent is not part of one of your favorite channels"
        else:
            pass

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = PlaylistManager(self)
        return self.manager

    @warnWxThread
    def CreateHeader(self, parent):
        return SelectedPlaylistFilter(parent, self, show_bundle=False)

    @warnWxThread
    def CreateTopHeader(self, parent):
        return PlaylistHeader(parent, self)

    def Set(self, playlist):
        self.playlist = playlist
        manager = self.GetManager()
        manager.SetPlaylist(playlist)
        if self.notebook.GetPageCount() > 0:
            self.notebook.SetSelection(0)
        if self.playlist:
            self.top_header.SetTitle(self.playlist)
            self.Layout()

    def SetTitle(self, title, description):
        header = u"%s's channel \u2192 %s" % (self.channel.name, self.playlist.name)

        self.header.SetTitle(header)
        self.header.SetStyle(self.playlist.description)
        self.Layout()

    def SetIds(self, channel):
        if channel:
            manager = self.commentList.GetManager()
            manager.SetIds(channel=channel, playlist=self.playlist)

            manager = self.activityList.GetManager()
            manager.SetIds(channel=channel, playlist=self.playlist)

            manager = self.moderationList.GetManager()
            manager.SetIds(channel=channel, playlist=self.playlist)

    def OnCommentCreated(self, key):
        SelectedChannelList.OnCommentCreated(self, key)

        if self.InList(key):
            manager = self.commentList.GetManager()
            manager.new_comment()

    def CreateFooter(self, parent):
        return PlaylistFooter(parent, radius=0, spacers=[7, 7])

    @warnWxThread
    def ResetBottomWindow(self):
        detailspanel = self.guiutility.SetBottomSplitterWindow(PlaylistInfoPanel)
        detailspanel.Set(len(self.list.raw_data) if self.list.raw_data else 1, self.playlist.channel.isFavorite() if self.playlist and self.playlist.channel else None)

class ManageChannelFilesManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.channel = None
        self.channelsearch_manager = self.guiutility.channelsearch_manager

        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)

        if self.channel:
            cancelWorker("ManageChannelFilesManager_refresh_%d" % self.channel.id)

        self.channel = None

    def refresh(self):
        def db_call():
            self.list.dirty = False
            return self.channelsearch_manager.getTorrentsFromChannel(self.channel, filterTorrents=False)

        startWorker(self._on_data, db_call, uId=u"ManageChannelFilesManager_refresh_%d" % self.channel.id, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def _on_data(self, delayedResult):
        total_items, nrfiltered, torrentList = delayedResult.get()
        self.list.SetData(torrentList)

    def SetChannel(self, channel):
        if self.channel != channel:
            self.channel = channel
            self.do_or_schedule_refresh()

    def RemoveItems(self, infohashes):
        for infohash in infohashes:
            self.channelsearch_manager.removeTorrent(self.channel, infohash)

    def RemoveAllItems(self):
        self.channelsearch_manager.removeAllTorrents(self.channel)

    def startDownloadFromUrl(self, url, *args, **kwargs):
        try:
            tdef = TorrentDef.load_from_url(url)
            if tdef:
                return self.AddTDef(tdef)
        except:
            print_exc()

        return False

    def startDownloadFromMagnet(self, url, *args, **kwargs):
        try:
            return TorrentDef.retrieve_from_magnet(url, self.AddTDef, timeout=300)

        except:
            print_exc()
        return False

    def startDownload(self, torrentfilename, *args, **kwargs):
        try:
            def swiftReady(sdef):
                self.AddSDef(sdef, tdef)

            # if fixtorrent not in kwargs -> new torrent created
            tdef = TorrentDef.load(torrentfilename)
            if 'fixtorrent' not in kwargs:
                download = self.guiutility.frame.startDownload(torrentfilename=torrentfilename, destdir=kwargs.get('destdir', None), correctedFilename=kwargs.get('correctedFilename', None))
                # self.guiutility.app.sesscb_reseed_via_swift(download, swiftReady)
            return self.AddTDef(tdef)

        except:
            print_exc()
        return False

    def startDownloads(self, filenames, *args, **kwargs):
        torrentdefs = []

        def swiftReady(sdef):
            self.AddSDef(sdef, tdef)

        while len(filenames) > 0:
            for torrentfilename in filenames[:500]:
                try:
                    # if fixtorrent not in kwargs -> new torrent created
                    tdef = TorrentDef.load(torrentfilename)
                    if 'fixtorrent' not in kwargs:
                        download = self.guiutility.frame.startDownload(torrentfilename=torrentfilename, destdir=kwargs.get('destdir', None), correctedFilename=kwargs.get('correctedFilename', None))
                        self.guiutility.app.sesscb_reseed_via_swift(download, swiftReady)

                    torrentdefs.append(tdef)
                except:
                    pass

            if not self.AddTDefs(torrentdefs):
                return False

            filenames = filenames[500:]
        return True

    def startDownloadFromTorrent(self, torrent):
        self.channelsearch_manager.createTorrent(self.channel, torrent)
        return True

    def AddTDef(self, tdef):
        if tdef:
            self.channelsearch_manager.createTorrentFromDef(self.channel.id, tdef)
            if not self.channel.isMyChannel():
                notification = "New torrent added to %s's channel" % self.channel.name
            else:
                notification = 'New torrent added to My Channel'
            self.guiutility.Notify(notification, icon=wx.ART_INFORMATION)

            return True
        return False

    def AddSDef(self, sdef, tdef):
        if tdef and sdef:
            torrent = self.channelsearch_manager.getTorrentFromChannel(self.channel, tdef.get_infohash())
            self.channelsearch_manager.modifyTorrent(self.channel.id, torrent.channeltorrent_id, {'swift-url': sdef.get_url()})
            return True
        return False

    def AddTDefs(self, tdefs):
        if tdefs:
            self.channelsearch_manager.createTorrentsFromDefs(self.channel.id, tdefs)
            if not self.channel.isMyChannel():
                notification = "%d new torrents added to %s's channel" % (len(tdefs), self.channel.name)
            else:
                notification = '%d new torrents added to My Channel' % len(tdefs)
            self.guiutility.Notify(notification, icon=wx.ART_INFORMATION)

            return True
        return False

    def DoExport(self, target_dir):
        if os.path.isdir(target_dir):
            torrent_dir = self.channelsearch_manager.session.get_torrent_collecting_dir()
            _, _, torrents = self.channelsearch_manager.getTorrentsFromChannel(self.channel, filterTorrents=False)

            nr_torrents_exported = 0
            for torrent in torrents:
                collected_torrent_filename = get_collected_torrent_filename(torrent.infohash)

                torrent_filename = os.path.join(torrent_dir, collected_torrent_filename)
                if os.path.isfile(torrent_filename):
                    new_torrent_filename = os.path.join(target_dir, collected_torrent_filename)
                    copyfile(torrent_filename, new_torrent_filename)

                    nr_torrents_exported += 1

            self.guiutility.Notify('%d torrents exported' % nr_torrents_exported, icon=wx.ART_INFORMATION)


class ManageChannelPlaylistsManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.channel = None
        self.channelsearch_manager = GUIUtility.getInstance().channelsearch_manager

        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)

        if self.channel:
            cancelWorker("ManageChannelPlaylistsManager_refresh_%d" % self.channel.id)

        self.channel = None

    def refresh(self):
        def db_call():
            self.list.dirty = False
            _, playlistList = self.channelsearch_manager.getPlaylistsFromChannel(self.channel)
            return playlistList

        startWorker(self.list.SetDelayedData, db_call, uId=u"ManageChannelPlaylistsManager_refresh_%d" % self.channel.id, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def refresh_partial(self, playlist_id):
        startWorker(self.list.RefreshDelayedData, self.channelsearch_manager.getPlaylist, wargs=(self.channel, playlist_id), cargs=(playlist_id,), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def SetChannel(self, channel):
        if channel != self.channel:
            self.channel = channel
            self.do_or_schedule_refresh()

    def RemoveItems(self, ids):
        for id in ids:
            self.channelsearch_manager.removePlaylist(self.channel, id)

    def RemoveAllItems(self):
        self.channelsearch_manager.removeAllPlaylists(self.channel)

    def GetTorrentsFromChannel(self):
        delayedResult = startWorker(None, self.channelsearch_manager.getTorrentsFromChannel, wargs=(self.channel,), wkwargs={'filterTorrents': False}, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        total_items, nrfiltered, torrentList = delayedResult.get()
        return torrentList

    def GetTorrentsNotInPlaylist(self):
        delayedResult = startWorker(None, self.channelsearch_manager.getTorrentsNotInPlaylist, wargs=(self.channel,), wkwargs={'filterTorrents': False}, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        total_items, nrfiltered, torrentList = delayedResult.get()
        return torrentList

    def GetTorrentsFromPlaylist(self, playlist):
        delayedResult = startWorker(None, self.channelsearch_manager.getTorrentsFromPlaylist, wargs=(playlist,), wkwargs={'filterTorrents': False}, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        total_items, nrfiltered, torrentList = delayedResult.get()
        return torrentList

    def createPlaylist(self, name, description, infohashes):
        startWorker(None, self.channelsearch_manager.createPlaylist, wargs=(self.channel.id, name, description, infohashes), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def savePlaylist(self, playlist_id, name, description):
        startWorker(None, self.channelsearch_manager.modifyPlaylist, wargs=(self.channel.id, playlist_id, name, description), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def savePlaylistTorrents(self, playlist_id, infohashes):
        startWorker(None, self.channelsearch_manager.savePlaylistTorrents, wargs=(self.channel.id, playlist_id, infohashes), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def playlistUpdated(self, playlist_id, modified=False):
        if self.list.InList(playlist_id):
            if modified:
                self.do_or_schedule_partial([playlist_id])
            else:
                self.do_or_schedule_refresh()


class ManageChannel(AbstractDetails):

    def __init__(self, parent):
        AbstractDetails.__init__(self, parent)
        self.SetForegroundColour(parent.GetForegroundColour())

        self.channel = None
        self.rss_url = None

        self.guiutility = GUIUtility.getInstance()
        self.uelog = UserEventLogDBHandler.getInstance()
        self.torrentfeed = RssParser.getInstance()
        self.channelsearch_manager = self.guiutility.channelsearch_manager

        self.SetBackgroundColour(LIST_LIGHTBLUE)
        boxSizer = wx.BoxSizer(wx.VERTICAL)

        self.header = ManageChannelHeader(self, self)
        self.header.SetBackgroundColour(LIST_LIGHTBLUE)
        boxSizer.Add(self.header, 0, wx.EXPAND)

        self.notebook = wx.Notebook(self, style=wx.NB_NOPAGETHEME)
        self.notebook.Bind(wx.EVT_NOTEBOOK_PAGE_CHANGED, self.OnChange)

        # overview page intro
        self.overviewpage = wx.Panel(self.notebook)
        self.overviewpage.SetBackgroundColour(LIST_DESELECTED)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.AddSpacer((-1, 10))
        header = ""
        self.overviewheader = self._add_header(self.overviewpage, vSizer, header, spacer=10)

        text = "Channels can be used to spread torrents to other Tribler users. "
        text += "If a channel provides other Tribler users with original or popular content, then they might mark your channel as one of their favorites. "
        text += "This will help to promote your channel, because the number of users which have marked a channel as one of their favorites is used to calculate popularity. "
        text += "Additionally, when another Tribler user marks your channel as a favorite they help you distribute all the .torrent files.\n\n"
        text += "Currently three options exist to spread torrents. "
        text += "Two of them, periodically importing .torrents from an rss feed and manually adding .torrent files, are available from the 'Manage' tab.\n"
        text += "The third option is available from the torrentview after completely downloading a torrent and allows you to add a torrent to your channel with a single click."

        overviewtext = wx.StaticText(self.overviewpage, -1, text)
        vSizer.Add(overviewtext, 0, wx.EXPAND | wx.ALL, 10)

        text = "Currently your channel is not created. Please fill in  a name and description and click the create button to start spreading your torrents."
        self.createText = wx.StaticText(self.overviewpage, -1, text)
        self.createText.Hide()
        vSizer.Add(self.createText, 0, wx.EXPAND | wx.ALL, 10)

        gridSizer = wx.FlexGridSizer(0, 2, 3, 3)
        gridSizer.AddGrowableCol(1)
        gridSizer.AddGrowableRow(1)

        self.name = EditText(self.overviewpage, '')
        self.name.SetMaxLength(40)

        self.description = EditText(self.overviewpage, '', multiline=True)
        self.description.SetMaxLength(2000)
        self.description.SetMinSize((-1, 50))

        identSizer = wx.BoxSizer(wx.VERTICAL)
        self.identifier = EditText(self.overviewpage, '')
        self.identifier.SetMaxLength(40)
        self.identifier.SetEditable(False)
        self.identifierText = BetterText(self.overviewpage, -1, 'You can use this identifier to allow other to manually join this channel.\nCopy and paste it in an email and let others join by going to Favorites and "Add Favorite channel"')

        identSizer.Add(self.identifier, 0, wx.EXPAND)
        identSizer.Add(self.identifierText, 0, wx.EXPAND)

        self._add_row(self.overviewpage, gridSizer, "Name", self.name, 10)
        self._add_row(self.overviewpage, gridSizer, 'Description', self.description, 10)
        self._add_row(self.overviewpage, gridSizer, 'Identifier', identSizer, 10)
        vSizer.Add(gridSizer, 0, wx.EXPAND | wx.RIGHT, 10)

        self.saveButton = wx.Button(self.overviewpage, -1, 'Save Changes')
        self.saveButton.Bind(wx.EVT_BUTTON, self.Save)
        vSizer.Add(self.saveButton, 0, wx.ALIGN_RIGHT | wx.ALL, 10)

        self.overviewpage.SetSizer(vSizer)
        self.overviewpage.Show(False)

        # Open2Edit settings
        self.settingspage = wx.Panel(self.notebook)
        self.settingspage.SetBackgroundColour(LIST_DESELECTED)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.AddSpacer((-1, 10))
        header = "Community Settings"
        self._add_header(self.settingspage, vSizer, header, spacer=10)

        text = "Tribler allows you to involve your community. "
        text += "You as a channel-owner have the option to define the openness of your community. "
        text += "By choosing a more open setting, other users are allowed to do more.\n\n"

        text += "Currently three configurations exist:\n"
        text += "\tOpen, only you can define playlists and delete torrents. Other users can do everything else, ie add torrents, categorize torrents, comment etc.\n"
        text += "\tSemi-Open, only you can add new .torrents. Other users can download and comment on them.\n"
        text += "\tClosed, only you can add new .torrents. Other users can only download them."
        vSizer.Add(wx.StaticText(self.settingspage, -1, text), 0, wx.EXPAND | wx.ALL, 10)

        gridSizer = wx.FlexGridSizer(0, 2, 3, 3)
        gridSizer.AddGrowableCol(1)
        gridSizer.AddGrowableRow(1)

        self.statebox = wx.RadioBox(self.settingspage, choices=('Open', 'Semi-Open', 'Closed'), style=wx.RA_VERTICAL)
        self._add_row(self.settingspage, gridSizer, "Configuration", self.statebox)
        vSizer.Add(gridSizer, 0, wx.EXPAND | wx.RIGHT, 10)

        saveButton = wx.Button(self.settingspage, -1, 'Save Changes')
        saveButton.Bind(wx.EVT_BUTTON, self.SaveSettings)
        vSizer.Add(saveButton, 0, wx.ALIGN_RIGHT | wx.ALL, 10)
        self.settingspage.SetSizer(vSizer)
        self.settingspage.Show(False)

        # shared files page
        self.fileslist = NotebookPanel(self.notebook)
        filelist = ManageChannelFilesList(self.fileslist)
        self.fileslist.SetList(filelist)
        filelist.SetNrResults = self.header.SetNrTorrents
        self.fileslist.Show(False)

        # playlist page
        self.playlistlist = NotebookPanel(self.notebook)
        self.playlistlist.SetList(ManageChannelPlaylistList(self.playlistlist))
        self.playlistlist.Show(False)

        # manage page
        self.managepage = wx.Panel(self.notebook)
        self.managepage.SetBackgroundColour(LIST_DESELECTED)
        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.AddSpacer((-1, 10))

        # rss intro
        header = "Rss import"
        self._add_header(self.managepage, vSizer, header, spacer=10)

        text = "Rss feeds are periodically checked for new .torrent files. \nFor each item in the rss feed a .torrent file should be present in either:\n\n"
        text += "\tThe link element\n"
        text += "\tA src attribute\n"
        text += "\tA url attribute"
        manageText = wx.StaticText(self.managepage, -1, text)
        vSizer.Add(manageText, 0, wx.EXPAND | wx.ALL, 10)

        # rss
        self.gridSizer = wx.FlexGridSizer(0, 2, 3)
        self.gridSizer.AddGrowableCol(1)
        self.gridSizer.AddGrowableRow(0)

        vSizer.Add(self.gridSizer, 1, wx.EXPAND | wx.ALL, 10)
        self.managepage.SetSizer(vSizer)
        self.managepage.Show(False)

        boxSizer.Add(self.notebook, 1, wx.EXPAND | wx.ALL, 5)
        self.SetSizer(boxSizer)
        self.Layout()

    def BuildRssPanel(self, parent, sizer):
        self._add_subheader(parent, sizer, "Current rss-feeds:", "(which are periodically checked)")

        rssSizer = wx.BoxSizer(wx.VERTICAL)

        if self.channel:
            urls = self.torrentfeed.getUrls(self.channel.id)
        else:
            urls = []

        if len(urls) > 0:
            rssPanel = wx.lib.scrolledpanel.ScrolledPanel(parent)
            rssPanel.SetBackgroundColour(LIST_DESELECTED)

            urlSizer = wx.FlexGridSizer(0, 2, 0, 5)
            urlSizer.AddGrowableCol(0)
            for url in urls:
                rsstext = wx.StaticText(rssPanel, -1, url.replace('&', '&&'))
                rsstext.SetMinSize((1, -1))

                deleteButton = wx.Button(rssPanel, -1, "Delete")
                deleteButton.url = url
                deleteButton.text = rsstext
                deleteButton.Bind(wx.EVT_BUTTON, self.OnDeleteRss)

                urlSizer.Add(rsstext, 1, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL)
                urlSizer.Add(deleteButton, 0, wx.ALIGN_RIGHT)

            rssPanel.SetMinSize((-1, 50))
            rssPanel.SetSizer(urlSizer)
            rssPanel.SetupScrolling(rate_y=5)
            rssSizer.Add(rssPanel, 1, wx.EXPAND)

            refresh = wx.Button(parent, -1, "Refresh all rss-feeds")
            refresh.Bind(wx.EVT_BUTTON, self.OnRefreshRss)
            rssSizer.Add(refresh, 0, wx.ALIGN_RIGHT | wx.TOP, 3)
        else:
            rssSizer.Add(wx.StaticText(parent, -1, "No rss feeds are being monitored."))

        # add-rss
        rssSizer.Add(wx.StaticText(parent, -1, "Add an rss-feed:"), 0, wx.TOP, 3)
        addSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.rss_url = wx.TextCtrl(parent)
        addButton = wx.Button(parent, -1, "Add")
        addButton.Bind(wx.EVT_BUTTON, self.OnAddRss)
        addSizer.Add(self.rss_url, 1, wx.ALIGN_CENTER_VERTICAL)
        addSizer.Add(addButton, 0, wx.LEFT | wx.ALIGN_CENTER_VERTICAL | wx.ALIGN_RIGHT, 5)
        rssSizer.Add(addSizer, 0, wx.EXPAND, 10)
        sizer.Add(rssSizer, 1, wx.EXPAND | wx.LEFT | wx.TOP | wx.BOTTOM, 10)

    def RebuildRssPanel(self):
        self.gridSizer.ShowItems(False)
        self.gridSizer.Clear()

        self.BuildRssPanel(self.managepage, self.gridSizer)
        self.managepage.Layout()

    @forceWxThread
    def SetChannel(self, channel):
        self.channel = channel

        if channel:
            self.fileslist.GetManager().SetChannel(channel)
            self.playlistlist.GetManager().SetChannel(channel)

            self.header.SetName('Management interface for %s\'s Channel' % channel.name)
            self.header.SetNrTorrents(channel.nr_torrents, channel.nr_favorites)

            if channel.isMyChannel():
                self.torrentfeed.register(self.guiutility.utility.session, channel.id)
                self.overviewheader.SetLabel('Welcome to the management interface for your channel.')

            self.name.SetValue(channel.name)
            self.name.originalValue = channel.name
            self.name.Enable(channel.isMyChannel())

            self.description.SetValue(channel.description)
            self.description.originalValue = channel.description
            self.description.Enable(channel.isMyChannel())

            self.identifier.SetValue(channel.dispersy_cid.encode('HEX'))
            self.identifier.Show(True)
            self.identifierText.Show(True)

            self.overviewpage.Layout()

            self.createText.Hide()
            self.saveButton.SetLabel('Save Changes')

            self.AddPage(self.notebook, self.overviewpage, "Overview", 0)

            def db_call():
                channel_state, iamModerator = self.channelsearch_manager.getChannelState(channel.id)
                return channel_state, iamModerator

            def update_panel(delayedResult):
                try:
                    channel_state, iamModerator = delayedResult.get()
                except:
                    startWorker(update_panel, db_call, delay=1.0, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
                    return

                if iamModerator:
                    if iamModerator and not channel.isMyChannel():
                        self.overviewheader.SetLabel('Welcome to the management interface for this channel. You can modified these setting due to having the permissions for them.')

                    self.name.Enable(True)
                    self.description.Enable(True)

                    selection = channel_state
                    if selection == 0:
                        selection = 2
                    elif selection == 2:
                        selection = 0

                    self.statebox.SetSelection(selection)
                    self.AddPage(self.notebook, self.settingspage, "Settings", 1)
                else:
                    self.overviewheader.SetLabel('Welcome to the management interface for this channel. You cannot modify any of these settings as you do not have the permissions to do so.')
                    self.RemovePage(self.notebook, "Settings")

                if iamModerator or channel_state == ChannelCommunity.CHANNEL_OPEN:
                    self.fileslist.SetFooter(channel_state, iamModerator)
                    self.AddPage(self.notebook, self.fileslist, "Manage torrents", 2)

                    self.playlistlist.SetFooter(channel_state, iamModerator)
                    self.AddPage(self.notebook, self.playlistlist, "Manage playlists", 3)
                else:
                    self.RemovePage(self.notebook, "Manage torrents")
                    self.RemovePage(self.notebook, "Manage playlists")

                if iamModerator:
                    self.RebuildRssPanel()
                    self.AddPage(self.notebook, self.managepage, "Manage", 4)
                else:
                    self.RemovePage(self.notebook, "Manage")

                self.Refresh()
                # self.CreateJoinChannelFile()

            startWorker(update_panel, db_call, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

        else:
            self.overviewheader.SetLabel('Welcome to the management interface for your channel. You currently do not yet have a channel, create one now.')

            self.name.SetValue('')
            self.name.originalValue = ''

            self.description.SetValue('')
            self.description.originalValue = ''

            self.name.Enable(True)
            self.description.Enable(True)
            self.identifier.Show(False)
            self.identifierText.Show(False)

            self.overviewpage.Layout()

            self.header.SetName('Create your own channel')
            self.header.SetNrTorrents(0, 0)

            self.createText.Show()
            self.saveButton.SetLabel('Create Channel')

            self.AddPage(self.notebook, self.overviewpage, "Overview", 0)

            # disable all other tabs, do it in reverse as pageindexes change
            for i in range(self.notebook.GetPageCount(), 1, -1):
                page = self.notebook.GetPage(i - 1)
                page.Show(False)
                self.notebook.RemovePage(i - 1)

            self.fileslist.Reset()
            self.playlistlist.Reset()

        # Always switch to page 1 after new id
        if self.notebook.GetPageCount() > 0:
            self.notebook.SetSelection(0)

    @warnWxThread
    def Reset(self):
        self.SetChannel(None)

    @forceDBThread
    def SetChannelId(self, channel_id):
        channel = self.channelsearch_manager.getChannel(channel_id)
        self.SetChannel(channel)

    def GetPage(self, notebook, title):
        for i in range(notebook.GetPageCount()):
            if notebook.GetPageText(i) == title:
                return i
        return None

    def AddPage(self, notebook, page, title, index):
        curindex = self.GetPage(notebook, title)
        if curindex is None:
            page.Show(True)

            index = min(notebook.GetPageCount(), index)
            notebook.InsertPage(index, page, title)

    def RemovePage(self, notebook, title):
        curindex = self.GetPage(notebook, title)
        if curindex is not None:
            page = notebook.GetPage(curindex)

            page.Show(False)
            notebook.RemovePage(curindex)

    def IsChanged(self):
        return self.name.IsChanged() or self.description.IsChanged()

    def OnChange(self, event):
        page = event.GetSelection()
        if page == self.GetPage(self.notebook, "Manage torrents"):
            self.fileslist.Show(isSelected=True)
            self.fileslist.Focus()

        elif page == self.GetPage(self.notebook, "Manage playlists"):
            self.playlistlist.Show(isSelected=True)
            self.playlistlist.Focus()
        event.Skip()

    def OnAddRss(self, event=None):
        url = self.rss_url.GetValue().strip()
        if len(url) > 0:
            self.torrentfeed.addURL(url, self.channel.id)
            self.RebuildRssPanel()

            self.uelog.addEvent(message="MyChannel: rssfeed added", type=2)

    def OnDeleteRss(self, event):
        item = event.GetEventObject()

        self.torrentfeed.deleteURL(item.url, self.channel.id)
        self.RebuildRssPanel()

        self.uelog.addEvent(message="MyChannel: rssfeed removed", type=2)

    def OnRefreshRss(self, event):
        self.torrentfeed.doRefresh()

        button = event.GetEventObject()
        button.Enable(False)
        wx.CallLater(5000, button.Enable, True)

        self.uelog.addEvent(message="MyChannel: rssfeed refreshed", type=2)

    def CreateJoinChannelFile(self):
        f = open('joinchannel', 'wb')
        f.write(self.channel.dispersy_cid)
        f.close()

    def _import_torrents(self, files):
        tdefs = [TorrentDef.load(file) for file in files if file.endswith(".torrent")]
        self.channelsearch_manager.createTorrentsFromDefs(self.channel.id, tdefs)
        nr_imported = len(tdefs)

        if nr_imported > 0:
            if nr_imported == 1:
                self.guiutility.Notify('New torrent added to My Channel', icon=wx.ART_INFORMATION)
            else:
                self.guiutility.Notify('Added %d torrents to your Channel' % nr_imported, icon=wx.ART_INFORMATION)

    def Show(self, show=True):
        if not show:
            if self.IsChanged():
                dlg = wx.MessageDialog(None, 'Do you want to save your changes made to this channel?', 'Save changes?', wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION)
                if dlg.ShowModal() == wx.ID_YES:
                    self.Save()

        AbstractDetails.Show(self, show)

    def Save(self, event=None):
        if self.name.GetValue():
            if self.channel:
                changes = {}
                if self.name.IsChanged():
                    changes['name'] = self.name.GetValue()
                if self.description.IsChanged():
                    changes['description'] = self.description.GetValue()

                self.channelsearch_manager.modifyChannel(self.channel.id, changes)
            else:
                self.channelsearch_manager.createChannel(self.name.GetValue(), self.description.GetValue())

            self.name.Saved()
            self.description.Saved()

            if event:
                button = event.GetEventObject()
                button.Enable(False)
                wx.CallLater(5000, button.Enable, True)

        elif sys.platform != 'darwin':
            showError(self.name)

    def SaveSettings(self, event):
        state = self.statebox.GetSelection()
        if state == 0:
            state = 2
        elif state == 2:
            state = 0

        startWorker(None, self.channelsearch_manager.setChannelState, wargs=(self.channel.id, state), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

        button = event.GetEventObject()
        button.Enable(False)
        wx.CallLater(5000, button.Enable, True)

    def playlistCreated(self, channel_id):
        if self.channel == channel_id:
            manager = self.playlistlist.GetManager()
            manager.do_or_schedule_refresh()

    def playlistUpdated(self, playlist_id, modified=False):
        manager = self.playlistlist.GetManager()
        manager.playlistUpdated(playlist_id, modified)

    def channelUpdated(self, channel_id, created=False, modified=False):
        if self.channel == channel_id:
            manager = self.fileslist.GetManager()
            manager.do_or_schedule_refresh()

            if modified:
                self.SetChannelId(channel_id)

        elif not self.channel and created:
            self.SetChannelId(channel_id)


class ManageChannelFilesList(List):

    def __init__(self, parent):
        columns = [{'name': 'Name', 'width': wx.LIST_AUTOSIZE, 'icon': 'checkbox', 'sortAsc': True, 'showColumname': False},
                   {'name': 'Date Added', 'width': 85, 'fmt': format_time, 'defaultSorted': True, 'showColumname': False}]

        List.__init__(self, columns, LIST_LIGHTBLUE, [0, 0], parent=parent, borders=False)

    def CreateHeader(self, parent):
        return TitleHeader(parent, self, self.columns, 0, wx.FONTWEIGHT_BOLD, 0)

    def CreateFooter(self, parent):
        return ManageChannelFilesFooter(parent, self.OnRemoveAll, self.OnRemoveSelected, self.OnAdd, self.OnExport)

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ManageChannelFilesManager(self)
        return self.manager

    def SetData(self, data):
        List.SetData(self, data)

        data = [(torrent.infohash, [torrent.name, torrent.time_stamp], torrent) for torrent in data]
        if len(data) > 0:
            self.list.SetData(data)
        else:
            self.list.ShowMessage('You are currently not sharing any torrents in your channel.')
            self.SetNrResults(0)

    def SetFooter(self, state, iamModerator):
        self.canDelete = iamModerator
        self.canAdd = (state == ChannelCommunity.CHANNEL_OPEN) or iamModerator

        self.footer.SetState(self.canDelete, self.canAdd)

        if self.canDelete:
            self.header.SetTitle('Use this view to add or remove torrents')
        elif self.canAdd:
            self.header.SetTitle('Use this view to add torrents')
        else:
            self.header.SetTitle('')

    def OnExpand(self, item):
        return True

    def OnRemoveAll(self, event):
        dlg = wx.MessageDialog(None, 'Are you sure you want to remove all torrents from your channel?', 'Remove torrents', wx.ICON_QUESTION | wx.YES_NO | wx.NO_DEFAULT)
        if dlg.ShowModal() == wx.ID_YES:
            self.GetManager().RemoveAllItems()
        dlg.Destroy()

    def OnRemoveSelected(self, event):
        dlg = wx.MessageDialog(None, 'Are you sure you want to remove all selected torrents from your channel?', 'Remove torrents', wx.ICON_QUESTION | wx.YES_NO | wx.NO_DEFAULT)
        if dlg.ShowModal() == wx.ID_YES:
            infohashes = [key for key, _ in self.list.GetExpandedItems()]
            self.GetManager().RemoveItems(infohashes)
        dlg.Destroy()

    def OnAdd(self, event):
        _, libraryTorrents = self.guiutility.library_manager.getHitsInCategory()

        dlg = AddTorrent(None, self.GetManager(), libraryTorrents)
        dlg.CenterOnParent()
        dlg.ShowModal()
        dlg.Destroy()

    def OnExport(self, event):
        dlg = wx.DirDialog(None, "Please select a directory to which all .torrents should be exported", style=wx.wx.DD_DIR_MUST_EXIST)
        if dlg.ShowModal() == wx.ID_OK and os.path.isdir(dlg.GetPath()):
            self.GetManager().DoExport(dlg.GetPath())
        dlg.Destroy()


class ManageChannelPlaylistList(ManageChannelFilesList):

    def __init__(self, parent):
        columns = [{'name': 'Name', 'width': wx.LIST_AUTOSIZE, 'icon': 'checkbox', 'sortAsc': True, 'showColumname': False}]

        List.__init__(self, columns, LIST_LIGHTBLUE, [0, 0], True, parent=parent, borders=False)

    def CreateFooter(self, parent):
        return ManageChannelPlaylistFooter(parent, self.OnNew)

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ManageChannelPlaylistsManager(self)
        return self.manager

    @forceWxThread
    def RefreshData(self, key, playlist):
        data = (playlist.id, (playlist.name,), playlist)
        self.list.RefreshData(key, data)

    @forceWxThread
    def SetData(self, data):
        List.SetData(self, data)

        data = [(playlist.id, [playlist.name, playlist.nr_torrents, 0, 0], playlist, PlaylistItem, index) for index, playlist in enumerate(data)]
        if len(data) > 0:
            self.list.SetData(data)
        else:
            self.list.ShowMessage('You currently do not have any playlists in your channel.')
            self.SetNrResults(0)

    def SetFooter(self, state, iamModerator):
        self.canDelete = iamModerator
        self.canAdd = (state == ChannelCommunity.CHANNEL_OPEN) or iamModerator

        self.footer.SetState(self.canDelete, self.canAdd)

        if self.canDelete:
            self.header.SetTitle('Use this view to create, modify and delete playlists')
        elif self.canAdd:
            self.header.SetTitle('Use this view to add torrents to existing playlists')
        else:
            self.header.SetTitle('')

    def OnExpand(self, item):
        return MyChannelPlaylist(item, self.OnEdit, self.canDelete, self.OnSave, self.OnRemoveSelected, item.original_data)

    def OnCollapse(self, item, panel, from_expand):
        playlist_id = item.original_data.get('id', False)
        if playlist_id:
            if panel.IsChanged():
                dlg = wx.MessageDialog(None, 'Do you want to save your changes made to this playlist?', 'Save changes?', wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION)
                if dlg.ShowModal() == wx.ID_YES:
                    self.OnSave(playlist_id, panel)
        ManageChannelFilesList.OnCollapse(self, item, panel, from_expand)
        self.list.Layout()

    def OnSave(self, playlist_id, panel):
        name, description, _ = panel.GetInfo()
        manager = self.GetManager()
        manager.savePlaylist(playlist_id, name, description)

    def OnNew(self, event):
        vSizer = wx.BoxSizer(wx.VERTICAL)

        dlg = wx.Dialog(None, -1, 'Create a new playlist', size=(500, 300), style=wx.RESIZE_BORDER | wx.DEFAULT_DIALOG_STYLE)
        playlistdetails = MyChannelPlaylist(dlg, self.OnManage, can_edit=True)

        vSizer.Add(playlistdetails, 1, wx.EXPAND | wx.ALL, 3)
        vSizer.Add(dlg.CreateSeparatedButtonSizer(wx.OK | wx.CANCEL), 0, wx.EXPAND | wx.ALL, 3)

        dlg.SetSizer(vSizer)
        if dlg.ShowModal() == wx.ID_OK:
            name, description, infohashes = playlistdetails.GetInfo()

            manager = self.GetManager()
            manager.createPlaylist(name, description, infohashes)
        dlg.Destroy()

#    def OnRemoveAll(self, event):
#        dlg = wx.MessageDialog(None, 'Are you sure you want to remove all playlists from your channel?', 'Remove playlists', wx.ICON_QUESTION | wx.YES_NO | wx.NO_DEFAULT)
#        if dlg.ShowModal() == wx.ID_YES:
#            self.GetManager().RemoveAllItems()
#        dlg.Destroy()

    def OnRemoveSelected(self, playlist_id, panel):
        dlg = wx.MessageDialog(None, 'Are you sure you want to remove this playlist from your channel?', 'Remove playlist', wx.ICON_QUESTION | wx.YES_NO | wx.NO_DEFAULT)
        if dlg.ShowModal() == wx.ID_YES:
            self.GetManager().RemoveItems([playlist_id])
        dlg.Destroy()

    def OnEdit(self, playlist):
        torrent_ids = self.OnManage(playlist)
        if torrent_ids is not None:
            manager = self.GetManager()
            manager.savePlaylistTorrents(playlist.id, torrent_ids)

    def OnManage(self, playlist):
        dlg = wx.Dialog(None, -1, 'Manage the torrents for this playlist', size=(900, 500), style=wx.RESIZE_BORDER | wx.DEFAULT_DIALOG_STYLE)

        manager = self.GetManager()
        available = manager.GetTorrentsFromChannel()
        not_in_playlist = manager.GetTorrentsNotInPlaylist()
        if playlist.get('id', False):
            dlg.selected = manager.GetTorrentsFromPlaylist(playlist)
        else:
            dlg.selected = []

        selected_infohashes = [data.infohash for data in dlg.selected]
        dlg.available = [data for data in available if data.infohash not in selected_infohashes]
        dlg.not_in_playlist = [data for data in not_in_playlist]
        dlg.filtered_available = None

        selected_names = [torrent.name for torrent in dlg.selected]
        available_names = [torrent.name for torrent in dlg.available]

        dlg.selectedList = wx.ListBox(dlg, choices=selected_names, style=wx.LB_MULTIPLE)
        dlg.selectedList.SetMinSize((1, -1))

        dlg.availableList = wx.ListBox(dlg, choices=available_names, style=wx.LB_MULTIPLE)
        dlg.availableList.SetMinSize((1, -1))

        sizer = wx.FlexGridSizer(2, 3, 3, 3)
        sizer.AddGrowableRow(1)
        sizer.AddGrowableCol(0, 1)
        sizer.AddGrowableCol(2, 1)

        selectedText = wx.StaticText(dlg, -1, "Selected torrents")
        _set_font(selectedText, size_increment=1, fontweight=wx.FONTWEIGHT_BOLD)
        sizer.Add(selectedText, 0, wx.ALIGN_CENTER_VERTICAL)
        sizer.AddSpacer(1)

        availableText = wx.StaticText(dlg, -1, "Available torrents")
        _set_font(availableText, size_increment=1, fontweight=wx.FONTWEIGHT_BOLD)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(availableText, 1, wx.ALIGN_CENTER_VERTICAL)

        dlg.filter = wx.SearchCtrl(dlg)
        dlg.filter.SetDescriptiveText('Search within torrents')
        dlg.filter.Bind(wx.EVT_TEXT, self.OnKey)
        dlg.filter.SetMinSize((175, -1))
        hSizer.Add(dlg.filter)
        sizer.Add(hSizer, 1, wx.EXPAND)

        sizer.Add(dlg.selectedList, 1, wx.EXPAND)

        vSizer = wx.BoxSizer(wx.VERTICAL)

        add = wx.Button(dlg, -1, "<<", style=wx.BU_EXACTFIT)
        add.SetToolTipString("Add selected torrents to playlist")
        add.Bind(wx.EVT_BUTTON, self.OnAdd)
        vSizer.Add(add)

        if self.canDelete:
            remove = wx.Button(dlg, -1, ">>", style=wx.BU_EXACTFIT)
            remove.SetToolTipString("Remove selected torrents from playlist")
            remove.Bind(wx.EVT_BUTTON, self.OnRemove)
            vSizer.Add(remove)

        sizer.Add(vSizer, 0, wx.ALIGN_CENTER_VERTICAL)

        sizer.Add(dlg.availableList, 1, wx.EXPAND)
        sizer.AddSpacer((1, 1))
        sizer.AddSpacer((1, 1))

        self.all = wx.RadioButton(dlg, -1, "Show all available torrents", style=wx.RB_GROUP)
        self.all.Bind(wx.EVT_RADIOBUTTON, self.OnRadio)
        self.all.dlg = dlg
        self.playlist = wx.RadioButton(dlg, -1, "Show torrents not yet present in a playlist")
        self.playlist.Bind(wx.EVT_RADIOBUTTON, self.OnRadio)
        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(self.all)
        vSizer.Add(self.playlist)
        sizer.Add(vSizer)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(sizer, 1, wx.TOP | wx.LEFT | wx.RIGHT | wx.EXPAND, 10)
        vSizer.AddSpacer((1, 3))
        vSizer.Add(dlg.CreateSeparatedButtonSizer(wx.OK | wx.CANCEL), 0, wx.EXPAND | wx.BOTTOM | wx.LEFT | wx.RIGHT, 10)

        dlg.SetSizer(vSizer)

        if dlg.ShowModal() == wx.ID_OK:
            return_val = [data.infohash for data in dlg.selected]
        else:
            return_val = None

        dlg.Destroy()
        return return_val

    def OnKey(self, event):
        dlg = event.GetEventObject().GetParent()
        self._filterAvailable(dlg)

    def OnRemove(self, event):
        dlg = event.GetEventObject().GetParent()
        selected = dlg.selectedList.GetSelections()

        to_be_removed = []
        for i in selected:
            to_be_removed.append(dlg.selected[i])

        dlg.available.extend(to_be_removed)
        dlg.not_in_playlist.extend(to_be_removed)
        for item in to_be_removed:
            dlg.selected.remove(item)

        self._rebuildLists(dlg)

    def OnRadio(self, event):
        dlg = self.all.dlg
        self._filterAvailable(dlg)

    def OnAdd(self, event):
        dlg = event.GetEventObject().GetParent()
        selected = dlg.availableList.GetSelections()

        to_be_removed = []
        for i in selected:
            if dlg.filtered_available:
                to_be_removed.append(dlg.filtered_available[i])
            elif self.all.GetValue():
                to_be_removed.append(dlg.available[i])
            else:
                to_be_removed.append(dlg.not_in_playlist[i])

        dlg.selected.extend(to_be_removed)
        for item in to_be_removed:
            if self.all.GetValue():
                dlg.available.remove(item)
            else:
                dlg.not_in_playlist.remove(item)

        self._rebuildLists(dlg)

    def _filterAvailable(self, dlg):
        keyword = dlg.filter.GetValue().strip().lower()
        try:
            re.compile(keyword)
        except:  # regex incorrect
            keyword = ''

        if len(keyword) > 0:
            def match(item):
                return re.search(keyword, item.name.lower())

            if self.all.GetValue():
                filtered_contents = filter(match, dlg.available)
            else:
                filtered_contents = filter(match, dlg.not_in_playlist)
            dlg.filtered_available = filtered_contents

        elif self.all.GetValue():
            filtered_contents = dlg.available
            dlg.filtered_available = None
        else:
            filtered_contents = dlg.not_in_playlist
            dlg.filtered_available = None

        names = [torrent.name for torrent in filtered_contents]
        dlg.availableList.SetItems(names)

    def _rebuildLists(self, dlg):
        names = [torrent.name for torrent in dlg.selected]
        dlg.selectedList.SetItems(names)
        self._filterAvailable(dlg)


class CommentManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.channelsearch_manager = GUIUtility.getInstance().channelsearch_manager

        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)

        self.channel = None
        self.playlist = None
        self.channeltorrent = None

    def SetIds(self, channel, playlist=None, channeltorrent=None):
        changed = False

        if channel:
            self.channel = channel
            if self.list.header:
                self.list.header.SetTitle('Comments for this channel')

            if channel:
                self.list.EnableCommeting(channel.isSemiOpen())
            else:
                self.list.EnableCommeting(False)

            changed = True

        if playlist:
            self.playlist = playlist
            if self.list.header:
                self.list.header.SetTitle('Comments for this playlist')

            changed = True

        elif channeltorrent:
            assert isinstance(channeltorrent, ChannelTorrent) or (isinstance(channeltorrent, CollectedTorrent) and isinstance(channeltorrent.torrent, ChannelTorrent)), type(channeltorrent)
            self.channeltorrent = channeltorrent
            if self.list.header:
                self.list.header.SetTitle('Comments for this torrent')

            changed = True

        if changed:
            self.do_or_schedule_refresh()

    def refresh(self):
        channel = self.channel
        if self.playlist:
            channel = self.playlist.channel
        elif self.channeltorrent:
            channel = self.channeltorrent.channel

        def db_callback():
            self.list.dirty = False

            if self.playlist:
                return self.channelsearch_manager.getCommentsFromPlayList(self.playlist)
            if self.channeltorrent:
                return self.channelsearch_manager.getCommentsFromChannelTorrent(self.channeltorrent)
            return self.channelsearch_manager.getCommentsFromChannel(self.channel)

        if channel.isFavorite() or channel.isMyChannel():
            startWorker(self.list.SetDelayedData, db_callback, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        else:
            self.list.ShowPreview()
            self.list.dirty = False

    def new_comment(self):
        self.do_or_schedule_refresh()

    def addComment(self, comment):
        item = self.list.GetExpandedItem()
        if item:
            _, replycomment = item.original_data
            reply_to = replycomment.dispersy_id
        else:
            reply_to = None

        reply_after = None
        items = self.list.GetItems().values()
        if len(items) > 0:
            _, prevcomment = items[-1].original_data
            reply_after = prevcomment.dispersy_id

        def db_callback():
            if self.playlist:
                self.channelsearch_manager.createComment(comment, self.channel, reply_to, reply_after, playlist=self.playlist)
            elif self.channeltorrent:
                self.channelsearch_manager.createComment(comment, self.channel, reply_to, reply_after, infohash=self.channeltorrent.infohash)
            else:
                self.channelsearch_manager.createComment(comment, self.channel, reply_to, reply_after)
        startWorker(None, workerFn=db_callback, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def removeComment(self, comment):
        self.channelsearch_manager.removeComment(comment, self.channel)


class CommentList(List):

    def __init__(self, parent, parent_list, canReply=False, quickPost=False, horizontal=False, noheader=False):
        if quickPost:
            self.quickPost = self.OnThankYou
        else:
            self.quickPost = None
        self.horizontal = horizontal
        self.noheader = noheader

        List.__init__(self, [], LIST_GREY, [10, 10], parent=parent, singleSelect=True, borders=False)
        self.parent_list = parent_list
        self.canReply = canReply

    def _PostInit(self):
        self.header = self.CreateHeader(self.parent) if not self.noheader else None
        if self.header:
            self.Add(self.header, 0, wx.EXPAND)

        self.list = self.CreateList(self.parent)
        self.footer = self.CreateFooter(self.parent)

        if self.horizontal:
            listSizer = wx.BoxSizer(wx.HORIZONTAL)

            listSizer.Add(self.footer, 0, wx.EXPAND)
            listSizer.Add(self.list, 1, wx.EXPAND)

            self.Add(listSizer, 1, wx.EXPAND)

        else:
            self.Add(self.list, 1, wx.EXPAND)
            self.Add(self.footer, 0, wx.EXPAND)

        self.SetBackgroundColour(self.background)
        self.Layout()

        self.list.Bind(wx.EVT_SIZE, self.OnSize)

    def CreateHeader(self, parent):
        return TitleHeader(parent, self, [], 0, radius=0, spacers=[10, 10])

    def CreateFooter(self, parent):
        return CommentFooter(parent, self.OnNew, self.quickPost, self.horizontal)

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = CommentManager(self)
        return self.manager

    @forceWxThread
    def SetData(self, data):
        List.SetData(self, data)

        listData = []

        def addComments(comment, depth):
            listData.append((comment.id, [], (depth, comment), CommentItem))
            for reply in comment.replies:
                addComments(reply, depth + 1)

        for comment in data:
            addComments(comment, 0)

        if len(listData) > 0:
            self.list.SetData(listData)
        else:
            self.list.ShowMessage('No comments are found.')
            self.SetNrResults(0)

    def ShowPreview(self):
        altControl = None
        if isinstance(self.parent_list, SelectedChannelList):
            def create_button(parentPanel):
                hSizer = wx.BoxSizer(wx.HORIZONTAL)
                hSizer.AddStretchSpacer()

                button = wx.Button(parentPanel, -1, 'Mark as Favorite')
                button.Bind(wx.EVT_BUTTON, self.parent_list.OnFavorite)
                hSizer.Add(button, 0, wx.TOP, 3)
                hSizer.AddStretchSpacer()
                return hSizer

            altControl = create_button
        self.list.ShowMessage('You have to mark this channel as a Favorite to start receiving comments.', 'No comments received yet', altControl)

    def EnableCommeting(self, enable=True):
        self.footer.EnableCommeting(enable)

    def OnExpand(self, item):
        if self.canReply:
            self.footer.SetReply(True)
        return True

    def OnCollapse(self, item, panel, from_expand):
        List.OnCollapse(self, item, panel, from_expand)
        self.footer.SetReply(False)

    def OnNew(self, event):
        comment = self.footer.GetComment()
        self.GetManager().addComment(comment)

        self.footer.SetComment('')

    def OnThankYou(self, event):
        self.GetManager().addComment(u'Thanks for uploading')
        self.footer.SetComment('')

    def OnShowTorrent(self, torrent):
        self.parent_list.Select(torrent)

    def OnRemoveComment(self, comment):
        self.GetManager().removeComment(comment)


class ActivityManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.channelsearch_manager = GUIUtility.getInstance().channelsearch_manager
        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)

        self.channel = None
        self.playlist = None
        self.channeltorrent = None

    def SetIds(self, channel, playlist=None):
        if channel:
            self.channel = channel
            self.list.dirty = True

            self.list.header.SetTitle('Recent activity in this Channel')

        if playlist:
            self.playlist = playlist
            self.list.dirty = True

            self.list.header.SetTitle('Recent activity in this Playlist')

    def refresh(self):
        def db_callback():
            self.list.dirty = False

            if self.playlist:
                commentList = self.channelsearch_manager.getCommentsFromPlayList(self.playlist, limit=10)
                nrTorrents, _, torrentList = self.channelsearch_manager.getTorrentsFromPlaylist(self.playlist, limit=10)
                nrRecentTorrents, _, recentTorrentList = self.channelsearch_manager.getRecentTorrentsFromPlaylist(self.playlist, limit=10)
                recentModifications = self.channelsearch_manager.getRecentModificationsFromPlaylist(self.playlist, limit=10)
                recentModerations = self.channelsearch_manager.getRecentModerationsFromPlaylist(self.playlist, limit=10)
                recent_markings = self.channelsearch_manager.getRecentMarkingsFromPlaylist(self.playlist, limit=10)
            else:
                commentList = self.channelsearch_manager.getCommentsFromChannel(self.channel, limit=10)
                nrTorrents, _, torrentList = self.channelsearch_manager.getTorrentsFromChannel(self.channel, limit=10)
                nrRecentTorrents, _, recentTorrentList = self.channelsearch_manager.getRecentReceivedTorrentsFromChannel(self.channel, limit=10)
                recentModifications = self.channelsearch_manager.getRecentModificationsFromChannel(self.channel, limit=10)
                recentModerations = self.channelsearch_manager.getRecentModerationsFromChannel(self.channel, limit=10)
                recent_markings = self.channelsearch_manager.getRecentMarkingsFromChannel(self.channel, limit=10)

            return torrentList, recentTorrentList, commentList, recentModifications, recentModerations, recent_markings

        def do_gui(delayedResult):
            torrentList, recentTorrentList, commentList, recentModifications, recentModerations, recent_markings = delayedResult.get()

            self.channelsearch_manager.populateWithPlaylists(torrentList)
            self.channelsearch_manager.populateWithPlaylists(recentTorrentList)
            self.list.SetData(commentList, torrentList, recentTorrentList, recentModifications, recentModerations, recent_markings)

        if self.channel.isFavorite() or self.channel.isMyChannel():
            startWorker(do_gui, db_callback, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        else:
            self.list.ShowPreview()
            self.list.dirty = False

    def new_activity(self):
        self.do_or_schedule_refresh()


class ActivityList(List):

    def __init__(self, parent, parent_list):
        List.__init__(self, [], LIST_GREY, [10, 10], parent=parent, singleSelect=True, borders=False)
        self.parent_list = parent_list
        self.channelsearch_manager = GUIUtility.getInstance().channelsearch_manager

    def CreateHeader(self, parent):
        return TitleHeader(parent, self, [], 0, radius=0, spacers=[10, 10])

    def CreateFooter(self, parent):
        return None

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ActivityManager(self)
        return self.manager

    @forceWxThread
    def SetData(self, comments, recent_torrents, recent_received_torrents, recent_modifications, recent_moderations, recent_markings):
        List.SetData(self, recent_torrents)

        # remove duplicates
        recent_torrent_infohashes = set([torrent.infohash for torrent in recent_torrents])
        recent_received_torrents = [torrent for torrent in recent_received_torrents if torrent.infohash not in recent_torrent_infohashes]

        # first element must be timestamp, allows for easy sorting
        data = [(comment.inserted, ("COMMENT_%d" % comment.id, (), (0, comment), CommentActivityItem)) for comment in comments]
        data += [(torrent.inserted, (torrent.infohash, (), torrent, NewTorrentActivityItem)) for torrent in recent_torrents]
        data += [(torrent.inserted, (torrent.infohash, (), torrent, TorrentActivityItem)) for torrent in recent_received_torrents]
        data += [(modification.inserted, ("MODIFICATION_%d" % modification.id, (), modification, ModificationActivityItem)) for modification in recent_modifications if modification.name != "swift-url"]
        data += [(modification.inserted, ("MODERATION_%d" % moderation.id, (), moderation, ModerationActivityItem)) for moderation in recent_moderations]
        data += [(marking.time_stamp, (marking.dispersy_id, (), marking, MarkingActivityItem)) for marking in recent_markings]
        data.sort(reverse=True)

        # removing timestamp
        data = [item for _, item in data]
        if len(data) > 0:
            self.list.SetData(data)
        else:
            self.list.ShowMessage('No recent activity is found.')

    @forceWxThread
    def ShowPreview(self):
        altControl = None
        if isinstance(self.parent_list, SelectedChannelList):
            def create_button(parentPanel):
                hSizer = wx.BoxSizer(wx.HORIZONTAL)
                hSizer.AddStretchSpacer()

                button = wx.Button(parentPanel, -1, 'Mark as Favorite')
                button.Bind(wx.EVT_BUTTON, self.parent_list.OnFavorite)
                hSizer.Add(button, 0, wx.TOP, 3)
                hSizer.AddStretchSpacer()
                return hSizer

            altControl = create_button
        self.list.ShowMessage('You have to mark this channel as a Favorite to start seeing activity.', 'No activity received yet', altControl)

    def OnShowTorrent(self, torrent):
        self.parent_list.Select(torrent)


class ModificationManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.channelsearch_manager = GUIUtility.getInstance().channelsearch_manager
        self.Reset()

    def Reset(self):
        self.torrent = None

    def SetIds(self, channeltorrent):
        if channeltorrent != self.torrent:
            self.torrent = channeltorrent
            self.do_or_schedule_refresh()

    def refresh(self):
        def db_callback():
            self.list.dirty = False
            return self.channelsearch_manager.getTorrentModifications(self.torrent)

        if self.torrent.channel.isFavorite() or self.torrent.channel.isMyChannel():
            startWorker(self.list.SetDelayedData, db_callback, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        else:
            self.list.ShowPreview()
            self.list.dirty = False

    def new_modification(self):
        self.do_or_schedule_refresh()

    def OnRevertModification(self, modification, reason, warning=False):
        severity = 1 if warning else 0
        self.channelsearch_manager.revertModification(self.torrent.channel, modification, reason, severity, None)


class ModificationList(List):

    def __init__(self, parent, canModify=True):
        List.__init__(self, [], LIST_GREY, [7, 7], parent=parent, singleSelect=True, borders=False)
        self.canModify = canModify

    def CreateHeader(self, parent):
        return None

    def CreateFooter(self, parent):
        return None

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ModificationManager(self)
        return self.manager

    @forceWxThread
    def SetData(self, data):
        List.SetData(self, data)
        data = [(modification.id, (), modification, ModificationItem) for modification in data]

        if len(data) > 0:
            self.list.SetData(data)
        else:
            self.list.ShowMessage('No modifications are found.')
            self.SetNrResults(0)

    @forceWxThread
    def ShowPreview(self):
        self.list.ShowMessage('You have to mark this channel as a Favorite to start seeing modifications.', 'No modifications received yet')

    def OnRevertModification(self, modification):
        dlg = wx.Dialog(None, -1, 'Revert this modification', size=(700, 400), style=wx.RESIZE_BORDER | wx.DEFAULT_DIALOG_STYLE)
        dlg.SetBackgroundColour(DEFAULT_BACKGROUND)
        vSizer = wx.BoxSizer(wx.VERTICAL)

        vSizer.Add(ModificationItem(dlg, dlg, '', '', modification, list_selected=DEFAULT_BACKGROUND), 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.TOP, 7)
        dlg.OnExpand = lambda a: False
        dlg.OnChange = vSizer.Layout

        why = BetterText(dlg, -1, 'Why do you want to revert this modification?')
        _set_font(why, fontweight=wx.FONTWEIGHT_BOLD)
        ori_why_colour = why.GetForegroundColour()
        vSizer.Add(why, 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.TOP, 7)

        reason = wx.TextCtrl(dlg, -1, style=wx.TE_MULTILINE)
        reason.SetMinSize((-1, 50))
        vSizer.Add(reason, 1, wx.EXPAND | wx.LEFT | wx.RIGHT, 7)

        def canClose(event):
            givenReason = reason.GetValue().strip()
            if givenReason == '':
                why.SetForegroundColour(wx.RED)
                wx.CallLater(500, why.SetForegroundColour, ori_why_colour)
            else:
                button = event.GetEventObject()
                dlg.EndModal(button.GetId())

        buttonSizer = wx.BoxSizer(wx.HORIZONTAL)
        cancel = wx.Button(dlg, wx.ID_CANCEL, '')
        buttonSizer.Add(cancel)

        revertAndWarn = wx.Button(dlg, -1, 'Revent and Warn')
        revertAndWarn.Bind(wx.EVT_BUTTON, canClose)
        buttonSizer.Add(revertAndWarn)

        revert = wx.Button(dlg, -1, 'Revert')
        revert.Bind(wx.EVT_BUTTON, canClose)
        buttonSizer.Add(revert)

        vSizer.AddStretchSpacer()
        vSizer.Add(buttonSizer, 0, wx.ALIGN_RIGHT | wx.LEFT | wx.RIGHT | wx.BOTTOM | wx.TOP, 7)

        dlg.SetSizer(vSizer)
        id = dlg.ShowModal()
        if id == revertAndWarn.GetId():
            self.GetManager().OnRevertModification(modification, reason.GetValue(), warning=True)
        elif id == revert.GetId():
            self.GetManager().OnRevertModification(modification, reason.GetValue())

        dlg.Destroy()


class ModerationManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.channelsearch_manager = GUIUtility.getInstance().channelsearch_manager
        self.Reset()

    def Reset(self):
        self.channel = None
        self.playlist = None
        self.channeltorrent = None

    def SetIds(self, channel=None, playlist=None):
        changed = False
        if channel:
            self.channel = channel
            self.list.header.SetTitle('Recent moderations for this Channel')

            changed = True

        if playlist:
            self.playlist = playlist
            self.list.header.SetTitle('Recent moderations for this Playlist')

            changed = True

        if changed:
            self.do_or_schedule_refresh()

    def refresh(self):
        def db_callback():
            self.list.dirty = False
            if self.playlist:
                return self.channelsearch_manager.getRecentModerationsFromPlaylist(self.playlist, 25)
            return self.channelsearch_manager.getRecentModerationsFromChannel(self.channel, 25)

        if self.channel.isFavorite() or self.channel.isMyChannel():
            startWorker(self.list.SetDelayedData, db_callback, retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        else:
            self.list.ShowPreview()
            self.list.dirty = False

    def new_moderation(self):
        self.do_or_schedule_refresh()


class ModerationList(List):

    def __init__(self, parent, parent_list):
        List.__init__(self, [], LIST_GREY, [10, 10], parent=parent, singleSelect=True, borders=False)
        self.parent_list = parent_list

    def CreateHeader(self, parent):
        return TitleHeader(parent, self, [], 0, radius=0, spacers=[10, 10])

    def CreateFooter(self, parent):
        return None

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ModerationManager(self)
        return self.manager

    @forceWxThread
    def SetData(self, data):
        List.SetData(self, data)
        data = [(moderation.id, (), moderation, ModerationItem) for moderation in data]

        if len(data) > 0:
            self.list.SetData(data)
        else:
            self.list.ShowMessage('No moderations are found.\nModerations are modifications which are reverted by another peer.')
            self.SetNrResults(0)

    @forceWxThread
    def ShowPreview(self):
        altControl = None
        if isinstance(self.parent_list, SelectedChannelList):
            def create_button(parentPanel):
                hSizer = wx.BoxSizer(wx.HORIZONTAL)
                hSizer.AddStretchSpacer()

                button = wx.Button(self.list.messagePanel, -1, 'Mark as Favorite')
                button.Bind(wx.EVT_BUTTON, self.parent_list.OnFavorite)
                hSizer.Add(button, 0, wx.TOP, 3)
                hSizer.AddStretchSpacer()
                return hSizer

            altControl = create_button
        self.list.ShowMessage('You have to mark this channel as a Favorite to start seeing moderations.', 'No moderations received yet', altControl)

    def OnShowTorrent(self, torrent):
        self.parent_list.Select(torrent)

########NEW FILE########
__FILENAME__ = DispersyDebugFrame
import wx
from wx.lib.mixins.listctrl import ListCtrlAutoWidthMixin
import binascii
from collections import defaultdict

from Tribler.Main.vwxGUI import LIST_GREY
from Tribler.Main.vwxGUI.widgets import _set_font, SimpleNotebook
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.Utility.GuiDBHandler import startWorker, GUI_PRI_DISPERSY

DATA_NONE = ""


class AutoWidthListCtrl(wx.ListCtrl, ListCtrlAutoWidthMixin):

    def __init__(self, parent, id, style):
        wx.ListCtrl.__init__(self, parent, id, style=style)
        ListCtrlAutoWidthMixin.__init__(self)

    def UpdateData(self, data_list):
        if not data_list:
            self.DeleteAllItems()
            return
        old_count = self.GetItemCount()
        new_count = len(data_list)

        to_modify_count = new_count if new_count < old_count else old_count
        to_append_count = new_count - to_modify_count
        to_delete_count = old_count - new_count

        row = 0
        for _ in xrange(to_modify_count):
            for col in xrange(len(data_list[row])):
                self.SetStringItem(row, col, data_list[row][col])
            row += 1
        for _ in xrange(to_append_count):
            self.Append(list(data_list[row]))
            row += 1
        for _ in xrange(to_delete_count):
            self.DeleteItem(row)


def set_small_modern_font(control):
    font = control.GetFont()
    font.SetPointSize(font.GetPointSize() - 1)
    font.SetFamily(wx.FONTFAMILY_MODERN)
    font.SetStyle(wx.FONTSTYLE_NORMAL)
    font.SetWeight(wx.FONTWEIGHT_NORMAL)
    control.SetFont(font)

def compute_ratio(i, j):
    return "%d / %d ~%.1f%%" % (i, j, (100.0 * i / j) if j else 0.0)

def str2unicode(string):
    if isinstance(string, unicode):
        return string
    try:
        converted_str = string.decode('utf-8')
        converted_str = string
    except UnicodeDecodeError:
        converted_str = binascii.hexlify(string).encode('utf-8')
    return converted_str

# ==================================================
# Frame
# ==================================================

class DispersyDebugFrame(wx.Frame):

    def __init__(self, parent, id, dispersy):
        super(DispersyDebugFrame, self).__init__(parent, id,
            "Dispersy Debug Frame", size=(1280, 720), name="DispersyDebugFrame")
        self.__dispersy = dispersy
        self.SetBackgroundColour(LIST_GREY)

        self.__notebook = SimpleNotebook(self, show_single_tab=True, style=wx.NB_NOPAGETHEME)

        self.__summary_panel = DispersySummaryPanel(self.__notebook, -1)
        self.__community_panel = CommunityPanel(self.__notebook, -1)
        self.__rawinfo_panel = RawInfoPanel(self.__notebook, -1)
        self.__runtime_panel = RuntimeProfilingPanel(self.__notebook, -1)

        self.__notebook.AddPage(self.__summary_panel, "Summary")
        self.__notebook.AddPage(self.__community_panel, "Community")
        self.__notebook.AddPage(self.__rawinfo_panel, "Raw Info")
        self.__notebook.AddPage(self.__runtime_panel, "Runtime Profiling")

        hsizer = wx.BoxSizer(wx.HORIZONTAL)
        self.__incstuff_checkbox = wx.CheckBox(self, -1, "include stuff")
        self.__incdebug_checkbox = wx.CheckBox(self, -1, "include debug")
        self.__incdebug_checkbox.SetValue(self.__dispersy.statistics.are_debug_statistics_enabled())

        self.__incstuff = False
        self.__incdebug = True

        hsizer.Add(self.__incstuff_checkbox, 0, wx.EXPAND)
        hsizer.Add(self.__incdebug_checkbox, 0, wx.EXPAND)

        self.__incstuff_checkbox.Bind(wx.EVT_CHECKBOX, self.OnIncludeStuffClicked)
        self.__incdebug_checkbox.Bind(wx.EVT_CHECKBOX, self.OnIncludeDebugClicked)

        vsizer = wx.BoxSizer(wx.VERTICAL)
        vsizer.Add(self.__notebook, 1, wx.EXPAND)
        vsizer.Add(hsizer, 0, wx.EXPAND | wx.ALL, 3)
        self.SetSizer(vsizer)

        self.__dispersy_update_timer = wx.Timer(self)
        self.Bind(wx.EVT_TIMER, self.UpdateInfo, self.__dispersy_update_timer)
        self.__dispersy_update_timer.Start(5000, False)

        self.UpdateInfo()

    def SwitchTab(self, num):
        self.__notebook.SetSelection(num)

    def OnIncludeStuffClicked(self, event):
        self.UpdateInfo()

    def OnIncludeDebugClicked(self, event):
        self.__dispersy.statistics.enable_debug_statistics(self.__incdebug_checkbox.GetValue())
        self.UpdateInfo()

    def UpdateInfo(self, event=None):
        def do_db():
            self.__dispersy.statistics.update(database=self.__incstuff_checkbox.GetValue())
            return self.__dispersy.statistics

        def do_gui(delayedResult):
            stats = delayedResult.get()  # can contain an exception
            enabled = bool(self.__incstuff_checkbox.GetValue())

            self.__summary_panel.UpdateInfo(stats)
            self.__community_panel.UpdateInfo(stats)
            self.__rawinfo_panel.UpdateInfo(stats)
            self.__runtime_panel.UpdateInfo(stats)
            self.Layout()

        startWorker(do_gui, do_db, uId=u"DispersyDebugFrame_UpdateInfo", priority=GUI_PRI_DISPERSY)

# --------------------------------------------------
# Summary Panel
# --------------------------------------------------
class DispersySummaryPanel(wx.lib.scrolledpanel.ScrolledPanel):

    def __init__(self, parent, id):
        super(DispersySummaryPanel, self).__init__(parent, id)
        self.__utility = GUIUtility.getInstance().utility

        self.SetBackgroundColour(wx.WHITE)

        gridsizer = wx.FlexGridSizer(0, 2, 3, 10)
        gridsizer.AddGrowableCol(1)

        spacer = wx.BoxSizer()
        spacer.Add(gridsizer, 1, wx.EXPAND | wx.ALL, 3)

        self.SetSizer(spacer)
        self.__info_list = None
        self.__text_dict = {}

        # key, value, tip (optional)
        self.__info_list = [
            ["WAN Address", DATA_NONE, None],
            ["LAN Address", DATA_NONE, None],
            ["Connection", DATA_NONE, None],
            ["Runtime", DATA_NONE, None],
            ["Download", DATA_NONE, None],
            ["Upload", DATA_NONE, None],
            ["Packets Sent", DATA_NONE,
                "Packets sent vs Packets handled"],
            ["Packets Received", DATA_NONE,
                "Packets received vs Packets handled"],
            ["Packets Success", DATA_NONE,
                "Messages successfully handled vs Packets received"],
            ["Packets Dropped", DATA_NONE,
                "Packets dropped vs Packets received"],
            ["Packets Delayed", DATA_NONE,
                "Packets being delayed vs Packets received"],
            ["Packets Delayed send", DATA_NONE,
                "Total number of delaymessages or delaypacket messages being sent"],
            ["Packets Delayed success", DATA_NONE,
                "Total number of packets which were delayed, and did not timeout"],
            ["Packets Delayed timeout", DATA_NONE,
                "Total number of packets which were delayed, but got a timeout"],
            ["Walker Success", DATA_NONE, None],
            ["Sync-Messages Created", DATA_NONE,
                "Total number of messages created by us in this session which should be synced"],
            ["Bloom New", DATA_NONE,
                "Total number of bloomfilters created vs IntroductionRequest sent in this session"],
            ["Bloom Reused", DATA_NONE,
                "Total number of bloomfilters reused vs IntroductionRequest sent in this session"],
            ["Bloom Skipped", DATA_NONE,
                "Total number of bloomfilters skipped vs IntroductionRequest sent in this session"],
            ["Debug Mode", DATA_NONE, None],
        ]

        for key, value, tooltip in self.__info_list:
            header = wx.StaticText(self, -1, key)
            _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)
            gridsizer.Add(header)
            self.__text_dict[key] = wx.StaticText(self, -1, value)
            gridsizer.Add(self.__text_dict[key])

            if tooltip:
                header.SetToolTipString(tooltip)
                self.__text_dict[key].SetToolTipString(tooltip)

        self.SetupScrolling()

    def UpdateInfo(self, stats, to_cleanup=False):
        if to_cleanup:
            for info in self.__info_list:
                info[1] = DATA_NONE
        else:
            self.__info_list[0][1] = "%s:%d" % stats.wan_address
            self.__info_list[1][1] = "%s:%d" % stats.lan_address
            self.__info_list[2][1] = unicode(stats.connection_type)

            self.__info_list[3][1] = "%s" % self.__utility.eta_value(stats.timestamp - stats.start)
            self.__info_list[4][1] = "%s or %s/s" % (
                self.__utility.size_format(stats.total_down),
                self.__utility.size_format(int(stats.total_down / (stats.timestamp - stats.start)))
            )
            self.__info_list[5][1] = "%s or %s/s" % (
                self.__utility.size_format(stats.total_up),
                self.__utility.size_format(int(stats.total_up / (stats.timestamp - stats.start)))
            )
            self.__info_list[6][1] = compute_ratio(stats.total_send,
                stats.total_received + stats.total_send)
            self.__info_list[7][1] = compute_ratio(stats.total_received,
                stats.total_received + stats.total_send)
            self.__info_list[8][1] = compute_ratio(stats.msg_statistics.success_count, stats.total_received)
            self.__info_list[9][1] = compute_ratio(stats.msg_statistics.drop_count, stats.total_received)
            self.__info_list[10][1] = compute_ratio(stats.msg_statistics.delay_received_count, stats.total_received)
            self.__info_list[11][1] = compute_ratio(stats.msg_statistics.delay_send_count, stats.msg_statistics.delay_received_count)
            self.__info_list[12][1] = compute_ratio(stats.msg_statistics.delay_success_count, stats.msg_statistics.delay_received_count)
            self.__info_list[13][1] = compute_ratio(stats.msg_statistics.delay_timeout_count, stats.msg_statistics.delay_received_count)
            self.__info_list[14][1] = compute_ratio(stats.walk_success_count, stats.walk_attempt_count)
            self.__info_list[15][1] = "%s" % stats.msg_statistics.created_count
            self.__info_list[16][1] = compute_ratio(sum(c.sync_bloom_new for c in stats.communities),
                sum(c.sync_bloom_send + c.sync_bloom_skip for c in stats.communities))
            self.__info_list[17][1] = compute_ratio(sum(c.sync_bloom_reuse for c in stats.communities),
                sum(c.sync_bloom_send + c.sync_bloom_skip for c in stats.communities))
            self.__info_list[18][1] = compute_ratio(sum(c.sync_bloom_skip for c in stats.communities),
                sum(c.sync_bloom_send + c.sync_bloom_skip for c in stats.communities))
            self.__info_list[19][1] = "yes" if __debug__ else "no"

        for key, value, _ in self.__info_list:
            self.__text_dict[key].SetLabel(value)

        self.SetupScrolling()

# --------------------------------------------------
# Community Panel and Widgets
# --------------------------------------------------

class CommunityPanel(wx.Panel):

    def __init__(self, parent, id):
        super(CommunityPanel, self).__init__(parent, id)
        self.SetBackgroundColour(wx.WHITE)

        splitter = wx.SplitterWindow(self, -1, style=wx.SP_BORDER)
        splitter.SetSashGravity(0.5)

        self.__listctrl = AutoWidthListCtrl(splitter, -1,
            style=wx.LC_REPORT | wx.LC_ALIGN_LEFT | wx.LC_SINGLE_SEL)
        self.__listctrl.SetMinSize((600, 200))
        self.__listctrl.InsertColumn(0, "Classification", width=200)
        self.__listctrl.InsertColumn(1, "Identifier", width=100)
        self.__listctrl.InsertColumn(2, "Database ID", width=100)
        self.__listctrl.InsertColumn(3, "Member", width=100)
        self.__listctrl.InsertColumn(4, "Candidates")

        self.__detail_panel = CommunityDetailPanel(splitter, -1)

        splitter.SplitHorizontally(self.__listctrl, self.__detail_panel)

        sizer = wx.BoxSizer()
        sizer.Add(splitter, 1, wx.EXPAND)
        self.SetSizer(sizer)

        self.__community_data_list = []
        self.__selected_community_identifier = None

        self.__listctrl.Bind(wx.EVT_LIST_ITEM_SELECTED, self.OnListCtrlSelected)

    def OnListCtrlSelected(self, event):
        community_data = self.__community_data_list[event.GetIndex()]
        if self.__selected_community_identifier == community_data["Identifier"]:
            return

        self.__selected_community_identifier = community_data["Identifier"]
        self.__detail_panel.UpdateInfo(community_data)

    def UpdateInfo(self, stats):
        community_list = sorted(stats.communities,
            key=lambda community:
                (not community.dispersy_enable_candidate_walker,
                community.classification, community.cid)
        )
        self.__community_data_list = []
        reselect_community_idx = None
        idx = 0
        community_list_for_update = []
        for community in community_list:
            candidate_list = None
            if community.dispersy_enable_candidate_walker or \
                    community.dispersy_enable_candidate_walker_responses:
                candidate_count = "%d " % len(community.candidates)
                candidate_list = [("%s" % global_time, "%s:%s" % lan, "%s:%s" % wan)
                    for lan, wan, global_time in community.candidates]
                candidate_list.sort()
            elif community.candidates:
                candidate_count = "%d*" % len(community.candidates)
            else:
                candidate_count = "-"

            median_global_time = "%d (%d difference)" % \
                (community.acceptable_global_time - community.dispersy_acceptable_global_time_range,
                 community.acceptable_global_time - community.global_time -
                    community.dispersy_acceptable_global_time_range)

            database_list = []
            if community.database:
                database_str = "%d packets" % \
                    sum(count for count in community.database.itervalues())
                for name, count in sorted(community.database.iteritems(), key=lambda tup: tup[1]):
                    database_list.append(("%s" % count, "%s" % name))
            else:
                database_str = "? packets"

            community_data = {
                "Identifier": "%s" % community.hex_cid,
                "Member": "%s" % community.hex_mid,
                "Classification": "%s" % community.classification,
                "Database id": "%s" % community.database_id,
                "Global time": "%s" % community.global_time,
                "Median global time": "%s" % median_global_time,
                "Acceptable range": "%s" % community.dispersy_acceptable_global_time_range,
                "Sync bloom created": "%s" % community.sync_bloom_new,
                "Sync bloom reused": "%s" % community.sync_bloom_reuse,
                "Sync bloom skipped": "%s" % community.sync_bloom_skip,
                "Candidates": "%s" % candidate_count,
                "Candidate_list": candidate_list,
                "Database": database_str,
                "Database_list": database_list,
                "Packets Sent": "%s" % community.msg_statistics.outgoing_count,
                "Packets Created": "%s" % community.msg_statistics.created_count,
                "Packets Success": "%s" % community.msg_statistics.success_count,
                "Packets Dropped": "%s" % community.msg_statistics.drop_count,
                "Packets Delayed Sent": "%s" % community.msg_statistics.delay_send_count,
                "Packets Delayed Received": "%s" % community.msg_statistics.delay_received_count,
                "Packets Delayed Success": "%s" % community.msg_statistics.delay_success_count,
                "Packets Delayed Timeout": "%s" % community.msg_statistics.delay_timeout_count,
                "Statistics": community,
            }
            # update community data list
            self.__community_data_list.append(community_data)

            community_list_for_update.append((community_data["Classification"],
                community_data["Identifier"][:7], community_data["Database id"],
                community_data["Member"][:7], community_data["Candidates"])
            )

            if self.__selected_community_identifier == community_data["Identifier"]:
                reselect_community_idx = idx
            idx += 1

        # update community detail
        self.__listctrl.UpdateData(community_list_for_update)
        community_data_for_update = None
        community_statistics = None
        if reselect_community_idx is not None:
            self.__listctrl.Select(reselect_community_idx)
            community_data_for_update = self.__community_data_list[reselect_community_idx]
        self.__detail_panel.UpdateInfo(community_data_for_update)


class CommunityDetailPanel(wx.Panel):

    def __init__(self, parent, id):
        super(CommunityDetailPanel, self).__init__(parent, id, style=wx.RAISED_BORDER)
        self.SetBackgroundColour(LIST_GREY)

        self.__FIELDS = ("Identifier", "Member", "Classification", "Global time",
            "Median global time", "Acceptable range", "Sync bloom created",
            "Sync bloom reused", "Sync bloom skipped",
            "Packets Sent", "Packets Created", "Packets Success", "Packets Dropped",
            "Packets Delayed Sent", "Packets Delayed Received",
            "Packets Delayed Success", "Packets Delayed Timeout",
            "Candidates", "Database")

        hsizer = wx.BoxSizer(wx.HORIZONTAL)

        info_panel = wx.Panel(self, -1, style=wx.BORDER_SUNKEN)
        info_panel.SetBackgroundColour(wx.WHITE)
        info_panel.SetMinSize((500, 300))
        self.__info_panel = info_panel

        self.__text = {}
        gridsizer = wx.FlexGridSizer(0, 2, 3, 3)
        for title in self.__FIELDS:
            key_text = wx.StaticText(info_panel, -1, title)
            _set_font(key_text, fontweight=wx.FONTWEIGHT_BOLD)

            value_text = wx.StaticText(info_panel, -1)
            gridsizer.AddMany([
                (key_text, 0, wx.EXPAND),
                (value_text, 0, wx.EXPAND)])

            self.__text[title] = (key_text, value_text)
        info_panel.SetSizer(gridsizer)

        self.__detail_notebook = SimpleNotebook(self, show_single_tab=True, style=wx.NB_NOPAGETHEME)

        self.__candidate_list = AutoWidthListCtrl(self.__detail_notebook, -1,
            style=wx.LC_REPORT | wx.LC_ALIGN_LEFT | wx.BORDER_SUNKEN)
        self.__candidate_list.InsertColumn(0, "Global time", width=100)
        self.__candidate_list.InsertColumn(1, "LAN", width=170)
        self.__candidate_list.InsertColumn(2, "WAN")

        self.__rawinfo_panel = RawInfoPanel(self.__detail_notebook, -1)

        self.__database_list = AutoWidthListCtrl(self.__detail_notebook, -1,
            style=wx.LC_REPORT | wx.LC_ALIGN_LEFT | wx.BORDER_SUNKEN)
        self.__database_list.InsertColumn(0, "Count")
        self.__database_list.InsertColumn(1, "Info")

        self.__detail_notebook.AddPage(self.__candidate_list, "Candidates")
        self.__detail_notebook.AddPage(self.__rawinfo_panel, "RawInfo")
        self.__detail_notebook.AddPage(self.__database_list, "Database")

        hsizer.Add(self.__info_panel, 0, wx.EXPAND | wx.RIGHT, 2)
        hsizer.Add(self.__detail_notebook, 1, wx.EXPAND)
        self.SetSizer(hsizer)

    def UpdateInfo(self, community_data):
        if community_data == None:
            for field_name in self.__FIELDS:
                self.__text[field_name][1].SetLabel(DATA_NONE)
            self.__database_list.DeleteAllItems()
            self.__candidate_list.DeleteAllItems()
            self.__rawinfo_panel.UpdateInfo(None)
        else:
            for field_name in self.__FIELDS:
                self.__text[field_name][1].SetLabel(community_data[field_name])
            self.__database_list.UpdateData(community_data["Database_list"])
            self.__candidate_list.UpdateData(community_data["Candidate_list"])
            self.__rawinfo_panel.UpdateInfo(community_data["Statistics"])

        self.Layout()

# --------------------------------------------------
# RawInfo Panel
# --------------------------------------------------

class RawInfoPanel(wx.Panel):

    def __init__(self, parent, id):
        super(RawInfoPanel, self).__init__(parent, id)
        self.SetBackgroundColour(LIST_GREY)

        self.__info = None
        self.__selected_category = None

        self.__CATEGORIES = ("attachment", "endpoint_recv", "endpoint_send",
            "walk_failure_dict", "incoming_intro_dict", "outgoing_intro_dict")
        self.__MSG_CATEGORIES = ("success", "drop", "created", "delay", "outgoing")
        self.__IP_CATEGORIES = ("walk_failure_dict", "incoming_intro_dict", "outgoing_intro_dict")

        self.__category_list = AutoWidthListCtrl(self, -1,
            style=wx.LC_REPORT | wx.LC_ALIGN_LEFT | wx.LC_SINGLE_SEL | wx.BORDER_SUNKEN)
        self.__category_list.InsertColumn(0, "Category", width=150)
        self.__category_list.InsertColumn(1, "Total Count")
        self.__category_list.Bind(wx.EVT_LIST_ITEM_SELECTED, self.OnCategorySelected)

        self.__detail_list = AutoWidthListCtrl(self, -1, style=wx.LC_REPORT | wx.BORDER_SUNKEN)
        self.__detail_list.InsertColumn(0, "Count", width=50)
        self.__detail_list.InsertColumn(1, "Info")

        hsizer = wx.BoxSizer(wx.HORIZONTAL)
        hsizer.Add(self.__category_list, 1, wx.EXPAND | wx.RIGHT, 2)
        hsizer.Add(self.__detail_list, 2, wx.EXPAND)
        self.SetSizer(hsizer)

    def OnCategorySelected(self, event):
        category = self.__info[event.GetIndex()][0]
        if self.__selected_category == category:
            return

        self.__selected_category = category
        self.__detail_list.UpdateData(self.__info[event.GetIndex()][1])

    def UpdateInfo(self, stats):
        if stats is None:
            self.__category_list.DeleteAllItems()
            self.__detail_list.DeleteAllItems()
            return

        raw_info = {}
        self.__info = []
        category_list = []
        for category in self.__CATEGORIES:
            if getattr(stats, category, None):
                raw_info[category] = getattr(stats, category).items()
                category_list.append(category)
                self.__info.append((category, []))

        for category in self.__MSG_CATEGORIES:
            dict_name = "%s_dict" % category
            if getattr(stats.msg_statistics, dict_name, None):
                raw_info[category] = getattr(stats.msg_statistics, dict_name).items()
                category_list.append(category)
                self.__info.append((category, []))

        idx = 0
        reselect_category_idx = None
        for category in category_list:
            data_list = raw_info[category]
            data_list.sort(key=lambda kv: kv[1], reverse=True)
            total_count = 0
            for key, value in data_list:
                count_str = "%s" % value
                total_count += value

                if category in self.__IP_CATEGORIES:
                    if isinstance(key, tuple):
                        info_str = "%s:%s" % key
                    else:
                        info_str = str2unicode(key)
                elif category == "attachment":
                    info_str = "%s" % binascii.hexlify(key)
                else:
                    info_str = str2unicode(key)
                self.__info[idx][1].append((count_str, info_str))

            # update category list
            total_count = "%s" % total_count
            if idx < self.__category_list.GetItemCount():
                self.__category_list.SetStringItem(idx, 0, category_list[idx])
                self.__category_list.SetStringItem(idx, 1, total_count)
            else:
                self.__category_list.Append([category_list[idx], total_count])

            # check selected category
            if self.__selected_category == category:
                reselect_category_idx = idx
            idx += 1
        while self.__category_list.GetItemCount() > len(category_list):
            self.__category_list.DeleteItem(self.__category_list.GetItemCount() - 1)

        # reselect the previous selection
        category_data_for_update = None
        if reselect_category_idx is not None:
            self.__category_list.Select(reselect_category_idx)
            category_data_for_update = self.__info[reselect_category_idx][1]
        self.__detail_list.UpdateData(category_data_for_update)

# --------------------------------------------------
# Runtime Profiling Panel
# --------------------------------------------------

class RuntimeProfilingPanel(wx.Panel):

    def __init__(self, parent, id):
        super(RuntimeProfilingPanel, self).__init__(parent, id)
        self.SetBackgroundColour(LIST_GREY)

        self.__current_selection_name = None
        self.__combined_list = []

        sizer = wx.BoxSizer(wx.HORIZONTAL)

        self.__list1 = AutoWidthListCtrl(self, -1,
            style=wx.LC_REPORT | wx.LC_ALIGN_LEFT | wx.LC_SINGLE_SEL | wx.BORDER_SUNKEN)
        self.__list1.InsertColumn(0, "Duration", width=70)
        self.__list1.InsertColumn(1, "Entry", width=250)
        self.__list1.InsertColumn(2, "Average", width=70)
        self.__list1.InsertColumn(3, "Count")
        set_small_modern_font(self.__list1)

        self.__list1.Bind(wx.EVT_LIST_ITEM_SELECTED, self.OnList1Selected)

        self.__list2 = AutoWidthListCtrl(self, -1, style=wx.LC_REPORT | wx.BORDER_SUNKEN)
        self.__list2.InsertColumn(0, "Duration", width=70)
        self.__list2.InsertColumn(1, "Entry", width=250)
        self.__list2.InsertColumn(2, "Average", width=70)
        self.__list2.InsertColumn(3, "Count")
        set_small_modern_font(self.__list2)

        sizer.Add(self.__list1, 1, wx.EXPAND | wx.RIGHT, 2)
        sizer.Add(self.__list2, 1, wx.EXPAND)
        self.SetSizer(sizer)

    def OnList1Selected(self, event):
        this_idx = event.GetIndex()
        if self.__current_selection_name == self.__combined_list[this_idx][1]:
            return

        self.__current_selection_name = self.__combined_list[this_idx][1]
        self.__list2.DeleteAllItems()
        data_list = self.__combined_list[this_idx][4]
        for duration, entry, average, count in data_list:
            self.__list2.Append([u"%7.2f" % duration, u"%s" % entry,
                u"%7.2f" % average, u"%s" % count])

    def UpdateInfo(self, stats):
        self.__list1.DeleteAllItems()
        self.__list2.DeleteAllItems()
        prev_selection_name = self.__current_selection_name
        self.__current_selection_name = None

        if not getattr(stats, "runtime", None):
            return

        combined_dict = {}
        for stat_dict in stats.runtime:
            processed_data = {}
            for k, v in stat_dict.iteritems():
                if k == "entry":
                    v = v.replace("\n", "\n          ")
                processed_data[k] = v

            name = processed_data["entry"].split("\n")[0]
            combined_name = name.split()[0]

            data = (processed_data["duration"], name,
                processed_data["average"], processed_data["count"])

            if combined_name not in combined_dict:
                # total-duration, average, count, and data-list
                combined_dict[combined_name] = [0, 0, 0, list()]

            combined_dict[combined_name][0] += processed_data["duration"]
            combined_dict[combined_name][1] += processed_data["average"]
            combined_dict[combined_name][2] += processed_data["count"]
            combined_dict[combined_name][3].append(data)

        # convert dict to list
        combined_list = []
        for k, v in combined_dict.iteritems():
            v[3].sort(reverse=True)
            combined_list.append((v[0], k, v[1], v[2], v[3]))
        combined_list.sort(reverse=True)
        self.__combined_list = combined_list

        prev_selection_idx = None
        idx = 0
        for duration, entry, average, count, _ in combined_list:
            if entry == prev_selection_name:
                prev_selection_idx = idx
            idx += 1
            self.__list1.Append([u"%7.2f" % duration, u"%s" % entry,
                u"%7.2f" % average, u"%s" % count])

        if prev_selection_idx is not None:
            self.__list1.Select(prev_selection_idx)

########NEW FILE########
__FILENAME__ = EmbeddedPlayer
# Written by Fabian van der Werf and Arno Bakker
# see LICENSE.txt for license information
#
# EmbeddedPlayerPanel is the panel used in Tribler 5.0
# EmbeddedPlayer4FramePanel is the panel used in the SwarmPlayer / 4.5
#

import wx
import time
import logging
from threading import currentThread
from traceback import print_exc

from Tribler.Core.simpledefs import NTFY_TORRENTS, NTFY_VIDEO_ENDED, \
    DLSTATUS_HASHCHECKING, DLSTATUS_STOPPED_ON_ERROR, NTFY_VIDEO_BUFFERING, \
    DLMODE_VOD
from Tribler.Core.CacheDB.Notifier import Notifier

from Tribler.Main.vwxGUI import forceWxThread, warnWxThread, \
    SEPARATOR_GREY, GRADIENT_DGREY, GRADIENT_LGREY
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.widgets import VideoProgress, FancyPanel, \
    ActionButton, TransparentText, VideoVolume, VideoSlider

from Tribler.Core.Video.defs import MEDIASTATE_PLAYING, MEDIASTATE_ENDED, \
    MEDIASTATE_STOPPED, MEDIASTATE_PAUSED
from Tribler.Core.Video.VideoPlayer import VideoPlayer


class DelayTimer(wx.Timer):

    """ vlc.MediaCtrl needs some time to stop after we give it a stop command.
        Wait until it is and then tell it to play the new item
    """
    def __init__(self, embedplay):
        wx.Timer.__init__(self)
        self._logger = logging.getLogger(self.__class__.__name__)

        self.embedplay = embedplay
        self.Start(100)

    def Notify(self):
        if self.embedplay.GetState() != MEDIASTATE_PLAYING:
            self._logger.debug("embedplay: VLC has stopped playing previous video, starting it on new")
            self.Stop()
            self.embedplay.Play()
        else:
            self._logger.debug("embedplay: VLC is still playing old video")


class EmbeddedPlayerPanel(wx.Panel):
    """
    The Embedded Player consists of a VLCWindow and the media controls such
    as Play/Pause buttons and Volume Control.
    """

    VIDEO_SIZE = (320, 240)

    def __init__(self, parent, utility, vlcwrap, bg_color):
        wx.Panel.__init__(self, parent, -1)

        self._logger = logging.getLogger(self.__class__.__name__)

        self._gui_image_manager = GuiImageManager.getInstance()

        self.utility = utility
        self.guiutility = utility.guiUtility
        self.videoplayer = VideoPlayer.getInstance()
        self.parent = parent
        self.SetBackgroundColour(bg_color)

        self.fullscreenwindow = None
        self.download = None
        self.download_hash = None
        self.update = True
        self.timeoffset = None

        vSizer = wx.BoxSizer(wx.VERTICAL)

        self.vlcwrap = vlcwrap

        if vlcwrap:
            self.vlcwin = VLCWindow(self, vlcwrap)
            self.vlcwin.SetMinSize(EmbeddedPlayerPanel.VIDEO_SIZE)
            vSizer.Add(self.vlcwin, 1, wx.EXPAND, 0)

            self.logowin = LogoWindow(self)
            self.logowin.SetMinSize(EmbeddedPlayerPanel.VIDEO_SIZE)
            vSizer.Add(self.logowin, 1, wx.EXPAND, 0)

            self.ctrlpanel = FancyPanel(self, border=wx.TOP)
            self.ctrlpanel.SetMinSize((-1, 30))
            self.ctrlpanel.SetBorderColour(SEPARATOR_GREY)
            self.ctrlpanel.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)

            self.ctrlsizer = wx.BoxSizer(wx.HORIZONTAL)

            self.slider = VideoSlider(self.ctrlpanel)
            self.slider.Enable(False)
            self.timeposition = TransparentText(self.ctrlpanel, -1, "--:-- / --:--")

            self.bmp_muted = self._gui_image_manager.getImage(u"video_muted.png")
            self.bmp_unmuted = self._gui_image_manager.getImage(u"video_unmuted.png")
            self.mute = ActionButton(self.ctrlpanel, -1, self.bmp_unmuted)
            self.mute.Bind(wx.EVT_LEFT_UP, self.MuteClicked)

            self.bmp_pause = self._gui_image_manager.getImage(u"video_pause.png")
            self.bmp_play = self._gui_image_manager.getImage(u"video_play.png")
            self.ppbtn = ActionButton(self.ctrlpanel, -1, self.bmp_play)
            self.ppbtn.Bind(wx.EVT_LEFT_UP, self.PlayPause)
            self.ppbtn.Enable(False)

            self.sbtn = ActionButton(self.ctrlpanel, -1, self._gui_image_manager.getImage(u"video_stop.png"))
            self.sbtn.Bind(wx.EVT_LEFT_UP, self.OnStop)
            self.sbtn.Enable(False)

            self.volctrl = VideoVolume(self.ctrlpanel, -1)
            self.volctrl.SetVolumeHandler(self.OnVolumeChanged)
            self.volctrl.SetMinSize((30, 17))
            self.volctrl.Enable(False)

            self.fsbtn = ActionButton(self.ctrlpanel, -1, self._gui_image_manager.getImage(u"video_fullscreen.png"))
            self.fsbtn.Bind(wx.EVT_LEFT_UP, self.FullScreen)
            self.fsbtn.Enable(False)

            self.ctrlsizer.AddSpacer((10, -1))
            self.ctrlsizer.Add(self.ppbtn, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 1)
            self.ctrlsizer.AddSpacer((10, -1))
            self.ctrlsizer.Add(self.sbtn, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 1)
            self.ctrlsizer.AddSpacer((10, -1))
            self.ctrlsizer.Add(self.slider, 1, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 5)
            self.ctrlsizer.Add(self.timeposition, 0, wx.ALIGN_CENTER_VERTICAL)
            self.ctrlsizer.AddSpacer((10, -1))

            self.ctrlsizer.Add(self.mute, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 1)
            self.ctrlsizer.AddSpacer((5, -1))
            self.ctrlsizer.Add(self.volctrl, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 1)
            self.ctrlsizer.AddSpacer((10, -1))
            self.ctrlsizer.Add(self.fsbtn, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 1)
            self.ctrlsizer.AddSpacer((10, -1))

            self.ctrlpanel.SetSizer(self.ctrlsizer)

            vSizer.Add(self.ctrlpanel, 0, wx.ALIGN_BOTTOM | wx.EXPAND)

            self.notifier = Notifier.getInstance()

        self.SetSizer(vSizer)

        self.playtimer = None
        self.timer = None

        if self.vlcwrap:
            self.SetMinSize((EmbeddedPlayerPanel.VIDEO_SIZE[0], -1))
            self.vlcwin.Show(True)
            self.logowin.Show(False)
            self.ctrlsizer.ShowItems(True)
            self.guiutility.frame.Layout()

            self.guiutility.library_manager.add_download_state_callback(self.OnStatesCallback)

            self.guiutility.utility.session.add_observer(self.OnVideoBuffering, NTFY_TORRENTS, [NTFY_VIDEO_BUFFERING])

            self.videoplayer.set_internalplayer_callback(self.LoadAndStartPlay)

    def OnVideoBuffering(self, subject, changeType, torrent_tuple):
        download_hash, _, is_buffering = torrent_tuple
        if self.download and self.download.get_def().get_id() == download_hash:
            @forceWxThread
            def do_gui():
                if is_buffering:
                    self.Pause(gui_vod_event=True)
                else:
                    self.Resume()
            do_gui()

    def OnStatesCallback(self, dslist, magnetlist):
        if not self.download:
            return

        for ds in dslist:
            if ds.get_download() == self.download and self.download.get_mode() == DLMODE_VOD:
                if ds.get_status() == DLSTATUS_HASHCHECKING:
                    progress = ds.get_progress()
                    label = 'Checking\n%d%%' % (progress * 100)
                elif ds.get_status() == DLSTATUS_STOPPED_ON_ERROR:
                    progress = 0
                    label = 'Loading\nfailed'
                else:
                    progress = ds.get_vod_prebuffering_progress()
                    label = 'Loading\n%d%%' % (progress * 100)

                pieces_complete = ds.get_pieces_complete() if ds.get_progress() < 1.0 else [True]
                self.UpdateStatus(label, progress, pieces_complete)

    def OnVolumeChanged(self, volume):
        if self.mute.GetBitmapLabel() == self.bmp_muted:  # unmute
            self.mute.SetBitmapLabel(self.bmp_unmuted, recreate=True)
        self.volume = volume
        self.oldvolume = self.volume
        self.SetVolume(self.volume)

    def MuteClicked(self, event):
        if self.mute.GetBitmapLabel() == self.bmp_muted:
            self.volume = self.oldvolume
        else:
            self.volume = 0

        self.volctrl.SetValue(self.volume)
        self.SetVolume(self.volume)
        self.mute.SetBitmapLabel(self.bmp_unmuted if self.mute.GetBitmapLabel() == self.bmp_muted else self.bmp_muted, recreate=True)

    @forceWxThread
    def LoadAndStartPlay(self, url, download):
        self.Load(url, download)
        self.StartPlay()

    @warnWxThread
    def Load(self, url, download):
        self._logger.debug("embedplay: Load: %s %s", url, currentThread().getName())

        self.download = download
        self.download_hash = download.get_def().get_id()

        # 19/02/10 Boudewijn: no self.slider when self.vlcwrap is None
        # 26/05/09 Boudewijn: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            self.slider.Enable(False)

            # Arno, 2009-02-17: If we don't do this VLC gets the wrong playlist somehow
            self.vlcwrap.stop()
            self.vlcwrap.load(url)

            # Enable update of progress slider
            wx.CallAfter(self.slider.SetValue, 0)
            if self.timer is None:
                self.timer = wx.Timer(self)
                self.Bind(wx.EVT_TIMER, self.UpdateSlider)
            self.timer.Start(500)

            self.volume = self.vlcwrap.sound_get_volume()
            self.oldvolume = self.vlcwrap.sound_get_volume()
            self.volctrl.SetValue(self.volume)
            self.volctrl.Enable(True)

        self.fsbtn.Enable(True)
        self.ppbtn.SetBitmapLabel(self.bmp_pause, recreate=True)
        self.ppbtn.Enable(True)
        self.sbtn.Enable(True)

    def StartPlay(self):
        """ Start playing the new item after VLC has stopped playing the old one """
        self._logger.debug("embedplay: PlayWhenStopped")

        self.playtimer = DelayTimer(self)

    @warnWxThread
    def Play(self, evt=None):
        self._logger.debug("embedplay: Play pressed")

        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            if self.GetState() != MEDIASTATE_PLAYING:
                self.vlcwrap.start()
                self.ppbtn.SetBitmapLabel(self.bmp_pause, recreate=True)
                self.ppbtn.Enable(True)
            else:
                self._logger.debug("embedplay: Play pressed, already playing")

    @warnWxThread
    def Pause(self, evt=None, gui_vod_event=False):
        self._logger.debug("embedplay: Pause pressed")

        if self.vlcwrap:
            if self.GetState() == MEDIASTATE_PLAYING:
                self.vlcwrap.pause()
            self.ppbtn.SetBitmapLabel(self.bmp_play, recreate=True)
            if gui_vod_event:
                self.ppbtn.Enable(False)
                self.ShowLoading()

    @warnWxThread
    def Resume(self, evt=None):
        self._logger.debug("embedplay: Resume pressed")

        if self.vlcwrap:
            if self.GetState() != MEDIASTATE_PLAYING:
                self.vlcwrap.resume()
            self.ppbtn.SetBitmapLabel(self.bmp_pause, recreate=True)
            self.ppbtn.Enable(True)
            self.slider.Enable(True)
            self.HideLoading()

    @warnWxThread
    def PlayPause(self, evt=None):
        self._logger.debug("embedplay: PlayPause pressed")

        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            if self.GetState() in [MEDIASTATE_ENDED, MEDIASTATE_STOPPED]:
                # Ensures that the related download also starts
                self.guiutility.library_manager.startLastVODTorrent()
            else:
                self.vlcwrap.resume()
                self.ppbtn.SetBitmapLabel(self.bmp_play if self.ppbtn.GetBitmapLabel() == self.bmp_pause else self.bmp_pause, recreate=True)
                self.ppbtn.Enable(True)

    @warnWxThread
    def Seek(self, evt=None):
        self._logger.debug("embedplay: Seek")

        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            self.ppbtn.SetBitmapLabel(self.bmp_pause, recreate=True)
            self.ppbtn.Enable(self.download.get_progress() == 1.0)
            position = self.slider.GetValue()
            self.update = False

            try:
                self.Pause(gui_vod_event=True)
                self.videoplayer.seek(position)
                self.vlcwrap.set_media_position_relative(position, self.GetState() in [MEDIASTATE_ENDED, MEDIASTATE_STOPPED])

                length = self.vlcwrap.get_stream_information_length()
                length = length / 1000 if length > 0 else self.videoplayer.get_vod_duration(self.download_hash)
                time_position = length * position
                self.timeoffset = time_position - (self.vlcwrap.get_media_position() / 1000)

                self.update = True
            except:
                print_exc()
                self._logger.debug('embedplay: Could not seek')

    def FullScreen(self, evt=None):
        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap and self.fsbtn.IsEnabled():
            self._ToggleFullScreen()

    def OnFullScreenKey(self, event):
        if event.GetUnicodeKey() == wx.WXK_ESCAPE:
            self._ToggleFullScreen()

        elif event.GetUnicodeKey() == wx.WXK_SPACE:
            self._TogglePause()

    def _TogglePause(self):
        if self.GetState() == MEDIASTATE_PLAYING:
            self.vlcwrap.pause()
        else:
            self.vlcwrap.resume()

    @warnWxThread
    def _ToggleFullScreen(self):
        # saving media player state
        cur_time = self.vlcwrap.get_media_position()
        cur_state = self.vlcwrap.get_our_state()

        self.vlcwrap.stop()
        if not self.fullscreenwindow:
            # create a new top level frame where to attach the vlc widget and
            # render the fullscreen video
            self.fullscreenwindow = wx.Frame(None, title="FullscreenVLC")
            self.fullscreenwindow.SetBackgroundColour("BLACK")

            eventPanel = wx.Panel(self.fullscreenwindow)
            eventPanel.SetBackgroundColour(wx.BLACK)
            eventPanel.Bind(wx.EVT_KEY_DOWN, lambda event: self.OnFullScreenKey(event))
            self.fullscreenwindow.Bind(wx.EVT_CLOSE, lambda event: self._ToggleFullScreen())
            self.fullscreenwindow.ShowFullScreen(True)
            eventPanel.SetFocus()
            self.vlcwrap.set_window(self.fullscreenwindow)
        else:
            self.vlcwrap.set_window(self.vlcwin)
            self.fullscreenwindow.Destroy()
            self.fullscreenwindow = None

        # restoring state
        if cur_state == MEDIASTATE_PLAYING:
            self.vlcwrap.start(cur_time)

        elif cur_state == MEDIASTATE_PAUSED:
            self.vlcwrap.start(cur_time)

            def doPause(cur_time):
                self.vlcwrap.pause()
                self.vlcwrap.set_media_position(cur_time)
            wx.CallLater(500, doPause, cur_time)

    def SetVolume(self, volume, evt=None):
        self._logger.debug("embedplay: SetVolume: %s", self.volume)

        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            self.vlcwrap.sound_set_volume(volume)

    def OnStop(self, event=None):
        if self.vlcwrap and self.sbtn.IsEnabled():
            self.Stop()
            self.ppbtn.Enable(True)
            # Ensures that the related download also stops.
            self.guiutility.library_manager.stopLastVODTorrent()

    @forceWxThread
    def Stop(self):
        self._logger.debug("embedplay: Stop")

        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            self.vlcwrap.stop()
            self.timeposition.SetLabel('--:-- / --:--')
            self.slider.SetValue(0)
            self.timeoffset = None
            self.fsbtn.Enable(False)
            self.sbtn.Enable(False)
            self.ppbtn.SetBitmapLabel(self.bmp_play, recreate=True)
            self.slider.Enable(False)
            self.HideLoading()

            if self.timer is not None:
                self.timer.Stop()

    def GetState(self):
        """ Returns the state of VLC as summarized by Fabian:
        MEDIASTATE_PLAYING, MEDIASTATE_PAUSED, MEDIASTATE_ENDED, MEDIASTATE_STOPPED """

        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap:
            status = self.vlcwrap.get_our_state()
            self._logger.debug("embedplay: GetState %s", status)

            return status

        # catchall
        return MEDIASTATE_STOPPED

    def Reset(self):
        self.Stop()
        self.slider.SetPieces([])

    @forceWxThread
    def UpdateStatus(self, label, progress, pieces_complete):
        self.logowin.loading.SetValue(progress)
        self.logowin.loading.SetLabel(label)

        if self.vlcwrap:
            self.slider.SetPieces(pieces_complete)

    @warnWxThread
    def UpdateSlider(self, evt):
        # Boudewijn, 26/05/09: when using the external player we do not have a vlcwrap
        if self.vlcwrap and self.update:
            if self.GetState() not in [MEDIASTATE_ENDED, MEDIASTATE_STOPPED]:

                length = self.vlcwrap.get_stream_information_length()
                length = length / 1000 if length > 0 else self.videoplayer.get_vod_duration(self.download_hash)
                cur = self.vlcwrap.get_media_position() / 1000
                if length and self.timeoffset:
                    cur += self.timeoffset

                if cur >= 0 and length:
                    self.slider.SetValue(float(cur) / length)

                cur_str = self.FormatTime(float(cur)) if cur >= 0 else '--:--'
                length_str = self.FormatTime(length) if length else '--:--'
                self.timeposition.SetLabel('%s / %s' % (cur_str, length_str))
                self.ctrlsizer.Layout()
            elif self.GetState() == MEDIASTATE_ENDED:
                vp = VideoPlayer.getInstance()
                download, fileindex = (vp.get_vod_download(), vp.get_vod_fileindex())
                self.OnStop(None)
                if download and download.get_def().get_def_type() == 'torrent':
                    self.notifier.notify(NTFY_TORRENTS, NTFY_VIDEO_ENDED, (download.get_def().get_id(), fileindex))
                if self.fullscreenwindow:
                    self._ToggleFullScreen()

    def FormatTime(self, s):
        longformat = time.strftime('%d:%H:%M:%S', time.gmtime(s))
        if longformat.startswith('01:'):
            longformat = longformat[3:]
        while longformat.startswith('00:') and len(longformat) > len('00:00'):
            longformat = longformat[3:]
        return longformat

    def ShowLoading(self):
        if self.vlcwrap:
            self.logowin.loading.SetValue(0.0)
            self.logowin.show_loading()
            self.logowin.Show(True)
            self.vlcwin.Show(False)
            self.Layout()

    def HideLoading(self):
        if self.vlcwrap:
            self.logowin.hide_loading()
            self.logowin.Show(False)
            self.vlcwin.Show(True)
            self.Layout()

    def RecreateVLCWindow(self):
        if self.vlcwrap:
            vlcwin = VLCWindow(self, self.vlcwrap)
            vlcwin.SetMinSize(EmbeddedPlayerPanel.VIDEO_SIZE)
            vlcwin.Show(self.vlcwin.IsShown())
            self.GetSizer().Replace(self.vlcwin, vlcwin)
            self.vlcwin.Destroy()
            self.vlcwin = vlcwin

class VLCWindow(wx.Panel):
    """ A wx.Window to be passed to the vlc.MediaControl to draw the video in (normally). """

    def __init__(self, parent, vlcwrap):
        wx.Panel.__init__(self, parent)
        self.parent = parent
        self.SetBackgroundColour(wx.BLACK)
        self.vlcwrap = vlcwrap

        self.hsizermain = wx.BoxSizer(wx.HORIZONTAL)
        self.vsizer = wx.BoxSizer(wx.VERTICAL)
        self.hsizermain.Add(self.vsizer, 1, wx.CENTER)
        self.SetSizer(self.hsizermain)
        self.SetAutoLayout(1)
        self.Layout()

        self.vlcwrap.set_window(self)
        self.Refresh()

    def get_vlcwrap(self):
        return self.vlcwrap

class LogoWindow(wx.Panel):
    """ A wx.Window that can display the buffering progress when VLC is not playing. """

    def __init__(self, parent):
        wx.Panel.__init__(self, parent)
        self.parent = parent
        self.SetBackgroundColour(wx.BLACK)

        self.hsizermain = wx.BoxSizer(wx.HORIZONTAL)
        self.vsizer = wx.BoxSizer(wx.VERTICAL)

        self.loading = VideoProgress(self, -1)
        self.loading.Hide()
        self.loading.SetMinSize((300, 300))
        self.vsizer.Add(self.loading, 0, wx.CENTER | wx.RESERVE_SPACE_EVEN_IF_HIDDEN)

        self.hsizermain.Add(self.vsizer, 1, wx.CENTER)
        self.SetSizer(self.hsizermain)
        self.SetAutoLayout(1)
        self.Layout()
        self.Refresh()

    def show_loading(self):
        if self.loading:
            self.logo = None
            self.loading.Show()
            self.Refresh()

    def hide_loading(self):
        if self.loading:
            self.loading.Hide()
            self.Refresh()

########NEW FILE########
__FILENAME__ = gaugesplash
# Modified by Niels Zeilemaker, removed timeout did a small cleanup
from Tribler.Main.vwxGUI import DEFAULT_BACKGROUND

#-----------------------------------------------------------------------------
# Name:        gaugesplash.py
# Purpose:     splash screen with gauge to show progress
#
# Author:      Rob McMullen
#
# Created:     2007
# RCS-ID:      $Id: $
# Copyright:   (c) 2007 Rob McMullen
# License:     wxWidgets
#-----------------------------------------------------------------------------

"""Splash screen with progress bar

A replacement for the standard wx.SplashScreen that adds a text label
and progress bar to update the user on the progress loading the
application.

I looked at both Andrea Gavana's AdvancedSplash, here:

http://xoomer.alice.it/infinity77/main/AdvancedSplash.html

and Ryaan Booysen's AboutBoxSplash

http://boa-constructor.cvs.sourceforge.net/boa-constructor/boa/About.py?revision=1.38&view=markup

for inspiration and code.
"""

import logging
import wx


class GaugeSplash(wx.Frame):

    """Placeholder for a gauge-bar splash screen."""
    def __init__(self, bmp):
        wx.Frame.__init__(self, None, style=wx.FRAME_NO_TASKBAR)

        self._logger = logging.getLogger(self.__class__.__name__)

        self.count = 0
        self.border = 2
        self.SetBackgroundColour(DEFAULT_BACKGROUND)

        sizer = wx.BoxSizer(wx.VERTICAL)
        self.bmp = wx.StaticBitmap(self, -1, bmp)
        sizer.Add(self.bmp, 0, wx.EXPAND)

        self.label = wx.StaticText(self, -1, "Loading...")
        self.label.SetBackgroundColour(DEFAULT_BACKGROUND)
        sizer.Add(self.label, 0, flag=wx.EXPAND | wx.ALL, border=self.border)

        self.progressHeight = 12
        self.gauge = wx.Gauge(self, -1,
                              range=100, size=(-1, self.progressHeight),
                             style=wx.GA_HORIZONTAL | wx.GA_SMOOTH)
        self.gauge.SetBackgroundColour(DEFAULT_BACKGROUND)
        sizer.Add(self.gauge, 0, flag=wx.EXPAND | wx.TOP, border=self.border)
        self.SetSizer(sizer)
        sizer.Fit(self)

        self.CenterOnScreen()
        self.Layout()
        self.Show(True)

        try:
            wx.Yield()
        except:
            pass

    def setTicks(self, count):
        """Set the total number of ticks that will be contained in the
        progress bar.
        """
        self.gauge.SetRange(count)

    def tick(self, text):
        """Advance the progress bar by one tick and update the label.
        """
        self.count += 1
        self.label.SetLabel(text)
        self.gauge.SetValue(self.count)
        self.gauge.Update()
        self.Refresh()
        wx.Yield()

    def __del__(self):
        self._logger.debug("MAX ticks == %s", self.count)

        self.gauge.SetValue(self.gauge.GetRange())
        wx.Yield()

########NEW FILE########
__FILENAME__ = GuiImageManager
#
#
# This GuiImsageBuffer loads and buffers the pictures used by GUI in
# the type of wx.Bitmap.
#
import wx
from wx.lib.embeddedimage import PyEmbeddedImage

import os
import os.path
import sys
import logging
import cStringIO

from Tribler.Main.vwxGUI import warnWxThread

ICON_MAX_DIM = 80
SMALL_ICON_MAX_DIM = 32

logger = logging.getLogger(__name__)

class GuiImageManager(object):

    __single = None

    def __init__(self, tribler_path):
        if GuiImageManager.__single:
            raise RuntimeError("GuiImageManager is singleton")

        object.__init__(self)

        self._logger = logging.getLogger(self.__class__.__name__)

        self.IMAGE_SUBDIR = os.path.join(tribler_path, u"Tribler", u"Main", u"vwxGUI", u"images")
        self.DEFAULT_SUBDIR = os.path.join(self.IMAGE_SUBDIR, u"default")
        self.FLAG_SUBDIR    = os.path.join(self.IMAGE_SUBDIR, u"flags")

        # load all images
        self._default_dict = {}
        self._flag_dict    = {}
        self._other_dict   = {}
        self.__loadAllImages()

        self._icons = {}

    @staticmethod
    def getInstance(*args, **kw):
        if GuiImageManager.__single is None:
            GuiImageManager.__single = GuiImageManager(*args, **kw)
        return GuiImageManager.__single

    @staticmethod
    def delInstance(*args, **kw):
        GuiImageManager.__single = None

    @warnWxThread
    def __loadAllImages(self):
        """
        Loads and initiailizes all images, including:
        (1) default images (don't know why they are called default),
            they need to be rescaled to both large and small sizes.
        (2) country flags.
        (3) other images.
        """
        self._logger.debug(u"Loading images.")

        self.__initDefaultImages()
        self.__initFlagImages()

    def __initDefaultImages(self):
        """
        Loads the default images from files.
        """
        self._logger.debug(u"Start loading default images.")

        DEFAULT_IMAGE_INFO_LIST = [
            ("PEER_THUMB",            u'defaultThumbPeer.png'),
            ("TORRENT",               u'file_extension_tor.png'),
            ("TORRENT_NEW",           u'file_extension_tornew.png'),
            ("MODIFICATION",          u'edit_diff.png'),
            ("REVERTED_MODIFICATION", u'edit_reverted.png'),
            ("COMMENT",               u'comments.png'),
            ("MARKING",               u'marking.png'),
        ]
        self._default_dict = {
            "PEER_THUMB": {},
            "TORRENT": {},
            "TORRENT_NEW": {},
            "MODIFICATION": {},
            "REVERTED_MODIFICATION": {},
            "COMMENT":{},
            "MARKING":{}
        }
        for default_image_info in DEFAULT_IMAGE_INFO_LIST:
            name     = default_image_info[0]
            filename = default_image_info[1]

            image_path = os.path.join(self.DEFAULT_SUBDIR, filename)
            if not os.path.exists(image_path):
                self._logger.warn(u"Default image doesn't exist %s", image_path)
                continue
            if not os.path.isfile(image_path):
                self._logger.warn(u"Default image is not a file %s", image_path)
                continue

            bitmap = wx.Bitmap(image_path)
            big_image = bitmap.ConvertToImage()
            small_image = big_image.Copy()
            big_image = big_image.Rescale(ICON_MAX_DIM, ICON_MAX_DIM)
            small_image = small_image.Rescale(SMALL_ICON_MAX_DIM, SMALL_ICON_MAX_DIM)

            self._default_dict[name][ICON_MAX_DIM] = wx.BitmapFromImage(big_image)
            self._default_dict[name][SMALL_ICON_MAX_DIM] = wx.BitmapFromImage(small_image)

    def __initFlagImages(self):
        """
        Loads the country flags from files.
        """
        self._logger.debug(u"Start loading country flag images.")

        if not os.path.exists(self.FLAG_SUBDIR):
            self._logger.warn(u"Flags dir doesn't exist %s", self.FLAG_SUBDIR)
            return
        if not os.path.isdir(self.FLAG_SUBDIR):
            self._logger.warn(u"Not a dir %s", self.FLAG_SUBDIR)
            return

        # For OS X, we do not use the country flags due to a wx bug
        if sys.platform != "darwin":
            for flag in os.listdir(self.FLAG_SUBDIR):
                flag_path = os.path.join(self.FLAG_SUBDIR, flag)

                if not os.path.isfile(flag_path):
                    continue
                if not flag.endswith(u".png"):
                    self._logger.warn(u"SKIP, Not a PNG file %s", flag_path)
                    continue

                bitmap = wx.Bitmap(flag_path, wx.BITMAP_TYPE_ANY)

                # Size check for flag images.
                if bitmap.GetWidth() != 16 or bitmap.GetHeight() != 11:
                    self._logger.warn(u"Country flag[%s] is of size [%dx%d], NOT [%dx%d].",
                        flag, bitmap.GetWidth(), bitmap.GetHeight(), 16, 11)
                self._flag_dict[os.path.splitext(flag)[0].lower()] = bitmap

    @warnWxThread
    def getImage(self, name, dimension=None):
        """
        All other modules should use this method to get an image.
        """
        image = None

        # default image
        if name in self._default_dict:
            dimension = dimension or ICON_MAX_DIM
            image = self._default_dict[name].get(dimension, None)
            if image is None:
                self._logger.warn(u"Default image is not loaded [%s].", name)

        # other image
        else:
            image = self._other_dict.get(name, None)
            if image is None:
                self._logger.debug(u"Trying to load image [%s].", name)
                # lazy load
                image_path = os.path.join(self.IMAGE_SUBDIR, name)
                if not os.path.exists(image_path):
                    self._logger.warn(u"Image[%s] doesn't exist.", image_path)
                elif not os.path.isfile(image_path):
                    self._logger.warn(u"Image[%s] is not a file.", image_path)
                else:
                    image = wx.Bitmap(image_path, wx.BITMAP_TYPE_ANY)
                    self._other_dict[name] = image

        return image

    @warnWxThread
    def getCountryFlagDict(self):
        """
        Gets the country flag dictionary.
        """
        return self._flag_dict

    @warnWxThread
    def getPeerThumbnail(self, raw_data, dim=ICON_MAX_DIM):
        """
        Gets the peer thumbnail.
        """
        if raw_data is None:
            return None

        return data2wxBitmap("image/jpeg", cStringIO.StringIO(raw_data), dim)

    @warnWxThread
    def getBitmap(self, parent, type, background, state):
        assert isinstance(background, wx.Colour), u"we require a wx.colour object here, got %s" % type(background)
        if isinstance(background, wx.Colour):
            background = background.Get()
        else:
            background = wx.Brush(background).GetColour().Get()

        icons = self._icons.setdefault(type, {})
        if background not in icons:
            icons.setdefault(background, {})

            def fixSize(bitmap, width, height):
                if width != bitmap.GetWidth() or height != bitmap.GetHeight():

                    bmp = wx.EmptyBitmap(width, height)
                    dc = wx.MemoryDC(bmp)
                    dc.SetBackground(wx.Brush(background))
                    dc.Clear()

                    offset_x = (width - bitmap.GetWidth()) / 2
                    offset_y = (height - bitmap.GetHeight()) / 2

                    dc.DrawBitmap(bitmap, offset_x, offset_y)
                    dc.SelectObject(wx.NullBitmap)
                    del dc

                    return bmp
                return bitmap

            # create both icons
            icons[background][0] = self.__createBitmap(parent, background, type, 0)
            icons[background][1] = self.__createBitmap(parent, background, type, 1)

            width = max(icons[background][0].GetWidth(), icons[background][1].GetWidth())
            height = max(icons[background][0].GetHeight(), icons[background][1].GetHeight())

            icons[background][0] = fixSize(icons[background][0], width, height)
            icons[background][1] = fixSize(icons[background][1], width, height)

        if state not in icons[background]:
            icons[background][state] = self.__createBitmap(parent, background, type, state)
        return icons[background][state]

    def drawBitmap(self, name, size, font):
        bitmap = None
        if name == "no-thumbnail":
            bitmap = wx.EmptyBitmap(*size)
            dc = wx.MemoryDC(bitmap)
            dc.SetBackground(wx.Brush(wx.Colour(230, 230, 230)))
            dc.Clear()

            font.SetPointSize(font.GetPointSize() + 4)
            dc.SetFont(font)
            dc.SetTextForeground(wx.Colour(100, 100, 100))
            dc.DrawLabel('No thumbnail\navailable', (0, 0) + size,
                alignment=wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL)
            dc.SelectObject(wx.NullBitmap)
            del dc
        return bitmap

    def __createBitmap(self, parent, background, type, state):
        if state == 1:
            if type == 'tree':
                state = wx.CONTROL_EXPANDED
            elif type == 'checkbox':
                state = wx.CONTROL_CHECKED
            else:
                state = wx.CONTROL_PRESSED

        # There are some strange bugs in RendererNative, the alignment is incorrect of the drawn images
        # Thus we create a larger bmp, allowing for borders
        bmp = wx.EmptyBitmap(24, 24)
        dc = wx.MemoryDC(bmp)
        dc.SetBackground(wx.Brush(background))
        dc.Clear()

        # max size is 16x16, using 4px as a border
        if type == 'checkbox':
            wx.RendererNative.Get().DrawCheckBox(parent, dc, (4, 4, 16, 16), state)

        elif type == 'tree':
            wx.RendererNative.Get().DrawTreeItemButton(parent, dc, (4, 4, 16, 16), state)

        elif type == 'arrow':
            arrow = PyEmbeddedImage(
                "iVBORw0KGgoAAAANSUhEUgAAAAcAAAAECAYAAABCxiV9AAAAAXNSR0IArs4c6QAAAARnQU1B"
                "AACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAAadEVYdFNvZnR3YXJlAFBhaW50Lk5F"
                "VCB2My41LjEwMPRyoQAAADFJREFUGFdjYGBg+I8Tf/jwQRSbJFCckQFIcIEZSCYA+RxAzAyS"
                "BGFGmAIgzQTlMwAAOBAx4jYP9TUAAAAASUVORK5CYII=")
            return arrow.GetBitmap()

        elif type == 'slider':
            slider = PyEmbeddedImage(
                "iVBORw0KGgoAAAANSUhEUgAAAAkAAAAICAYAAAArzdW1AAAAAXNSR0IArs4c6QAAAARnQU1B"
                "AACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAAadEVYdFNvZnR3YXJlAFBhaW50Lk5F"
                "VCB2My41LjEwMPRyoQAAAOZJREFUKFM9j71rg1AUxd9LIUuX/gvZRAcRdfBjqp+jIoKYoZBQ"
                "UdEO+pysa6f+mZ0ayJCWri/nhcYLP7icc+6BS3Rd/3Jdl6dpyrMsW0mShNu2zU3T/CaKovC2"
                "bV+naXoGOTiAPRihN8Inqqryuq6Nvu83gALyD4W+Ez6RJOmnKIrPYRieGGMbNBCwxU7Lspxk"
                "Wf4jvu83mqadUP0xz/MDoIKu65hhGGf4jIgJw/CABy7jOPbLslC07BG4BEHwcguIyfN8G8dx"
                "4zjOb1VVR3x7jqKoFvoaui+4fLcs6+R53ttdQ/vjFXw5XtzmpGeLAAAAAElFTkSuQmCC")
            return slider.GetBitmap()

        dc.SelectObject(wx.NullBitmap)
        del dc

        # determine actual size of drawn icon, and return this subbitmap
        bb = wx.RegionFromBitmapColour(bmp, background).GetBox()
        return bmp.GetSubBitmap(bb)


@warnWxThread
def data2wxBitmap(type, data, dimension=ICON_MAX_DIM):
    """
    Creates a wx.Bitmap from a given raw data.
    """
    bitmap = None
    try:
        string_io = cStringIO.StringIO(data)

        if type == "image/bmp":
            image = wx.ImageFromStream(string_io, wx.BITMAP_TYPE_BMP)
        else:
            image = wx.ImageFromStreamMime(string_io, type)

        image.Rescale(dimension, dimension)
        bitmap = wx.BitmapFromImage(image)
    except:
        logger.exception('data2wxBitmap() failed (%s, %s)', repr(type), repr(dimension))

    return bitmap
########NEW FILE########
__FILENAME__ = GuiUtility
# Written by Jelle Roozenburg, Maarten ten Brinke, Arno Bakker, Lucian Musat
# Modified by Niels Zeilemaker
# see LICENSE.txt for license information

import wx
import os
import sys
import json
import logging
from time import time

from Tribler import LIBRARYNAME

from Tribler.Category.Category import Category
from Tribler.Core.simpledefs import SWIFT_URL_SCHEME
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler
from Tribler.Core.Search.SearchManager import split_into_keywords

from Tribler.Core.Video.VideoPlayer import VideoPlayer

from Tribler.Main.Utility.GuiDBHandler import startWorker, GUI_PRI_DISPERSY
from Tribler.Main.Utility.GuiDBTuples import RemoteChannel

from Tribler.Main.vwxGUI import forceWxThread
from Tribler.Main.vwxGUI.SearchGridManager import TorrentManager, ChannelManager, LibraryManager
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.TorrentStateManager import TorrentStateManager


class GUIUtility:
    __single = None

    def __init__(self, utility=None, params=None, app=None):
        if GUIUtility.__single:
            raise RuntimeError("GUIUtility is singleton")
        GUIUtility.__single = self
        self.registered = False

        self._logger = logging.getLogger(self.__class__.__name__)

        # do other init
        self.utility = utility
        self.vwxGUI_path = os.path.join(self.utility.getPath(), LIBRARYNAME, 'Main', 'vwxGUI')
        self.utility.guiUtility = self
        self.params = params
        self.frame = None
        self.app = app

        # videoplayer
        self.videoplayer = None

        # current GUI page
        self.guiPage = 'home'
        # previous pages
        self.oldpage = []

        # firewall
        self.firewall_restart = False  # ie Tribler needs to restart for the port number to be updated

        # Recall improves by 20-25% by increasing the number of peers to query to 20 from 10 !
        self.max_remote_queries = 20  # max number of remote peers to query

        self.current_search_query = ''

        self.lists = []

        from Tribler.Main.vwxGUI.list_header import ListHeaderIcon

        self.listicon = ListHeaderIcon.getInstance()

    def getInstance(*args, **kw):
        if GUIUtility.__single is None:
            GUIUtility(*args, **kw)
        return GUIUtility.__single
    getInstance = staticmethod(getInstance)

    def hasInstance():
        return GUIUtility.__single != None
    hasInstance = staticmethod(hasInstance)

    def delInstance():
        if GUIUtility.__single:
            GUIUtility.__single.listicon.delInstance()
            GUIUtility.__single.library_manager.delInstance()
            GUIUtility.__single.channelsearch_manager.delInstance()
            GUIUtility.__single.torrentsearch_manager.delInstance()
            GUIUtility.__single.torrentstate_manager.delInstance()

        GUIUtility.__single = None
    delInstance = staticmethod(delInstance)

    def register(self):
        if not self.registered:
            self.registered = True

            self.torrentsearch_manager = TorrentManager.getInstance(self)
            self.channelsearch_manager = ChannelManager.getInstance()
            self.library_manager = LibraryManager.getInstance(self)
            self.torrentstate_manager = TorrentStateManager.getInstance(self)

            self.torrentsearch_manager.connect(self.utility.session, self.library_manager, self.channelsearch_manager)
            self.channelsearch_manager.connect(self.utility.session, self.library_manager, self.torrentsearch_manager)
            self.library_manager.connect(self.utility.session, self.torrentsearch_manager, self.channelsearch_manager)
            self.torrentstate_manager.connect(self.torrentsearch_manager, self.library_manager, self.channelsearch_manager)

            self.videoplayer = VideoPlayer.getInstance()
        else:
            raise RuntimeError('GuiUtility is already registered')

    def ShowPlayer(self):
        if self.frame.videoparentpanel:
            self.ShowPage('videoplayer')

    @forceWxThread
    def ShowPage(self, page, *args):
        if page == 'settings':
            from Tribler.Main.vwxGUI.settingsDialog import SettingsDialog
            dialog = SettingsDialog()

            dialog.Centre()
            dialog.ShowModal()
            dialog.Destroy()

        elif page != self.guiPage:
            self.frame.actlist.selectTab(page)

            self.frame.top_bg.ClearButtonHandlers()

            self.oldpage.append(self.guiPage)
            if len(self.oldpage) > 3:
                self.oldpage.pop(0)

            self.frame.Freeze()

            if page not in ['search_results', 'my_files', 'selectedchannel', 'playlist', 'channels']:
                self.frame.splitter.Show(False)

            if page == 'search_results':
                # Show list
                self.SetTopSplitterWindow(self.frame.searchlist)
                items = self.frame.searchlist.GetExpandedItems()
                if items:
                    self.frame.searchlist.Select(items[0][0])
                else:
                    self.frame.searchlist.ResetBottomWindow()
            elif self.guiPage == 'search_results':
                # Hide list
                self.frame.searchlist.Show(False)

            if page == 'channels':
                self.SetTopSplitterWindow(self.frame.channellist)
                items = self.frame.channellist.GetExpandedItems()
                if items:
                    self.frame.channellist.Select(items[0][0])
                else:
                    self.frame.channellist.ResetBottomWindow()

            elif self.guiPage == 'channels':
                self.frame.channellist.Show(False)

            if page == 'mychannel':
                # Show list
                self.frame.managechannel.SetChannelId(self.channelsearch_manager.channelcast_db._channel_id)
                self.frame.managechannel.Show()

            elif self.guiPage == 'mychannel':
                self.frame.managechannel.Show(False)

            if page == 'managechannel':
                self.frame.managechannel.Show()

            elif self.guiPage == 'managechannel':
                self.frame.managechannel.Show(False)

            if page == 'selectedchannel':
                self.SetTopSplitterWindow(self.frame.selectedchannellist)
                items = self.frame.selectedchannellist.GetExpandedItems()
                if items:
                    self.frame.selectedchannellist.Select(items[0][0])
                else:
                    self.frame.selectedchannellist.ResetBottomWindow()
                channelmenu = self.frame.actlist.GetItem(3)
                if channelmenu and channelmenu.expandedPanel:
                    channelmenu.expandedPanel.AddCurrentChannelLink()

            elif self.guiPage == 'selectedchannel':
                self.frame.selectedchannellist.Show(False)
                if not self.frame.splitter.IsSplit():
                    sashpos = getattr(self.frame.splitter_top_window, 'sashpos', -185)
                    self.frame.splitter.SplitHorizontally(self.frame.splitter_top_window, self.frame.splitter_bottom_window, sashpos)

            if page == 'playlist':
                self.SetTopSplitterWindow(self.frame.playlist)
                items = self.frame.playlist.GetExpandedItems()
                if items:
                    self.frame.playlist.Select(items[0][0])
                else:
                    self.frame.playlist.ResetBottomWindow()
                channelmenu = self.frame.actlist.GetItem(3)
                if channelmenu and channelmenu.expandedPanel:
                    channelmenu.expandedPanel.AddCurrentPlaylistLink()

            elif self.guiPage == 'playlist':
                self.frame.playlist.Show(False)

            if page == 'my_files':
                # Show list
                self.SetTopSplitterWindow(self.frame.librarylist)

                # Open infohash
                if args:
                    self.frame.librarylist.GetManager().refresh_or_expand(args[0])
                else:
                    items = self.frame.librarylist.GetExpandedItems()
                    if items:
                        items[0][1].expanded = False
                        self.frame.librarylist.Select(items[0][0])
                    else:
                        self.frame.librarylist.ResetBottomWindow()

                # Open infohash
                if args:
                    self.frame.librarylist.GetManager().refresh_or_expand(args[0])

            elif self.guiPage == 'my_files':
                # Hide list
                self.frame.librarylist.Show(False)

            if page == 'home':
                self.frame.home.ResetSearchBox()
                self.frame.home.Show()
            elif self.guiPage == 'home':
                self.frame.home.Show(False)

            if page == 'stats':
                self.frame.stats.Show()
            elif self.guiPage == 'stats':
                self.frame.stats.Show(False)

            if page == 'anonymity':
                # Removing anonymity panel from library details in order to make it fullscreen.
                lib_details = self.frame.librarydetailspanel
                anon_panel = lib_details.anonymityPanel
                anon_panel.Reparent(self.frame)
                anon_panel.SetFullScreenMode(True)
                anon_panel.Show(False)
                lib_details.anonymitySizer.Detach(anon_panel)
                anon_panel.Show(True)
                self.frame.GetSizer().GetChildren()[1].GetSizer().Add(anon_panel, 1, wx.EXPAND)
            elif self.guiPage == 'anonymity':
                lib_details = self.frame.librarydetailspanel
                anon_panel = lib_details.anonymityPanel
                anon_panel.Show(False)
                self.frame.GetSizer().GetChildren()[1].GetSizer().Detach(anon_panel)
                anon_panel.Show(True)
                anon_panel.Reparent(lib_details.anonymityTab)
                lib_details.anonymitySizer.Add(anon_panel, 1, wx.EXPAND)
                anon_panel.SetFullScreenMode(False)
                lib_details.Layout()

            if self.frame.videoparentpanel:
                if page == 'videoplayer':
                    self.frame.videoparentpanel.Show(True)
                elif self.guiPage == 'videoplayer':
                    self.frame.videoparentpanel.Show(False)

            self.guiPage = page
            self.frame.Layout()
            self.frame.Thaw()

        # Set focus to page
        if page == 'search_results':
            self.frame.searchlist.Focus()

            if args:
                self.frame.searchlist.total_results = None
                self.frame.searchlist.SetKeywords(args[0])

        elif page == 'channels':
            self.frame.channellist.Focus()
        elif page == 'selectedchannel':
            self.frame.selectedchannellist.Focus()
        elif page == 'my_files':
            self.frame.librarylist.Focus()

    def GetSelectedPage(self):
        if self.guiPage == 'home':
            return self.frame.home

        if self.guiPage == 'search_results':
            return self.frame.searchlist

        if self.guiPage == 'channels':
            return self.frame.channellist

        if self.guiPage == 'selectedchannel':
            return self.frame.selectedchannellist

        if self.guiPage == 'mychannel':
            return self.frame.managechannel

        if self.guiPage == 'managechannel':
            return self.frame.managechannel

        if self.guiPage == 'playlist':
            return self.frame.playlist

        if self.guiPage == 'my_files':
            return self.frame.librarylist

    def SetTopSplitterWindow(self, window=None, show=True):
        while self.frame.splitter_top.GetChildren():
            self.frame.splitter_top.Detach(0)

        from Tribler.Main.vwxGUI.list_details import ChannelInfoPanel
        self.SetBottomSplitterWindow(ChannelInfoPanel)
        if window:
            self.frame.splitter_top.Add(window, 1, wx.EXPAND)
            window.Show(show)
        self.frame.splitter.Show(show)
        self.frame.splitter_top.Layout()
        self.frame.splitter_top_window.Refresh()

    def SetBottomSplitterWindow(self, panel_type):
        self.frame.splitter_bottom_window.Freeze()

        from Tribler.Main.vwxGUI.list_details import TorrentDetails, ChannelInfoPanel, LibraryDetails, ChannelDetails, PlaylistDetails, SearchInfoPanel, LibraryInfoPanel, SelectedchannelInfoPanel, PlaylistInfoPanel

        type_to_panel = {TorrentDetails.__name__: self.frame.torrentdetailspanel,
                         LibraryDetails.__name__: self.frame.librarydetailspanel, \
                         ChannelDetails.__name__: self.frame.channeldetailspanel, \
                         PlaylistDetails.__name__: self.frame.playlistdetailspanel, \
                         SearchInfoPanel.__name__: self.frame.searchinfopanel, \
                         ChannelInfoPanel.__name__: self.frame.channelinfopanel, \
                         LibraryInfoPanel.__name__: self.frame.libraryinfopanel, \
                         PlaylistInfoPanel.__name__: self.frame.playlistinfopanel, \
                         SelectedchannelInfoPanel.__name__: self.frame.selectedchannelinfopanel}

        result = None
        for pt, pl in type_to_panel.iteritems():
            pl.Show(pt == panel_type.__name__)
            if pt == panel_type.__name__:
                result = pl
        if self.guiPage != 'mychannel':
            self.frame.splitter.Show(True)
        self.frame.splitter_bottom.Layout()
        self.frame.splitter_bottom_window.Thaw()
        self.frame.splitter_bottom_window.Refresh()
        return result

    def SetColumnInfo(self, itemtype, columns, hide_defaults=[]):
        # Load hidden column info
        hide_columns = self.ReadGuiSetting("hide_columns", default={})
        hide_columns = hide_columns.get(itemtype.__name__, {})
        for index, column in enumerate(columns):
            if column['name'] in hide_columns:
                column['show'] = hide_columns[column['name']]
            else:
                column['show'] = not (index in hide_defaults)

        # Load column width info
        column_sizes = self.ReadGuiSetting("column_sizes", default={})
        column_sizes = column_sizes.get(itemtype.__name__, {})
        for index, column in enumerate(columns):
            if column['name'] in column_sizes:
                column['width'] = column_sizes[column['name']]

        return columns

    def ReadGuiSetting(self, setting_name, default=None, do_json=True):
        setting_value = self.utility.read_config(setting_name, literal_eval=False)
        if do_json and setting_value:
            setting_value = json.loads(setting_value)
        elif not setting_value:
            setting_value = default
        return setting_value

    def WriteGuiSetting(self, setting_name, setting_value, do_json=True):
        self.utility.write_config(setting_name, json.dumps(setting_value) if do_json else setting_value)
        self.utility.flush_config()

    @forceWxThread
    def GoBack(self, scrollTo=None, topage=None):
        if topage:
            self.oldpage.pop()
        else:
            if len(self.oldpage) > 0:
                topage = self.oldpage.pop()
            else:
                return

        if topage == 'search_results':
            self.frame.actlist.selectTab('results')
        elif topage in ['channels', 'selectedchannel', 'mychannel']:
            self.frame.actlist.selectTab('channels')
        else:
            self.frame.actlist.selectTab(topage)

        self.ShowPage(topage)
        self.oldpage.pop()  # remove curpage from history

        if scrollTo:
            self.ScrollTo(scrollTo)

    def dosearch(self, input=None):
        if input == None:
            sf = self.frame.top_bg.searchField
            if sf is None:
                return

            input = sf.GetValue()

        if input:
            input = input.strip()
            if input == '':
                return
        else:
            return
        self.frame.top_bg.searchField.SetValue(input)

        if input.startswith("http://"):
            if self.frame.startDownloadFromUrl(str(input)):
                self.frame.top_bg.searchField.Clear()
                self.ShowPage('my_files')

        elif input.startswith("magnet:"):
            if self.frame.startDownloadFromMagnet(str(input)):
                self.frame.top_bg.searchField.Clear()
                self.ShowPage('my_files')

        elif input.startswith(SWIFT_URL_SCHEME) or input.startswith("ppsp://"):
            if self.frame.startDownloadFromSwift(str(input)):
                self.frame.top_bg.searchField.Clear()
                self.ShowPage('my_files')

        else:
            keywords = split_into_keywords(input)
            keywords = [keyword for keyword in keywords if len(keyword) > 1]

            if len(keywords) == 0:
                self.Notify('Please enter a search term', "Your search term '%s' was either to small or to general." % input, icon=wx.ART_INFORMATION)

            else:
                self.frame.top_bg.StartSearch()
                self.current_search_query = keywords
                self._logger.debug("GUIUtil: searchFiles: %s %s", keywords, time())

                self.frame.searchlist.Freeze()

                self.torrentsearch_manager.setSearchKeywords(keywords)
                self.channelsearch_manager.setSearchKeywords(keywords)

                # We set oldkeywords to '', which will trigger a reset in SetKeywords (called from ShowPage). This avoid calling reset twice.
                # Niels: 17-09-2012, unfortunately showpage calls show(true) which results in the dirty items being refreshed.
                # We need to call Reset in order to prevent this from happening
                self.frame.searchlist.Reset()
                self.ShowPage('search_results', keywords)

                # We now have to call thaw, otherwise loading message will not be shown.
                self.frame.searchlist.Thaw()

                # Peform local search
                self.torrentsearch_manager.set_gridmgr(self.frame.searchlist.GetManager())
                self.channelsearch_manager.set_gridmgr(self.frame.searchlist.GetManager())

                def db_thread():
                    self.torrentsearch_manager.refreshGrid()

                    nr_peers_connected = self.torrentsearch_manager.searchDispersy()
                    self.channelsearch_manager.searchDispersy()
                    return nr_peers_connected

                def wx_thread(delayedResult):
                    nr_peers_connected = delayedResult.get()

                    self.frame.searchlist.SetMaxResults(nr_peers_connected + 1, keywords)
                    self.frame.searchlist.NewResult()

                startWorker(wx_thread, db_thread, priority=1024)

    @forceWxThread
    def NewResult(self):
        self.frame.searchlist.NewResult()

    @forceWxThread
    def showChannelCategory(self, category, show=True):

        manager = self.frame.channellist.GetManager()
        manager.SetCategory(category, True)

        if show:
            self.ShowPage('channels')

    @forceWxThread
    def showLibrary(self, show=True):
        manager = self.frame.librarylist.GetManager()
        manager.do_or_schedule_refresh(True)

        if show:
            self.ShowPage('my_files')

    def showChannelFromId(self, channel_id):
        def db_callback():
            channel = self.channelsearch_manager.getChannel(channel_id)
            self.showChannel(channel)

        startWorker(None, db_callback, priority=GUI_PRI_DISPERSY)

    def showChannelFromDispCid(self, channel_cid):
        def db_callback():
            channel = self.channelsearch_manager.getChannelByCid(channel_cid)
            self.showChannel(channel)

        startWorker(None, db_callback, priority=GUI_PRI_DISPERSY)

    def showChannelFromPermid(self, channel_permid):
        def db_callback():
            channel = self.channelsearch_manager.getChannelByPermid(channel_permid)
            self.showChannel(channel)

        startWorker(None, db_callback, priority=GUI_PRI_DISPERSY)

    @forceWxThread
    def showChannel(self, channel):
        if channel:
            manager = self.frame.selectedchannellist.GetManager()
            manager.refresh_if_required(channel)

            self.ShowPage('selectedchannel')

            if isinstance(channel, RemoteChannel):
                self.showChannelFromPermid(channel.permid)

    def showChannels(self):
        self.frame.actlist.selectTab('channels')
        self.ShowPage('channels')

    @forceWxThread
    def showChannelResults(self, data_channel):
        self.frame.actlist.selectTab('channels')

        def subscribe_latestupdate_sort(a, b):
            val = cmp(a.modified, b.modified)
            if val == 0:
                return cmp(a.name, b.name)
            return val

        data = data_channel.values()
        data.sort(subscribe_latestupdate_sort, reverse=True)

        manager = self.frame.channellist.GetManager()
        manager.SetCategory('searchresults')
        manager.refresh(data)

        self.ShowPage('channels')

    @forceWxThread
    def showManageChannel(self, channel):
        self.frame.managechannel.SetChannel(channel)
        self.ShowPage('managechannel')

    @forceWxThread
    def showPlaylist(self, data):
        self.frame.playlist.Set(data)
        self.ShowPage('playlist')

    def OnList(self, goto_end, event=None):
        lists = {'channels': self.frame.channellist, 'selectedchannel': self.frame.selectedchannellist, 'mychannel': self.frame.managechannel, 'search_results': self.frame.searchlist, 'my_files': self.frame.librarylist}
        if self.guiPage in lists and lists[self.guiPage].HasFocus():
            lists[self.guiPage].ScrollToEnd(goto_end)
        elif event:
            event.Skip()

    def ScrollTo(self, id):
        lists = {'channels': self.frame.channellist, 'selectedchannel': self.frame.selectedchannellist, 'mychannel': self.frame.managechannel, 'search_results': self.frame.searchlist, 'my_files': self.frame.librarylist}
        if self.guiPage in lists:
            lists[self.guiPage].ScrollToId(id)

    @forceWxThread
    def Notify(self, title, msg='', icon=wx.ART_INFORMATION):
        if sys.platform == 'win32' and not self.frame.IsShownOnScreen():
            self.frame.tbicon.Notify(title, msg, icon)
        else:
            if isinstance(icon, basestring):
                icon = wx.ArtProvider.GetBitmap(icon, wx.ART_FRAME_ICON) or \
                    GuiImageManager.getInstance().getImage(u"notify_%s.png" % icon)
            self.frame.actlist.Notify(msg or title, icon)

    def ShouldGuiUpdate(self):
        if self.frame.ready:
            return self.frame.GUIupdate
        return True

    def addList(self, l):
        if l not in self.lists:
            self.lists.append(l)

    def toggleFamilyFilter(self, newState=None, setCheck=False):
        if newState == None:
            newState = not self.getFamilyFilter()

        Category.getInstance().set_family_filter(newState)
        for l in self.lists:
            if getattr(l, 'GotFilter', False):
                l.GotFilter(None)

        if setCheck:
            self.frame.SRstatusbar.ff_checkbox.SetValue(newState)

        if newState:
            self.utility.write_config('family_filter', 1)
        else:
            self.utility.write_config('family_filter', 0)
        self.utility.flush_config()

    def getFamilyFilter(self):
        catobj = Category.getInstance()
        return catobj.family_filter_enabled()

    def set_firewall_restart(self, b):
        self.firewall_restart = b

    @forceWxThread
    def MarkAsFavorite(self, event, channel):
        if channel:
            if event:
                button = event.GetEventObject()
                button.Enable(False)
                if hasattr(button, 'selected'):
                    button.selected = False

            dlgname = 'MFdialog'
            if not self.ReadGuiSetting('show_%s' % dlgname, default=True):
                response = wx.ID_OK
            else:
                from Tribler.Main.Dialogs.ConfirmationDialog import ConfirmationDialog
                dlg = ConfirmationDialog(None, dlgname, "You are about to add \'%s\' to your list of favourite channels." % channel.name,
                                         "If you mark this channel as your favourite, you will be able to access its full content.")
                response = dlg.ShowModal()

            if response == wx.ID_OK:
                @forceDBThread
                def add_vote():
                    self.channelsearch_manager.favorite(channel.id)
                    wx.CallAfter(self.Notify, "Channel marked as favourite", "Marked channel '%s' as favourite" % channel.name, icon='favourite')
                    if event:
                        button.Enable(True)
                    UserEventLogDBHandler.getInstance().addEvent(message="User marked a channel as favorite", type=2)
                    self.RefreshChannel(channel.id)
                add_vote()
            elif event:
                button.Enable(True)

    @forceWxThread
    def RemoveFavorite(self, event, channel):
        if channel:
            if event:
                button = event.GetEventObject()
                button.Enable(False)
                if hasattr(button, 'selected'):
                    button.selected = False

            dlgname = 'RFdialog'
            if not self.ReadGuiSetting('show_%s' % dlgname, default=True):
                response = wx.ID_OK
            else:
                from Tribler.Main.Dialogs.ConfirmationDialog import ConfirmationDialog
                dlg = ConfirmationDialog(None, dlgname, "You are about to remove \'%s\' from your list of favourite channels." % channel.name,
                                         "If you remove this channel from your favourites, you will no longer be able to access its full content.")
                response = dlg.ShowModal()

            if response == wx.ID_OK:
                @forceDBThread
                def remove_vote():
                    self.channelsearch_manager.remove_vote(channel.id)
                    wx.CallAfter(self.Notify, "Channel removed from favourites", "Removed channel '%s' from your favourites" % channel.name, icon='favourite')
                    if event:
                        button.Enable(True)
                    self.RefreshChannel(channel.id)
                remove_vote()
            elif event:
                button.Enable(True)

    @forceWxThread
    def MarkAsSpam(self, event, channel):
        if channel:
            if event:
                button = event.GetEventObject()
                button.Enable(False)
                if hasattr(button, 'selected'): button.selected = False

            dlgname = 'MSdialog'
            if not self.ReadGuiSetting('show_%s' % dlgname, default=True):
                response = wx.ID_OK
            else:
                from Tribler.Main.Dialogs.ConfirmationDialog import ConfirmationDialog
                dlg = ConfirmationDialog(None, dlgname, "You are about to report channel \'%s\' as spam." % channel.name, "")
                response = dlg.ShowModal()

            if response == wx.ID_OK:
                @forceDBThread
                def remove_vote():
                    self.channelsearch_manager.spam(channel.id)
                    wx.CallAfter(self.Notify, "Channel marked as spam", "Channel '%s' marked as spam" % channel.name)
                    if event: button.Enable(True)
                    self.RefreshChannel(channel.id)
                remove_vote()
            elif event:
                button.Enable(True)

    @forceWxThread
    def RemoveSpam(self, event, channel):
        if channel:
            if event:
                button = event.GetEventObject()
                button.Enable(False)
                if hasattr(button, 'selected'): button.selected = False

            dlgname = 'RSdialog'
            if not self.ReadGuiSetting('show_%s' % dlgname, default=True):
                response = wx.ID_OK
            else:
                from Tribler.Main.Dialogs.ConfirmationDialog import ConfirmationDialog
                dlg = ConfirmationDialog(None, dlgname, "You are about unmark channel \'%s\' as spam." % channel.name, "")
                response = dlg.ShowModal()

            if response == wx.ID_OK:
                @forceDBThread
                def remove_vote():
                    self.channelsearch_manager.remove_vote(channel.id)
                    wx.CallAfter(self.Notify, "Channel unmarked as spam", "Channel '%s' unmarked as spam" % channel.name)
                    if event: button.Enable(True)
                    self.RefreshChannel(channel.id)
                remove_vote()
            elif event:
                button.Enable(True)

    def RefreshChannel(self, channelid):
        if self.guiPage in ['search_results', 'selectedchannel', 'channels']:

            list = self.GetSelectedPage()
            if self.guiPage == 'search_results':
                list.GetManager().refresh_partial(channelids=[channelid])
            else:
                list.GetManager().refresh_partial((channelid,))

            if self.guiPage == 'selectedchannel':
                wx.CallAfter(list.GetManager().reload, channelid)

    def SelectVideo(self, videofiles, selected_file=None):
        if len(videofiles) > 1:
            videofiles.sort()
            dialog = wx.SingleChoiceDialog(None, 'Tribler currently only supports playing one file at a time.\nSelect the file you want to play.', 'Which file do you want to play?', videofiles)
            if selected_file in videofiles:
                dialog.SetSelection(videofiles.index(selected_file))

            selected_file = dialog.GetStringSelection() if dialog.ShowModal() == wx.ID_OK else None
            dialog.Destroy()
            return selected_file
        elif len(videofiles) == 1:
            return videofiles[0]

########NEW FILE########
__FILENAME__ = home
# Written by Niels Zeilemaker
import threading
import wx
import sys
import os
import copy

import wx
import igraph
from Tribler.Main.Dialogs.GUITaskQueue import GUITaskQueue
from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue
from Tribler.community.anontunnel.community import ProxyCommunity
import datetime
from Tribler.community.anontunnel.routing import Hop

try:
    import igraph.vendor.texttable
except:
    pass
import random
import logging
import binascii
from time import strftime, time
from collections import defaultdict
from traceback import print_exc

from Tribler.Category.Category import Category
from Tribler.Core.Tag.Extraction import TermExtraction
from Tribler.Core.simpledefs import NTFY_TORRENTS, NTFY_INSERT, NTFY_ANONTUNNEL, \
    NTFY_CREATED, NTFY_EXTENDED, NTFY_BROKEN, NTFY_SELECT, NTFY_JOINED, \
    NTFY_EXTENDED_FOR
from Tribler.Core.Session import Session
from Tribler.Core.CacheDB.SqliteCacheDBHandler import MiscDBHandler, \
    TorrentDBHandler, ChannelCastDBHandler
from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler

from Tribler.Main.vwxGUI import SEPARATOR_GREY, DEFAULT_BACKGROUND, LIST_BLUE
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility, forceWxThread
from Tribler.Main.Utility.GuiDBHandler import startWorker, GUI_PRI_DISPERSY
from Tribler.Main.vwxGUI.list_header import DetailHeader
from Tribler.Main.vwxGUI.list_body import ListBody
from Tribler.Main.vwxGUI.list_item import ThumbnailListItemNoTorrent
from Tribler.Main.vwxGUI.list_footer import ListFooter
from Tribler.Main.vwxGUI.widgets import SelectableListCtrl, \
    TextCtrlAutoComplete, BetterText as StaticText, LinkStaticText

try:
    # C(ython) module
    import arflayout
except ImportError, e:
    # Python fallback module
    import arflayout_fb as arflayout


class Home(wx.Panel):

    def __init__(self, parent):
        wx.Panel.__init__(self, parent)
        self.guiutility = GUIUtility.getInstance()

        self.SetBackgroundColour(DEFAULT_BACKGROUND)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.AddStretchSpacer()

        text = StaticText(self, -1, "Tribler")
        font = text.GetFont()
        font.SetPointSize(font.GetPointSize() * 3)
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        text.SetForegroundColour((255, 51, 0))
        text.SetFont(font)

        textSizer = wx.FlexGridSizer(2, 2, 3, 7)
        if sys.platform == 'darwin':  # mac
            self.searchBox = wx.TextCtrl(self, style=wx.TE_PROCESS_ENTER)
        else:
            self.searchBox = TextCtrlAutoComplete(self, entrycallback=parent.top_bg.complete, selectcallback=parent.top_bg.OnAutoComplete)

        font = self.searchBox.GetFont()
        font.SetPointSize(font.GetPointSize() * 2)
        self.searchBox.SetFont(font)
        self.searchBox.Bind(wx.EVT_TEXT_ENTER, self.OnSearchKeyDown)

        if sys.platform == 'darwin':  # mac
            self.searchBox.SetMinSize((450, self.searchBox.GetTextExtent('T')[1] + 5))
        else:
            self.searchBox.SetMinSize((450, -1))
        self.searchBox.SetFocus()

        textSizer.Add(text, 0, wx.EXPAND | wx.RIGHT, 7)
        scalingSizer = wx.BoxSizer(wx.HORIZONTAL)
        scalingSizer.Add(self.searchBox)

        if sys.platform == 'darwin':  # mac
            searchButton = wx.Button(self, -1, '\n')
            searchButton.SetLabel('Search')
        else:
            searchButton = wx.Button(self, -1, 'Search')
        searchButton.Bind(wx.EVT_BUTTON, self.OnClick)

        scalingSizer.Add(searchButton, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 3)

        textSizer.Add(scalingSizer, 0, wx.ALIGN_CENTER_VERTICAL)
        textSizer.AddSpacer((1, 1))

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(StaticText(self, -1, "Take me to "))
        channelLink = LinkStaticText(self, "channels", icon=None)

        channelLink.Bind(wx.EVT_LEFT_UP, self.OnChannels)
        hSizer.Add(channelLink)
        hSizer.Add(StaticText(self, -1, " to see what others are sharing"))
        textSizer.Add(hSizer)

        vSizer.Add(textSizer, 0, wx.ALIGN_CENTER)
        vSizer.AddStretchSpacer()

        self.aw_panel = ArtworkPanel(self)
        self.aw_panel.SetMinSize((-1, 275))
        self.aw_panel.Show(self.guiutility.ReadGuiSetting('show_artwork', True))
        vSizer.Add(self.aw_panel, 0, wx.EXPAND)

        self.SetSizer(vSizer)
        self.Layout()

        self.Bind(wx.EVT_RIGHT_UP, self.OnRightClick)

        self.SearchFocus()

    def OnRightClick(self, event):
        menu = wx.Menu()
        itemid = wx.NewId()
        menu.AppendCheckItem(itemid, 'Show recent videos')
        menu.Check(itemid, self.aw_panel.IsShown())

        def toggleArtwork(event):
            show = not self.aw_panel.IsShown()
            self.aw_panel.Show(show)
            self.guiutility.WriteGuiSetting("show_artwork", show)
            self.Layout()

        menu.Bind(wx.EVT_MENU, toggleArtwork, id=itemid)

        if menu:
            self.PopupMenu(menu, self.ScreenToClient(wx.GetMousePosition()))
            menu.Destroy()

    def OnClick(self, event):
        term = self.searchBox.GetValue()
        self.guiutility.dosearch(term)

    def OnSearchKeyDown(self, event):
        self.OnClick(event)

    def OnChannels(self, event):
        self.guiutility.showChannels()

    def ResetSearchBox(self):
        self.searchBox.Clear()

    def SearchFocus(self):
        self.searchBox.SetFocus()
        self.searchBox.SelectAll()


class Stats(wx.Panel):

    def __init__(self, parent):
        wx.Panel.__init__(self, parent)

        self._logger = logging.getLogger(self.__class__.__name__)

        self.guiutility = GUIUtility.getInstance()
        self.createTimer = None
        self.isReady = False

    def _DoInit(self):
        self.SetBackgroundColour(DEFAULT_BACKGROUND)
        vSizer = wx.BoxSizer(wx.VERTICAL)

        self.dowserStatus = StaticText(self, -1, 'Dowser is not running')
        self.dowserButton = wx.Button(self, -1, 'Start dowser')
        self.dowserButton.Bind(wx.EVT_BUTTON, self.OnDowser)
        self.memdumpButton = wx.Button(self, -1, 'Dump memory')
        self.memdumpButton.Bind(wx.EVT_BUTTON, self.OnMemdump)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(self.dowserStatus, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 3)
        hSizer.Add(self.dowserButton)
        hSizer.Add(self.memdumpButton, 0, wx.RIGHT, 3)
        vSizer.Add(hSizer, 0, wx.ALIGN_RIGHT | wx.TOP | wx.BOTTOM, 3)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.__dispersy_frame_btn = wx.Button(self, -1, "Open Dispersy Debug Frame")
        self.__dispersy_frame_btn.Bind(wx.EVT_BUTTON, self.OnOpenDispersyDebugButtonClicked)
        hSizer.Add(self.__dispersy_frame_btn, 0, wx.EXPAND, 3)
        vSizer.Add(hSizer, 0, wx.EXPAND | wx.BOTTOM, 3)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(NetworkPanel(self), 1, wx.EXPAND | wx.RIGHT, 7)
        self.activity = ActivityPanel(self)
        hSizer.Add(self.activity, 1, wx.EXPAND)
        vSizer.Add(hSizer, 1, wx.EXPAND)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(NewTorrentPanel(self), 1, wx.EXPAND | wx.RIGHT, 7)
        hSizer.Add(PopularTorrentPanel(self), 1, wx.EXPAND, 7)
        vSizer.Add(hSizer, 1, wx.EXPAND)

        self.SetSizer(vSizer)
        self.Layout()

        self.Bind(wx.EVT_KEY_UP, self.onKey)
        if sys.platform.startswith('win'):
            # on Windows, the panel doesn't respond to keypresses
            self.Bind(wx.EVT_MOUSE_EVENTS, self.onMouse)

        self.isReady = True

    def OnOpenDispersyDebugButtonClicked(self, event):
        self.guiutility.frame.OnOpenDebugFrame(None)

    def onActivity(self, msg):
        if self.isReady:
            self.activity.onActivity(msg)

    def onKey(self, event):
        if event.ControlDown() and (event.GetKeyCode() == 73 or event.GetKeyCode() == 105):  # ctrl + i
            self._showInspectionTool()

        elif event.ControlDown() and (event.GetKeyCode() == 68 or event.GetKeyCode() == 100):  # ctrl + d
            self._printDBStats()
        else:
            event.Skip()

    def onMouse(self, event):
        if all([event.RightUp(), event.ControlDown(), event.AltDown(), event.ShiftDown()]):
            self._showInspectionTool()

        elif all([event.LeftUp(), event.ControlDown(), event.AltDown(), event.ShiftDown()]):
            self._printDBStats()

        else:
            event.Skip()

    def OnDowser(self, event):
        if self.dowserStatus.GetLabel() == 'Dowser is running':
            self._stopDowser()
        else:
            if not self._startDowser():
                dlg = wx.DirDialog(None, "Please select your dowser installation directory", style=wx.wx.DD_DIR_MUST_EXIST)
                if dlg.ShowModal() == wx.ID_OK and os.path.isdir(dlg.GetPath()):
                    sys.path.append(dlg.GetPath())
                    self._startDowser()

                dlg.Destroy()

    def OnMemdump(self, event):
        from meliae import scanner
        scanner.dump_all_objects("memory-dump.out")

    def _startDowser(self):
        try:
            import cherrypy
            import dowser
            cherrypy.config.update({'server.socket_port': 8080})
            cherrypy.tree.mount(dowser.Root())
            cherrypy.engine.start()

            self.dowserButton.SetLabel('Stop dowser')
            self.dowserStatus.SetLabel('Dowser is running')
            return True

        except:
            print_exc()
            return False

    def _stopDowser(self):
        try:
            import cherrypy
            cherrypy.engine.stop()

            self.dowserButton.SetLabel('Start dowser')
            self.dowserStatus.SetLabel('Dowser is not running')
            return True

        except:
            print_exc()
            return False

    def _showInspectionTool(self):
        import wx.lib.inspection
        itool = wx.lib.inspection.InspectionTool()
        itool.Show()
        try:
            frame = itool._frame

            import Tribler
            frame.locals['Tribler'] = Tribler

            session = Session.get_instance()
            frame.locals['session'] = session
            frame.locals['dispersy'] = session.lm.dispersy

        except Exception:
            import traceback
            traceback.print_exc()

    def _printDBStats(self):
        torrentdb = TorrentDBHandler.getInstance()
        tables = torrentdb._db.fetchall("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
        for table, in tables:
            self._logger.info("%s %s", table, torrentdb._db.fetchone("SELECT COUNT(*) FROM %s" % table))

    def Show(self, show=True):
        if show:
            if not self.isReady:
                self._DoInit()

        wx.Panel.Show(self, show)


class HomePanel(wx.Panel):

    def __init__(self, parent, title, background, hspacer=(0, 0), vspacer=(0, 0)):
        wx.Panel.__init__(self, parent)

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.SetBackgroundColour(background)
        self.SetForegroundColour(parent.GetForegroundColour())

        spacerFlags = 0
        if hspacer[0]:
            spacerFlags |= wx.LEFT
        if hspacer[1]:
            spacerFlags |= wx.RIGHT
        spacer = max(hspacer)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.AddSpacer((-1, vspacer[0]))

        self.header = self.CreateHeader()
        self.header.SetTitle(title)
        self.header.SetBackgroundColour(background)
        vSizer.Add(self.header, 0, wx.EXPAND | spacerFlags, spacer)

        self.panel = self.CreatePanel()
        if self.panel:
            vSizer.Add(self.panel, 1, wx.EXPAND | spacerFlags, spacer)

        self.footer = self.CreateFooter()
        self.footer.SetBackgroundColour(background)
        vSizer.Add(self.footer, 0, wx.EXPAND | spacerFlags, spacer)
        vSizer.AddSpacer((-1, vspacer[1]))

        self.SetSizer(vSizer)
        self.Layout()

    def CreateHeader(self):
        return DetailHeader(self)

    def CreatePanel(self):
        pass

    def CreateFooter(self):
        return ListFooter(self)

    def DoLayout(self):
        self.Freeze()
        self.Layout()
        self.GetParent().Layout()
        self.Thaw()


class NetworkPanel(HomePanel):

    def __init__(self, parent):
        HomePanel.__init__(self, parent, 'Network info', SEPARATOR_GREY, (0, 1))

        self.torrentdb = TorrentDBHandler.getInstance()
        self.channelcastdb = ChannelCastDBHandler.getInstance()
        self.remotetorrenthandler = RemoteTorrentHandler.getInstance()

        self.timer = None

        session = Session.get_instance()
        session.add_observer(self.OnNotify, NTFY_TORRENTS, [NTFY_INSERT])
        self.UpdateStats()

    def CreatePanel(self):
        panel = wx.Panel(self)
        panel.SetBackgroundColour(DEFAULT_BACKGROUND)
        vSizer = wx.BoxSizer(wx.VERTICAL)

        self.nrTorrents = StaticText(panel)
        self.nrFiles = StaticText(panel)
        self.totalSize = StaticText(panel)
        self.queueSize = StaticText(panel)
        self.queueSize.SetToolTipString('Number of torrents queued per prio')
        self.queueSuccess = StaticText(panel)
        self.queueBW = StaticText(panel)
        self.queueBW.SetToolTipString('Bandwidth spent on collecting .torrents')
        self.nrChannels = StaticText(panel)

        self.freeMem = None
        try:
            if wx.GetFreeMemory() != -1:
                self.freeMem = StaticText(panel)
        except:
            pass

        gridSizer = wx.FlexGridSizer(0, 2, 3, 10)
        gridSizer.AddGrowableCol(1)

        gridSizer.Add(StaticText(panel, -1, 'Number files'))
        gridSizer.Add(self.nrFiles, 0, wx.EXPAND)
        gridSizer.Add(StaticText(panel, -1, 'Total size'))
        gridSizer.Add(self.totalSize, 0, wx.EXPAND)
        gridSizer.Add(StaticText(panel, -1, 'Torrents collected'))
        gridSizer.Add(self.nrTorrents, 0, wx.EXPAND)
        gridSizer.Add(StaticText(panel, -1, 'Torrents in queue'))
        gridSizer.Add(self.queueSize, 0, wx.EXPAND)
        gridSizer.Add(StaticText(panel, -1, 'Torrent queue success'))
        gridSizer.Add(self.queueSuccess, 0, wx.EXPAND)
        gridSizer.Add(StaticText(panel, -1, 'Torrent queue bw'))
        gridSizer.Add(self.queueBW, 0, wx.EXPAND)
        gridSizer.Add(StaticText(panel, -1, 'Channels found'))
        gridSizer.Add(self.nrChannels, 0, wx.EXPAND)
        if self.freeMem:
            gridSizer.Add(StaticText(panel, -1, 'WX:Free memory'))
            gridSizer.Add(self.freeMem, 0, wx.EXPAND)

        vSizer.Add(gridSizer, 0, wx.EXPAND | wx.LEFT, 7)
        panel.SetSizer(vSizer)
        return panel

    def OnNotify(self, subject, type, infohash):
        try:
            if self.IsShownOnScreen():
                self.UpdateStats()
        except wx.PyDeadObjectError:
            pass

    def UpdateStats(self):
        def db_callback():
            stats = self.torrentdb.getTorrentsStats()
            nr_channels = self.channelcastdb.getNrChannels()
            self._UpdateStats(stats, nr_channels)

        startWorker(None, db_callback, uId=u"NetworkPanel_UpdateStats", priority=GUI_PRI_DISPERSY)

    @forceWxThread
    def _UpdateStats(self, stats, nr_channels):
        self.nrTorrents.SetLabel(str(stats[0]))
        if stats[1] is None:
            self.totalSize.SetLabel(str(stats[1]))
        else:
            self.totalSize.SetLabel(self.guiutility.utility.size_format(stats[1]))
        self.nrFiles.SetLabel(str(stats[2]))
        self.queueSize.SetLabel(self.remotetorrenthandler.getQueueSize())
        self.queueBW.SetLabel(self.remotetorrenthandler.getBandwidthSpent())

        qsuccess = self.remotetorrenthandler.getQueueSuccess()
        qlabel = ", ".join(label for label, tooltip in qsuccess)
        qtooltip = ", ".join(tooltip for label, tooltip in qsuccess)
        self.queueSuccess.SetLabel(qlabel)
        self.queueSuccess.SetToolTipString(qtooltip)
        self.nrChannels.SetLabel(str(nr_channels))

        if self.freeMem:
            self.freeMem.SetLabel(self.guiutility.utility.size_format(wx.GetFreeMemory()))

        if self.timer:
            self.timer.Restart(10000)
        else:
            self.timer = wx.CallLater(10000, self.UpdateStats)


class NewTorrentPanel(HomePanel):

    def __init__(self, parent):
        HomePanel.__init__(self, parent, 'Newest Torrents', SEPARATOR_GREY, (0, 1))
        self.Layout()

        self.torrentdb = TorrentDBHandler.getInstance()
        session = Session.get_instance()
        session.add_observer(self.OnNotify, NTFY_TORRENTS, [NTFY_INSERT])

    def CreatePanel(self):
        self.list = SelectableListCtrl(self)
        self.list.InsertColumn(0, 'Torrent')
        self.list.setResizeColumn(0)
        self.list.Bind(wx.EVT_LEFT_DCLICK, self.OnDoubleClick)
        self.list.SetMinSize((1, 80))
        return self.list

    def OnNotify(self, subject, type, infohash):
        try:
            if self.IsShownOnScreen():
                self.UpdateStats(infohash)
        except wx.PyDeadObjectError:
            pass

    def UpdateStats(self, infohash):
        def db_callback():
            torrent = self.torrentdb.getTorrent(infohash, include_mypref=False)
            if torrent:
                self._UpdateStats(torrent)

        startWorker(None, db_callback, uId=u"NewTorrentPanel_UpdateStats", priority=GUI_PRI_DISPERSY)

    @forceWxThread
    def _UpdateStats(self, torrent):
        self.list.InsertStringItem(0, torrent['name'])
        size = self.list.GetItemCount()
        if size > 10:
            self.list.DeleteItem(size - 1)

    def OnDoubleClick(self, event):
        selected = self.list.GetFirstSelected()
        if selected != -1:
            selected_file = self.list.GetItemText(selected)
            self.guiutility.dosearch(selected_file)


class PopularTorrentPanel(NewTorrentPanel):

    def __init__(self, parent):
        HomePanel.__init__(self, parent, 'Popular Torrents', SEPARATOR_GREY, (1, 0))
        self.Layout()

        self.misc_db = MiscDBHandler.getInstance()
        self.torrentdb = TorrentDBHandler.getInstance()

        self.timer = wx.Timer(self)
        self.Bind(wx.EVT_TIMER, self._onTimer, self.timer)
        self.timer.Start(10000, False)
        self.RefreshList()

    def _onTimer(self, event):
        if self.IsShownOnScreen():
            self.RefreshList()

    def RefreshList(self):
        def db_callback():
            familyfilter_sql = Category.getInstance().get_family_filter_sql(self.misc_db.categoryName2Id)
            if familyfilter_sql:
                familyfilter_sql = familyfilter_sql[4:]

            topTen = self.torrentdb._db.getAll("CollectedTorrent", ("infohash", "name", "(num_seeders+num_leechers) as popularity"), where=familyfilter_sql, order_by="(num_seeders+num_leechers) DESC", limit=10)
            self._RefreshList(topTen)

        startWorker(None, db_callback, uId=u"PopularTorrentPanel_RefreshList", priority=GUI_PRI_DISPERSY)

    @forceWxThread
    def _RefreshList(self, topTen):
        self.list.Freeze()
        self.list.DeleteAllItems()
        for item in topTen:
            if item[2] > 0:
                self.list.InsertStringItem(sys.maxsize, item[1])
        self.list.Thaw()


class ActivityPanel(NewTorrentPanel):

    def __init__(self, parent):
        HomePanel.__init__(self, parent, 'Recent Activity', SEPARATOR_GREY, (1, 0))

    @forceWxThread
    def onActivity(self, msg):
        msg = strftime("%H:%M:%S ") + msg
        self.list.InsertStringItem(0, msg)
        size = self.list.GetItemCount()
        if size > 50:
            self.list.DeleteItem(size - 1)


class Anonymity(wx.Panel):
    def __init__(self, parent):
        wx.Panel.__init__(self, parent, -1)

        self.SetBackgroundColour(wx.WHITE)
        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.session = self.utility.session

        self.AddComponents()

        self.vertices = {}
        self.edges = []

        self.selected_edges = []

        self.vertex_active = -1
        self.vertex_hover = -1
        self.vertex_hover_evt = None
        self.vertex_active_evt = None

        self.vertex_to_colour = {}
        self.colours = [wx.RED, wx.Colour(156, 18, 18), wx.Colour(183, 83, 83), wx.Colour(254, 134, 134), wx.Colour(254, 190, 190)]

        self.step = 0
        self.fps = 20

        self.last_keyframe = 0
        self.time_step = 5.0
        self.radius = 32
        self.line_width = 4
        self.margin_x = self.margin_y = 0

        self.layout_busy = False
        self.new_data = False

        self.peers = []
        self.toInsert = set()

        self.try_proxy()

    def try_proxy(self):
        dispersy = self.utility.session.lm.dispersy
        try:
            proxy_community = (c for c in dispersy.get_communities() if isinstance(c, ProxyCommunity)).next()
            self.found_proxy(proxy_community)
        except:
            wx.CallLater(1000, self.try_proxy)

    def found_proxy(self, proxy_community):
        self.proxy_community = proxy_community

        self.my_address = Hop(self.proxy_community.my_member._ec.pub())
        self.my_address.address = ('127.0.0.1', "SELF")

        self.refresh_timer = wx.Timer(self)
        self.Bind(wx.EVT_TIMER, lambda evt: self.graph_panel.Refresh(), self.refresh_timer)
        self.refresh_timer.Start(1000.0 / self.fps)

        self.circuit_timer = wx.Timer(self)
        self.Bind(wx.EVT_TIMER, self.OnUpdateCircuits, self.circuit_timer)
        self.circuit_timer.Start(5000)

        self.taskqueue = GUITaskQueue.getInstance()

        self.lock = threading.RLock()

        self.session.add_observer(self.OnExtended, NTFY_ANONTUNNEL, [NTFY_CREATED, NTFY_EXTENDED, NTFY_BROKEN])
        self.session.add_observer(self.OnSelect, NTFY_ANONTUNNEL, [NTFY_SELECT])
        self.session.add_observer(self.OnJoined, NTFY_ANONTUNNEL, [NTFY_JOINED])
        self.session.add_observer(self.OnExtendedFor, NTFY_ANONTUNNEL, [NTFY_EXTENDED_FOR])

    def SetFullScreenMode(self, enable):
        self.fullscreen = enable
        self.log_text.Show(enable)
        self.radius = 20 if enable else 12
        self.line_width = 2 if enable else 1
        self.vSizer.GetChildren()[0].SetBorder(20 if enable else 0)
        self.main_sizer.GetChildren()[0].SetBorder(20 if enable else 0)
        self.main_sizer.GetChildren()[1].SetBorder(20 if enable else 0)
        self.margin_x = 0 if enable else 50
        self.Layout()

    def AddComponents(self):
        self.graph_panel = wx.Panel(self, -1)
        self.graph_panel.Bind(wx.EVT_MOTION, self.OnMouse)
        self.graph_panel.Bind(wx.EVT_LEFT_UP, self.OnMouse)
        self.graph_panel.Bind(wx.EVT_PAINT, self.OnPaint)
        self.graph_panel.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)
        self.graph_panel.Bind(wx.EVT_SIZE, self.OnSize)

        self.circuit_list = SelectableListCtrl(self, style=wx.LC_REPORT | wx.BORDER_SIMPLE)
        self.circuit_list.InsertColumn(0, 'Circuit', wx.LIST_FORMAT_LEFT, 30)
        self.circuit_list.InsertColumn(1, 'Online', wx.LIST_FORMAT_RIGHT, 50)
        self.circuit_list.InsertColumn(2, 'Hops', wx.LIST_FORMAT_RIGHT, 45)
        self.circuit_list.InsertColumn(3, 'Bytes up', wx.LIST_FORMAT_RIGHT, 65)
        self.circuit_list.InsertColumn(4, 'Bytes down', wx.LIST_FORMAT_RIGHT, 65)
        self.circuit_list.setResizeColumn(0)
        self.circuit_list.Bind(wx.EVT_LIST_ITEM_SELECTED, self.OnItemSelected)
        self.circuit_list.Bind(wx.EVT_LIST_ITEM_DESELECTED, self.OnItemSelected)
        self.circuit_to_listindex = {}

        self.log_text = wx.TextCtrl(self, style=wx.TE_MULTILINE | wx.BORDER_SIMPLE | wx.HSCROLL & wx.VSCROLL)
        self.log_text.SetEditable(False)

        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.vSizer.Add(self.circuit_list, 1, wx.EXPAND | wx.BOTTOM, 20)
        self.vSizer.Add(self.log_text, 1, wx.EXPAND)
        self.main_sizer = wx.BoxSizer(wx.HORIZONTAL)
        self.main_sizer.Add(self.graph_panel, 3, wx.EXPAND | wx.ALL, 20)
        self.main_sizer.Add(self.vSizer, 2, wx.EXPAND | wx.ALL, 20)
        self.SetSizer(self.main_sizer)

    def OnItemSelected(self, event):
        selected = []
        item = self.circuit_list.GetFirstSelected()
        while item != -1:
            selected.append(item)
            item = self.circuit_list.GetNextSelected(item)

        selected_edges = []
        for item in selected:
            for circuit_id, listindex in self.circuit_to_listindex.iteritems():
                if listindex == item:
                    circuit = self.circuits.get(circuit_id, None)

                    if circuit:
                        hops = [self.my_address] + list(copy.copy(circuit.hops))
                        for index in range(len(hops) - 1):
                            vertexid1 = self.peers.index(hops[index]) if hops[index] in self.peers else None
                            vertexid2 = self.peers.index(hops[index + 1]) if hops[index + 1] in self.peers else None
                            edge = set([vertexid1, vertexid2])
                            selected_edges.append(edge)

        self.selected_edges = selected_edges

    def OnUpdateCircuits(self, event):
        self.circuits = dict(self.proxy_community.circuits)
        stats = self.proxy_community.global_stats.circuit_stats

        # Add new circuits & update existing circuits
        for circuit_id, circuit in self.circuits.iteritems():
            if circuit_id not in self.circuit_to_listindex:
                pos = self.circuit_list.InsertStringItem(sys.maxsize, str(circuit_id))
                self.circuit_to_listindex[circuit_id] = pos
            else:
                pos = self.circuit_to_listindex[circuit_id]
            self.circuit_list.SetStringItem(pos, 1, str(circuit.state))
            self.circuit_list.SetStringItem(pos, 2, str(len(circuit.hops)) + "/" + str(circuit.goal_hops))

            bytes_uploaded = stats[circuit_id].bytes_uploaded
            bytes_downloaded = stats[circuit_id].bytes_downloaded

            self.circuit_list.SetStringItem(pos, 3, self.utility.size_format(bytes_uploaded))
            self.circuit_list.SetStringItem(pos, 4, self.utility.size_format(bytes_downloaded))

        # Remove old circuits
        old_circuits = [circuit_id for circuit_id in self.circuit_to_listindex if circuit_id not in self.circuits]
        for circuit_id in old_circuits:
            listindex = self.circuit_to_listindex[circuit_id]
            self.circuit_list.DeleteItem(listindex)
            self.circuit_to_listindex.pop(circuit_id)
            for k, v in self.circuit_to_listindex.items():
                if v > listindex:
                    self.circuit_to_listindex[k] = v - 1

        # Update graph
        old_edges = getattr(self, 'old_edges', [])
        new_edges = []

        for circuit in self.circuits.values():
            hops = [self.my_address] + list(circuit.hops)
            for index in range(len(hops) - 1):
                edge = set([hops[index], hops[index + 1]])
                if edge not in new_edges:
                    new_edges.append(edge)

        for edge in new_edges:
            if edge not in old_edges:
                self.AddEdge(*edge)

        for edge in old_edges:
            if edge not in new_edges:
                self.RemoveEdge(*edge)

        self.old_edges = new_edges

    def AppendToLog(self, msg):
        self.log_text.AppendText('[%s]: %s' % (datetime.datetime.now().strftime("%H:%M:%S"), msg))

    @forceWxThread
    def OnExtended(self, subject, changeType, circuit):
        if changeType == NTFY_CREATED:
            self.AppendToLog("Created circuit %s\n" % (circuit.circuit_id))
        if changeType == NTFY_EXTENDED:
            self.AppendToLog("Extended circuit %s\n" % (circuit.circuit_id))
        if changeType == NTFY_BROKEN:
            self.AppendToLog("Circuit %d has been broken\n" % circuit)

    @forceWxThread
    def OnSelect(self, subject, changeType, circuit, address):
        self.AppendToLog("Circuit %d has been selected for destination %s\n" % (circuit, address))

    @forceWxThread
    def OnJoined(self, subject, changeType, address, circuit_id):
        self.AppendToLog("Joined an external circuit %d with %s:%d\n" % (circuit_id, address[0], address[1]))

    @forceWxThread
    def OnExtendedFor(self, subject, changeType, extended_for, extended_with):
        self.AppendToLog("Extended an external circuit (%s:%d, %d) with (%s:%d, %d)\n" % (
            extended_for[0].sock_addr[0], extended_for[0].sock_addr[1], extended_for[1], extended_with[0].sock_addr[0],
            extended_with[0].sock_addr[1], extended_with[1]))

    def AddEdge(self, from_addr, to_addr):
        with self.lock:
            # Convert from_addr/to_addr to from_id/to_id
            if from_addr not in self.peers:
                self.peers.append(from_addr)
            from_id = self.peers.index(from_addr)
            if to_addr not in self.peers:
                self.peers.append(to_addr)
            to_id = self.peers.index(to_addr)

            # Add id's to graph
            for peer_id in (from_id, to_id):
                if peer_id not in self.vertices:
                    self.toInsert.add(peer_id)
                    self.vertices[peer_id] = {}
            self.edges.append([to_id, from_id])
            self.new_data = True

    def RemoveEdge(self, from_addr, to_addr):
        with self.lock:
            if from_addr in self.peers and to_addr in self.peers:
                from_id = self.peers.index(from_addr)
                to_id = self.peers.index(to_addr)
                if [to_id, from_id] in self.edges:
                    self.edges.remove([to_id, from_id])
                if [from_id, to_id] in self.edges:
                    self.edges.remove([from_id, to_id])
                self.RemoveUnconnectedVertices()
                self.new_data = True

    def RemoveUnconnectedVertices(self):
        # Build a list of vertices and their number of neighbors, and delete the unconnected ones.
        for vertex_id, num_neighbors in self.CountNeighbors().iteritems():
            if num_neighbors == 0:
                self.RemoveVertex(vertex_id)

    def CountNeighbors(self):
        with self.lock:
            num_neighbors = dict([(k, 0) for k in self.vertices])
            for edge in self.edges:
                for vertexid in edge:
                    num_neighbors[vertexid] = num_neighbors.get(vertexid, 0) + 1
            return num_neighbors

    def RemoveVertex(self, toremove_id):
        with self.lock:
            if toremove_id in self.vertices:
                self.vertices.pop(toremove_id)
            if toremove_id in self.vertex_to_colour:
                self.vertex_to_colour.pop(toremove_id)
            if toremove_id < len(self.peers):
                self.peers.pop(toremove_id)
            self.edges = [edge for edge in self.edges if toremove_id not in edge]
            self.toInsert = set([id - 1 if id > toremove_id else id for id in self.toInsert if id != toremove_id])
            self.vertex_active = self.vertex_active - 1 if self.vertex_active > toremove_id else self.vertex_active
            self.vertex_hover = self.vertex_hover - 1 if self.vertex_hover > toremove_id else self.vertex_hover

            # We want the vertex id's to be 0, 1, 2 etc., so we need to correct for the vertex that we just removed.
            vertices = {}
            for index, vertexid in enumerate(sorted(self.vertices)):
                vertices[index] = self.vertices[vertexid]
            self.vertices = vertices
            vertex_to_colour = {}
            for index, vertexid in enumerate(sorted(self.vertex_to_colour)):
                vertex_to_colour[index] = self.vertex_to_colour[vertexid]
            self.vertex_to_colour = vertex_to_colour
            for edge in self.edges:
                if edge[0] >= toremove_id:
                    edge[0] -= 1
                if edge[1] >= toremove_id:
                    edge[1] -= 1

            # The arflayout module keeps the vertex positions from the latest iteration in memory. So we need to notify arflayout.
            arflayout.arf_remove([toremove_id])

    def CalculateLayout(self):
        with self.lock:
            edges = copy.copy(self.edges)
            toInsert = self.toInsert
            self.toInsert = set()

        graph = igraph.Graph(edges, directed=False)
        positions = arflayout.arf_layout(toInsert, graph)

        with self.lock:
            self.step += 1
            for vertexid, pos in positions.iteritems():
                self.SetVertexPosition(vertexid, self.step, *pos)
            self.time_step = 5 + max(0, len(self.vertices) - 75) / 9
            self.last_keyframe = time()
            self.layout_busy = False

    def OnMouse(self, event):
        if event.Moving():
            self.vertex_hover_evt = event.GetPosition()
        elif event.LeftUp():
            self.vertex_active_evt = event.GetPosition()

    def OnSize(self, evt):
        size = min(*evt.GetEventObject().GetSize())
        x = min(size + self.margin_x * 2, self.GetSize().x - self.circuit_list.GetSize().x)
        y = size + self.margin_y * 2
        self.graph_panel.SetSize((x, y))

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        eo = event.GetEventObject()
        dc = wx.BufferedPaintDC(eo)
        dc.Clear()
        gc = wx.GraphicsContext.Create(dc)

        w, h = eo.GetSize().x - 2 * self.radius - 2 * self.margin_x - 1, eo.GetSize().y - 2 * self.radius - 2 * self.margin_y - 1

        schedule_layout = not self.layout_busy and self.new_data and time() - self.last_keyframe >= self.time_step
        if schedule_layout:
            task = lambda : self.CalculateLayout()
            self.taskqueue.add_task(task)
            self.new_data = False
            self.layout_busy = True

        if len(self.vertices) > 0:

            int_points = {}

            with self.lock:

                # Get current vertex positions using interpolation
                for vertexid in self.vertices.iterkeys():
                    if self.GetVertexPosition(vertexid, self.step):
                        if self.GetVertexPosition(vertexid, self.step - 1):
                            scaled_x, scaled_y = self.InterpolateVertexPosition(vertexid, self.step - 1, self.step)
                        else:
                            scaled_x, scaled_y = self.GetVertexPosition(vertexid, self.step)
                        int_points[vertexid] = (scaled_x * w + self.radius + self.margin_x, scaled_y * h + self.radius + self.margin_y)

                # Draw edges
                for vertexid1, vertexid2 in self.edges:
                    if int_points.has_key(vertexid1) and int_points.has_key(vertexid2):
                        if set([vertexid1, vertexid2]) in self.selected_edges:
                            gc.SetPen(wx.Pen(wx.BLUE, self.line_width))
                        else:
                            gc.SetPen(wx.Pen(wx.Colour(229, 229, 229), self.line_width))
                        x1, y1 = int_points[vertexid1]
                        x2, y2 = int_points[vertexid2]
                        gc.DrawLines([(x1, y1), (x2, y2)])

                # Draw vertices
                gc.SetPen(wx.TRANSPARENT_PEN)
                for vertexid in self.vertices.iterkeys():
                    colour = self.vertex_to_colour.get(vertexid, None)
                    if not colour:
                        colour = self.colours[0] if self.peers[vertexid] == self.my_address else random.choice(self.colours[1:])
                        self.vertex_to_colour[vertexid] = colour
                    gc.SetBrush(wx.Brush(colour))

                    if int_points.has_key(vertexid):
                        x, y = int_points[vertexid]
                        gc.DrawEllipse(x - self.radius / 2, y - self.radius / 2, self.radius, self.radius)

                        if len(self.vertices.get(vertexid, {})) <= 2:
                            gc.SetBrush(wx.WHITE_BRUSH)
                            gc.DrawEllipse(x - self.radius / 4, y - self.radius / 4, self.radius / 2, self.radius / 2)

                # Draw circle around active vertex
                gc.SetBrush(wx.TRANSPARENT_BRUSH)

                if self.vertex_hover_evt:
                    self.vertex_hover = self.PositionToVertex(self.vertex_hover_evt, int_points)
                    self.vertex_hover_evt = None

                if self.vertex_hover >= 0:
                    x, y = int_points[self.vertex_hover]
                    pen = wx.Pen(wx.Colour(229, 229, 229), 1, wx.USER_DASH)
                    pen.SetDashes([8, 4])
                    gc.SetPen(pen)
                    gc.DrawEllipse(x - self.radius, y - self.radius, self.radius * 2, self.radius * 2)

                if self.vertex_active_evt:
                    self.vertex_active = self.PositionToVertex(self.vertex_active_evt, int_points)
                    self.vertex_active_evt = None

                if self.vertex_active in int_points:
                    x, y = int_points[self.vertex_active]
                    pen = wx.Pen(self.vertex_to_colour.get(self.vertex_active, wx.BLACK), 1, wx.USER_DASH)
                    pen.SetDashes([8, 4])
                    gc.SetPen(pen)
                    gc.DrawEllipse(x - self.radius, y - self.radius, self.radius * 2, self.radius * 2)

                    if 'UNKNOWN HOST' not in self.peers[self.vertex_active].host:
                        text_height = dc.GetTextExtent('gG')[1]
                        box_height = text_height + 3

                        # Draw status box
                        x = x - 150 - 1.1 * self.radius if x > self.graph_panel.GetSize()[0] / 2 else x + 1.1 * self.radius
                        y = y - box_height - 1.1 * self.radius if y > self.graph_panel.GetSize()[1] / 2 else y + 1.1 * self.radius
                        gc.SetBrush(wx.Brush(wx.Colour(216, 237, 255, 50)))
                        gc.SetPen(wx.Pen(LIST_BLUE))
                        gc.DrawRectangle(x, y, 150, box_height)

                        # Draw status text
                        dc.SetFont(self.GetFont())
                        for index, text in enumerate(['IP %s:%s' % (self.peers[self.vertex_active].host, self.peers[self.vertex_active].port)]):
                            dc.DrawText(text, x + 5, y + index * text_height + 5)

            if self.fullscreen:
                # Draw vertex count
                gc.SetFont(self.GetFont())
                gc.DrawText("|V| = %d" % len(int_points), w - 50, h - 20)

    def PositionToVertex(self, position, key_to_position):
        for vertexid, vposition in key_to_position.iteritems():
            if (position[0] - vposition[0]) ** 2 + (position[1] - vposition[1]) ** 2 < self.radius ** 2:
                return vertexid
        return -1

    def InterpolateVertexPosition(self, vertexid, s1, s2):
        x0, y0 = self.GetVertexPosition(vertexid, s1)
        x1, y1 = self.GetVertexPosition(vertexid, s2)

        t = min(time() - self.last_keyframe, self.time_step)
        t1 = 1.0 / 5 * self.time_step
        t2 = 3.0 / 5 * self.time_step
        t3 = 1.0 / 5 * self.time_step
        x = arflayout.CubicHermiteInterpolate(t1, t2, t3, x0, x1, t)
        y = arflayout.CubicHermiteInterpolate(t1, t2, t3, y0, y1, t)
        return (x, y)

    def GetVertexPosition(self, vertexid, t):
        if self.vertices.has_key(vertexid):
            return self.vertices[vertexid].get(t, None)
        return None

    def SetVertexPosition(self, vertexid, t, x, y):
        if self.vertices.has_key(vertexid):
            self.vertices[vertexid][t] = (x, y)
        else:
            self.vertices[vertexid] = {t: (x, y)}

    def ResetSearchBox(self):
        pass


class ArtworkPanel(wx.Panel):

    def __init__(self, parent):
        wx.Panel.__init__(self, parent)
        self.SetBackgroundColour(wx.WHITE)
        self.SetForegroundColour(parent.GetForegroundColour())

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.OnExpand = lambda *args: None
        self.OnCollapse = lambda *args: None
        self.update_interval = 120
        self.max_torrents = 20

        self.list = ListBody(self, self, [{'width': wx.LIST_AUTOSIZE}], 0, 0, True, False, grid_columns=self.max_torrents, horizontal_scroll=True)
        self.list.SetBackgroundColour(self.GetBackgroundColour())

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(DetailHeader(self, "Start streaming immediately by clicking on one of items below"), 0, wx.EXPAND)
        vSizer.Add(self.list, 1, wx.EXPAND)

        self.SetSizer(vSizer)
        self.Layout()

        startWorker(self.SetData, self.GetData)

    def GetData(self):
        data = []
        torrents = self.guiutility.torrentsearch_manager.getThumbnailTorrents(limit=self.max_torrents)

        for torrent in torrents:
            thumb_path = os.path.join(self.utility.session.get_torrent_collecting_dir(), 'thumbs-%s' % binascii.hexlify(torrent.infohash))
            if os.path.isdir(thumb_path):
                data.append((torrent.infohash, [torrent.name], torrent, ThumbnailListItemNoTorrent))

        return data

    @forceWxThread
    def SetData(self, delayedResult):
        data = delayedResult.get()

        self.list.SetData(data)
        self.list.SetupScrolling()

        if len(data) < self.max_torrents:
            interval = self.update_interval / 2
        else:
            interval = self.update_interval

        startWorker(self.SetData, self.GetData, delay=interval)

########NEW FILE########
__FILENAME__ = list
# Written by Niels Zeilemaker
import sys
import logging
from math import log
from time import time
from colorsys import hsv_to_rgb, rgb_to_hsv
import re
import copy

import wx
from wx.lib.wordwrap import wordwrap
from time import time
from datetime import date, datetime
from colorsys import hsv_to_rgb, rgb_to_hsv

from Tribler.Category.Category import Category
from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr

from Tribler.Core.simpledefs import NTFY_MISC, DLSTATUS_STOPPED, \
    DLSTATUS_STOPPED_ON_ERROR, DLSTATUS_WAITING4HASHCHECK, \
    DLSTATUS_HASHCHECKING
from Tribler.Core.exceptions import NotYetImplementedException
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler

from Tribler.Main.vwxGUI.GuiUtility import GUIUtility, forceWxThread
from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager

from Tribler.Main.vwxGUI import warnWxThread, DEFAULT_BACKGROUND, \
    LIST_GREY, LIST_GREEN, LIST_ORANGE, LIST_DESELECTED, SEPARATOR_GREY, \
    GRADIENT_LGREY, GRADIENT_DGREY, TRIBLER_RED, format_time
from Tribler.Main.vwxGUI.list_header import ListHeader, DownloadFilter, \
    TorrentFilter, ChannelFilter
from Tribler.Main.vwxGUI.list_body import ListBody, FixedListBody
from Tribler.Main.vwxGUI.list_footer import ListFooter
from Tribler.Main.vwxGUI.list_item import ChannelListItem, TorrentListItem, \
    ChannelListItemAssociatedTorrents, ColumnsManager, LibraryListItem, \
    DragItem, ActivityListItem
from Tribler.Main.vwxGUI.list_details import TorrentDetails, ChannelDetails, \
    SearchInfoPanel, LibraryDetails, LibraryInfoPanel, ChannelInfoPanel, \
    ChannelsExpandedPanel, VideoplayerExpandedPanel
from Tribler.Main.vwxGUI.widgets import HorizontalGauge, TorrentStatus, \
    FancyPanel, TransparentStaticBitmap, _set_font, SwarmHealth, LinkStaticText, \
    TransparentText, TagText, BetterText

from Tribler.Main.Utility.GuiDBHandler import startWorker, cancelWorker, GUI_PRI_DISPERSY
from Tribler.Main.Utility.GuiDBTuples import Torrent, CollectedTorrent, \
    ChannelTorrent, Channel


DEBUG_RELEVANCE = False
MAX_REFRESH_PARTIAL = 5


class BaseManager:

    def __init__(self, list):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.list = list
        self.dirtyset = set()
        self.guiutility = GUIUtility.getInstance()

    def Reset(self):
        self.dirtyset.clear()

    def refreshDirty(self):
        if 'COMPLETE_REFRESH' in self.dirtyset or len(self.dirtyset) > MAX_REFRESH_PARTIAL or len(self.dirtyset) == 0:
            if len(self.dirtyset) > 0:
                self.list.MarkForRemoval(self.dirtyset)

            self.refresh()
        else:
            if 'COMPLETE_REFRESH' in self.dirtyset:
                self.dirtyset.remove('COMPLETE_REFRESH')
            self.refresh_partial(self.dirtyset)
            self.list.dirty = False
        self.dirtyset.clear()

    def refresh(self):
        raise NotImplementedError('refresh is not implemented')

    def refresh_partial(self, ids):
        raise NotImplementedError('refresh_partial is not implemented')

    def do_or_schedule_refresh(self, force_refresh=False):
        if self.list.isReady and (self.list.ShouldGuiUpdate() or force_refresh):
            self.refresh()
        else:
            self.dirtyset.add('COMPLETE_REFRESH')
            self.list.dirty = True

    def do_or_schedule_partial(self, ids, force_refresh=False):
        if self.list.isReady and (self.list.ShouldGuiUpdate() or force_refresh):
            if len(ids) > MAX_REFRESH_PARTIAL:
                self.list.RemoveItems(ids)
                self.refresh()
            else:
                self.refresh_partial(ids)
        else:
            self.dirtyset.update(ids)
            self.list.dirty = True


class RemoteSearchManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)
        self.oldkeywords = ''

        self.guiserver = self.guiutility.frame.guiserver
        self.torrentsearch_manager = self.guiutility.torrentsearch_manager
        self.channelsearch_manager = self.guiutility.channelsearch_manager

        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)

        if self.oldkeywords:
            cancelWorker(u"RemoteSearchManager_refresh_%s" % self.oldkeywords)
            cancelWorker(u"RemoteSearchManager_refresh_channel_%s" % self.oldkeywords)

        self.oldkeywords = ''
        self.torrentsearch_manager.oldsearchkeywords = None
        self.data_channels = []

    def SetKeywords(self, keywords):
        if self.oldkeywords != keywords:
            self.list.Reset()
            self.oldkeywords = keywords

    def NewResult(self, keywords):
        if self.oldkeywords == keywords:
            self.list.NewResult()

    def refresh(self, remote=False):
        def db_callback():
            begintime = time()

            keywords = self.oldkeywords

            total_items, nrfiltered, new_items, selected_bundle_mode, data_files, modified_hits = self.torrentsearch_manager.getHitsInCategory()
            total_channels, new_channels, self.data_channels = self.channelsearch_manager.getChannelHits()
            self._logger.debug('RemoteSearchManager: refresh returning results took %s %s', time() - begintime, time())

            return keywords, data_files, total_items, nrfiltered, new_items, total_channels, new_channels, selected_bundle_mode, modified_hits
        delay = 0.5 if remote else 0.0
        workerType = "guiTaskQueue" if remote else "dbThread"
        startWorker(self._on_refresh, db_callback, delay=delay, uId=u"RemoteSearchManager_refresh_%s" % self.oldkeywords, retryOnBusy=True, workerType=workerType, priority=GUI_PRI_DISPERSY)

    def _on_refresh(self, delayedResult):
        keywords, data_files, total_items, nrfiltered, new_items, total_channels, new_channels, selected_bundle_mode, modified_hits = delayedResult.get()

        if keywords == self.oldkeywords:
            self.list.SetSelectedBundleMode(selected_bundle_mode)

            if modified_hits:
                self.list.RemoveItems(modified_hits)

            if new_items or modified_hits:
                self.list.SetData(data_files)
            else:
                self._logger.debug("RemoteSearchManager: not refreshing list, no new items")
        else:
            self._logger.debug("RemoteSearchManager: ignoring old keywords")

    def refresh_channel(self):
        def db_callback():
            [total_channels, new_hits, self.data_channels] = self.channelsearch_manager.getChannelHits()
            return total_channels

        startWorker(self._on_refresh_channel, db_callback, uId=u"RemoteSearchManager_refresh_channel_%s" % self.oldkeywords, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def _on_refresh_channel(self, delayedResult):
        self.list.SetNrChannels(delayedResult.get())

    def refresh_partial(self, infohashes=[], channelids=[]):
        for infohash in infohashes:
            if self.list.HasItem(infohash):
                curTorrent = self.list.GetItem(infohash).original_data
                if isinstance(curTorrent, ChannelTorrent):
                    startWorker(self.list.RefreshDelayedData, self.channelsearch_manager.getTorrentFromChannelTorrentId, cargs=(infohash,), wargs=(curTorrent.channel, curTorrent.channeltorrent_id), retryOnBusy=True, priority=GUI_PRI_DISPERSY)
                else:
                    startWorker(self.list.RefreshDelayedData, self.torrentsearch_manager.getTorrentByInfohash, cargs=(infohash,), wargs=(infohash,), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

        if channelids:
            def do_db():
                return self.channelsearch_manager.getChannels(channelids)

            def do_gui(delayedResult):
                _, newChannels = delayedResult.get()

                for channel in newChannels:
                    id = channel.id
                    if self.list.InList(id):
                        item = self.list.GetItem(id)
                        oldChannel = item.original_data
                        if oldChannel.torrents:
                            channel.torrents = oldChannel.torrents

                    self.list.RefreshData(id, channel)
            startWorker(do_gui, do_db, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def showSearchSuggestions(self, keywords):
        startWorker(self.list._ShowSuggestions, self.torrentsearch_manager.getSearchSuggestion, cargs=(keywords,), wargs=(keywords, 3), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def downloadStarted(self, infohash):
        if self.list.InList(infohash):
            item = self.list.GetItem(infohash)

            torrent_details = item.GetExpandedPanel()
            if torrent_details:
                torrent_details.DownloadStarted()
            else:
                item.DoExpand()

    def torrentUpdated(self, infohash):
        if self.list.InList(infohash):
            self.do_or_schedule_partial([infohash])

    def torrentsUpdated(self, infohashes):
        infohashes = [infohash for infohash in infohashes if self.list.InList(infohash)]
        self.do_or_schedule_partial(infohashes)


class LocalSearchManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)

        self.library_manager = self.guiutility.library_manager
        self.prev_refresh_if = 0

    def refresh(self):
        startWorker(self._on_data, self.library_manager.getHitsInCategory, uId=u"LocalSearchManager_refresh", retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def refresh_partial(self, ids):
        for infohash in ids:
            startWorker(self.list.RefreshDelayedData, self.library_manager.getTorrentFromInfohash, cargs=(infohash,), wargs=(infohash,), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def refresh_if_exists(self, infohashes, force=False):
        def db_call():
            if self.library_manager.exists(infohashes):
                self._logger.info("%s Scheduling a refresh, missing some infohashes in the Library", long(time()))

                self.refresh()
            else:
                self._logger.info("%s Not scheduling a refresh", long(time()))

        diff = time() - self.prev_refresh_if
        if force or diff > 30:
            self.prev_refresh_if = time()

            startWorker(None, db_call, uId=u"LocalSearchManager_refresh_if_exists", retryOnBusy=True, priority=GUI_PRI_DISPERSY)
        else:
            self._logger.info("%s Not scheduling a refresh, update limit %s %s", long(time()), long(time()), long(self.prev_refresh_if))

    def refresh_or_expand(self, infohash):
        if not self.list.InList(infohash):
            def select(delayedResult):
                delayedResult.get()
                self.refresh_or_expand(infohash)

            startWorker(select, self.refresh_partial, wargs=([infohash],), priority=GUI_PRI_DISPERSY)
        else:
            self.list.Select(infohash)

    @forceWxThread
    def _on_data(self, delayedResult):
        total_items, data = delayedResult.get()

        self.list.SetData(data)
        self.list.Layout()

    def torrentUpdated(self, infohash):
        if self.list.InList(infohash):
            self.do_or_schedule_partial([infohash])

    def torrentsUpdated(self, infohashes):
        infohashes = [infohash for infohash in infohashes if self.list.InList(infohash)]
        self.do_or_schedule_partial(infohashes)

    def downloadStarted(self, infohash):
        self.prev_refresh_if = 0
        self.refresh()


class ChannelSearchManager(BaseManager):

    def __init__(self, list):
        BaseManager.__init__(self, list)
        self.category = ''

        self.channelsearch_manager = self.guiutility.channelsearch_manager
        self.Reset()

    def Reset(self):
        BaseManager.Reset(self)
        if self.category:
            cancelWorker(u"ChannelSearchManager_refresh_%s" % self.category)

        self.category = ''
        self.dirtyset.clear()
        self.prev_refresh_if = 0

    def do_or_schedule_refresh(self, force_refresh=False):
        if self.list.isReady and (self.list.ShouldGuiUpdate() or force_refresh):
            diff = time() - self.prev_refresh_if
            if diff > 5 or force_refresh:
                self.prev_refresh_if = time()
                self.refresh()
        else:
            self.dirtyset.add('COMPLETE_REFRESH')
            self.list.dirty = True

    def refreshDirty(self):
        if self.category != 'searchresults' and 'COMPLETE_REFRESH' in self.dirtyset or len(self.dirtyset) > 5:
            self.refresh()
        else:
            if 'COMPLETE_REFRESH' in self.dirtyset:
                self.dirtyset.remove('COMPLETE_REFRESH')

            self.refresh_partial()
            self.list.dirty = False
        self.dirtyset.clear()

    def refresh(self, search_results=None):
        self._logger.debug("ChannelManager complete refresh")

        if self.category != 'searchresults':
            category = self.category

            def db_callback():
                self.list.dirty = False

                data = []
                total_items = 0

                if category == 'New':
                    total_items, data = self.channelsearch_manager.getNewChannels()
                elif category == 'Popular':
                    total_items, data = self.channelsearch_manager.getPopularChannels()
                elif category == 'Updated':
                    total_items, data = self.channelsearch_manager.getUpdatedChannels()
                elif category == 'All':
                    total_items, data = self.channelsearch_manager.getAllChannels()
                elif category == 'Favorites':
                    total_items, data = self.channelsearch_manager.getMySubscriptions()
                elif category == 'Mine':
                    total_items, data = self.channelsearch_manager.getMyChannels()
                return data, category

            startWorker(self._on_data_delayed, db_callback, uId=u"ChannelSearchManager_refresh_%s" % category, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

        else:
            if search_results:
                total_items = len(search_results)
                self._on_data(search_results, self.category)

    def _on_data_delayed(self, delayedResult):
        data, category = delayedResult.get()
        self._on_data(data, category)

    def _on_data(self, data, category):
        if category == self.category:
            if category != 'searchresults':  # if we filter empty channels from search we will never see them
                data = [channel for channel in data if not channel.isEmpty()]

            self.list.SetCategory(category)
            self.list.SetData(data)
            self._logger.debug("ChannelManager complete refresh done")

    def refresh_partial(self, ids=None):
        if ids:
            self.dirtyset.update(ids)

        def do_db():
            ids = list(self.dirtyset)
            self.dirtyset.clear()

            return self.channelsearch_manager.getChannels(ids)

        def do_gui(delayedResult):
            _, newChannels = delayedResult.get()

            for channel in newChannels:
                id = channel.id
                if self.list.InList(id):
                    item = self.list.GetItem(id)
                    oldChannel = item.original_data
                    if oldChannel.torrents:
                        channel.torrents = oldChannel.torrents

                self.list.RefreshData(id, channel)
        startWorker(do_gui, do_db, uId=u"ChannelSearchManager_refresh_partial", retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    def SetCategory(self, category, force_refresh=False):
        if category != self.category:
            self.list.Reset()

            self.category = category
            if category != 'searchresults':
                self.do_or_schedule_refresh(force_refresh)
        else:
            self.list.DeselectAll()

    def channelUpdated(self, id, votecast=False, myvote=False):
        if self.list.isReady:
            # only update when shown
            if self.list.InList(id):
                self.do_or_schedule_partial([id])

            elif self.category in ['All', 'New']:
                # Show new channel, but only if we are not showing search results
                self.do_or_schedule_refresh()

            elif self.category == 'Popular':
                if len(self.list.GetItems()) < 20:
                    self.do_or_schedule_refresh()

            elif self.category == 'Favorites' and myvote:
                self.do_or_schedule_refresh()

            else:
                update = False

                if not votecast:
                    if self.category == 'All':
                        update = True
                    elif self.category == 'Popular':
                        update = len(self.list.GetItems()) < 20
                    else:
                        update = False

                if myvote and self.category == "Favorites":
                    update = True

                if update:
                    self.do_or_schedule_refresh()

    def joinChannel(self, cid):
        self.channelsearch_manager.do_vote_cid(cid, 2)


class List(wx.BoxSizer):

    def __init__(self, columns, background, spacers=[0, 0], singleSelect=False, showChange=False, borders=True, parent=None):
        """
        Column alignment:

        Text should usually be left-aligned, though if there are only a small number of possible values and
        they are all short, then centre alignment can work well.

        Numbers should usually be right-aligned with each other.

        Numbers with decimal points should have the same number of digits to the right of the point. They
        should be right-aligned (so the decimal points are all aligned).

        Numbers are right-aligned to make it easy to visually compare magnitudes. So in cases where the
        magnitude is irrelevant (for example, listing the team numbers of football players) you could consider left- or centre-alignment.
        For the same reason, numbers representing magnitudes should use the same units. For example, Mac OS "helpfully" displays file sizes
        in differing units (kB, MB). This makes it very easy to miss a 3MB file in a listing of 3kB files. If it were listed as 3000kB then it would stand out appropriately.

        Headings often look good if they are aligned the same as their data. You could consider alternatives such as centre-alignment, but
        avoid situations where a column heading is not actually above the data in the column (e.g. a wide column with left-aligned header and right-aligned data).

        taken from: http://uxexchange.com/questions/2249/text-alignment-in-tables-legibility
        """

        self.columns = columns
        self.background = background
        self.spacers = spacers
        self.singleSelect = singleSelect
        self.borders = borders
        self.showChange = showChange
        self.dirty = False
        self.hasData = False
        self.rawfilter = ''
        self.filter = ''

        self.footer = self.header = self.list = None
        self.nr_results = 0
        self.nr_filtered = 0
        self.cur_nr_filtered = 0

        self.guiutility = GUIUtility.getInstance()
        self.uelog = UserEventLogDBHandler.getInstance()
        self.category = Category.getInstance()

        self.leftLine = self.rightLine = None
        self.parent = parent

        wx.BoxSizer.__init__(self, wx.VERTICAL)

        self.isReady = False
        self._PostInit()
        self.isReady = True

        self.guiutility.addList(self)
        self.GotFilter(None)

    def _PostInit(self):
        self.header = self.CreateHeader(self.parent)
        if self.header:
            self.Add(self.header, 0, wx.EXPAND)

        self.list = self.CreateList(self.parent)

        # left and right borders
        if self.borders:
            listSizer = wx.BoxSizer(wx.HORIZONTAL)
            self.leftLine = wx.Panel(self.parent, size=(1, -1))
            self.rightLine = wx.Panel(self.parent, size=(1, -1))

            listSizer.Add(self.leftLine, 0, wx.EXPAND)
            listSizer.Add(self.list, 1, wx.EXPAND)
            listSizer.Add(self.rightLine, 0, wx.EXPAND)
            self.Add(listSizer, 1, wx.EXPAND)
        else:
            self.Add(self.list, 1, wx.EXPAND)

        self.footer = self.CreateFooter(self.parent)
        if self.footer:
            self.Add(self.footer, 0, wx.EXPAND)

        self.SetBackgroundColour(self.background)
        self.Layout()

        self.list.Bind(wx.EVT_SIZE, self.OnSize)

    def CreateHeader(self, parent):
        return ListHeader(parent, self, self.columns)

    def CreateList(self, parent=None, listRateLimit=1):
        if not parent:
            parent = self
        return ListBody(parent, self, self.columns, self.spacers[0], self.spacers[1], self.singleSelect, self.showChange, listRateLimit=listRateLimit)

    def CreateFooter(self, parent):
        return ListFooter(parent)

    def OnSize(self, event):
        assert self.isReady, "List not ready"
        event.Skip()

    def OnSort(self, column, reverse):
        assert self.isReady, "List not ready"
        if self.isReady:
            self.list.OnSort(column, reverse)

    @warnWxThread
    def Reset(self):
        assert self.isReady, "List not ready"

        self.nr_filtered = self.nr_results = 0
        if self.isReady and self.hasData:
            self.rawfilter = ''
            self.filter = ''
            self.hasData = False

            manager = self.GetManager()
            if manager and getattr(manager, 'Reset', False):
                manager.Reset()

            self.list.Reset()

            if self.header:
                self.header.Reset()

            if self.footer:
                self.footer.Reset()

            self.dirty = False
            self.Layout()

            return True
        return False

    @warnWxThread
    def OnExpand(self, item):
        assert self.isReady, "List not ready"

        wx.CallAfter(self.guiutility.frame.top_bg.TorrentsChanged)

    @warnWxThread
    def OnCollapse(self, item, panel, from_expand):
        assert self.isReady, "List not ready"

        if not from_expand:
            self.OnCollapseInternal(item)

            wx.CallAfter(self.guiutility.frame.top_bg.TorrentsChanged)

    def OnCollapseInternal(self, item):
        pass

    def GetManager(self):
        pass

    def do_or_schedule_refresh(self, force_refresh=False):
        self.GetManager().do_or_schedule_refresh(force_refresh=force_refresh)

    @warnWxThread
    def SetDelayedData(self, delayedResult):
        assert self.isReady, "List not ready"
        self.SetData(delayedResult.get())

    @warnWxThread
    def SetData(self, data):
        assert self.isReady, "List not ready"
        self.hasData = True

    @warnWxThread
    def RefreshDelayedData(self, delayedResult, key):
        assert self.isReady, "List not ready"
        data = delayedResult.get()
        if data:
            self.RefreshData(key, data)

    @warnWxThread
    def RefreshData(self, key, data):
        assert self.isReady, "List not ready"

    def RemoveItem(self, key):
        assert self.isReady, "List not ready"
        self.list.RemoveKey(key)

    def RemoveItems(self, keys):
        assert self.isReady, "List not ready"
        self.list.RemoveKeys(keys)

    def MarkForRemoval(self, keys):
        assert self.isReady, "List not ready"
        self.list.MarkForRemoval(keys)

    @warnWxThread
    def SetNrResults(self, nr):
        assert self.isReady, "List not ready"
        self.nr_results = nr

        # ff uses two variables, cur_nr_filtered is used to count the total number in the loop
        # nr_filtered is the total number filtered from the previous run
        self.nr_filtered = self.cur_nr_filtered
        self.cur_nr_filtered = 0

    def GetNrResults(self):
        return self.nr_results

    def InList(self, key, onlyCreated=True):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.InList(key, onlyCreated)

    def HasItem(self, key):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.HasItem(key)

    def GetItem(self, key):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.GetItem(key)

    def GetItems(self):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.items

    def GetItemPos(self, key):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.GetItemPos(key)

    def GetExpandedItem(self):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.GetExpandedItem()

    def GetExpandedItems(self):
        assert self.isReady, "List not ready"
        if self.isReady:
            return self.list.GetExpandedItems()

    @warnWxThread
    def Focus(self):
        assert self.isReady, "List not ready"
        if self.isReady:
            self.list.SetFocusIgnoringChildren()

    @warnWxThread
    def HasFocus(self):
        assert self.isReady, "List not ready"
        focussed = wx.Window.FindFocus()
        return focussed == self.list

    @warnWxThread
    def SetBackgroundColour(self, colour):
        if self.header:
            self.header.SetBackgroundColour(colour)

        if self.leftLine:
            self.leftLine.SetBackgroundColour(colour)

        self.list.SetBackgroundColour(colour)

        if self.rightLine:
            self.rightLine.SetBackgroundColour(colour)

        if self.footer:
            self.footer.SetBackgroundColour(colour)

    @warnWxThread
    def ScrollToEnd(self, scroll_to_end):
        assert self.isReady, "List not ready"
        if self.isReady:
            self.list.ScrollToEnd(scroll_to_end)

    @warnWxThread
    def ScrollToId(self, id):
        assert self.isReady, "List not ready"
        self.list.ScrollToId(id)

    @warnWxThread
    def DeselectAll(self):
        assert self.isReady, "List not ready"
        if self.isReady:
            self.list.DeselectAll()

    @warnWxThread
    def Select(self, key, raise_event=True):
        assert getattr(self, 'list', False), "List not ready"
        if self.isReady:
            self.list.Select(key, raise_event)

    def ShouldGuiUpdate(self):
        if not self.IsShownOnScreen():
            return False
        return self.guiutility.ShouldGuiUpdate()

    def ShowLoading(self):
        if self.isReady:
            self.list.ShowLoading()

    def ShowMessage(self, message, header=None, altControl=None):
        if self.isReady:
            self.list.ShowMessage(message, header, altControl)

    def OnLoadAll(self):
        if self.isReady:
            self.list.OnLoadAll()

    def IsShownOnScreen(self):
        return self.IsShown(0)

    def Freeze(self):
        self.parent.Freeze()

    def Thaw(self):
        self.parent.Thaw()

    def Show(self, show=True, isShown=False):
        self.ShowItems(show)

        if show and (isShown or self.IsShownOnScreen()):
            if self.dirty:
                self.dirty = False

                manager = self.GetManager()
                if manager:
                    manager.refreshDirty()

            self.list.Layout()
        self.list.Show(show)

    def ShowFooter(self, show=True):
        self.footer.Show(show)

    def GotFilter(self, keyword=None):
        oldrawfilter = self.rawfilter
        if keyword != None:
            self.rawfilter = keyword.lower().strip()
        else:
            self.LoadEnabledCategoryIDs()

        if self.rawfilter == '' and not self.guiutility.getFamilyFilter():
            wx.CallAfter(self.list.SetFilter, None, None, keyword == None)

        else:
            highlight = True
            if oldrawfilter[:-1] == self.rawfilter:  # did the user simple remove 1 character?
                highlight = False

            wx.CallAfter(self.list.SetFilter, self.MatchFilter, self.GetFilterMessage, highlight)

        self.OnFilter(self.rawfilter)

    def OnFilter(self, keyword):
        self.filter = keyword
        if keyword:
            self.filter = keyword.strip()
            try:
                re.compile(self.filter)
                self.header.FilterCorrect(True)

            except:  # regex incorrect
                self.filter = ''
                self.header.FilterCorrect(False)

    def LoadEnabledCategoryIDs(self):
        misc_db = self.guiutility.utility.session.open_dbhandler(NTFY_MISC)
        enabled_category_keys = [key.lower() for key, _ in self.category.getCategoryNames()]
        self.enabled_category_ids = set([0, 8])
        for key, id in misc_db._category_name2id_dict.iteritems():
            if key.lower() in enabled_category_keys:
                self.enabled_category_ids.add(id)
        self.deadstatus_id = misc_db.torrentStatusName2Id(u'dead')

    def MatchFFilter(self, item):
        result = True
        if self.guiutility.getFamilyFilter():
            if isinstance(item[2], (Torrent, CollectedTorrent)):
                torrent = item[2]
                category = torrent.category_id if torrent.category_id else 0
                result = category in self.enabled_category_ids

            elif isinstance(item[2], Channel):
                result = not self.category.xxx_filter.isXXX(item[2].name, False)

        if not result:
            self.cur_nr_filtered += 1

        return result

    def GetFFilterMessage(self):
        if self.guiutility.getFamilyFilter() and self.nr_filtered:
            return None, '%d items were blocked by the Familiy filter' % self.nr_filtered
        return None, ''

    def MatchFilter(self, item):
        ff = self.MatchFFilter(item)
        if self.filter == '':
            return ff
        return re.search(self.filter, item[1][0].lower()) and ff

    def GetFilterMessage(self, empty=False):
        if self.rawfilter:
            if empty:
                message = '0 items'
            else:
                message = 'Only showing items'

            if self.filter:
                return None, message + ' matching "%s"' % self.filter
            return None, message
        else:
            return self.GetFFilterMessage()

    @warnWxThread
    def Layout(self):
        return wx.BoxSizer.Layout(self)

    def SetupScrolling(self, *args, **kwargs):
        return self.list.SetupScrolling(*args, **kwargs)


class SizeList(List):

    def __init__(self, columns, background, spacers=[0, 0], singleSelect=False, showChange=False, borders=True, parent=None):
        List.__init__(self, columns, background, spacers, singleSelect, showChange, borders, parent)
        self.prevStates = {}
        self.library_manager = self.guiutility.library_manager

        self.curMax = -1
        self.filteredMax = -1
        self.sizefilter = None

    def OnFilter(self, keyword):
        new_filter = keyword.lower().strip()

        self.sizefilter = None
        if new_filter.find("size=") > -1:
            try:
                minSize = 0
                maxSize = sys.maxsize

                start = new_filter.find("size=") + 5
                end = new_filter.find(" ", start)
                if end == -1:
                    end = len(new_filter)

                sizeStr = new_filter[start:end]
                if sizeStr.find(":") > -1:
                    sizes = sizeStr.split(":")
                    if sizes[0] != '':
                        minSize = int(sizes[0])
                    if sizes[1] != '':
                        maxSize = int(sizes[1])
                else:
                    minSize = maxSize = int(sizeStr)

                self.sizefilter = [minSize, maxSize]
                new_filter = new_filter[:start - 5] + new_filter[end:]
                new_filter = new_filter.rstrip()

            except:
                pass
        List.OnFilter(self, new_filter)

    def MatchFilter(self, item):
        listmf = List.MatchFilter(self, item)

        if listmf:
            length = item[2].get('length', 0)
            self.filteredMax = max(self.filteredMax, length)

            if self.sizefilter:
                size = int(length / 1048576.0)
                if size < self.sizefilter[0] or size > self.sizefilter[1]:
                    return False
        return listmf

    def GetFilterMessage(self, empty=False):
        header, message = List.GetFilterMessage(self, empty)

        if self.sizefilter:
            if self.sizefilter[0] == self.sizefilter[1]:
                message += " equal to %d MB in size" % self.sizefilter[0]
            elif self.sizefilter[0] == 0:
                message += " smaller than %d MB in size" % self.sizefilter[1]
            elif self.sizefilter[1] == sys.maxsize:
                message += " larger than %d MB in size" % self.sizefilter[0]
            else:
                message += " between %d and %d MB in size" % (self.sizefilter[0], self.sizefilter[1])
        return header, message

    def SetData(self, data):
        List.SetData(self, data)

        if getattr(self.header, 'SetSliderMinMax', None):
            # detect min/max size for this data
            minSize = 0
            self.curMax = -1
            for item in data:
                if isinstance(item, tuple) and item and isinstance(item[0], Channel):
                    pass
                else:
                    if 'bundle' in item:
                        item = item['bundle'][0]
                    self.curMax = max(self.curMax, item.length)

    @warnWxThread
    def SetNrResults(self, nr):
        List.SetNrResults(self, nr)

        if getattr(self.header, 'SetSliderMinMax', None):
            if nr != 0:
                self.header.SetSliderMinMax(0, max(0, self.filteredMax) if self.sizefilter or self.guiutility.getFamilyFilter() else max(0, self.curMax))
            self.filteredMax = -1

    @warnWxThread
    def RefreshItems(self, dslist, magnetlist, rawdata=False):
        dsdict = {}
        old_dsdict = {}
        for ds in dslist:
            id = ds.get_download().get_def().get_id()
            dsdict[id] = ds

        curStates = {}
        didStateChange = False

        if rawdata:
            list_data = [(self.list.items.get(getattr(values[2], 'infohash', None), None), values[2]) for values in self.list.raw_data or []]
        else:
            list_data = [(item, item.original_data) for item in self.list.items.itervalues() if item]

        for item, original_data in list_data:
            if isinstance(original_data, Torrent):
                infohash = original_data.infohash
                old_dsdict[infohash] = original_data.ds
                prevState = self.prevStates.get(infohash, (original_data.state, original_data.magnetState))

                original_data.clearDs()

                removekeys = [key for key, ds in dsdict.iteritems() if original_data.addDs(ds)]
                for key in removekeys:
                    del dsdict[key]

                if infohash in magnetlist:
                    original_data.magnetstatus = magnetlist[infohash]
                else:
                    original_data.magnetstatus = None

                if item:  # torrents in raw_data and items are not equal
                    item.original_data.dslist = original_data.dslist
                    item.original_data.magnetstatus = original_data.magnetstatus

                curState = curStates[infohash] = original_data.state, original_data.magnetState
                if curState != prevState:
                    didStateChange = True

                    if item:
                        item.RefreshData([infohash, item.data, item.original_data])

        if didStateChange:
            self.guiutility.frame.top_bg.TorrentsChanged()
        self.prevStates = curStates

        return didStateChange, old_dsdict, dsdict

    def Show(self, show=True, isShown=False):
        List.Show(self, show, isShown)
        if show:
            self.library_manager.add_download_state_callback(self.RefreshItems)
        else:
            self.library_manager.remove_download_state_callback(self.RefreshItems)


class GenericSearchList(SizeList):

    def __init__(self, columns, background, spacers=[0, 0], singleSelect=False, showChange=False, borders=True, parent=None):
        SizeList.__init__(self, columns, background, spacers, singleSelect, showChange, borders, parent)

        self.infohash2key = {}  # bundled infohashes

        gui_image_manager = GuiImageManager.getInstance()

        self.statusDHT = gui_image_manager.getImage(u"status_dht.png")
        self.statusInactive = gui_image_manager.getImage(u"status_inact.png")
        self.statusDownloading = gui_image_manager.getImage(u"status_dl.png")
        self.statusFinished = gui_image_manager.getImage(u"status_fin.png")
        self.statusSeeding = gui_image_manager.getImage(u"status_sd.png")
        self.statusStopped = gui_image_manager.getImage(u"status_stop.png")

        self.favorite = gui_image_manager.getImage(u"starEnabled.png")
        self.normal = gui_image_manager.getImage(u"star.png")

        self.ministar = gui_image_manager.getImage(u"ministarEnabled.png")
        self.normalministar = gui_image_manager.getImage(u"ministar.png")

        self.mychannel = gui_image_manager.getImage(u"mychannel.png")
        self.spam = gui_image_manager.getImage(u"bug.png")
        self.max_votes = 5

    def _status_icon(self, item):
        def handler(event, function):
            self.list.Select(item.original_data.infohash)
            function(event)

        torrent = item.original_data
        if torrent.magnetstatus or "metadata" in torrent.state:
            return self.statusDHT, None, "This torrent being fetched from the DHT"
        elif "checking" in torrent.state:
            return self.statusDownloading, None, "Checking this torrent"
        elif "downloading" in torrent.state:
            return self.statusDownloading, self.statusStopped, "Stop downloading this torrent", lambda evt: handler(evt, self.guiutility.frame.top_bg.OnStop)
        elif "seeding" in torrent.state:
            return self.statusSeeding, self.statusFinished, "Stop seeding this torrent", lambda evt: handler(evt, self.guiutility.frame.top_bg.OnStop)
        elif "completed" in torrent.state:
            return self.statusFinished, self.statusSeeding, "Resume seeding this torrent", lambda evt: handler(evt, self.guiutility.frame.top_bg.OnResume)
        elif "stopped" in torrent.state:
            return self.statusStopped, self.statusDownloading, "Resume downloading this torrent", lambda evt: handler(evt, self.guiutility.frame.top_bg.OnResume)
        else:
            return self.statusInactive, self.statusDownloading, "Start downloading this torrent", lambda evt: handler(evt, self.guiutility.frame.top_bg.OnDownload)

    @warnWxThread
    def CreateDownloadButton(self, parent, item):
        button = wx.Button(parent, -1, 'Download', style=wx.BU_EXACTFIT)
        button.item = item
        item.button = button

        if not item.original_data.get('ds', False):
            button.Bind(wx.EVT_BUTTON, self.OnDownload)
        else:
            button.Enable(False)
        return button

    @warnWxThread
    def CreateRatio(self, parent, item):
        num_seeders, num_leechers, _ = item.original_data.swarminfo
        seeders = int(num_seeders) if num_seeders else 0
        leechers = int(num_leechers) if num_leechers else 0
        item.data[-2] = seeders + leechers

        control = SwarmHealth(parent)
        width = item.columns[-2]['width'] if isinstance(item.columns[-2]['width'], int) else -1
        control.SetMinSize((width, 7))
        control.SetBackgroundColour(DEFAULT_BACKGROUND)
        control.SetRatio(seeders, leechers)
        return control, 3

    @warnWxThread
    def CreateFrom(self, parent, item):
        channel = getattr(item.original_data, 'channel', None)
        from Tribler.Main.vwxGUI.channel import SelectedChannelList
        if channel and not isinstance(item.parent_list.parent_list, SelectedChannelList):
            control = wx.Panel(item)
            control.SetBackgroundColour(item.GetBackgroundColour())
            sizer = wx.BoxSizer(wx.HORIZONTAL)
            if channel.isFavorite():
                sizer.Add(wx.StaticBitmap(control, bitmap=self.favorite), 0, wx.RIGHT, 5)
            sizer.Add(wx.StaticText(control, label=channel.name))
            control.SetSizer(sizer)
            return control, 0
        return None

    @warnWxThread
    def OnDownload(self, event):
        item = event.GetEventObject().item
        key = self.infohash2key.get(item.original_data.infohash, item.original_data.infohash)
        self.Select(key)
        self.StartDownload(item.original_data)

        button = event.GetEventObject()
        button.Enable(False)

    @warnWxThread
    def SetData(self, data):
        from Tribler.Main.vwxGUI.list_bundle import BundleListItem  # solving circular dependency for now

        resetbottomwindow = not bool(self.list.raw_data)

        SizeList.SetData(self, data)
        if len(data) > 0:
            list_data = []
            for item in data:
                if isinstance(item, tuple) and item and isinstance(item[0], Channel):
                    channel, position, isAssociated = item[:3]
                    self.max_votes = max(channel.nr_favorites, self.max_votes)
                    if isAssociated:
                        list_data.append((channel.id, [channel.name, channel.modified, channel.nr_torrents, channel.nr_favorites, item[3]], channel, ChannelListItemAssociatedTorrents, position))
                    else:
                        list_data.append((channel.id, [channel.name, channel.modified, channel.nr_torrents, channel.nr_favorites], channel, ChannelListItem, position))
                else:

                    # either we have a bundle of hits:
                    if 'bundle' in item:
                        head = item['bundle'][0]
                        create_method = BundleListItem
                        key = item['key']

                        for hit in item['bundle']:
                            self.infohash2key[hit.infohash] = key

                        # if the bundle is changed, inform the ListBody
                        if 'bundle_changed' in item:
                            self.RefreshData(key, item)

                    # or a single hit:
                    else:
                        head = item
                        create_method = TorrentListItem
                        key = head.infohash

                        if key in self.infohash2key:
                            del self.infohash2key[key]

                    if DEBUG_RELEVANCE:
                        item_data = ["%s %s" % (head.name, head.relevance_score), head.length, self.category_names[head.category_id], head.num_seeders, head.num_leechers, 0, None]
                    else:
                        item_data = [head.name, head.length, self.category_names[head.category_id], head.num_seeders, head.num_leechers, 0, None]
                    original_data = item

                    list_data.append((key, item_data, original_data, create_method))

            self.list.SetData(list_data)

        else:
            header = 'No torrents matching your query are found.'
            message = 'Try leaving Tribler running for a longer time to allow it to discover new torrents, or use less specific search terms.'

            if self.guiutility.getFamilyFilter():
                message += '\n\nAdditionally, you could disable the "Family filter".'

                def create_suggestion(parentPanel):
                    vSizer = wx.BoxSizer(wx.VERTICAL)
                    ffbutton = LinkStaticText(parentPanel, 'Turn off Family filter', None)
                    ffbutton.Bind(wx.EVT_LEFT_UP, lambda evt: self.guiutility.toggleFamilyFilter(setCheck=True))
                    vSizer.Add(ffbutton)
                    return vSizer

                self.list.ShowMessage(message, header, create_suggestion)
            else:
                self.list.ShowMessage(message, header)
            self.SetNrResults(0)

        if resetbottomwindow:
            self.ResetBottomWindow()

    @warnWxThread
    def RefreshData(self, key, data):
        List.RefreshData(self, key, data)

        if data:
            if isinstance(data, Channel):
                self.max_votes = max(data.nr_favorites, self.max_votes)
                self.list.RefreshData(key, (data.id, [data.name, data.modified, data.nr_torrents, data.nr_favorites, None], data))
                return

            original_data = data
            if 'bundle' in data:  # bundle update
                head = data['bundle'][0]
            else:  # individual hit update
                head = original_data

                # check whether the individual hit is in a bundle
                key = self.infohash2key.get(key, key)

            # we need to merge the dslist from the current item
            prevItem = self.list.GetItem(head.infohash)
            if prevItem.original_data.ds:
                original_data.dslist = prevItem.original_data.dslist

            # Update primary columns with new data
            if DEBUG_RELEVANCE:
                data = (head.infohash, ["%s %s" % (head.name, head.relevance_score), head.length, self.category_names[head.category_id], head.num_seeders, head.num_leechers, 0, None], original_data)
            else:
                data = (head.infohash, [head.name, head.length, self.category_names[head.category_id], head.num_seeders, head.num_leechers, 0, None], original_data)

            self.list.RefreshData(key, data)

    def Reset(self):
        self.infohash2key = {}
        return List.Reset(self)

    @warnWxThread
    def OnExpand(self, item):
        List.OnExpand(self, item)
        if isinstance(item.original_data, Torrent):
            detailspanel = self.guiutility.SetBottomSplitterWindow(TorrentDetails)
            detailspanel.setTorrent(item.original_data)
            item.expandedPanel = detailspanel
        elif isinstance(item.original_data, Channel):
            detailspanel = self.guiutility.SetBottomSplitterWindow(ChannelDetails)
            detailspanel.showChannel(item.original_data)
            item.expandedPanel = detailspanel
        return True

    @warnWxThread
    def OnCollapseInternal(self, item):
        self.ResetActionButtons()
        self.ResetBottomWindow()

    def ResetActionButtons(self):
        self.guiutility.frame.top_bg.ClearButtonHandlers()

    def ResetBottomWindow(self):
        detailspanel = self.guiutility.SetBottomSplitterWindow(SearchInfoPanel)
        detailspanel.Set(len(self.list.raw_data) if self.list.raw_data else 0)

    @forceWxThread
    def StartDownload(self, torrent, files=None):
        from Tribler.Main.vwxGUI.channel import SelectedChannelList
        from list_bundle import BundleListView

        # vliegendhart: Logging relevance ranking stats
        def relevance_ranking_msg():
            infohash = torrent.infohash

            main_searchlist = self.guiutility.frame.searchlist
            header = main_searchlist.header

            bundlestate = main_searchlist.header.bundlestate
            selected_bundle_mode = header.selected_bundle_mode
            bundlestate_str = header.bundlestates_str[bundlestate]
            selected_bundle_mode_str = header.bundlestates_str.get(selected_bundle_mode, None)

            pos_visual = None
            subpos_visual = None
            subpos_hits = None

            if isinstance(self, BundleListView):
                bundlelistitem = main_searchlist.GetItem(infohash)

                pos_visual = main_searchlist.GetItemPos(infohash)
                subpos_visual = self.GetItemPos(infohash)
                try:
                    subpos_hits = bundlelistitem.bundle[1:].index(torrent)
                except:
                    pass
            else:
                pos_visual = self.GetItemPos(infohash)

            hits = self.guiutility.torrentsearch_manager.hits
            try:
                hits_pos = hits.index(torrent)
                hits_old_pos = sorted(hits, key=lambda hit: hit.relevance_score[-1], reverse=True).index(torrent)
            except:
                hits_pos = None
                hits_old_pos = None

            keywords = self.guiutility.torrentsearch_manager.getSearchKeywords()[0]
            query = ' '.join(keywords)

            return \
                'RelevanceRanking: pos/subpos_v/subpos_h: %s/%s/%s; hits_pos: %s; hits_old_pos: %s; bundle: %s/%s [%s/%s]; family: %s; relevance: %s; q=%s' \
            % (pos_visual, subpos_visual, subpos_hits,
               hits_pos, hits_old_pos,
               bundlestate, selected_bundle_mode, bundlestate_str, selected_bundle_mode_str,
               self.guiutility.getFamilyFilter(), torrent.relevance_score, query)

        relevance_msg = relevance_ranking_msg()

        def db_callback():
            if isinstance(self, SelectedChannelList):
                self.uelog.addEvent(message="Torrent: torrent download from channel", type=2)
            elif isinstance(self, BundleListView):
                self.uelog.addEvent(message="Torrent: torrent download from bundle", type=2)
            else:
                self.uelog.addEvent(message="Torrent: torrent download from other", type=2)

            self.uelog.addEvent(message=relevance_msg, type=4)

        startWorker(None, db_callback, retryOnBusy=True)
        return self.guiutility.torrentsearch_manager.downloadTorrent(torrent, selectedFiles=files)

    def InList(self, key):
        key = self.infohash2key.get(key, key)
        return List.InList(self, key)

    def GetItem(self, key):
        key = self.infohash2key.get(key, key)
        return List.GetItem(self, key)

    def GetItemPos(self, key):
        key = self.infohash2key.get(key, key)
        return List.GetItemPos(self, key)

    def format(self, val):
        val = int(val)
        if val < 0:
            return "?"
        return str(val)

    def OnFilter(self, keyword):
        new_filter = keyword.lower().strip()

        self.categoryfilter = None
        if new_filter.find("category=") > -1:
            try:
                start = new_filter.find("category='")
                start = start + 10 if start >= 0 else -1
                end = new_filter.find("'", start)
                if start == -1 or end == -1:
                    category = None
                else:
                    category = new_filter[start:end]

                self.categoryfilter = category
                new_filter = new_filter[:start - 10] + new_filter[end + 1:]
            except:
                pass

        SizeList.OnFilter(self, new_filter)

    def MatchFilter(self, item):
        if isinstance(item[2], Torrent) and (self.categoryfilter and self.categoryfilter not in self.category_names[item[2].category_id].lower()):
            return False

        return SizeList.MatchFilter(self, item)

    def GetFilterMessage(self, empty=False):
        header, message = SizeList.GetFilterMessage(self, empty)

        if self.categoryfilter:
            message = message.rstrip('.')
            message += " matching category '%s'" % self.categoryfilter
        return header, message


class SearchList(GenericSearchList):

    def __init__(self, parent=None):
        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.session = self.guiutility.utility.session
        self.category = Category.getInstance()

        self.total_channels = None
        self.keywords = None
        self.categoryfilter = None
        self.keywords = None
        self.xxx_keywords = False

        columns = [{'name': 'Name', 'sortAsc': True, 'fontSize': 2, 'showColumname': False, 'dlbutton': not self.guiutility.ReadGuiSetting('hide_buttons', True)},
                   {'name': 'Size', 'width': '16em', 'fmt': self.guiutility.utility.size_format},
                   {'name': 'File type', 'width': '24em', 'sortAsc': True},
                   {'name': 'Seeders', 'width': '14em', 'fmt': lambda x: '?' if x < 0 else str(x)},
                   {'name': 'Leechers', 'width': '15em', 'fmt': lambda x: '?' if x < 0 else str(x)},
                   {'name': 'Health', 'width': 100, 'type': 'method', 'method': self.CreateRatio},
                   {'name': 'From', 'width': '25em', 'type': 'method', 'method': self.CreateFrom, 'showEmpty': False}]

        columns = self.guiutility.SetColumnInfo(TorrentListItem, columns, hide_defaults=[3, 4])
        ColumnsManager.getInstance().setColumns(TorrentListItem, columns)
        ColumnsManager.getInstance().setColumns(DragItem, columns)

        misc_db = self.session.open_dbhandler(NTFY_MISC)
        self.category_names = {}
        for key, name in self.category.getCategoryNames(filter=False):
            if key in misc_db._category_name2id_dict:
                self.category_names[misc_db._category_name2id_dict[key]] = name
        self.category_names[8] = 'Other'
        self.category_names[None] = self.category_names[0] = 'Unknown'

        GenericSearchList.__init__(self, None, LIST_GREY, [0, 0], True, parent=parent)

    def _PostInit(self):
        self.header = self.CreateHeader(self.parent)
        self.Add(self.header, 0, wx.EXPAND)

        self.leftLine = wx.Panel(self.parent, size=(1, -1))
        self.rightLine = wx.Panel(self.parent, size=(1, -1))

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(self.leftLine, 0, wx.EXPAND)

        list = wx.Panel(self.parent)
        list.SetForegroundColour(self.parent.GetForegroundColour())

        self.list = self.CreateList(list, listRateLimit=0.5)
        list.OnSort = self.list.OnSort

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(self.list, 1, wx.EXPAND)
        list.SetSizer(vSizer)

        hSizer.Add(list, 1, wx.EXPAND)
        hSizer.Add(self.rightLine, 0, wx.EXPAND)

        self.Add(hSizer, 1, wx.EXPAND)

        self.footer = self.CreateFooter(self.parent)
        self.Add(self.footer, 0, wx.EXPAND)

        self.SetBackgroundColour(self.background)
        self.Layout()

        self.list.Bind(wx.EVT_SIZE, self.OnSize)

    def _special_icon(self, item):
        torrent = item.original_data
        if torrent.hasChannel() and torrent.channel.isFavorite():
            return self.favorite, self.normal, "This torrent is part of one of your favorite channels, %s" % torrent.channel.name
        else:
            return self.normal, self.favorite, "This torrent is not part of one of your favorite channels"

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = RemoteSearchManager(self)
        return self.manager

    @warnWxThread
    def CreateHeader(self, parent):
        return TorrentFilter(parent, self)

    @warnWxThread
    def CreateFooter(self, parent):
        footer = ListFooter(parent, radius=0)
        footer.SetMinSize((-1, 0))
        return footer

    def SetSelectedBundleMode(self, selected_bundle_mode):
        self.header.SetSelectedBundleMode(selected_bundle_mode)

    @warnWxThread
    def SetData(self, torrents):
        # Determine the associated channels
        associated = {}
        for torrent in torrents:
            if torrent.get('channel', False):
                channel = torrent.get('channel')
                if channel.id not in associated:
                    associated[channel.id] = [0, [], channel]
                if channel.nr_favorites > 0 or channel.isFavorite():
                    associated[channel.id][0] += 1
                associated[channel.id][1].append(torrent)

        # Determine the channels results
        results = self.GetManager().data_channels
        results = results if results else {}
        results = dict([(key, result) for key, result in results.iteritems() if result.nr_torrents > 0])
        results_ids = results.keys()
        if results:
            for chid in associated.keys():
                if chid in results_ids:
                    associated.pop(chid)

        # Sorting + filtering..
        associated_torrents = dict([(ch, tr) for _, tr, ch in associated.values()])
        associated = associated.values()
        associated.sort(reverse=True)
        associated = [a[-1] for a in associated]
        results = results.values()
        results.sort(reverse=True, key=lambda x: x.nr_torrents)

        # We need to filter here, as otherwise our top-3 associated channels could only consist of
        # xxx channels, which will be filtered afterwards. Resulting in no channels being shown.
        def channelFilter(channel):
            isXXX = self.category.xxx_filter.isXXX(channel.name, False)
            return not isXXX

        if self.guiutility.getFamilyFilter():
            associated = filter(channelFilter, associated)
            results = filter(channelFilter, results)

        associated = associated[:3]
        results = results[:3]
        channels = results + associated
        for index, channel in enumerate(channels):
            if channel in associated:
                channels[index] = (channel, (index + 1) * 5, True, associated_torrents[channel])
            else:
                channels[index] = (channel, (index + 1) * 5, False)

        self.SetNrChannels(len(channels))
        GenericSearchList.SetData(self, channels + torrents)

    def SetNrResults(self, nr):
        SizeList.SetNrResults(self, nr)

        actitem = self.guiutility.frame.actlist.GetItem(2)
        num_items = getattr(actitem, 'num_items', None)
        if num_items:
            num_items.SetValue(str(nr))
            actitem.hSizer.Layout()

    def SetNrChannels(self, nr_channels):
        self.total_channels = nr_channels

    def GetNrChannels(self):
        return self.total_channels

    def SetKeywords(self, keywords):
        self.GetManager().SetKeywords(keywords)
        self.keywords = keywords

        self.CalcXXXKeywords()

    def CalcXXXKeywords(self):
        if self.keywords and self.guiutility.getFamilyFilter():
            self.xxx_keywords = any(self.category.xxx_filter.isXXX(keyword, False) for keyword in self.keywords)
        else:
            self.xxx_keywords = False

    @warnWxThread
    def ShowSuggestions(self, suggestions):
        if len(suggestions) > 0:
            header, message = self.list.GetMessage()
            message += '\n\nAlternatively your could search for %s' % suggestions[0][0]
            self.list.ShowMessage(message, header=header)

    @forceWxThread
    def SetMaxResults(self, max, keywords):
        self.guiutility.frame.top_bg.ShowSearching(max)
        wx.CallLater(10000, self.SetFinished, keywords)

    @forceWxThread
    def NewResult(self):
        if self.guiutility.frame.top_bg.NewResult():
            self.SetFinished(None)

    def SetFinished(self, keywords):
        curkeywords, hits, filtered = self.guiutility.torrentsearch_manager.getSearchKeywords()
        if not keywords or curkeywords == keywords:
            self.guiutility.frame.top_bg.SetFinished()

            def db_callback(keywords):
                self.uelog.addEvent(message="Search: nothing found for query: " + " ".join(keywords), type=2)
                self.GetManager().showSearchSuggestions(keywords)

            if self.nr_results == 0 and self.nr_filtered == 0:
                startWorker(None, db_callback, wargs=(self.keywords,), retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    @warnWxThread
    def _ShowSuggestions(self, delayedResult, keywords):
        if keywords == self.keywords and self.nr_results == 0 and self.nr_filtered == 0 and not self.xxx_keywords:
            suggestions = delayedResult.get()

            if len(suggestions) > 0:
                def create_suggestion(parentPanel):
                    vSizer = wx.BoxSizer(wx.VERTICAL)
                    vSizer.Add(BetterText(parentPanel, -1, "Alternatively, try one of the following suggestions:"))
                    for suggestion in suggestions:
                        label = LinkStaticText(parentPanel, suggestion)
                        label.Bind(wx.EVT_LEFT_UP, self.OnSearchSuggestion)
                        vSizer.Add(label)

                    return vSizer

                header, message = self.list.GetMessage()
                self.list.ShowMessage(message, header, create_suggestion)

    def OnSearchSuggestion(self, event):
        label = event.GetEventObject()
        self.guiutility.dosearch(label.GetLabel())

    def Reset(self):
        if GenericSearchList.Reset(self):
            self.total_channels = None
            self.keywords = None
            self.xxx_keywords = False
            return True
        return False

    def OnSize(self, event):
        event.Skip()

    def GotFilter(self, keyword=None):
        self.CalcXXXKeywords()

        GenericSearchList.GotFilter(self, keyword)

    def GetFFilterMessage(self):
        if self.xxx_keywords and self.guiutility.getFamilyFilter():
            return 'At least one of the keywords that you used has been blocked by the family filter.', 'If you would still like to see the results, please disable the "Family filter" in the bottom left of your screen.'
        return GenericSearchList.GetFFilterMessage(self)

    def MatchFFilter(self, item):
        if self.xxx_keywords:
            return False

        return GenericSearchList.MatchFFilter(self, item)


class LibraryList(SizeList):

    def __init__(self, parent):
        self.user_download_choice = UserDownloadChoice.get_singleton()
        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility

        self.channelsearch_manager = self.guiutility.channelsearch_manager

        self.statefilter = None
        self.newfilter = False
        self.prevStates = {}
        self.oldDS = {}

        self.bw_history = {}
        self.bw_history_counter = 0

        self.initnumitems = False

        columns = [{'name': 'Name', 'width': wx.LIST_AUTOSIZE, 'sortAsc': True, 'fontSize': 2, 'showColumname': False},
                   {'name': 'Progress', 'type': 'method', 'width': '20em', 'method': self.CreateProgress, 'showColumname': False, 'autoRefresh': False},
                   {'name': 'Size', 'width': '16em', 'fmt': self.guiutility.utility.size_format},
                   {'name': 'ETA', 'width': '13em', 'fmt': self._format_eta, 'sortAsc': True, 'autoRefresh': False},
                   {'name': 'Down speed', 'width': '20em', 'fmt': self.utility.speed_format, 'autoRefresh': False},
                   {'name': 'Up speed', 'width': '20em', 'fmt': self.utility.speed_format, 'autoRefresh': False},
                   {'name': 'Connections', 'width': '15em', 'autoRefresh': False},
                   {'name': 'Ratio', 'width': '15em', 'fmt': self._format_ratio, 'autoRefresh': False},
                   {'name': 'Time seeding', 'width': '25em', 'fmt': self._format_seedingtime, 'autoRefresh': False},
                   {'name': 'Swift ratio', 'width': '15em', 'fmt': self._format_ratio, 'autoRefresh': False},
                   {'name': 'Swift time seeding', 'width': '30em', 'fmt': self._format_seedingtime, 'autoRefresh': False},
                   {'name': 'Anonymous', 'width': '15em', 'autoRefresh': False}]

        columns = self.guiutility.SetColumnInfo(LibraryListItem, columns, hide_defaults=[2, 7, 8, 9, 10])
        ColumnsManager.getInstance().setColumns(LibraryListItem, columns)

        gui_image_manager = GuiImageManager.getInstance()

        self.hasSwift = gui_image_manager.getImage(u"swift.png")
        self.hasTorrent = gui_image_manager.getImage(u"bittorrent.png")
        SizeList.__init__(self, None, LIST_GREY, [0, 0], False, parent=parent)

        self.library_manager.add_download_state_callback(self.RefreshBandwidthHistory)

    def OnDeleteKey(self, event):
        if self.list.GetExpandedItems():
            self.guiutility.frame.top_bg.OnDelete()

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = LocalSearchManager(self)
        return self.manager

    def _format_eta(self, value):
        eta = self.utility.eta_value(value, truncate=2)
        return eta or '-'

    def _format_seedingtime(self, value):
        eta = self.utility.eta_value(value)
        return eta or '0s'

    def _format_ratio(self, value):
        return "%.2f" % value

    def _swift_icon(self, item):
        # Always return icon, toggle icon from RefreshItems
        return self.hasSwift, None, "Using Swift for this download", None, False

    def _torrent_icon(self, item):
        # Always return icon, toggle icon from RefreshItems
        return self.hasTorrent, None, "Using Bittorrent for this download", None, False

    @warnWxThread
    def CreateHeader(self, parent):
        if self.guiutility.frame.top_bg:
            header = DownloadFilter(parent, self)
        else:
            raise NotYetImplementedException('')
#            header = LibraryOnlyHeader(parent, self, self.columns)
#            def showSettings(event):
#                self.guiutility.ShowPage('settings')
#
#            def showChannel(event):
#                self.guiutility.ShowPage('selectedchannel')
#
#            header.SetEvents(self.OnAdd, showSettings, showChannel)
#            header.SetTitle('Downloads')

        return header

    @warnWxThread
    def CreateFooter(self, parent):
        footer = ListFooter(parent, radius=0)
        footer.SetMinSize((-1, 0))
        return footer

    @warnWxThread
    def CreateProgress(self, parent, item):
        progressPanel = TorrentStatus(parent)
        progressPanel.SetMinSize((item.columns[1]['width'], -1))
        item.progressPanel = progressPanel
        return progressPanel

    def OnExpand(self, item):
        List.OnExpand(self, item)
        detailspanel = self.guiutility.SetBottomSplitterWindow(LibraryDetails)
        detailspanel.setTorrent(item.original_data, self.bw_history.get(item.original_data.infohash, []))
        item.expandedPanel = detailspanel
        return True

    def OnCollapseInternal(self, item):
        self.ResetActionButtons()
        self.ResetBottomWindow()

    def ResetActionButtons(self):
        self.guiutility.frame.top_bg.ClearButtonHandlers()

    def ResetBottomWindow(self):
        detailspanel = self.guiutility.SetBottomSplitterWindow(LibraryInfoPanel)
        detailspanel.Set(len(self.list.raw_data) if self.list.raw_data else 0)

    def __ds__eq__(self, ds1, ds2):
        # Exact same objects or both None
        if ds1 == ds2:
            return True

        # Check if one of the two is None
        if not ds1:
            return False
        if not ds2:
            return False

        # Compare status
        if ds1.get_status() != ds2.get_status():
            return False

        # Compare connections
        if ds1.get_num_con_initiated() != ds2.get_num_con_initiated():
            return False
        if ds1.get_num_con_candidates() != ds2.get_num_con_candidates():
            return False

        # Compare current speed
        if ds1.get_current_speed('down') != ds2.get_current_speed('down'):
            return False
        if ds1.get_current_speed('up') != ds2.get_current_speed('up'):
            return False

        # Compare seeding stats
        if ds1.get_seeding_statistics() != ds2.get_seeding_statistics():
            return False

        seeds1, peers1 = ds1.get_num_seeds_peers()
        seeds2, peers2 = ds2.get_num_seeds_peers()
        if seeds1 != seeds2:
            return False
        if peers1 != peers2:
            return False

        ds1progress = long(ds1.get_progress() * 1000) / 1000.0
        ds2progress = long(ds2.get_progress() * 1000) / 1000.0
        if ds1progress != ds2progress:
            return False

        # Compare size
        if ds1.get_length() != ds2.get_length():
            return False

        return True

    @warnWxThread
    def RefreshItems(self, dslist, magnetlist):
        didStateChange, _, newDS = SizeList.RefreshItems(self, dslist, magnetlist, rawdata=True)

        newFilter = self.newfilter
        show_seeding_colours = False
        if self.statefilter == 'active' and self.utility.read_config('t4t_option') == 0:
            show_seeding_colours = True
            t4t_ratio = self.utility.read_config('t4t_ratio') / 100.0

            orange = LIST_ORANGE
            orange = rgb_to_hsv(orange.Red() / 255.0, orange.Green() / 255.0, orange.Blue() / 255.0)

            green = LIST_GREEN
            green = rgb_to_hsv(green.Red() / 255.0, green.Green() / 255.0, green.Blue() / 255.0)

            colourstep = (green[0] - orange[0], green[1] - orange[1], green[2] - orange[2])

        if len(newDS) > 0:
            ids = newDS.keys()
            self.GetManager().refresh_if_exists(ids, force=True)  # new torrent?

        if didStateChange:
            if self.statefilter != None:
                self.list.SetData()  # basically this means execute filter again

        for infohash, item in self.list.items.iteritems():
            ds = item.original_data.ds
            id = ds.get_download().get_def().get_id() if ds else None
            if True or newFilter or not self.__ds__eq__(ds, self.oldDS.get(id, None)):
                if ds and hasattr(item, 'progressPanel'):
                    progress = item.progressPanel.Update(item.original_data)
                    item.data[1] = progress
                else:
                    item.data[1] = -1

                tooltip = ''
                if ds:
                    torrent_ds, swift_ds = item.original_data.dslist

                    # Set Swift seeding time and ratio
                    if swift_ds and swift_ds.get_seeding_statistics():
                        seeding_stats = swift_ds.get_seeding_statistics()
                        dl = seeding_stats['total_down']
                        ul = seeding_stats['total_up']

                        if dl == 0:
                            if ul != 0:
                                ratio = sys.maxsize
                            else:
                                ratio = 0
                        else:
                            ratio = 1.0 * ul / dl

                        item.RefreshColumn(9, ratio)
                        item.RefreshColumn(10, seeding_stats['time_seeding'])

                    # Set torrent seeding time and ratio
                    if torrent_ds and torrent_ds.get_seeding_statistics():
                        seeding_stats = torrent_ds.get_seeding_statistics()
                        dl = seeding_stats['total_down']
                        ul = seeding_stats['total_up']

                        # set dl at min progress*length
                        size_progress = torrent_ds.get_length() * torrent_ds.get_progress()
                        dl = max(dl, size_progress)

                        if dl == 0:
                            if ul != 0:
                                ratio = sys.maxsize
                            else:
                                ratio = 0
                        else:
                            ratio = 1.0 * ul / dl

                        tooltip = "Total transferred: %s down, %s up." % (self.utility.size_format(dl), self.utility.size_format(ul))

                        item.RefreshColumn(7, ratio)
                        item.RefreshColumn(8, seeding_stats['time_seeding'])

                        if show_seeding_colours:
                            # t4t_ratio is goal
                            step = ratio / t4t_ratio
                            step = int(min(1, step) * 5) / 5.0  # rounding to 5 different colours

                            rgbTuple = (c * 255.0 for c in hsv_to_rgb(orange[0] + step * colourstep[0], orange[1] + step * colourstep[1], orange[2] + step * colourstep[2]))
                            bgcolour = wx.Colour(*rgbTuple)
                            item.SetDeselectedColour(bgcolour)
                        else:
                            item.SetDeselectedColour(LIST_DESELECTED)

                item.RefreshColumn(3, ds.get_eta() if ds else None)

                item.RefreshColumn(4, ds.get_current_speed('down') if ds else 0)
                item.SetToolTipColumn(4, tooltip)

                item.RefreshColumn(5, ds.get_current_speed('up') if ds else 0)
                item.SetToolTipColumn(5, tooltip)

                seeds, peers = ds.get_num_seeds_peers() if ds else (0, 0)
                item.RefreshColumn(6, seeds + peers)
                item.SetToolTipColumn(6, "Connected to %d Seeders and %d Leechers." % (seeds, peers) if ds else '')

                item.RefreshColumn(11, 'Yes' if ds and ds.get_download() and ds.get_download().get_anon_mode() else 'No')

                # For updating torrent icons
                torrent_ds, swift_ds = item.original_data.dslist
                torrent_enabled = bool(torrent_ds) and torrent_ds.get_download().get_def().get_def_type() == 'torrent' and \
                                  torrent_ds.get_status() not in [DLSTATUS_WAITING4HASHCHECK, DLSTATUS_HASHCHECKING, DLSTATUS_STOPPED, DLSTATUS_STOPPED_ON_ERROR]
                swift_enabled = bool(swift_ds) and swift_ds.get_download().get_def().get_def_type() == 'swift' and \
                                swift_ds.get_status() not in [DLSTATUS_WAITING4HASHCHECK, DLSTATUS_HASHCHECKING, DLSTATUS_STOPPED, DLSTATUS_STOPPED_ON_ERROR]
                item.icons[0].Show(torrent_enabled)
                item.icons[1].Show(swift_enabled)

                self.oldDS[infohash] = ds

        if newFilter:
            self.newfilter = False

        # Clean old downloadstates
        for infohash in set(self.oldDS.iterkeys()) - set(self.list.items.iterkeys()):
            self.oldDS.pop(infohash)

    @warnWxThread
    def RefreshBandwidthHistory(self, dslist, magnetlist):
        for item in self.list.items.itervalues():
            # Store bandwidth history in self.bw_history
            self.bw_history_counter += 1
            if self.bw_history_counter % 5 == 0:
                ds = item.original_data.ds
                self.bw_history[item.original_data.infohash] = self.bw_history.get(item.original_data.infohash, [])
                self.bw_history[item.original_data.infohash].append((ds.get_current_speed('up') if ds else 0, ds.get_current_speed('down') if ds else 0))
                self.bw_history[item.original_data.infohash] = self.bw_history[item.original_data.infohash][-120:]


    @warnWxThread
    def SetData(self, data):
        SizeList.SetData(self, data)

        if len(data) > 0:
            data = [(file.infohash, [file.name, None, file.length, None, None, None, 0, 0, 0, 0, 0, ''], file, LibraryListItem) for file in data]
        else:
            header = "Currently not downloading or uploading any torrents."
            message = "Torrents can be found using our integrated search or using channels.\n"
            message += "Additionally you could add any torrent file downloaded from an external source by using the '+ Add' button or dropping it here."
            self.list.ShowMessage(message, header=header)
            self.SetNrResults(0)

        self.list.SetData(data)

    @warnWxThread
    def RefreshData(self, key, data):
        List.RefreshData(self, key, data)

        data = (data.infohash, [data.name, None, data.length, None, None, None, 0, 0, 0, 0, 0, ''], data)
        self.list.RefreshData(key, data)

    def SetNrResults(self, nr):
        highlight = nr > self.nr_results and self.initnumitems
        SizeList.SetNrResults(self, nr)

        actitem = self.guiutility.frame.actlist.GetItem(4)
        num_items = getattr(actitem, 'num_items', None)
        if num_items:
            num_items.SetValue(str(nr))
            actitem.hSizer.Layout()
            if highlight:
                actitem.Highlight()
            self.initnumitems = True

    @warnWxThread
    def OnFilter(self, keyword):
        self.statefilter = None
        if keyword:
            new_filter = keyword.lower().strip()

            if new_filter.find("state=") > -1:
                try:
                    start = new_filter.find("state=") + 6
                    end = new_filter.find(" ", start)
                    if end == -1:
                        end = len(new_filter)

                    state = new_filter[start:end]
                    if state in ['completed', 'active', 'stopped', 'checking', 'seeding', 'downloading']:
                        self.statefilter = state
                        self.newfilter = True

                        new_filter = new_filter[:start - 6] + new_filter[end:]
                except:
                    pass

            SizeList.OnFilter(self, new_filter)
        else:
            SizeList.OnFilter(self, keyword)

    def MatchFilter(self, item):
        if self.statefilter:
            if self.statefilter not in item[2].state:
                return False
            elif self.statefilter == 'stopped' and 'completed' in item[2].state:
                return False
            elif self.statefilter == 'completed' and 'seeding' in item[2].state:
                return False

        return SizeList.MatchFilter(self, item)

    def MatchFFilter(self, item):
        return True

    def GetFilterMessage(self, empty=False):
        header, message = SizeList.GetFilterMessage(self, empty)

        if self.statefilter:
            message += " with state %s" % self.statefilter
            if self.statefilter == 'active'and self.utility.read_config('t4t_option') == 0:
                t4t_ratio = self.utility.read_config('t4t_ratio') / 100.0
                message += ".\nColours represent the upload/download ratio. Starting at orange, the colour will change into green when approaching a upload/download ratio of %.1f" % t4t_ratio
        return header, message


class ChannelList(List):

    def __init__(self, parent):
        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility

        columns = [{'name': 'Name', 'sortAsc': True, 'fontSize': 2, 'showColumname': False},
                   {'name': 'Latest Update', 'width': '27em', 'fmt': format_time},
                   {'name': 'Torrents', 'width': '13em'},
                   {'type': 'method', 'width': '20em', 'method': self.CreatePopularity, 'name': 'Popularity', 'defaultSorted': True}]

        columns = self.guiutility.SetColumnInfo(ChannelListItem, columns)
        ColumnsManager.getInstance().setColumns(ChannelListItem, columns)

        columns = [copy.copy(column) for column in columns]
        columns.append({'name': 'Associated torrents', 'width': '25em', 'fmt': lambda x: str(len(x)), 'autoRefresh': False})
        columns = self.guiutility.SetColumnInfo(ChannelListItemAssociatedTorrents, columns)
        ColumnsManager.getInstance().setColumns(ChannelListItemAssociatedTorrents, columns)

        gui_image_manager = GuiImageManager.getInstance()

        self.favorite = gui_image_manager.getImage(u"starEnabled.png")
        self.normal = gui_image_manager.getImage(u"star.png")
        self.mychannel = gui_image_manager.getImage(u"mychannel.png")
        self.spam = gui_image_manager.getImage(u"bug.png")
        self.ministar = gui_image_manager.getImage(u"ministarEnabled.png")
        self.normalministar = gui_image_manager.getImage(u"ministar.png")

        self.select_popular = True
        self.max_votes = 5
        List.__init__(self, None, LIST_GREY, [0, 0], True, parent=parent)

    def _special_icon(self, item):
        channel = item.original_data
        if channel.isMyChannel():
            return self.mychannel, None, ''
        elif channel.isFavorite():
            return self.favorite, self.normal, 'Remove from favourites', lambda evt, data = item.original_data: self.guiutility.RemoveFavorite(evt, data)
        elif channel.isSpam():
            return self.spam, None, ''
        else:
            return self.normal, self.favorite, 'Favourite this channel', lambda evt, data = item.original_data: self.guiutility.MarkAsFavorite(evt, data)

    def __format(self, val):
        val = int(val)
        if val <= 0:
            return "New"
        return str(val)

    @warnWxThread
    def CreateHeader(self, parent):
        return ChannelFilter(parent, self)

    @warnWxThread
    def CreateFooter(self, parent):
        footer = ListFooter(parent, radius=0)
        footer.SetMinSize((-1, 0))
        return footer

    def SetCategory(self, category):
        if category == "Favorites":
            self.header.AddButton("Add Favorite channel", self.OnAdd)
        else:
            self.header.AddButton('', None)

    @warnWxThread
    def CreatePopularity(self, parent, item):
        pop = item.original_data.nr_favorites
        if pop <= 0:
            ratio = wx.StaticText(parent, -1, "New",)
            return ratio

        max = log(self.max_votes)
        cur = log(pop + 1)
        ratio = min(1, cur / max)
        ratio = int(item.columns[3]['width'] * ratio) / float(item.columns[3]['width'])
        prev_ratio = getattr(item, 'prev_ratio', None)

        if ratio != prev_ratio:  # if not enough difference don't return the control
            item.prev_ratio = ratio

            control = HorizontalGauge(parent, self.normalministar, self.ministar, 5)
            control.SetBackgroundColour(DEFAULT_BACKGROUND)
            # control.SetMinSize((50,10))
            control.SetPercentage(ratio)
            control.SetToolTipString('%s users marked this channel as one of their favorites.' % pop)
            return control

    def OnExpand(self, item):
        List.OnExpand(self, item)
        detailspanel = self.guiutility.SetBottomSplitterWindow(ChannelDetails)
        detailspanel.showChannel(item.original_data)
        item.expandedPanel = detailspanel
        return True

    def OnCollapseInternal(self, item):
        self.ResetActionButtons()
        self.ResetBottomWindow()

    def ResetActionButtons(self):
        self.guiutility.frame.top_bg.ClearButtonHandlers()

    def ResetBottomWindow(self):
        detailspanel = self.guiutility.SetBottomSplitterWindow(ChannelInfoPanel)
        detailspanel.Set(len(self.list.raw_data) if self.list.raw_data else 1, self.GetManager().category == "Favorites")

    def OnAdd(self, event):
        dlg = wx.TextEntryDialog(None, 'Please specify the channel-identifier.\nThis should be a 40 character string which can be found in the overview tab of the channel management interface.\n\nJoining a channel can take up to 1 minute and should appear in the all channellist.', 'Enter channel-identifier')
        if dlg.ShowModal() == wx.ID_OK:
            cid = dlg.GetValue()
            cid = cid.decode("hex")

            self.GetManager().joinChannel(cid)

        dlg.Destroy()

    def GetManager(self):
        if getattr(self, 'manager', None) == None:
            self.manager = ChannelSearchManager(self)
        return self.manager

    def SetData(self, data):
        List.SetData(self, data)

        if len(data) > 0:
            max_votes = max([channel.nr_favorites for channel in data])
            if max_votes > self.max_votes:
                self.max_votes = max_votes

            data = [(channel.id, [channel.name, channel.modified, channel.nr_torrents, channel.nr_favorites], channel, ChannelListItem) for channel in data]
            self.list.SetData(data)
        else:
            self.list.ShowMessage('No channels are discovered for this category.')
            self.SetNrResults(0)

    def RefreshData(self, key, data):
        List.RefreshData(self, key, data)

        data = (data.id, [data.name, data.modified, data.nr_torrents, data.nr_favorites], data)
        self.list.RefreshData(key, data)

    def SetNrResults(self, nr):
        List.SetNrResults(self, nr)

        actitem = self.guiutility.frame.actlist.GetItem(3)
        chcat = actitem.expandedPanel.channel_category if actitem.expandedPanel else None
        if chcat and chcat != 'All':
            return
        num_items = getattr(actitem, 'num_items', None)
        if num_items:
            num_items.SetValue(str(nr))
            actitem.hSizer.Layout()

    def SetMyChannelId(self, channel_id):
        self.GetManager().refresh_partial((channel_id,))


class ActivitiesList(List):

    def __init__(self, parent):
        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.settings = {}
        self.expandedPanel_channels = None
        self.expandedPanel_videoplayer = None
        self.notifyTimer = None
        columns = [{'width': wx.LIST_AUTOSIZE}]
        List.__init__(self, columns, wx.WHITE, [10, 10], True, parent=parent)

    def _PostInit(self):
        self.list = self.CreateList(self.parent)
        self.Add(self.list, 0, wx.EXPAND)

        self.notifyPanel = FancyPanel(self.parent, radius=5, border=wx.ALL)
        self.notifyPanel.SetBorderColour(SEPARATOR_GREY)
        self.notifyPanel.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)
        self.notifyPanel.SetForegroundColour(wx.Colour(80, 80, 80))
        self.notifyIcon = TransparentStaticBitmap(self.notifyPanel, -1)
        self.notify = TransparentText(self.notifyPanel)
        _set_font(self.notify, fontweight=wx.FONTWEIGHT_NORMAL, size_increment=0)

        notifySizer = wx.BoxSizer(wx.HORIZONTAL)
        notifySizer.Add(self.notifyIcon, 0, wx.ALIGN_CENTER_VERTICAL | wx.ALL, 5)
        notifySizer.Add(self.notify, 1, wx.ALIGN_CENTER_VERTICAL | wx.ALL, 5)
        self.notifyPanel.SetSizer(notifySizer)
        self.notifyPanel.Hide()

        self.AddStretchSpacer()
        self.Add(self.notifyPanel, 0, wx.EXPAND | wx.ALIGN_BOTTOM | wx.LEFT | wx.RIGHT | wx.BOTTOM, 5)

        self.SetBackgroundColour(self.background)
        self.Layout()
        self.guiutility.frame.Bind(wx.EVT_SIZE, self.OnSize)
        _set_font(self.list, size_increment=2)
        wx.CallAfter(self.__SetData)

    def __SetData(self):
        self.list.SetData([(1, ['Home'], None, ActivityListItem), (2, ['Results'], None, ActivityListItem), (3, ['Channels'], None, ActivityListItem),
                           (4, ['Downloads'], None, ActivityListItem), (5, ['Videoplayer'], None, ActivityListItem)])
        self.ResizeListItems()
        self.DisableItem(2)
        if not self.guiutility.frame.videoparentpanel:
            self.DisableItem(6)
        self.DisableCollapse()
        self.selectTab('home')

        # Create expanded panels in advance
        channels_item = self.list.GetItem(3)
        self.expandedPanel_channels = ChannelsExpandedPanel(channels_item)
        channels_item.AddEvents(self.expandedPanel_channels)
        self.expandedPanel_channels.Hide()

        videoplayer_item = self.list.GetItem(5)
        self.expandedPanel_videoplayer = VideoplayerExpandedPanel(videoplayer_item)
        videoplayer_item.AddEvents(self.expandedPanel_videoplayer)
        self.expandedPanel_videoplayer.Hide()

    def do_or_schedule_refresh(self, force_refresh=False):
        pass

    def OnSize(self, event):
        if self.expandedPanel_videoplayer:
            self.expandedPanel_videoplayer.OnChange()
        event.Skip()

    def GotFilter(self, filter):
        pass

    def CreateList(self, parent):
        flb = FixedListBody(parent, self, self.columns, self.spacers[0], self.spacers[1], self.singleSelect)
        flb.listpanel.SetBackgroundColour(self.background)
        flb.SetStyle(list_expanded=None)
        return flb

    def DisableItem(self, index):
        if self.settings.get(index, None):
            return
        item = self.list.items[index]
        num_items = getattr(item, 'num_items', None)
        if num_items:
            num_items.Show(False)
            item.hSizer.Layout()
        for child in item.GetChildren():
            if not isinstance(child, TagText):
                _set_font(child, fontweight=wx.FONTWEIGHT_NORMAL, fontcolour=wx.Colour(160, 160, 160))
        self.settings[index] = (item.list_deselected, item.list_selected, item.OnClick)
        item.list_deselected = wx.WHITE
        item.list_selected = wx.WHITE
        item.ShowSelected()
        item.OnClick = lambda evt: None

    def EnableItem(self, index):
        if not self.settings.get(index, None):
            return
        item = self.list.items[index]
        num_items = getattr(item, 'num_items', None)
        if num_items:
            num_items.Show(True)
            item.hSizer.Layout()
        item.list_deselected, item.list_selected, item.OnClick = self.settings[index]
        item.ShowSelected()
        self.settings.pop(index)

    def DisableCollapse(self):
        # Ensure that items from the menu cannot be deselected by double-clicking.
        for item in self.list.items.values():
            item.DoCollapse = lambda raise_events = True: None

    def ResizeListItems(self):
        for item in self.list.items.values():
            item.vSizer.Detach(item.hSizer)
            item.vSizer.Add(item.hSizer, 0, wx.EXPAND | wx.TOP | wx.BOTTOM, 5)

    def OnExpand(self, item):
        for child in item.GetChildren():
            if not isinstance(child, TagText):
                _set_font(child, fontweight=wx.FONTWEIGHT_NORMAL, fontcolour=TRIBLER_RED)
        wx.CallAfter(self.Layout)
        if item.data[0] == 'Home':
            self.guiutility.ShowPage('home')
        elif item.data[0] == 'Results':
            self.guiutility.ShowPage('search_results')
        elif item.data[0] == 'Channels':
            if self.guiutility.guiPage not in ['channels', 'selectedchannel', 'mychannel']:
                self.guiutility.ShowPage('channels')
            return self.expandedPanel_channels
        elif item.data[0] == 'Downloads':
            self.guiutility.ShowPage('my_files')
        elif item.data[0] == 'Videoplayer':
            if self.guiutility.guiPage not in ['videoplayer']:
                self.guiutility.ShowPage('videoplayer')
            return self.expandedPanel_videoplayer
        return True

    def OnCollapse(self, item, panel, from_expand):
        List.OnCollapse(self, item, panel, False)

    def OnCollapseInternal(self, item):
        for child in item.GetChildren():
            if not isinstance(child, TagText):
                _set_font(child, fontweight=wx.FONTWEIGHT_NORMAL, fontcolour=item.GetForegroundColour())
        List.OnCollapseInternal(self, item)
        self.list.OnChange()
        self.list.Refresh()

    @forceWxThread
    def Notify(self, msg, icon=None):
        if self.notifyTimer:
            self.notifyTimer.Stop()
            self.notifyTimer = None

        if isinstance(icon, wx.Bitmap):
            self.notifyIcon.Show()
            self.notifyIcon.SetBitmap(icon)
        else:
            self.notifyIcon.Hide()

        self.notifyPanel.Show()
        self.notifyPanel.Layout()
        self.Layout()
        cdc = wx.ClientDC(self.notify)
        cdc.SetFont(self.notify.GetFont())
        wrapped_msg = wordwrap(msg, self.notify.GetSize()[0], cdc, breakLongWords=True, margin=0)
        self.notify.SetLabel(wrapped_msg)
        self.notify.SetSize(self.notify.GetBestSize())
        # NotifyLabel size changed, thus call Layout again
        self.Layout()
        self.Freeze()
        self.Thaw()

        self.notifyTimer = wx.CallLater(5000, self.HideNotify)

    def HideNotify(self):
        if self.notifyPanel.GetScreenRect().Contains(wx.GetMousePosition()):
            self.notifyTimer = wx.CallLater(1000, self.HideNotify)
        else:
            def DoHide():
                self.notifyPanel.Hide()
                self.Layout()
            self.notifyTimer = None
            wx.CallLater(500, DoHide)

    def selectTab(self, tab):
        itemKey = 0
        if tab == 'home':
            itemKey = 1
        elif tab == 'search_results':
            itemKey = 2
            self.EnableItem(2)
        elif tab in ['channels', 'selectedchannel', 'mychannel']:
            itemKey = 3
        elif tab == 'my_files':
            itemKey = 4
        elif tab == 'videoplayer':
            itemKey = 5
        if itemKey:
            wx.CallAfter(self.Select, itemKey, True)
        return

    def NextPage(self):
        self._DoPage(1)

    def PrevPage(self):
        self._DoPage(-1)

    def _DoPage(self, increment):
        pages = [self.list.items[k].expanded for k in range(1, len(self.list.items) + 1)]
        for i in self.settings.keys():
            pages.pop(i - 1)

        curPage = pages.index(True)
        curPage = (curPage + increment) % len(pages)
        if curPage < 0:
            curPage = len(pages) - 1

        pageNames = ['home', 'search_results', 'channels', 'my_files', 'videoplayer']
        for i in self.settings.keys():
            pageNames.pop(i - 1)
        self.guiutility.ShowPage(pageNames[curPage])

########NEW FILE########
__FILENAME__ = list_body
# Written by Niels Zeilemaker
import wx
import wx.lib.scrolledpanel as scrolled
from wx._core import PyDeadObjectError

from _abcoll import Iterable

import sys
import logging
from traceback import print_exc
from time import time

from Tribler.Main.vwxGUI import warnWxThread, LIST_SELECTED, LIST_EXPANDED, \
    LIST_DARKBLUE, LIST_DESELECTED, DEFAULT_BACKGROUND, LIST_ITEM_BATCH_SIZE, \
    LIST_AUTOSIZEHEADER, LIST_HIGHTLIGHT, LIST_RATE_LIMIT, LIST_ITEM_MAX_SIZE
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.widgets import BetterText as StaticText, \
    _set_font, ActionButton


class ListItem(wx.Panel):

    @warnWxThread
    def __init__(self, parent, parent_list, columns, data, original_data, leftSpacer=0, rightSpacer=0, showChange=False, list_selected=LIST_SELECTED, list_expanded=LIST_EXPANDED, list_selected_and_expanded=LIST_DARKBLUE):
        wx.Panel.__init__(self, parent)

        self._logger = logging.getLogger(self.__class__.__name__)

        self.parent_list = parent_list
        from Tribler.Main.vwxGUI.list_item import ColumnsManager
        self.columns = columns if columns != None else ColumnsManager.getInstance().getColumns(self.__class__)
        self.data = data
        self.original_data = original_data

        self.showChange = showChange
        self.list_deselected = LIST_DESELECTED
        self.list_selected = list_selected
        self.list_expanded = list_expanded
        self.list_selected_and_expanded = list_selected_and_expanded

        self.highlightTimer = None
        self.selected = False
        self.expanded = False
        self.expandedPanel = None
        self.SetBackgroundColour(self.list_deselected)
        self.SetForegroundColour(parent_list.GetForegroundColour())
        self.SetFont(parent_list.GetFont())

        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.hSizer = wx.BoxSizer(wx.HORIZONTAL)

        self.controls = []
        self.AddComponents(leftSpacer, rightSpacer)

        self.vSizer.Add(self.hSizer, 0, wx.EXPAND)
        self.SetSizer(self.vSizer)

    @warnWxThread
    def AddComponents(self, leftSpacer, rightSpacer):
        if leftSpacer > 0:
            self.hSizer.AddSpacer((leftSpacer, -1))

        for i in xrange(len(self.columns)):
            if self.columns[i].get('show', True):
                width = self.columns[i].get('width', wx.LIST_AUTOSIZE)
                if isinstance(width, basestring) and width.endswith('em'):
                    test_string = 'T' * int(self.columns[i]['width'][:-2])
                    width = self.GetTextExtent(test_string)[0]
                    self.columns[i]['width'] = width

                if width == wx.LIST_AUTOSIZE:
                    option = 1
                    size = wx.DefaultSize
                else:
                    option = 0
                    size = (self.columns[i]['width'], -1)

                control = None
                remaining_width = size[0]
                addColumnname = self.columns[i].get('showColumname', True) and self.columns[i].get('name', False)
                type = self.columns[i].get('type', 'label')
                if type == 'label':
                    if self.data[i] or self.columns[i].get('showEmpty', True):
                        str_data = self.columns[i].get('fmt', unicode)(self.data[i])

                        prefix = self.columns[i]['name'] + ": " if addColumnname else ''
                        str_data = prefix + str_data

                        control = StaticText(self, style=self.columns[i].get('style', 0) | wx.ST_NO_AUTORESIZE | wx.ST_DOTS_END, size=size)

                        fontWeight = self.columns[i].get('fontWeight', wx.FONTWEIGHT_NORMAL)
                        fontSize = self.columns[i].get('fontSize', 0)
                        if fontWeight != wx.FONTWEIGHT_NORMAL or fontSize:
                            _set_font(control, size_increment=fontSize, fontweight=fontWeight)

                        # niels: wx magic prevents us from passing this string with the constructor, ampersands will not work
                        control.SetLabel(str_data.replace('&', "&&"))

                else:
                    method_control = self.columns[i]['method'](self, self) if type == 'method' else None
                    if method_control or self.columns[i].get('showEmpty', True):
                        if addColumnname:
                            control = StaticText(self, -1, self.columns[i]['name'] + ": ", style=self.columns[i].get('style', 0) | wx.ST_NO_AUTORESIZE | wx.ST_DOTS_END)
                            self._add_control(control, -1, 0, 0)
                            remaining_width -= control.GetSize()[0]
                    control = method_control or control

                spacing = 0
                if isinstance(control, Iterable):
                    control, spacing = control

                self.controls.append(control)
                self.columns[i]['controlindex'] = len(self.controls) - 1

                if control:
                    control.icon = self._get_icon(i, 'icon')
                    control.icon_right = self._get_icon(i, 'icon_right')

                    if remaining_width != size[0]:
                        control.SetMinSize((remaining_width, control.GetMinSize()[1]))

                    self._add_control(control, i, option, spacing)

                    if width == wx.LIST_AUTOSIZE:
                        control.SetMinSize((1, -1))

                    elif width == LIST_AUTOSIZEHEADER:
                        self.columns[i]['width'] = control.GetSize()[0]
                        if self.parent_list.parent_list.header:
                            self.parent_list.parent_list.header.ResizeColumn(i, self.columns[i]['width'])
                        else:
                            if width != LIST_AUTOSIZEHEADER:
                                self.hSizer.Add((width, -1), 0, wx.LEFT, 3)

        if rightSpacer > 0:
            self.hSizer.AddSpacer((rightSpacer, -1))
        self.hSizer.Layout()

        self.AddEvents(self)

    def _add_control(self, control, column_index, option, spacing):
        if column_index != 0:
            self.hSizer.AddSpacer((3, -1))

        if getattr(control, 'icon', None):
            self.hSizer.Add(control.icon, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 3)

        self.hSizer.Add(control, option, wx.RESERVE_SPACE_EVEN_IF_HIDDEN | wx.ALIGN_CENTER_VERTICAL | wx.TOP | wx.BOTTOM, 3 + spacing)

        if getattr(control, 'icon_right', None):
            self.hSizer.Add(control.icon_right, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 3)

    def _replace_control(self, old_index, newcontrol):
        oldcontrol = self.controls[old_index]
        self.hSizer.Replace(oldcontrol, newcontrol)
        self.hSizer.Detach(oldcontrol)

        if isinstance(oldcontrol, wx.Sizer):
            oldcontrol.ShowItems(False)
            oldcontrol.DeleteWindows()
            oldcontrol.Destroy()
        else:
            oldcontrol.Show(False)
            oldcontrol.Destroy()

    def _get_icon(self, column, name="icon", staticbitmap=None):
        icon = None
        if self.columns[column].get(name, False):
            if self.columns[column][name] == 'checkbox' or self.columns[column][name] == 'tree':
                if staticbitmap:
                    staticbitmap.SetBitmap(self.GetIcon(self.columns[column][name], LIST_DESELECTED, 0))
                    staticbitmap.Refresh()
                    icon = staticbitmap
                else:
                    icon = wx.StaticBitmap(self, -1, self.GetIcon(self.columns[column][name], LIST_DESELECTED, 0))
                icon.type = self.columns[column][name]

            else:
                icon = self.columns[column][name](self)
                if icon:
                    tooltip = None
                    if isinstance(icon, tuple):
                        icon, tooltip = icon

                    if staticbitmap:
                        staticbitmap.SetBitmap(icon)
                        staticbitmap.Refresh()
                        icon = staticbitmap
                    else:
                        icon = wx.StaticBitmap(self, -1, icon)
                    icon.type = None

                    if tooltip:
                        icon.SetToolTipString(tooltip)
        return icon

    @warnWxThread
    def AddEvents(self, control):
        if getattr(control, 'GetWindow', False):  # convert sizeritems
            control = control.GetWindow() or control.GetSizer()

        if getattr(control, 'Bind', False):
            if not isinstance(control, (wx.Button, ActionButton, wx.StaticLine)):
                control.Bind(wx.EVT_MOUSE_EVENTS, self.OnMouse)
                control.SetCursor(wx.StockCursor(wx.CURSOR_HAND))
            else:
                control.Bind(wx.EVT_ENTER_WINDOW, self.OnMouse)
                control.Bind(wx.EVT_LEAVE_WINDOW, self.OnMouse)

        func = getattr(control, 'GetChildren', False)
        if func:
            for child in func():
                self.AddEvents(child)

    @warnWxThread
    def GetIcon(self, icontype, background, state):
        return GuiImageManager.getInstance().getBitmap(self, icontype, background, state)

    @warnWxThread
    def RefreshData(self, data):
        self._logger.debug("LISTITEM: refreshdata")

        if isinstance(data[2], dict):  # update original_data
            for key in data[2].keys():
                self.original_data[key] = data[2][key]
        else:
            self.original_data = data[2]

        new_controls = False
        has_changed = False

        self.Freeze()
        for i in xrange(len(self.columns)):
            if self.columns[i].get('autoRefresh', True):
                i_new_controls, i_has_changed = self.RefreshColumn(i, data[1][i])

                if i_new_controls:
                    new_controls = True
                if i_has_changed:
                    has_changed = True

        if new_controls:
            self.hSizer.Layout()

        if self.showChange and has_changed:
            self.Highlight()

        elif new_controls:
            self.ShowSelected()

        self.Thaw()

    def RefreshColumn(self, columnindex, data):
        new_controls = has_changed = False
        column = self.columns[columnindex]
        prevdata = self.data[columnindex]
        self.data[columnindex] = data

        if column.get('show', True):
            control_index = column['controlindex']
            if not self.controls[control_index]:
                return False, False

            self.controls[control_index].icon = self._get_icon(columnindex, 'icon', self.controls[control_index].icon)
            self.controls[control_index].icon_right = self._get_icon(columnindex, 'icon_right', self.controls[control_index].icon_right)

            addColumnname = column.get('showColumname', True) and column.get('name', False)

            type = column.get('type', 'label')
            if type == 'label':
                str_data = column.get('fmt', unicode)(data)

                prefix = column['name'] + ": " if addColumnname else ''
                str_data = prefix + str_data

                # niels: we need to escape ampersand to allow them to be visible
                str_data = str_data.replace('&', "&&")

                if str_data != self.controls[control_index].GetLabel():
                    self.controls[control_index].SetLabel(str_data)
                    has_changed = True

            elif type == 'method':
                if prevdata != data:
                    control = column['method'](self, self)

                    if isinstance(control, Iterable):
                        control, _ = control

                    if control:
                        control.icon = self.controls[control_index].icon
                        control.icon_right = self.controls[control_index].icon_right

                        if isinstance(control, wx.Window):
                            control.SetBackgroundColour(self.GetBackgroundColour())

                        self._replace_control(control_index, control)
                        self.controls[control_index] = control
                        new_controls = True
                        has_changed = True

                        self.AddEvents(control)
        return new_controls, has_changed

    def SetToolTipColumn(self, columnindex, tooltip):
        column = self.columns[columnindex]
        if column.get('show', True):
            control_index = column['controlindex']
            control = self.controls[control_index]
            if control:
                control.SetToolTipString(tooltip)

    @warnWxThread
    def Highlight(self, timeout=3.0, revert=True, colour=LIST_HIGHTLIGHT):
        if self.IsShownOnScreen():
            self.BackgroundColor(colour)

            if revert:
                if self.highlightTimer == None:
                    self.highlightTimer = wx.CallLater(timeout * 1000, self.Revert)
                else:
                    self.highlightTimer.Restart(timeout * 1000)
            return True
        return False

    def Revert(self):
        try:
            self.ShowSelected()
            self.highlightTimer = None

        except PyDeadObjectError:  # PyDeadError
            pass

    def ShowSelected(self):
        def IsSelected(control):
            if getattr(control, 'GetWindow', False):  # convert sizeritems
                control = control.GetWindow()

            if getattr(control, 'selected', False):
                return True

            if getattr(control, 'GetChildren', False):
                children = control.GetChildren()
                for child in children:
                    if IsSelected(child):
                        return True
            return False

        if self.expanded:
            if self.list_expanded:
                if self.GetScreenRect().Contains(wx.GetMousePosition()):
                    self.BackgroundColor(self.list_selected_and_expanded)
                else:
                    self.BackgroundColor(self.list_expanded)
            else:
                self.BackgroundColor(self.list_selected)
        elif IsSelected(self):
            self.BackgroundColor(self.list_selected)
        else:
            self.BackgroundColor(self.list_deselected)

    def SetDeselectedColour(self, deselected):
        if deselected.Get() != self.list_deselected.Get():
            self.list_deselected = deselected
            self.ShowSelected()

    @warnWxThread
    def BackgroundColor(self, color):
        if self.GetBackgroundColour() != color:
            self.Freeze()

            self.SetBackgroundColour(color)
            for child in self.GetChildren():
                child = child.GetWindow() if getattr(child, 'IsWindow', False) and child.IsWindow() else child
                if isinstance(child, wx.Window) and not isinstance(child, wx.Button):
                    child.SetBackgroundColour(color)

            for control in self.controls:
                if control and getattr(control, 'icon', False) and control.icon.type:
                    state = 1 if self.expanded else 0
                    control.icon.SetBitmap(self.GetIcon(control.icon.type, self.GetBackgroundColour(), state))
                    control.icon.Refresh()

            # self.Refresh()
            self.Thaw()
            return True

        return False

    @warnWxThread
    def Deselect(self, raise_event=True):
        if self.GetBackgroundColour() == self.list_selected or self.expanded:
            def SetDeselected(control):
                if getattr(control, 'GetWindow', False):  # convert sizeritems
                    control = control.GetWindow()

                control.selected = False
                if getattr(control, 'GetChildren', False):
                    children = control.GetChildren()
                    for child in children:
                        SetDeselected(child)

            SetDeselected(self)

            if self.expanded:
                self.DoCollapse(raise_event)

            self.ShowSelected()

    def GetColumn(self, column):
        return self.data[column]

    @warnWxThread
    def OnMouse(self, event):
        if event.Entering():
            event.GetEventObject().selected = True
            wx.CallAfter(self.ShowSelected)

        elif event.Leaving():
            event.GetEventObject().selected = False
            wx.CallAfter(self.ShowSelected)

        elif event.LeftDown():
            event.listitem = self
            self.parent_list.lastMouseLeftDownEvent = event
            self.parent_list.SetFocusIgnoringChildren()

        elif event.LeftUp():
            if getattr(self.parent_list.lastMouseLeftDownEvent, 'listitem', None) == self:
                self.OnClick(event)

        elif event.RightUp():
            self.OnRightClick(event)

        elif event.ButtonDClick(wx.MOUSE_BTN_LEFT):
            self.OnDClick(event)

        event.Skip()  # Allow windows to paint button hover

    @warnWxThread
    def OnClick(self, event=None):
        if not self.expanded:
            if self.parent_list.OnExpand(self):
                self.expanded = True
                self.ShowSelected()

                for control in self.controls:
                    if control and control.icon and control.icon.type:
                        control.icon.SetBitmap(self.GetIcon(control.icon.type, self.list_selected, 1))
        else:
            self.DoCollapse()

    @warnWxThread
    def OnRightClick(self, event=None):
        pass

    @warnWxThread
    def OnDClick(self, event=None):
        pass

    @warnWxThread
    def DoExpand(self):
        if not self.expanded:
            self.OnClick()

    @warnWxThread
    def Expand(self, panel):
        self.expandedPanel = panel

        if getattr(panel, 'SetCursor', False):
            panel.SetCursor(wx.StockCursor(wx.CURSOR_DEFAULT))
            # panel.SetFont(panel.GetDefaultAttributes().font)

        panel.Show()
        if not self.vSizer.GetItem(panel, recursive=True):
            self.vSizer.Add(panel, 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.BOTTOM, 3)
        self.Layout()

    def GetExpandedPanel(self):
        return self.expandedPanel

    @warnWxThread
    def DoCollapse(self, raise_events=True):
        self.parent_list.OnCollapse(self, raise_events=raise_events)
        self.expanded = False

        for control in self.controls:
            if control and control.icon and control.icon.type:
                control.icon.SetBitmap(self.GetIcon(control.icon.type, self.list_selected, 0))

    @warnWxThread
    def Collapse(self):
        if self.expanded:
            self.expanded = False
            self.ShowSelected()

            if self.expandedPanel:
                self.expandedPanel.Hide()

                self.vSizer.Detach(self.expandedPanel)
                self.vSizer.Layout()
                return self.expandedPanel

    def OnEventSize(self, width):
        if self.expanded and self.expandedPanel:
            if getattr(self.expandedPanel, 'OnEventSize', False):
                return self.expandedPanel.OnEventSize(width)
        return False

    def __str__(self):
        return "ListItem " + " ".join(map(str, self.data))


class AbstractListBody():

    @warnWxThread
    def __init__(self, parent_list, columns, leftSpacer=0, rightSpacer=0, singleExpanded=False, showChange=False, list_item_max=None, hasFilter=True, listRateLimit=LIST_RATE_LIMIT, grid_columns=0, horizontal_scroll=False):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.columns = columns
        self.leftSpacer = leftSpacer
        self.rightSpacer = rightSpacer
        self.parent_list = parent_list
        self.singleExpanded = singleExpanded
        self.showChange = showChange
        self.list_selected = LIST_SELECTED
        self.list_expanded = LIST_EXPANDED
        self.listRateLimit = listRateLimit
        if not list_item_max:
            list_item_max = LIST_ITEM_MAX_SIZE
        self.list_item_max = list_item_max
        self.list_cur_max = self.list_item_max
        self.horizontal_scroll = horizontal_scroll

        self.hasFilter = hasFilter

        self.listpanel = wx.Panel(self, name="LIST")
        self.messagePanel = wx.Panel(self.listpanel)

        # vertical sizer containing all items
        self.grid_columns = grid_columns
        if self.horizontal_scroll:
            self.vSizer = wx.BoxSizer(wx.HORIZONTAL)
        elif self.grid_columns > 0:
            self.vSizer = wx.FlexGridSizer(0, self.grid_columns, 0, 0)
        else:
            self.vSizer = wx.BoxSizer(wx.VERTICAL)

        sizer = wx.BoxSizer(wx.VERTICAL)
        sizer.Add(self.vSizer, 1, wx.EXPAND)
        sizer.Add(self.messagePanel, 0, wx.EXPAND)
        self.listpanel.SetSizer(sizer)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(self.listpanel, 1, wx.EXPAND if self.horizontal_scroll else 0, 0)
        self.SetSizer(hSizer)

        # messagePanel text
        self.messagePanel.SetBackgroundColour(DEFAULT_BACKGROUND)
        self.messagePanel.Show(False)
        messageVSizer = wx.BoxSizer(wx.VERTICAL)

        self.headerText = StaticText(self.messagePanel)
        _set_font(self.headerText, fontweight=wx.FONTWEIGHT_BOLD)
        self.messageText = StaticText(self.messagePanel)
        self.loadNext = wx.Button(self.messagePanel)
        self.loadNext.Bind(wx.EVT_BUTTON, self.OnLoadMore)
        self.loadNext.Hide()

        messageVSizer.Add(self.headerText, 0, wx.EXPAND)
        messageVSizer.Add(self.messageText, 0, wx.EXPAND)
        messageVSizer.Add(self.loadNext, 0, wx.ALIGN_CENTER)
        self.messageText.sizer = messageVSizer
        self.messageText.altControl = None

        messageSizer = wx.BoxSizer(wx.HORIZONTAL)
        messageSizer.AddStretchSpacer()
        messageSizer.Add(messageVSizer, 0, wx.TOP | wx.BOTTOM, 7)
        messageSizer.AddStretchSpacer()
        self.messagePanel.SetSizer(messageSizer)

        # vertical scrollrate
        self.rate = None

        # states
        self.cur_expanded = None

        # quick filter
        self.filter = None
        self.filterMessage = None

        # sorting
        self.sortcolumn = None

        # queue lists
        self.done = True
        self.lastData = 0
        self.dataTimer = None
        self.data = None
        self.raw_data = None
        self.items = {}
        self.to_be_removed = set()

        # Allow list-items to store the most recent mouse left-down events:
        self.lastMouseLeftDownEvent = None
        self.curWidth = -1
        self.Bind(wx.EVT_SIZE, self.OnEventSize)

        self.ShowLoading()

    @warnWxThread
    def SetBackgroundColour(self, colour):
        wx.Panel.SetBackgroundColour(self, DEFAULT_BACKGROUND)
        self.listpanel.SetBackgroundColour(colour)

    @warnWxThread
    def SetStyle(self, font=None, foregroundcolour=None, list_selected=LIST_SELECTED, list_expanded=LIST_EXPANDED):
        if font:
            self.SetFont(font)
        if foregroundcolour:
            self.SetForegroundColour(foregroundcolour)

        self.list_selected = list_selected
        self.list_expanded = list_expanded

    @warnWxThread
    def OnSort(self, column, reverse):
        self.Scroll(-1, 0)

        # Niels: translating between -1 and None conventions
        if column == -1:
            column = None

        self.sortcolumn = column
        self.sortreverse = reverse

        self.SetData(highlight=False, force=True)

    def DoSort(self):
        def sortby(b, a):
            if a[0] in self.items:
                a = self.items[a[0]].data[self.sortcolumn]
            else:
                a = a[1][self.sortcolumn]

            if b[0] in self.items:
                b = self.items[b[0]].data[self.sortcolumn]
            else:
                b = b[1][self.sortcolumn]

            if isinstance(a, basestring):
                a = a.lower()
            if isinstance(b, basestring):
                b = b.lower()

            return cmp(a, b)

        fixed_positions = []

        index = 0
        while index < len(self.data):
            item = self.data[index]
            if len(item) == 5:
                fixed_positions.append((item[-1], item))
                self.data.pop(index)
                continue
            index += 1

        if self.sortcolumn != None:
            self.data = sorted(self.data, cmp=sortby, reverse=self.sortreverse)

        fixed_positions.sort()
        for pos, item in fixed_positions:
            self.data.insert(pos, item)

    def SetFilter(self, filter, filterMessage, highlight):
        self.filterMessage = filterMessage

        if self.filter is not None or filter is not None:
            self.filter = filter

            if self.raw_data:
                self.Scroll(-1, 0)
                self.SetData(highlight=highlight)

    @warnWxThread
    def OnExpand(self, item, raise_event=False):
        self.Freeze()

        if not self.singleExpanded and wx.GetKeyState(wx.WXK_SHIFT):
            pos_from = self.GetItemPos(self.GetItemKey(self.cur_expanded))
            pos_to = self.GetItemPos(self.GetItemKey(item))
            if pos_from != None and pos_to != None:
                pos_min = min(pos_from, pos_to)
                pos_max = max(pos_from, pos_to)
                self.DeselectAll()
                for index, data in enumerate(self.data[pos_min:pos_max + 1]):
                    if index + pos_min != pos_to:
                        self.Select(data[0], raise_event=False)

        elif self.singleExpanded or not wx.GetKeyState(wx.WXK_CONTROL):
            if self.cur_expanded:
                self.OnCollapse(self.cur_expanded, from_expand=True)

        panel = self.parent_list.OnExpand(item)
        if panel and not isinstance(panel, bool):
            item.Expand(panel)
            self.OnChange()

        self.cur_expanded = item
        self.Thaw()
        return panel

    @warnWxThread
    def OnCollapse(self, item=None, raise_events=True, from_expand=False):
        self.Freeze()

        if not item:
            item = self.cur_expanded

        if item:
            panel = item.Collapse()
            self.parent_list.OnCollapse(item, panel, from_expand)
            self.cur_expanded = None

        toBeSelected = None
        if self.singleExpanded or wx.GetKeyState(wx.WXK_CONTROL):
            # select another still expanded item
            selectedItems = self.GetExpandedItems()
            if selectedItems:
                toBeSelected = selectedItems[0]

        else:
            if raise_events:
                # if we're not comming from expand, then this is a click on a previously selected item
                # schedule a expand if we had multiple items selected
                selectedItems = self.GetExpandedItems()
                if len(selectedItems) > 1 and not from_expand:
                    toBeSelected = self.GetItemKey(item), item

                self.DeselectAll()

        # use callafter for select to let all expanded boolean flags settle, before yet again selecting this item
        if toBeSelected:
            toBeSelected[1].expanded = False
            wx.CallAfter(self.Select, toBeSelected[0])

        self.Thaw()

    @warnWxThread
    def OnChange(self, scrollToTop=False):
        self._logger.debug("ListBody: OnChange")
        self.Freeze()

        self.vSizer.Layout()
        self.listpanel.Layout()
        self.Layout()

        # Determine scrollrate
        if not self.horizontal_scroll:
            nritems = len(self.vSizer.GetChildren())
            if self.rate is None or nritems <= LIST_ITEM_BATCH_SIZE * 3:
                if nritems > 0:
                    height = self.vSizer.GetSize()[1]
                    self.rate = height / nritems
                    self._logger.debug("ListBody: setting scrollrate to %s", self.rate)

                    self.SetupScrolling(scrollToTop=scrollToTop, rate_y=self.rate)
                else:
                    self._logger.debug("ListBody: setting scrollrate to default")

                    self.SetupScrolling(scrollToTop=scrollToTop)
            else:
                self._logger.debug("ListBody: using scrollrate %s", self.rate)
                self.SetupScrolling(scrollToTop=scrollToTop, rate_y=self.rate)

        self.Thaw()

    @warnWxThread
    def Reset(self):
        self._logger.debug("ListBody: Reset")

        self.Freeze()

        self.filter = None
        self.filterMessage = None
        self.sortcolumn = None
        self.rate = None

        self.vSizer.ShowItems(False)
        self.vSizer.Clear()
        for item in self.items.itervalues():
            if item:
                item.Destroy()

        if self.dataTimer:
            self.dataTimer.Stop()

        self.list_cur_max = self.list_item_max

        self.items = {}
        self.to_be_removed = set()
        self.data = None
        self.lastData = 0
        self.raw_data = None
        self.ShowLoading()
        self.OnChange()
        self.Thaw()

    def Rebuild(self):
        _rawdata = self.raw_data
        self.Reset()
        self.SetData(_rawdata, highlight=False, force=True)

    def IsEmpty(self):
        return len(self.items) == 0

    def InList(self, key, onlyCreated=True):
        if onlyCreated or not self.data:
            return key in self.items

        if key in self.items:
            return True
        return any(curdata[0] == key for curdata in self.data)

    @warnWxThread
    def ScrollToEnd(self, scroll_to_end):
        if scroll_to_end:
            self.Scroll(-1, self.vSizer.GetSize()[1])
        else:
            self.Scroll(-1, 0)

    @warnWxThread
    def ScrollToNextPage(self, scroll_to_nextpage):
        scroll_pos = self.CalcUnscrolledPosition(0, 0)[1] / self.GetScrollPixelsPerUnit()[1]
        if scroll_to_nextpage:
            scroll_pos = min(scroll_pos + self.GetScrollPageSize(0), self.vSizer.GetSize()[1])
        else:
            scroll_pos = max(scroll_pos - self.GetScrollPageSize(0), 0)
        self.Scroll(-1, scroll_pos)

    @warnWxThread
    def ScrollToId(self, id):
        if id in self.items:
            sy = self.items[id].GetPosition()[1] / self.GetScrollPixelsPerUnit()[1]
            self.Scroll(-1, sy)

    @warnWxThread
    def ShowMessage(self, message, header=None, altControl=None, clearitems=True):
        self._logger.debug("ListBody: ShowMessage %s %s", message, header)

        self.Freeze()

        if header:
            self.headerText.SetLabel(header)
            self.headerText.Show()
        else:
            self.headerText.Hide()

        self.messageText.SetLabel(message)

        if self.messageText.altControl:
            self.messageText.sizer.Detach(self.messageText.altControl)
            if getattr(self.messageText.altControl, 'ShowItems', False):
                self.messageText.altControl.ShowItems(False)
                self.messageText.altControl.Clear(True)
            else:
                self.messageText.altControl.Destroy()
            self.messageText.altControl = None

        if altControl:
            self.messageText.altControl = altControl(self.messagePanel)
            self.messageText.sizer.Insert(2, self.messageText.altControl, 0, wx.EXPAND)

        if clearitems:
            self.loadNext.Hide()
            self.vSizer.ShowItems(False)
            self.vSizer.Clear()

        if not self.messagePanel.IsShown():
            self.messagePanel.Show()

        self.messagePanel.Layout()

        self.OnChange()
        self.Thaw()

    def GetMessage(self):
        header = message = None
        if self.headerText.IsShown():
            header = self.headerText.GetLabel()

        if self.messageText.IsShown():
            message = self.messageText.GetLabel()

        return header, message

    @warnWxThread
    def ShowLoading(self):
        self.ShowMessage('Loading, please wait.')

    @warnWxThread
    def RefreshData(self, key, data):
        if key in self.items:
            self._logger.debug("ListBody: refresh item %s", self.items[key])
            self.items[key].RefreshData(data)

            # forward update to expandedPanel
            panel = self.items[key].GetExpandedPanel()
            if panel and getattr(panel, 'RefreshData', False):
                self._logger.debug("ListBody: refresh item (Calling expandedPanel refreshdata) %s", self.items[key])

                panel.RefreshData(data)

        elif self.data:
            self.data.append(data)
            self.CreateItem(key)

    @warnWxThread
    def SetData(self, data=None, highlight=None, force=False):
        if data == None:
            data = self.raw_data
        else:
            self.raw_data = data

        nr_items = -1
        if data:
            nr_items = len(data)
        self._logger.debug("ListBody: new data %s %s", time(), nr_items)

        if highlight is None:
            highlight = not self.IsEmpty()

        def doSetData():
            self.lastData = time()
            self.dataTimer = None

            self.__SetData(highlight)

        if force:
            if self.dataTimer:
                self.dataTimer.Stop()
            doSetData()
        else:
            diff = time() - (self.listRateLimit + self.lastData)
            call_in = -diff * 1000
            if call_in <= 0:
                doSetData()
            else:
                if self.dataTimer == None:
                    self.dataTimer = wx.CallLater(call_in, doSetData)
                else:
                    self.dataTimer.Restart(call_in)

    @warnWxThread
    def __SetData(self, highlight=True):
        self._logger.debug("ListBody: __SetData %s", time())

        # apply quickfilter
        if self.filter:
            if self.raw_data:
                data = filter(self.filter, self.raw_data)
            else:
                data = None
        else:
            data = self.raw_data

        if not data:
            data = []
        if getattr(self.parent_list, 'SetNrResults', None):
            self.parent_list.SetNrResults(len(data))

        self.highlightSet = set()
        cur_keys = set(self.items.keys())
        for curdata in data[:self.list_cur_max]:
            key = curdata[0]
            if key not in cur_keys:
                if highlight:
                    self.highlightSet.add(key)
            else:
                cur_keys.discard(key)

        # cur_keys now contains all removed items
        for key in cur_keys:
            self.items[key].DoCollapse()
            self.items[key].Show(False)
            self.items[key].Destroy()
            del self.items[key]

        self.data = data
        self.DoSort()
        self.done = False

        if len(data) > 0:
            self.vSizer.ShowItems(False)
            self.vSizer.Clear()

            self.CreateItems(nr_items_to_create=3 * LIST_ITEM_BATCH_SIZE)

            # Try to yield
            try:
                wx.Yield()
            except:
                pass

        elif self.filter:
            header, message = self.filterMessage(empty=True)
            if message:
                self.ShowMessage(message + '.', header)

        if self.done:
            self.Unbind(wx.EVT_IDLE)  # unbinding unnecessary event handler seems to improve visual performance
        else:
            self.Bind(wx.EVT_IDLE, self.OnIdle)

    def OnIdle(self, event):
        self._logger.debug("ListBody: OnIdle")
        if not self.done:
            if self.data and len(self.data) > 0:
                self.CreateItems()
            else:
                self.done = True

            # idle event also paints search animation, use request more to show this update
            event.RequestMore(not self.done)
            if self.done:
                self.Unbind(wx.EVT_IDLE)

    def OnLoadMore(self, event=None):
        if self.loadNext.IsShown():
            self.loadNext.Disable()
            self.list_cur_max += LIST_ITEM_MAX_SIZE

            wx.CallAfter(self.CreateItems)
            self.Bind(wx.EVT_IDLE, self.OnIdle)

    def OnLoadAll(self):
        self.loadNext.Disable()
        self.list_cur_max = sys.maxsize

        wx.CallAfter(self.CreateItems)
        self.Bind(wx.EVT_IDLE, self.OnIdle)

    @warnWxThread
    def CreateItem(self, key):
        if not key in self.items and self.data:
            for curdata in self.data:
                if key == curdata[0]:
                    if len(curdata) > 3:
                        _, item_data, original_data, create_method = curdata[:4]
                    else:
                        _, item_data, original_data = curdata
                        create_method = ListItem

                    self.items[key] = create_method(self.listpanel, self, self.columns, item_data, original_data, self.leftSpacer, self.rightSpacer, showChange=self.showChange, list_selected=self.list_selected, list_expanded=self.list_expanded)
                    break

        if key in self.items:
            item = self.items[key]
            sizer = self.vSizer.GetItem(item) if item else True
            if not sizer:
                self.vSizer.Add(item, 0, wx.EXPAND | wx.BOTTOM, 1)
                item.Show()

                self.OnChange()
            return True
        return False

    @warnWxThread
    def CreateItems(self, nr_items_to_create=LIST_ITEM_BATCH_SIZE, nr_items_to_add=None):
        if not nr_items_to_add:
            nr_items_to_add = self.list_cur_max

        self._logger.debug("ListBody: Creating items %s", time())

        initial_nr_items_to_add = nr_items_to_add
        done = True
        didAdd = False

        if len(self.data) > 0:
            t1 = time()
            self.Freeze()

            # Check if we need to clear vSizer
            self.messagePanel.Show(False)
            self.loadNext.Show(False)

            message = ''
            header = None

            revertList = []
            # Add created/cached items
            for curdata in self.data:
                if len(curdata) > 3:
                    key, item_data, original_data, create_method = curdata[:4]
                else:
                    key, item_data, original_data = curdata
                    create_method = ListItem

                if nr_items_to_add > 0 and nr_items_to_create > 0:
                    if key in self.to_be_removed:
                        self.DestroyItem(key)
                        self.to_be_removed.remove(key)

                    if key not in self.items:
                        try:
                            self.items[key] = create_method(self.listpanel, self, self.columns, item_data, original_data, self.leftSpacer, self.rightSpacer, showChange=self.showChange, list_selected=self.list_selected, list_expanded=self.list_expanded)
                            nr_items_to_create -= 1
                        except:
                            print_exc()
                            self.items[key] = None

                    item = self.items[key]
                    sizer = self.vSizer.GetItem(item) if item else True
                    if not sizer:
                        self.vSizer.Add(item, 0, wx.EXPAND | wx.BOTTOM, 1)
                        item.Show()
                        didAdd = True

                        if key in self.highlightSet:
                            self.highlightSet.remove(key)

                            if item.Highlight(revert=False):
                                revertList.append(key)

                    nr_items_to_add -= 1

                else:
                    done = nr_items_to_add == 0 or initial_nr_items_to_add == sys.maxsize

                    if done:
                        if message != '':
                            message = 'Only showing the first %d of %d' % (len(self.vSizer.GetChildren()), len(self.data)) + message[12:] + '\nFurther specify keywords to reduce the number of items, or click the button below.'
                        else:
                            message = 'Only showing the first %d of %d items in this list.' % (len(self.vSizer.GetChildren()), len(self.data))
                            if self.hasFilter:
                                message += '\nFilter results to reduce the number of items, or click the button below.'

                        remainingItems = min(LIST_ITEM_MAX_SIZE, len(self.data) - len(self.vSizer.GetChildren()))
                        self.loadNext.SetLabel("Show next %d items" % remainingItems)
                        self.loadNext.Enable()
                        self.loadNext.Show()
                    break

            if done and self.filter:
                header, message_start = self.filterMessage()
                if message_start:
                    message = message_start + '.' + message

            if len(message) > 12:
                self.ShowMessage(message, header, clearitems=False)

            if didAdd:
                self.OnChange()

            self.Thaw()

            if len(revertList) > 0:
                wx.CallLater(1000, self.Revert, revertList)

        self.done = done
        self._logger.debug("List created %s rows of %s took %s done: %s %s", len(self.vSizer.GetChildren()), len(self.data), time() - t1, self.done, time())

    def HasItem(self, key):
        return key in self.items

    def GetItem(self, key):
        return self.items[key]

    def GetItems(self):
        return self.items.values()

    def GetItemPos(self, key):
        # Returns the index of the ListItem belonging to this key
        for i, data in enumerate(self.data):
            if key == data[0]:
                return i

    def GetItemKey(self, item):
        for key, curitem in self.items.iteritems():
            if item == curitem:
                return key

    def RemoveItem(self, remove):
        for key, item in self.items.iteritems():
            if item == remove:
                self.RemoveKey(key)
                break

    def RemoveKey(self, key):
        self.RemoveKeys([key])

    @warnWxThread
    def RemoveKeys(self, keys):
        _keys = set(keys)

        updated = False
        for key in _keys:
            if self.DestroyItem(key):
                updated = True

        if updated:
            self.OnChange()

        if self.raw_data:
            for i, curdata in enumerate(self.raw_data):
                if curdata[0] in _keys:
                    self.raw_data.pop(i)
                    _keys.discard(curdata[0])

                if len(_keys) == 0:
                    break

    def DestroyItem(self, key):
        item = self.items.get(key, None)
        if item:
            self.items.pop(key)

            self.vSizer.Detach(item)
            item.Destroy()
            return True
        return False

    def MarkForRemoval(self, keys):
        self.to_be_removed.update(keys)

    def GetExpandedItem(self):
        return self.cur_expanded

    def GetExpandedItems(self):
        return [(key, item) for key, item in self.items.iteritems() if item and item.expanded]

    @warnWxThread
    def Select(self, key, raise_event=True):
        # check if we need to create this item on the spot
        if self.CreateItem(key):
            if not self.items[key].expanded:
                if self.singleExpanded:
                    self.DeselectAll()

                if raise_event:
                    self.items[key].OnClick(None)
                else:
                    self.items[key].expanded = True
                    self.cur_expanded = self.items[key]

            self.items[key].ShowSelected()

    @warnWxThread
    def SelectNextItem(self, next=True):
        item = self.GetExpandedItem()
        if not item:
            return

        key = None
        for k, i in self.items.iteritems():
            if item == i:
                key = k

        select = None
        for index, data in enumerate(self.data):
            if data[0] == key:
                offset = self.grid_columns or 1
                if next and len(self.data) > index + offset:
                    select = self.data[index + offset][0]
                elif not next and index >= offset:
                    select = self.data[index - offset][0]
                break

        if select:
            cur_scroll = self.CalcUnscrolledPosition(0, 0)[1] / self.GetScrollPixelsPerUnit()[1]
            if next:
                tot_scroll = (self.items[select].GetPosition()[1] + self.items[select].GetSize()[1] + 1) / self.GetScrollPixelsPerUnit()[1]
                if tot_scroll - cur_scroll > self.GetScrollPageSize(1):
                    self.Scroll(-1, tot_scroll - self.GetScrollPageSize(1))
            else:
                tot_scroll = self.items[select].GetPosition()[1] / self.GetScrollPixelsPerUnit()[1]
                if tot_scroll - cur_scroll < 0:
                    self.Scroll(-1, tot_scroll)
            self.Select(select, True)

    @warnWxThread
    def DeselectAll(self):
        for _, item in self.GetExpandedItems():
            item.Deselect(raise_event=False)

    def Revert(self, revertList):
        for key in revertList:
            if key in self.items:
                self.items[key].Revert()

    def OnEventSize(self, event):
        width = self.GetSize()[0]
        if width != self.curWidth:
            doOnChange = False

            self.Freeze()
            self.curWidth = width

            for item in self.items.itervalues():
                if item.OnEventSize(width):
                    doOnChange = True

            if doOnChange:
                self.OnChange()

            self.Thaw()

        if not self.horizontal_scroll and self.grid_columns > 0 and self.items:
            column_width = self.items.values()[0].GetSize().x
            viewable_width = self.listpanel.GetParent().GetSize().x

            if viewable_width / column_width != self.grid_columns:
                self.grid_columns = (viewable_width / column_width) or 1
                self.vSizer.Clear()
                self.vSizer = wx.FlexGridSizer(0, self.grid_columns, 0, 0)
                self.listpanel.GetSizer().Insert(0, self.vSizer, 1, wx.EXPAND)
                self.listpanel.GetSizer().Detach(1)
                self.Rebuild()

        event.Skip()

    def SetGrid(self, enable):
        # Set the default value, later we calculate the correct value by triggering a resize event
        self.grid_columns = 4 if enable else 0
        self.vSizer.Clear()
        self.vSizer = wx.FlexGridSizer(0, self.grid_columns, 0, 0) if enable else wx.BoxSizer(wx.VERTICAL)
        self.listpanel.GetSizer().Insert(0, self.vSizer, 1, wx.EXPAND)
        self.listpanel.GetSizer().Detach(1)
        self.Rebuild()
        # Resize event
        if enable:
            self.SendSizeEvent()


class ListBody(AbstractListBody, scrolled.ScrolledPanel):

    def __init__(self, parent, parent_list, columns, leftSpacer=0, rightSpacer=0, singleExpanded=False, showChange=False, list_item_max=LIST_ITEM_MAX_SIZE, listRateLimit=LIST_RATE_LIMIT, grid_columns=0, horizontal_scroll=False):
        scrolled.ScrolledPanel.__init__(self, parent)
        AbstractListBody.__init__(self, parent_list, columns, leftSpacer, rightSpacer, singleExpanded, showChange, listRateLimit=listRateLimit, list_item_max=list_item_max, grid_columns=grid_columns, horizontal_scroll=horizontal_scroll)

        homeId = wx.NewId()
        endId = wx.NewId()
        pupId = wx.NewId()
        pdownId = wx.NewId()
        aupId = wx.NewId()
        adownId = wx.NewId()
        deleteId = wx.NewId()
        backId = wx.NewId()
        self.Bind(wx.EVT_MENU, lambda event: self.ScrollToEnd(False), id=homeId)
        self.Bind(wx.EVT_MENU, lambda event: self.ScrollToEnd(True), id=endId)
        self.Bind(wx.EVT_MENU, lambda event: self.ScrollToNextPage(False), id=pupId)
        self.Bind(wx.EVT_MENU, lambda event: self.ScrollToNextPage(True), id=pdownId)
        self.Bind(wx.EVT_MENU, lambda event: self.SelectNextItem(False), id=aupId)
        self.Bind(wx.EVT_MENU, lambda event: self.SelectNextItem(True), id=adownId)
        self.Bind(wx.EVT_MENU, lambda event: self.parent_list.OnDeleteKey(event) if getattr(self.parent_list, 'OnDeleteKey', False) else None, id=deleteId)
        self.Bind(wx.EVT_MENU, lambda event: self.OnBack(event), id=backId)
        self.Bind(wx.EVT_CHILD_FOCUS, self.OnChildFocus)
        wx.GetTopLevelParent(self).Bind(wx.EVT_MOUSEWHEEL, self.OnMouseWheel)

        accelerators = [(wx.ACCEL_NORMAL, wx.WXK_HOME, homeId)]
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_END, endId))
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_PRIOR, pupId))
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_NEXT, pdownId))
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_UP, aupId))
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_DOWN, adownId))
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_DELETE, deleteId))
        accelerators.append((wx.ACCEL_NORMAL, wx.WXK_BACK, backId))
        self.SetAcceleratorTable(wx.AcceleratorTable(accelerators))

        self.SetForegroundColour(parent.GetForegroundColour())
        self.SetupScrolling()

        TIMER_ID = wx.NewId()
        self.scrollTimer = wx.Timer(self, TIMER_ID)
        self.Bind(wx.EVT_TIMER, self.checkScroll)
        self.processingMousewheel = False

    def OnChildFocus(self, event):
        pass

    def OnBack(self, event):
        pass

    def OnMouseWheel(self, event):
        try:
            if self.processingMousewheel:
                return
            self.processingMousewheel = True
            if self.IsShownOnScreen() and self.GetScreenRect().Contains(wx.GetMousePosition()):
                self.GetEventHandler().ProcessEvent(event)
                self.processingMousewheel = False
            else:
                self.processingMousewheel = False
                event.Skip()

        except PyDeadObjectError:
            GUIUtility.getInstance().frame.Unbind(wx.EVT_MOUSEWHEEL)

    def Show(self, show=True):
        scrolled.ScrolledPanel.Show(self, show)
        if show:
            self.scrollTimer.Start(1000)
        else:
            self.scrollTimer.Stop()

    def checkScroll(self, event):
        maxY = self.vSizer.GetSize()[1]
        doMore = maxY * 0.8

        height = self.GetClientSize()[1]
        viewY = self.CalcUnscrolledPosition(list(self.GetViewStart()))[1] + height

        if viewY > doMore:
            self.OnLoadMore()


class FixedListBody(wx.Panel, AbstractListBody):

    def __init__(self, parent, parent_list, columns, leftSpacer=0, rightSpacer=0, singleExpanded=False, showChange=False, list_item_max=LIST_ITEM_MAX_SIZE):
        wx.Panel.__init__(self, parent)
        AbstractListBody.__init__(self, parent_list, columns, leftSpacer, rightSpacer, singleExpanded, showChange, list_item_max=list_item_max, hasFilter=False)

        self.SetForegroundColour(parent.GetForegroundColour())

    def Scroll(self, x, y):
        pass

    def SetupScrolling(self, scroll_x=True, scroll_y=True, rate_x=20, rate_y=20, scrollToTop=True):
        pass

    def GetScrollPixelsPerUnit(self):
        return [0, 0]

########NEW FILE########
__FILENAME__ = list_bundle
# written by Raynor Vliegendhart
# see LICENSE.txt for license information

import wx
import logging

from Tribler.Main.vwxGUI import LIST_SELECTED, DEFAULT_BACKGROUND, LIST_GREY, \
    LIST_AUTOSIZEHEADER, format_size
from Tribler.Main.vwxGUI.list_body import ListItem, FixedListBody
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.list import GenericSearchList
from Tribler.Main.vwxGUI.list_header import ListHeader
from Tribler.Main.vwxGUI.list_details import TorrentDetails
from Tribler.Main.vwxGUI.widgets import LinkStaticText, BetterText as StaticText
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler

BUNDLE_FONT_SIZE_DECREMENT = 0
BUNDLE_FONT_COLOR = (50, 50, 50)
BUNDLE_GRID_COLLAPSE = 800

BUNDLE_NUM_COLS = 2
BUNDLE_NUM_ROWS = 3


class BundleListItem(ListItem):

    def __init__(self, parent, parent_list, columns, data, original_data, leftSpacer=0, rightSpacer=0, showChange=False, list_selected=LIST_SELECTED):
        self._logger = logging.getLogger(self.__class__.__name__)

        # fetch bundle and descriptions
        self.bundle = original_data['bundle']
        self.general_description = original_data.get('bundle_general_description')
        self.description = original_data.get('bundle_description')

        # use the head as original_data (needed for SearchList)
        original_data = self.bundle[0]

        # call the original constructor
        ListItem.__init__(self, parent, parent_list, columns, data, original_data, leftSpacer, rightSpacer, showChange, list_selected)

        # Now add the BundleListView (after AddComponents)
        self.AddBundlePanel(self.bundle[1:])
        self.bundlepanel.Layout()

        self.expanded_panel = None
        self.expanded_panel_shown = False

    def AddBundlePanel(self, bundled):
        self.bundlepanel = BundlePanel(self, self.parent_list, bundled,
                                       self.general_description, self.description,
                                       - BUNDLE_FONT_SIZE_DECREMENT)
        self.AddEvents(self.bundlepanel)
        self.vSizer.Add(self.bundlepanel, 1, wx.EXPAND)

    def RefreshData(self, data):
        infohash, item_data, original_data = data

        if isinstance(original_data, dict) and 'bundle' in original_data:
            self.bundle = original_data['bundle']
            head_original_data, bundled = self.bundle[0], self.bundle[1:]

            ListItem.RefreshData(self, (infohash, item_data, head_original_data))

            showHighlight = self.bundlepanel.SetHits(bundled)
            if showHighlight:
                self.Highlight(1)

            self.bundlepanel.UpdateHeader(original_data['bundle_general_description'], original_data['bundle_description'])

            self._logger.debug("*** BundleListItem.RefreshData: bundle changed: %s #1+%s", original_data['key'], len(bundled))
        else:
            if infohash == self.original_data.infohash:  # update top row
                ListItem.RefreshData(self, data)

            else:  # update part of list
                self.bundlepanel.RefreshDataBundleList(infohash, original_data)

    def GetExpandedPanel(self):
        if self.expanded_panel_shown:
            return self.expanded_panel

        return self.bundlepanel.GetExpandedPanel()

    def Expand(self, panel):
        ListItem.Expand(self, panel)

        self.vSizer.Detach(panel)
        self.vSizer.Insert(1, panel, 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.BOTTOM, 3)

        self.expanded_panel = panel
        self.expanded_panel_shown = True

    def Collapse(self):
        panel = ListItem.Collapse(self)

        self.expanded_panel = None
        self.expanded_panel_shown = False
        self.bundlepanel.ChangeState(BundlePanel.COLLAPSED)

        return panel

    def OnClick(self, event=None):
        if event:
            # ignore onclick from bundlegrid
            control = event.GetEventObject()
            if getattr(control, 'action', False):
                self.showing_similar_item = True
                return

            if getattr(self, 'showing_similar_item', False):
                self.showing_similar_item = False
                self.parent_list.OnExpand(self)
                self.bundlepanel.SetBackgroundColour(self.bundlepanel.parent.GetBackgroundColour())

        if True:  # self.expanded == self.expanded_panel_shown:
            ListItem.OnClick(self, event)
        else:
            self.ShowExpandedPanel(not self.expanded_panel_shown)

    def ShowExpandedPanel(self, show=True):
        panel = self.expanded_panel

        if panel and panel.IsShown() != show:
            self.Freeze()

            self._logger.debug("BundleListItem: ShowExpandedPanel %s %s", show, self.expanded_panel_shown)

            panel.Show(show)

            self.expanded_panel_shown = show
            if self.expanded_panel_shown:
                self.bundlepanel.CollapseExpandedItem()

            self.parent_list.OnChange()
            self.Layout()

            self.Thaw()

            if show:
                panel.Layout()

    def BackgroundColor(self, color):
        if self.GetBackgroundColour() != color:
            self.Freeze()

            ListItem.BackgroundColor(self, color)
            self.bundlepanel.SetBackgroundColour(color)

            self.Thaw()

    def OnChange(self, scrollToTop=False):
        self.Layout()
        self.parent_list.OnChange(scrollToTop)

    def AddEvents(self, control):
        if isinstance(control, LinkStaticText):
            control.Bind(wx.EVT_MOUSE_EVENTS, self.OnMouse)
        else:
            ListItem.AddEvents(self, control)

    def OnEventSize(self, width):
        ListItem.OnEventSize(self, width)
        return self.bundlepanel.OnEventSize(width)


class BundlePanel(wx.BoxSizer):

    COLLAPSED, PARTIAL, FULL = range(3)

    icons = None

    @classmethod
    def load_icons(cls):
        if not cls.icons:
            icons = cls.icons = {}

            icons['info'] = GuiImageManager.getInstance().getImage(u"info.png")

    def __init__(self, parent, parent_list, hits, general_description=None, description=None, font_increment=0):
        wx.BoxSizer.__init__(self, wx.HORIZONTAL)

        self._logger = logging.getLogger(self.__class__.__name__)

        # preload icons
        self.load_icons()

        self.parent = parent
        self.parent_listitem = parent
        self.parent_list = parent_list

        listbody_width = parent_list.GetSize()[0]
        if listbody_width < BUNDLE_GRID_COLLAPSE:
            self.num_cols = 1
        else:
            self.num_cols = BUNDLE_NUM_COLS

        # logging
        self.guiutility = GUIUtility.getInstance()
        self.uelog = UserEventLogDBHandler.getInstance()

        self.state = BundlePanel.COLLAPSED
        self.nrhits = -1
        self.bundlelist = None

        self.font_increment = font_increment
        self.vsizer = wx.BoxSizer(wx.VERTICAL)

        self.SetBackgroundColour(DEFAULT_BACKGROUND)

        self.indent = 3 + 3 + self.parent_list.leftSpacer  # width of 3px left spacer + 3px right spacer

        self.AddHeader()
        self.AddGrid()

        self.SetHits(hits, noChange=True)
        self.UpdateHeader(general_description, description)

        self.AddSpacer((self.indent, -1))
        self.Add(self.vsizer, 1, wx.EXPAND | wx.BOTTOM, 7)

    def AddHeader(self):
        sizer = wx.BoxSizer(wx.HORIZONTAL)

        self.header = StaticText(self.parent, -1, ' ')
        self.info_icon = wx.StaticBitmap(self.parent, -1, self.icons['info'])

        sizer.Add(self.header, 0, wx.RIGHT, 7)
        sizer.Add(self.info_icon, 0, wx.ALIGN_CENTER_VERTICAL)
        self.vsizer.Add(sizer, 0, wx.BOTTOM, 3)

    def UpdateHeader(self, general_description, description):
        self.SetGeneralDescription(general_description)
        self.SetDescription(description)

    def AddGrid(self):
        self.grid = wx.FlexGridSizer(0, self.num_cols, 3, 7)
        self.grid.SetFlexibleDirection(wx.HORIZONTAL)
        self.grid.SetNonFlexibleGrowMode(wx.FLEX_GROWMODE_NONE)
        self.grid.SetMinSize((1, -1))

        for i in xrange(BUNDLE_NUM_ROWS):
            self.grid.AddGrowableRow(i, 1)

        for j in xrange(self.num_cols):
            self.grid.AddGrowableCol(j, 1)
        self.vsizer.Add(self.grid, 1, wx.EXPAND | wx.LEFT | wx.RIGHT, 14 + self.indent)

    def RebuildGrid(self, new_cols):
        if self.num_cols != new_cols:
            self.num_cols = new_cols

            children = self.grid.GetChildren()
            children_controls = []
            for child in children:
                children_controls.append(child.GetWindow() or child.GetSizer())

            for child in children_controls:
                self.grid.Detach(child)

            self.vsizer.Detach(self.grid)
            self.grid.Destroy()

            self.grid = wx.FlexGridSizer(0, self.num_cols, 3, 7)
            for child in children_controls:
                self.grid.Add(child, 0, wx.EXPAND)

            for j in xrange(self.num_cols):
                self.grid.AddGrowableCol(j, 1)

            self.vsizer.Add(self.grid, 1, wx.EXPAND | wx.LEFT | wx.RIGHT, 14 + self.indent)

            self.Layout()
            self.parent_listitem.Layout()

            return True
        return False

    def UpdateGrid(self, hits, noChange=False):
        N = BUNDLE_NUM_ROWS * BUNDLE_NUM_COLS
        items_to_add = min(N, self.nrhits)
        if self.nrhits > N:
            items_to_add -= 1

        self.parent.Freeze()
        children = self.grid.GetChildren()
        didChange = len(children) < min(N, self.nrhits)
        if not didChange:
            self._logger.debug("*** BundlePanel.UpdateGrid: total nr items did not change, updating labels only")

            # total nr items did not change
            for i in range(items_to_add):
                link_static_text = children[i].GetWindow() or children[i].GetSizer()
                if link_static_text and getattr(link_static_text, 'SetLabel', False):
                    link_static_text.SetLabel(hits[i].name)
                    link_static_text.action = hits[i]
                else:
                    didChange = True
                    break

            if self.nrhits > N:
                more_caption = '(%s more...)' % (self.nrhits - N + 1)
                link_static_text = children[i + 1].GetWindow() or children[i + 1].GetSizer()
                if link_static_text and getattr(link_static_text, 'SetLabel', False):
                    link_static_text.SetLabel(more_caption)
                    link_static_text.Unbind(wx.EVT_LEFT_UP)
                    link_static_text.Bind(wx.EVT_LEFT_UP, self.OnMoreClick)
                else:
                    didChange = True

        if didChange:
            self._logger.debug("*** BundlePanel.UpdateGrid: something did change rebuilding grid %s %s", len(children), min(N, self.nrhits))

            curRows = len(children) / BUNDLE_NUM_COLS
            newRows = min(self.nrhits / BUNDLE_NUM_COLS, BUNDLE_NUM_ROWS)
            rowsChanged = curRows != newRows

            self.grid.ShowItems(False)
            self.grid.Clear(deleteWindows=True)
            for i in range(items_to_add):
                hit = hits[i]

                new_text = LinkStaticText(self.parent, hit.name, icon=False, icon_align=wx.ALIGN_LEFT, font_increment=self.font_increment, font_colour=BUNDLE_FONT_COLOR)
                new_text.Bind(wx.EVT_LEFT_UP, self.OnBundleLinkClick)
                new_text.SetMinSize((1, -1))
                new_text.action = hit
                self.grid.Add(new_text, 0, wx.EXPAND)

            if self.nrhits > N:
                caption = '(%s more...)' % (self.nrhits - N + 1)

                more_label = LinkStaticText(self.parent, caption, icon=False, icon_align=wx.ALIGN_LEFT, font_increment=self.font_increment, font_colour=BUNDLE_FONT_COLOR)
                more_label.Bind(wx.EVT_LEFT_UP, self.OnMoreClick)
                self.grid.Add(more_label, 0, wx.EXPAND)

            self.parent_listitem.AddEvents(self.grid)

            if self.state != self.COLLAPSED:
                self.ShowGrid(False)

            if rowsChanged and not noChange:
                self.parent_listitem.OnChange()

        self.parent.Thaw()

        return didChange

    def OnEventSize(self, width):
        if width < BUNDLE_GRID_COLLAPSE:
            return self.RebuildGrid(1)

        return self.RebuildGrid(BUNDLE_NUM_COLS)

    def ShowGrid(self, show):
        if show:
            self.grid.ShowItems(True)
        else:
            self.grid.ShowItems(False)

    def UpdateList(self, hits):
        self.hits = hits

        if self.bundlelist:
            self.bundlelist.SetData(hits)
            if self.state == BundlePanel.FULL:
                self.bundlelist.OnLoadAll()

    def ShowList(self, show):
        if self.bundlelist is None and show:
            max_list = BUNDLE_NUM_ROWS * BUNDLE_NUM_COLS
            if len(self.hits) != BUNDLE_NUM_ROWS * BUNDLE_NUM_COLS:
                max_list -= 1

            self.bundlelist = BundleListView(parent=self.parent, list_item_max=max_list)
            self.vsizer.Add(self.bundlelist, 0, wx.EXPAND | wx.BOTTOM, self.indent - 7)  # a 7px spacer is already present

            # SetData does wx.Yield, which could cause a collapse event to be processed within the setdata
            # method. Thus we have to do this after the add to the sizer
            self.bundlelist.SetData(self.hits)

        elif self.bundlelist is not None and not show:
            self.vsizer.Detach(self.bundlelist)
            self.bundlelist.Show(False)
            self.bundlelist.Destroy()
            self.bundlelist = None

    def CollapseExpandedItem(self):
        if self.state != BundlePanel.COLLAPSED:
            self.bundlelist.list.OnCollapse()

    def RefreshDataBundleList(self, key, data):
        if self.bundlelist is not None:
            self.bundlelist.RefreshData(key, data)

    def SetDescription(self, description):
        self.header.SetToolTipString(description)
        self.info_icon.SetToolTipString(description)

    def SetGeneralDescription(self, general_description):
        if general_description:
            general_description = unicode(general_description)
        else:
            general_description = u'Similar'
        self.header.SetLabel(u'%s items (%s):' % (general_description, self.nrhits))

    def SetHits(self, hits, noChange=False):
        self.nrhits = len(hits)

        gridChanged = self.UpdateGrid(hits, noChange)
        self.UpdateList(hits)

        self.Layout()
        return gridChanged

    def ChangeState(self, new_state, doLayout=True):
        if self.state != new_state:
            old_state = self.state
            self.state = new_state

            if new_state == BundlePanel.COLLAPSED:
                self.ShowList(False)
                self.ShowGrid(True)
            else:
                if new_state == BundlePanel.PARTIAL or new_state == BundlePanel.FULL:
                    self.ShowGrid(False)
                    if old_state == BundlePanel.COLLAPSED:
                        self.ShowList(True)

                    if new_state == BundlePanel.FULL and self.bundlelist:
                        self.bundlelist.OnLoadAll()

            statestr = lambda st: ['COLLAPSED', 'PARTIAL', 'FULL'][st]
            self._logger.debug('*** BundlePanel.ChangeState: %s --> %s', statestr(old_state), statestr(new_state))

    def ExpandHit(self, hit):
        id = hit.infohash

        self.bundlelist.ExpandItem(id)
        self.parent_listitem.ShowSelected()

    def OnBundleLinkClick(self, event):
        # do expand
        # self.ExpandAndHideParent()

        staticText = event.GetEventObject()
        action = getattr(staticText, 'action', None)
        if action is not None:
            # Reason for non-persistence (for now) is least-surprise.
            # If the user collapses a bundled listitem, the previously
            # clicked item is still at the same location.
            if action in self.hits:
                self.hits.remove(action)
                self.hits.insert(0, action)

            # self.ChangeState(BundlePanel.PARTIAL)
            # self.ExpandHit(action)
            self.SetBackgroundColour(self.parent.GetBackgroundColour())
            from __init__ import TRIBLER_RED, LIST_HIGHTLIGHT
            event.GetEventObject().SetBackgroundColour(LIST_HIGHTLIGHT)
            for item in self.parent_listitem.bundle:
                if action.infohash == item.infohash:
                    detailspanel = self.guiutility.SetBottomSplitterWindow(TorrentDetails)
                    detailspanel.setTorrent(item.original_data)
                    item.expandedPanel = detailspanel

        def db_callback():
            self.uelog.addEvent(message="Bundler GUI: BundleLink click; %s; %s;" %
                                (self.nrhits, self.parent_listitem.general_description), type=3)
        self.guiutility.frame.guiserver.add_task(db_callback)

    def OnMoreClick(self, event):
        return
        # do expand
        self.ExpandAndHideParent()
        self.ChangeState(BundlePanel.FULL)

        def db_callback():
            self.uelog.addEvent(message="Bundler GUI: More click; %s; %s;" %
                                (self.nrhits, self.parent_listitem.general_description), type=3)
        self.guiutility.frame.guiserver.add_task(db_callback)

    def ExpandAndHideParent(self):
        self.parent.Freeze()

        if not self.parent_listitem.expanded:
            # Make sure the listitem is marked as expanded
            self.parent_listitem.OnClick()

        # but hide the panel
        self.parent_listitem.ShowExpandedPanel(False)
        self.parent.Thaw()

    # Called from GUI to get expanded torrentdetails panel
    def GetExpandedPanel(self):
        if self.bundlelist:
            item = self.bundlelist.GetExpandedItem()
            if item:
                return item.GetExpandedPanel()

    def SetBackgroundColour(self, colour):
        self.parent.Freeze()
        if getattr(self, 'grid', False):
            for sizeritem in self.grid.GetChildren():
                child = sizeritem.GetWindow() or sizeritem.GetSizer()
                if child and getattr(child, 'SetBackgroundColour', False):
                    child.SetBackgroundColour(colour)

        self.parent.Thaw()


class BundleListView(GenericSearchList):

    def __init__(self, parent=None, list_item_max=None):
        self.list_item_max = list_item_max
        columns = [{'name': 'Name', 'width': wx.LIST_AUTOSIZE, 'sortAsc': True, 'icon': 'tree'},
                   {'name': 'Size', 'width': '9em', 'style': wx.ALIGN_RIGHT, 'fmt': format_size},
                   {'type': 'method', 'width': wx.LIST_AUTOSIZE_USEHEADER, 'method': self.CreateRatio, 'name': 'Popularity'},
                   {'type': 'method', 'width': LIST_AUTOSIZEHEADER, 'method': self.CreateDownloadButton}]

        GenericSearchList.__init__(self, columns, LIST_GREY, [7, 7], True, showChange=True, parent=parent)

    def CreateHeader(self, parent):
        # Normally, the column-widths are fixed during this phase
        # Or perhaps easier... just create the simplest header, but don't return it:
        header = ListHeader(parent, self, self.columns)
        header.Destroy()

    def CreateFooter(self, parent):
        pass

    def CreateList(self, parent):
        pass
        # return ExpandableFixedListBody(parent, self, self.columns, self.spacers[0], self.spacers[1], self.singleSelect, self.showChange, list_item_max = self.list_item_max)

    def OnExpand(self, item):
        # Keep only one panel open at all times, thus we make sure the parent is closed
        self.parent.ShowExpandedPanel(False)
        td = TorrentDetails(self.guiutility.frame.splitter_bottom_window, item.original_data, compact=True)
        self.guiutility.SetBottomSplitterWindow(td)
        return True

    def OnCollapseInternal(self, item):
        self.guiutility.frame.top_bg.ClearButtonHandlers()
        self.guiutility.SetBottomSplitterWindow(None)

    def SetFilteredResults(self, nr):
        pass

    def OnChange(self, scrollToTop=False):
        self.parent.OnChange(scrollToTop)

    def ExpandItem(self, id):
        # id == infohash
        self.list.Select(id, raise_event=True)

    def VerticalItemOffset(self, id):
        # id == infohash
        item = self.list.items[id]
        return item.GetPosition()[1]


class ExpandableFixedListBody(FixedListBody):

    def OnChange(self, scrollToTop=False):
        FixedListBody.OnChange(self, scrollToTop)
        self.parent_list.OnChange(scrollToTop)

########NEW FILE########
__FILENAME__ = list_details
# Written by Niels Zeilemaker, Egbert Bouman
import os
import sys
import re
import binascii
from time import time
import logging
import copy
import wx
import imghdr
import tempfile
import shutil

from Tribler.Core.osutils import startfile
from Tribler.Core.simpledefs import DLSTATUS_ALLOCATING_DISKSPACE, \
    DLSTATUS_WAITING4HASHCHECK, DLSTATUS_HASHCHECKING, DLSTATUS_DOWNLOADING, \
    DLSTATUS_SEEDING, DLSTATUS_STOPPED, DLSTATUS_STOPPED_ON_ERROR, \
    DLSTATUS_METADATA, UPLOAD, DOWNLOAD, NTFY_TORRENTS, \
    NTFY_VIDEO_ENDED, DLMODE_VOD
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler
from Tribler.Core.TorrentDef import TorrentDefNoMetainfo
from Tribler.Core.Video.utils import videoextdefaults
from Tribler.Core.Video.VideoUtility import limit_resolution
from Tribler.Core.Video.VideoPlayer import VideoPlayer
from Tribler.TrackerChecking.TorrentChecking import TorrentChecking

from Tribler.community.channel.community import ChannelCommunity

from Tribler.Main.Utility.GuiDBTuples import Torrent, ChannelTorrent, \
    CollectedTorrent, Channel, Playlist
from Tribler.Main.vwxGUI import warnWxThread, forceWxThread, startWorker, \
    GRADIENT_LGREY, GRADIENT_DGREY, THUMBNAIL_FILETYPES, GUI_PRI_DISPERSY, \
    DEFAULT_BACKGROUND, FILTER_GREY, SEPARATOR_GREY, DOWNLOADING_COLOUR, \
    SEEDING_COLOUR, TRIBLER_RED, LIST_LIGHTBLUE, format_time
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.widgets import LinkStaticText, EditText, \
    SelectableListCtrl, _set_font, BetterText as StaticText, \
    MaxBetterText, NotebookPanel, SimpleNotebook, ProgressButton, \
    FancyPanel, TransparentText, LinkText, StaticBitmaps, \
    TransparentStaticBitmap, Graph, ProgressBar


class AbstractDetails(FancyPanel):

    @warnWxThread
    def _create_tab(self, notebook, tabname, header=None, spacer=0, border=0):
        panel = wx.lib.scrolledpanel.ScrolledPanel(notebook)

        def OnChange():
            panel.Layout()
            panel.SetupScrolling(rate_y=5, scroll_x=False)
        panel.OnChange = OnChange

        themeColour = notebook.GetThemeBackgroundColour()
        if themeColour.IsOk():
            panel.SetBackgroundColour(themeColour)

        notebook.AddPage(panel, tabname)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        panel.SetSizer(vSizer)

        if border:
            vSizer2 = wx.BoxSizer(wx.VERTICAL)
            vSizer.Add(vSizer2, 1, wx.EXPAND | wx.ALL, border)
            vSizer = vSizer2

        if header:
            header = self._add_header(panel, vSizer, header, spacer)
            panel.SetLabel = header.SetLabel

        return panel, vSizer

    @warnWxThread
    def _add_header(self, panel, sizer, header, spacer=0):
        header = wx.StaticText(panel, -1, header)
        _set_font(header, fontweight=wx.FONTWEIGHT_BOLD)

        sizer.Add(header, 0, wx.LEFT | wx.BOTTOM, spacer)
        return header

    @warnWxThread
    def _add_row(self, parent, sizer, name, value, spacer=0, flags=wx.EXPAND):
        nametext = name
        if name != None:
            nametext = wx.StaticText(parent, -1, name)
            _set_font(nametext, fontweight=wx.FONTWEIGHT_BOLD)

            sizer.Add(nametext, 0, wx.LEFT, spacer)

        if value != None:
            if isinstance(value, basestring):
                try:
                    value = MaxBetterText(parent, unicode(value), maxLines=3, name=name)
                except:
                    value = MaxBetterText(parent, value.decode('utf-8', 'ignore'), maxLines=3, name=name)
                value.SetMinSize((1, -1))
            sizer.Add(value, 0, flags | wx.LEFT, spacer)

        return nametext, value

    @warnWxThread
    def _add_subheader(self, parent, sizer, title, subtitle):
        title = wx.StaticText(parent, -1, title)
        _set_font(title, fontweight=wx.FONTWEIGHT_BOLD)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(title)
        vSizer.Add(wx.StaticText(parent, -1, subtitle))

        sizer.Add(vSizer)
        return vSizer


class TorrentDetails(AbstractDetails):
    FINISHED = 6
    FINISHED_INACTIVE = 5

    INCOMPLETE = 4
    INCOMPLETE_INACTIVE = 3

    VOD = 2
    INACTIVE = 1

    @warnWxThread
    def __init__(self, parent):
        self._logger = logging.getLogger(self.__class__.__name__)

        FancyPanel.__init__(self, parent)
        self.Hide()

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.uelog = UserEventLogDBHandler.getInstance()

        self.parent = parent
        self.torrent = Torrent('0', '0', '0', '0', '', '', 0, 0, 0, 0, 0, None)
        self.state = -1
        self.timeouttimer = None

        self.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)
        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.notebook = SimpleNotebook(self, style=wx.NB_NOPAGETHEME, name="TorrentDetailsNotebook")
        self.notebook.Bind(wx.EVT_NOTEBOOK_PAGE_CHANGED, self.OnChange)
        self.vSizer.Add(self.notebook, 1, wx.EXPAND)
        self.SetSizer(self.vSizer)
        self.Layout()

        self.createMessagePanel()
        self.notebook.SetMessagePanel(self.messagePanel)

        self.doMark = self.guiutility.frame.selectedchannellist.OnMarkTorrent
        self.doSave = self.guiutility.frame.selectedchannellist.OnSaveTorrent
        self.canEdit = False
        self.canComment = False
        self.canMark = False
        self.showInfohash = False
        self.markWindow = None
        self.markings = None
        self.myMark = None
        self.isEditable = {}

        self.guiutility.library_manager.add_download_state_callback(self.OnRefresh)

        self.createAllTabs()

        self.Show()
        self.DownloadStarted = lambda: None

    @forceWxThread
    def setTorrent(self, torrent):
        if torrent:
            if self.timeouttimer:
                self.timeouttimer.Stop()
                self.timeouttimer = None

            # Intermediate update
            self.messageText.SetLabel('Loading details, please wait.\nTribler first needs to fetch the torrent file before this information can be accessed.')
            self.messageGauge.Show(False)
            self.messageButton.Show(False)
            self.messagePanel.Layout()
            self.torrent = torrent
            self.showTorrent(self.torrent)

            filename = self.guiutility.torrentsearch_manager.getCollectedFilename(self.torrent, retried=True)
            if filename:
                self.guiutility.torrentsearch_manager.loadTorrent(self.torrent, callback=self.showTorrent)
            else:
                def doGui(delayedResult):
                    requesttype = delayedResult.get()
                    if requesttype:
                        self.messageText.SetLabel('Loading details, please wait. The torrent file is requested %s.\nTribler first needs to fetch the torrent file before this information can be accessed.' % requesttype)
                        self.messageGauge.Show(True)
                        self.messageGauge.Pulse()
                        self.messagePanel.Layout()
                    self.timeouttimer = wx.CallLater(10000, timeout) if not self.guiutility.frame.librarylist.IsShownOnScreen() else None

                def timeout():
                    self.messageText.SetLabel("Failed loading torrent.\nPlease click retry or wait to allow other peers to respond.")
                    self.messageGauge.Show(False)
                    self.messageButton.Show(True)
                    self.messagePanel.Layout()
                startWorker(doGui, self.guiutility.torrentsearch_manager.loadTorrent, wargs=(self.torrent,), wkwargs={'callback': self.showTorrent})

    @forceWxThread
    def showTorrent(self, torrent, showTab=None):
        if self.torrent.infohash != torrent.infohash:
            return

        if isinstance(torrent, CollectedTorrent):
            GUIUtility.getInstance().frame.top_bg.AddCollectedTorrent(torrent)

        self.state = -1
        self.torrent = torrent

        isChannelTorrent = isinstance(self.torrent, ChannelTorrent) or (isinstance(self.torrent, CollectedTorrent) and isinstance(self.torrent.torrent, ChannelTorrent))
        if isChannelTorrent and self.torrent.hasChannel():
            # This is a db call
            state, iamModerator = self.torrent.channel.getState()

            if isinstance(self, LibraryDetails):
                self.canMark = state >= ChannelCommunity.CHANNEL_SEMI_OPEN
            else:
                self.canEdit = state >= ChannelCommunity.CHANNEL_OPEN
                self.canComment = state >= ChannelCommunity.CHANNEL_SEMI_OPEN
        else:
            self.canEdit = False
            self.canComment = False
            self.canMark = False

        self.updateAllTabs()

        self._Refresh(self.torrent.ds)

    def createMessagePanel(self):
        # Create messagePanel
        self.messagePanel = FancyPanel(self.notebook)
        self.messagePanel.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)
        self.messageIcon = TransparentStaticBitmap(self.messagePanel, -1, wx.ArtProvider.GetBitmap(wx.ART_INFORMATION))
        self.messageText = TransparentText(self.messagePanel, -1, "Loading details, please wait.\nTribler first needs to fetch the torrent file before this information can be accessed.")
        self.messageGauge = wx.Gauge(self.messagePanel, -1, size=(100, 15))
        self.messageButton = wx.Button(self.messagePanel, -1, "Retry")
        self.messageButton.Bind(wx.EVT_BUTTON, lambda evt: self.setTorrent(self.torrent))
        _set_font(self.messageText, size_increment=2, fontweight=wx.FONTWEIGHT_NORMAL)
        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.AddStretchSpacer()
        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(self.messageIcon, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 15)
        hSizer.Add(self.messageText, 0, wx.ALL, 3)
        vSizer.Add(hSizer, 0, wx.ALIGN_CENTER_VERTICAL | wx.ALIGN_CENTER_HORIZONTAL)
        vSizer.Add(self.messageGauge, 0, wx.ALIGN_CENTER_HORIZONTAL | wx.TOP, 10)
        vSizer.Add(self.messageButton, 0, wx.ALIGN_CENTER_HORIZONTAL | wx.TOP, 10)
        vSizer.AddStretchSpacer()
        self.messageGauge.Show(False)
        self.messageButton.Show(False)
        self.messagePanel.SetSizer(vSizer)

    def createAllTabs(self):
        self.Freeze()
        self.createDetailsTab()
        self.createFilesTab()
        self.createEditTab()
        self.createCommentsTab()
        self.createModificationsTab()
        self.createTrackersTab()
        self.Thaw()
        self.Layout()

        showTab = getattr(self.parent, self.__class__.__name__ + '_tab', None) if self.parent else None
        if showTab:
            for i in range(self.notebook.GetPageCount()):
                if self.notebook.GetPageText(i) == showTab:
                    self.notebook.SetSelection(i)
                    break
        else:
            self.notebook.SetSelection(0)

    def createDetailsTab(self):
        def OnToggleInfohash(event):
            self.showInfohash = not self.showInfohash
            self.updateDetailsTab()

        self.detailsTab, self.detailsSizer = self._create_tab(self.notebook, 'Torrent details', border=10)
        self.detailsTab.SetBackgroundColour(wx.WHITE)
        self.detailsTab.Bind(wx.EVT_LEFT_DCLICK, OnToggleInfohash)
        self.Freeze()

        fgSizer = wx.FlexGridSizer(0, 2, 3, 10)
        fgSizer.AddGrowableCol(1)
        titles = ['Name', 'Description', 'Status', 'Type', 'Uploaded', 'Filesize', 'Health']
        for title in titles:
            control1, control2 = self._add_row(self.detailsTab, fgSizer, title, '')
            setattr(self, title.lower() + '_title', control1)
            setattr(self, title.lower(), control2)

        # Add piece progress
        class tmp_object():
            def __init__(self, data, original_data):
                self.data = data
                self.original_data = original_data
        self.item = tmp_object(['', [0, 0], [0, 0], 0, 0], self.torrent)
        self.downloaded = ProgressPanel(self.detailsTab, self.item, show_bar=True, show_status=False)
        self.downloaded.SetMinSize((-1, 25))
        self.detailsSizer.Add(self.downloaded, 0, wx.EXPAND | wx.BOTTOM, 10)

        # Add infohash
        textCtrl = wx.TextCtrl(self.detailsTab, -1, '')
        textCtrl.SetEditable(False)
        self.infohash_title, self.infohash = self._add_row(self.detailsTab, fgSizer, "Infohash", textCtrl)

        # Add associated channel
        ulfont = self.GetFont()
        ulfont.SetUnderlined(True)
        link = LinkText(self.detailsTab, '', fonts=[self.GetFont(), ulfont], colours=[self.GetForegroundColour(), wx.RED])
        link.SetBackgroundColour(self.detailsTab.GetBackgroundColour())
        link.Bind(wx.EVT_LEFT_UP, lambda evt: self.torrent.get('channel') and self.guiutility.showChannel(self.torrent.channel))
        self.channel_title, self.channel = self._add_row(self.detailsTab, fgSizer, 'Channel', link, flags=0)

        # Add thumbnails
        self.thumbnails = StaticBitmaps(self.detailsTab, -1)
        self.thumbnails.SetBackgroundColour(self.detailsTab.GetBackgroundColour())
        self.thumbnails.SetBitmaps([])
        tSizer = wx.BoxSizer(wx.HORIZONTAL)
        tSizer.Add(fgSizer, 1, wx.ALIGN_LEFT | wx.ALIGN_TOP | wx.EXPAND)
        tSizer.Add(self.thumbnails, 0, wx.ALIGN_RIGHT | wx.ALIGN_TOP | wx.EXPAND)
        self.detailsSizer.Add(tSizer, 1, wx.EXPAND)
        self.thumbnails.Show(False)

        self.no_thumb_bitmap = wx.StaticBitmap(self.detailsTab, -1)
        bitmap = GuiImageManager.getInstance().drawBitmap("no-thumbnail",
            (125, 100), self.no_thumb_bitmap.GetFont())
        self.no_thumb_bitmap.SetBitmap(bitmap)
        self.upload_thumbs_btn = wx.Button(self.detailsTab, -1, label=u"Upload thumbnail")
        self.upload_thumbs_btn.SetMaxSize((-1, 30))
        vsizer = wx.BoxSizer(wx.VERTICAL)
        vsizer.Add(self.no_thumb_bitmap, 1, wx.EXPAND)
        vsizer.Add(self.upload_thumbs_btn, 0, wx.EXPAND)
        tSizer.Add(vsizer, 0, wx.EXPAND)
        self.upload_thumbs_btn.Bind(wx.EVT_BUTTON, self.OnUploadThumbsButtonClick)
        self.upload_thumbs_btn.Show(False)

        # Add 'Mark this torrent' option
        self.marking_hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.marking_vSizer = wx.BoxSizer(wx.VERTICAL)
        self.marking_vSizer.Add(wx.StaticLine(self.detailsTab, -1, style=wx.LI_HORIZONTAL), 0, wx.TOP | wx.BOTTOM | wx.EXPAND, 5)
        self.marking_vSizer.Add(self.marking_hSizer, 1, wx.EXPAND)
        self.markicon = GuiImageManager.getInstance().getBitmap(self, u"arrow", self.GetBackgroundColour(), state=0).ConvertToImage().Rotate90(False).ConvertToBitmap()
        self.markicon = wx.StaticBitmap(self.detailsTab, -1, self.markicon)
        ulfont = self.GetFont()
        ulfont.SetUnderlined(True)
        self.marktoggle = LinkText(self.detailsTab, 'Mark this torrent', fonts=[self.GetFont(), ulfont], colours=[self.GetForegroundColour(), wx.RED])
        self.marktoggle.SetBackgroundColour(self.detailsTab.GetBackgroundColour())
        self.marktoggle.Bind(wx.EVT_LEFT_UP, self.OnMark)
        self.marking_hSizer.AddStretchSpacer()
        self.marking_hSizer.Add(self.markicon, 0, wx.CENTER | wx.RIGHT, 3)
        self.marking_hSizer.Add(self.marktoggle)
        self.detailsSizer.Add(self.marking_vSizer, 0, wx.EXPAND)
        self.marking_vSizer.ShowItems(False)

        self.detailsTab.OnChange()
        self.detailsTab.Layout()

        self.Thaw()

    def createFilesTab(self):
        self.filesTab = wx.Panel(self.notebook)
        self.filesTab.SetBackgroundColour(wx.WHITE)

        self.filesList = SelectableListCtrl(self.filesTab)
        self.filesList.InsertColumn(0, 'Name')
        self.filesList.InsertColumn(1, 'Size', wx.LIST_FORMAT_RIGHT, 100)

        if isinstance(self, LibraryDetails):
            self.filesList.InsertColumn(2, 'Priority', wx.LIST_FORMAT_RIGHT)
            self.filesList.InsertColumn(3, 'Status', wx.LIST_FORMAT_RIGHT)

        self.filesList.Bind(wx.EVT_LEFT_DCLICK, self.OnDoubleClick)
        self.filesList.Bind(wx.EVT_LIST_ITEM_SELECTED, self.OnFilesSelected)
        self.filesList.Bind(wx.EVT_LIST_ITEM_DESELECTED, self.OnFilesSelected)

        self.il = wx.ImageList(16, 16)
        self.play_img = self.il.Add(GuiImageManager.getInstance().getImage(u"file_video.png"))
        self.file_img = self.il.Add(GuiImageManager.getInstance().getImage(u"file_default.png"))
        self.filesList.SetImageList(self.il, wx.IMAGE_LIST_SMALL)

        self.filesList.setResizeColumn(0)
        # Calling SetColumnWidth seems to cause Refresh issues in list_body
        # self.filesList.SetColumnWidth(1, wx.LIST_AUTOSIZE)  # autosize only works after adding rows
        self.filesList.SetMinSize((1, -1))

        self.filesSizer = wx.BoxSizer(wx.VERTICAL)
        self.filesList.Bind(wx.EVT_LIST_ITEM_RIGHT_CLICK, self.OnRightUp)
        self.filesSizer.Add(self.filesList, 1, wx.EXPAND | wx.LEFT | wx.TOP | wx.BOTTOM, 10)
        self.filesTab.SetSizer(self.filesSizer)
        self.notebook.AddPage(self.filesTab, "Files")

    def createEditTab(self):
        self.editTab, self.editSizer = self._create_tab(self.notebook, 'Edit', border=10)
        self.editTab.SetBackgroundColour(wx.WHITE)

        vSizer = wx.FlexGridSizer(0, 2, 3, 10)
        vSizer.AddGrowableCol(1)
        vSizer.AddGrowableRow(1)

        self.isEditable['name'] = EditText(self.editTab, '')
        self.isEditable['description'] = EditText(self.editTab, '', True)
        self.isEditable['description'].SetMinSize((1, 1))

        self._add_row(self.editTab, vSizer, "Name", self.isEditable['name'])
        self._add_row(self.editTab, vSizer, "Description", self.isEditable['description'])

        def save(event):
            self.doSave(self.torrent.channel, self)

            button = event.GetEventObject()
            button.Enable(False)
            wx.CallLater(5000, button.Enable, True)

        self.editButton = wx.Button(self.editTab, -1, "Save")
        self.editButton.Bind(wx.EVT_BUTTON, save)
        vSizer.Add((-1, -1), 0, wx.ALIGN_RIGHT)
        vSizer.Add(self.editButton, 0, wx.ALIGN_RIGHT)
        self.editSizer.Add(vSizer, 1, wx.EXPAND)

    def createCommentsTab(self):
        from Tribler.Main.vwxGUI.channel import CommentList
        self.commentList = NotebookPanel(self.notebook)
        self.commentList.SetList(CommentList(self.commentList, self.parent, canReply=True, quickPost=True, horizontal=True, noheader=True))
        def updateTitle(nrcomments):
            for i in range(self.notebook.GetPageCount()):
                if self.notebook.GetPageText(i).startswith('Comments'):
                    self.notebook.SetPageText(i, "Comments(%d)" % nrcomments)
        self.commentList.SetNrResults = updateTitle
        self.notebook.AddPage(self.commentList, 'Comments')

    def createModificationsTab(self):
        from channel import ModificationList
        self.modificationList = NotebookPanel(self.notebook)
        self.modificationList.SetList(ModificationList(self.modificationList, self.canEdit))
        def updateTitle(nrmodifications):
            for i in range(self.notebook.GetPageCount()):
                if self.notebook.GetPageText(i).startswith('Modifications'):
                    self.notebook.SetPageText(i, "Modifications(%d)" % nrmodifications)
        self.modificationList.SetNrResults = updateTitle
        self.notebook.AddPage(self.modificationList, 'Modifications', tab_colour=wx.WHITE)

    def createTrackersTab(self):
        self.trackerTab, self.trackerSizer = self._create_tab(self.notebook, "Trackers", border=10)
        self.trackerTab.SetBackgroundColour(wx.WHITE)

    def updateAllTabs(self):
        self.updateDetailsTab()
        self.updateFilesTab()
        self.updateEditTab()
        self.updateCommentsTab()
        self.updateModificationsTab()
        self.updateTrackersTab()

    def OnUploadThumbsButtonClick(self, event):
        type_str = "Pictures (*.png, *.jpeg, *jpg)|*.png;*.jpeg;*.jpg"
        dialog = wx.FileDialog(self, "Upload Thumbnails", wildcard=type_str,
            style=wx.FD_OPEN | wx.FD_FILE_MUST_EXIST | wx.FD_MULTIPLE)
        extra_info = {'thumbnail-tempdir': None, 'thumbnail-file-list': []}
        if dialog.ShowModal() == wx.ID_OK:
            path_list = dialog.GetPaths()
            tempdir = tempfile.mkdtemp(suffix="thumbs", prefix="tribler")
            extra_info['thumbnail-tempdir'] = tempdir
            thumb_idx = 0
            for thumb_path in path_list:
                if not os.path.exists(thumb_path) or not os.path.isfile(thumb_path):
                    continue
                type_check = imghdr.what(thumb_path)
                if type_check not in ('png', 'jpeg'):
                    continue
                thumb_file_name = "thumbnail-%d.%s" % (thumb_idx, type_check)
                dst = os.path.join(tempdir, thumb_file_name)
                shutil.copy(thumb_path, dst)
                thumb_idx += 1
                extra_info['thumbnail-file-list'].append(thumb_file_name)
            if thumb_idx > 0:
                self.guiutility.torrentsearch_manager.createMetadataModificationFromDef(
                    None, None, extraInfo=extra_info, guitorrent=self.torrent)

        dialog.Destroy()

    def updateDetailsTab(self):
        self.Freeze()

        todo = []
        todo.append((self.name, self.torrent.name))
        todo.append((self.description, ''))
        todo.append((self.type, ', '.join(self.torrent.categories).capitalize() if isinstance(self.torrent.categories, list) else 'Unknown'))
        todo.append((self.uploaded, self.torrent.formatCreationDate() if hasattr(self.torrent, 'formatCreationDate') else ''))
        todo.append((self.filesize, '%s in %d file(s)' % (self.guiutility.utility.size_format(self.torrent.length), len(self.torrent.files)) if hasattr(self.torrent, 'files') else '%s' % self.guiutility.utility.size_format(self.torrent.length)))

        for control, new_value in todo:
            if control.GetLabel() != new_value:
                control.SetLabel(new_value)

        # Toggle piece progress
        self.downloaded.Update(torrent=self.torrent)
        self.downloaded.Show(bool(self.torrent.state))

        # Hide description
        self.description_title.Show(False)
        self.description.Show(False)
        self._updateDescription()

        # Toggle status
        show_status = bool(self.torrent.state) or bool(self.torrent.magnetstatus)
        self.status_title.Show(show_status)
        self.status.Show(show_status)

        # Toggle infohash
        if self.showInfohash:
            self.infohash.SetValue(self.torrent.infohash_as_hex)
        self.infohash_title.Show(self.showInfohash)
        self.infohash.Show(self.showInfohash)

        # Toggle associated channel
        show_channel = bool(self.torrent.get('channel', False))
        if show_channel:
            self.channel.SetLabel(self.torrent.channel.name)
        self.channel_title.Show(show_channel)
        self.channel.Show(show_channel)

        # Toggle thumbnails
        thumb_dir = os.path.join(self.guiutility.utility.session.get_torrent_collecting_dir(), 'thumbs-' + binascii.hexlify(self.torrent.infohash))
        thumb_files = [os.path.join(dp, fn) for dp, _, fns in os.walk(thumb_dir) for fn in fns if os.path.splitext(fn)[1] in THUMBNAIL_FILETYPES]
        show_thumbnails = bool(thumb_files)
        self.thumbnails.Show(show_thumbnails)
        self.no_thumb_bitmap.Show(not show_thumbnails)
        self.upload_thumbs_btn.Show(not show_thumbnails)
        if show_thumbnails:
            bmps = [wx.Bitmap(thumb, wx.BITMAP_TYPE_ANY) for thumb in thumb_files[:4]]
            res = limit_resolution(bmps[0].GetSize(), (175, 175)) if bmps else None
            bmps = [bmp.ConvertToImage().Scale(*res, quality=wx.IMAGE_QUALITY_HIGH).ConvertToBitmap() for bmp in bmps if bmp.IsOk()] if res else []
            self.thumbnails.SetBitmaps(bmps)

        # Toggle 'Mark this torrent' option
        self.marking_vSizer.ShowItems(self.canComment)

        self.UpdateHealth()
        self.detailsTab.OnChange()
        self.detailsTab.Layout()

        self.Thaw()

    def _updateDescription(self):
        def do_db():
            # try metadata
            metadata = self.torrent.get('metadata', None)
            if metadata:
                return metadata.get('description', '')

        def set_description(description):
            if not description:
                if self.canEdit:
                    description = 'No description yet, be the first to add a description.'
                else:
                    description = ''

            # Toggle description
            self.description.SetLabel(description)

            show_description = self.canEdit or bool(description)
            self.description_title.Show(show_description)
            self.description.Show(show_description)

        the_description = self.torrent.get('description', '')
        if not the_description:
            startWorker(lambda delayedResult: set_description(delayedResult.get()), do_db)
        else:
            set_description(the_description)

    def updateFilesTab(self):
        self.filesList.DeleteAllItems()

        if hasattr(self.torrent, 'files') and len(self.torrent.files) > 0:
            self.notebook.ShowMessageOnPage(self.notebook.GetIndexFromText('Files'), False)
            files = copy.copy(self.torrent.files)
            keywords = ' | '.join(self.guiutility.current_search_query)

            def sort_by_keywords(a, b):
                a_match = re.search(keywords, a[0].lower())
                b_match = re.search(keywords, b[0].lower())
                if a_match and not b_match:
                    return -1
                if b_match and not a_match:
                    return 1
                return cmp(a[0], b[0])

            files.sort(sort_by_keywords)

            for filename, size in files:
                try:
                    pos = self.filesList.InsertStringItem(sys.maxsize, filename)
                except:
                    try:
                        pos = self.filesList.InsertStringItem(sys.maxsize, filename.decode('utf-8', 'ignore'))
                    except:
                        self._logger.error("Could not format filename %s", self.torrent.name)
                self.filesList.SetItemData(pos, pos)

                size = "%.1f MB" % (size / 1048576.0)
                self.filesList.SetStringItem(pos, 1, size)

                if filename in self.torrent.videofiles:
                    self.filesList.SetItemColumnImage(pos, 0, self.play_img)
                else:
                    self.filesList.SetItemColumnImage(pos, 0, self.file_img)
        else:
            self.notebook.ShowMessageOnPage(self.notebook.GetIndexFromText('Files'), True)

    def updateEditTab(self):
        if self.canEdit:
            self.isEditable['name'].SetValue(self.torrent.name)
            self.isEditable['description'].SetValue(self.torrent.description or '')
        self.editButton.Enable(self.canEdit)
        self.notebook.ShowPage(self.notebook.GetIndexFromText('Edit'), self.canEdit)

    def updateCommentsTab(self):
        if self.canComment:
            commentManager = self.commentList.GetManager()
            commentManager.SetIds(self.torrent.channel, channeltorrent=self.torrent)
            commentManager.refresh()
        self.notebook.ShowPage(self.notebook.GetIndexFromText('Comments'), self.canComment)

    def updateModificationsTab(self):
        show_modifications = self.canEdit or bool(self.torrent.get('description', ''))
        if show_modifications:
            modificationManager = self.modificationList.GetManager()
            modificationManager.SetIds(self.torrent)
            modificationManager.refresh()
        self.notebook.ShowPage(self.notebook.GetIndexFromText('Modifications'), show_modifications)

    def updateTrackersTab(self):
        self.trackerSizer.Clear(deleteWindows=True)
        collected_trackers = hasattr(self.torrent, 'trackers')
        notcollected_trackers = hasattr(self.torrent, 'torrent') and hasattr(self.torrent.torrent, 'trackers')
        if collected_trackers or notcollected_trackers:
            self.notebook.ShowMessageOnPage(self.notebook.GetIndexFromText('Trackers'), False)
            if self.torrent.trackers and len(self.torrent.trackers) > 0:
                for tracker in (self.torrent.trackers if collected_trackers else self.torrent.torrent.trackers):
                    if isinstance(tracker, basestring):
                        self._add_row(self.trackerTab, self.trackerSizer, None, tracker)
                self.trackerSizer.Layout()
        else:
            self.notebook.ShowMessageOnPage(self.notebook.GetIndexFromText('Trackers'), True)

    @warnWxThread
    def ShowPanel(self, newState=None):
        if getattr(self, 'notebook', False):
            if newState is None:
                newState = self._GetState()

            if self.state != newState:
                self.state = newState

                if newState in [TorrentDetails.FINISHED, TorrentDetails.FINISHED_INACTIVE]:
                    self.torrent._progress = 1

        else:
            # Additionally called by database event, thus we need to check if sizer exists(torrent is downloaded).
            wx.CallAfter(self.ShowPanel, newState)

    @warnWxThread
    def OnChange(self, event):
        page = event.GetSelection()

        title = self.notebook.GetPageText(page)
        if title.startswith('Comments'):
            self.commentList.Show()
            self.commentList.SetupScrolling()
            self.commentList.SetFocus()

        elif title.startswith('Modifications'):
            self.modificationList.Show()
            self.modificationList.SetupScrolling()
            self.modificationList.SetFocus()

        setattr(self.parent, self.__class__.__name__ + '_tab', title)

        event.Skip()

    def OnCommentCreated(self, infohash):
        if self.torrent.infohash == infohash and self.canComment:
            manager = self.commentList.GetManager()
            manager.new_comment()

    def OnModificationCreated(self, channeltorrent_id):
        if self.canEdit:
            manager = self.modificationList.GetManager()
            manager.new_modification()

    def OnMarkingCreated(self, channeltorrent_id):
        if self.torrent.get('channeltorrent_id', False) == channeltorrent_id:
            self.UpdateMarkings()

    def UpdateMarkings(self):
        if self.torrent.get('channeltorrent_id', False):
            startWorker(self.ShowMarkings, self.guiutility.channelsearch_manager.getTorrentMarkings, wargs=(self.torrent.channeltorrent_id,), priority=GUI_PRI_DISPERSY)

    @warnWxThread
    def ShowMarkings(self, delayedResult):
        markings = delayedResult.get()
        if len(markings) > 0:
            msg = 'This torrent is marked as:'
            for marktype, nr, myMark in markings:
                msg += ' %s (%d)' % (marktype, nr)
                if myMark:
                    self.myMark = marktype

            # see if we are updating
            if not self.markings:
                self.markings = MaxBetterText(self.detailsTab, unicode(msg), maxLines=3)
                self.markingSizer.Insert(0, self.markings)
            else:
                self.markings.SetLabel(msg)

            self.detailsSizer.Layout()

    def GetChanged(self):
        newValues = {}
        for key, editable in self.isEditable.iteritems():
            newValue = editable.GetChanged()
            if newValue:
                newValues[key] = newValue
        return newValues

    def Saved(self):
        for editable in self.isEditable.values():
            editable.Saved()

    @warnWxThread
    def OnDrag(self, event):
        if event.LeftIsDown():
            filename = self.guiutility.torrentsearch_manager.getCollectedFilename(self.torrent)
            if filename:
                tdo = wx.FileDataObject()
                tdo.AddFile(filename)

                tds = wx.DropSource(self)
                tds.SetData(tdo)
                tds.DoDragDrop(True)

    @warnWxThread
    def OnDoubleClick(self, event):
        selected = self.filesList.GetFirstSelected()
        playable_files = self.torrent.videofiles

        if selected != -1:
            selected_file = self.filesList.GetItemText(selected)
            if selected_file in playable_files:
                self.guiutility.library_manager.playTorrent(self.torrent.infohash, selected_file)

            elif self.torrent.progress == 1:  # not playable, but are we complete?
                file = self._GetPath(selected_file)
                if os.path.isfile(file):
                    startfile(file)

    @warnWxThread
    def OnRightUp(self, event):
        if not self.torrent or not self.torrent.ds or not self.torrent.ds.download:
            return
        download = self.torrent.ds.download

        selection = []
        index = self.filesList.GetFirstSelected()
        selection.append(index)
        while len(selection) != self.filesList.GetSelectedItemCount():
            index = self.filesList.GetNextSelected(index)
            selection.append(index)

        selection = set([self.filesList.GetItem(index, 0).GetText() for index in selection])
        selected_files = set(download.get_selected_files()) or set(download.get_def().get_files_as_unicode())

        selected_files_includable = selection - selected_files
        selected_files_excludable = selection & selected_files

        if not selected_files_includable and not selected_files_excludable:
            return

        menu = wx.Menu()

        menuitems = [("Include", [], False), ("Exclude", [], False)]

        if selected_files_includable:
            files = list(selected_files | selected_files_includable)
            menuitems[0] = ("Include", files, True)

        if selected_files_excludable:
            files = list(selected_files - selected_files_excludable)
            # Don't allow excluding everything
            if files:
                menuitems[1] = ("Exclude", files, True)

        for label, files, enabled in menuitems:
            itemid = wx.NewId()
            menu.Append(itemid, label)
            menu.Enable(itemid, enabled)
            if enabled:
                menu.Bind(wx.EVT_MENU, lambda evt, d=download, f=files: self.guiutility.frame.modifySelection(d, f), id=itemid)

        self.PopupMenu(menu, self.ScreenToClient(wx.GetMousePosition()))
        menu.Destroy()

        self.old_progress = None

    @warnWxThread
    def _GetPath(self, file=None):
        ds = self.torrent.ds
        if ds:
            destdirs = ds.get_download().get_dest_files()
            if file:
                for filenameintorrent, path in destdirs:
                    if filenameintorrent == file:
                        return path

            return os.path.commonprefix([os.path.split(path)[0] for _, path in destdirs])

    @warnWxThread
    def OnFilesSelected(self, event):
        pass

    @warnWxThread
    def OnClick(self, event):
        label = event.GetEventObject()
        if label.target == 'my_files':
            self.guiutility.frame.actlist.selectTab('my_files')
            self.guiutility.ShowPage('my_files', self.torrent.infohash)

        else:
            self.guiutility.showChannel(self.torrent.channel)

    @warnWxThread
    def OnMark(self, event):
        menu = wx.Menu()
        itemid = wx.NewId()
        for mark in ['Good', 'High-Quality', 'Mid-Quality', 'Low-Quality', 'Corrupt', 'Fake', 'Spam']:
            itemid = wx.NewId()
            if self.myMark:
                menu.AppendRadioItem(itemid, mark)
                menu.Check(itemid, self.myMark == mark)
            else:
                menu.Append(itemid, mark)
            menu.Bind(wx.EVT_MENU, lambda x, selected=mark: self.doMark(self.torrent.channel, self.torrent.infohash, unicode(selected)), id=itemid)

        pos = wx.Point(self.markicon.GetPosition().x, self.marktoggle.GetPosition().y + self.marktoggle.GetSize().y)
        self.detailsTab.PopupMenu(menu, pos)
        menu.Destroy()

    @warnWxThread
    def RefreshData(self, data):
        if isinstance(self.torrent, Torrent):
            curTorrent = self.torrent
        else:
            curTorrent = self.torrent.torrent

        if hasattr(data[2], "bundle"):
            newTorrent = data[2]['bundle'][0]
        else:
            newTorrent = data[2]

        if curTorrent.infohash != newTorrent.infohash:
            return

        self.torrent.updateSwarminfo(newTorrent.swarminfo)
        self.torrent.update_torrent_id(newTorrent.torrent_id)
        del self.torrent.status

        if not curTorrent.exactCopy(newTorrent):
            # replace current torrent
            curTorrent.swift_hash = newTorrent.swift_hash
            curTorrent.swift_torrent_hash = newTorrent.swift_torrent_hash
            curTorrent.torrent_file_name = newTorrent.torrent_file_name

            curTorrent.name = newTorrent.name
            curTorrent.length = newTorrent.length
            curTorrent.category_id = newTorrent.category_id
            curTorrent.status_id = newTorrent.status_id

            self.updateDetailsTab()
            if self.canEdit:
                if not self.isEditable['name'].IsChanged():
                    self.isEditable['name'].SetValue(curTorrent.name)

                if not self.isEditable['description'].IsChanged():
                    self.isEditable['description'].SetValue(curTorrent.description or '')

    @forceDBThread
    def UpdateHealth(self):
        # touch swarminfo property
        _, _, last_check = self.torrent.swarminfo

        if getattr(self.torrent, 'trackers', None) and len(self.torrent.trackers) > 0:
            diff = time() - last_check

            if diff > 1800:
                TorrentChecking.getInstance().addGuiRequest(self.torrent)
                self.ShowHealth(True)
            else:
                self.ShowHealth(False)
        else:
            self.ShowHealth(False, ', no trackers found')

    @forceWxThread
    def ShowHealth(self, updating, no_update_reason=''):
        if isinstance(self.torrent, CollectedTorrent):
            updating = ', updating now' if updating else no_update_reason

            num_seeders, num_leechers, last_check = self.torrent.swarminfo
            diff = time() - last_check

            if num_seeders < 0 and num_leechers < 0:
                if self.torrent.status == 'good':
                    self.health.SetLabel("Unknown, but found peers in the DHT")
                else:
                    self.health.SetLabel("Unknown" + updating)
            else:
                if diff < 5:
                    self.health.SetLabel("%s seeders, %s leechers (current)" % (num_seeders, num_leechers))
                else:
                    updated = self.guiutility.utility.eta_value(diff, 2)
                    if updated == '<unknown>':
                        self.health.SetLabel("%s seeders, %s leechers" % (num_seeders, num_leechers) + updating)
                    else:
                        self.health.SetLabel("%s seeders, %s leechers (updated %s ago%s)" % (num_seeders, num_leechers, updated, updating))

        else:
            self.health.SetLabel("Unknown")

    def OnRefresh(self, dslist, magnetlist):
        found = False

        for ds in dslist:
            if self.torrent.addDs(ds):
                found = True

        self.torrent.magnetstatus = magnetlist.get(self.torrent.infohash, None)

        if not found:
            self.torrent.clearDs()
        self._Refresh()

    @warnWxThread
    def _Refresh(self, ds=None):
        if ds:
            self.torrent.addDs(ds)

        state = self._GetState()

        if state != self.state:
            self.ShowPanel(state)

        if state in [TorrentDetails.INCOMPLETE, TorrentDetails.INCOMPLETE_INACTIVE, TorrentDetails.VOD, TorrentDetails.FINISHED]:
            self.updateDetailsTab()

        if self.status_title.IsShown() != (bool(self.torrent.state) or bool(self.torrent.magnetstatus)):
            self.updateDetailsTab()
        self.UpdateStatus()

    def UpdateStatus(self):
        ds = self.torrent.ds
        progress = ds.get_progress() if ds else 0
        statusflag = ds.get_status() if ds else DLSTATUS_STOPPED
        finished = progress == 1.0
        is_vod = ds.get_download().get_mode() == DLMODE_VOD if ds else False
        status = None

        if self.torrent.magnetstatus or statusflag == DLSTATUS_METADATA:
            status = 'Torrent file is being downloaded from the DHT'
        elif statusflag == DLSTATUS_SEEDING:
            uls = ds.get_current_speed('up')
            status = 'Seeding @ %s' % self.utility.speed_format(uls)
        elif finished:
            status = 'Completed'
        elif statusflag in [DLSTATUS_ALLOCATING_DISKSPACE, DLSTATUS_WAITING4HASHCHECK]:
            status = 'Waiting'
        elif statusflag == DLSTATUS_HASHCHECKING:
            status = 'Checking'
        elif statusflag == DLSTATUS_DOWNLOADING:
            dls = ds.get_current_speed('down')
            status = 'Streaming' if is_vod else 'Downloading'
            status += ' @ %s' % self.utility.speed_format(dls)
        elif statusflag == DLSTATUS_STOPPED:
            status = 'Stopped'

        if status and not finished and self.torrent.progress and statusflag in [DLSTATUS_DOWNLOADING, DLSTATUS_STOPPED]:
            status += " (%.1f%%)" % (self.torrent.progress * 100)

        if status:
            self.status.SetLabel(status)

    def _GetState(self):
        active = vod = False

        progress = self.torrent.progress
        finished = progress == 1.0

        ds = self.torrent.ds
        if ds:
            if finished:  # finished download
                active = ds.get_status() == DLSTATUS_SEEDING

            else:  # active download
                active = ds.get_status() not in [DLSTATUS_STOPPED, DLSTATUS_STOPPED_ON_ERROR]
                if ds.is_vod():
                    vod = True

        if finished:
            if active:
                state = TorrentDetails.FINISHED
            else:
                state = TorrentDetails.FINISHED_INACTIVE

        elif vod:
            state = TorrentDetails.VOD

        elif progress > 0 or active:
            if active:
                state = TorrentDetails.INCOMPLETE
            else:
                state = TorrentDetails.INCOMPLETE_INACTIVE
        else:
            state = TorrentDetails.INACTIVE
        return state

    @warnWxThread
    def Layout(self):
        returnValue = wx.Panel.Layout(self)

        # force setupscrolling for scrollpages, if constructed while not shown this is required.
        for i in range(self.notebook.GetPageCount()):
            page = self.notebook.GetPage(i)
            page.Layout()

            if getattr(page, 'SetupScrolling', False):
                page.SetupScrolling(scroll_x=False)

        return returnValue

    @warnWxThread
    def __del__(self):
        self._logger.debug("TorrentDetails: destroying %s", self.torrent['name'])
        self.guiutility.library_manager.remove_download_state_callback(self.OnRefresh)

        if self.markWindow:
            self.markWindow.Show(False)
            self.markWindow.Destroy()


class LibraryDetails(TorrentDetails):

    @warnWxThread
    def __init__(self, parent):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.old_progress = -1
        self.refresh_counter = 0
        self.bw_history = []

        self.gui_image_manager = GuiImageManager.getInstance()

        TorrentDetails.__init__(self, parent)

    def getHashes(self):
        hashes = []
        if self.torrent:
            if self.torrent.swift_hash:
                hashes.append(self.torrent.swift_hash)
            if self.torrent.infohash:
                hashes.append(self.torrent.infohash)
        return hashes

    def setTorrent(self, torrent, bw_history=[]):
        # Arno, 2012-07-17: Retrieving peerlist for the DownloadStates takes CPU
        # so only do it when needed for display.
        self.guiutility.library_manager.set_want_peers(self.getHashes(), enable=False)

        self.old_progress = -1
        self.bw_history = bw_history
        TorrentDetails.setTorrent(self, torrent)

        self.guiutility.library_manager.set_want_peers(self.getHashes(), enable=True)

    def createAllTabs(self):
        self.Freeze()
        self.createDetailsTab()
        self.createFilesTab()
        self.createEditTab()
        self.createCommentsTab()
        self.createModificationsTab()
        self.createTrackersTab()
        self.createPeersTab()
        self.createSpeedTab()
        self.createAnonymityTab()
        self.Thaw()
        self.Layout()

        showTab = getattr(self.parent, self.__class__.__name__ + '_tab', None) if self.parent else None
        if showTab:
            for i in range(self.notebook.GetPageCount()):
                if self.notebook.GetPageText(i) == showTab:
                    self.notebook.SetSelection(i)
                    break
        else:
            self.notebook.SetSelection(0)

    def createFilesTab(self):
        TorrentDetails.createFilesTab(self)

        self.filesFooter = wx.BoxSizer(wx.VERTICAL)
        self.filesFooter.Add(wx.StaticLine(self.filesTab, -1, style=wx.LI_HORIZONTAL), 0, wx.EXPAND | wx.ALL, 3)
        self.filesFooter.Add(wx.StaticText(self.filesTab, -1, 'Right click to include/exclude selected file(s). Use ctrl+a to select all/deselect all.'), 1, wx.EXPAND)
        self.filesSizer.Add(self.filesFooter, 0, wx.EXPAND | wx.LEFT | wx.RIGHT, 6)
        self.filesSizer.AddSpacer((-1, 3))

    def createPeersTab(self):
        self.peersTab = wx.Panel(self.notebook)
        self.peersTab.SetBackgroundColour(DEFAULT_BACKGROUND)
        self.peersSizer = wx.BoxSizer(wx.VERTICAL)

        self.peerList = SelectableListCtrl(self.peersTab, tooltip=False)
        self.peerList.InsertColumn(0, 'IP-address')
        self.peerList.InsertColumn(1, 'Traffic', wx.LIST_FORMAT_RIGHT)
        self.peerList.InsertColumn(2, 'State', wx.LIST_FORMAT_RIGHT)
        self.peerList.InsertColumn(3, 'ID', wx.LIST_FORMAT_RIGHT)
        self.peerList.setResizeColumn(0)
        tt_string = "States:" + (" "*75 if sys.platform == 'win32' else "")
        tt_string += "\nO\t\toptimistic unchoked\nUI\t\tgot interested\nUC\t\tupload chocked\nUQ\t\tgot request\nUBL\t\tsending data\nUE\t\tupload eligable\nDI\t\tsend interested\nDC\t\tdownload chocked\nS\t\tis snubbed\nL\t\toutgoing connection\nR\t\tincoming connection"
        self.peerList.SetToolTipString(tt_string)
        self.peersTab.il = wx.ImageList(16, 11)
        self.peerList.SetImageList(self.peersTab.il, wx.IMAGE_LIST_SMALL)
        self.peersSizer.Add(self.peerList, 1, wx.EXPAND | wx.LEFT | wx.TOP | wx.BOTTOM, 10)

        self.country_to_index = {}
        for code, flag in self.gui_image_manager.getCountryFlagDict().iteritems():
            self.country_to_index[code] = self.peersTab.il.Add(flag)

        self.availability_hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.availability = StaticText(self.peersTab)
        self.pieces = StaticText(self.peersTab)

        self._add_row(self.peersTab, self.availability_hSizer, 'Availability', self.availability, spacer=3)
        self.availability_hSizer.AddSpacer((4, -1))
        self._add_row(self.peersTab, self.availability_hSizer, 'Pieces', self.pieces, spacer=3)

        self.availability_vSizer = wx.BoxSizer(wx.VERTICAL)
        self.availability_vSizer.Add(wx.StaticLine(self.peersTab, -1, style=wx.LI_HORIZONTAL), 0, wx.EXPAND | wx.ALL, 3)
        self.availability_vSizer.Add(self.availability_hSizer, 0, wx.EXPAND | wx.LEFT | wx.RIGHT | wx.BOTTOM, 3)

        self.peersSizer.Add(self.availability_vSizer, 0, wx.EXPAND)

        self.peersTab.SetSizer(self.peersSizer)
        self.notebook.InsertPage(2, self.peersTab, "Peers")

    def createSpeedTab(self):
        self.speedPanel = Graph(self.notebook)
        self.speedPanel.SetAxisLabels('Time (5 second update interval)', 'kB/s')
        self.speedPanel.SetMaxPoints(120)
        self.speedPanel.AddGraph(wx.Colour(0, 162, 232), [bw[1] for bw in self.bw_history], "Download speed")
        self.speedPanel.AddGraph(wx.Colour(163, 73, 164), [bw[0] for bw in self.bw_history], "Upload speed")
        self.notebook.AddPage(self.speedPanel, "Speed")

    def createAnonymityTab(self):
        self.anonymityTab, self.anonymitySizer = self._create_tab(self.notebook, "Anonymity", border=10)
        self.anonymityTab.SetBackgroundColour(wx.WHITE)

        from Tribler.Main.vwxGUI.home import Anonymity
        self.anonymityPanel = Anonymity(self.anonymityTab)
        self.anonymityPanel.SetFullScreenMode(False)
        self.anonymitySizer.Add(self.anonymityPanel, 1, wx.EXPAND)

    def updateAllTabs(self):
        self.updateDetailsTab()
        self.updateFilesTab()
        self.updateEditTab()
        self.updateCommentsTab()
        self.updateModificationsTab()
        self.updateTrackersTab()
        self.updatePeersTab()
        self.updateSpeedTab()

    def updateFilesTab(self):
        self.filesList.DeleteAllItems()

        if hasattr(self.torrent, 'files') and len(self.torrent.files) > 0:
            self.notebook.ShowMessageOnPage(self.notebook.GetIndexFromText('Files'), False)
            files = copy.copy(self.torrent.files)
            if self.torrent.ds:
                selected_files = self.torrent.ds.get_selected_files()
                if selected_files:
                    def sort_by_selected_name(a, b):
                        aSelected = a[0] in selected_files
                        bSelected = b[0] in selected_files

                        if aSelected != bSelected:
                            if aSelected:
                                return -1
                            return 1

                        return cmp(a[0], b[0])
                    files.sort(sort_by_selected_name)

            for filename, size in files:
                try:
                    pos = self.filesList.InsertStringItem(sys.maxsize, filename)
                except:
                    try:
                        pos = self.filesList.InsertStringItem(sys.maxsize, filename.decode('utf-8', 'ignore'))
                    except:
                        self._logger.error("Could not format filename %s", self.torrent.name)
                self.filesList.SetItemData(pos, pos)

                size = "%.1f MB" % (size / 1048576.0)
                self.filesList.SetStringItem(pos, 1, size)

                if filename in self.torrent.videofiles:
                    self.filesList.SetItemColumnImage(pos, 0, self.play_img)
                else:
                    self.filesList.SetItemColumnImage(pos, 0, self.file_img)

                self.filesList.SetStringItem(pos, 2, '')
        else:
            self.notebook.ShowMessageOnPage(self.notebook.GetIndexFromText('Files'), True)

    def updatePeersTab(self):
        ds = self.torrent.ds if self.torrent else None
        finished = self.torrent.get('progress', 0) == 100 or (ds and ds.get_progress() == 1.0)
        self.availability_vSizer.ShowItems(not finished)

    def updateSpeedTab(self):
        if self.bw_history:
            self.speedPanel.SetData(0, [bw[1] for bw in self.bw_history])
            self.speedPanel.SetData(1, [bw[0] for bw in self.bw_history])

    @warnWxThread
    def ShowPanel(self, newState=None):
        if newState and newState != self.state:
            self.state = newState

    @warnWxThread
    def _Refresh(self, ds=None):
        TorrentDetails._Refresh(self, ds)

        self.refresh_counter += 1
        if self.refresh_counter % 5 == 0:
            self.speedPanel.AppendData(0, self.torrent.ds.get_current_speed(DOWNLOAD) if self.torrent.ds else 0)
            self.speedPanel.AppendData(1, self.torrent.ds.get_current_speed(UPLOAD) if self.torrent.ds else 0)

        # register callback for peerlist update
        self.peerList.Freeze()

        ds = self.torrent.ds
        index = 0
        if ds:
            peers = ds.get_peerlist()

            def downsort(a, b):
                if a.get('downrate', 0) != b.get('downrate', 0):
                    return a.get('downrate', 0) - b.get('downrate', 0)
                return a.get('uprate', 0) - b.get('uprate', 0)
            peers.sort(downsort, reverse=True)

            for peer_dict in peers:
                peer_name = peer_dict['ip'] + ':%d @ %d%%' % (peer_dict['port'], peer_dict.get('completed', 0) * 100.0)
                if index < self.peerList.GetItemCount():
                    self.peerList.SetStringItem(index, 0, peer_name)
                else:
                    self.peerList.InsertStringItem(index, peer_name)

                traffic = ""
                traffic += self.guiutility.utility.speed_format(peer_dict.get('downrate', 0)) + u"\u2193 "
                traffic += self.guiutility.utility.speed_format(peer_dict.get('uprate', 0)) + u"\u2191"
                self.peerList.SetStringItem(index, 1, traffic.strip())

                state = ""
                if peer_dict.get('optimistic'):
                    state += "O,"
                if peer_dict.get('uinterested'):
                    state += "UI,"
                if peer_dict.get('uchoked'):
                    state += "UC,"
                if peer_dict.get('uhasqueries'):
                    state += "UQ,"
                if not peer_dict.get('uflushed'):
                    state += "UBL,"
                if peer_dict.get('ueligable'):
                    state += "UE,"
                if peer_dict.get('dinterested'):
                    state += "DI,"
                if peer_dict.get('dchoked'):
                    state += "DC,"
                if peer_dict.get('snubbed'):
                    state += "S,"
                state += peer_dict.get('direction', '')
                self.peerList.SetStringItem(index, 2, state)

                image_index = self.country_to_index.get(peer_dict.get('country', '00').lower(), -1)
                self.peerList.SetItemColumnImage(index, 0, image_index)

                if 'extended_version' in peer_dict:
                    try:
                        self.peerList.SetStringItem(index, 3, peer_dict['extended_version'].decode('ascii'))
                    except:
                        try:
                            self.peerList.SetStringItem(index, 3, peer_dict['extended_version'].decode('utf-8', 'ignore'))
                        except:
                            self._logger.error("Could not format peer client version")
                else:
                    self.peerList.SetStringItem(index, 3, '')

                index += 1

            if self.availability:
                self.availability.SetLabel("%.2f" % ds.get_availability())
                self.pieces.SetLabel("total %d, have %d" % ds.get_pieces_total_complete())

                self.availability_vSizer.Layout()

            dsprogress = ds.get_progress()
            # Niels: 28-08-2012 rounding to prevent updating too many times
            dsprogress = long(dsprogress * 1000) / 1000.0
            if self.old_progress != dsprogress and self.filesList.GetItemCount() > 0:
                completion = {}

                useSimple = ds.get_download().get_def().get_def_type() == 'swift' or self.filesList.GetItemCount() > 100
                selected_files = ds.get_download().get_selected_files()
                if ds.get_download().get_def().get_def_type() == 'swift':
                    selected_files = [file.split('/')[1] for file in selected_files]
                if useSimple:
                    if selected_files:
                        for i in range(self.filesList.GetItemCount()):
                            file = self.filesList.GetItem(i, 0).GetText()
                            if file in selected_files:
                                completion[file] = dsprogress
                    else:
                        for i in range(self.filesList.GetItemCount()):
                            completion[self.filesList.GetItem(i, 0).GetText()] = dsprogress
                else:
                    for file, progress in ds.get_files_completion():
                        completion[file] = progress

                for i in range(self.filesList.GetItemCount()):
                    listfile = self.filesList.GetItem(i, 0).GetText()

                    if listfile in selected_files or not selected_files:
                        self.filesList.SetStringItem(i, 2, 'Included')
                    else:
                        self.filesList.SetStringItem(i, 2, 'Excluded')

                    progress = completion.get(listfile, None)
                    if isinstance(progress, float) or isinstance(progress, int):
                        self.filesList.SetStringItem(i, 3, "%.2f%%" % (progress * 100))

                self.old_progress = dsprogress

        if index == 0:
            self.peerList.DeleteAllItems()
        else:
            while index < self.peerList.GetItemCount():
                self.peerList.DeleteItem(index)
                index += 1

        self.peerList.SetColumnWidth(1, wx.LIST_AUTOSIZE)
        self.peerList.SetColumnWidth(2, wx.LIST_AUTOSIZE)
        self.peerList.SetColumnWidth(3, wx.LIST_AUTOSIZE)
        self.peerList._doResize()
        self.peerList.Thaw()

    def __del__(self):
        TorrentDetails.__del__(self)
        self.guiutility.library_manager.set_want_peers(self.getHashes(), enable=False)

class ChannelDetails(AbstractDetails):

    def __init__(self, parent):
        FancyPanel.__init__(self, parent)
        self.Hide()

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.uelog = UserEventLogDBHandler.getInstance()

        self.parent = parent
        self.channel = None

        self.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)
        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.notebook = SimpleNotebook(self, style=wx.NB_NOPAGETHEME, name="ChannelDetailsNotebook")
        self.vSizer.Add(self.notebook, 1, wx.EXPAND)
        self.SetSizer(self.vSizer)
        self.Layout()

        self.createAllTabs()

        self.Show()

    @forceWxThread
    def showChannel(self, channel):
        self.channel = channel
        self.updateAllTabs()
        self.Layout()

    def createAllTabs(self):
        self.Freeze()

        self.detailsTab, self.detailsSizer = self._create_tab(self.notebook, 'Channel details', border=10)
        self.detailsTab.SetBackgroundColour(wx.WHITE)

        fgSizer = wx.FlexGridSizer(0, 2, 3, 10)
        fgSizer.AddGrowableCol(1)
        fgSizer.AddGrowableRow(6)

        titles = ['Name', 'Description', 'Torrents', 'Latest update', 'Favorite votes']
        for title in titles:
            control1, control2 = self._add_row(self.detailsTab, fgSizer, title, '')
            control1_name = title.lower().replace(' ', '') + '_title'
            control2_name = title.lower().replace(' ', '')
            setattr(self, control1_name, control1)
            setattr(self, control2_name, control2)

        self.detailsSizer.Add(fgSizer, 1, wx.EXPAND)
        self.detailsTab.Layout()

        self.Thaw()
        self.Layout()

        self.notebook.SetSelection(0)

    def updateAllTabs(self):
        self.Freeze()

        todo = []
        todo.append((self.name, self.channel.name))
        if self.channel.description:
            todo.append((self.description, self.channel.description))
        todo.append((self.torrents, str(self.channel.nr_torrents)))
        todo.append((self.latestupdate, format_time(self.channel.modified)))
        todo.append((self.favoritevotes, str(self.channel.nr_favorites)))

        for control, new_value in todo:
            if control.GetLabel() != new_value:
                control.SetLabel(new_value)

        self.description.Show(bool(self.channel.description))
        self.description_title.Show(bool(self.channel.description))

        self.detailsTab.Layout()

        self.Thaw()

    @warnWxThread
    def RefreshData(self, data):
        if isinstance(self.channel, Channel):
            self.channel.name = data[2].name
            self.channel.description = data[2].description
            self.channel.nr_torrents = data[2].nr_torrents
            self.channel.modified = data[2].modified
            self.channel.nr_favorites = data[2].nr_favorites

        self.updateAllTabs()


class PlaylistDetails(AbstractDetails):

    def __init__(self, parent):
        FancyPanel.__init__(self, parent)
        self.Hide()

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.uelog = UserEventLogDBHandler.getInstance()

        self.parent = parent
        self.playlist = None
        self.playlist_torrents = None

        self.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)
        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.notebook = SimpleNotebook(self, style=wx.NB_NOPAGETHEME, name="PlaylistDetailsNotebook")
        self.vSizer.Add(self.notebook, 1, wx.EXPAND)
        self.SetSizer(self.vSizer)
        self.Layout()

        self.createAllTabs()

        self.Show()

    @forceWxThread
    def showPlaylist(self, playlist):
        self.playlist = playlist
        self.playlist_torrents = None
        self.updateAllTabs()
        self.Layout()

    def createAllTabs(self):
        self.Freeze()

        self.detailsTab, self.detailsSizer = self._create_tab(self.notebook, 'Playlist details', border=10)
        self.detailsTab.SetBackgroundColour(wx.WHITE)

        fgSizer = wx.FlexGridSizer(0, 2, 3, 10)
        fgSizer.AddGrowableCol(1)
        fgSizer.AddGrowableRow(6)

        titles = ['Name', 'Description', 'Torrents']
        for title in titles:
            control1, control2 = self._add_row(self.detailsTab, fgSizer, title, '')
            setattr(self, title.lower() + '_title', control1)
            setattr(self, title.lower(), control2)

        # Add thumbnails
        self.thumbnails = wx.Panel(self.detailsTab, -1)
        self.thumbnails.SetBackgroundColour(self.detailsTab.GetBackgroundColour())
        fgThumbSizer = wx.FlexGridSizer(2, 2, 5, 5)
        hThumbSizer = wx.BoxSizer(wx.HORIZONTAL)
        hThumbSizer.Add(fgThumbSizer, 1, 0)
        self.smallthumbs = []
        for _ in range(4):
            sbmp = wx.StaticBitmap(self.thumbnails, -1)
            self.smallthumbs.append(sbmp)
            fgThumbSizer.Add(sbmp, 0, 0)
        self.bigthumb = StaticBitmaps(self.thumbnails, -1)
        hThumbSizer.AddSpacer((5, -1))
        hThumbSizer.Add(self.bigthumb, 1, 0)
        self.thumbnails.SetSizer(hThumbSizer)

        tSizer = wx.BoxSizer(wx.HORIZONTAL)
        tSizer.Add(fgSizer, 1, wx.ALIGN_LEFT | wx.ALIGN_TOP | wx.EXPAND)
        tSizer.Add(self.thumbnails, 0, wx.ALIGN_RIGHT | wx.ALIGN_TOP | wx.EXPAND)
        self.detailsSizer.Add(tSizer, 1, wx.EXPAND)
        self.thumbnails.Show(False)
        self.detailsTab.Layout()

        self.Thaw()
        self.Layout()

        self.notebook.SetSelection(0)

    def updateAllTabs(self):
        self.Freeze()

        todo = []
        todo.append((self.name, self.playlist.name))
        if self.playlist.description:
            todo.append((self.description, self.playlist.description))
        todo.append((self.torrents, str(self.playlist.nr_torrents)))

        for control, new_value in todo:
            if control.GetLabel() != new_value:
                control.SetLabel(new_value)

        self.description.Show(bool(self.playlist.description))
        self.description_title.Show(bool(self.playlist.description))

        # Reset old thumbnails
        self.bigthumb.SetBitmaps([])
        for sbmp in self.smallthumbs:
            sbmp.SetBitmap(wx.NullBitmap)

        # Set new thumbnails
        if self.playlist and self.playlist.nr_torrents > 0:
            if self.playlist_torrents == None:
                def do_db():
                    from Tribler.Main.vwxGUI.SearchGridManager import ChannelManager
                    return ChannelManager.getInstance().getTorrentsFromPlaylist(self.playlist)[2]

                def do_gui(delayedResult):
                    self.playlist_torrents = delayedResult.get()
                    bmps = []
                    for torrent in self.playlist_torrents:
                        thumb_dir = os.path.join(self.guiutility.utility.session.get_torrent_collecting_dir(), 'thumbs-' + binascii.hexlify(torrent.infohash))
                        thumb_files = [os.path.join(dp, fn) for dp, _, fns in os.walk(thumb_dir) for fn in fns if os.path.splitext(fn)[1] in THUMBNAIL_FILETYPES]
                        if thumb_files:
                            bmps.append(wx.Bitmap(thumb_files[0], wx.BITMAP_TYPE_ANY))
                        if len(bmps) > 3:
                            break

                    if bmps:
                        self.thumbnails.Show(True)
                        self.Freeze()
                        res_large = limit_resolution(bmps[0].GetSize(), (175, 175))
                        res_small = limit_resolution(bmps[0].GetSize(), (85, 85))

                        bmps_large = [bmp.ConvertToImage().Scale(*res_large, quality=wx.IMAGE_QUALITY_HIGH).ConvertToBitmap() for bmp in bmps if bmp.IsOk()]
                        bmps_small = [bmp.ConvertToImage().Scale(*res_small, quality=wx.IMAGE_QUALITY_HIGH).ConvertToBitmap() for bmp in bmps if bmp.IsOk()]

                        self.bigthumb.SetBitmaps(bmps_large)
                        for i, sbmp in enumerate(self.smallthumbs):
                            if i < len(bmps_small):
                                sbmp.SetBitmap(bmps_small[i])
                        self.thumbnails.Layout()
                        self.detailsTab.Layout()
                        self.Thaw()

                startWorker(do_gui, do_db, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

        self.detailsTab.Layout()

        self.Thaw()

    @warnWxThread
    def RefreshData(self, data):
        if isinstance(self.playlist, Playlist):
            self.playlist.name = data[2].name
            self.playlist.description = data[2].description
            self.playlist.nr_torrents = data[2].nr_torrents

        self.updateAllTabs()


class AbstractInfoPanel(FancyPanel):

    def __init__(self, parent):
        FancyPanel.__init__(self, parent)
        self.Hide()

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.uelog = UserEventLogDBHandler.getInstance()

        self.parent = parent
        self.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)

        self.topSizer = wx.BoxSizer(wx.VERTICAL)
        self.mainSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.dialogSizer = wx.BoxSizer(wx.VERTICAL)
        self.messageSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.textSizer = wx.BoxSizer(wx.VERTICAL)
        self.buttonSizer = wx.BoxSizer(wx.HORIZONTAL)

        self.mainSizer.AddStretchSpacer()
        self.mainSizer.Add(self.dialogSizer, 0, wx.EXPAND)
        self.mainSizer.AddStretchSpacer()

        self.dialogSizer.AddStretchSpacer()
        self.dialogSizer.Add(self.messageSizer, 0, wx.EXPAND)
        self.dialogSizer.Add(self.buttonSizer, 0, wx.EXPAND | wx.TOP, 15)
        self.dialogSizer.AddStretchSpacer()

        self.messageSizer.Add(self.textSizer, 0, 0)

        self.buttonSizer.AddStretchSpacer()

        for colour, height in [(SEPARATOR_GREY, 1), (FILTER_GREY, 23), (SEPARATOR_GREY, 1)]:
            panel = wx.Panel(self)
            panel.SetMinSize((-1, height))
            panel.SetBackgroundColour(colour)
            self.topSizer.Add(panel, 0, wx.EXPAND)
        self.topSizer.Add(self.mainSizer, 1, wx.EXPAND)
        self.SetSizer(self.topSizer)
        self.Layout()

    def AddMessage(self, message, colour=wx.Colour(50, 50, 50), bold=False):
        if not self.textSizer.GetChildren():
            self.messageSizer.Insert(0, TransparentStaticBitmap(self, -1, wx.ArtProvider.GetBitmap(wx.ART_INFORMATION)), 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 15)

        message = TransparentText(self, -1, message)
        _set_font(message, size_increment=2, fontcolour=colour, fontweight=wx.FONTWEIGHT_NORMAL if not bold else wx.FONTWEIGHT_BOLD)
        self.textSizer.Add(message, 0, wx.ALIGN_CENTER_VERTICAL)

        self.Layout()

    def AddButton(self, label, handler, icon=None):
        if handler == None or label == None:
            return

        button = ProgressButton(self, -1, label)
        button.Bind(wx.EVT_LEFT_UP, handler)
        if icon:
            button.SetIcon(icon)
        self.buttonSizer.Add(button, 0, wx.LEFT, 15)
        self.Layout()

    def Clear(self):
        self.messageSizer.Clear(deleteWindows=True)
        self.textSizer = wx.BoxSizer(wx.VERTICAL)
        self.messageSizer.Add(self.textSizer, 0, 0)
        self.buttonSizer.Clear(deleteWindows=True)


class SearchInfoPanel(AbstractInfoPanel):

    def Set(self, num_items):
        self.Show(False)
        self.Clear()
        self.AddMessage('A channel is a collection of torrents made by users to share their favorite torrents.')
        self.AddMessage('Channels may contain torrents associated with your search.')
        if num_items > 0:
            self.AddMessage('Please click on a channel or a torrent for more details.')
        self.Show(True)


class ChannelInfoPanel(AbstractInfoPanel):

    def Set(self, num_items, is_favourite):
        self.Show(False)
        self.Clear()
        if is_favourite:
            self.AddMessage('This is a list of your favorite channels.')
            if num_items > 0:
                self.AddMessage('Please select a channel for more details, or visit it to access its content.')
        else:
            self.AddMessage('A channel is a collection of torrents made by users to share their favorite torrents.')
            if num_items > 0:
                self.AddMessage('Please click on a channel for more details.')
        self.Show(True)


class LibraryInfoPanel(AbstractInfoPanel):

    def Set(self, num_items):
        self.Show(False)
        self.Clear()
        if num_items > 0:
            self.AddMessage('Please select a torrent for more details.')
        self.Show(True)


class PlaylistInfoPanel(AbstractInfoPanel):

    def Set(self, num_items, is_favourite):
        self.Show(False)
        self.Clear()
        if is_favourite == True:
            self.AddMessage('You are looking at the full content of this playlist.')
        elif is_favourite == False:
            self.AddMessage('You are looking at a preview of this playlist. To see more of it, mark the channel as favorite.')
        if num_items > 0:
            self.AddMessage('Please click on a torrent for more details.')
        self.Show(True)


class SelectedchannelInfoPanel(AbstractInfoPanel):

    def Set(self, num_items, vote, channelstate, iamModerator):
        self.Show(False)
        self.Clear()
        explicit_vote = vote != 0
        preview = not explicit_vote and not iamModerator
        open2edit = channelstate == ChannelCommunity.CHANNEL_CLOSED and iamModerator
        allow2edit = vote == 2 and channelstate == ChannelCommunity.CHANNEL_OPEN

        if preview:
            self.AddMessage("You are looking at a preview of this channel. If you want to see more of it, \"Mark it as Favorite\".")

        else:
            msg1 = ""
            msg2 = ""

            if iamModerator:
                msg1 = "You are looking at the contents of your channel."
            elif vote == -1:
                msg1 = "You have marked this Channel as Spam."
            elif vote == 2:
                msg1 = 'You are looking at the full content of one of your favorite channels.'

            if open2edit:
                msg1 = "You can now enable community-features for this Channel."
                msg2 = "Allowing other users to comment, modify and improve meta-data will increase the overall community feel. Try it now.\nEdit the channel settings to get started."

            elif allow2edit:
                msg1 = "This is an open community channel. You can modify it, comment on it and add new content."
                msg2 = "You can edit this channel" if not msg2 else msg2

            if msg1:
                self.AddMessage(msg1)
            if msg2:
                self.AddMessage(msg2)

        if num_items > 0:
            self.AddMessage('Please click on a torrent or a playlist for more details.')
        self.Show(True)


class ProgressPanel(wx.BoxSizer):
    # eta style
    ETA_DEFAULT = 1
    ETA_EXTENDED = 2

    def __init__(self, parent, item, style=ETA_DEFAULT, show_bar=True, show_status=True):
        wx.BoxSizer.__init__(self, wx.VERTICAL)
        self.item = item
        self.style = style
        self.show_bar = show_bar
        self.show_status = show_status
        guiutility = GUIUtility.getInstance()
        self.utility = guiutility.utility

        # self.AddStretchSpacer()
        if show_bar:
            self.pb = ProgressBar(parent, colours=["#ffffff", DOWNLOADING_COLOUR, SEEDING_COLOUR])
            self.pb.SetMaxSize((-1, -1))
            self.Add(self.pb, 1, wx.EXPAND)
        if show_status:
            self.status = StaticText(parent)
            self.Add(self.status, 0, wx.EXPAND)

        # self.AddStretchSpacer()
        wx.CallLater(100, self.Update)

    def Show(self, show):
        self.ShowItems(show)

    def Update(self, ds=None, torrent=None):
        # return_val, 0 == inactive, 1 == incomplete, 2 == complete/seeding
        return_val = 0

        if ds == None:
            if torrent:
                ds = torrent.ds
            else:
                ds = self.item.original_data.get('ds', None)

        if ds != None:
            progress = ds.get_progress()
            size = ds.get_length()

            seeds, peers = ds.get_num_seeds_peers()

            dls = ds.get_current_speed('down')
            uls = ds.get_current_speed('up')

            eta = ds.get_eta()
            status = ds.get_status()

        else:
            progress = self.item.original_data.get('progress')
            if progress == None:
                progress = 0
            size = self.item.original_data.get('length', False)

            seeds = peers = None
            dls = uls = 0

            eta = ''
            status = DLSTATUS_STOPPED

        if seeds == None:
            seeds = 0
        if peers == None:
            peers = 0

        progress = max(0, min(1, progress))  # progress has to be between 0 and 1

        self.item.data[1] = status
        self.item.data[2] = [seeds, peers]
        self.item.data[3] = dls
        self.item.data[4] = uls

        finished = progress == 1.0
        if finished:
            eta = "Completed"
            if status == DLSTATUS_SEEDING:
                eta += ", seeding"
                return_val = 2
            elif status == DLSTATUS_WAITING4HASHCHECK:
                eta += ', waiting for hashcheck'
            elif status == DLSTATUS_HASHCHECKING:
                eta += ', checking'
            else:
                eta += ", inactive"
        else:
            if status == DLSTATUS_ALLOCATING_DISKSPACE:
                eta = 'Allocating diskspace'

            elif status == DLSTATUS_WAITING4HASHCHECK:
                eta = 'Waiting for hashcheck'

            elif status == DLSTATUS_HASHCHECKING:
                eta = 'Checking'
                if progress > 0:
                    eta += "(%0.1f%%)" % (progress * 100)

            elif status == DLSTATUS_DOWNLOADING:
                sizestr = ''
                if size:
                    size_progress = size * progress

                    def format_size(bytes):
                        if bytes > 1073741824:
                            return self.utility.size_format(bytes, 1)
                        return self.utility.size_format(bytes, 0)
                    sizestr = '%s/%s (%0.1f%%)' % (format_size(size_progress), format_size(size), progress * 100)

                eta = self.utility.eta_value(eta, truncate=2)
                if eta == '' or eta.find('unknown') != -1:
                    eta = sizestr

                    if self.show_status and self.style == ProgressPanel.ETA_DEFAULT and dls == 0 and uls == 0 and ds:
                        if ds.get_num_con_initiated() > 0:
                            eta += ' - connecting'

                            nrdots = (self.status.GetLabel()[-3:].count('.') + 1) % 4
                            eta += '.' * nrdots

                else:
                    eta = sizestr + ' - ' + eta

                return_val = 1
            else:
                eta = 'Incomplete, inactive (%0.1f%%)' % (progress * 100)

        if self.style == ProgressPanel.ETA_EXTENDED:
            if status == DLSTATUS_SEEDING:
                upSpeed = " @ " + self.utility.speed_format(uls)
                eta += upSpeed
            elif status == DLSTATUS_DOWNLOADING:
                dlSpeed = " @ " + self.utility.speed_format(dls)
                eta += dlSpeed

        # Update eta
        if self.show_status and self.status.GetLabel() != eta:
            self.status.SetLabel(eta)
            self.status.Refresh()

        if self.show_bar:
            if not status in [DLSTATUS_WAITING4HASHCHECK, DLSTATUS_ALLOCATING_DISKSPACE, DLSTATUS_HASHCHECKING] and ds:
                havedigest = ds.get_pieces_complete()
            else:
                havedigest = None

            # Update graph
            if finished:
                self.pb.reset(colour=2)  # Show as complete
            elif havedigest:
                self.pb.set_pieces(havedigest)
            elif progress > 0:
                self.pb.setNormalPercentage(progress)  # Show as having some
            else:
                self.pb.reset(colour=0)  # Show as having none
            self.pb.Refresh()

        return return_val


class MyChannelPlaylist(AbstractDetails):

    def __init__(self, parent, on_manage, can_edit=False, on_save=None, on_remove=None, playlist={}):
        self.can_edit = can_edit
        self.on_manage = on_manage
        self.on_save = on_save
        self.on_remove = on_remove
        self.playlist = playlist
        self.torrent_ids = []

        wx.Panel.__init__(self, parent)
        self.SetBackgroundColour(wx.WHITE)
        vSizer = wx.BoxSizer(wx.VERTICAL)

        gridSizer = wx.FlexGridSizer(0, 2, 3, 10)
        gridSizer.AddGrowableCol(1)
        gridSizer.AddGrowableRow(1)

        if can_edit:
            self.name = EditText(self, playlist.get('name', ''))
            self.name.SetMaxLength(40)

            self.description = EditText(self, playlist.get('description', ''), multiline=True)
            self.description.SetMaxLength(2000)
        else:
            self.name = StaticText(self, -1, playlist.get('name', ''))
            self.description = StaticText(self, -1, playlist.get('description', ''))

            self.name.SetMinSize((1, -1))
            self.description.SetMinSize((1, -1))

        self._add_row(self, gridSizer, 'Name', self.name)
        self._add_row(self, gridSizer, 'Description', self.description)
        vSizer.Add(gridSizer, 1, wx.EXPAND | wx.ALL, 3)

        manage = wx.Button(self, -1, 'Manage Torrents')
        manage.Bind(wx.EVT_BUTTON, self.OnManage)

        if can_edit and playlist.get('id', False):
            hSizer = wx.BoxSizer(wx.HORIZONTAL)
            save = wx.Button(self, -1, 'Save Playlist')
            save.Bind(wx.EVT_BUTTON, self.OnSave)

            delete = wx.Button(self, -1, 'Remove Playlist')
            delete.Bind(wx.EVT_BUTTON, self.OnRemove)

            hSizer.Add(save, wx.RIGHT, 3)
            hSizer.Add(delete, wx.RIGHT, 3)
            hSizer.Add(manage)

            vSizer.Add(hSizer, 0, wx.ALIGN_RIGHT | wx.ALL, 3)
        else:
            vSizer.Add(manage, 0, wx.ALIGN_RIGHT | wx.ALL, 3)

        self.SetSizer(vSizer)

    def OnManage(self, event):
        self.torrent_ids = self.on_manage(self.playlist)

    def OnSave(self, event):
        self.on_save(self.playlist.get('id'), self)

    def OnRemove(self, event):
        self.on_remove(self.playlist.get('id'), self)

    def GetInfo(self):
        name = self.name.GetValue()
        description = self.description.GetValue()
        return name, description, self.torrent_ids

    def IsChanged(self):
        if self.can_edit:
            name = self.name.GetValue()
            description = self.description.GetValue()

            return name != self.playlist.get('name', '') or description != self.playlist.get('description', '')
        return False


class ChannelsExpandedPanel(wx.Panel):

    def __init__(self, parent, size=wx.DefaultSize):
        wx.Panel.__init__(self, parent, size=size, style=wx.NO_BORDER)
        self.guiutility = GUIUtility.getInstance()
        self.fg_colour = self.GetForegroundColour()
        self.manager = self.guiutility.frame.channellist.GetManager()
        self.channel_category = None
        self.channel_or_playlist = None
        self.AddComponents()
        self.SetBackgroundColour(parent.GetBackgroundColour())
        self.Bind(wx.EVT_SHOW, self.OnShow)
        wx.CallAfter(self.AddCurrentChannelLink)

    def AddComponents(self):
        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.hSizer.Add(self.vSizer, 1, wx.EXPAND | wx.LEFT, 20)

        self.links = {}
        for name in ['All', 'Favorites', 'My Channel']:
            link = LinkStaticText(self, name, icon=None, font_colour=TRIBLER_RED if name == 'All' else self.fg_colour)
            link.Bind(wx.EVT_LEFT_UP, self.OnCategory)
            self.links[name] = link
            self.vSizer.Add(link, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL)

        self.SetSizer(self.hSizer)
        self.Layout()

    def OnShow(self, event):
        if self.IsShownOnScreen():
            if self.channel_or_playlist:
                if isinstance(self.channel_or_playlist, Channel):
                    self.guiutility.showChannel(self.channel_or_playlist)
                elif isinstance(self.channel_or_playlist, Playlist):
                    self.guiutility.showPlaylist(self.channel_or_playlist)
            elif self.GetCategory() == 'My Channel':
                self.guiutility.ShowPage('mychannel')

    def SetBackgroundColour(self, colour):
        if self.GetBackgroundColour() != colour:
            wx.Panel.SetBackgroundColour(self, colour)
            for link in self.links.values():
                link.SetBackgroundColour(colour)

    def SetTextColour(self, colour):
        for link in self.links.values():
            link.SetForegroundColour(colour)

    def SetTextHighlight(self):
        self.SetTextColour(self.fg_colour)
        if not self.channel_or_playlist:
            link = self.links[self.GetCategory()]
            link.SetForegroundColour(TRIBLER_RED)
        elif isinstance(self.channel_or_playlist, Playlist) and 'playlist' in self.links:
            self.links['playlist'].SetForegroundColour(TRIBLER_RED)
        elif isinstance(self.channel_or_playlist, Channel) and 'channel' in self.links:
            self.links['channel'].SetForegroundColour(TRIBLER_RED)

    def AddCurrentPlaylistLink(self):
        playlist = self.guiutility.frame.playlist.playlist
        self.AddLink(playlist)

    def AddCurrentChannelLink(self):
        channel = self.guiutility.frame.selectedchannellist.channel
        self.AddLink(channel)

    def AddLink(self, channel_or_playlist):
        if channel_or_playlist:

            def DetermineText(text, maxWidth):
                for i in xrange(len(text), 0, -1):
                    newText = text[0:i]
                    if i != len(text):
                        newText += ".."
                    width, _ = self.GetTextExtent(newText)
                    if width <= maxWidth:
                        return newText
                return ""

            def CreateLinkStaticText():
                link = LinkStaticText(self, '', icon=None, font_colour=self.fg_colour)
                link_icon = GuiImageManager.getInstance().getBitmap(self, u"arrow", self.GetBackgroundColour(), state=0)
                link_icon = link_icon.ConvertToImage().Rotate90(False).ConvertToBitmap()
                link_icon = wx.StaticBitmap(self, -1, link_icon)
                link.Insert(0, link_icon, 0, wx.CENTER | wx.RIGHT, 3)
                return link

            if not self.links.get('channel', None):
                self.links['channel'] = CreateLinkStaticText()
            else:
                self.vSizer.Detach(self.links['channel'])
            if not self.links.get('playlist', None):
                self.links['playlist'] = CreateLinkStaticText()
            else:
                self.vSizer.Detach(self.links['playlist'])

            channel = channel_or_playlist if isinstance(channel_or_playlist, Channel) else channel_or_playlist.channel
            self.links['channel'].Bind(wx.EVT_LEFT_UP, lambda evt: self.OnHistory(evt, channel))
            self.links['channel'].SetLabel(DetermineText(channel.name, self.GetSize()[0] - self.links['channel'].text.GetPosition()[0]))
            self.vSizer.Insert(2 if channel.isFavorite() else 1, self.links['channel'], 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 2)

            if isinstance(channel_or_playlist, Playlist):
                self.links['playlist'].ShowItems(True)
                self.links['playlist'].Bind(wx.EVT_LEFT_UP, lambda evt: self.OnHistory(evt, channel_or_playlist))
                self.links['playlist'].SetLabel(DetermineText(channel_or_playlist.name, self.GetSize()[0] - self.links['playlist'].text.GetPosition()[0]))
                self.vSizer.Insert(3 if channel_or_playlist.channel.isFavorite() else 2, self.links['playlist'], 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 10)
            else:
                self.links['playlist'].ShowItems(False)

            self.vSizer.Layout()
            self.channel_or_playlist = channel_or_playlist
            self.SetTextHighlight()
            self.guiutility.frame.actlist.Layout()

    def GetCategory(self):
        cat = self.channel_category
        if not cat and self.manager.category:
            if self.manager.category in ["Popular", "New", "Updated"]:
                cat = "All"
            else:
                cat = self.manager.category
        if not cat:
            cat = "All"
        return cat

    def OnCategory(self, event):
        control = event.GetEventObject()
        label = control.GetLabel()
        if label == 'My Channel':
            self.guiutility.ShowPage('mychannel')
        else:
            self.guiutility.showChannelCategory(label)
            self.guiutility.frame.channellist.header.ShowChannelTypeFilter(label != 'Favorites')
            self.guiutility.frame.channellist.ResetBottomWindow()
        self.channel_category = label
        self.channel_or_playlist = None
        self.SetTextHighlight()

    def OnHistory(self, event, channel_or_playlist):
        if isinstance(channel_or_playlist, Channel):
            self.guiutility.showChannel(channel_or_playlist)
        elif isinstance(channel_or_playlist, Playlist):
            self.guiutility.showPlaylist(channel_or_playlist)
        self.channel_or_playlist = channel_or_playlist
        self.SetTextHighlight()


class VideoplayerExpandedPanel(wx.lib.scrolledpanel.ScrolledPanel):

    def __init__(self, parent):
        wx.lib.scrolledpanel.ScrolledPanel.__init__(self, parent, style=wx.NO_BORDER)

        self.guiutility = GUIUtility.getInstance()
        self.library_manager = self.guiutility.library_manager
        self.torrentsearch_manager = self.guiutility.torrentsearch_manager

        self.tdef = None
        self.fileindex = -1
        self.message = None

        self.close_icon = GuiImageManager.getInstance().getImage(u"close.png")
        self.fg_colour = self.GetForegroundColour()
        self.bg_colour = LIST_LIGHTBLUE
        self.SetBackgroundColour(self.bg_colour)
        self.AddComponents()

        self.guiutility.utility.session.add_observer(self.OnVideoEnded, NTFY_TORRENTS, [NTFY_VIDEO_ENDED])

    def AddComponents(self):
        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.hSizer.Add(self.vSizer, 1, wx.EXPAND | wx.LEFT, 20)
        self.links = []
        self.SetSizer(self.hSizer)
        self.Layout()

    def AddLinks(self):
        def DetermineText(linktext, text):
            for i in xrange(len(text), 0, -1):
                newText = text[0:i]
                if i != len(text):
                    newText += ".."
                width, _ = linktext.GetTextExtent(newText)
                if width <= 140:
                    return newText
            return ""

        self.links = []
        files = self.tdef.get_files_as_unicode()
        videofiles = self.tdef.get_files_as_unicode(exts=videoextdefaults)
        for filename in sorted(files):
            if filename in videofiles:
                fileindex = files.index(filename)
                link = LinkStaticText(self, filename, icon=None, font_colour=TRIBLER_RED if fileindex == self.fileindex else self.fg_colour)
                link.SetBackgroundColour(self.bg_colour)
                link.SetLabel(DetermineText(link.text, filename))
                link.Bind(wx.EVT_MOUSE_EVENTS, self.OnLinkStaticTextMouseEvent)
                link.SetToolTipString(filename)
                link_close = wx.StaticBitmap(self, -1, self.close_icon)
                link_close.Show(False)
                link_close.Bind(wx.EVT_LEFT_UP, lambda evt, i=fileindex: self.RemoveFileindex(i))
                link.Add(link_close, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP | wx.RIGHT, 2)
                link.fileindex = fileindex
                self.links.append(link)
                self.vSizer.Add(link, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL)

        self.OnChange()
        self.GetParent().parent_list.parent_list.Layout()

    def UpdateComponents(self):
        self.Freeze()
        self.vSizer.Clear(deleteWindows=True)
        self.links = []
        if not self.message:
            self.AddLinks()
        else:
            label, show_animation = self.message
            text = wx.StaticText(self, -1, label)
            sizer = wx.BoxSizer(wx.HORIZONTAL)
            sizer.Add(text, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 10)
            if show_animation:
                ag = wx.animate.GIFAnimationCtrl(self, -1, os.path.join(self.guiutility.vwxGUI_path, 'images', 'search_new.gif'))
                ag.Play()
                sizer.Add(ag, 0, wx.ALIGN_CENTER_VERTICAL)
            sizer.AddStretchSpacer()
            self.vSizer.Add(sizer, 1, wx.EXPAND)
        self.Layout()
        self.OnChange()
        self.Thaw()

    @forceWxThread
    def SetTorrentDef(self, tdef, fileindex= -1):
        if self.tdef != tdef and self.fileindex != fileindex:
            self.tdef = tdef
            self.fileindex = fileindex
            self.message = None
            self.UpdateComponents()

    @forceWxThread
    def SetMessage(self, message, show_animation=False):
        if self.message != (message, show_animation):
            self.tdef = None
            self.fileindex = -1
            self.message = (message, show_animation)
            self.UpdateComponents()

    @forceWxThread
    def Reset(self):
        self.tdef = None
        self.fileindex = -1
        self.message = None
        self.links = []
        self.vSizer.Clear(deleteWindows=True)
        self.Layout()
        self.OnChange()

    def RemoveFileindex(self, fileindex):
        for index, link in reversed(list(enumerate(self.links))):
            if link.fileindex == fileindex:
                self.links.pop(index)
                link.ShowItems(False)
                link.Clear(deleteWindows=True)
                self.vSizer.Remove(link)
                self.OnChange()

        vod_dl = VideoPlayer.getInstance().get_vod_download()
        if vod_dl and vod_dl.get_vod_fileindex() == fileindex:
            self.library_manager.stopTorrent(self.tdef.get_id())
            self.library_manager.last_vod_torrent = None

    def SetNrFiles(self, nr):
        videoplayer_item = self.guiutility.frame.actlist.GetItem(5)
        num_items = getattr(videoplayer_item, 'num_items', None)
        if num_items and self.guiutility.frame.videoparentpanel:
            num_items.SetValue(str(nr))
            num_items.Show(bool(nr))
            videoplayer_item.hSizer.Layout()

    def DoHighlight(self):
        for control in self.links:
            if control.fileindex == self.fileindex:
                control.SetForegroundColour(TRIBLER_RED)
            else:
                control.SetForegroundColour(self.fg_colour)

    def OnChange(self):
        self.Freeze()

        max_height = self.guiutility.frame.actlist.GetSize().y - self.GetParent().GetPosition()[1] * 1.25 - 4
        virtual_height = sum([link.text.GetSize()[1] for link in self.links]) if self.links else (30 if self.message else 0)
        best_height = min(max_height, virtual_height)
        self.SetMinSize((-1, best_height))
        self.GetParent().parent_list.Layout()
        self.SetupScrolling(scroll_x=False, scroll_y=True)
        self.SetNrFiles(len(self.links))

        self.Thaw()

    def OnLinkStaticTextMouseEvent(self, event):
        link = event.GetEventObject()
        if event.LeftDown():
            self.dragging = link
        elif event.LeftUp():
            destination = None
            source = self.dragging
            self.dragging = None
            for l in self.links:
                if l.text.GetScreenRect().Contains(wx.GetMousePosition()):
                    destination = l

            if source and destination and source != destination:
                source_index = self.links.index(source)
                destination_index = self.links.index(destination)
                self.links.pop(source_index)
                self.links.insert(destination_index, source)
                self.vSizer.Detach(source)
                self.vSizer.Insert(destination_index, source, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL)
                self.Layout()
                return
            else:
                self.fileindex = link.fileindex
                self.DoHighlight()
                # This needs to be in a CallAfter, or VLC may crash.
                wx.CallAfter(lambda: self.library_manager.playTorrent(self.tdef.get_id(), self.tdef.get_files_as_unicode()[self.fileindex]))

        for link in self.links:
            mousepos = wx.GetMousePosition()
            show = link.GetItem(0).GetWindow().GetScreenRect().Contains(mousepos) or \
                   link.GetItem(1).GetWindow().GetScreenRect().Contains(mousepos)
            wx.BoxSizer.Show(link, 1, show)
        event.Skip()

    @forceWxThread
    def OnVideoEnded(self, subject, changeType, torrent_tuple):
        infohash, fileindex = torrent_tuple

        if not self.tdef or self.tdef.get_id() != infohash:
            return

        for index, control in enumerate(self.links):
            if control.fileindex == fileindex:
                control.SetForegroundColour(self.fg_colour)
                if index + 1 < len(self.links):
                    control_next = self.links[index + 1]
                    control_next.SetForegroundColour(TRIBLER_RED)
                    self.fileindex = control_next.fileindex
                    self.DoHighlight()
                    self.library_manager.playTorrent(self.tdef.get_id(), self.tdef.get_files_as_unicode()[control_next.fileindex])

########NEW FILE########
__FILENAME__ = list_footer
# Written by Niels Zeilemaker
import wx

from Tribler.Main.vwxGUI import LIST_RADIUS, LIST_HIGHTLIGHT
from Tribler.Main.vwxGUI.list_details import AbstractDetails
from Tribler.Main.vwxGUI.widgets import TextCtrl


class ListFooter(wx.Panel):

    def __init__(self, parent, radius=0, spacers=[0, 0]):
        wx.Panel.__init__(self, parent)
        self.SetForegroundColour(parent.GetForegroundColour())

        self.originalColor = None
        self.radius = radius
        self.spacers = spacers

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        if radius + spacers[0] > 0:
            hSizer.AddSpacer((radius + spacers[0], 10))

        midSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.GetMidPanel(midSizer)
        hSizer.Add(midSizer, 1, wx.EXPAND)

        if radius + spacers[1] > 0:
            hSizer.AddSpacer((radius + spacers[1], 10))

        self.SetSizer(hSizer)

        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_SIZE, self.OnResize)

        self.background = wx.Brush(self.GetBackgroundColour())

    def GetMidPanel(self, hSizer):
        hSizer.AddStretchSpacer()

    def SetBackgroundColour(self, colour):
        if self.originalColor == None:
            self.originalColor = colour

        self.background = wx.Brush(colour)
        return wx.Panel.SetBackgroundColour(self, colour)

    def Blink(self):
        self.HighLight(0.15)
        wx.CallLater(300, self.HighLight, 0.15)

    def HighLight(self, timeout=2.0):
        self.SetBackgroundColour(LIST_HIGHTLIGHT)
        self.Refresh()
        wx.CallLater(timeout * 1000, self.Revert)

    def Revert(self):
        self.SetBackgroundColour(self.originalColor)
        self.Refresh()

    def OnPaint(self, event):
        obj = event.GetEventObject()
        dc = wx.BufferedPaintDC(obj)
        dc.Clear()

        w, h = self.GetClientSize()
        dc.SetPen(wx.TRANSPARENT_PEN)
        dc.SetBrush(self.background)
        if h < 2 * LIST_RADIUS:
            dc.DrawRoundedRectangle(0, h - 2 * self.radius, w, 2 * self.radius, self.radius)
        else:
            dc.DrawRoundedRectangle(0, 0, w, h, self.radius)
        dc.DrawRectangle(0, 0, w, h - self.radius)

    def OnResize(self, event):
        self.Refresh()
        event.Skip()

    def Reset(self):
        pass


class PlaylistFooter(ListFooter):

    def SetStates(self, vote, channelstate, iamModerator):
        pass

    def GetStates(self):
        return True, True


class ManageChannelFilesFooter(ListFooter):

    def __init__(self, parent, removeall, removesel, add, export):
        ListFooter.__init__(self, parent, 0)
        self.removeall.Bind(wx.EVT_BUTTON, removeall)
        self.removesel.Bind(wx.EVT_BUTTON, removesel)
        self.add.Bind(wx.EVT_BUTTON, add)
        self.export.Bind(wx.EVT_BUTTON, export)

    def GetMidPanel(self, hSizer):
        hSizer.AddStretchSpacer()

        self.removesel = wx.Button(self, -1, "Remove Selected")
        self.removeall = wx.Button(self, -1, "Remove All")
        self.add = wx.Button(self, -1, "+ Add...")
        self.export = wx.Button(self, -1, "Export All .torrents")

        hSizer.Add(self.removesel, 0, wx.TOP | wx.BOTTOM, 3)
        hSizer.Add(self.removeall, 0, wx.TOP | wx.BOTTOM, 3)
        hSizer.Add(self.add, 0, wx.TOP | wx.BOTTOM, 3)
        hSizer.Add(self.export, 0, wx.TOP | wx.BOTTOM, 3)

    def SetState(self, canDelete, canAdd):
        self.removesel.Show(canDelete)
        self.removeall.Show(canDelete)
        self.add.Show(canAdd)
        self.export.Show(canDelete)


class ManageChannelPlaylistFooter(ListFooter):

    def __init__(self, parent, createnew):
        ListFooter.__init__(self, parent, 0)
        self.addnew.Bind(wx.EVT_BUTTON, createnew)

    def GetMidPanel(self, hSizer):
        hSizer.AddStretchSpacer()

        self.addnew = wx.Button(self, -1, "Create New")
        hSizer.Add(self.addnew, 0, wx.TOP | wx.BOTTOM, 3)

    def SetState(self, canDelete, canAdd):
        self.addnew.Show(canDelete)


class CommentFooter(ListFooter):

    def __init__(self, parent, createnew, quickPost, horizontal):
        self.quickPost = quickPost
        self.horizontal = horizontal

        if quickPost and not horizontal:
            spacers = [3, 3]
        else:
            spacers = [7, 7]
        ListFooter.__init__(self, parent, 0, spacers=spacers)
        self.addnew.Bind(wx.EVT_BUTTON, createnew)

        if quickPost:
            self.quickAdd.Bind(wx.EVT_BUTTON, quickPost)

    def GetMidPanel(self, topsizer):
        vSizer = wx.BoxSizer(wx.VERTICAL)
#        self._add_header(self, vSizer, 'Post a comment', spacer = 0)

        self.commentbox = TextCtrl(self, style=wx.TE_MULTILINE)
        self.commentbox.SetDescriptiveText('Type in your comment here')
        if self.horizontal:
            sizer = wx.BoxSizer(wx.VERTICAL)
            sizer.AddSpacer((-1, 7))
            self.commentbox.SetMinSize((200, -1))
            sizer.Add(self.commentbox, 1, wx.EXPAND)
        else:
            sizer = wx.BoxSizer(wx.HORIZONTAL)
            self.commentbox.SetMinSize((-1, 70))
            sizer.Add(self.commentbox, 1, wx.EXPAND | wx.TOP, 7)

        if self.horizontal:
            sizer.AddSpacer((-1, 7))

        self.addnew = wx.Button(self, -1, 'Post')
        self.quickAdd = None
        if self.quickPost:
            if self.horizontal:
                self.quickAdd = wx.Button(self, -1, "Post 'Thanks'")
                postSizer = wx.BoxSizer(wx.HORIZONTAL)
            else:
                self.quickAdd = wx.Button(self, -1, "Post\n'Thanks'")
                postSizer = wx.BoxSizer(wx.VERTICAL)

            postSizer.Add(self.quickAdd)
            postSizer.AddStretchSpacer()
            postSizer.Add(self.addnew)
            sizer.Add(postSizer, 0, wx.EXPAND | wx.LEFT, 3)
        else:
            sizer.Add(self.addnew, 0, wx.ALIGN_BOTTOM | wx.LEFT, 3)

        vSizer.Add(sizer, 1, wx.EXPAND | wx.BOTTOM, self.spacers[0])
        topsizer.Add(vSizer, 1, wx.EXPAND)

    def GetComment(self):
        return self.commentbox.GetValue()

    def SetComment(self, value):
        self.commentbox.SetValue(value)

    def SetReply(self, reply):
        if reply:
            self.addnew.SetLabel('Reply')
        else:
            self.addnew.SetLabel('Post')
        self.Layout()

    def EnableCommeting(self, enable):
        self.commentbox.Enable(enable)
        self.addnew.Enable(enable)
        if self.quickAdd:
            self.quickAdd.Enable(enable)

########NEW FILE########
__FILENAME__ = list_header
# Written by Niels Zeilemaker, Egbert Bouman
import wx
import sys
import logging

from Tribler.Category.Category import Category
from Tribler.Core.Search.Bundler import Bundler
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import BundlerPreferenceDBHandler, UserEventLogDBHandler

from Tribler.community.channel.community import ChannelCommunity

from Tribler.Main.Utility.GuiDBHandler import startWorker
from Tribler.Main.Utility.GuiDBTuples import Channel, Playlist
from Tribler.Main.vwxGUI import SEPARATOR_GREY, FILTER_GREY, warnWxThread
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.list_item import ColumnsManager, TorrentListItem, \
    ChannelListItem, LibraryListItem, ChannelListItemNoButton, \
    PlaylistItemNoButton, PlaylistItem
from Tribler.Main.vwxGUI.list_body import FixedListBody
from Tribler.Main.vwxGUI.widgets import MinMaxSlider, LinkStaticText, LinkText, \
    BetterText as StaticText, _set_font


class ListHeaderIcon:
    __single = None

    def __init__(self):
        if ListHeaderIcon.__single:
            raise RuntimeError("ListHeaderIcon is singleton")
        ListHeaderIcon.__single = self
        self.icons = {}

        self._logger = logging.getLogger(self.__class__.__name__)

    def getInstance(*args, **kw):
        if ListHeaderIcon.__single is None:
            ListHeaderIcon(*args, **kw)
        return ListHeaderIcon.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        ListHeaderIcon.__single = None
    delInstance = staticmethod(delInstance)

    @warnWxThread
    def getBitmaps(self, parent, background):
        assert isinstance(background, wx.Colour), "we require a wx.colour object here"
        if not isinstance(background, wx.Colour):
            background = wx.Brush(background).GetColour()

        key = background.Get()
        if key not in self.icons:
            self.icons[key] = self.__createBitmap(parent, background, 'arrow')
        return self.icons[key]

    @warnWxThread
    def __createBitmap(self, parent, background, type, flag=0):
        self._logger.debug("Creating new sorting bitmaps %s %s %s", parent, background, type)
        gui_image_manager = GuiImageManager.getInstance()
        down = gui_image_manager.getBitmap(parent, type, background, flag)

        img = down.ConvertToImage()
        up = img.Rotate90().Rotate90().ConvertToBitmap()

        empty = wx.EmptyBitmap(up.GetWidth(), up.GetHeight())
        dc = wx.MemoryDC(empty)
        dc.SetBackground(wx.Brush(background))
        dc.Clear()
        dc.SelectObject(wx.NullBitmap)
        del dc

        return [down, up, empty]


class ListHeader(wx.Panel):

    def __init__(self, parent, parent_list, columns, radius=0, spacers=[3, 3]):
        self._logger = logging.getLogger(self.__class__.__name__)

        wx.Panel.__init__(self, parent)
        self.parent_list = parent_list
        self.columnHeaders = []

        self.columns = columns
        self.radius = radius

        self.sortedColumn = -1
        self.defaultSort = -1
        self.sortedDirection = False

        self.scrollBar = None
        self.SetForegroundColour(parent.GetForegroundColour())

        self.AddComponents(columns, spacers)
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_SIZE, self.OnResize)

    @warnWxThread
    def AddComponents(self, columns, spacers):
        hSizer = wx.BoxSizer(wx.HORIZONTAL)

        if self.radius + spacers[0] > 0:
            hSizer.AddSpacer((self.radius + spacers[0], 10))

        self.AddColumns(hSizer, self, columns)

        if self.radius + spacers[1] > 0:
            hSizer.AddSpacer((self.radius + spacers[1], 10))

        self.SetSizer(hSizer)

    @warnWxThread
    def AddColumns(self, sizer, parent, columns):
        selectedfont = self.GetFont()
        selectedfont.SetUnderlined(True)

        self.columnHeaders = []

        if len(columns) > 0:
            down, up, empty = ListHeaderIcon.getInstance().getBitmaps(self, self.GetBackgroundColour())
            for i in xrange(len(columns)):
                if columns[i].get('name', '') != '':
                    label = LinkText(parent, columns[i]['name'], fonts=[None, selectedfont], style=columns[i].get('style', 0) | wx.ST_NO_AUTORESIZE, parentsizer=sizer)
                    label.SetToolTipString('Click to sort table by %s.' % columns[i]['name'])
                    label.SetBackgroundColour(self.GetBackgroundColour())
                    label.column = i
                    label.Bind(wx.EVT_LEFT_UP, self.OnClick)

                    if i == 0:
                        sizer.Add(label, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP | wx.BOTTOM, 3)
                    else:
                        sizer.Add(label, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT | wx.TOP | wx.BOTTOM, 3)

                    if columns[i].get('defaultSorted', False):
                        if columns[i].get('sortAsc', False):
                            label.sortIcon = wx.StaticBitmap(self, -1, up)
                        else:
                            label.sortIcon = wx.StaticBitmap(self, -1, down)

                        self.sortedColumn = i
                        self.defaultSort = i
                    else:
                        label.sortIcon = wx.StaticBitmap(self, -1, empty)
                    sizer.Add(label.sortIcon, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 3)

                    if columns[i]['width'] == wx.LIST_AUTOSIZE_USEHEADER:
                        columns[i]['width'] = label.GetBestSize()[0] + down.GetWidth() + 3

                    elif columns[i]['width'] == wx.LIST_AUTOSIZE:
                        sizer.AddStretchSpacer()

                    else:
                        if isinstance(columns[i]['width'], basestring) and columns[i]['width'].endswith('em'):
                            test_string = 'T' * int(columns[i]['width'][:-2])
                            labelWidth = self.GetTextExtent(test_string)[0]
                            columns[i]['width'] = labelWidth + 3 + down.GetWidth()

                        remainingWidth = columns[i]['width'] - label.GetBestSize()[0] - down.GetWidth() - 3
                        if remainingWidth > 0:
                            sizer.AddSpacer((remainingWidth, 1))
                        else:
                            self._logger.info("LIST_HEADER: specified width is too small %s %s %s", columns[i]['name'], columns[i]['width'], remainingWidth)
                            label.SetSize((label.GetBestSize()[0] + remainingWidth, -1))

                    self.columnHeaders.append(label)
                else:
                    spacer = sizer.Add((columns[i]['width'], -1), 0, wx.LEFT, 3)
                    self.columnHeaders.append(spacer)

        self.scrollBar = sizer.AddSpacer((0, 0))
        self.scrollBar.sizer = sizer

    @warnWxThread
    def ResizeColumn(self, column, width):
        changed = False
        item = self.columnHeaders[column]
        if isinstance(item, wx.Window):
            if item.GetSize()[0] != width:
                if getattr(item, 'sortIcon', False):
                    width -= (item.sortIcon.GetSize()[0] + 3)
                item.SetMinSize((width, -1))
                changed = True
        elif item.GetSpacer()[0] != width:
            item.SetSpacer((width, -1))

    @warnWxThread
    def OnClick(self, event):
        newColumn = event.GetEventObject().column

        if newColumn == self.sortedColumn:
            newDirection = not self.sortedDirection

            if newDirection == self.columns[newColumn].get('sortAsc', False):  # back to default, treat as off
                newColumn = -1
        else:
            newDirection = self.columns[newColumn].get('sortAsc', False)

        self.parent_list.OnSort(newColumn, newDirection)
        self._SetSortedIcon(newColumn, newDirection)

    def ShowSortedBy(self, column):
        direction = self.columns[column].get('sortAsc', False)
        self._SetSortedIcon(column, direction)

    @warnWxThread
    def _SetSortedIcon(self, newColumn, newDirection):
        down, up, empty = ListHeaderIcon.getInstance().getBitmaps(self, self.GetBackgroundColour())

        if self.sortedColumn != -1 and newColumn != self.sortedColumn:
            prevSort = self.columnHeaders[self.sortedColumn].sortIcon
            prevSort.SetBitmap(empty)
            prevSort.Refresh()

        if newColumn == -1 and self.defaultSort != -1:
            newColumn = self.defaultSort
            newDirection = self.columns[self.defaultSort].get('sortAsc', False)

        if newColumn != -1:
            newSort = self.columnHeaders[newColumn].sortIcon
            if newDirection:
                newSort.SetBitmap(up)
            else:
                newSort.SetBitmap(down)
            newSort.Refresh()

        self.sortedColumn = newColumn
        self.sortedDirection = newDirection

    def Reset(self):
        if self.defaultSort != -1:
            defaultDirection = self.columns[self.defaultSort].get('sortAsc', False)
        else:
            defaultDirection = False
        self._SetSortedIcon(self.defaultSort, defaultDirection)

    @warnWxThread
    def SetBackgroundColour(self, colour):
        self.backgroundBrush = wx.Brush(colour)
        colour = self.backgroundBrush.GetColour()

        down, up, empty = ListHeaderIcon.getInstance().getBitmaps(self, colour)
        for i in range(len(self.columnHeaders)):
            if getattr(self.columnHeaders[i], 'sortIcon', False):
                bitmap = self.columnHeaders[i].sortIcon

                if i == self.sortedColumn:
                    if self.sortedDirection:
                        bitmap.SetBitmap(up)
                    else:
                        bitmap.SetBitmap(down)
                else:
                    bitmap.SetBitmap(empty)
                bitmap.Refresh()

            if getattr(self.columnHeaders[i], 'SetBackgroundColour', False):
                self.columnHeaders[i].SetBackgroundColour(colour)
        return wx.Panel.SetBackgroundColour(self, colour)

    @warnWxThread
    def OnPaint(self, event):
        obj = event.GetEventObject()
        dc = wx.BufferedPaintDC(obj)
        dc.Clear()

        w, h = self.GetClientSize()
        dc.SetPen(wx.TRANSPARENT_PEN)
        dc.SetBrush(self.backgroundBrush)

        if self.radius > 0:
            dc.DrawRoundedRectangle(0, 0, w, 2 * self.radius, self.radius)
        dc.DrawRectangle(0, self.radius, w, h - self.radius)

    @warnWxThread
    def OnResize(self, event):
        self.Refresh()
        event.Skip()


class TitleHeader(ListHeader):

    def __init__(self, parent, parent_list, columns, font_increment=2, fontweight=wx.FONTWEIGHT_BOLD, radius=0, spacers=[3, 3]):
        self.font_increment = font_increment
        self.fontweight = fontweight

        ListHeader.__init__(self, parent, parent_list, columns, radius=radius, spacers=spacers)

    @warnWxThread
    def AddComponents(self, columns, spacers):
        vSizer = wx.BoxSizer(wx.VERTICAL)

        vSizer.AddSpacer((-1, 3))

        self.title = StaticText(self)
        _set_font(self.title, self.font_increment, self.fontweight)

        titlePanel = self.GetTitlePanel(self)
        subtitlePanel = self.GetSubTitlePanel(self)
        righttitlePanel = self.GetRightTitlePanel(self)
        belowPanel = self.GetBelowPanel(self)

        if titlePanel:
            subSizer = wx.BoxSizer(wx.HORIZONTAL)
            subSizer.Add(self.title)
            subSizer.Add(titlePanel, 0, wx.LEFT | wx.ALIGN_CENTER_VERTICAL, 3)
            titlePanel = subSizer
        else:
            titlePanel = self.title

        if subtitlePanel:
            subSizer = wx.BoxSizer(wx.VERTICAL)
            subSizer.Add(titlePanel, 0, wx.BOTTOM, 3)
            subSizer.Add(subtitlePanel)
            subtitlePanel = subSizer
        else:
            subtitlePanel = titlePanel

        subSizer = wx.BoxSizer(wx.HORIZONTAL)
        subSizer.Add(subtitlePanel)
        if righttitlePanel:
            subSizer.Add(righttitlePanel, 1, wx.LEFT, 3)
        righttitlePanel = subSizer

        vSizer.Add(righttitlePanel, 0, wx.EXPAND | wx.LEFT | wx.RIGHT, self.radius + spacers[0])
        if belowPanel:
            vSizer.Add(belowPanel, 1, wx.EXPAND | wx.TOP, 3)

        vSizer.AddSpacer((-1, 3))

        if len(columns) > 0:
            hSizer = wx.BoxSizer(wx.HORIZONTAL)
            self.AddColumns(hSizer, self, columns)
            vSizer.Add(hSizer, 0, wx.EXPAND | wx.LEFT | wx.RIGHT, self.radius + spacers[0])
        self.SetSizer(vSizer)

    def GetTitlePanel(self, parent):
        pass

    def GetSubTitlePanel(self, parent):
        pass

    def GetRightTitlePanel(self, parent):
        pass

    def GetBelowPanel(self, parent):
        pass

    @warnWxThread
    def SetTitle(self, title):
        if title != self.title.GetLabel():
            self.Freeze()

            self.title.SetLabel(title)
            self.title.Refresh()
            self.Layout()
            self.Thaw()

    @warnWxThread
    def SetToolTip(self, tooltip):
        self.title.SetToolTipString(tooltip)


class SearchHeaderHelper():

    @warnWxThread
    def GetTitlePanel(self, parent):
        self.afterFilter = wx.StaticText(parent)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.Add(self.afterFilter)
        return hSizer

    @warnWxThread
    def SetSubTitle(self, label):
        if label != '':
            label = '( %s )' % label

        if getattr(self, 'subtitle', '') != label:
            self.afterFilter.SetLabel(label)
            self.subtitle = label

    @warnWxThread
    def GetRightTitlePanel(self, parent):
        self.filter = wx.SearchCtrl(parent)
        self.filter.SetDescriptiveText('Filter results')
        self.filter.Bind(wx.EVT_TEXT, self.OnKey)
        self.filter.SetMinSize((175, -1))

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.AddStretchSpacer()
        hSizer.Add(self.filter, 0, wx.ALIGN_CENTER_VERTICAL)
        return hSizer

    def FilterCorrect(self, regex_correct):
        pass

    @warnWxThread
    def OnKey(self, event):
        self.parent_list.GotFilter(self.filter.GetValue().strip())

    @warnWxThread
    def SetFiltered(self, nr):
        if nr:
            self.afterFilter.SetLabel('( Discovered %d after filter )' % nr)
        else:
            self.afterFilter.SetLabel(getattr(self, 'subtitle', ''))

    @warnWxThread
    def Reset(self):
        self.SetSubTitle('')
        self.filter.Clear()


class SubTitleHeader(TitleHeader):

    @warnWxThread
    def GetSubTitlePanel(self, parent):
        self.subtitle = StaticText(parent)
        return self.subtitle

    @warnWxThread
    def SetSubTitle(self, subtitle):
        if subtitle != self.subtitle.GetLabel():
            self.Freeze()

            self.subtitle.SetLabel(subtitle)
            self.subtitle.Refresh()

            self.Thaw()


class ManageChannelHeader(SubTitleHeader):

    def __init__(self, parent, parent_list):
        TitleHeader.__init__(self, parent, parent_list, [])
        self.nr_favorites = None

    @warnWxThread
    def SetName(self, name):
        self.SetTitle(name)

    @warnWxThread
    def SetNrTorrents(self, nr, nr_favorites=None):
        subtitle = ''
        if nr == 1:
            subtitle = 'Sharing %d torrent' % nr
        else:
            subtitle = 'Sharing %d torrents' % nr

        if nr_favorites:
            self.nr_favorites = nr_favorites
        else:
            nr_favorites = self.nr_favorites

        if nr > 0 and nr_favorites:
            if nr_favorites == 0:
                subtitle += ', but not marked as a favorite yet.'
            elif nr_favorites == 1:
                subtitle += ' and 1 Tribler user marked it as one of its favorites.'
            else:
                subtitle += ' and ' + str(nr_favorites) + ' Tribler users marked it as one of their favorites.'
        self.SetSubTitle(subtitle)

    def AddColumns(self, sizer, parent, columns):
        SubTitleHeader.AddColumns(self, sizer, parent, [])

    def Reset(self):
        SubTitleHeader.Reset(self)
        self.nr_favorites = None


class BaseFilter(wx.Panel):

    def __init__(self, parent, parent_list, columns, spacers):
        wx.Panel.__init__(self, parent)

        self.spacers = spacers
        self.parent_list = parent_list
        self.columns = columns

        self.SetBackgroundColour(FILTER_GREY)
        self.SetForegroundColour(parent.GetForegroundColour())
        self.AddComponents(spacers)

    @warnWxThread
    def AddComponents(self, spacers):
        vSizer = wx.BoxSizer(wx.VERTICAL)

        self.filter_panel = self.GetFilterPanel(self)
        if self.filter_panel:
            vSizer.Add(self.filter_panel, 0, wx.EXPAND)
            self.filter_separator = wx.Panel(self, size=(-1, 1))
            self.filter_separator.SetBackgroundColour(SEPARATOR_GREY)
            vSizer.Add(self.filter_separator, 0, wx.EXPAND)

        self.SetSizer(vSizer)

    def GetFilterPanel(self, parent):
        panel = wx.Panel(parent)
        panel.SetMinSize((-1, 25))
        panel.SetBackgroundColour(self.GetBackgroundColour())
        return panel

    def SetTitle(self, title):
        pass

    def SetSubTitle(self, subtitle):
        pass

    def SetStyle(self, style):
        pass

    def ShowSortedBy(self, sortedby):
        pass

    def SetAssociatedChannels(self, channels):
        pass

    def FilterCorrect(self, regex_correct):
        pass


class TorrentFilter(BaseFilter):

    def __init__(self, parent, parent_list, spacers=[10, 3], show_bundle=False):
        self.guiutility = GUIUtility.getInstance()
        self.torrentsearch_manager = self.guiutility.torrentsearch_manager

        self.bundlestates = [Bundler.ALG_MAGIC, Bundler.ALG_NAME, Bundler.ALG_NUMBERS, Bundler.ALG_SIZE, Bundler.ALG_OFF]
        self.bundlestates_str = {Bundler.ALG_NAME: 'Name',
                                 Bundler.ALG_NUMBERS: 'Numbers',
                                 Bundler.ALG_SIZE: 'Size',
                                 Bundler.ALG_MAGIC: 'Magic',
                                 Bundler.ALG_OFF: 'Off'}
        self.bundletexts = []
        self.bundle_db = BundlerPreferenceDBHandler.getInstance()
        self.uelog = UserEventLogDBHandler.getInstance()

        self.slider_minmax = (0, 0)
        self.slider_positions = (0, 0)
        self.conversion_factor = 1048576.0
        self.show_bundle = show_bundle
        self.SetBundleState(None)

        BaseFilter.__init__(self, parent, parent_list, ColumnsManager.getInstance().getColumns(TorrentListItem), spacers)

    def GetFilterPanel(self, parent):
        panel = wx.Panel(parent)
        panel.SetMinSize((-1, 25))
        panel.SetBackgroundColour(self.GetBackgroundColour())
        panel.SetForegroundColour(self.GetForegroundColour())

        self.icon_down = GuiImageManager.getInstance().getBitmap(self, 'arrow', self.GetBackgroundColour(), state=0)
        self.icon_right = self.icon_down.ConvertToImage().Rotate90(False).ConvertToBitmap()

        self.sortby_icon = wx.StaticBitmap(panel, -1, self.icon_right)
        self.sortby = LinkStaticText(panel, 'Sort by', None, font_colour=wx.BLACK)
        self.sortby.Bind(wx.EVT_LEFT_UP, self.OnPopupSort)

        if self.show_bundle:
            self.bundleby_icon = wx.StaticBitmap(panel, -1, self.icon_right)
            self.bundleby = LinkStaticText(panel, 'Bundle by', None, font_colour=wx.BLACK)
            self.bundleby.Bind(wx.EVT_LEFT_UP, self.OnPopupBundle)

        self.filetype_icon = wx.StaticBitmap(panel, -1, self.icon_right)
        self.filetype = LinkStaticText(panel, 'File type', None, font_colour=wx.BLACK)
        self.filetype.Bind(wx.EVT_LEFT_UP, self.OnPopupFileType)

        self.filesize_str = StaticText(panel, -1, 'File size:')
        self.filesize = MinMaxSlider(panel, -1)
        self.filesize.SetFormatter(self.guiutility.utility.size_format)

        self.search = wx.SearchCtrl(panel)
        self.search.SetDescriptiveText('Filter results')
        self.search.Bind(wx.EVT_TEXT, self.OnKey)
        if sys.platform == 'darwin':
            self.search.SetMinSize((175, 20))
        else:
            self.search.SetMinSize((175, -1))

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.AddSpacer((self.spacers[0], -1))
        hSizer.Add(self.sortby_icon, 0, wx.CENTER | wx.RIGHT, 3)
        hSizer.Add(self.sortby, 0, wx.CENTER)
        hSizer.AddSpacer((45, -1))
        if self.show_bundle:
            hSizer.Add(self.bundleby_icon, 0, wx.CENTER | wx.RIGHT, 3)
            hSizer.Add(self.bundleby, 0, wx.CENTER)
            hSizer.AddSpacer((45, -1))
        hSizer.Add(self.filetype_icon, 0, wx.CENTER | wx.RIGHT, 3)
        hSizer.Add(self.filetype, 0, wx.CENTER)
        hSizer.AddSpacer((45, -1))
        hSizer.Add(self.filesize_str, 0, wx.CENTER | wx.RIGHT, 10)
        hSizer.Add(self.filesize, 0, wx.CENTER)
        hSizer.AddStretchSpacer()
        hSizer.Add(self.search, 0, wx.CENTER)
        hSizer.AddSpacer((self.spacers[1], -1))
        self.filter_sizer = hSizer

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(hSizer, 1, wx.EXPAND)
        panel.SetSizer(vSizer)
        return panel

    def OnPopupSort(self, event):
        sortcolumn = self.parent_list.list.sortcolumn if self.parent_list.list.sortcolumn != None else -1
        sortreverse = getattr(self.parent_list.list, 'sortreverse', False)

        menu = wx.Menu()
        itemid = wx.NewId()
        menu.AppendRadioItem(itemid, "Relevance")
        menu.Bind(wx.EVT_MENU, lambda x: self.parent_list.OnSort(-1, False), id=itemid)
        menu.Check(itemid, sortcolumn == -1)
        for index, column in enumerate(self.columns):
            if column.get('show', True):
                sortAsc = column.get('sortAsc', False)
                itemid = wx.NewId()
                menu.AppendRadioItem(itemid, column['name'])
                menu.Bind(wx.EVT_MENU, lambda x, index=index, sortAsc=sortAsc: self.parent_list.OnSort(index, sortAsc), id=itemid)
                menu.Check(itemid, sortcolumn == index)

        if len(self.columns) > 0:
            menu.AppendSeparator()
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, "Ascending").Enable(sortcolumn != -1)
            menu.Bind(wx.EVT_MENU, lambda x, col=sortcolumn: self.parent_list.OnSort(col, True), id=itemid)
            menu.Check(itemid, (sortcolumn >= 0 and sortreverse))
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, "Descending")
            menu.Bind(wx.EVT_MENU, lambda x, col=sortcolumn: self.parent_list.OnSort(col, False), id=itemid)
            menu.Check(itemid, (sortcolumn == -1) or (not sortreverse))

        ctrl = self.sortby_icon
        pos = wx.Point(ctrl.GetPosition().x, self.filter_panel.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnPopupBundle(self, event):
        menu = wx.Menu()
        for state, state_str in self.bundlestates_str.iteritems():
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, state_str)
            menu.Bind(wx.EVT_MENU, lambda x, state=state: self.Rebundle(state), id=itemid)
            menu.Check(itemid, self.bundlestate == state)

        ctrl = self.bundleby_icon
        pos = wx.Point(ctrl.GetPosition().x, self.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnPopupFileType(self, event):
        menu = wx.Menu()
        itemid = wx.NewId()
        menu.AppendRadioItem(itemid, "All")
        menu.Bind(wx.EVT_MENU, lambda x: self.CategoryFilter(''), id=itemid)
        menu.Check(itemid, not self.parent_list.categoryfilter)
        for _, filetype in Category.getInstance().getCategoryNames():
            if filetype != 'XXX':
                itemid = wx.NewId()
                menu.AppendRadioItem(itemid, filetype)
                menu.Bind(wx.EVT_MENU, lambda x, filetype=filetype: self.CategoryFilter(filetype), id=itemid)
                menu.Check(itemid, bool(self.parent_list.categoryfilter) and (filetype.lower() in self.parent_list.categoryfilter))

        ctrl = self.filetype_icon
        pos = wx.Point(ctrl.GetPosition().x, self.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnSlider(self, min_val, max_val):
        search = self.search.GetValue().strip()
        # Remove old filter
        if search.find("size=") > -1:
            try:
                start = search.find("size=") + 5
                end = search.find(" ", start)
                if end == -1:
                    end = len(search)
                search = search[:start - 5] + search[end:]
                search = search.strip()
            except:
                pass
        # Insert new filter
        if min_val <= max_val:
            if search:
                search += " "
            search += "size=%d:%d" % (min_val / self.conversion_factor, max_val / self.conversion_factor)
        self.search.SetValue(search)

    def OnKey(self, event=None):
        search = self.search.GetValue().strip()
        self.parent_list.GotFilter(search)
        if event and search.find("size=") > -1:
            try:
                start = search.find("size=") + 5
                end = search.find(" ", start)
                if end == -1:
                    end = len(search)

                sizeStr = search[start:end]
                if sizeStr.find(":") > -1:
                    sizes = sizeStr.split(":")
                    if sizes[0] != '':
                        min_val = int(sizes[0])
                    if sizes[1] != '':
                        max_val = int(sizes[1])
                else:
                    min_val = max_val = int(sizeStr)
                self.slider_positions = (min_val * self.conversion_factor, max_val * self.conversion_factor)
                self.filesize.SetCurrentValues(*self.slider_positions)
            except:
                pass

    def CategoryFilter(self, category):
        search = self.search.GetValue().strip()
        # Remove old filter
        if search.find("category=") > -1:
            try:
                start = search.find("category='") + 10
                end = search.find("'", start)
                if start != -1 and end != -1:
                    search = search[:start - 10] + search[end + 1:]
                    search = search.strip()
            except:
                pass
        # Insert new filter
        if category:
            if search:
                search += " "
            search += "category='%s'" % category
        self.search.SetValue(search)

    def Reset(self):
        self.search.Clear()
        self.filesize.Reset()
        self.slider_minmax = (0, 0)
        self.slider_positions = (0, 0)

    def GetSliderMinMax(self):
        return self.slider_minmax

    def SetSliderMinMax(self, length_min, length_max):
        if self.slider_minmax != (length_min, length_max):
            self.slider_minmax = (length_min, length_max)
            self.filesize.SetMinMax(length_min, length_max)
            min_val = max(self.slider_positions[0], length_min)
            max_val = min(self.slider_positions[1], length_max)
            self.filesize.SetCurrentValues(min_val, max_val)

    def Rebundle(self, newstate):
        curstate = self.bundlestate
        selectedByMagic = self.selected_bundle_mode if self.bundlestate == Bundler.ALG_MAGIC else -1

        def db_callback():
            self.SetBundleState(newstate)

            keywords = self.torrentsearch_manager.getSearchKeywords()[0]
            self.bundle_db.storePreference(keywords, newstate)
            query = ' '.join(keywords)

            selectedByMagicStr = ''
            if selectedByMagic != -1:
                selectedByMagicStr = self.bundlestates_str[selectedByMagic]

            self.uelog.addEvent(message="Bundler GUI: %s -> %s; %s -> %s; selectedByMagic %s (%s); q=%s"
                                % (curstate, newstate, self.bundlestates_str[curstate],
                                   self.bundlestates_str[newstate],
                                   selectedByMagic, selectedByMagicStr, query), type=3)

        startWorker(None, db_callback)

    @forceDBThread
    def SetBundleState(self, newstate, refresh=True):
        if newstate is None:
            auto_guess = self.guiutility.utility.read_config('use_bundle_magic')

            newstate = Bundler.ALG_OFF  # default
            keywords = self.torrentsearch_manager.getSearchKeywords()[0]
            if keywords != '':
                try:
                    stored_state = self.bundle_db.getPreference(keywords)
                except:
                    # if db interaction fails, ignore
                    stored_state = None

                local_override = stored_state is not None

                if local_override:
                    newstate = stored_state

                elif auto_guess:
                    newstate = Bundler.ALG_MAGIC

        self.bundlestate = newstate
        self.selected_bundle_mode = None

        self.torrentsearch_manager.setBundleMode(newstate, refresh)

    def SetSelectedBundleMode(self, selected_bundle_mode):
        if self.bundlestate == Bundler.ALG_MAGIC:
            self.selected_bundle_mode = selected_bundle_mode

    def AddButton(self, btn_label, btn_handler):
        num_children = len(self.filter_sizer.GetChildren())
        if num_children < 2:
            return
        child = self.filter_sizer.GetItem(num_children - 3)
        child = child.GetWindow() if getattr(child, 'IsWindow', False) and child.IsWindow() else child
        if not isinstance(child, wx.Button):
            if btn_handler:
                btn = wx.Button(self.filter_panel, -1, btn_label)
                btn.Bind(wx.EVT_BUTTON, btn_handler)
                btn.SetMinSize((-1, 23))
                self.filter_sizer.Insert(num_children - 2, btn, 0, wx.CENTER | wx.RIGHT, 3)
                self.filter_sizer.Layout()
                self.Layout()
        else:
            btn = child
            if btn_handler:
                btn.SetLabel(btn_label)
                btn.Bind(wx.EVT_BUTTON, btn_handler)
            else:
                self.filter_sizer.Remove(btn)
                btn.Destroy()
                self.filter_sizer.Layout()


class SelectedChannelFilter(TorrentFilter):

    def __init__(self, *args, **kwargs):
        TorrentFilter.__init__(self, *args, **kwargs)
        self.columns = self.columns[:]
        for column in self.columns:
            if column['name'] == 'From':
                self.columns.remove(column)
                break

    def AddComponents(self, spacers):
        self.SetBackgroundColour(wx.WHITE)
        TorrentFilter.AddComponents(self, spacers)
        self.search.SetDescriptiveText('Filter channel content')
        button = wx.ToggleButton(self.filter_panel, -1, 'Show grid')
        button.Bind(wx.EVT_TOGGLEBUTTON, lambda evt: self.parent_list.SetGrid(evt.GetEventObject().GetValue()))
        self.filter_sizer.Insert(len(self.filter_sizer.GetChildren()) - 2, button, 0, wx.CENTER | wx.RIGHT, 3)


class SelectedPlaylistFilter(TorrentFilter):

    def AddComponents(self, spacers):
        TorrentFilter.AddComponents(self, spacers)
        self.search.SetDescriptiveText('Filter playlist content')


class ChannelFilter(BaseFilter):

    def __init__(self, parent, parent_list, spacers=[10, 3]):
        self.guiutility = GUIUtility.getInstance()
        self.channellist_manager = parent_list.GetManager()
        self.channel_categories = ["All", "Popular", "New", "Updated", "Mine"]

        BaseFilter.__init__(self, parent, parent_list, ColumnsManager.getInstance().getColumns(ChannelListItem), spacers)

    def GetFilterPanel(self, parent):
        panel = wx.Panel(parent)
        panel.SetMinSize((-1, 25))
        panel.SetBackgroundColour(self.GetBackgroundColour())
        panel.SetForegroundColour(self.GetForegroundColour())

        self.icon_down = GuiImageManager.getInstance().getBitmap(self, 'arrow', self.GetBackgroundColour(), state=0)
        self.icon_right = self.icon_down.ConvertToImage().Rotate90(False).ConvertToBitmap()

        self.sortby_icon = wx.StaticBitmap(panel, -1, self.icon_right)
        self.sortby = LinkStaticText(panel, 'Sort by', None, font_colour=wx.BLACK)
        self.sortby.Bind(wx.EVT_LEFT_UP, self.OnPopupSort)

        self.channeltype_icon = wx.StaticBitmap(panel, -1, self.icon_right)
        self.channeltype = LinkStaticText(panel, 'Channel type', None, font_colour=wx.BLACK)
        self.channeltype.Bind(wx.EVT_LEFT_UP, self.OnPopupChannelType)

        self.search = wx.SearchCtrl(panel)
        self.search.SetDescriptiveText('Filter channels')
        self.search.Bind(wx.EVT_TEXT, self.OnKey)
        if sys.platform == 'darwin':
            self.search.SetMinSize((175, 20))
        else:
            self.search.SetMinSize((175, -1))

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.AddSpacer((self.spacers[0], -1))
        hSizer.Add(self.sortby_icon, 0, wx.CENTER | wx.RIGHT, 3)
        hSizer.Add(self.sortby, 0, wx.CENTER)
        hSizer.AddSpacer((45, -1))
        hSizer.Add(self.channeltype_icon, 0, wx.CENTER | wx.RIGHT, 3)
        hSizer.Add(self.channeltype, 0, wx.CENTER)
        hSizer.AddStretchSpacer()
        hSizer.Add(self.search, 0, wx.CENTER)
        hSizer.AddSpacer((self.spacers[1], -1))
        self.filter_sizer = hSizer

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(hSizer, 1, wx.EXPAND)
        panel.SetSizer(vSizer)
        return panel

    def OnPopupSort(self, event):
        sortcolumn = self.parent_list.list.sortcolumn if self.parent_list.list.sortcolumn != None else -1
        sortreverse = getattr(self.parent_list.list, 'sortreverse', False)

        menu = wx.Menu()
        for index, column in enumerate(self.columns):
            if column.get('show', True):
                sortAsc = column.get('sortAsc', False)
                sortDef = column.get('defaultSorted', False)
                sortcolumn = index if (sortcolumn == -1 and sortDef) else sortcolumn
                itemid = wx.NewId()
                menu.AppendRadioItem(itemid, column['name'])
                menu.Bind(wx.EVT_MENU, lambda x, index=index, sortAsc=sortAsc: self.parent_list.OnSort(index, sortAsc), id=itemid)
                menu.Check(itemid, sortcolumn == index)

        if len(self.columns) > 0:
            menu.AppendSeparator()
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, "Ascending")
            menu.Bind(wx.EVT_MENU, lambda x, col=sortcolumn: self.parent_list.OnSort(col, True), id=itemid)
            menu.Check(itemid, sortreverse)
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, "Descending")
            menu.Bind(wx.EVT_MENU, lambda x, col=sortcolumn: self.parent_list.OnSort(col, False), id=itemid)
            menu.Check(itemid, not sortreverse)

        ctrl = self.sortby_icon
        pos = wx.Point(ctrl.GetPosition().x, self.filter_panel.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnPopupChannelType(self, event):
        current_cat = self.GetChannelCategory()

        menu = wx.Menu()
        for cat in self.channel_categories:
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, cat)
            menu.Bind(wx.EVT_MENU, lambda x, cat=cat: self.SetChannelCategory(cat), id=itemid)
            menu.Check(itemid, current_cat == cat)

        ctrl = self.channeltype_icon
        pos = wx.Point(ctrl.GetPosition().x, self.filter_panel.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnKey(self, event=None):
        search = self.search.GetValue().strip()
        self.parent_list.GotFilter(search)

    def GetChannelCategory(self):
        if self.channellist_manager.category:
            return self.channellist_manager.category
        else:
            return "All"

    def SetChannelCategory(self, cat):
        if cat in self.channel_categories:
            self.guiutility.showChannelCategory(cat)

    def ShowChannelTypeFilter(self, show):
        self.channeltype_icon.Show(show)
        self.channeltype.Show(show)

    def Reset(self):
        self.search.Clear()

    def AddButton(self, btn_label, btn_handler):
        num_children = len(self.filter_sizer.GetChildren())
        if num_children < 2:
            return
        child = self.filter_sizer.GetItem(num_children - 3)
        child = child.GetWindow() if getattr(child, 'IsWindow', False) and child.IsWindow() else child
        if not isinstance(child, wx.Button):
            if btn_handler:
                btn = wx.Button(self.filter_panel, -1, btn_label)
                btn.Bind(wx.EVT_BUTTON, btn_handler)
                btn.SetMinSize((-1, 23))
                self.filter_sizer.Insert(num_children - 2, btn, 0, wx.CENTER | wx.RIGHT, 3)
                self.filter_sizer.Layout()
                self.Layout()
        else:
            btn = child
            if btn_handler:
                btn.SetLabel(btn_label)
                btn.Bind(wx.EVT_BUTTON, btn_handler)
            else:
                self.filter_sizer.Remove(btn)
                btn.Destroy()
                self.filter_sizer.Layout()


class DownloadFilter(BaseFilter):

    def __init__(self, parent, parent_list, spacers=[10, 3]):
        self.guiutility = GUIUtility.getInstance()
        self.slider_minmax = (0, 0)
        self.slider_positions = (0, 0)
        self.conversion_factor = 1048576.0

        BaseFilter.__init__(self, parent, parent_list, ColumnsManager.getInstance().getColumns(LibraryListItem), spacers)

    def GetFilterPanel(self, parent):
        panel = wx.Panel(parent)
        panel.SetMinSize((-1, 25))
        panel.SetBackgroundColour(self.GetBackgroundColour())

        self.icon_down = GuiImageManager.getInstance().getBitmap(self, 'arrow', self.GetBackgroundColour(), state=0)
        self.icon_right = self.icon_down.ConvertToImage().Rotate90(False).ConvertToBitmap()

        self.sortby_icon = wx.StaticBitmap(panel, -1, self.icon_right)
        self.sortby = LinkStaticText(panel, 'Sort by', None, font_colour=wx.BLACK)
        self.sortby.Bind(wx.EVT_LEFT_UP, self.OnPopupSort)

        self.filesize_str = StaticText(panel, -1, 'File size:')
        self.filesize = MinMaxSlider(panel, -1)
        self.filesize.SetFormatter(self.guiutility.utility.size_format)

        self.state_icon = wx.StaticBitmap(panel, -1, self.icon_right)
        self.state = LinkStaticText(panel, 'Download state', None, font_colour=wx.BLACK)
        self.state.Bind(wx.EVT_LEFT_UP, self.OnPopupState)

        self.search = wx.SearchCtrl(panel)
        self.search.SetDescriptiveText('Filter downloads')
        self.search.Bind(wx.EVT_TEXT, self.OnKey)
        if sys.platform == 'darwin':
            self.search.SetMinSize((175, 20))
        else:
            self.search.SetMinSize((175, -1))

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        hSizer.AddSpacer((self.spacers[0], -1))
        hSizer.Add(self.sortby_icon, 0, wx.CENTER | wx.RIGHT, 3)
        hSizer.Add(self.sortby, 0, wx.CENTER)
        hSizer.AddSpacer((45, -1))
        hSizer.Add(self.state_icon, 0, wx.CENTER | wx.RIGHT, 3)
        hSizer.Add(self.state, 0, wx.CENTER)
        hSizer.AddSpacer((45, -1))
        hSizer.Add(self.filesize_str, 0, wx.CENTER | wx.RIGHT, 10)
        hSizer.Add(self.filesize, 0, wx.CENTER)
        hSizer.AddStretchSpacer()
        hSizer.Add(self.search, 0, wx.CENTER)
        hSizer.AddSpacer((self.spacers[1], -1))
        self.filter_sizer = hSizer

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(hSizer, 1, wx.EXPAND)
        panel.SetSizer(vSizer)
        return panel

    def OnPopupState(self, event):
        currentState = self.parent_list.statefilter if self.parent_list.statefilter != None else ''

        menu = wx.Menu()
        for state in ['All', 'Completed', 'Active', 'Seeding', 'Downloading', 'Stopped', 'Checking']:
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, state)
            menu.Bind(wx.EVT_MENU, lambda x, state=state: self.OnState(state), id=itemid)
            if state == 'All':
                enabled = bool(currentState)
            else:
                enabled = state.lower() == currentState.lower()
            menu.Check(itemid, enabled)

        ctrl = self.state_icon
        pos = wx.Point(ctrl.GetPosition().x, self.filter_panel.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnPopupSort(self, event):
        sortcolumn = self.parent_list.list.sortcolumn if self.parent_list.list.sortcolumn != None else -1
        sortreverse = getattr(self.parent_list.list, 'sortreverse', False)

        menu = wx.Menu()
        for index, column in enumerate(self.columns):
            if column.get('show', True):
                sortAsc = column.get('sortAsc', False)
                sortDef = column.get('defaultSorted', False)
                sortcolumn = index if (sortcolumn == -1 and sortDef) else sortcolumn
                itemid = wx.NewId()
                menu.AppendRadioItem(itemid, column['name'] if column['name'] else 'Progress')
                menu.Bind(wx.EVT_MENU, lambda x, index=index, sortAsc=sortAsc: self.parent_list.OnSort(index, sortAsc), id=itemid)
                menu.Check(itemid, sortcolumn == index)

        if len(self.columns) > 0:
            menu.AppendSeparator()
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, "Ascending")
            menu.Bind(wx.EVT_MENU, lambda x, col=sortcolumn: self.parent_list.OnSort(col, True), id=itemid)
            menu.Check(itemid, sortreverse)
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, "Descending")
            menu.Bind(wx.EVT_MENU, lambda x, col=sortcolumn: self.parent_list.OnSort(col, False), id=itemid)
            menu.Check(itemid, not sortreverse)

        ctrl = self.sortby_icon
        pos = wx.Point(ctrl.GetPosition().x, self.filter_panel.GetPosition().y + self.filter_panel.GetSize().y)
        self.PopupMenu(menu, pos)
        menu.Destroy()
        self.Layout()

    def OnSlider(self, min_val, max_val):
        search = self.search.GetValue().strip()
        # Remove old filter
        if search.find("size=") > -1:
            try:
                start = search.find("size=") + 5
                end = search.find(" ", start)
                if end == -1:
                    end = len(search)
                search = search[:start - 5] + search[end:]
                search = search.strip()
            except:
                pass
        # Insert new filter
        if min_val <= max_val:
            if search:
                search += " "
            search += "size=%d:%d" % (min_val / self.conversion_factor, max_val / self.conversion_factor)
        self.search.SetValue(search)

    def OnState(self, state):
        search = self.search.GetValue().strip()
        # Remove old filter
        if search.find("state=") > -1:
            try:
                start = search.find("state=") + 6
                end = search.find(" ", start)
                if end == -1:
                    end = len(search)
                search = search[:start - 6] + search[end:]
                search = search.strip()
            except:
                pass
        # Insert new filter
        if state and state != 'All':
            if search:
                search += " "
            search += "state=%s" % state
        self.search.SetValue(search)

    def OnKey(self, event=None):
        search = self.search.GetValue().strip()
        self.parent_list.GotFilter(search)
        if event and search.find("size=") > -1:
            try:
                start = search.find("size=") + 5
                end = search.find(" ", start)
                if end == -1:
                    end = len(search)

                sizeStr = search[start:end]
                if sizeStr.find(":") > -1:
                    sizes = sizeStr.split(":")
                    if sizes[0] != '':
                        min_val = int(sizes[0])
                    if sizes[1] != '':
                        max_val = int(sizes[1])
                else:
                    min_val = max_val = int(sizeStr)
                self.slider_positions = (min_val * self.conversion_factor, max_val * self.conversion_factor)
                self.filesize.SetCurrentValues(*self.slider_positions)
            except:
                pass

    def Reset(self):
        self.search.Clear()
        self.filesize.Reset()
        self.slider_positions = (0, 0)

    def GetSliderMinMax(self):
        return self.slider_minmax

    def SetSliderMinMax(self, length_min, length_max):
        if self.slider_minmax != (length_min, length_max):
            self.slider_minmax = (length_min, length_max)
            self.filesize.SetMinMax(length_min, length_max)
            min_val = max(self.slider_positions[0], length_min)
            max_val = min(self.slider_positions[1], length_max)
            self.filesize.SetCurrentValues(min_val, max_val)

    def AddButton(self, btn_label, btn_handler):
        num_children = len(self.filter_sizer.GetChildren())
        if num_children < 2:
            return
        child = self.filter_sizer.GetItem(num_children - 3)
        child = child.GetWindow() if getattr(child, 'IsWindow', False) and child.IsWindow() else child
        if not isinstance(child, wx.Button):
            if btn_handler:
                btn = wx.Button(self.filter_panel, -1, btn_label)
                btn.Bind(wx.EVT_BUTTON, btn_handler)
                btn.SetMinSize((-1, 23))
                self.filter_sizer.Insert(num_children - 2, btn, 0, wx.CENTER | wx.RIGHT, 3)
                self.filter_sizer.Layout()
                self.Layout()
        else:
            btn = child
            if btn_handler:
                btn.SetLabel(btn_label)
                btn.Bind(wx.EVT_BUTTON, btn_handler)
            else:
                self.filter_sizer.Remove(btn)
                btn.Destroy()
                self.filter_sizer.Layout()

    def ResizeColumn(self, *args, **kwargs):
        pass


class ListItemHeader(wx.Panel):

    def __init__(self, parent, parent_list):
        wx.Panel.__init__(self, parent)

        self.guiutility = GUIUtility.getInstance()

        self.SetBackgroundColour(FILTER_GREY)
        self.SetForegroundColour(parent.GetForegroundColour())

        self.icon_down = GuiImageManager.getInstance().getBitmap(self, 'arrow', self.GetBackgroundColour(), state=0)
        self.icon_right = self.icon_down.ConvertToImage().Rotate90(False).ConvertToBitmap()

        self.parent_list = parent_list
        self.header_cols = [{'name': 'Name', 'fontSize': 2, 'showColumname': False}]
        self.header_list = self.GetHeaderList(self)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(self.header_list, 1, wx.EXPAND)
        self.SetSizer(vSizer)

    def SetTitle(self, item):
        pass

    def SetButtons(self, channel):
        pass

    def OnExpand(self, item):
        return True

    def OnCollapse(self, item, panel, from_expand=False):
        if panel:
            self.parent_list.ResetBottomWindow()
        wx.CallAfter(self.guiutility.frame.top_bg.TorrentsChanged)

    def GetHeaderList(self, parent):
        return FixedListBody(parent, self, self.header_cols, singleExpanded=True)


class ChannelHeader(ListItemHeader):

    @warnWxThread
    def SetTitle(self, item):
        if item and isinstance(item, Channel):
            channel = item
            if self.header_list.InList(channel.id):
                self.header_list.RemoveKey(channel.id)

            self.header_list.SetData([(channel.id, [channel.name], channel, ChannelListItemNoButton)], force=True)

            new_item = self.header_list.GetItem(channel.id)
            new_item.SetTitleSizerHeight(30)
            new_item.list_deselected = FILTER_GREY
            new_item.SetHideButtons(False)

            self.header_list.Layout()

    def SetButtons(self, channel):
        item = self.header_list.GetItems()[0]
        num_items = len(self.parent_list.list.raw_data) if self.parent_list.list.raw_data else 0

        channelstate, iamModerator = channel.getState()

        open2edit = channelstate == ChannelCommunity.CHANNEL_CLOSED and iamModerator
        allow2edit = channel.my_vote == 2 and channelstate == ChannelCommunity.CHANNEL_OPEN
        item.buttonSizer.Clear(deleteWindows=True)

        if channel.my_vote == 0 and not iamModerator:
            item.AddButton("Mark as Spam", self.parent_list.OnSpam, 4)
            item.AddButton("Mark as Favorite", self.parent_list.OnFavorite, 4)
        else:
            if open2edit or allow2edit:
                item.AddButton("Edit this Channel", self.parent_list.OnManage, 4)
            if channel.my_vote == -1:
                item.AddButton("This is not Spam", self.parent_list.OnRemoveSpam, 4)
            elif channel.my_vote == 2:
                item.AddButton("Remove Favorite", self.parent_list.OnRemoveFavorite, 4)
            elif not open2edit and not allow2edit:
                item.AddButton("Edit this Channel", self.parent_list.OnManage, 4)

    def OnExpand(self, item):
        if isinstance(item, ChannelListItem):
            from Tribler.Main.vwxGUI.list_details import ChannelDetails
            self.parent_list.list.DeselectAll()
            detailspanel = self.guiutility.SetBottomSplitterWindow(ChannelDetails)
            detailspanel.showChannel(item.original_data)
            item.expandedPanel = detailspanel

        return ListItemHeader.OnExpand(self, item)


class PlaylistHeader(ListItemHeader):

    @warnWxThread
    def SetTitle(self, item):
        if item and isinstance(item, Playlist):
            playlist = item
            if self.header_list.InList(playlist.id):
                self.header_list.RemoveKey(playlist.id)

            self.header_list.SetData([(playlist.id, [playlist.name], playlist, PlaylistItemNoButton)], force=True)

            new_item = self.header_list.GetItem(playlist.id)
            new_item.SetTitleSizerHeight(30)

            from Tribler.Main.vwxGUI.widgets import TagText
            tag = TagText(new_item, -1, label='channel', fill_colour=wx.Colour(210, 252, 120))
            tag.SetToolTipString("Click on this icon to return to %s's channel" % playlist.channel.name)
            new_item.AddEvents(tag)
            tag.Bind(wx.EVT_LEFT_UP, lambda evt: self.guiutility.showChannel(playlist.channel))
            new_item.titleSizer.Insert(0, tag, 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 2)
            new_item.titleSizer.Insert(1, (5, -1))
            new_item.titleSizer.Insert(2, wx.StaticBitmap(new_item, -1, self.icon_right), 0, wx.ALIGN_CENTER_VERTICAL | wx.TOP, 2)
            new_item.titleSizer.Insert(3, (5, -1))
            new_item.buttonSizer.Clear(deleteWindows=True)

            new_item.list_deselected = FILTER_GREY
            new_item.ShowSelected()

            self.header_list.Layout()

    def OnExpand(self, item):
        if isinstance(item, PlaylistItem):
            from Tribler.Main.vwxGUI.list_details import PlaylistDetails
            self.parent_list.list.DeselectAll()
            detailspanel = self.guiutility.SetBottomSplitterWindow(PlaylistDetails)
            detailspanel.showPlaylist(item.original_data)
            item.expandedPanel = detailspanel

        return ListItemHeader.OnExpand(self, item)


class DetailHeader(wx.Panel):

    def __init__(self, parent, title=""):
        wx.Panel.__init__(self, parent)
        self.SetBackgroundColour(SEPARATOR_GREY)

        vSizer = wx.BoxSizer(wx.VERTICAL)

        panel = wx.Panel(self)
        panel.SetMinSize((-1, 25))
        panel.SetBackgroundColour(FILTER_GREY)
        if hasattr(parent, 'OnLeaveWindow'):
            panel.Bind(wx.EVT_ENTER_WINDOW, lambda event: parent.OnLeaveWindow())
        self.title = wx.StaticText(panel, label=title)
        _set_font(self.title, fontweight=wx.FONTWEIGHT_BOLD, fontcolour=wx.BLACK)
        sizer = wx.BoxSizer(wx.HORIZONTAL)
        sizer.Add(self.title, 0, wx.CENTER | wx.LEFT, 7)
        panel.SetSizer(sizer)

        vSizer.Add(panel, 0, wx.EXPAND | wx.TOP | wx.BOTTOM, 1)
        self.SetSizer(vSizer)

    def SetTitle(self, title):
        self.title.SetLabel(title)

########NEW FILE########
__FILENAME__ = list_item
# Written by Niels Zeilemaker, Egbert Bouman
import wx
import os
import sys
import json
import shutil
import urllib
import logging
import binascii
from datetime import timedelta

from Tribler.Core.simpledefs import DOWNLOAD, UPLOAD, DLSTATUS_METADATA, \
    DLSTATUS_HASHCHECKING, DLSTATUS_WAITING4HASHCHECK
from Tribler.Core.osutils import startfile
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler
from Tribler.Core.DownloadConfig import DownloadStartupConfig

from Tribler.Main.vwxGUI import warnWxThread, GRADIENT_DGREY, SEPARATOR_GREY, \
    LIST_AT_HIGHLIST, LIST_SELECTED, LIST_EXPANDED, format_time, \
    LIST_DARKBLUE, LIST_DESELECTED, THUMBNAIL_FILETYPES
from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice
from Tribler.Main.vwxGUI.widgets import _set_font, TagText, ActionButton, \
    ProgressButton, MaxBetterText, FancyPanel
from Tribler.Main.vwxGUI.list_body import ListItem
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager, SMALL_ICON_MAX_DIM
from Tribler.Main.Utility.GuiDBTuples import MergedDs, Torrent, CollectedTorrent

from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.Core.Video.VideoUtility import limit_resolution


class ColumnsManager:
    __single = None

    def __init__(self):
        if ColumnsManager.__single:
            raise RuntimeError("ColumnsManager is singleton")
        ColumnsManager.__single = self
        self.defaults = {}

    def getInstance(*args, **kw):
        if ColumnsManager.__single is None:
            ColumnsManager(*args, **kw)
        return ColumnsManager.__single
    getInstance = staticmethod(getInstance)

    def setColumns(self, itemtype, columns):
        self.defaults[itemtype.__name__] = columns

    def getColumns(self, itemtype):
        return self.defaults.get(itemtype.__name__, [])


class DoubleLineListItem(ListItem):

    def __init__(self, *args, **kwargs):
        self.guiutility = GUIUtility.getInstance()
        ListItem.__init__(self, *args, **kwargs)

        self._logger = logging.getLogger(self.__class__.__name__)

    @warnWxThread
    def AddComponents(self, leftSpacer, rightSpacer):
        if leftSpacer > 0:
            self.hSizer.AddSpacer((leftSpacer, -1))

        self.icons = self.GetIcons()
        if self.icons:
            iconSizer = wx.BoxSizer(wx.VERTICAL)
            for index, icon in enumerate(self.icons):
                if icon:
                    bmp = ActionButton(self, bitmap=icon[0], hover=False)
                    bmp.SetBitmapDisabled(icon[1] or icon[0])
                    bmp.SetBitmapHover(icon[1] or icon[0])
                    bmp.SetToolTipString(icon[2])
                    bmp.Bind(wx.EVT_LEFT_UP, icon[3] if len(icon) > 3 else None)
                    bmp.Show(icon[4] if len(icon) > 4 else True)
                    if index < len(self.icons) - 1:
                        iconSizer.Add(bmp, 0, wx.CENTER | wx.RESERVE_SPACE_EVEN_IF_HIDDEN | wx.BOTTOM, 7)
                    else:
                        iconSizer.Add(bmp, 0, wx.CENTER | wx.RESERVE_SPACE_EVEN_IF_HIDDEN)
                    self.icons[index] = bmp
            iconSizer.AddSpacer((33, -1))
            self.hSizer.Add(iconSizer, 0, wx.ALIGN_CENTER_VERTICAL)
        else:
            self.hSizer.AddSpacer((33, -1))

        self.titleSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.descrSizer = wx.BoxSizer(wx.HORIZONTAL)

        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(self.titleSizer, 0, wx.TOP | wx.BOTTOM | wx.EXPAND, 3)
        vSizer.Add(self.descrSizer, 0, wx.TOP | wx.BOTTOM, 3)
        self.hSizer.Add(vSizer, 1, wx.RESERVE_SPACE_EVEN_IF_HIDDEN | wx.CENTER | wx.TOP | wx.BOTTOM | wx.EXPAND, 3)

        ListItem.AddComponents(self, 0, rightSpacer)

        # remove last line
        nrchildren = len(self.descrSizer.GetChildren())
        if nrchildren > 0:
            lastline = self.descrSizer.GetItem(nrchildren - 1)
            lastline.Show(False)
            self.descrSizer.Detach(nrchildren - 1)

        else:
            vSizer.Detach(self.descrSizer)
            self.descrSizer = None

    def _add_control(self, control, column_index, option, spacing):
        if column_index == 0:
            self.titleSizer.Add(control, 1, wx.CENTER)

            if getattr(control, 'icon', None):
                # Remove the spacer and replace it with the icon
                self.hSizer.Remove(0)
                self.hSizer.Insert(0, control.icon, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT | wx.RIGHT, (33 - control.icon.GetSize().x) / 2)
        else:
            self.descrSizer.Add(control, 0, wx.CENTER | wx.TOP, spacing)

            if column_index >= 0:
                sline = wx.StaticLine(self, -1, style=wx.LI_VERTICAL)
                if sys.platform == 'win32':
                    self._add_columnresizing(sline, column_index)
                self.descrSizer.Add(sline, 0, wx.EXPAND | wx.RIGHT | wx.LEFT, 7)

    def _add_columnresizing(self, sline, column_index):
        sline.SetCursor(wx.StockCursor(wx.CURSOR_SIZEWE))
        # Take hidden columns into account
        control_index = self.columns[column_index]['controlindex']

        def OnLeftDown(event):
            eo = event.GetEventObject()
            eo.CaptureMouse()
            eo.Unbind(wx.EVT_ENTER_WINDOW)
            eo.Unbind(wx.EVT_LEAVE_WINDOW)
            eo.Bind(wx.EVT_MOTION, OnMotion)

        def OnMotion(event, control_index=control_index):
            control = self.controls[control_index]
            mouse_x = event.GetPosition().x
            width = max(0, control.GetSize().x + mouse_x)
            if getattr(self, 'buttonSizer', False):
                width = min(width, self.buttonSizer.GetPosition().x - self.descrSizer.GetPosition().x - sum([child.GetSize().x for child in self.descrSizer.GetChildren()]) + control.GetSize().x)
            else:
                pass
            control.SetMinSize((width, -1))
            self.hSizer.Layout()

        def OnLeftUp(event, column_index=column_index, control_index=control_index):
            eo = event.GetEventObject()
            eo.ReleaseMouse()
            eo.Bind(wx.EVT_ENTER_WINDOW, self.OnMouse)
            eo.Bind(wx.EVT_LEAVE_WINDOW, self.OnMouse)
            eo.Unbind(wx.EVT_MOTION)
            self.columns[column_index]['width'] = self.controls[control_index].GetSize().x

            # If we are dealing with a control with a label in front of it, we need to add the width of the label to the column width.
            if self.columns[column_index].get('showColumname', True) and \
               self.columns[column_index].get('name', False) and \
               self.columns[column_index].get('type', '') == 'method':
                for index, child in enumerate(self.descrSizer.GetChildren()):
                    if child.IsWindow() and child.GetWindow() == self.controls[control_index]:
                        if index > 1:
                            self.columns[column_index]['width'] += self.descrSizer.GetChildren()[index - 1].GetSize().x
                        break

            column_sizes = self.guiutility.ReadGuiSetting("column_sizes", default={})
            column_sizes[type(self).__name__] = column_sizes.get(type(self).__name__, {})
            column_sizes[type(self).__name__].update({self.columns[column_index]['name']: self.columns[column_index]['width']})
            self.guiutility.WriteGuiSetting("column_sizes", column_sizes)

            def rebuild():
                if hasattr(self.parent_list.parent_list, 'oldDS'):
                    self.parent_list.parent_list.oldDS = {}
                self.parent_list.Rebuild()

            wx.CallAfter(rebuild)

        sline.Bind(wx.EVT_LEFT_DOWN, OnLeftDown)
        sline.Bind(wx.EVT_LEFT_UP, OnLeftUp)

    def _replace_control(self, columnindex, newcontrol):
        oldcontrol = self.controls[columnindex]
        if columnindex == 0:
            self.titleSizer.Replace(oldcontrol, newcontrol)
        else:
            self.descrSizer.Replace(oldcontrol, newcontrol)
            newcontrol.SetMinSize(oldcontrol.GetMinSize())

        if isinstance(oldcontrol, wx.Sizer):
            oldcontrol.ShowItems(False)
            oldcontrol.DeleteWindows()
            oldcontrol.Destroy()
        else:
            oldcontrol.Show(False)
            oldcontrol.Destroy()

    @warnWxThread
    def RefreshData(self, data):
        ListItem.RefreshData(self, data)

        new_icons = self.GetIcons()
        for index, new_icon in enumerate(new_icons):
            if new_icon and (new_icon[0].ConvertToImage().GetData() != self.icons[index].GetBitmapLabel().ConvertToImage().GetData() or
                             new_icon[2] != self.icons[index].GetToolTip().GetTip()):
                self.icons[index].SetBitmapLabel(new_icon[0])
                self.icons[index].SetBitmapDisabled(new_icon[1] or new_icon[0])
                self.icons[index].SetBitmapHover(new_icon[1] or new_icon[0])
                self.icons[index].SetToolTipString(new_icon[2])
                self.icons[index].Bind(wx.EVT_LEFT_UP, new_icon[3] if len(new_icon) > 3 else None)
                self.icons[index].Enable(True)
                self.icons[index].Show(True)
            elif not new_icon and self.icons[index]:
                self.icons[index].Show(False)

    @warnWxThread
    def OnRightClick(self, event=None):
        mousepos = wx.GetMousePosition()
        if not self.expanded:
            self.OnClick(event)

        def do_menu():
            menu = self.GetContextMenu()
            if menu:
                self.PopupMenu(menu, self.ScreenToClient(mousepos))
                menu.Destroy()
        wx.CallLater(200, do_menu)

    @warnWxThread
    def OnShowColumn(self, event, index):
        self.columns[index]['show'] = not self.columns[index].get('show', True)

        hide_columns = self.guiutility.ReadGuiSetting("hide_columns", default={})
        hide_columns[type(self).__name__] = hide_columns.get(type(self).__name__, {})
        hide_columns[type(self).__name__].update({self.columns[index]['name']: self.columns[index]['show']})
        self.guiutility.WriteGuiSetting("hide_columns", hide_columns)

        if getattr(self.parent_list.parent_list, 'ResetBottomWindow', False):
            self.parent_list.parent_list.ResetBottomWindow()
        wx.CallAfter(self.parent_list.Rebuild)

    @warnWxThread
    def GetContextMenu(self):
        menu = wx.Menu()
        self.GetSubMenu([{'title': 'Show labels..', \
                          'handler': [{'title': c['name'], 'type': 'check', 'enable': c['name'] != 'Name', 'check': c.get('show', True), \
                                       'handler': lambda e, i=i: self.OnShowColumn(e, i)} for i, c in enumerate(self.columns)]}], menu)
        return menu

    def GetSubMenu(self, items, submenu=None):
        submenu = submenu or wx.Menu()
        for item in items:
            if not item:
                submenu.AppendSeparator()
                continue

            title = item['title']
            itemtype = item.get('type', '')
            enable = item.get('enable', None)
            check = item.get('check', None)
            updateui = item.get('updateui', None)
            handler = item.get('handler', None)

            if type(handler) is list:
                itemid = wx.NewId()
                submenu.AppendMenu(itemid, title, self.GetSubMenu(handler))
            else:
                itemid = wx.NewId()
                if itemtype == 'check':
                    submenu.AppendCheckItem(itemid, title)
                else:
                    submenu.Append(itemid, title)
                wx.EVT_MENU(self, itemid, handler)

            if updateui != None:
                wx.EVT_UPDATE_UI(self, itemid, updateui)

            if type(enable) is bool:
                submenu.Enable(itemid, enable)

            if itemtype == 'check' and type(check) is bool:
                submenu.Check(itemid, check)

        return submenu

    @warnWxThread
    def GetIcons(self):
        if getattr(self.parent_list.parent_list, '_special_icon', None):
            return [self.parent_list.parent_list._special_icon(self)]
        else:
            return []


class DoubleLineListItemWithButtons(DoubleLineListItem):

    def AddComponents(self, *args, **kwargs):
        DoubleLineListItem.AddComponents(self, *args, **kwargs)

        self.buttonSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.hSizer.Add(self.buttonSizer, 0, wx.CENTER | wx.TOP | wx.BOTTOM | wx.EXPAND, 3)
        self.hide_buttons = True
        self.AddButtons()

    def AddButtons(self):
        pass

    def AddButton(self, label, handler, right_spacer=10):
        if handler == None or label == None:
            return

        button = ProgressButton(self, -1, label)
        button.Bind(wx.EVT_LEFT_UP, handler)
        self.AddEvents(button)
        self.buttonSizer.Add(button, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, right_spacer)
        self.Layout()
        self.ShowSelected()
        return button

    def ShowSelected(self):
        DoubleLineListItem.ShowSelected(self)

        if self.hide_buttons and self.GetBackgroundColour() == self.list_deselected:
            self.buttonSizer.ShowItems(False)
        else:
            self.buttonSizer.ShowItems(True)
        self.Layout()

    def SetHideButtons(self, val):
        self.hide_buttons = val
        self.ShowSelected()


class TorrentListItem(DoubleLineListItemWithButtons):

    def __init__(self, *args, **kwargs):
        DoubleLineListItem.__init__(self, *args, **kwargs)
        self.SetThumbnailIcon()
        self.dlbutton = None

    def AddButtons(self):
        self.buttonSizer.Clear(deleteWindows=True)

        do_add = False
        for column in self.columns:
            if column.get('name', None) == 'Name':
                do_add = column.get('dlbutton', False)
                break

        if do_add:
            self.dlbutton = self.AddButton("Download", lambda evt: self.guiutility.frame.top_bg.OnDownload(evt, [self.original_data]))
            self.dlbutton.Enable('completed' not in self.original_data.state and 'active' not in self.original_data.state)

    @warnWxThread
    def GetIcons(self):
        if getattr(self.parent_list.parent_list, '_status_icon', None):
            return [self.parent_list.parent_list._status_icon(self)]
        else:
            return []

    @warnWxThread
    def RefreshData(self, data):
        DoubleLineListItem.RefreshData(self, data)
        self.SetThumbnailIcon()
        if self.dlbutton:
            self.dlbutton.Enable('completed' not in self.original_data.state and 'active' not in self.original_data.state)

    def SetThumbnailIcon(self):
        torcoldir = self.guiutility.utility.session.get_torrent_collecting_dir()
        rel_thumbdir = 'thumbs-' + binascii.hexlify(self.original_data.infohash)
        abs_thumbdir = os.path.join(torcoldir, rel_thumbdir)
        has_thumbnails = os.path.exists(abs_thumbdir) and os.listdir(abs_thumbdir)

        if has_thumbnails and not getattr(self, 'snapshot', None):
            # Override the settings flags set by AddComponents
            self.controls[0].SetMinSize(self.controls[0].GetBestSize())
            self.titleSizer.Detach(self.controls[0])
            self.titleSizer.Insert(0, self.controls[0], 0, wx.CENTER)

            # Add icon right after the torrent title, indicating that the torrent has thumbnails
            snapshot_bmp = GuiImageManager.getInstance().getImage(u"snapshot.png")
            self.snapshot = wx.StaticBitmap(self, -1, snapshot_bmp)
            self.snapshot.SetToolTipString("This torrent has thumbnails.")
            self.AddEvents(self.snapshot)
            self.titleSizer.Add(self.snapshot, 0, wx.ALIGN_CENTER_VERTICAL | wx.ALIGN_LEFT | wx.LEFT, 10)
            self.Layout()
            wx.CallAfter(self.Refresh)

    @warnWxThread
    def GetContextMenu(self):
        menu = DoubleLineListItem.GetContextMenu(self)

        self.GetSubMenu([{'title': 'Show download button on hover', 'type': 'check', 'updateui': self.CanShowHover, 'handler': self.OnShowHover}, \
                         None, \
                         {'title': 'Force start', 'updateui': self.CanForceStart, 'handler': self.OnForceStart}, \
                         {'title': 'Start', 'updateui': self.CanStart, 'handler': self.OnStart}, \
                         {'title': 'Stop', 'updateui': self.CanStop, 'handler': self.OnStop}, \
                         None, \
                         {'title': 'Remove download', 'updateui': self.CanRemove, 'handler': self.OnRemove}, \
                         {'title': 'Remove download + data', 'updateui': self.CanRemoveAll, 'handler': self.OnRemoveAll}, \
                         None, \
                         {'title': 'Force recheck', 'updateui': self.CanRecheck, 'handler': self.OnRecheck}, \
                         None, \
                         {'title': 'Bandwidth allocation..', 'updateui': self.CanAllocateBandwidth, 'handler': []}, \
                         None, \
                         {'title': 'Export torrent..', 'updateui': self.CanExportTorrent, 'handler': self.OnExportTorrent}, \
                         {'title': 'Copy magnet link', 'updateui': self.CanCopyMagnet, 'handler': self.OnCopyMagnet}, \
                         {'title': 'Add to my channel', 'updateui': self.CanAddToMyChannel, 'handler': self.OnAddToMyChannel}, \
                         None, \
                         {'title': 'Explore files', 'updateui': self.CanExplore, 'handler': self.OnExplore}, \
                         {'title': 'Change download location..', 'updateui': self.CanMove, 'handler': self.OnMove}], menu)

        bw_alloc = menu.FindItemById(menu.FindItem('Bandwidth allocation..')).GetSubMenu()
        download = self.original_data.ds.get_download() if self.original_data.ds else None
        if download and download.get_def().get_def_type() == 'torrent':
            bw_alloc.AppendMenu(wx.ID_ANY, 'Set download limit..', self.CreateBandwidthMenu(download, DOWNLOAD, menu))
            bw_alloc.AppendMenu(wx.ID_ANY, 'Set upload limit..', self.CreateBandwidthMenu(download, UPLOAD, menu))

        return menu

    def CreateBandwidthMenu(self, download, direction, parent_menu):
        result = wx.Menu()

        limit = download.get_max_speed(direction)

        values = self.guiutility.utility.round_range(limit) if limit > 0 else range(0, 1000, 100)
        if limit > 0 and limit not in values:
            values.append(limit)
            values.sort(cmp=lambda x, y: cmp(int(x), int(y)))
        if 0 in values:
            values.remove(0)
        values.append(0)

        for value in values:
            itemid = wx.NewId()
            result.AppendRadioItem(itemid, str(value) if value > 0 else 'unlimited')
            if sys.platform == 'win32':
                parent_menu.Bind(wx.EVT_MENU, lambda x, value=value: download.set_max_speed(direction, value), id=itemid)
            else:
                result.Bind(wx.EVT_MENU, lambda x, value=value: download.set_max_speed(direction, value), id=itemid)
            result.Check(itemid, limit == value)

        return result

    def OnShowHover(self, event):
        show = not bool(len(self.buttonSizer.GetChildren()))
        for column in self.columns:
            if column.get('name', None) == 'Name':
                column['dlbutton'] = show
                break

        for item in self.parent_list.items.values():
            if isinstance(item, TorrentListItem):
                item.AddButtons()

        self.guiutility.WriteGuiSetting("hide_buttons", not show)

    def OnForceStart(self, event):
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            self.guiutility.library_manager.resumeTorrent(torrent, force_seed=True)

    def OnStart(self, event):
        self.guiutility.frame.top_bg.OnDownload()

    def OnStop(self, event):
        self.guiutility.frame.top_bg.OnStop()

    def OnRemove(self, event):
        wx.CallAfter(lambda: self.guiutility.frame.top_bg.OnDelete(silent=True, delete=False))

    def OnRemoveAll(self, event):
        wx.CallAfter(lambda: self.guiutility.frame.top_bg.OnDelete(silent=True, delete=True))

    def OnRecheck(self, event):
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            if torrent.dslist[0] and 'metadata' not in torrent.state and 'checking' not in torrent.state:
                torrent.dslist[0].get_download().force_recheck()

    def OnExportTorrent(self, filename):
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        if len(torrents) == 1:
            filename = self.guiutility.torrentsearch_manager.getCollectedFilename(torrents[0])
            dlg = wx.FileDialog(None, message="Select an export destination", defaultFile="%s.torrent" % torrents[0].name, wildcard="*.torrent", style=wx.FD_SAVE | wx.CHANGE_DIR | wx.OVERWRITE_PROMPT)
            dlg.SetDirectory(DefaultDownloadStartupConfig.getInstance().get_dest_dir())
            if dlg.ShowModal() == wx.ID_OK:
                paths = dlg.GetPaths()
                if os.path.exists(paths[0]):
                    os.remove(paths[0])
                shutil.copyfile(filename, paths[0])
            dlg.Destroy()
        elif len(torrents) > 1:
            dlg = wx.DirDialog(None, "Choose where to move the selected torrent(s)", style=wx.DEFAULT_DIALOG_STYLE)
            dlg.SetPath(DefaultDownloadStartupConfig.getInstance().get_dest_dir())
            if dlg.ShowModal() == wx.ID_OK:
                path = dlg.GetPath()
                for torrent in torrents:
                    src_filename = self.guiutility.torrentsearch_manager.getCollectedFilename(torrent)
                    dst_filename = os.path.join(path, "%s.torrent" % torrent.name)
                    if os.path.exists(dst_filename):
                        os.remove(dst_filename)
                    shutil.copyfile(src_filename, dst_filename)
            dlg.Destroy()

    def OnCopyMagnet(self, event):
        magnetlinks = ''
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            magnetlink = "magnet:?xt=urn:btih:" + binascii.hexlify(torrent.infohash)
            trackers = self.guiutility.channelsearch_manager.torrent_db.getTrackerListByTorrentID(torrent.torrent_id)
            if trackers:
                for tracker in trackers:
                    magnetlink += "&tr=" + urllib.quote_plus(tracker)
            magnetlinks += magnetlink + '\n'

        if wx.TheClipboard.Open():
            magnetlinkObj = wx.TextDataObject()
            magnetlinkObj.SetText(magnetlinks)
            wx.TheClipboard.SetData(magnetlinkObj)
            wx.TheClipboard.Close()
        else:
            wx.MessageBox("Unable to copy magnet link to clipboard", "Error")

    @forceDBThread
    def OnAddToMyChannel(self, event):
        added = []
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            if self.guiutility.channelsearch_manager.createTorrent(None, torrent):
                added.append(torrent)

        if added:
            UserEventLogDBHandler.getInstance().addEvent(message="MyChannel: %d manual add(s) from library" % len(added), type=2)

            # remote channel link to force reload
            for torrent in added:
                del torrent.channel
                torrent.channel

            if len(added) == 1:
                def gui_call():
                    self.guiutility.Notify('New torrent added to My Channel', "Torrent '%s' has been added to My Channel" % self.original_data.name, icon=wx.ART_INFORMATION)
            else:
                def gui_call():
                    self.guiutility.Notify('New torrents added to My Channel', "%d Torrents have been added to My Channel" % len(added), icon=wx.ART_INFORMATION)

            wx.CallAfter(gui_call)

    def OnExplore(self, event):
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            path = None
            if torrent.ds:
                destdirs = torrent.ds.get_download().get_dest_files()
                path = os.path.commonprefix([os.path.split(path)[0] for _, path in destdirs])
                if path and os.path.exists(path):
                    startfile(path)
                else:
                    path = DefaultDownloadStartupConfig.getInstance().get_dest_dir()
                    startfile(path)


    def OnMove(self, event):
        items = self.guiutility.frame.librarylist.GetExpandedItems()
        torrents = [item[1].original_data for item in items if isinstance(item[1].original_data, Torrent) or isinstance(item[1].original_data, CollectedTorrent)]

        dlg = wx.DirDialog(None, "Choose where to move the selected torrent(s)", style=wx.DEFAULT_DIALOG_STYLE)
        dlg.SetPath(self.original_data.ds.get_download().get_dest_dir())
        if dlg.ShowModal() == wx.ID_OK:
            new_dir = dlg.GetPath()
            for torrent in torrents:
                if torrent.ds:
                    self._MoveDownload(torrent.ds, new_dir)

    def _MoveDownload(self, download_state, new_dir):
        def modify_config(download):
            self.guiutility.library_manager.deleteTorrentDownload(download, None, removestate=False)

            cdef = download.get_def()
            dscfg = DownloadStartupConfig(download.dlconfig)
            dscfg.set_dest_dir(new_dir)

            return cdef, dscfg

        def rename_or_merge(old, new):
            if os.path.exists(old):
                if os.path.exists(new):
                    files = os.listdir(old)
                    for file in files:
                        oldfile = os.path.join(old, file)
                        newfile = os.path.join(new, file)

                        if os.path.isdir(oldfile):
                            self.rename_or_merge(oldfile, newfile)

                        elif os.path.exists(newfile):
                            os.remove(newfile)
                            os.rename(oldfile, newfile)
                        else:
                            os.rename(oldfile, newfile)
                else:
                    os.renames(old, new)

        destdirs = download_state.get_download().get_dest_files()
        if len(destdirs) > 1:
            old = os.path.commonprefix([os.path.split(path)[0] for _, path in destdirs])
            _, old_dir = new = os.path.split(old)
            new = os.path.join(new_dir, old_dir)
        else:
            old = destdirs[0][1]
            _, old_file = os.path.split(old)
            new = os.path.join(new_dir, old_file)

        self._logger.info("Creating new downloadconfig")
        if isinstance(download_state, MergedDs):
            dslist = download_state.dslist
        else:
            dslist = [download_state]

        # Remove Swift downloads
        to_start = []
        for ds in dslist:
            download = ds.get_download()
            if download.get_def().get_def_type() == 'swift':
                to_start.append(modify_config(download))

        # Move torrents
        storage_moved = False
        for ds in dslist:
            download = ds.get_download()
            if download.get_def().get_def_type() == 'torrent':
                self._logger.info("Moving from %s to %s newdir %s", old, new, new_dir)
                download.move_storage(new_dir)
                if download.get_save_path() == new_dir:
                    storage_moved = True

        # If libtorrent hasn't moved the files yet, move them now
        if not storage_moved:
            self._logger.info("Moving from %s to %s newdir %s", old, new, new_dir)
            movelambda = lambda: rename_or_merge(old, new)
            self.guiutility.utility.session.lm.rawserver.add_task(movelambda, 0.0)

        # Start Swift downloads again..
        for cdef, dscfg in to_start:
            startlambda = lambda cdef = cdef, dscfg = dscfg: self.guiutility.utility.session.start_download(cdef, dscfg)
            self.guiutility.utility.session.lm.rawserver.add_task(startlambda, 0.0)

    def OnDClick(self, event):
        self.guiutility.frame.top_bg.OnDownload(None, [self.original_data])

    def CanShowHover(self, event):
        enable = not isinstance(self, LibraryListItem)
        check = bool(len(self.buttonSizer.GetChildren()))
        event.Enable(enable)
        event.Check(enable and check)

    def CanForceStart(self, event):
        enable = True
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            if 'completed' in torrent.state or 'seeding' in torrent.state:
                tdef = torrent.ds.get_download().get_def() if torrent.ds else None
                if tdef and tdef.get_def_type() == 'torrent':
                    if UserDownloadChoice.get_singleton().get_download_state(tdef.get_id()) == 'restartseed':
                        enable = False
                        break
        event.Enable(enable)

    def CanStart(self, event):
        event.Enable(self.guiutility.frame.top_bg.upload_btn.IsEnabled() or \
                     self.guiutility.frame.top_bg.download_btn.IsEnabled())

    def CanStop(self, event):
        event.Enable(self.guiutility.frame.top_bg.stop_btn.IsEnabled())

    def CanRemove(self, event):
        event.Enable(self.guiutility.frame.top_bg.delete_btn.IsEnabled())

    def CanRemoveAll(self, event):
        event.Enable(self.guiutility.frame.top_bg.delete_btn.IsEnabled())

    def CanRecheck(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            status = torrent.dslist[0].get_status() if torrent.dslist[0] else None
            if status not in [None, DLSTATUS_METADATA, DLSTATUS_HASHCHECKING, DLSTATUS_WAITING4HASHCHECK]:
                enable = True
                break
        event.Enable(enable)

    def CanAllocateBandwidth(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            download = torrent.ds.get_download() if torrent.ds else None
            if download and download.get_def().get_def_type() == 'torrent':
                enable = True
                break
        event.Enable(enable)

    def CanExplore(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            if torrent.state:
                enable = True
                break
        event.Enable(enable)

    def CanExportTorrent(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            filename = self.guiutility.torrentsearch_manager.getCollectedFilename(torrent)
            if filename and os.path.exists(filename):
                enable = True
                break
        event.Enable(enable)

    def CanCopyMagnet(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            download = torrent.ds.get_download() if torrent.ds else None
            if download and download.get_def().get_def_type() == 'torrent':
                enable = True
                break
        event.Enable(enable)

    def CanAddToMyChannel(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        for torrent in torrents:
            if 'seeding' in torrent.state:
                enable = True
                break
        event.Enable(enable)

    def CanMove(self, event):
        enable = False
        torrents = self.guiutility.frame.top_bg.GetSelectedTorrents()
        # Only support moving 1 download at a time
        if len(torrents) == 1 and torrents[0].infohash and 'active' in torrents[0].state:
            enable = True
        event.Enable(enable)


class ChannelListItem(DoubleLineListItemWithButtons):

    def __init__(self, *args, **kwargs):
        DoubleLineListItemWithButtons.__init__(self, *args, **kwargs)
        self.last_my_vote = None

    def AddComponents(self, *args, **kwargs):
        DoubleLineListItemWithButtons.AddComponents(self, *args, **kwargs)

        tag = TagText(self, -1, label='channel', fill_colour=wx.Colour(210, 252, 120))
        self.AddEvents(tag)
        self.titleSizer.Insert(0, tag, 0, wx.CENTER | wx.TOP, 2)
        self.titleSizer.Insert(1, (5, -1), 0, 0)

    def AddButtons(self):
        self.buttonSizer.Clear(deleteWindows=True)
        from Tribler.Main.vwxGUI.list import GenericSearchList
        from Tribler.Main.vwxGUI.list_header import BaseFilter
        if not isinstance(self.parent_list.parent_list, BaseFilter):
            self.AddButton("Visit channel", lambda evt: self.guiutility.showChannel(self.original_data))
        if not isinstance(self.parent_list.parent_list, GenericSearchList):
            if self.original_data.my_vote == 2:
                self.AddButton("Remove Favorite", lambda evt, data=self.original_data: self.guiutility.RemoveFavorite(evt, data))
            elif not self.original_data.isMyChannel():
                self.AddButton("Mark as Favorite", lambda evt, data=self.original_data: self.guiutility.MarkAsFavorite(evt, data))
            self.last_my_vote = self.original_data.my_vote

    @warnWxThread
    def RefreshData(self, data):
        DoubleLineListItemWithButtons.RefreshData(self, data)

        if self.last_my_vote != data[2].my_vote:
            self.AddButtons()

    def GetIcons(self):
        return [self.guiutility.frame.channellist._special_icon(self)]

    def OnDClick(self, event=None):
        self.guiutility.showChannel(self.original_data)

    @warnWxThread
    def SetTitleSizerHeight(self, height):
        self.titleSizer.AddSpacer((-1, height))


class ChannelListItemAssociatedTorrents(ChannelListItem):

    def __init__(self, *args, **kwargs):
        self.at_index = -1
        ChannelListItem.__init__(self, *args, **kwargs)

    def AddComponents(self, *args, **kwargs):
        DoubleLineListItemWithButtons.AddComponents(self, *args, **kwargs)

        visible_columns = [column['name'] for column in self.columns if column['show']]
        try:
            self.at_index = visible_columns.index('Associated torrents')
            self.controls[self.at_index].SetToolTipString('This channel contains %d torrents matching your search query. The visible matches are currently highlighted.' % len(self.data[-1]))
            self.controls[self.at_index].Bind(wx.EVT_MOUSE_EVENTS, self.ShowSelected)
        except:
            pass

        tag = TagText(self, -1, label='channel', fill_colour=wx.Colour(210, 252, 120))
        self.AddEvents(tag)
        self.titleSizer.Insert(0, tag, 0, wx.CENTER | wx.TOP, 2)
        self.titleSizer.Insert(1, (5, -1), 0, 0)

    def ShowSelected(self, event=None):
        if event:
            self.OnMouse(event)
        DoubleLineListItemWithButtons.ShowSelected(self)

        highlight = event and event.GetEventObject() == self.controls[self.at_index] and not event.Leaving()

        if self.at_index >= 0:
            for torrent in self.data[-1]:
                infohash = torrent.infohash
                if infohash in self.parent_list.items:
                    torrent_item = self.parent_list.GetItem(infohash)
                    if highlight:
                        torrent_item.Highlight(colour=LIST_AT_HIGHLIST, timeout=5, revert=True)
                    else:
                        torrent_item.ShowSelected()

    def OnDClick(self, event=None):
        for torrent in self.data[4]:
            self.original_data.addTorrent(torrent)
        ChannelListItem.OnDClick(self, event)


class ChannelListItemNoButton(ChannelListItem):

    def AddButtons(self):
        pass


class PlaylistItem(DoubleLineListItemWithButtons):

    def __init__(self, parent, parent_list, columns, data, original_data, *args, **kwargs):
        DoubleLineListItemWithButtons.__init__(self, parent, parent_list, columns, data, original_data, *args, **kwargs)

        if getattr(parent_list.parent_list, 'AddTorrent', False):
            from channel import TorrentDT
            self.SetDropTarget(TorrentDT(original_data, parent_list.parent_list.AddTorrent))

    def AddComponents(self, *args, **kwargs):
        DoubleLineListItemWithButtons.AddComponents(self, *args, **kwargs)

        tag = TagText(self, -1, label='playlist', fill_colour=wx.Colour(136, 117, 255), text_colour=wx.WHITE)
        self.AddEvents(tag)
        self.titleSizer.Insert(0, tag, 0, wx.CENTER | wx.TOP, 2)
        self.titleSizer.Insert(1, (5, -1), 0, 0)

    def AddButtons(self):
        self.buttonSizer.Clear(deleteWindows=True)
        self.AddButton("Visit playlist", lambda evt: self.guiutility.showPlaylist(self.original_data))

    def OnChange(self):
        self.parent_list.OnChange()

    def OnDClick(self, event):
        self.guiutility.showPlaylist(self.original_data)

    @warnWxThread
    def GetIcons(self):
        return []

    @warnWxThread
    def SetTitleSizerHeight(self, height):
        self.titleSizer.AddSpacer((-1, height))


class PlaylistItemNoButton(PlaylistItem):

    def AddButtons(self):
        pass


class LibraryListItem(TorrentListItem):

    def AddButtons(self):
        pass

    def GetIcons(self):
        return [self.parent_list.parent_list._torrent_icon(self), self.parent_list.parent_list._swift_icon(self)]

    def GetContextMenu(self):
        menu = TorrentListItem.GetContextMenu(self)
        menu.Enable(menu.FindItem('Show download button on hover'), False)
        return menu

    def OnDClick(self, event):
        pass

class ThumbnailListItemNoTorrent(FancyPanel, ListItem):

    def __init__(self, parent, parent_list, columns, data, original_data, leftSpacer=0, rightSpacer=0, showChange=False, list_selected=LIST_SELECTED, list_expanded=LIST_EXPANDED, list_selected_and_expanded=LIST_DARKBLUE):
        FancyPanel.__init__(self, parent, border=wx.RIGHT | wx.BOTTOM)
        self.SetBorderColour(SEPARATOR_GREY)
        self.guiutility = GUIUtility.getInstance()

        self._logger = logging.getLogger(self.__class__.__name__)

        self.parent_list = parent_list
        self.columns = self.controls = []
        self.data = data
        self.original_data = original_data
        self.max_bitmap_size = (175, 175)

        self.showChange = showChange
        self.list_deselected = LIST_DESELECTED
        self.list_selected = list_selected
        self.list_expanded = list_expanded
        self.list_selected_and_expanded = list_selected_and_expanded

        self.highlightTimer = self.expandedPanel = self.dlbutton = None
        self.selected = self.expanded = False
        self.SetBackgroundColour(self.list_deselected)

        self.vSizer = wx.BoxSizer(wx.VERTICAL)
        self.hSizer = wx.BoxSizer(wx.HORIZONTAL)
        self.vSizer.Add(self.hSizer, 0, wx.EXPAND)

        self.AddComponents(leftSpacer, rightSpacer)

        self.SetSizer(self.vSizer)

    def AddComponents(self, leftSpacer, rightSpacer):
        ListItem.AddComponents(self, leftSpacer, rightSpacer)

        self.bitmap, self.bitmap_hover = self.CreateBitmaps()

        self.thumbnail = wx.BitmapButton(self, -1, self.bitmap, style=wx.NO_BORDER)
        self.thumbnail.SetBitmapHover(self.bitmap_hover)
        self.thumbnail.Bind(wx.EVT_BUTTON, self.OnThumbnailClick)
        self.hSizer.Add(self.thumbnail, 1, wx.EXPAND | wx.ALL, 15)
        self.AddEvents(self.thumbnail)

        def ShortenText(statictext, text):
            for i in xrange(len(text), 0, -1):
                newText = text[0:i]
                if i != len(text):
                    newText += ".."
                width, _ = statictext.GetTextExtent(newText)
                if width <= self.GetBestSize().x:
                    return newText
            return ""

        self.vSizer.AddStretchSpacer()

        name = wx.StaticText(self, -1, '')
        name.SetLabel(ShortenText(name, self.original_data.name))
        self.AddEvents(name)
        self.vSizer.Add(name, 0, wx.ALIGN_CENTER_HORIZONTAL | wx.BOTTOM, 10)

        self.hSizer.Layout()

    def CreateBitmaps(self):
        bitmap = None

        thumb_dir = os.path.join(self.guiutility.utility.session.get_torrent_collecting_dir(), 'thumbs-' + binascii.hexlify(self.original_data.infohash))
        thumb_files = [os.path.join(dp, fn) for dp, _, fns in os.walk(thumb_dir) for fn in fns if os.path.splitext(fn)[1] in THUMBNAIL_FILETYPES]

        if thumb_files:
            bmp = wx.Bitmap(thumb_files[0], wx.BITMAP_TYPE_ANY)
            res = limit_resolution(bmp.GetSize(), self.max_bitmap_size)
            bitmap = bmp.ConvertToImage().Scale(*res, quality=wx.IMAGE_QUALITY_HIGH).ConvertToBitmap() if bmp.IsOk() and res else None

        if not bitmap:
            bitmap = GuiImageManager.getInstance().drawBitmap("no-thumbnail",
                self.max_bitmap_size, self.GetFont())

        res = bitmap.GetSize()
        bitmap_hover = wx.EmptyBitmap(*res)
        dc = wx.MemoryDC(bitmap_hover)
        gc = wx.GraphicsContext.Create(dc)
        gc.DrawBitmap(bitmap, 0, 0, *res)
        gc.SetBrush(wx.Brush(wx.Colour(0, 0, 0, 150)))
        gc.DrawRectangle(0, 0, *res)

        size = min(res)
        path = gc.CreatePath()
        path.MoveToPoint(0.2 * size, 0.2 * size)
        path.AddLineToPoint(0.2 * size, 0.8 * size)
        path.AddLineToPoint(0.8 * size, 0.5 * size)
        gc.PushState()
        gc.Translate((res[0] - size) / 2, (res[1] - size) / 2)
        gc.SetBrush(wx.Brush(wx.Colour(255, 255, 255, 150)))
        gc.SetPen(wx.TRANSPARENT_PEN)
        gc.DrawPath(path)

        dc.SelectObject(wx.NullBitmap)
        del dc

        return (bitmap, bitmap_hover)

    def OnThumbnailClick(self, event):
        self.guiutility.library_manager.playTorrent(self.original_data.infohash)


class ThumbnailListItem(ThumbnailListItemNoTorrent, TorrentListItem):

    def __init__(self, *args, **kwargs):
        ThumbnailListItemNoTorrent.__init__(self, *args, **kwargs)

    def AddComponents(self, *args, **kwargs):
        ThumbnailListItemNoTorrent.AddComponents(self, *args, **kwargs)

    def GetContextMenu(self):
        menu = TorrentListItem.GetContextMenu(self)
        menu.DestroyId(menu.FindItem('Show labels..'))
        return menu

    def CanShowHover(self, event):
        event.Enable(False)
        event.Check(False)

    def ShowSelected(self):
        DoubleLineListItem.ShowSelected(self)

    def GetIcons(self):
        return []

    def SetThumbnailIcon(self):
        pass


class ActivityListItem(ListItem):

    def __init__(self, *args, **kwargs):
        ListItem.__init__(self, *args, **kwargs)

    def AddComponents(self, leftSpacer, rightSpacer):
        ListItem.AddComponents(self, leftSpacer, rightSpacer)
        if self.data[0] in ['Results', 'Channels', 'Downloads', 'Videoplayer']:
            self.num_items = TagText(self, -1, label='0', fill_colour=GRADIENT_DGREY, edge_colour=SEPARATOR_GREY)
            self.hSizer.Add(self.num_items, 0, wx.CENTER | wx.RIGHT, 5)
            self.hSizer.Layout()


class DragItem(TorrentListItem):

    def AddEvents(self, control):
        if getattr(control, 'GetWindow', False):  # convert sizeritems
            control = control.GetWindow() or control.GetSizer()

        if getattr(control, 'Bind', False):
            control.Bind(wx.EVT_MOTION, self.OnDrag)

        TorrentListItem.AddEvents(self, control)

    def OnDrag(self, event):
        if event.LeftIsDown():
            self.parent_list.parent_list.OnDrag(self)


class AvantarItem(ListItem):

    def __init__(self, parent, parent_list, columns, data, original_data, leftSpacer=0, rightSpacer=0, showChange=False, list_selected=LIST_SELECTED, list_expanded=LIST_EXPANDED):
        self.header = ''
        self.body = ''
        self.avantar = None
        self.additionalButtons = []
        self.maxlines = 6
        ListItem.__init__(self, parent, parent_list, columns, data, original_data, leftSpacer, rightSpacer, showChange, list_selected)

    def AddComponents(self, leftSpacer, rightSpacer):
        titleRow = wx.BoxSizer(wx.HORIZONTAL)
        if leftSpacer > 0:
            titleRow.AddSpacer((leftSpacer, -1))

        if self.avantar:
            titleRow.Add(wx.StaticBitmap(self, bitmap=self.avantar), 0, wx.RIGHT, 7)

        vSizer = wx.BoxSizer(wx.VERTICAL)

        header = wx.StaticText(self, -1, self.header)
        _set_font(header, -1, wx.FONTWEIGHT_BOLD)
        header.SetMinSize((1, -1))

        vSizer.Add(header, 0, wx.EXPAND)
        vSizer.Add(wx.StaticLine(self, -1, style=wx.LI_HORIZONTAL), 0, wx.EXPAND | wx.RIGHT, 5)

        self.moreButton = None
        if len(self.additionalButtons) > 0:
            self.moreButton = wx.Button(self, style=wx.BU_EXACTFIT)

        hSizer = wx.BoxSizer(wx.HORIZONTAL)
        if len(self.additionalButtons) > 0:
            hSizer.Add(self.moreButton, 0, wx.RESERVE_SPACE_EVEN_IF_HIDDEN | wx.ALIGN_BOTTOM)

            for button in self.additionalButtons:
                hSizer.Add(button, 0, wx.RESERVE_SPACE_EVEN_IF_HIDDEN | wx.ALIGN_BOTTOM)
                button.Show(False)

            self.moreButton.Show(False)

        if isinstance(self.body, basestring):
            self.desc = MaxBetterText(self, self.body, maxLines=self.maxlines, button=self.moreButton)
            self.desc.SetMinSize((1, -1))
            vSizer.Add(self.desc, 0, wx.EXPAND)
            vSizer.Add(hSizer, 0, wx.ALIGN_RIGHT)
        else:
            self.desc = None
            for index, bmp in enumerate(self.body):
                sbmp = wx.StaticBitmap(self, -1, bmp)
                hSizer.Insert(index, sbmp, 0, wx.ALIGN_RIGHT | wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 6)
            hSizer.InsertStretchSpacer(len(self.body))
            vSizer.Add(hSizer, 0, wx.EXPAND | wx.TOP | wx.BOTTOM, 5)

        titleRow.Add(vSizer, 1)

        if rightSpacer > 0:
            titleRow.AddSpacer((rightSpacer, -1))
        self.vSizer.Add(titleRow, 0, wx.EXPAND | wx.TOP | wx.BOTTOM, 3)
        self.AddEvents(self)

    def BackgroundColor(self, color):
        changed = ListItem.BackgroundColor(self, color)

        if len(self.additionalButtons) > 0 and changed:
            if self.desc and self.desc.hasMore:
                self.moreButton.Show(color == self.list_selected)

            for button in self.additionalButtons:
                button.Show(color == self.list_selected)

    def OnChange(self):
        self.parent_list.OnChange()


class CommentItem(AvantarItem):

    def __init__(self, parent, parent_list, columns, data, original_data, leftSpacer=0, rightSpacer=0, showChange=False, list_selected=LIST_SELECTED, list_expanded=LIST_EXPANDED):
        # check if we are part of a torrent
        manager = parent_list.parent_list.GetManager()
        if manager.channeltorrent:
            self.inTorrent = True
        else:
            self.inTorrent = False

        _, comment = original_data
        self.canRemove = comment.isMyComment() or (comment.channel and comment.channel.isMyChannel())

        AvantarItem.__init__(self, parent, parent_list, columns, data, original_data, leftSpacer, rightSpacer, showChange, list_selected)

    def AddComponents(self, leftSpacer, rightSpacer):
        depth, comment = self.original_data

        self.header = "Posted %s by %s" % (format_time(comment.time_stamp).lower(), comment.name)
        self.body = comment.comment
        self.avantar = comment.avantar

        if depth == 0:
            if not self.inTorrent and comment.torrent:
                self.header += " in %s" % comment.torrent.name
                button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
                button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
                self.additionalButtons.append(button)
        else:
            leftSpacer += depth * (self.avantar.GetWidth() + 7)  # avantar + spacer

        if self.canRemove:
            button = wx.Button(self, -1, 'Remove Comment', style=wx.BU_EXACTFIT)
            button.Bind(wx.EVT_BUTTON, self.RemoveComment)
            self.additionalButtons.append(button)

        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def ShowTorrent(self, event):
        _, comment = self.original_data
        if comment.torrent:
            self.parent_list.parent_list.OnShowTorrent(comment.torrent)

    def RemoveComment(self, event):
        _, comment = self.original_data
        self.parent_list.parent_list.OnRemoveComment(comment)


class CommentActivityItem(CommentItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        _, comment = self.original_data
        self.header = "New comment received, posted %s by %s" % (format_time(comment.time_stamp).lower(), comment.name)

        if not self.inTorrent and comment.torrent:
            self.header += " in %s" % comment.torrent.name
            button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
            button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
            self.additionalButtons.append(button)

        self.body = comment.comment
        self.avantar = GuiImageManager.getInstance().getImage(u"COMMENT", SMALL_ICON_MAX_DIM)

        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)


class NewTorrentActivityItem(AvantarItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        torrent = self.original_data

        self.header = "New torrent received at %s" % (format_time(torrent.time_stamp).lower())
        self.body = torrent.name

        button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
        button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
        self.additionalButtons.append(button)

        self.avantar = GuiImageManager.getInstance().getImage(u"TORRENT_NEW", SMALL_ICON_MAX_DIM)
        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def ShowTorrent(self, event):
        if self.original_data:
            self.parent_list.parent_list.OnShowTorrent(self.original_data)


class TorrentActivityItem(AvantarItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        torrent = self.original_data

        self.header = "Discovered a torrent at %s, injected at %s" % (format_time(torrent.inserted).lower(), format_time(torrent.time_stamp).lower())
        self.body = torrent.name

        button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
        button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
        self.additionalButtons.append(button)

        self.avantar = GuiImageManager.getInstance().getImage(u"TORRENT", SMALL_ICON_MAX_DIM)
        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def ShowTorrent(self, event):
        if self.original_data:
            self.parent_list.parent_list.OnShowTorrent(self.original_data)


class ModificationActivityItem(AvantarItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        modification = self.original_data

        self.header = "Discovered a modification by %s at %s" % (modification.peer_name, format_time(modification.inserted).lower())

        if modification.name == "swift-thumbnails":
            self.guiutility = GUIUtility.getInstance()
            self.session = self.guiutility.utility.session

            thumb_dir = os.path.join(self.session.get_torrent_collecting_dir(), 'thumbs-' + binascii.hexlify(modification.torrent.infohash))
            self.body = []
            if os.path.exists(thumb_dir):
                for single_thumb in os.listdir(thumb_dir)[:4]:
                    bmp = wx.Bitmap(os.path.join(thumb_dir, single_thumb), wx.BITMAP_TYPE_ANY)
                    if bmp.IsOk():
                        res = limit_resolution(bmp.GetSize(), (100, 100))
                        self.body.append(bmp.ConvertToImage().Scale(*res, quality=wx.IMAGE_QUALITY_HIGH).ConvertToBitmap())
            if not self.body:
                self.body = "WARNING: The thumbnails related to this modification could not be found on the filesystem."
        elif modification.name == "video-info":
            video_info = json.loads(modification.value)
            duration = timedelta(seconds=video_info['duration'])
            duration = str(duration).split('.')[0]
            self.body = "Modified the bitrate in '%s kb/s', the duration in '%s', and the resolution in '%dx%d'" % \
                        (video_info['bitrate'], duration, video_info['resolution'][0], video_info['resolution'][1])
        else:
            self.body = "Modified %s in '%s'" % (modification.name, modification.value)

        if modification.torrent:
            self.header += " for torrent '%s'" % modification.torrent.colt_name
            button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
            button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
            self.additionalButtons.append(button)

        self.avantar = GuiImageManager.getInstance().getImage(u"MODIFICATION", SMALL_ICON_MAX_DIM)
        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def ShowTorrent(self, event):
        if self.original_data:
            self.parent_list.parent_list.OnShowTorrent(self.original_data.torrent)


class ModificationItem(AvantarItem):

    def __init__(self, parent, parent_list, columns, data, original_data, leftSpacer=0, rightSpacer=0, showChange=False, list_selected=LIST_SELECTED, list_expanded=LIST_EXPANDED):
        if isinstance(parent, wx.Dialog):
            self.noButton = True
        else:
            self.noButton = not getattr(parent_list.parent_list, 'canModify', True)
        AvantarItem.__init__(self, parent, parent_list, columns, data, original_data, leftSpacer, rightSpacer, showChange, list_selected)

    def AddComponents(self, leftSpacer, rightSpacer):
        modification = self.original_data

        if modification.name == "swift-thumbnails":
            self.guiutility = GUIUtility.getInstance()
            self.session = self.guiutility.utility.session

            thumb_dir = os.path.join(self.session.get_torrent_collecting_dir(), 'thumbs-' + binascii.hexlify(modification.torrent.infohash))
            self.body = []
            if os.path.exists(thumb_dir):
                for single_thumb in os.listdir(thumb_dir)[:4]:
                    bmp = wx.Bitmap(os.path.join(thumb_dir, single_thumb), wx.BITMAP_TYPE_ANY)
                    if bmp.IsOk():
                        res = limit_resolution(bmp.GetSize(), (100, 100))
                        self.body.append(bmp.ConvertToImage().Scale(*res, quality=wx.IMAGE_QUALITY_HIGH).ConvertToBitmap())
            if not self.body:
                self.body = "WARNING: The thumbnails related to this modification could not be found on the filesystem."
        elif modification.name == "video-info":
            video_info = json.loads(modification.value)
            duration = timedelta(seconds=video_info['duration'])
            duration = str(duration).split('.')[0]
            self.body = "Modified the bitrate in '%s kb/s', the duration in '%s', and the resolution in '%dx%d'" % \
                        (video_info['bitrate'], duration, video_info['resolution'][0], video_info['resolution'][1])
        else:
            self.body = modification.value

        gui_image_manager = GuiImageManager.getInstance()
        if modification.moderation:
            moderation = modification.moderation
            self.header = "%s modified by %s,\nbut reverted by %s due to: '%s'" % (modification.name.capitalize(), modification.peer_name, moderation.peer_name, moderation.message)
            self.avantar = gui_image_manager.getImage(u"REVERTED_MODIFICATION", SMALL_ICON_MAX_DIM)
            self.maxlines = 2
        else:
            self.header = "%s modified by %s at %s" % (modification.name.capitalize(), modification.peer_name, format_time(modification.time_stamp).lower())
            self.avantar = gui_image_manager.getImage(u"MODIFICATION", SMALL_ICON_MAX_DIM)

            if not self.noButton:
                button = wx.Button(self, -1, 'Revert Modification', style=wx.BU_EXACTFIT)
                button.Bind(wx.EVT_BUTTON, self.RevertModification)
                self.additionalButtons.append(button)

        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def RevertModification(self, event):
        self.parent_list.parent_list.OnRevertModification(self.original_data)


class ModerationActivityItem(AvantarItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        moderation = self.original_data

        self.header = "Discovered a moderation %s" % (format_time(moderation.inserted).lower())
        self.body = "%s reverted a modification made by %s, reason '%s'" % (moderation.peer_name, moderation.by_peer_name, moderation.message)

        gui_image_manager = GuiImageManager.getInstance()
        self.avantar = gui_image_manager.getImage(u"REVERTED_MODIFICATION", SMALL_ICON_MAX_DIM)
        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)


class ModerationItem(AvantarItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        moderation = self.original_data

        self.header = "%s reverted a modification by %s at %s" % (moderation.peer_name.capitalize(), moderation.by_peer_name, format_time(moderation.time_stamp).lower())

        if moderation.modification:
            modification = moderation.modification
            self.body = "%s reverted due to '%s'.\n" % (modification.name.capitalize(), moderation.message)
            if moderation.severity > 0:
                self.body += "%s additionally issued a warning!\n" % moderation.peer_name.capitalize()
            self.body += "Modification was:\n%s" % modification.value

            if modification.torrent:
                self.header += " for torrent '%s'" % modification.torrent.name
                button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
                button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
                self.additionalButtons.append(button)

        else:
            self.body = moderation.message
        gui_image_manager = GuiImageManager.getInstance()
        self.avantar = gui_image_manager.getImage(u"REVERTED_MODIFICATION", SMALL_ICON_MAX_DIM)

        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def ShowTorrent(self, event):
        if self.original_data:
            self.parent_list.parent_list.OnShowTorrent(self.original_data.modification.torrent)


class MarkingActivityItem(AvantarItem):

    def AddComponents(self, leftSpacer, rightSpacer):
        marking = self.original_data

        self.header = "Discovered an opinion %s" % (format_time(marking.time_stamp).lower())
        self.body = "%s was marked as '%s'" % (marking.torrent.name, marking.type)

        button = wx.Button(self, -1, 'Open Torrent', style=wx.BU_EXACTFIT)
        button.Bind(wx.EVT_BUTTON, self.ShowTorrent)
        self.additionalButtons.append(button)

        gui_image_manager = GuiImageManager.getInstance()
        self.avantar = gui_image_manager.getImage(u"MARKING", SMALL_ICON_MAX_DIM)
        AvantarItem.AddComponents(self, leftSpacer, rightSpacer)

    def ShowTorrent(self, event):
        if self.original_data:
            self.parent_list.parent_list.OnShowTorrent(self.original_data.torrent)

########NEW FILE########
__FILENAME__ = MainFrame
#
# Author : Choopan RATTANAPOKA, Jie Yang, Arno Bakker
#
# Description : Main ABC [Yet Another Bittorrent Client] python script.
#               you can run from source code by using
#               >python abc.py
#               need Python, WxPython in order to run from source code.
#
# see LICENSE.txt for license information
#

import os
import sys
import traceback
import logging
import wx

import subprocess
import atexit
import re
import urlparse

import threading
import time
from traceback import print_exc, print_stack
import urllib

from Tribler.Category.Category import Category

from Tribler.Core.version import version_id
from Tribler.Core.simpledefs import dlstatus_strings, NTFY_MYPREFERENCES, \
    DLSTATUS_ALLOCATING_DISKSPACE, DLSTATUS_SEEDING, \
    NTFY_ACT_NEW_VERSION, NTFY_ACT_NONE, NTFY_ACT_ACTIVE, NTFY_ACT_UPNP, \
    NTFY_ACT_REACHABLE, NTFY_ACT_MEET, NTFY_ACT_GET_EXT_IP_FROM_PEERS, \
    NTFY_ACT_GOT_METADATA, NTFY_ACT_RECOMMEND, NTFY_ACT_DISK_FULL, NTFY_TORRENTS, \
    NTFY_VIDEO_STARTED
from Tribler.Core.exceptions import DuplicateDownloadException
from Tribler.Core.TorrentDef import TorrentDef, TorrentDefNoMetainfo
from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core.Utilities.bencode import bencode, bdecode
from Tribler.Core.Utilities.utilities import parse_magnetlink

from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.Main.Utility.GuiDBHandler import startWorker

from Tribler.Main.Dialogs.ConfirmationDialog import ConfirmationDialog
from Tribler.Main.Dialogs.FeedbackWindow import FeedbackWindow
from Tribler.Main.Dialogs.GUITaskQueue import GUITaskQueue
from Tribler.Main.Dialogs.systray import ABCTaskBarIcon
from Tribler.Main.Dialogs.SaveAs import SaveAs
from Tribler.Main.Dialogs.ThreadSafeProgressDialog import ThreadSafeProgressDialog

from Tribler.Main.vwxGUI.GuiUtility import GUIUtility, forceWxThread
from Tribler.Main.vwxGUI import DEFAULT_BACKGROUND, SEPARATOR_GREY
from Tribler.Main.vwxGUI.list import SearchList, ChannelList, \
    LibraryList, ActivitiesList
from Tribler.Main.vwxGUI.list_details import SearchInfoPanel, ChannelInfoPanel, \
    LibraryInfoPanel, PlaylistInfoPanel, SelectedchannelInfoPanel, \
    TorrentDetails, LibraryDetails, ChannelDetails, PlaylistDetails
from Tribler.Main.vwxGUI.TopSearchPanel import TopSearchPanel, \
    TopSearchPanelStub
from Tribler.Main.vwxGUI.home import Home, Stats
from Tribler.Main.vwxGUI.channel import SelectedChannelList, Playlist, \
    ManageChannel
from Tribler.Main.vwxGUI.SRstatusbar import SRstatusbar

from Tribler.Core.Video.VideoPlayer import VideoPlayer
from Tribler.Core.Video.utils import videoextdefaults


#
#
# Class: FileDropTarget
#
# To enable drag and drop for ABC list in main menu
#
#


class FileDropTarget(wx.FileDropTarget):

    def __init__(self, frame):
        # Initialize the wsFileDropTarget Object
        wx.FileDropTarget.__init__(self)
        # Store the Object Reference for dropped files
        self.frame = frame

    def OnDropFiles(self, x, y, filenames):
        destdir = None
        for filename in filenames:
            if not filename.endswith(".torrent"):
                # lets see if we can find a .torrent in this directory
                head, _ = os.path.split(filename)
                files = os.listdir(head)

                found = False
                for file in files:
                    if file.endswith(".torrent"):  # this is the .torrent, use head as destdir to start seeding
                        filename = os.path.join(head, file)
                        destdir = head

                        found = True
                        break

                if not found:
                    dlg = wx.FileDialog(None, "Tribler needs a .torrent file to start seeding, please select the associated .torrent file.", wildcard="torrent (*.torrent)|*.torrent", style=wx.FD_OPEN)
                    if dlg.ShowModal() == wx.ID_OK:
                        filename = dlg.GetPath()

                        destdir = head
                        found = True
                    dlg.Destroy()
                if not found:
                    break
            try:
                self.frame.startDownload(filename, destdir=destdir, fixtorrent=True)
            except IOError:
                dlg = wx.MessageDialog(None,
                    "File not found or cannot be accessed.",
                    "Tribler Warning", wx.OK | wx.ICON_ERROR)
                dlg.ShowModal()
                dlg.Destroy()
        return True


class MainFrame(wx.Frame):

    def __init__(self, parent, channelonly, internalvideo, progress):
        self._logger = logging.getLogger(self.__class__.__name__)

        print >> sys.stderr, 'GUI started'

        # Do all init here
        self.ready = False
        self.guiUtility = GUIUtility.getInstance()
        self.guiUtility.frame = self
        self.utility = self.guiUtility.utility
        self.params = self.guiUtility.params
        self.utility.frame = self
        self.torrentfeed = None
        self.category = Category.getInstance()
        self.shutdown_and_upgrade_notes = None

        self.guiserver = GUITaskQueue.getInstance()

        title = "Tribler %s" % version_id

        # Get window size and (sash) position from config file
        size, position, sashpos = self.getWindowSettings()
        style = wx.DEFAULT_DIALOG_STYLE | wx.MINIMIZE_BOX | wx.MAXIMIZE_BOX | wx.RESIZE_BORDER | wx.NO_FULL_REPAINT_ON_RESIZE | wx.CLIP_CHILDREN

        wx.Frame.__init__(self, parent, wx.ID_ANY, title, position, size, style)
        if sys.platform == 'linux2':
            font = self.GetFont()
            if font.GetPointSize() > 9:
                font.SetPointSize(9)
                self.SetFont(font)

        self.Freeze()
        self.SetDoubleBuffered(True)
        self.SetBackgroundColour(DEFAULT_BACKGROUND)

        themeColour = wx.SystemSettings.GetColour(wx.SYS_COLOUR_WINDOWTEXT)
        r, g, b = themeColour.Get(False)
        if r > 190 or g > 190 or b > 190:  # Grey == 190,190,190
            self.SetForegroundColour(wx.BLACK)

        if internalvideo:
            self.videoparentpanel = wx.Panel(self)
            self.videoparentpanel.Hide()
        else:
            self.videoparentpanel = None

        # Create all components
        progress('Creating panels')
        if not channelonly:
            self.actlist = ActivitiesList(self)
            self.top_bg = TopSearchPanel(self)
            self.home = Home(self)

            self.splitter = wx.SplitterWindow(self, style=wx.SP_NOBORDER)
            self.splitter.SetMinimumPaneSize(1)
            self.splitter.SetForegroundColour(self.GetForegroundColour())
            self.splitter_top_window = wx.Panel(self.splitter, style=wx.NO_BORDER)
            self.splitter_top_window.SetForegroundColour(self.GetForegroundColour())
            self.splitter_top = wx.BoxSizer(wx.HORIZONTAL)
            self.splitter_top_window.SetSizer(self.splitter_top)
            self.splitter_bottom_window = wx.Panel(self.splitter)
            self.splitter_bottom_window.SetMinSize((-1, 25))
            self.splitter_bottom_window.SetForegroundColour(self.GetForegroundColour())
            self.splitter_bottom_window.OnChange = lambda: self.splitter_bottom.Layout()
            self.splitter_bottom_window.parent_list = self.splitter_bottom_window

            self.searchlist = SearchList(self.splitter_top_window)
            self.searchlist.Show(False)
            self.librarylist = LibraryList(self.splitter_top_window)
            self.librarylist.Show(False)
            self.channellist = ChannelList(self.splitter_top_window)
            self.channellist.Show(False)
            self.selectedchannellist = SelectedChannelList(self.splitter_top_window)
            self.selectedchannellist.Show(False)
            self.playlist = Playlist(self.splitter_top_window)
            self.playlist.Show(False)

            # Populate the bottom window
            self.splitter_bottom = wx.BoxSizer(wx.HORIZONTAL)
            self.torrentdetailspanel = TorrentDetails(self.splitter_bottom_window)
            self.torrentdetailspanel.Show(False)
            self.librarydetailspanel = LibraryDetails(self.splitter_bottom_window)
            self.librarydetailspanel.Show(False)
            self.channeldetailspanel = ChannelDetails(self.splitter_bottom_window)
            self.channeldetailspanel.Show(False)
            self.playlistdetailspanel = PlaylistDetails(self.splitter_bottom_window)
            self.playlistdetailspanel.Show(False)
            self.searchinfopanel = SearchInfoPanel(self.splitter_bottom_window)
            self.searchinfopanel.Show(False)
            self.channelinfopanel = ChannelInfoPanel(self.splitter_bottom_window)
            self.channelinfopanel.Show(False)
            self.libraryinfopanel = LibraryInfoPanel(self.splitter_bottom_window)
            self.libraryinfopanel.Show(False)
            self.playlistinfopanel = PlaylistInfoPanel(self.splitter_bottom_window)
            self.playlistinfopanel.Show(False)
            self.selectedchannelinfopanel = SelectedchannelInfoPanel(self.splitter_bottom_window)
            self.selectedchannelinfopanel.Show(False)
            self.splitter_bottom.Add(self.torrentdetailspanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.librarydetailspanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.channeldetailspanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.playlistdetailspanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.searchinfopanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.channelinfopanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.libraryinfopanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.playlistinfopanel, 1, wx.EXPAND)
            self.splitter_bottom.Add(self.selectedchannelinfopanel, 1, wx.EXPAND)
            self.splitter_bottom_window.SetSizer(self.splitter_bottom)

            self.splitter.SetSashGravity(0.8)
            self.splitter.SplitHorizontally(self.splitter_top_window, self.splitter_bottom_window, sashpos)
            self.splitter.Show(False)

            # Reset the sash position after the splitter has been made visible
            def OnShowSplitter(event):
                wx.CallAfter(self.splitter.SetSashPosition, sashpos)
                self.splitter.Unbind(wx.EVT_SHOW)
                event.Skip()
            self.splitter.Bind(wx.EVT_SHOW, OnShowSplitter)

        else:
            self.actlist = None
            self.top_bg = None

            self.guiUtility.guiPage = 'selectedchannel'
            self.home = None
            self.searchlist = None
            self.librarylist = LibraryList(self)
            self.librarylist.Show(False)
            self.channellist = None
            self.selectedchannellist = SelectedChannelList(self)
            self.selectedchannellist.Show(True)
            self.playlist = Playlist(self)
            self.playlist.Show(False)

        self.stats = Stats(self)
        self.stats.Show(False)
        self.managechannel = ManageChannel(self)
        self.managechannel.Show(False)

        progress('Positioning')

        if not channelonly:
            # position all elements
            vSizer = wx.BoxSizer(wx.VERTICAL)

            vSizer.Add(self.top_bg, 0, wx.EXPAND)

            hSizer = wx.BoxSizer(wx.HORIZONTAL)
            vSizer.Add(hSizer, 1, wx.EXPAND)

            hSizer.Add(self.actlist, 0, wx.EXPAND)
            separator = wx.Panel(self, size=(1, -1))
            separator.SetBackgroundColour(SEPARATOR_GREY)
            hSizer.Add(separator, 0, wx.EXPAND)
            hSizer.Add(self.home, 1, wx.EXPAND)
            hSizer.Add(self.stats, 1, wx.EXPAND)
            hSizer.Add(self.splitter, 1, wx.EXPAND)
        else:
            vSizer = wx.BoxSizer(wx.VERTICAL)
            hSizer = wx.BoxSizer(wx.HORIZONTAL)
            vSizer.Add(hSizer, 1, wx.EXPAND | wx.ALL, 5)

            self.top_bg = TopSearchPanelStub()

        hSizer.Add(self.managechannel, 1, wx.EXPAND)

        if self.videoparentpanel:
            hSizer.Add(self.videoparentpanel, 1, wx.EXPAND)

        self.SetSizer(vSizer)

        # set sizes
        if not channelonly:
            self.top_bg.SetMinSize((-1, 45))
            self.actlist.SetMinSize((200, -1))

        self.SRstatusbar = SRstatusbar(self)
        self.SetStatusBar(self.SRstatusbar)

        def preload_data():
            if not channelonly:
                self.guiUtility.showChannelCategory('All', False)
            self.guiUtility.showLibrary(False)
        startWorker(None, preload_data, delay=1.5, workerType="guiTaskQueue")

        if channelonly:
            self.guiUtility.showChannelFromDispCid(channelonly)
            if internalvideo:
                self.guiUtility.ShowPlayer()

        if sys.platform != 'darwin':
            dragdroplist = FileDropTarget(self)
            self.SetDropTarget(dragdroplist)
        try:
            self.SetIcon(wx.Icon(os.path.join(self.utility.getPath(), 'Tribler', 'Main', 'vwxGUI', 'images', 'tribler.ico'), wx.BITMAP_TYPE_ICO))
        except:
            pass

        self.tbicon = None
        try:
            self.tbicon = ABCTaskBarIcon(self)
        except:
            print_exc()

        # Don't update GUI as often when iconized
        self.GUIupdate = True
        self.window = self.GetChildren()[0]
        self.window.utility = self.utility

        progress('Binding events')
        # Menu Events
        #
        self.Bind(wx.EVT_CLOSE, self.OnCloseWindow)

        # leaving here for the time being:
        # wxMSW apparently sends the event to the App object rather than
        # the top-level Frame, but there seemed to be some possibility of
        # change
        self.Bind(wx.EVT_QUERY_END_SESSION, self.OnCloseWindow)
        self.Bind(wx.EVT_END_SESSION, self.OnCloseWindow)
        self.Bind(wx.EVT_ICONIZE, self.onIconify)
        self.Bind(wx.EVT_SIZE, self.onSize)
        self.Bind(wx.EVT_MAXIMIZE, self.onSize)

        findId = wx.NewId()
        quitId = wx.NewId()
        nextId = wx.NewId()
        prevId = wx.NewId()
        dispId = wx.NewId()
        anonId = wx.NewId()
        DISPERSY_DEBUG_FRAME_ID = wx.NewId()
        self.Bind(wx.EVT_MENU, self.OnFind, id=findId)
        self.Bind(wx.EVT_MENU, lambda event: self.Close(), id=quitId)
        self.Bind(wx.EVT_MENU, self.OnNext, id=nextId)
        self.Bind(wx.EVT_MENU, self.OnPrev, id=prevId)
        self.Bind(wx.EVT_MENU, lambda evt: self.guiUtility.ShowPage('stats'), id=dispId)
        self.Bind(wx.EVT_MENU, lambda evt: self.guiUtility.ShowPage('anonymity'), id=anonId)
        self.Bind(wx.EVT_MENU, self.OnOpenDebugFrame, id=DISPERSY_DEBUG_FRAME_ID)

        accelerators = [(wx.ACCEL_CTRL, ord('f'), findId)]
        accelerators.append((wx.ACCEL_CTRL, ord('d'), dispId))
        accelerators.append((wx.ACCEL_CTRL, ord('n'), anonId))
        accelerators.append((wx.ACCEL_CTRL, wx.WXK_TAB, nextId))
        accelerators.append((wx.ACCEL_CTRL | wx.ACCEL_SHIFT, wx.WXK_TAB, prevId))
        accelerators.append((wx.ACCEL_CTRL | wx.ACCEL_ALT, ord('d'), DISPERSY_DEBUG_FRAME_ID))

        if sys.platform == 'linux2':
            accelerators.append((wx.ACCEL_CTRL, ord('q'), quitId))
            accelerators.append((wx.ACCEL_CTRL, ord('/'), findId))
        self.SetAcceleratorTable(wx.AcceleratorTable(accelerators))

        # Init video player
        print >> sys.stderr, 'GUI ready'
        self.Thaw()
        self.ready = True

        def post():
            self.checkVersion()
            self.startCMDLineTorrent()

        # If the user passed a torrentfile on the cmdline, load it.
        wx.CallAfter(post)

    def OnOpenDebugFrame(self, event=None):
        from Tribler.Main.vwxGUI.DispersyDebugFrame import DispersyDebugFrame
        if not wx.FindWindowByName("DispersyDebugFrame"):
            frame = DispersyDebugFrame(self, -1, self.utility.session.get_dispersy_instance())
            frame.Show()

        if event:
            event.Skip()

    def startCMDLineTorrent(self):
        if self.params[0] != "" and not self.params[0].startswith("--"):
            vod = False
            url_filename = self.params[0]
            selectedFiles = [self.params[1]] if len(self.params) == 2 else []
            if selectedFiles:
                _, ext = os.path.splitext(selectedFiles[0])
                if ext != '' and ext[0] == '.':
                    ext = ext[1:]
                if ext.lower() in videoextdefaults:
                    vod = True

            if url_filename.startswith("magnet:"):
                self.startDownloadFromMagnet(self.params[0], cmdline=True, selectedFiles=selectedFiles, vodmode=vod)
            elif url_filename.startswith("http"):
                self.startDownloadFromUrl(self.params[0], cmdline=True, selectedFiles=selectedFiles, vodmode=vod)
            elif url_filename.startswith("tswift") or url_filename.startswith("ppsp"):
                self.startDownloadFromSwift(url_filename)
            else:
                self.startDownload(url_filename, cmdline=True, selectedFiles=selectedFiles, vodmode=vod)

    def startDownloadFromMagnet(self, url, destdir=None, cmdline=False, selectedFiles=None, vodmode=False, anon_mode=False):
        name, infohash, _ = parse_magnetlink(url)
        tdef = TorrentDefNoMetainfo(infohash, name, url=url)
        wx.CallAfter(self.startDownload, tdef=tdef, cmdline=cmdline, destdir=destdir, selectedFiles=selectedFiles, vodmode=vodmode, anon_mode=anon_mode)
        return True

    def startDownloadFromSwift(self, url, destdir=None):
        url = url.replace("ppsp://", "tswift://127.0.0.1:%d/" % self.utility.session.get_swift_dht_listen_port()) if url.startswith("ppsp://") else url
        sdef = SwiftDef.load_from_url(url)
        sdef.set_name("Unnamed video - " + time.strftime("%d-%m-%Y at %H:%M", time.localtime()))
        wx.CallAfter(self.startDownload, sdef=sdef, destdir=destdir)
        return True

    def startDownloadFromUrl(self, url, destdir=None, cmdline=False, selectedFiles=[], vodmode=False, anon_mode=False):
        try:
            tdef = TorrentDef.load_from_url(url)
            if tdef:
                wx.CallAfter(self.startDownload, tdef=tdef, cmdline=cmdline, destdir=destdir, selectedFiles=selectedFiles, vodmode=vodmode, anon_mode=anon_mode)
                return True
        except:
            print_exc()
        self.guiUtility.Notify("Download from url failed", icon=wx.ART_WARNING)
        return False

    def startDownload(self, torrentfilename=None, destdir=None, sdef=None, tdef=None, cmdline=False, clicklog=None, name=None, vodmode=False, anon_mode=False, fixtorrent=False, selectedFiles=None, correctedFilename=None, hidden=False):
        self._logger.debug("mainframe: startDownload: %s %s %s %s %s %s", torrentfilename, destdir, sdef, tdef, vodmode, selectedFiles)

        if fixtorrent and torrentfilename:
            self.fixTorrent(torrentfilename)

        # Niels: if you call startdownload with both a Swift sdef and a tdef/torrentfilename, we allow Swift to download the file in the first X seconds
        if sdef and (torrentfilename or tdef):
            monitorSwiftProgress = True
        else:
            monitorSwiftProgress = False

        try:
            if torrentfilename and tdef is None:
                tdef = TorrentDef.load(torrentfilename)

            # Prefer to download using libtorrent
            # cdef = sdef or tdef
            cdef = tdef or sdef

            d = self.utility.session.get_download(cdef.get_id())
            if d and cdef.get_def_type() == 'torrent':
                new_trackers = list(set(cdef.get_trackers_as_single_tuple()) - set(d.get_def().get_trackers_as_single_tuple()))
                if not new_trackers:
                    raise DuplicateDownloadException()

                else:
                    @forceWxThread
                    def do_gui():
                        # Show update tracker dialog
                        dialog = wx.MessageDialog(None, 'This torrent is already being downloaded. Do you wish to load the trackers from it?', 'Tribler', wx.YES_NO | wx.NO_DEFAULT | wx.ICON_QUESTION)
                        if dialog.ShowModal() == wx.ID_YES:
                            # Update trackers
                            self.utility.session.update_trackers(cdef.get_id(), new_trackers)
                        dialog.Destroy()

                    do_gui()
                return

            defaultDLConfig = DefaultDownloadStartupConfig.getInstance()
            dscfg = defaultDLConfig.copy()

            cancelDownload = False
            useDefault = not self.utility.read_config('showsaveas')
            if not useDefault and not destdir:
                defaultname = correctedFilename
                if not correctedFilename and tdef and tdef.is_multifile_torrent():
                    defaultname = tdef.get_name_as_unicode()

                if wx.Thread_IsMain():
                    dlg = SaveAs(None, tdef, dscfg.get_dest_dir(), defaultname, selectedFiles)
                    dlg.CenterOnParent()

                    if isinstance(tdef, TorrentDefNoMetainfo):
                        # Correct for the smaller size of the dialog if there is no metainfo
                        center_pos = dlg.GetPosition()
                        center_pos[1] -= 150
                        dlg.SetPosition(center_pos)

                    if dlg.ShowModal() == wx.ID_OK:
                        # If the dialog has collected a torrent, use the new tdef
                        tdef = dlg.GetCollected() or tdef
                        # cdef = sdef or tdef
                        cdef = tdef or sdef

                        # for multifile we enabled correctedFilenames, use split to remove the filename from the path
                        if tdef and tdef.is_multifile_torrent():
                            destdir, correctedFilename = os.path.split(dlg.GetPath())
                            selectedFiles = dlg.GetSelectedFiles()
                        else:
                            destdir = dlg.GetPath()
                        anon_mode = dlg.GetAnonMode()
                    else:
                        cancelDownload = True
                    dlg.Destroy()
                else:
                    raise Exception("cannot create dialog, not on wx thread")

            if anon_mode:
                if not tdef:
                    raise Exception('Currently only torrents can be downloaded in anonymous mode')
                elif sdef:
                    sdef = None
                    cdef = tdef
                    monitorSwiftProgress = False

            dscfg.set_anon_mode(anon_mode)

            if not cancelDownload:
                if destdir is not None:
                    dscfg.set_dest_dir(destdir)

                if correctedFilename:
                    dscfg.set_corrected_filename(correctedFilename)

                if selectedFiles and len(selectedFiles) == 1:
                    # we should filter files to see if they are all playable
                    videofiles = selectedFiles

                elif tdef and not selectedFiles:
                    videofiles = tdef.get_files(exts=videoextdefaults)

                else:
                    videofiles = []

                # disable vodmode if no videofiles, unless we still need to collect the torrent
                if vodmode and len(videofiles) == 0 and (not tdef or not isinstance(tdef, TorrentDefNoMetainfo)):
                    vodmode = False

                vodmode = vodmode or cdef.get_live()

                selectedFile = None
                if vodmode:
                    self._logger.info('MainFrame: startDownload: Starting in VOD mode')
                    result = self.utility.session.start_download(cdef, dscfg)
                    self.guiUtility.library_manager.playTorrent(cdef.get_id(), videofiles[0] if len(videofiles) == 1 else None)

                else:
                    if selectedFiles:
                        if cdef.get_def_type() == 'swift' and tdef:
                            swift_selectedFiles = []
                            for selectedFile in selectedFiles:
                                swift_selectedFiles.append(tdef.get_name_as_unicode() + "/" + selectedFile)
                            dscfg.set_selected_files(swift_selectedFiles)

                        else:
                            dscfg.set_selected_files(selectedFiles)

                    self._logger.debug('MainFrame: startDownload: Starting in DL mode')
                    result = self.utility.session.start_download(cdef, dscfg, hidden=hidden)

                if result and not hidden:
                    self.show_saved(tdef)

                    if monitorSwiftProgress:
                        state_lambda = lambda ds, vodmode = vodmode, torrentfilename = torrentfilename, dscfg = dscfg, selectedFile = selectedFile, selectedFiles = selectedFiles: self.monitorSwiftProgress(ds, vodmode, torrentfilename, dscfg, selectedFile, selectedFiles)
                        result.set_state_callback(state_lambda, delay=15.0)

                if clicklog is not None:
                    mypref = self.utility.session.open_dbhandler(NTFY_MYPREFERENCES)
                    startWorker(None, mypref.addClicklogToMyPreference, wargs=(cdef.get_id(), clicklog))

                return result

        except DuplicateDownloadException as e:
            # If there is something on the cmdline, all other torrents start
            # in STOPPED state. Restart
            if cmdline and cdef.get_def_type() == 'torrent':
                dlist = self.utility.session.get_downloads()
                for d in dlist:
                    if d.get_def().get_infohash() == cdef.get_infohash():
                        d.restart()
                        break

            if wx.Thread_IsMain():
                # show nice warning dialog
                dlg = wx.MessageDialog(None,
                    "You are already downloading this torrent, see the Downloads section.",
                    "Duplicate download", wx.OK | wx.ICON_ERROR)
                result = dlg.ShowModal()
                dlg.Destroy()

            else:
                print_exc()
                self.onWarning(e)

        except Exception as e:
            print_exc()
            self.onWarning(e)

        return None

    def startReseedSwiftDownload(self, tdef, storagepath, sdef):
        # Arno, 2012-05-07:
        self._logger.info("main: frame: startReseedSwift %s %s %s", tdef, storagepath, sdef)

        # 1. Tell library_manager that we have a 'swift_hash' for this infohash
        self.guiUtility.library_manager.updateTorrent(tdef.get_infohash(), sdef.get_roothash())

        # 2. Start swift download reseeding BitTorrent content
        self.startDownload(destdir=storagepath, sdef=sdef, hidden=True)

        # 3. Checkpoint Session
        self.utility.session.checkpoint()

    def modifySelection(self, download, selectedFiles):
        download.set_selected_files(selectedFiles)

    def fixTorrent(self, filename):
        f = open(filename, "rb")
        bdata = f.read()
        f.close()

        # Check if correct bdata
        try:
            bdecode(bdata)
        except ValueError:
            # Try reading using sloppy
            try:
                bdata = bencode(bdecode(bdata, 1))
                # Overwrite with non-sloppy torrent
                f = open(filename, "wb")
                f.write(bdata)
                f.close()
            except:
                return False

        return True

    def monitorSwiftProgress(self, ds, vodmode, torrentfilename, dscfg, selectedFile, selectedFiles):
        if ds.get_progress() == 0:
            if ds.get_status() == DLSTATUS_ALLOCATING_DISKSPACE:
                return (5.0, True)

            download = ds.get_download()
            self.utility.session.remove_download(download)

            # pause for swift file release
            time.sleep(1)

            self._logger.info("Switching to Bittorrent")
            cdef = TorrentDef.load(torrentfilename)
            if vodmode:
                wx.CallAfter(self.startDownload, tdef=cdef, destdir=dscfg.get_dest_dir(), vodmode=True, selectedFiles=[selectedFile] if selectedFile else [])
            else:
                dscfg = dscfg.copy()
                dscfg.set_selected_files(selectedFiles or [])
                self.utility.session.start_download(cdef, dscfg)
        return (0, False)

    @forceWxThread
    def show_saved(self, tdef):
        if self.ready and self.librarylist.isReady:
            torrentname = tdef.get_name_as_unicode() if tdef else ''
            if isinstance(tdef, TorrentDefNoMetainfo):
                if torrentname:
                    self.guiUtility.Notify('Downloading .torrent \'%s\' from DHT' % torrentname, icon='magnet')
                else:
                    self.guiUtility.Notify('Downloading .torrent from DHT', icon='magnet')
            elif torrentname:
                self.guiUtility.Notify("Download started", "Torrent '%s' has been added to the download queue." % torrentname, icon='download')
            else:
                self.guiUtility.Notify("Download started", "A new torrent has been added to the download queue.", icon='download')

            self._logger.info("Allowing refresh in 3 seconds %s", long(time.time() + 3))
            self.librarylist.GetManager().prev_refresh_if = time.time() - 27

    def checkVersion(self):
        self.guiserver.add_task(self._checkVersion, 5.0)

    def _checkVersion(self):
        # Called by GUITaskQueue thread
        my_version = self.utility.getVersion()
        try:
            curr_status = urllib.urlopen('http://tribler.org/version').readlines()
            line1 = curr_status[0]
            if len(curr_status) > 1:
                self.update_url = curr_status[1].strip()
            else:
                self.update_url = 'http://tribler.org'

            info = {}
            if len(curr_status) > 2:
                # the version file contains additional information in
                # "KEY:VALUE\n" format
                pattern = re.compile("^\s*(?<!#)\s*([^:\s]+)\s*:\s*(.+?)\s*$")
                for line in curr_status[2:]:
                    match = pattern.match(line)
                    if match:
                        key, value = match.group(1, 2)
                        if key in info:
                            info[key] += "\n" + value
                        else:
                            info[key] = value

            _curr_status = line1.split()
            self.curr_version = _curr_status[0]
            if self.newversion(self.curr_version, my_version):
                # Arno: we are a separate thread, delegate GUI updates to MainThread
                self.upgradeCallback()

                # Boudewijn: start some background downloads to
                # upgrade on this separate thread
                if len(info) > 0:
                    self._upgradeVersion(my_version, self.curr_version, info)
                else:
                    self._manualUpgrade(my_version, self.curr_version, self.update_url)

            # Also check new version of web2definitions for youtube etc. search
            # Web2Updater(self.utility).checkUpdate()
        except Exception as e:
            self._logger.error("Tribler: Version check failed %s %s", time.ctime(time.time()), str(e))
            # print_exc()

    def _upgradeVersion(self, my_version, latest_version, info):
        # check if there is a .torrent for our OS
        torrent_key = "torrent-%s" % sys.platform
        notes_key = "notes-txt-%s" % sys.platform
        if torrent_key in info:
            self._logger.info("-- Upgrade %s -> %s", my_version, latest_version)
            notes = []
            if "notes-txt" in info:
                notes.append(info["notes-txt"])
            if notes_key in info:
                notes.append(info[notes_key])
            notes = "\n".join(notes)
            if notes:
                for line in notes.split("\n"):
                    self._logger.info("-- Notes: %s", line)
            else:
                notes = "No release notes found"
            self._logger.info("-- Downloading %s for upgrade", info[torrent_key])

            # prepare directort and .torrent file
            location = os.path.join(self.utility.session.get_state_dir(), "upgrade")
            if not os.path.exists(location):
                os.mkdir(location)
            self._logger.info("-- Dir: %s", location)
            filename = os.path.join(location, os.path.basename(urlparse.urlparse(info[torrent_key])[2]))
            self._logger.info("-- File: %s", filename)
            if not os.path.exists(filename):
                urllib.urlretrieve(info[torrent_key], filename)

            # torrent def
            tdef = TorrentDef.load(filename)
            defaultDLConfig = DefaultDownloadStartupConfig.getInstance()
            dscfg = defaultDLConfig.copy()

            # figure out what file to start once download is complete
            files = tdef.get_files_as_unicode()
            executable = None
            for file_ in files:
                if sys.platform == "win32" and file_.endswith(u".exe"):
                    self._logger.info("-- exe: %s", file_)
                    executable = file_
                    break

                elif sys.platform == "linux2" and file_.endswith(u".deb"):
                    self._logger.info("-- deb: %s", file_)
                    executable = file_
                    break

                elif sys.platform == "darwin" and file_.endswith(u".dmg"):
                    self._logger.info("-- dmg: %s", file_)
                    executable = file_
                    break

            if not executable:
                self._logger.info("-- Abort upgrade: no file found")
                return

            # start download
            try:
                download = self.utility.session.start_download(tdef)

            except DuplicateDownloadException:
                self._logger.error("-- Duplicate download")
                download = None
                for random_download in self.utility.session.get_downloads():
                    if random_download.get_def().get_infohash() == tdef.get_infohash():
                        download = random_download
                        break

            # continue until download is finished
            if download:
                def start_upgrade():
                    """
                    Called by python when everything is shutdown.  We
                    can now start the downloaded file that will
                    upgrade tribler.
                    """
                    executable_path = os.path.join(download.get_dest_dir(), executable)

                    if sys.platform == "win32":
                        args = [executable_path]

                    elif sys.platform == "linux2":
                        args = ["gdebi-gtk", executable_path]

                    elif sys.platform == "darwin":
                        args = ["open", executable_path]

                    self._logger.info("-- Tribler closed, starting upgrade")
                    self._logger.info("-- Start: %s", args)
                    subprocess.Popen(args)

                def wxthread_upgrade():
                    """
                    Called on the wx thread when the .torrent file is
                    downloaded.  Will ask the user if Tribler can be
                    shutdown for the upgrade now.
                    """
                    if self.Close():
                        atexit.register(start_upgrade)
                    else:
                        self.shutdown_and_upgrade_notes = None

                def state_callback(state):
                    """
                    Called every n seconds with an update on the
                    .torrent download that we need to upgrade
                    """
                    self._logger.debug("-- State: %s %s", dlstatus_strings[state.get_status()], state.get_progress())
                    # todo: does DLSTATUS_STOPPED mean it has completely downloaded?
                    if state.get_status() == DLSTATUS_SEEDING:
                        self.shutdown_and_upgrade_notes = notes
                        wx.CallAfter(wxthread_upgrade)
                        return (0.0, False)
                    return (1.0, False)

                download.set_state_callback(state_callback)

    @forceWxThread
    def _manualUpgrade(self, my_version, latest_version, url):
        dialog = wx.MessageDialog(self, 'There is a new version of Tribler.\nYour version:\t\t\t\t%s\nLatest version:\t\t\t%s\n\nPlease visit %s to upgrade.' % (my_version, latest_version, url), 'New version of Tribler is available', wx.OK | wx.ICON_INFORMATION)
        dialog.ShowModal()

    def newversion(self, curr_version, my_version):
        curr = curr_version.split('.')
        my = my_version.split('.')
        if len(my) >= len(curr):
            nversion = len(my)
        else:
            nversion = len(curr)
        for i in range(nversion):
            if i < len(my):
                my_v = int(my[i])
            else:
                my_v = 0
            if i < len(curr):
                curr_v = int(curr[i])
            else:
                curr_v = 0
            if curr_v > my_v:
                return True
            elif curr_v < my_v:
                return False
        return False

    @forceWxThread
    def upgradeCallback(self):
        self.setActivity(NTFY_ACT_NEW_VERSION)
        wx.CallLater(6000, self.upgradeCallback)

    # Force restart of Tribler
    @forceWxThread
    def Restart(self):
        path = os.getcwd()
        if sys.platform == "win32":
            executable = "tribler.exe"
        elif sys.platform == "linux2":
            executable = "tribler.sh"
        elif sys.platform == "darwin":
            executable = "?"

        executable = os.path.join(path, executable)
        self._logger.info(repr(executable))

        def start_tribler():
            try:
                subprocess.Popen(executable)
            except:
                print_exc()

        atexit.register(start_tribler)
        self.Close(force=True)

    def OnFind(self, event):
        self.top_bg.SearchFocus()

    def OnNext(self, event):
        self.actlist.NextPage()

    def OnPrev(self, event):
        self.actlist.PrevPage()

    #
    # minimize to tray bar control
    #
    def onTaskBarActivate(self, event=None):
        if not self.GUIupdate:
            self.Iconize(False)
            self.Show(True)
            self.Raise()

            if self.tbicon is not None:
                self.tbicon.updateIcon(False)

            self.GUIupdate = True

    def onIconify(self, event=None):
        # This event handler is called both when being minimalized
        # and when being restored.
        # Arno, 2010-01-15: on Win7 with wxPython2.8-win32-unicode-2.8.10.1-py26
        # there is no event on restore :-(
        if event is not None:
            self._logger.debug("main: onIconify( %s", event.Iconized())
        else:
            self._logger.debug("main: onIconify event None")

        if event.Iconized():
            # Niels, 2011-06-17: why pause the video? This does not make any sense
            # videoplayer = VideoPlayer.getInstance()
            # videoplayer.pause_playback() # when minimzed pause playback

            if self.utility.read_config('mintray') == 1:
                self.tbicon.updateIcon(True)
                self.Show(False)

            self.GUIupdate = False
        else:
            # Niels, 2011-06-17: why pause the video? This does not make any sense
            # at least make it so, that it will only resume if it was actually paused by the minimize action

            # videoplayer = VideoPlayer.getInstance()
            # videoplayer.resume_playback()

            self.GUIupdate = True
        if event is not None:
            event.Skip()

    def onSize(self, event=None):
        # Arno: On Windows when I enable the tray icon and then change
        # virtual desktop (see MS DeskmanPowerToySetup.exe)
        # I get a onIconify(event.Iconized()==True) event, but when
        # I switch back, I don't get an event. As a result the GUIupdate
        # remains turned off. The wxWidgets wiki on the TaskBarIcon suggests
        # catching the onSize event.
        if event is not None:
            self._logger.debug("main: onSize: %s", self.GetSize())
        else:
            self._logger.debug("main: onSize: None")

        self.GUIupdate = True
        if event is not None:
            if event.GetEventType() == wx.EVT_MAXIMIZE:
                self.window.SetClientSize(self.GetClientSize())
            event.Skip()

    def getWindowSettings(self):
        width = self.utility.read_config("window_width")
        height = self.utility.read_config("window_height")
        try:
            size = wx.Size(int(width), int(height))
        except:
            size = wx.Size(1024, 670)

        x = self.utility.read_config("window_x")
        y = self.utility.read_config("window_y")
        if (x == "" or y == "" or x == 0 or y == 0):
            # position = wx.DefaultPosition

            # On Mac, the default position will be underneath the menu bar, so lookup (top,left) of
            # the primary display
            primarydisplay = wx.Display(0)
            dsize = primarydisplay.GetClientArea()
            position = dsize.GetTopLeft()

            # Decrease size to fit on screen, if needed
            width = min(size.GetWidth(), dsize.GetWidth())
            height = min(size.GetHeight(), dsize.GetHeight())
            size = wx.Size(width, height)
        else:
            position = wx.Point(int(x), int(y))
        sashpos = self.utility.read_config("sash_position")
        try:
            sashpos = int(sashpos)
        except:
            sashpos = -185

        return size, position, sashpos

    def saveWindowSettings(self):
        width, height = self.GetSizeTuple()
        x, y = self.GetPositionTuple()
        self.utility.write_config("window_width", width)
        self.utility.write_config("window_height", height)
        self.utility.write_config("window_x", x)
        self.utility.write_config("window_y", y)

        if self.splitter.IsShownOnScreen() and self.splitter.IsSplit():
            self.utility.write_config("sash_position", self.splitter.GetSashPosition())

        self.utility.flush_config()

    #
    # Close Program
    #

    def OnCloseWindow(self, event=None, force=False):
        found = False
        if event != None:
            nr = event.GetEventType()
            lookup = {wx.EVT_CLOSE.evtType[0]: "EVT_CLOSE", wx.EVT_QUERY_END_SESSION.evtType[0]: "EVT_QUERY_END_SESSION", wx.EVT_END_SESSION.evtType[0]: "EVT_END_SESSION"}
            if nr in lookup:
                nr = lookup[nr]
                found = True

            self._logger.info("mainframe: Closing due to event %s %s", nr, repr(event))
        else:
            self._logger.info("mainframe: Closing untriggered by event")

        # Don't do anything if the event gets called twice for some reason
        if self.utility.abcquitting:
            return

        # Check to see if we can veto the shutdown
        # (might not be able to in case of shutting down windows)
        if event is not None:
            try:
                if isinstance(event, wx.CloseEvent) and event.CanVeto() and self.utility.read_config('confirmonclose') and not event.GetEventType() == wx.EVT_QUERY_END_SESSION.evtType[0]:
                    if self.shutdown_and_upgrade_notes:
                        confirmmsg = "Do you want to close Tribler and upgrade to the next version?  See release notes below" + "\n\n" + self.shutdown_and_upgrade_notes
                        confirmtitle = "Upgrade Tribler?"
                    else:
                        confirmmsg = "Do you want to close Tribler?"
                        confirmtitle = "Confirm"

                    dialog_name = 'closeconfirmation'
                    if not self.shutdown_and_upgrade_notes and not self.guiUtility.ReadGuiSetting('show_%s' % dialog_name, default=True):
                        result = wx.ID_OK
                    else:
                        dialog = ConfirmationDialog(None, dialog_name, confirmmsg, title=confirmtitle)
                        result = dialog.ShowModal()
                        dialog.Destroy()

                    if result != wx.ID_OK:
                        event.Veto()

                        self._logger.info("mainframe: Not closing messagebox did not return OK")
                        return
            except:
                print_exc()

        print >> sys.stderr, 'GUI closing'
        self.utility.abcquitting = True
        self.GUIupdate = False

        if self.videoframe:
            self._logger.info("mainframe: Stopping internal player")

            self.videoframe.get_videopanel().Stop()

        try:
            self._logger.info("mainframe: Restoring from taskbar")

            # Restore the window before saving size and position
            # (Otherwise we'll get the size of the taskbar button and a negative position)
            self.onTaskBarActivate()
            self.saveWindowSettings()
        except:
            print_exc()

        if self.tbicon is not None:
            try:
                self._logger.info("mainframe: Removing tbicon")

                self.tbicon.RemoveIcon()
                self.tbicon.Destroy()
            except:
                print_exc()

        self._logger.info("mainframe: Calling quit")
        self.quit(event != None or force)

        self._logger.debug("mainframe: OnCloseWindow END")
        ts = threading.enumerate()
        for t in ts:
            self._logger.info("mainframe: Thread still running %s daemon %s", t.getName(), t.isDaemon())

        print >> sys.stderr, 'GUI closed'

    @forceWxThread
    def onWarning(self, exc):
        msg = "A non-fatal error occured during Tribler startup, you may need to change the network Preferences:  \n\n"
        msg += str(exc.__class__) + ':' + str(exc)
        dlg = wx.MessageDialog(None, msg, "Tribler Warning", wx.OK | wx.ICON_WARNING)
        result = dlg.ShowModal()
        dlg.Destroy()

    def exceptionHandler(self, exc, fatal=False):
        type, value, stack = sys.exc_info()
        backtrace = traceback.format_exception(type, value, stack)

        def do_gui():
            win = FeedbackWindow("Tribler Warning")
            win.SetParent(self)
            win.CreateOutputWindow('')
            for line in backtrace:
                win.write(line)

            if fatal:
                win.Show()

        wx.CallAfter(do_gui)

    def progressHandler(self, title, message, maximum):
        return ThreadSafeProgressDialog(title, message, maximum, self, wx.PD_APP_MODAL | wx.PD_ELAPSED_TIME | wx.PD_ESTIMATED_TIME | wx.PD_REMAINING_TIME | wx.PD_AUTO_HIDE)

    def onUPnPError(self, upnp_type, listenport, error_type, exc=None, listenproto='TCP'):

        if error_type == 0:
            errormsg = unicode(' UPnP mode ' + str(upnp_type) + ' ') + "request to the firewall failed."
        elif error_type == 1:
            errormsg = unicode(' UPnP mode ' + str(upnp_type) + ' ') + "request to firewall returned:  '" + unicode(str(exc)) + "'. "
        elif error_type == 2:
            errormsg = unicode(' UPnP mode ' + str(upnp_type) + ' ') + "was enabled, but initialization failed."
        else:
            errormsg = unicode(' UPnP mode ' + str(upnp_type) + ' Unknown error')

        msg = "An error occured while trying to open the listen port "
        msg += listenproto + ' '
        msg += str(listenport)
        msg += " on the firewall."
        msg += errormsg
        msg += " This will hurt the performance of Tribler.\n\nTo fix this, configure your firewall/router/modem or try setting a different listen port or UPnP mode in (advanced) network Preferences."

        dlg = wx.MessageDialog(None, msg, "Tribler Warning", wx.OK | wx.ICON_WARNING)
        result = dlg.ShowModal()
        dlg.Destroy()

    def setActivity(self, type, msg=u'', arg2=None):
        try:
            # print >>sys.stderr,"MainFrame: setActivity: t",type,"m",msg,"a2",arg2
            if self.utility is None:
                self._logger.debug("MainFrame: setActivity: Cannot display: t %s m %s a2 %s", type, msg, arg2)
                return

            if not wx.Thread_IsMain():
                self._logger.debug("main: setActivity thread %s is NOT MAIN THREAD", threading.currentThread().getName())
                print_stack()

            if type == NTFY_ACT_NONE:
                prefix = msg
                msg = u''
            elif type == NTFY_ACT_ACTIVE:
                prefix = u""
                if msg == "no network":
                    text = "No network - last activity: %.1f seconds ago" % arg2
                    self.SetTitle(text)
                    self._logger.info("main: Activity %s", repr(text))
                elif self.GetTitle().startswith("No network"):
                    title = "Tribler %s" % version_id
                    self.SetTitle(title)

            elif type == NTFY_ACT_UPNP:
                prefix = "Opening firewall (if any) via UPnP"
            elif type == NTFY_ACT_REACHABLE:
                prefix = "Seeing if not firewalled"
            elif type == NTFY_ACT_GET_EXT_IP_FROM_PEERS:
                prefix = "Asking peers for my IP address"
            elif type == NTFY_ACT_MEET:
                prefix = "Person connected: "
            elif type == NTFY_ACT_GOT_METADATA:
                prefix = "File discovered:"

                if self.category.family_filter_enabled() and arg2 == 7:  # XXX category
                    self._logger.debug("MainFrame: setActivity: Hiding XXX torrent %s", msg)
                    return

            elif type == NTFY_ACT_RECOMMEND:
                prefix = "Discovered more persons and files from"
            elif type == NTFY_ACT_DISK_FULL:
                prefix = "Disk is full to collect more torrents. Please change your preferences or free space on "
            elif type == NTFY_ACT_NEW_VERSION:
                prefix = "New version of Tribler available"
            if msg == u'':
                text = prefix
            else:
                text = unicode(prefix + u' ' + msg)

            self._logger.debug("main: Activity %s", repr(text))
            self.SRstatusbar.onActivity(text)
            self.stats.onActivity(text)
        except wx.PyDeadObjectError:
            pass

    def set_wxapp(self, wxapp):
        self.wxapp = wxapp

    @forceWxThread
    def quit(self, force=True):
        self._logger.info("mainframe: in quit")
        if self.wxapp is not None:
            self._logger.info("mainframe: using self.wxapp")
            app = self.wxapp
        else:
            self._logger.info("mainframe: got app from wx")
            app = wx.GetApp()

        self._logger.info("mainframe: looping through toplevelwindows")
        for item in wx.GetTopLevelWindows():
            if item != self:
                if isinstance(item, wx.Dialog):
                    self._logger.info("mainframe: destroying %s", item)
                    item.Destroy()
                item.Close()
        self._logger.info("mainframe: destroying %s", self)
        self.Destroy()

        if app:
            def doexit():
                app.ExitMainLoop()
                wx.WakeUpMainThread()

            wx.CallLater(1000, doexit)
            if force:
                wx.CallLater(2500, app.Exit)

########NEW FILE########
__FILENAME__ = MainVideoFrame
# Written by Fabian van der Werf and Arno Bakker
# see LICENSE.txt for license information

import wx

from Tribler.Main.vwxGUI.EmbeddedPlayer import EmbeddedPlayerPanel


class VideoDummyFrame(object):

    """ Provides a fake Frame around an EmbeddedPlayerPanel so the embedded player
    can be shown inside another window.
    """

    def __init__(self, parent, utility, vlcwrap):
        self.videopanel = EmbeddedPlayerPanel(parent, utility, vlcwrap, wx.BLACK)
        self.parent = parent
        self.utility = utility
        self.vlcwrap = vlcwrap

        if vlcwrap:
            sizer = wx.BoxSizer()
            sizer.Add(self.videopanel, 1, wx.EXPAND)
            parent.SetSizer(sizer)
        else:
            self.videopanel.Hide()

    def recreate_vlc_window(self):
        self.videopanel.RecreateVLCWindow()

    def get_videopanel(self):
        return self.videopanel

########NEW FILE########
__FILENAME__ = SearchGridManager
# Written by Jelle Roozenburg, Maarten ten Brinke, Lucan Musat, Arno Bakker
# see LICENSE.txt for license information
import json
import logging
import os
import threading
from math import sqrt
from time import time
from traceback import print_exc

import wx

from Tribler.Category.Category import Category
from Tribler.Core.CacheDB.sqlitecachedb import bin2str, str2bin, forceAndReturnDBThread, forceDBThread
from Tribler.Core.RemoteTorrentHandler import RemoteTorrentHandler
from Tribler.Core.Search.Bundler import Bundler
from Tribler.Core.Search.Reranking import DefaultTorrentReranker
from Tribler.Core.Search.SearchManager import split_into_keywords
from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core.TorrentDef import TorrentDef, TorrentDefNoMetainfo
from Tribler.Core.Utilities.utilities import parse_magnetlink
from Tribler.Core.Video.VideoPlayer import VideoPlayer
from Tribler.Core.Video.utils import videoextdefaults
from Tribler.Core.simpledefs import (NTFY_MISC, NTFY_TORRENTS, NTFY_MYPREFERENCES, NTFY_VOTECAST, NTFY_CHANNELCAST,
                                     NTFY_METADATA, DLSTATUS_METADATA, DLSTATUS_WAITING4HASHCHECK)
from Tribler.Main.Utility.GuiDBHandler import startWorker, GUI_PRI_DISPERSY
from Tribler.Main.Utility.GuiDBTuples import (Torrent, ChannelTorrent, CollectedTorrent, RemoteTorrent,
                                              NotCollectedTorrent, LibraryTorrent, Comment, Modification, Channel,
                                              RemoteChannel, Playlist, Moderation, RemoteChannelTorrent, Marking,
                                              MetadataModification)
from Tribler.Main.globals import DefaultDownloadStartupConfig
from Tribler.Main.vwxGUI import (warnWxThread, forceWxThread, TORRENT_REQ_COLUMNS, LIBRARY_REQ_COLUMNS,
                                 CHANNEL_REQ_COLUMNS, PLAYLIST_REQ_COLUMNS, MODIFICATION_REQ_COLUMNS,
                                 MODERATION_REQ_COLUMNS, MARKING_REQ_COLUMNS, COMMENT_REQ_COLUMNS,
                                 TUMBNAILTORRENT_REQ_COLUMNS)
from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice
from Tribler.TrackerChecking.TorrentChecking import TorrentChecking
from Tribler.community.allchannel.community import AllChannelCommunity
from Tribler.community.channel.community import (ChannelCommunity, warnDispersyThread)
from Tribler.community.metadata.community import MetadataCommunity
from Tribler.community.search.community import SearchCommunity
from Tribler.dispersy.exception import CommunityNotFoundException
from Tribler.dispersy.util import call_on_reactor_thread


SEARCHMODE_STOPPED = 1
SEARCHMODE_SEARCHING = 2
SEARCHMODE_NONE = 3
VOTE_LIMIT = -5


class TorrentManager:
    # Code to make this a singleton
    __single = None

    def __init__(self, guiUtility):
        if TorrentManager.__single:
            raise RuntimeError("TorrentManager is singleton")

        self._logger = logging.getLogger(self.__class__.__name__)

        self.guiUtility = guiUtility
        self.dispersy = None
        self.col_torrent_dir = None
        self.connected = False

        # Contains all matches for keywords in DB, not filtered by category
        self.hits = []
        self.hitsLock = threading.Lock()

        # Remote results for current keywords
        self.remoteHits = []
        self.gotRemoteHits = False
        self.remoteLock = threading.Lock()

        # Requests for torrents
        self.requestedTorrents = set()
        self.requestedTorrentsMessages = set()

        # For asking for a refresh when remote results came in
        self.gridmgr = None
        self.searchkeywords = []
        self.rerankingStrategy = DefaultTorrentReranker()
        self.oldsearchkeywords = None

        self.filteredResults = 0

        self.bundler = Bundler()
        self.bundle_mode = None
        self.bundle_mode_changed = True

        self.category = Category.getInstance()
        self.xxx_category = 0

    def getInstance(*args, **kw):
        if TorrentManager.__single is None:
            TorrentManager.__single = TorrentManager(*args, **kw)
        return TorrentManager.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        TorrentManager.__single = None
    delInstance = staticmethod(delInstance)

    def getCollectedFilename(self, torrent, retried=False):
        """
        TORRENT is a dictionary containing torrent information used to
        display the entry on the UI. it is NOT the torrent file!

        Returns a filename, if filename is known
        """
        torrent_filename = torrent.torrent_file_name
        if torrent_filename and os.path.isfile(torrent_filename):
            return torrent_filename

        # .torrent not found
        if torrent.swift_torrent_hash:
            sdef = SwiftDef(torrent.swift_torrent_hash)
            torrent_filename = torrent_filename = os.path.join(self.col_torrent_dir, sdef.get_roothash_as_hex())

            if os.path.isfile(torrent_filename):
                try:
                    tdef = TorrentDef.load(torrent_filename)

                    @forceDBThread
                    def do_db():
                        if self.torrent_db.hasTorrent(torrent.infohash):
                            self.torrent_db.updateTorrent(torrent.infohash, torrent_file_name=torrent_filename)
                        else:
                            self.torrent_db._addTorrentToDB(tdef, source="BC", extra_info={'filename': torrent_filename, 'status': 'good'})
                    do_db()

                    torrent.torrent_file_name = torrent_filename
                    return torrent_filename

                except ValueError:
                    pass  # bad bedecoded torrent, ie not complete yet

        if not retried:
            # reload torrent to see if database contains any changes
            dict = self.torrent_db.getTorrent(torrent.infohash, keys=['torrent_id', 'swift_torrent_hash', 'torrent_file_name'], include_mypref=False)
            if dict:
                torrent.update_torrent_id(dict['torrent_id'])
                torrent.swift_torrent_hash = dict['swift_torrent_hash']
                torrent.torrent_file_name = dict['torrent_file_name']
                return self.getCollectedFilename(torrent, retried=True)

    def getCollectedFilenameFromDef(self, torrentdef):
        torrent = self.getTorrentByInfohash(torrentdef.infohash)
        if torrent:
            return self.getCollectedFilename(torrent)

    def getTorrent(self, torrent, callback, prio=0):
        """
        TORRENT is a dictionary containing torrent information used to
        display the entry on the UI. it is NOT the torrent file!

        CALLBACK is called when the torrent is downloaded. When no
        torrent can be downloaded the callback is ignored
        As a first argument the filename of the torrent is passed

        Returns a boolean + request_type
        describing if the torrent is requested
        """

        if self.downloadTorrentfileFromPeers(torrent, callback, duplicate=True, prio=prio):
            candidates = torrent.query_candidates
            if candidates and len(candidates) > 0:
                return (True, "from peers")
            return (True, "from the dht")
        return False

    def downloadTorrentfileFromPeers(self, torrent, callback, duplicate=True, prio=0):
        """
        TORRENT is a GuiDBTuple containing torrent information used to
        display the entry on the UI. it is NOT the torrent file!

        CALLBACK is called when the torrent is downloaded. When no
        torrent can be downloaded the callback is ignored
        As a first argument the filename of the torrent is passed

        DUPLICATE can be True: the file will be downloaded from peers
        regardless of a previous/current download attempt (returns
        True). Or DUPLICATE can be False: the file will only be
        downloaded when it was not yet attempted to download (when
        False is returned no callback will be made)

        PRIO is the priority, default is 0 which means we need this torrent now.
        If PRIO != 0, then a rate limiter could be used by the remotetorrentrequester

        Returns True or False
        """

        # return False when duplicate
        if not duplicate and torrent.infohash in self.requestedTorrents:
            return False

        if torrent.query_candidates == None or len(torrent.query_candidates) == 0:
            self.session.download_torrentfile(torrent.infohash, torrent.swift_torrent_hash, callback, prio)

        else:
            # only add to requestedTorrents if we have peers
            self.requestedTorrents.add(torrent.infohash)

            for candidate in torrent.query_candidates:
                self.session.download_torrentfile_from_peer(candidate, torrent.infohash, torrent.swift_torrent_hash, callback, prio)

        return True

    def downloadTorrentmessageFromPeer(self, torrent, callback=None, duplicate=True, prio=0):
        """
        TORRENT is a GuiDBTuple containing torrent information used to
        display the entry on the UI. it is NOT the torrent file!

        CALLBACK is called when the torrent is downloaded. When no
        torrent can be downloaded the callback is ignored

        DUPLICATE can be True: the message will be downloaded from peers
        regardless of a previous/current download attempt (returns
        True). Or DUPLICATE can be False: the message will only be
        downloaded when it was not yet attempted to download (when
        False is returned no callback will be made)

        PRIO is the priority, default is 0 which means we need this torrent now.
        If PRIO != 0, then a rate limiter could be used by the remotetorrentrequester

        Returns True or False
        """
        # return False when duplicate
        if not duplicate and torrent.infohash in self.requestedTorrentsMessages:
            return False

        if torrent.query_candidates == None or len(torrent.query_candidates) == 0:
            return False

        else:
            # only add to requestedTorrents if we have peers
            self.requestedTorrentsMessages.add(torrent.infohash)

            for candidate in torrent.query_candidates:
                self.session.download_torrentmessage_from_peer(candidate, torrent.infohash, callback, prio)
        return True

    def downloadTorrent(self, torrent, dest=None, secret=False, vodmode=False, selectedFiles=None):
        torrent_filename = self.getCollectedFilename(torrent)

        name = torrent.get('name', torrent.infohash)
        clicklog = {'keywords': self.searchkeywords,
                    'reranking_strategy': self.rerankingStrategy.getID()}

        if "click_position" in torrent:
            clicklog["click_position"] = torrent["click_position"]

        sdef = SwiftDef(torrent.swift_hash, "127.0.0.1:%d" % self.session.get_swift_dht_listen_port()) if torrent.swift_hash else None
        tdef = TorrentDefNoMetainfo(torrent.infohash, torrent.name) if not isinstance(torrent_filename, basestring) else None

        # Api download
        def do_gui():
            d = self.guiUtility.frame.startDownload(torrent_filename, sdef=sdef, tdef=tdef, destdir=dest, clicklog=clicklog, name=name, vodmode=vodmode, selectedFiles=selectedFiles)  # # remove name=name
            if d:
                if secret:
                    self.torrent_db.setSecret(torrent.infohash, secret)

                self._logger.debug('standardDetails: download: download started')
        wx.CallAfter(do_gui)

        return bool(tdef)

    def loadTorrent(self, torrent, callback=None):
        if not isinstance(torrent, CollectedTorrent):
            torrent_filename = self.getCollectedFilename(torrent)
            if not torrent_filename:
                files = []
                trackers = []

                # see if we have most info in our tables
                if isinstance(torrent, RemoteTorrent):
                    torrent_id = self.torrent_db.getTorrentID(torrent.infohash)
                else:
                    torrent_id = torrent.torrent_id

                if torrent_id and torrent_id != -1:
                    files = self.torrent_db.getTorrentFiles(torrent_id)

                    collectingSources = self.torrent_db.getTorrentCollecting(torrent_id)
                    for source, in collectingSources:
                        if source.startswith('magnet'):
                            _, _, trs = parse_magnetlink(source)
                            trackers.extend(trs)

                trackers.extend(self.torrent_db.getTrackerListByTorrentID(torrent_id))

                if 'DHT' in trackers:
                    trackers.remove('DHT')
                if 'no-DHT' in trackers:
                    trackers.remove('no-DHT')

                if len(files) > 0:
                    # We still call getTorrent to fetch .torrent
                    self.getTorrent(torrent, None)

                    torrent = NotCollectedTorrent(torrent, files, trackers)
                else:
                    torrent_callback = lambda torfilename: self.loadTorrent(torrent, callback)
                    torrent_filename = self.getTorrent(torrent, torrent_callback)

                    if torrent_filename[0]:
                        return torrent_filename[1]
            else:
                try:
                    tdef = TorrentDef.load(torrent_filename)

                except ValueError:
                    # we should move fixTorrent to this object
                    if self.guiUtility.frame.fixTorrent(torrent_filename):
                        tdef = TorrentDef.load(torrent_filename)

                    else:
                        # cannot repair torrent, removing
                        os.remove(torrent_filename)
                        return self.loadTorrent(torrent, callback)

                if torrent.torrent_id <= 0:
                    del torrent.torrent_id

                torrent = CollectedTorrent(torrent, tdef)

        self.library_manager.addDownloadState(torrent)
        if not callback is None:
            callback(torrent)
        else:
            return torrent

    def getTorrentByInfohash(self, infohash):
        dict = self.torrent_db.getTorrent(infohash, keys=['C.torrent_id', 'infohash', 'swift_hash', 'swift_torrent_hash', 'name', 'torrent_file_name', 'length', 'category_id', 'status_id', 'num_seeders', 'num_leechers'])
        if dict:
            t = Torrent(dict['C.torrent_id'], dict['infohash'], dict['swift_hash'], dict['swift_torrent_hash'], dict['name'], dict['torrent_file_name'], dict['length'], dict['category_id'], dict['status_id'], dict['num_seeders'], dict['num_leechers'], None)
            t.misc_db = self.misc_db
            t.torrent_db = self.torrent_db
            t.channelcast_db = self.channelcast_db
            t.metadata_db = self.metadata_db

            # prefetching channel, metadata
            _ = t.channel
            _ = t.metadata
            return t

    def set_gridmgr(self, gridmgr):
        self.gridmgr = gridmgr

    def connect(self, session, library_manager, channel_manager):
        if not self.connected:
            self.connected = True
            self.session = session
            self.col_torrent_dir = self.session.get_torrent_collecting_dir()

            self.misc_db = session.open_dbhandler(NTFY_MISC)
            self.metadata_db = session.open_dbhandler(NTFY_METADATA)
            self.torrent_db = session.open_dbhandler(NTFY_TORRENTS)
            self.mypref_db = session.open_dbhandler(NTFY_MYPREFERENCES)
            self.votecastdb = session.open_dbhandler(NTFY_VOTECAST)
            self.channelcast_db = session.open_dbhandler(NTFY_CHANNELCAST)

            self.library_manager = library_manager
            self.channel_manager = channel_manager

            self.dispersy = session.lm.dispersy
            self.xxx_category = self.misc_db.categoryName2Id([u'xxx'])
        else:
            raise RuntimeError('TorrentManager already connected')

    def getSearchSuggestion(self, keywords, limit=1):
        return self.torrent_db.getSearchSuggestion(keywords, limit)

    @warnDispersyThread
    def searchDispersy(self):
        nr_requests_made = 0
        if self.dispersy:
            for community in self.dispersy.get_communities():
                if isinstance(community, SearchCommunity):
                    nr_requests_made = community.create_search(self.searchkeywords, self.gotDispersyRemoteHits)
                    if not nr_requests_made:
                        self._logger.info("Could not send search in SearchCommunity, no verified candidates found")
                    break

            else:
                self._logger.info("Could not send search in SearchCommunity, community not found")

        else:
            self._logger.info("Could not send search in SearchCommunity, Dispersy not found")

        return nr_requests_made

    def getHitsInCategory(self, categorykey='all', sort='fulltextmetric'):
        begintime = time()
        # categorykey can be 'all', 'Video', 'Document', ...
        bundle_mode = self.bundle_mode

        self._logger.debug("TorrentSearchManager: getHitsInCategory: %s", categorykey)

        try:
            # locking hits variable
            self.hitsLock.acquire()

            # 1. Local search puts hits in self.hits
            beginlocalsearch = time()
            new_local_hits = self.searchLocalDatabase()

            self._logger.debug('TorrentSearchGridManager: getHitsInCat: search found: %d items took %s', len(self.hits), time() - beginlocalsearch)

            # 2. Add remote hits that may apply.
            new_remote_hits, modified_hits = self.addStoredRemoteResults()

            self._logger.debug('TorrentSearchGridManager: getHitsInCat: found after remote search: %d items', len(self.hits))

            beginsort = time()

            if new_local_hits or new_remote_hits:
                if sort == 'rameezmetric':
                    self.rameezSort()

                elif sort == 'fulltextmetric':
                    self.fulltextSort()

                self.hits = self.rerankingStrategy.rerank(self.hits, self.searchkeywords, self.torrent_db,
                                                         None, self.mypref_db, None)

                self.hits = self.library_manager.addDownloadStates(self.hits)

                # boudewijn: now that we have sorted the search results we
                # want to prefetch the top N torrents.
                startWorker(None, self.prefetch_hits, delay=1, uId=u"PREFETCH_RESULTS", workerType="guiTaskQueue")

            beginbundle = time()

        finally:
            self.hitsLock.release()

        # Niels: important, we should not change self.hits otherwise prefetching will not work
        returned_hits, selected_bundle_mode = self.bundler.bundle(self.hits, bundle_mode, self.searchkeywords)

        self._logger.debug('TorrentSearchGridManager: getHitsInCat took: %s of which sort took %s, bundle took %s', time() - begintime, beginbundle - beginsort, time() - beginbundle)

        bundle_mode_changed = self.bundle_mode_changed or (selected_bundle_mode != bundle_mode)
        self.bundle_mode_changed = False

        return [len(returned_hits), self.filteredResults, new_local_hits or new_remote_hits or bundle_mode_changed, selected_bundle_mode, returned_hits, modified_hits]

    def prefetch_hits(self):
        """
        Prefetching attempts to reduce the time required to get the
        user the data it wants.

        We assume the torrent at the beginning of self.hits are more
        likely to be selected by the user than the ones at the
        end. This allows us to perform prefetching operations on a
        subselection of these items.

        The prefetch_hits function can be called multiple times. It
        will only attempt to prefetch every PREFETCH_DELAY
        seconds. This gives search results from multiple sources the
        chance to be received and sorted before prefetching a subset.
        """
        begin_time = time()

        def sesscb_prefetch_done(torrent_fn):
            try:
                tdef = TorrentDef.load(torrent_fn)

                # find the original hit
                for hit in self.hits:
                    if hit.infohash == tdef.get_infohash():
                        self._logger.debug("Prefetch: in %.1fs %s", time() - begin_time, hit.name)
                        return
                self._logger.debug("Prefetch BUG. We got a hit from something we didn't ask for")
            except:
                pass

        # we will prefetch 2 types of torrents, full .torrent files and torrentmessages (only containing the info dict)
        hit_counter_limit = [25, 150]
        prefetch_counter = [0, 0]
        prefetch_counter_limit = [5, 10]

        for i, hit in enumerate(self.hits):
            torrent_filename = self.getCollectedFilename(hit, retried=True)
            if not torrent_filename:
                # this .torrent is not collected, decide if we want to collect it, or only collect torrentmessage
                if prefetch_counter[0] < prefetch_counter_limit[0] and i < hit_counter_limit[0]:
                    if self.downloadTorrentfileFromPeers(hit, lambda _, infohash=hit.infohash: sesscb_prefetch_done(infohash), duplicate=False, prio=1):
                        self._logger.debug("Prefetch: attempting to download actual torrent %s", hit.name)
                        prefetch_counter[0] += 1

                elif prefetch_counter[1] < prefetch_counter_limit[1] and i < hit_counter_limit[1]:
                    if self.downloadTorrentmessageFromPeer(hit, None, duplicate=False, prio=1):
                        self._logger.debug("Prefetch: attempting to download torrent message %s", hit.name)
                        prefetch_counter[1] += 1
                else:
                    break

            else:
                # schedule health check
                TorrentChecking.getInstance().addGuiRequest(hit)

    def getSearchKeywords(self):
        return self.searchkeywords, len(self.hits), self.filteredResults

    def setSearchKeywords(self, wantkeywords):
        if wantkeywords != self.searchkeywords:
            try:
                self.hitsLock.acquire()
                self.remoteLock.acquire()

                self.bundle_mode = None
                self.searchkeywords = [kw for kw in wantkeywords if kw != '']
                self._logger.debug("TorrentSearchGridManager: keywords: %s; time: %s", self.searchkeywords, time())

                self.filteredResults = 0

                self.hits = []
                self.remoteHits = []
                self.gotRemoteHits = False
                self.oldsearchkeywords = None
            finally:
                self.hitsLock.release()
                self.remoteLock.release()

    def setBundleMode(self, bundle_mode, refresh=True):
        if bundle_mode != self.bundle_mode:
            self.bundle_mode = bundle_mode
            self.bundle_mode_changed = True
            if refresh:
                self.refreshGrid()

    def searchLocalDatabase(self):
        """ Called by GetHitsInCategory() to search local DB. Caches previous query result. """
        if self.searchkeywords == self.oldsearchkeywords:
            self._logger.debug("TorrentSearchGridManager: searchLocalDB: returning old hit list %s", len(self.hits))
            return False
        self.oldsearchkeywords = self.searchkeywords

        self._logger.debug("TorrentSearchGridManager: searchLocalDB: Want %s", self.searchkeywords)

        if len(self.searchkeywords) == 0:
            return False

        return self._doSearchLocalDatabase()

    @forceAndReturnDBThread
    def _doSearchLocalDatabase(self):
        begintime = time()

        results = self.torrent_db.searchNames(self.searchkeywords, doSort=False, keys=TORRENT_REQ_COLUMNS)

        begintuples = time()

        if len(results) > 0:
            def create_channel(a):
                return Channel(*a)

            channels = {}
            for a in results:
                channel_details = a[-10:]
                if channel_details[0] and channel_details[0] not in channels:
                    channels[channel_details[0]] = create_channel(channel_details)

            def create_torrent(a):
                channel = channels.get(a[-10], False)
                if channel and (channel.isFavorite() or channel.isMyChannel()):
                    t = ChannelTorrent(*a[:-12] + [channel, None])
                else:
                    t = Torrent(*a[:11] + [False])

                t.misc_db = self.misc_db
                t.torrent_db = self.torrent_db
                t.channelcast_db = self.channelcast_db
                t.metadata_db = self.metadata_db
                t.assignRelevance(a[-11])
                return t

            results = map(create_torrent, results)
        self.hits = results

        self._logger.debug('TorrentSearchGridManager: _doSearchLocalDatabase took: %s of which tuple creation took %s', time() - begintime, time() - begintuples)
        return True

    def addStoredRemoteResults(self):
        """ Called by GetHitsInCategory() to add remote results to self.hits """
        begintime = time()
        try:
            hitsUpdated = False
            hitsModified = set()

            with self.remoteLock:
                hits = self.remoteHits
                self.remoteHits = []

            for remoteItem in hits:
                known = False

                for item in self.hits:
                    if item.infohash == remoteItem.infohash:
                        if item.query_candidates == None:
                            item.query_candidates = set()
                        item.query_candidates.update(remoteItem.query_candidates)

                        if item.swift_hash == None:
                            item.swift_hash = remoteItem.swift_hash
                            hitsModified.add(item.infohash)

                        if item.swift_torrent_hash == None:
                            item.swift_torrent_hash = remoteItem.swift_torrent_hash
                            hitsModified.add(item.infohash)

                        if remoteItem.hasChannel():
                            if isinstance(item, RemoteTorrent):
                                self.hits.remove(item)  # Replace this item with a new result with a channel
                                break

                            # Maybe update channel?
                            if isinstance(item, RemoteChannelTorrent):
                                this_rating = remoteItem.channel.nr_favorites - remoteItem.channel.nr_spam

                                if item.hasChannel():
                                    current_rating = item.channel.nr_favorites - item.channel.nr_spam
                                else:
                                    current_rating = this_rating - 1

                                if this_rating > current_rating:
                                    item.updateChannel(remoteItem.channel)
                                    hitsModified.add(item.infohash)

                        known = True
                        break

                if not known:
                    # Niels 26-10-2012: override category if name is xxx
                    if remoteItem.category_id != self.xxx_category:
                        local_category = self.category.calculateCategoryNonDict([], remoteItem.name, '', '')[0]
                        if local_category == 'xxx':
                            self._logger.debug('TorrentSearchGridManager: %s is xxx', remoteItem.name)
                            remoteItem.category_id = self.xxx_category

                    self.hits.append(remoteItem)
                    hitsUpdated = True

            return hitsUpdated, hitsModified
        except:
            raise

        finally:
            self.remoteRefresh = False

            self._logger.debug("TorrentSearchGridManager: addStoredRemoteResults: %s", time() - begintime)

        return False, []

    def gotDispersyRemoteHits(self, keywords, results, candidate):
        refreshGrid = False
        try:
            self._logger.debug("TorrentSearchGridManager: gotRemoteHist: got %s unfiltered results for %s %s %s", len(results), keywords, candidate, time())

            if self.searchkeywords == keywords:
                self.gotRemoteHits = True

                channeldict = {}
                channels = set([result[-1] for result in results if result[-1]])
                if len(channels) > 0:
                    _, channels = self.channel_manager.getChannelsByCID(channels)

                    for channel in channels:
                        channeldict[channel.dispersy_cid] = channel

                for result in results:
                    categories = result[4]
                    category_id = self.misc_db.categoryName2Id(categories)

                    channel = channeldict.get(result[-1], False)
                    if channel:
                        remoteHit = RemoteChannelTorrent(-1, result[0], result[8], result[9], result[1], result[2], category_id, self.misc_db.torrentStatusName2Id(u'good'), result[6], result[7], channel, set([candidate]))
                    else:
                        remoteHit = RemoteTorrent(-1, result[0], result[8], result[9], result[1], result[2], category_id, self.misc_db.torrentStatusName2Id(u'good'), result[6], result[7], set([candidate]))

                    # Guess matches
                    keywordset = set(keywords)
                    swarmnameset = set(split_into_keywords(remoteHit.name))
                    matches = {'fileextensions': set()}
                    matches['swarmname'] = swarmnameset & keywordset  # all keywords matching in swarmname
                    matches['filenames'] = keywordset - matches['swarmname']  # remaining keywords should thus me matching in filenames or fileextensions

                    if len(matches['filenames']) == 0:
                        _, ext = os.path.splitext(result[0])
                        ext = ext[1:]

                        matches['filenames'] = matches['swarmname']
                        matches['filenames'].discard(ext)

                        if ext in keywordset:
                            matches['fileextensions'].add(ext)
                    remoteHit.assignRelevance(matches)
                    remoteHit.misc_db = self.misc_db
                    remoteHit.torrent_db = self.torrent_db
                    remoteHit.channelcast_db = self.channelcast_db

                    with self.remoteLock:
                        self.remoteHits.append(remoteHit)
                    refreshGrid = True
        finally:
            if self.gridmgr:
                self.gridmgr.NewResult(keywords)

            if refreshGrid:
                self._logger.debug("TorrentSearchGridManager: gotRemoteHist: scheduling refresh")
                self.refreshGrid(remote=True)
            else:
                self._logger.debug("TorrentSearchGridManager: gotRemoteHist: not scheduling refresh")

    def refreshGrid(self, remote=False):
        if self.gridmgr:
            self.gridmgr.refresh(remote)

    # Rameez: The following code will call normalization functions and then
    # sort and merge the torrent results
    def rameezSort(self):
        norm_num_seeders = self.doStatNormalization(self.hits, 'num_seeders')
        norm_neg_votes = self.doStatNormalization(self.hits, 'neg_votes')
        norm_subscriptions = self.doStatNormalization(self.hits, 'subscriptions')

        def score_cmp(a, b):
            info_a = a.infohash
            info_b = b.infohash

            # normScores can be small, so multiply
            score_a = 0.8 * norm_num_seeders[info_a] - 0.1 * norm_neg_votes[info_a] + 0.1 * norm_subscriptions[info_a]
            score_b = 0.8 * norm_num_seeders[info_b] - 0.1 * norm_neg_votes[info_b] + 0.1 * norm_subscriptions[info_b]

            return cmp(score_a, score_b)

        self.hits.sort(cmp, reverse=True)

    def fulltextSort(self):
        norm_num_seeders = self.doStatNormalization(self.hits, 'num_seeders')
        norm_neg_votes = self.doStatNormalization(self.hits, 'neg_votes')
        norm_subscriptions = self.doStatNormalization(self.hits, 'subscriptions')

        for hit in self.hits:
            score = 0.8 * norm_num_seeders[hit.infohash] - 0.1 * norm_neg_votes[hit.infohash] + 0.1 * norm_subscriptions[hit.infohash]
            hit.relevance_score[-1] = score

        self.hits.sort(key=lambda hit: hit.relevance_score, reverse=True)

    def doStatNormalization(self, hits, normKey):
        '''Center the variance on zero (this means mean == 0) and divide
        all values by the standard deviation. This is sometimes called scaling.
        This is done on the field normKey of hits.'''

        tot = 0
        for hit in hits:
            tot += (hit.get(normKey, 0) or 0)

        if len(hits) > 0:
            mean = tot / len(hits)
        else:
            mean = 0

        sum = 0
        for hit in hits:
            temp = (hit.get(normKey, 0) or 0) - mean
            temp = temp * temp
            sum += temp

        if len(hits) > 1:
            dev = sum / (len(hits) - 1)
        else:
            dev = 0

        stdDev = sqrt(dev)

        return_dict = {}
        for hit in hits:
            if stdDev > 0:
                return_dict[hit.infohash] = ((hit.get(normKey, 0) or 0) - mean) / stdDev
            else:
                return_dict[hit.infohash] = 0
        return return_dict


    @call_on_reactor_thread
    def modifyTorrent(self, torrent, modifications):
        for community in self.dispersy.get_communities():
            if isinstance(community, MetadataCommunity):
                community.create_metadata_message(torrent.infohash,
                    torrent.swift_hash, modifications)
                break


    def getTorrentModifications(self, torrent):
        message_list = self.metadata_db.getMetadataMessageList(
            torrent.infohash, torrent.swift_hash,
            columns=("message_id",))
        if not message_list:
            return []

        metadata_mod_list = []
        for message_id, in message_list:
            data_list = self.metadata_db.getMetadataData(message_id)
            for key, value in data_list:
                metadata_mod_list.append(MetadataModification(torrent, message_id, key, value))

        return metadata_mod_list

    def createMetadataModificationFromDef(self, channel_id, tdef, extraInfo={}, forward=True, guitorrent=None):
        torrent = guitorrent if guitorrent else Torrent.fromTorrentDef(tdef)

        modifications = []
        for key, value in extraInfo.iteritems():
            if key == 'thumbnail-tempdir':
                continue
            elif key == 'thumbnail-file-list':
                continue
            modifications.append((key, value))

        # handle the downloaded thumbnails
        if extraInfo['thumbnail-file-list']:
            from Tribler.Main.vwxGUI.TorrentStateManager import TorrentStateManager
            result = TorrentStateManager.getInstance()._create_metadata_roothash_and_contenthash(extraInfo['thumbnail-tempdir'], torrent)
            if result:
                roothash_hex, contenthash_hex = result
                modifications.append(('swift-thumbs', json.dumps((None, roothash_hex, contenthash_hex))))

            self.modifyTorrent(torrent, modifications)

        return True

    def getThumbnailTorrents(self, limit=20):
        result = []
        for t in self.metadata_db.getThumbnailTorrents(TUMBNAILTORRENT_REQ_COLUMNS, limit=limit):
            t = Torrent(*(list(t) + [None]))
            t.misc_db = self.misc_db
            t.torrent_db = self.torrent_db
            result.append(t)
        return result

class LibraryManager:
    # Code to make this a singleton
    __single = None

    def __init__(self, guiUtility):
        if LibraryManager.__single:
            raise RuntimeError("LibraryManager is singleton")

        self._logger = logging.getLogger(self.__class__.__name__)

        self.guiUtility = guiUtility
        self.connected = False

        # Contains all matches for keywords in DB, not filtered by category
        self.hits = []
        self.dslist = []
        self.magnetlist = {}

        # current progress of download states
        self.cache_progress = {}
        self.last_progress_update = time()
        self.rerankingStrategy = DefaultTorrentReranker()

        # For asking for a refresh when remote results came in
        self.gridmgr = None

        # Gui callbacks
        self.gui_callback = []
        self.user_download_choice = UserDownloadChoice.get_singleton()
        self.wantpeers = []

        self.last_vod_torrent = None

    def getInstance(*args, **kw):
        if LibraryManager.__single is None:
            LibraryManager.__single = LibraryManager(*args, **kw)
        return LibraryManager.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        LibraryManager.__single = None
    delInstance = staticmethod(delInstance)

    @warnWxThread
    def _get_videoplayer(self):
        """
        Returns the VideoPlayer instance.
        """
        return VideoPlayer.getInstance()

    def download_state_callback(self, dslist):
        """
        Called by any thread
        """
        self.dslist = dslist
        startWorker(None, self._do_gui_callback, uId=u"LibraryManager_refresh_callbacks", workerType="guiTaskQueue")

        if time() - self.last_progress_update > 10:
            self.last_progress_update = time()
            startWorker(None, self.updateProgressInDB, uId=u"LibraryManager_refresh_callbacks", retryOnBusy=True, priority=GUI_PRI_DISPERSY)

        return self.wantpeers

    def magnet_started(self, infohash):
        self.magnetlist[infohash] = [long(time()), 0, 0]

    def magnet_got_peers(self, infohash, total_peers):
        if infohash not in self.magnetlist:
            self.magnet_started(infohash)
        self.magnetlist[infohash][1] = total_peers

    def magnet_got_piece(self, infohash, progress):
        if infohash not in self.magnetlist:
            self.magnet_started(infohash)
        self.magnetlist[infohash][2] = progress

    def magnet_close(self, infohash):
        if infohash in self.magnetlist:
            del self.magnetlist[infohash]

        return self.wantpeers

    @forceWxThread
    def _do_gui_callback(self):
        dslist = self.dslist[:]
        magnetlist = self.magnetlist.copy()

        for callback in self.gui_callback:
            try:
                callback(dslist, magnetlist)
            except:
                print_exc()

    def updateProgressInDB(self):
        for ds in self.dslist[:]:
            id = ds.get_download().get_def().get_id()
            progress = (ds.get_progress() or 0.0) * 100.0

            # update progress if difference is larger than 5%
            if progress - self.cache_progress.get(id, 0) > 5:
                self.cache_progress[id] = progress
                try:
                    self.mypref_db.updateProgressByHash(id, progress)
                except:
                    print_exc()

    def add_download_state_callback(self, callback):
        if callback not in self.gui_callback:
            self.gui_callback.append(callback)

    def remove_download_state_callback(self, callback):
        if callback in self.gui_callback:
            self.gui_callback.remove(callback)

    def set_want_peers(self, hashes, enable=True):
        if not enable:
            for h in hashes:
                if h in self.wantpeers:
                    self.wantpeers.remove(h)
        else:
            for h in hashes:
                if hash not in self.wantpeers:
                    self.wantpeers.append(h)

    def addDownloadState(self, torrent):
        # Add downloadstate data to a torrent instance
        for ds in self.dslist:
            torrent.addDs(ds)
        if torrent.infohash in self.magnetlist:
            torrent.magnetstatus = self.magnetlist[torrent.infohash]
        return torrent

    def addDownloadStates(self, torrentlist):
        for torrent in torrentlist:
            for ds in self.dslist:
                torrent.addDs(ds)
            if torrent.infohash in self.magnetlist:
                torrent.magnetstatus = self.magnetlist[torrent.infohash]
        return torrentlist

    def startLastVODTorrent(self):
        if self.last_vod_torrent:
            self.playTorrent(*self.last_vod_torrent)

    def stopLastVODTorrent(self):
        if self.last_vod_torrent:
            self.stopTorrent(self.last_vod_torrent[0])

    @forceWxThread
    def playTorrent(self, infohash, selectedinfilename=None):
        # Videoplayer calls should be on GUI thread, hence forceWxThread

        download = self.session.get_download(infohash)
        if download:
            self.last_vod_torrent = [infohash, selectedinfilename]
            self.guiUtility.ShowPlayer()
            self.stopPlayback()
            self.guiUtility.frame.actlist.expandedPanel_videoplayer.Reset()

            # Call _playDownload when download is ready
            wait_state = [DLSTATUS_METADATA, DLSTATUS_WAITING4HASHCHECK]
            status = download.get_status()
            if status in wait_state:
                fetch_msg = "Fetching torrent..."
                if status == DLSTATUS_METADATA:
                    self.guiUtility.frame.actlist.expandedPanel_videoplayer.SetMessage(fetch_msg, True)

                def wait_until_collected(ds):
                    # Try to kill callbacks from previous calls
                    if [infohash, selectedinfilename] != self.last_vod_torrent:
                        return (0, False)
                    # Wait until we know for sure that the download has metadata
                    elif ds.get_status() in wait_state:
                        if ds.get_status() == DLSTATUS_METADATA:
                            self.guiUtility.frame.actlist.expandedPanel_videoplayer.SetMessage(fetch_msg, True)
                        return (1.0, False)
                    # Play the download
                    self._playDownload(infohash, selectedinfilename)
                    return (0, False)
                download.set_state_callback(wait_until_collected)
            else:
                self._playDownload(infohash, selectedinfilename)
        else:
            def do_db():
                torrent = self.guiUtility.torrentsearch_manager.getTorrentByInfohash(infohash)
                filename = self.guiUtility.torrentsearch_manager.getCollectedFilename(torrent)
                if filename:
                    tdef = TorrentDef.load(filename)
                else:
                    tdef = TorrentDefNoMetainfo(infohash, torrent.name)
                return tdef

            def do_gui(delayedResult):
                tdef = delayedResult.get()
                download = self.guiUtility.frame.startDownload(tdef=tdef, destdir=DefaultDownloadStartupConfig.getInstance().get_dest_dir(), vodmode=True)

            startWorker(do_gui, do_db, retryOnBusy=True, priority=GUI_PRI_DISPERSY)

    @forceWxThread
    def _playDownload(self, infohash, selectedinfilename):
        download = self.session.get_download(infohash)
        tdef = download.get_def()

        # Default: pick largest videofile
        if not selectedinfilename:
            videofiles = tdef.get_files_as_unicode(exts=videoextdefaults)

            if not videofiles:
                if self.guiUtility.frame.videoparentpanel:
                    self.guiUtility.frame.actlist.expandedPanel_videoplayer.SetMessage("Torrent has no video files.")
                return

            if self.guiUtility.frame.videoparentpanel:
                selectedinfilename = sorted(videofiles, key=lambda x: tdef.get_length(selectedfiles=[x]))[-1]
            else:
                selectedinfilename = self.guiUtility.SelectVideo(videofiles, selectedinfilename)

            if not selectedinfilename:
                return

        fileindex = tdef.get_files_as_unicode().index(selectedinfilename)
        videoplayer = self._get_videoplayer()
        videoplayer.play(download, fileindex)

        # Notify playlist panel
        if self.guiUtility.frame.videoparentpanel:
            self.guiUtility.frame.actlist.expandedPanel_videoplayer.SetTorrentDef(tdef, fileindex)

    def stopPlayback(self):
        if self.guiUtility.frame.videoframe:
            self.guiUtility.frame.videoframe.get_videopanel().Reset()
            self.guiUtility.frame.videoframe.recreate_vlc_window()
        videoplayer = self._get_videoplayer()
        videoplayer.set_vod_download(None)

    def startDownloadFromUrl(self, url, useDefault=False):
        if useDefault:
            dscfg = DefaultDownloadStartupConfig.getInstance()
            destdir = dscfg.get_dest_dir()
        else:
            destdir = None

        if url.startswith("http"):
            self.guiUtility.frame.startDownloadFromUrl(url, destdir)
        elif url.startswith("magnet:"):
            self.guiUtility.frame.startDownloadFromMagnet(url, destdir)

    def resumeTorrent(self, torrent, force_seed=False):
        downloads = self._getDownloads(torrent)
        resumed = False
        for download in downloads:
            if download:
                download.restart()
                resumed = True

                id = download.get_def().get_id()
                self.user_download_choice.set_download_state(id, "restartseed" if force_seed and download.get_progress() == 1.0 else "restart")

        if not resumed:
            filename = self.torrentsearch_manager.getCollectedFilename(torrent)
            if filename:
                tdef = TorrentDef.load(filename)

                destdirs = self.mypref_db.getMyPrefStats(torrent.torrent_id)
                destdir = destdirs.get(torrent.torrent_id, None)
                if destdir:
                    destdir = destdir[-1]
                self.guiUtility.frame.startDownload(tdef=tdef, destdir=destdir)
            else:
                callback = lambda torrentfilename: self.resumeTorrent(torrent)
                self.torrentsearch_manager.getTorrent(torrent, callback)

    def stopTorrent(self, torrent):
        downloads = self._getDownloads(torrent) if not isinstance(torrent, basestring) else [self.session.get_download(torrent)]
        for download in downloads:
            if download:
                self.stopVideoIfEqual(download)
                download.stop()

                id = download.get_def().get_id()
                self.user_download_choice.set_download_state(id, "stop")

    def _getDownloads(self, torrent):
        downloads = []
        for curdownload in self.session.get_downloads():
            id = curdownload.get_def().get_id()
            if id == torrent.infohash or id == torrent.swift_hash:
                downloads.append(curdownload)
        return downloads

    def updateTorrent(self, infohash, roothash):
        self.torrent_db.updateTorrent(infohash, swift_hash=roothash)

        # Niels 09-01-2013: we need to commit now to prevent possibly forgetting the link between this torrent and the roothash
        dispersy = self.session.lm.dispersy
        startWorker(None, dispersy.database.commit)

    def deleteTorrent(self, torrent, removecontent=False):
        if torrent.dslist:
            dslist = torrent.dslist
        else:
            dslist = [None, None]

        for i, ds in enumerate(dslist):
            if i == 0:
                id = torrent.infohash
            else:
                id = torrent.swift_hash
            self.deleteTorrentDS(ds, id, removecontent)

    def deleteTorrentDS(self, ds, infohash, removecontent=False):
        if not ds is None:
            self.stopVideoIfEqual(ds.download, reset_playlist=True)
            self.deleteTorrentDownload(ds.get_download(), infohash, removecontent)

        elif infohash:
            self.deleteTorrentDownload(None, infohash, removecontent)

    def deleteTorrentDownload(self, download, id, removecontent=False, removestate=True):
        if download:
            self.session.remove_download(download, removecontent=removecontent, removestate=removestate)
        else:
            self.session.remove_download_by_id(id, removecontent, removestate)

        if id:
            self.user_download_choice.remove_download_state(id)

    def stopVideoIfEqual(self, download, reset_playlist=False):
        videoplayer = self._get_videoplayer()
        playd = videoplayer.get_vod_download()

        if playd == download:
            self.stopPlayback()

            if reset_playlist:
                self.guiUtility.frame.actlist.expandedPanel_videoplayer.Reset()

    def connect(self, session, torrentsearch_manager, channelsearch_manager):
        if not self.connected:
            self.session = session
            self.misc_db = session.open_dbhandler(NTFY_MISC)
            self.torrent_db = session.open_dbhandler(NTFY_TORRENTS)
            self.channelcast_db = session.open_dbhandler(NTFY_CHANNELCAST)
            self.mypref_db = session.open_dbhandler(NTFY_MYPREFERENCES)

            self.torrentsearch_manager = torrentsearch_manager
            self.channelsearch_manager = channelsearch_manager
            self.connected = True
        else:
            raise RuntimeError('LibrarySearchGridManager is already connected')

    def getHitsInCategory(self):
        begintime = time()

        results = self.torrent_db.getLibraryTorrents(LIBRARY_REQ_COLUMNS)

        if len(results) > 0:
            channelDict = {}
            channels = set((result[0] for result in results))
            if len(channels) > 0:
                _, channels = self.channelsearch_manager.getChannels(channels)
                for channel in channels:
                    channelDict[channel.id] = channel

            def create_torrent(a):
                t = ChannelTorrent(*a[1:-1] + [channelDict.get(a[0], False), None])

                t.misc_db = self.misc_db
                t.torrent_db = self.torrent_db
                t.channelcast_db = self.channelcast_db
                t._progress = a[-1] / 100.0
                return t

            results = map(create_torrent, results)

            # use best channel torrent
            torrentdict = {}
            for torrent in results:
                if torrent.infohash not in torrentdict:
                    torrentdict[torrent.infohash] = torrent
                else:
                    competitor = torrentdict[torrent.infohash]
                    if competitor.channel and torrent.channel:
                        if competitor.channel.nr_favorites < torrent.channel.nr_favorites:
                            torrentdict[torrent.infohash] = torrent

                        elif competitor.channel.nr_favorites == torrent.channel.nr_favorites and competitor.channel.nr_spam > torrent.channel.nr_spam:
                            torrentdict[torrent.infohash] = torrent
                    elif torrent.channel:
                        torrentdict[torrent.infohash] = torrent

            results = torrentdict.values()

        def sort_by_name(a, b):
            return cmp(a.name.lower(), b.name.lower())

        results.sort(cmp=sort_by_name)

        # Niels: maybe create a clever reranking for library results, for now disable
        # results = self.rerankingStrategy.rerank(results, '', self.torrent_db, self.pref_db, self.mypref_db, self.search_db)

        self._logger.debug('getHitsInCat took: %s', time() - begintime)

        self.hits = self.addDownloadStates(results)
        return [len(self.hits), self.hits]

    def getTorrentFromInfohash(self, infohash):
        dict = self.torrent_db.getTorrent(infohash, keys=['C.torrent_id', 'infohash', 'swift_hash', 'swift_torrent_hash', 'name', 'torrent_file_name', 'length', 'category_id', 'status_id', 'num_seeders', 'num_leechers'])
        if dict and dict['myDownloadHistory']:
            t = LibraryTorrent(dict['C.torrent_id'], dict['infohash'], dict['swift_hash'], dict['swift_torrent_hash'], dict['name'], dict['torrent_file_name'], dict['length'], dict['category_id'], dict['status_id'], dict['num_seeders'], dict['num_leechers'], None)
            t.misc_db = self.misc_db
            t.torrent_db = self.torrent_db
            t.channelcast_db = self.channelcast_db

            # touch channel to force load
            t.channel
            self.addDownloadState(t)
            return t

    def exists(self, infohashes):
        prefrerences = self.mypref_db.getMyPrefListInfohash(returnDeleted=False)
        for infohash in infohashes:
            if infohash in prefrerences:
                self._logger.info("%s missing in library", bin2str(infohash))
                return True
        return False

    def set_gridmgr(self, gridmgr):
        self.gridmgr = gridmgr

    def refreshGrid(self):
        if self.gridmgr is not None:
            self.gridmgr.refresh()


class ChannelManager:
    # Code to make this a singleton
    __single = None

    def __init__(self):
        if ChannelManager.__single:
            raise RuntimeError("ChannelManager is singleton")
        self.connected = False

        self._logger = logging.getLogger(self.__class__.__name__)

        # Contains all matches for keywords in DB, not filtered by category
        self.hits = {}
        self.remoteHits = []
        self.remoteLock = threading.Lock()
        self.remoteRefresh = False

        self.misc_db = None
        self.channelcast_db = None
        self.votecastdb = None
        self.dispersy = None

        # For asking for a refresh when remote results came in
        self.gridmgr = None

        self.searchkeywords = []
        self.oldsearchkeywords = []

        self.category = Category.getInstance()

    def getInstance(*args, **kw):
        if ChannelManager.__single is None:
            ChannelManager.__single = ChannelManager(*args, **kw)
        return ChannelManager.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        ChannelManager.__single = None
    delInstance = staticmethod(delInstance)

    def connect(self, session, library_manager, torrentsearch_manager):
        if not self.connected:
            self.connected = True
            self.session = session
            self.misc_db = self.session.open_dbhandler(NTFY_MISC)
            self.torrent_db = self.session.open_dbhandler(NTFY_TORRENTS)
            self.channelcast_db = self.session.open_dbhandler(NTFY_CHANNELCAST)
            self.votecastdb = self.session.open_dbhandler(NTFY_VOTECAST)
            self.torrentsearch_manager = torrentsearch_manager
            self.library_manager = library_manager
            self.remote_th = RemoteTorrentHandler.getInstance()

            self.dispersy = session.lm.dispersy
        else:
            raise RuntimeError('ChannelManager already connected')

    def set_gridmgr(self, gridmgr):
        self.gridmgr = gridmgr

    def getChannel(self, channel_id):
        channel = self.channelcast_db.getChannel(channel_id)
        return self._getChannel(channel)

    def getChannelByCid(self, channel_cid):
        channel = self.channelcast_db.getChannelByCID(channel_cid)
        return self._getChannel(channel)

    def getChannelByPermid(self, channel_permid):
        channel = self.channelcast_db.getChannelFromPermid(channel_permid)
        return self._getChannel(channel)

    def _getChannel(self, channel):
        if channel:
            channel = self._createChannel(channel)

            # check if we need to convert our vote
            if channel.isDispersy() and channel.my_vote != 0:
                dispersy_id = self.votecastdb.getDispersyId(channel.id, None) or ''
                if dispersy_id <= 0:
                    timestamp = self.votecastdb.getTimestamp(channel.id, None)
                    self.do_vote(channel.id, channel.my_vote, timestamp)

        return channel

    def getChannels(self, channel_ids):
        channels = self.channelcast_db.getChannels(channel_ids)
        return self._createChannels(channels)

    def getChannelsByCID(self, channel_cids):
        channels = self.channelcast_db.getChannelsByCID(channel_cids)
        return self._createChannels(channels)

    def getChannelState(self, channel_id):
        community = self._disp_get_community_from_channel_id(channel_id)
        return community.get_channel_mode()

    def getChannelStateByCID(self, dispersy_cid):
        community = self._disp_get_community_from_cid(dispersy_cid)
        if community:
            return community.get_channel_mode()

    def setChannelState(self, channel_id, channel_mode):
        community = self._disp_get_community_from_channel_id(channel_id)
        return community.set_channel_mode(channel_mode)

    def getPermidFromChannel(self, channel_id):
        return self.channelcast_db.getPermidForChannel(channel_id)

    def getNewChannels(self):
        two_months = time() - 5259487

        newchannels = self.channelcast_db.getNewChannels(two_months)
        return self._createChannels(newchannels)

    def getAllChannels(self):
        allchannels = self.channelcast_db.getAllChannels()
        return self._createChannels(allchannels)

    def getMySubscriptions(self):
        subscriptions = self.channelcast_db.getMySubscribedChannels(includeDispsersy=True)
        return self._createChannels(subscriptions)

    def getPopularChannels(self):
        pchannels = self.channelcast_db.getMostPopularChannels()
        return self._createChannels(pchannels)

    def getUpdatedChannels(self):
        lchannels = self.channelcast_db.getLatestUpdated()
        return self._createChannels(lchannels)

    def getMyChannels(self):
        if self.channelcast_db._channel_id:
            return 1, [self.getChannel(self.channelcast_db._channel_id)]
        return 0, []

    def _createChannel(self, hit):
        return Channel(*hit)

    def _createChannels(self, hits, filterTorrents=True):
        channels = []
        for hit in hits:
            channel = Channel(*hit)
            channels.append(channel)

        return len(channels), channels

    def getTorrentMarkings(self, channeltorrent_id):
        return self.channelcast_db.getTorrentMarkings(channeltorrent_id)

    def getTorrentFromChannel(self, channel, infohash, collectedOnly=True):
        data = self.channelcast_db.getTorrentFromChannelId(channel.id, infohash, CHANNEL_REQ_COLUMNS)
        return self._createTorrent(data, channel, collectedOnly=collectedOnly)

    def getChannnelTorrents(self, infohash, filterTorrents=False):
        hits = self.channelcast_db.getChannelTorrents(infohash, CHANNEL_REQ_COLUMNS)
        return self._createTorrents(hits, filterTorrents)

    def getTorrentFromChannelTorrentId(self, channel, channeltorrent_id, collectedOnly=True):
        data = self.channelcast_db.getTorrentFromChannelTorrentId(channeltorrent_id, CHANNEL_REQ_COLUMNS)
        return self._createTorrent(data, channel, collectedOnly=collectedOnly)

    def getTorrentsFromChannel(self, channel, filterTorrents=True, limit=None):
        hits = self.channelcast_db.getTorrentsFromChannelId(channel.id, channel.isDispersy(), CHANNEL_REQ_COLUMNS, limit)
        return self._createTorrents(hits, filterTorrents, {channel.id: channel})

    def getRecentReceivedTorrentsFromChannel(self, channel, filterTorrents=True, limit=None):
        hits = self.channelcast_db.getRecentReceivedTorrentsFromChannelId(channel.id, CHANNEL_REQ_COLUMNS, limit)
        return self._createTorrents(hits, filterTorrents, {channel.id: channel})

    def getTorrentsNotInPlaylist(self, channel, filterTorrents=True):
        hits = self.channelcast_db.getTorrentsNotInPlaylist(channel.id, CHANNEL_REQ_COLUMNS)
        results = self._createTorrents(hits, filterTorrents, {channel.id: channel})

        if isinstance(channel, RemoteChannel):
            if len(results) == 0:
                return channel.torrents
        return results

    def getTorrentsFromPlaylist(self, playlist, filterTorrents=True, limit=None):
        hits = self.channelcast_db.getTorrentsFromPlaylist(playlist.id, CHANNEL_REQ_COLUMNS, limit)
        return self._createTorrents(hits, filterTorrents, {playlist.channel.id: playlist.channel}, playlist)

    def getTorrentFromPlaylist(self, playlist, infohash):
        data = self.channelcast_db.getTorrentFromPlaylist(playlist.id, infohash, CHANNEL_REQ_COLUMNS)
        return self._createTorrent(data, playlist.channel, playlist)

    def getRecentTorrentsFromPlaylist(self, playlist, filterTorrents=True, limit=None):
        hits = self.channelcast_db.getRecentTorrentsFromPlaylist(playlist.id, CHANNEL_REQ_COLUMNS, limit)
        return self._createTorrents(hits, filterTorrents, {playlist.channel.id: playlist.channel}, playlist)

    def populateWithPlaylists(self, torrents):
        torrentdict = {}
        for torrent in torrents:
            torrentdict[torrent.channeltorrent_id] = torrent

        hits = self.channelcast_db.getPlaylistsForTorrents(torrentdict.keys(), PLAYLIST_REQ_COLUMNS)
        for hit in hits:
            torrent = torrentdict[hit[0]]
            playlist = Playlist(*hit[1:] + (torrent.channel,))
            torrent.playlist = playlist

    def getMostPopularTorrentsFromChannel(self, channel_id, keys, family_filter=False, limit=None):
        return self.channelcast_db.getMostPopularTorrentsFromChannel(channel_id, keys, limit, family_filter)

    def _createTorrent(self, tuple, channel, playlist=None, collectedOnly=True, addDs=True):
        if tuple:
            ct = ChannelTorrent(*tuple[1:] + [channel, playlist])
            ct.misc_db = self.misc_db
            ct.torrent_db = self.torrent_db
            ct.channelcast_db = self.channelcast_db

            if addDs:
                self.library_manager.addDownloadState(ct)

            # Only return ChannelTorrent with a name, old not-collected torrents
            # will be filtered due to this
            if not collectedOnly or ct.name:
                return ct

    def _createTorrents(self, hits, filterTorrents, channel_dict={}, playlist=None):
        fetch_channels = set(hit[0] for hit in hits if hit[0] not in channel_dict)
        if len(fetch_channels) > 0:
            _, channels = self.getChannels(fetch_channels)
            for channel in channels:
                channel_dict[channel.id] = channel

        torrents = []
        for hit in hits:
            torrent = self._createTorrent(hit, channel_dict.get(hit[0], None), playlist, addDs=False)
            if torrent:
                torrents.append(torrent)

        self.library_manager.addDownloadStates(torrents)

        self.filteredResults = 0
        if filterTorrents:
            torrents = self._applyFF(torrents)
        return len(torrents), self.filteredResults, torrents

    def getTorrentModifications(self, torrent):
        data = self.channelcast_db.getTorrentModifications(torrent.channeltorrent_id, MODIFICATION_REQ_COLUMNS)
        return self._createModifications(data)

    def getRecentModificationsFromChannel(self, channel, limit=None):
        data = self.channelcast_db.getRecentModificationsFromChannelId(channel.id, MODIFICATION_REQ_COLUMNS, limit)
        return self._createModifications(data)

    def getRecentModificationsFromPlaylist(self, playlist, limit=None):
        data = self.channelcast_db.getRecentModificationsFromPlaylist(playlist.id, MODIFICATION_REQ_COLUMNS, limit)
        return self._createModifications(data)

    def _createModifications(self, hits):
        returnList = []
        for hit in hits:
            mod = Modification(*hit[:8])
            mod.channelcast_db = self.channelcast_db
            mod.get_nickname = self.session.get_nickname

            moderation = hit[8:]
            if moderation[0] is not None:
                moderation = Moderation(*moderation)
                moderation.channelcast_db = self.channelcast_db
                moderation.get_nickname = self.session.get_nickname

                mod.moderation = moderation
            # touch torrent property to load torrent
            mod.torrent

            returnList.append(mod)

        return returnList

    def getRecentModerationsFromChannel(self, channel, limit=None):
        data = self.channelcast_db.getRecentModerationsFromChannel(channel.id, MODERATION_REQ_COLUMNS, limit)
        return self._createModerations(data)

    def getRecentModerationsFromPlaylist(self, playlist, limit=None):
        data = self.channelcast_db.getRecentModerationsFromPlaylist(playlist.id, MODERATION_REQ_COLUMNS, limit)
        return self._createModerations(data)

    def _createModerations(self, hits):
        returnList = []
        for hit in hits:
            mod = Moderation(*hit[:8])
            mod.channelcast_db = self.channelcast_db
            mod.get_nickname = self.session.get_nickname

            modification = hit[8:]
            if modification[0] is not None:
                modification = Modification(*modification)
                modification.channelcast_db = self.channelcast_db
                modification.get_nickname = self.session.get_nickname

                # touch torrent property to load torrent
                modification.torrent

                mod.modification = modification
            returnList.append(mod)

        return returnList

    def getRecentMarkingsFromChannel(self, channel, limit=None):
        data = self.channelcast_db.getRecentMarkingsFromChannel(channel.id, MARKING_REQ_COLUMNS, limit)
        return self._createMarkings(data)

    def getRecentMarkingsFromPlaylist(self, playlist, limit=None):
        data = self.channelcast_db.getRecentMarkingsFromPlaylist(playlist.id, MARKING_REQ_COLUMNS, limit)
        return self._createMarkings(data)

    def _createMarkings(self, hits):
        returnList = []
        for hit in hits:
            mar = Marking(*hit[:5])
            mar.get_nickname = self.session.get_nickname

            # touch torrent property to load torrent
            mar.torrent

            returnList.append(mar)

        return returnList

    def getCommentsFromChannel(self, channel, limit=None, resolve_names=True):
        hits = self.channelcast_db.getCommentsFromChannelId(channel.id, COMMENT_REQ_COLUMNS, limit)
        return self._createComments(hits, channel=channel)

    def getCommentsFromPlayList(self, playlist, limit=None):
        hits = self.channelcast_db.getCommentsFromPlayListId(playlist.id, COMMENT_REQ_COLUMNS, limit)
        return self._createComments(hits, channel=playlist.channel, playlist=playlist)

    def getCommentsFromChannelTorrent(self, channel_torrent, limit=None):
        hits = self.channelcast_db.getCommentsFromChannelTorrentId(channel_torrent.channeltorrent_id, COMMENT_REQ_COLUMNS, limit)
        return self._createComments(hits, channel=channel_torrent.channel, channel_torrent=channel_torrent)

    def _createComments(self, hits, channel=None, playlist=None, channel_torrent=None):
        hitsDict = {}
        hitsSequence = []
        for hit in hits:
            comment = Comment(*(hit + (channel, playlist, channel_torrent)))

            comment.get_nickname = self.session.get_nickname
            comment.get_mugshot = self.session.get_mugshot

            # touch torrent property to load torrent
            comment.torrent

            hitsSequence.append(comment.dispersy_id)
            hitsDict[comment.dispersy_id] = comment

        for comment in hitsDict.itervalues():
            if comment.reply_to_id and isinstance(comment.reply_to_id, (long, int)) and comment.reply_to_id in hitsDict:
                replyAfter = hitsDict[comment.reply_to_id]
                replyAfter.replies.append(comment)
                hitsSequence.remove(comment.dispersy_id)

        return [hitsDict[id] for id in hitsSequence if id in hitsDict]

    def getPlaylist(self, channel, playlist_id):
        hit = self.channelcast_db.getPlaylist(playlist_id, PLAYLIST_REQ_COLUMNS)
        return self._createPlaylist(hit, channel)

    def getPlaylistsFromChannel(self, channel):
        hits = self.channelcast_db.getPlaylistsFromChannelId(channel.id, PLAYLIST_REQ_COLUMNS)
        return len(hits), self._createPlaylists(hits, channel=channel)

    def _createPlaylist(self, hit, channel=None):
        if hit:
            pl = Playlist(*(hit + (channel,)))

            # touch extended_description property to possibly load torrents
            pl.extended_description
            return pl

    def _createPlaylists(self, hits, channel=None):
        returnList = []
        for hit in hits:
            playlist = self._createPlaylist(hit, channel)
            returnList.append(playlist)

        return returnList

    def getMyVote(self, channel):
        return self.votecastdb.getVoteOnChannel(channel.id, None)

    def getSubscribersCount(self, channel):
        return self.channelcast_db.getSubscribersCount(channel.id)

    def _applyFF(self, hits):
        enabled_category_keys = [key.lower() for key, _ in self.category.getCategoryNames()] + ['other']
        enabled_category_ids = set()
        for key, id in self.misc_db._category_name2id_dict.iteritems():
            if key.lower() in enabled_category_keys:
                enabled_category_ids.add(id)
        deadstatus_id = self.misc_db.torrentStatusName2Id(u'dead')

        def torrentFilter(torrent):
            okCategory = False

            category = torrent.get("category_id", None)
            if not category:
                category = 0

            if category in enabled_category_ids:
                okCategory = True

            if not okCategory:
                self.filteredResults += 1

            okGood = torrent.status_id != deadstatus_id
            return okCategory and okGood

        return filter(torrentFilter, hits)

    @warnDispersyThread
    def _disp_get_community_from_channel_id(self, channel_id):
        if not channel_id:
            channel_id = self.channelcast_db.getMyChannelId()

        if channel_id:
            # 1. get the dispersy identifier from the channel_id
            dispersy_cid = self.channelcast_db.getDispersyCIDFromChannelId(channel_id)
            dispersy_cid = str(dispersy_cid)

            return self._disp_get_community_from_cid(dispersy_cid)

        self._logger.info("Could not find channel %s", channel_id)

    @warnDispersyThread
    def _disp_get_community_from_cid(self, dispersy_cid):
        try:
            return self.dispersy.get_community(dispersy_cid)
        except CommunityNotFoundException:
            return None

    @call_on_reactor_thread
    def createChannel(self, name, description):
        community = ChannelCommunity.create_community(self.dispersy, self.session.dispersy_member)
        community.set_channel_mode(ChannelCommunity.CHANNEL_OPEN)
        community.create_channel(name, description)

    @call_on_reactor_thread
    def createPlaylist(self, channel_id, name, description, infohashes=[]):
        community = self._disp_get_community_from_channel_id(channel_id)
        community.create_playlist(name, description, infohashes)

    @call_on_reactor_thread
    def savePlaylistTorrents(self, channel_id, playlist_id, infohashes):
        # detect changesmodification
        to_be_created = set(infohashes)
        to_be_removed = set()

        sql = "SELECT distinct infohash, PL.dispersy_id FROM PlaylistTorrents PL, ChannelTorrents CT, Torrent T WHERE PL.channeltorrent_id = CT.id AND CT.torrent_id = T.torrent_id AND playlist_id = ?"
        records = self.channelcast_db._db.fetchall(sql, (playlist_id,))
        for infohash, dispersy_id in records:
            infohash = str2bin(infohash)
            if infohash in to_be_created:
                to_be_created.remove(infohash)
            else:
                to_be_removed.add(dispersy_id)

        if len(to_be_created) > 0 or len(to_be_removed) > 0:
            community = self._disp_get_community_from_channel_id(channel_id)

            if len(to_be_created) > 0:
                community.create_playlist_torrents(playlist_id, to_be_created)

            if len(to_be_removed) > 0:
                community.remove_playlist_torrents(playlist_id, to_be_removed)

    @call_on_reactor_thread
    def addPlaylistTorrent(self, playlist, torrent):
        if not self.channelcast_db.playlistHasTorrent(playlist.id, torrent.channeltorrent_id):
            community = self._disp_get_community_from_channel_id(playlist.channel.id)
            community.create_playlist_torrents(playlist.id, [torrent.infohash])

    @call_on_reactor_thread
    def createTorrent(self, channel, torrent):
        if not isinstance(torrent, CollectedTorrent):
            def torrent_loaded(loaded_torrent):
                self.createTorrent(channel, loaded_torrent)
            self.torrentsearch_manager.loadTorrent(torrent, torrent_loaded)
            return True

        if not channel:
            channel_id = self.channelcast_db.getMyChannelId()
            if not channel_id:
                self.createChannel(self.session.get_nickname(), '')
                channel_id = self.channelcast_db.getMyChannelId()
        else:
            channel_id = channel.id

        if len(torrent.files) == 0:
            self._logger.info("Could not create torrent, no files? %s %s %s", torrent.name, torrent.files, torrent.trackers)
            return False

        if not self.channelcast_db.hasTorrent(channel_id, torrent.infohash):
            community = self._disp_get_community_from_channel_id(channel_id)
            community._disp_create_torrent(torrent.infohash, long(time()), torrent.name, tuple(torrent.files), tuple(torrent.trackers))
            return True
        return False

    @call_on_reactor_thread
    def createTorrentFromDef(self, channel_id, tdef, extraInfo={}, forward=True):
        # Make sure that this new tdef is also in collected torrents
        self.remote_th.save_torrent(tdef)

        if not channel_id:
            channel_id = self.channelcast_db.getMyChannelId()

        if channel_id and not self.channelcast_db.hasTorrent(channel_id, tdef.infohash):
            community = self._disp_get_community_from_channel_id(channel_id)

            files = tdef.get_files_as_unicode_with_length()
            if len(files) == 0:
                self._logger.info("Could not create torrent, no files? %s %s %s", tdef.get_name_as_unicode(), files, tdef.get_trackers_as_single_tuple())
                return False

            community._disp_create_torrent(tdef.infohash, long(time()), tdef.get_name_as_unicode(), tuple(files), tdef.get_trackers_as_single_tuple(), forward=forward)

            if 'description' in extraInfo:
                desc = extraInfo['description']
                desc = desc.strip()

                if desc != '':
                    data = self.channelcast_db.getTorrentFromChannelId(channel_id, tdef.infohash, CHANNEL_REQ_COLUMNS)
                    torrent = self._createTorrent(data, False)

                    self.modifyTorrent(channel_id, torrent.channeltorrent_id, {'description': desc}, forward=forward)
            return True
        return False

    @call_on_reactor_thread
    def createTorrentsFromDefs(self, channel_id, tdefs):
        if not channel_id:
            channel_id = self.channelcast_db.getMyChannelId()

        if not channel_id:
            self._logger.info("No channel")
            return

        for tdef in tdefs:
            self.createTorrentFromDef(channel_id, tdef, forward=False)

    @call_on_reactor_thread
    def removeTorrent(self, channel, infohash):
        torrent = self.getTorrentFromChannel(channel, infohash, collectedOnly=False)
        if torrent:
            community = self._disp_get_community_from_channel_id(channel.id)
            community.remove_torrents([torrent.dispersy_id])

    @call_on_reactor_thread
    def removeAllTorrents(self, channel):
        _, _, torrents = self.getTorrentsFromChannel(channel, filterTorrents=False)
        dispersy_ids = [torrent.dispersy_id for torrent in torrents if torrent]

        community = self._disp_get_community_from_channel_id(channel.id)
        community.remove_torrents(dispersy_ids)

    @call_on_reactor_thread
    def removePlaylist(self, channel, playlist_id):
        playlist = self.getPlaylist(channel, playlist_id)
        if playlist:
            community = self._disp_get_community_from_channel_id(channel.id)
            community.remove_playlists([playlist.dispersy_id])

            self.removeAllPlaylistTorrents(community, playlist)

    @call_on_reactor_thread
    def removeAllPlaylists(self, channel):
        _, playlists = self.dispersy_id(channel)
        dispersy_ids = [playlist.dispersy_id for playlist in playlists if playlist]

        community = self._disp_get_community_from_channel_id(channel.id)
        community.remove_playlists(dispersy_ids)
        for playlist in playlists:
            self.removeAllPlaylistTorrents(community, playlist)

    @call_on_reactor_thread
    def removeAllPlaylistTorrents(self, community, playlist):
        sql = "SELECT dispersy_id FROM PlaylistTorrents WHERE playlist_id = ?"
        records = self.channelcast_db._db.fetchall(sql, (playlist.id,))
        to_be_removed = [dispersy_id for dispersy_id, in records]

        community.remove_playlist_torrents(playlist.dispersy_id, to_be_removed)

    @call_on_reactor_thread
    def createComment(self, comment, channel, reply_to=None, reply_after=None, playlist=None, infohash=None):
        comment = comment.strip()
        comment = comment[:1023]
        if len(comment) > 0:
            playlist_id = None
            if playlist:
                playlist_id = playlist.id

            community = self._disp_get_community_from_channel_id(channel.id)
            community.create_comment(comment, long(time()), reply_to, reply_after, playlist_id, infohash)

    @call_on_reactor_thread
    def removeComment(self, comment, channel):
        community = self._disp_get_community_from_channel_id(channel.id)
        community.remove_comment(comment.dispersy_id)

    @call_on_reactor_thread
    def modifyChannel(self, channel_id, changes):
        community = self._disp_get_community_from_channel_id(channel_id)
        community.modifyChannel(changes)

    @call_on_reactor_thread
    def modifyPlaylist(self, channel_id, playlist_id, name, description):
        dict = {'name': name, 'description': description}

        community = self._disp_get_community_from_channel_id(channel_id)
        community.modifyPlaylist(playlist_id, dict)

    @call_on_reactor_thread
    def modifyTorrent(self, channel_id, channeltorrent_id, dict_changes, forward=True):
        community = self._disp_get_community_from_channel_id(channel_id)
        community.modifyTorrent(channeltorrent_id, dict_changes, forward=forward)

    def spam(self, channel_id):
        self.do_vote(channel_id, -1)

    def favorite(self, channel_id):
        self.do_vote(channel_id, 2)

    def remove_vote(self, channel_id):
        self.do_vote(channel_id, 0)

    def do_vote(self, channel_id, vote, timestamp=None):
        dispersy_cid = self.channelcast_db.getDispersyCIDFromChannelId(channel_id)
        dispersy_cid = str(dispersy_cid)

        if len(dispersy_cid) == 20:
            self.do_vote_cid(dispersy_cid, vote, timestamp)

        elif vote == 2:
            self.votecastdb.subscribe(channel_id)
        elif vote == -1:
            self.votecastdb.spam(channel_id)
        else:
            self.votecastdb.unsubscribe(channel_id)

    @call_on_reactor_thread
    def do_vote_cid(self, dispersy_cid, vote, timestamp=None):
        if not timestamp:
            timestamp = int(time())

        if len(dispersy_cid) == 20:
            for community in self.dispersy.get_communities():
                if isinstance(community, AllChannelCommunity):
                    community.disp_create_votecast(dispersy_cid, vote, timestamp)
                    break

    @call_on_reactor_thread
    def markTorrent(self, channel_id, infohash, type):
        community = self._disp_get_community_from_channel_id(channel_id)
        community._disp_create_mark_torrent(infohash, type, long(time()))

    @call_on_reactor_thread
    def revertModification(self, channel, moderation, text, severity, revert_to):
        cause = moderation.dispersy_id

        community = self._disp_get_community_from_channel_id(channel.id)
        community._disp_create_moderation(text, long(time()), severity, cause)

    def getChannelForTorrent(self, infohash):
        return self.channelcast_db.getMostPopularChannelFromTorrent(infohash)[:-1]

    def getNrTorrentsDownloaded(self, publisher_id):
        return self.channelcast_db.getNrTorrentsDownloaded(publisher_id)

    def setSearchKeywords(self, wantkeywords):
        if wantkeywords != self.searchkeywords:
            try:
                self.remoteLock.acquire()

                self.searchkeywords = wantkeywords
                self.remoteHits = []
                self.remoteRefresh = False

            finally:
                self.remoteLock.release()

    def getChannelHits(self):
        begintime = time()

        hitsUpdated = self.searchLocalDatabase()
        self._logger.debug('ChannelManager: getChannelHits: search found: %d items', len(self.hits))

        try:
            # merge remoteHits
            self.remoteLock.acquire()

            if len(self.remoteHits) > 0:
                for remoteItem, permid in self.remoteHits:

                    channel = None
                    if not isinstance(remoteItem, Channel):
                        channel_id, _, infohash, torrent_name, timestamp = remoteItem

                        if channel_id not in self.hits:
                            channel = self.getChannel(channel_id)
                        else:
                            channel = self.hits[channel_id]

                        torrent = channel.getTorrent(infohash)
                        if not torrent:
                            torrent = RemoteChannelTorrent(torrent_id=None, infohash=infohash, name=torrent_name, channel=channel, query_permids=set())
                            channel.addTorrent(torrent)

                        if not torrent.query_permids:
                            torrent.query_permids = set()
                        torrent.query_permids.add(permid)

                        channel.nr_torrents += 1
                        channel.modified = max(channel.modified, timestamp)
                    else:
                        channel = remoteItem

                    if channel and not channel.id in self.hits:
                        self.hits[channel.id] = channel
                        hitsUpdated = True
        finally:
            self.remoteLock.release()

        self._logger.debug("ChannelManager: getChannelHits took %s", time() - begintime)

        if len(self.hits) == 0:
            return [0, hitsUpdated, None]
        else:
            return [len(self.hits), hitsUpdated, self.hits]

    @warnDispersyThread
    def searchDispersy(self):
        nr_requests_made = 0
        if self.dispersy:
            for community in self.dispersy.get_communities():
                if isinstance(community, AllChannelCommunity):
                    nr_requests_made = community.create_channelsearch(self.searchkeywords, self.gotDispersyRemoteHits)
                    if not nr_requests_made:
                        self._logger.info("Could not send search in AllChannelCommunity, no verified candidates found")
                    break

            else:
                self._logger.info("Could not send search in AllChannelCommunity, community not found")

        else:
            self._logger.info("Could not send search in AllChannelCommunity, Dispersy not found")

        return nr_requests_made

    def searchLocalDatabase(self):
        """ Called by GetChannelHits() to search local DB. Caches previous query result. """
        if self.searchkeywords == self.oldsearchkeywords:
            self._logger.debug("ChannelManager: searchLocalDB: returning old hit list %s", len(self.hits))
            return False

        self.oldsearchkeywords = self.searchkeywords

        ("ChannelManager: searchLocalDB: Want %s", self.searchkeywords)

        if len(self.searchkeywords) == 0 or len(self.searchkeywords) == 1 and self.searchkeywords[0] == '':
            return False
        return self._searchLocalDatabase()

    @forceAndReturnDBThread
    def _searchLocalDatabase(self):
        self.hits = {}
        hits = self.channelcast_db.searchChannels(self.searchkeywords)
        _, channels = self._createChannels(hits)

        for channel in channels:
            self.hits[channel.id] = channel
        return True

    def gotDispersyRemoteHits(self, kws, answers):
        if self.searchkeywords == kws:
            channel_cids = answers.keys()
            _, dispersyChannels = self.getChannelsByCID(channel_cids)
            try:
                self.remoteLock.acquire()

                for channel in dispersyChannels:
                    self.remoteHits.append((channel, -1))

            finally:
                refreshGrid = len(self.remoteHits) > 0
                if refreshGrid:
                    # if already scheduled, dont schedule another
                    if self.remoteRefresh:
                        refreshGrid = False
                    else:
                        self.remoteRefresh = True

                self.remoteLock.release()

                if refreshGrid:
                    self.refreshGrid()

    def refreshGrid(self):
        if self.gridmgr is not None:
            self.gridmgr.refresh_channel()

########NEW FILE########
__FILENAME__ = settingsDialog
# Written by Niels Zeilemaker

# see LICENSE.txt for license information
import wx
import wx.lib.masked.textctrl
import wx.lib.imagebrowser as ib
import sys
import os
import tempfile
import atexit
import time
import logging

from Tribler.Core.simpledefs import UPLOAD, DOWNLOAD, \
    STATEDIR_TORRENTCOLL_DIR, STATEDIR_SWIFTRESEED_DIR
from Tribler.Core.Session import Session
from Tribler.Core.SessionConfig import SessionStartupConfig
from Tribler.Core.osutils import get_picture_dir

from Tribler.Main.globals import DefaultDownloadStartupConfig, get_default_dscfg_filename
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager, data2wxBitmap, ICON_MAX_DIM
from Tribler.Main.vwxGUI.widgets import _set_font, EditText
from Tribler.Main.vwxGUI.validator import DirectoryValidator, NetworkSpeedValidator, \
    NumberValidator


def create_section(parent, hsizer, label):
    panel = wx.Panel(parent)

    vsizer = wx.BoxSizer(wx.VERTICAL)

    title = wx.StaticText(panel, label=label)
    _set_font(title, 1, wx.FONTWEIGHT_BOLD)
    vsizer.AddSpacer((1,7))
    vsizer.Add(title, 0, wx.EXPAND | wx.BOTTOM, -7)

    hsizer.Add(panel, 1, wx.EXPAND)
    panel.SetSizer(vsizer)
    return panel, vsizer

def create_subsection(parent, parent_sizer, label, num_cols=1, vgap=0, hgap=0):
    line = wx.StaticLine(parent, size=(-1,1), style=wx.LI_HORIZONTAL)
    parent_sizer.Add(line, 0, wx.EXPAND | wx.TOP | wx.BOTTOM, 7)

    title = wx.StaticText(parent, label=label)
    _set_font(title, 0, wx.FONTWEIGHT_BOLD)
    parent_sizer.Add(title, 0, wx.EXPAND | wx.BOTTOM, 5)

    if num_cols == 1:
        sizer = wx.BoxSizer(wx.VERTICAL)
    else:
        sizer = wx.FlexGridSizer(cols=num_cols, vgap=vgap, hgap=hgap)
        sizer.AddGrowableCol(1)

    parent_sizer.Add(sizer, 0, wx.EXPAND)
    return sizer

def add_label(parent, sizer, label):
    label = wx.StaticText(parent, label=label)
    label.SetMinSize((100,-1))
    sizer.Add(label)

class SettingsDialog(wx.Dialog):

    def __init__(self):
        super(SettingsDialog, self).__init__(None, size=(600, 600),
            title="Settings", name="settingsDialog", style=wx.DEFAULT_DIALOG_STYLE)
        self.SetExtraStyle(self.GetExtraStyle() | wx.WS_EX_VALIDATE_RECURSIVELY)
        self._logger = logging.getLogger(self.__class__.__name__)

        self.guiUtility = GUIUtility.getInstance()
        self.utility = self.guiUtility.utility
        self.defaultDLConfig = DefaultDownloadStartupConfig.getInstance()

        # create the dialog and widgets
        self._tree_ctrl = wx.TreeCtrl(self,
            style=wx.TR_DEFAULT_STYLE | wx.SUNKEN_BORDER | wx.TR_HIDE_ROOT | wx.TR_SINGLE)
        self._tree_ctrl.SetMinSize(wx.Size(150, -1))
        tree_root = self._tree_ctrl.AddRoot('Root')
        self._tree_ctrl.Bind(wx.EVT_TREE_SEL_CHANGING, self.OnSelectionChanging)

        hsizer = wx.BoxSizer(wx.HORIZONTAL)
        hsizer.Add(self._tree_ctrl, 0, wx.EXPAND | wx.RIGHT, 10)

        self._general_panel, self._general_id = self.__create_s1(tree_root, hsizer)
        self._conn_panel, self._conn_id = self.__create_s2(tree_root, hsizer)
        self._bandwidth_panel, self._bandwidth_id = self.__create_s3(tree_root, hsizer)
        self._seeding_panel, self._seeding_id = self.__create_s4(tree_root, hsizer)
        self._experimental_panel, self._experimental_id = self.__create_s5(tree_root, hsizer)

        self._general_panel.Show(True)
        self._conn_panel.Show(False)
        self._bandwidth_panel.Show(False)
        self._seeding_panel.Show(False)
        self._experimental_panel.Show(False)

        self._save_btn = wx.Button(self, wx.ID_OK, label="Save")
        self._cancel_btn = wx.Button(self, wx.ID_CANCEL, label="Cancel")

        btn_sizer = wx.StdDialogButtonSizer()
        btn_sizer.AddButton(self._save_btn)
        btn_sizer.AddButton(self._cancel_btn)
        btn_sizer.Realize()

        self._save_btn.Bind(wx.EVT_BUTTON, self.saveAll)
        self._cancel_btn.Bind(wx.EVT_BUTTON, self.cancelAll)

        vsizer = wx.BoxSizer(wx.VERTICAL)
        vsizer.Add(hsizer, 1, wx.EXPAND | wx.ALL, 10)
        vsizer.Add(btn_sizer, 0, wx.EXPAND | wx.ALL, 5)
        self.SetSizer(vsizer)

        # select General page by default
        self._tree_ctrl.SelectItem(self._general_id)

    def OnSelectionChanging(self, event):
        old_item = event.GetOldItem()
        new_item = event.GetItem()
        try:
            self.ShowPage(self._tree_ctrl.GetItemData(new_item).GetData(), self._tree_ctrl.GetItemData(old_item).GetData())
        except:
            pass

    def ShowPage(self, page, oldpage):
        if oldpage == None:
            selection = self._tree_ctrl.GetSelection()
            oldpage = self._tree_ctrl.GetItemData(selection).GetData()

        oldpage.Hide()

        page.Show(True)
        page.Layout()

        self.Layout()
        self.Refresh()

    def setUp(self, value, event=None):
        self.resetUploadDownloadCtrlColour()
        self._upload_ctrl.SetValue(str(value))

        if event:
            event.Skip()

    def setDown(self, value, event=None):
        self.resetUploadDownloadCtrlColour()
        self._download_ctrl.SetValue(str(value))

        if event:
            event.Skip()

    def resetUploadDownloadCtrlColour(self):
        self._upload_ctrl.SetForegroundColour(wx.BLACK)
        self._download_ctrl.SetForegroundColour(wx.BLACK)

    def saveAll(self, event):
        if not self.Validate():
            return

        restart = False

        state_dir = self.utility.session.get_state_dir()
        cfgfilename = self.utility.session.get_default_config_filename(state_dir)
        scfg = SessionStartupConfig.load(cfgfilename)

        valdown = self._download_ctrl.GetValue()
        valup = self._upload_ctrl.GetValue()
        convert = lambda v: 0 if v == 'unlimited' else (-1 if v == '0' else int(v))
        for config_option, value in [('maxdownloadrate', convert(valdown)), ('maxuploadrate', convert(valup))]:
            if self.utility.read_config(config_option) != value:
                self.utility.write_config(config_option, value)
                self.guiUtility.app.ratelimiter.set_global_max_speed(UPLOAD if config_option == 'maxuploadrate' else DOWNLOAD, value)

        valport = self._firewall_value.GetValue()
        if valport != str(self.utility.session.get_listen_port()):
            scfg.set_listen_port(int(valport))
            scfg.set_swift_tunnel_listen_port(int(valport) - 2)
            scfg.set_dispersy_port(int(valport) - 1)
            self.saveDefaultDownloadConfig(scfg)

            self.guiUtility.set_firewall_restart(True)
            restart = True

        showSave = int(self._disk_location_choice.IsChecked())
        if showSave != self.utility.read_config('showsaveas'):
            self.utility.write_config('showsaveas', showSave)
            self.saveDefaultDownloadConfig(scfg)

        valdir = self._disk_location_ctrl.GetValue()
        if valdir != self.currentDestDir:
            self.defaultDLConfig.set_dest_dir(valdir)

            self.saveDefaultDownloadConfig(scfg)
            self.moveCollectedTorrents(self.currentDestDir, valdir)
            restart = True

        useWebUI = self._use_webui.IsChecked()
        if useWebUI != self.utility.read_config('use_webui'):
            self.utility.write_config('use_webui', useWebUI)
            restart = True

        valwebuiport = self._webui_port.GetValue()
        if valwebuiport != str(self.utility.read_config('webui_port')):
            self.utility.write_config('webui_port', valwebuiport)
            restart = True

        curMintray = self.utility.read_config('mintray')
        if self._minimize_to_tray:
            minimizeToTray = 1 if self._minimize_to_tray.IsChecked() else 0
            if minimizeToTray != curMintray:
                self.utility.write_config('mintray', minimizeToTray)

        for target in [scfg, self.utility.session]:
            try:
                target.set_nickname(self._my_name_field.GetValue())
                if getattr(self, 'icondata', False):
                    target.set_mugshot(self.icondata, mime='image/jpeg')
            except:
                self._logger.exception("Could not set target")

        # tit-4-tat
        t4t_option = self.utility.read_config('t4t_option')
        for i in range(4):
            if getattr(self, '_t4t%d' % i).GetValue():
                self.utility.write_config('t4t_option', i)

                if i != t4t_option:
                    restart = True

                break
        t4t_ratio = int(float(self._t4t0choice.GetStringSelection()) * 100)
        self.utility.write_config("t4t_ratio", t4t_ratio)

        hours_min = self._t4t2text.GetValue()
        hours_min = hours_min.split(':')
        if len(hours_min) > 0:
            if len(hours_min) > 1:
                self.utility.write_config("t4t_hours", hours_min[0] or 0)
                self.utility.write_config("t4t_mins", hours_min[1] or 0)
            else:
                self.utility.write_config("t4t_hours", hours_min[0] or 0)
                self.utility.write_config("t4t_mins", 0)

        # give-2-get
        g2g_option = self.utility.read_config('g2g_option')
        for i in range(4):
            if getattr(self, '_g2g%d' % i).GetValue():
                self.utility.write_config("g2g_option", i)

                if i != g2g_option:
                    restart = True
                break
        g2g_ratio = int(float(self._g2g0choice.GetStringSelection()) * 100)
        self.utility.write_config("g2g_ratio", g2g_ratio)

        hours_min = self._g2g2text.GetValue()
        hours_min = hours_min.split(':')
        if len(hours_min) > 0:
            if len(hours_min) > 1:
                self.utility.write_config("g2g_hours", hours_min[0] or 0)
                self.utility.write_config("g2g_mins", hours_min[1] or 0)
            else:
                self.utility.write_config("g2g_hours", hours_min[0] or 0)
                self.utility.write_config("g2g_mins", 0)

        # Proxy settings
        old_ptype, old_server, old_auth = self.utility.session.get_libtorrent_proxy_settings()
        new_ptype = self._lt_proxytype.GetSelection()
        new_server = (self._lt_proxyserver.GetValue(), int(self._lt_proxyport.GetValue())) if self._lt_proxyserver.GetValue() and self._lt_proxyport.GetValue() else None
        new_auth = (self._lt_proxyusername.GetValue(), self._lt_proxypassword.GetValue()) if self._lt_proxyusername.GetValue() and self._lt_proxypassword.GetValue() else None
        if old_ptype != new_ptype or old_server != new_server or old_auth != new_auth:
            self.utility.session.set_libtorrent_proxy_settings(new_ptype, new_server, new_auth)
            scfg.set_libtorrent_proxy_settings(new_ptype, new_server, new_auth)

        enable_utp = self._enable_utp.GetValue()
        if enable_utp != self.utility.session.get_libtorrent_utp():
            self.utility.session.set_libtorrent_utp(enable_utp)
            scfg.set_libtorrent_utp(enable_utp)

        scfg.save(cfgfilename)

        self.utility.flush_config()

        if restart:
            dlg = wx.MessageDialog(self, "A restart is required for these changes to take effect.\nDo you want to restart Tribler now?", "Restart required", wx.ICON_QUESTION | wx.YES_NO | wx.YES_DEFAULT)
            if dlg.ShowModal() == wx.ID_YES:
                self.guiUtility.frame.Restart()
            dlg.Destroy()
        self.EndModal(1)
        event.Skip()

    def cancelAll(self, event):
        self.EndModal(1)

    def EditClicked(self, event=None):
        dlg = ib.ImageDialog(self, get_picture_dir())
        dlg.Centre()
        if dlg.ShowModal() == wx.ID_OK:
            self.iconpath = dlg.GetFile()
            self.process_input()
        else:
            pass
        dlg.Destroy()

    def BrowseClicked(self, event=None):
        dlg = wx.DirDialog(None, "Choose download directory", style=wx.DEFAULT_DIALOG_STYLE)
        dlg.SetPath(self.defaultDLConfig.get_dest_dir())
        if dlg.ShowModal() == wx.ID_OK:
            self._disk_location_ctrl.SetForegroundColour(wx.BLACK)
            self._disk_location_ctrl.SetValue(dlg.GetPath())
        else:
            pass

    def ProxyTypeChanged(self, event=None):
        selection = self._lt_proxytype.GetStringSelection()
        self._lt_proxyusername.Enable(selection.endswith('with authentication'))
        self._lt_proxypassword.Enable(selection.endswith('with authentication'))
        self._lt_proxyserver.Enable(selection != 'None')
        self._lt_proxyport.Enable(selection != 'None')

    def _SelectAll(self, dlg, event, nrchoices):
        if event.ControlDown():
            if event.GetKeyCode() == 65:  # ctrl + a
                if dlg.allselected:
                    dlg.SetSelections([])
                else:
                    select = list(range(nrchoices))
                    dlg.SetSelections(select)
                dlg.allselected = not dlg.allselected

    def saveDefaultDownloadConfig(self, scfg):
        state_dir = self.utility.session.get_state_dir()

        # Save DownloadStartupConfig
        dlcfgfilename = get_default_dscfg_filename(state_dir)
        self.defaultDLConfig.save(dlcfgfilename)

        # Save SessionStartupConfig
        # Also change torrent collecting dir, which is by default in the default destdir
        cfgfilename = Session.get_default_config_filename(state_dir)
        defaultdestdir = self.defaultDLConfig.get_dest_dir()
        for target in [scfg, self.utility.session]:
            try:
                target.set_torrent_collecting_dir(os.path.join(defaultdestdir, STATEDIR_TORRENTCOLL_DIR))
            except:
                self._logger.exception("Could not set target torrent collecting dir")
            try:
                target.set_swift_meta_dir(os.path.join(defaultdestdir, STATEDIR_SWIFTRESEED_DIR))
            except:
                self._logger.exception("Could not set target swift meta dir")

        scfg.save(cfgfilename)

    def moveCollectedTorrents(self, old_dir, new_dir):
        def rename_or_merge(old, new, ignore=True):
            if os.path.exists(old):
                if os.path.exists(new):
                    files = os.listdir(old)
                    for file in files:
                        oldfile = os.path.join(old, file)
                        newfile = os.path.join(new, file)

                        if os.path.isdir(oldfile):
                            rename_or_merge(oldfile, newfile)

                        elif os.path.exists(newfile):
                            if not ignore:
                                os.remove(newfile)
                                os.rename(oldfile, newfile)
                        else:
                            os.rename(oldfile, newfile)
                else:
                    os.renames(old, new)

        def move(old_dir, new_dir):
            # physical move
            old_dirtf = os.path.join(old_dir, 'collected_torrent_files')
            new_dirtf = os.path.join(new_dir, 'collected_torrent_files')
            rename_or_merge(old_dirtf, new_dirtf, False)

        atexit.register(move, old_dir, new_dir)

        msg = "Please wait while we update your MegaCache..."
        busyDlg = wx.BusyInfo(msg)
        try:
            time.sleep(0.3)
            wx.Yield()
        except:
            pass

        # update db
        self.guiUtility.torrentsearch_manager.torrent_db.updateTorrentDir(os.path.join(new_dir, 'collected_torrent_files'))

        busyDlg.Destroy()

    def process_input(self):
        try:
            im = wx.Image(self.iconpath)
            if im is None:
                self.show_inputerror("Could not open thumbnail file")
            else:
                if sys.platform != 'darwin':
                    bm = wx.BitmapFromImage(im.Scale(ICON_MAX_DIM, ICON_MAX_DIM), -1)
                    thumbpanel = self._thumb
                    thumbpanel.SetBitmap(bm)

                # Arno, 2008-10-21: scale image!
                sim = im.Scale(ICON_MAX_DIM, ICON_MAX_DIM)
                [thumbhandle, thumbfilename] = tempfile.mkstemp("user-thumb")
                os.close(thumbhandle)
                sim.SaveFile(thumbfilename, wx.BITMAP_TYPE_JPEG)

                f = open(thumbfilename, "rb")
                self.icondata = f.read()
                f.close()
                os.remove(thumbfilename)
        except:
            self._logger.exception("Could not read thumbnail")
            self.show_inputerror("The icon you selected is not in a supported format")

    def show_inputerror(self, txt):
        dlg = wx.MessageDialog(self, txt, "Invalid input", wx.OK | wx.ICON_INFORMATION)
        dlg.ShowModal()
        dlg.Destroy()

    def __create_s1(self, tree_root, sizer):
        general_panel, gp_vsizer = create_section(self, sizer, "General")

        item_id = self._tree_ctrl.AppendItem(tree_root, "General", data=wx.TreeItemData(general_panel))

        # Tribler Profile
        gp_s1_sizer = create_subsection(general_panel, gp_vsizer, "Tribler Profile", 2)

        add_label(general_panel, gp_s1_sizer, "Nickname")
        self._my_name_field = wx.TextCtrl(general_panel, style=wx.TE_PROCESS_ENTER)
        self._my_name_field.SetMaxLength(40)
        gp_s1_sizer.Add(self._my_name_field, 1, wx.EXPAND)

        add_label(general_panel, gp_s1_sizer, "Profile Image")
        self._thumb = wx.StaticBitmap(general_panel, size=(80,80))
        self._edit = wx.Button(general_panel, label="Change Image")
        gp_s1_porfile_vsizer = wx.BoxSizer(wx.VERTICAL)
        gp_s1_porfile_vsizer.Add(self._thumb, 0, wx.LEFT, 1)
        gp_s1_porfile_vsizer.Add(self._edit)
        gp_s1_sizer.Add(gp_s1_porfile_vsizer, 0, wx.TOP, 3)

        # Download Location
        gp_s2_sizer = create_subsection(general_panel, gp_vsizer, "Download Location", 1)

        gp_s2_label = wx.StaticText(general_panel, label="Save files to:")
        gp_s2_sizer.Add(gp_s2_label)
        gp_s2_hsizer = wx.BoxSizer(wx.HORIZONTAL)
        self._disk_location_ctrl = EditText(general_panel,
            validator=DirectoryValidator())
        gp_s2_hsizer.Add(self._disk_location_ctrl, 1, wx.ALIGN_CENTER_VERTICAL)
        self._browse = wx.Button(general_panel, label="Browse")
        gp_s2_hsizer.Add(self._browse)
        gp_s2_sizer.Add(gp_s2_hsizer, 0, wx.EXPAND)
        self._disk_location_choice = wx.CheckBox(general_panel,
            label="Let me choose a location for every download")
        self._disk_location_choice.SetValue(False)
        gp_s2_sizer.Add(self._disk_location_choice)

        # Minimize
        if sys.platform == "darwin":
            self._minimize_to_tray = None
        else:
            gp_s3_sizer = create_subsection(general_panel, gp_vsizer, "Minimize", 1)

            self._minimize_to_tray = wx.CheckBox(general_panel, label="Minimize to tray")
            self._minimize_to_tray.SetValue(False)
            gp_s3_sizer.Add(self._minimize_to_tray)

        self._edit.Bind(wx.EVT_BUTTON, self.EditClicked)
        self._browse.Bind(wx.EVT_BUTTON, self.BrowseClicked)

        # nickname
        self._my_name_field.SetValue(self.utility.session.get_nickname())
        # thumbnail
        mime, data = self.utility.session.get_mugshot()
        if data is None:
            gui_image_manager = GuiImageManager.getInstance()
            mugshot = gui_image_manager.getImage(u"PEER_THUMB")
        else:
            mugshot = data2wxBitmap(mime, data)
        self._thumb.SetBitmap(mugshot)
        # download location
        self.currentDestDir = self.defaultDLConfig.get_dest_dir()
        self._disk_location_ctrl.SetValue(self.currentDestDir)
        self._disk_location_choice.SetValue(self.utility.read_config('showsaveas'))
        # minimize to tray
        if sys.platform != "darwin":
            min_to_tray = self.utility.read_config('mintray') == 1
            self._minimize_to_tray.SetValue(min_to_tray)

        return general_panel, item_id

    def __create_s2(self, tree_root, sizer):
        conn_panel, cn_vsizer = create_section(self, sizer, "Connection")

        item_id = self._tree_ctrl.AppendItem(tree_root, "Connection", data=wx.TreeItemData(conn_panel))

        # Firewall-status
        cn_s1_sizer = create_subsection(conn_panel, cn_vsizer, "Firewall-status", 2, 3)
        add_label(conn_panel, cn_s1_sizer, "Current port")
        self._firewall_value = EditText(conn_panel, validator=NumberValidator(min=1, max=65535))
        self._firewall_value.SetMinSize(wx.Size(150, -1))
        cn_s1_sizer.Add(self._firewall_value)

        add_label(conn_panel, cn_s1_sizer, "Status")
        self._firewall_status_text = wx.StaticText(conn_panel)
        cn_s1_sizer.Add(self._firewall_status_text)

        # BitTorrent proxy settings
        cn_s2_sizer = create_subsection(conn_panel, cn_vsizer, "BitTorrent proxy settings", 2, 3)
        add_label(conn_panel, cn_s2_sizer, "Type")
        self._lt_proxytype = wx.Choice(conn_panel)
        self._lt_proxytype.AppendItems(["None", "Socks4", "Socks5",
            "Socks5 with authentication", "HTTP", "HTTP with authentication"])
        cn_s2_sizer.Add(self._lt_proxytype)

        add_label(conn_panel, cn_s2_sizer, "Server")
        self._lt_proxyserver = wx.TextCtrl(conn_panel, style=wx.TE_PROCESS_ENTER)
        self._lt_proxyserver.SetMaxLength(1024)
        cn_s2_sizer.Add(self._lt_proxyserver, 0, wx.EXPAND)

        add_label(conn_panel, cn_s2_sizer, "Port")
        self._lt_proxyport = EditText(conn_panel, validator=NumberValidator(min=1, max=65535))
        self._lt_proxyport.SetMinSize(wx.Size(150, -1))
        cn_s2_sizer.Add(self._lt_proxyport, 0, wx.EXPAND)

        add_label(conn_panel, cn_s2_sizer, "Username")
        self._lt_proxyusername = wx.TextCtrl(conn_panel, style=wx.TE_PROCESS_ENTER)
        self._lt_proxyusername.SetMaxLength(255)
        cn_s2_sizer.Add(self._lt_proxyusername, 0, wx.EXPAND)

        add_label(conn_panel, cn_s2_sizer, "Password")
        self._lt_proxypassword = wx.TextCtrl(conn_panel, style=wx.TE_PROCESS_ENTER | wx.TE_PASSWORD)
        self._lt_proxypassword.SetMaxLength(255)
        cn_s2_sizer.Add(self._lt_proxypassword, 0, wx.EXPAND)

        # BitTorrent features
        cn_s3_sizer = create_subsection(conn_panel, cn_vsizer, "BitTorrent features", 1)
        self._enable_utp = wx.CheckBox(conn_panel, size=(200,-1),
            label="Enable bandwidth management (uTP)")
        cn_s3_sizer.Add(self._enable_utp, 0, wx.EXPAND)

        self._lt_proxytype.Bind(wx.EVT_CHOICE, self.ProxyTypeChanged)

        # firewall status
        if self.guiUtility.frame.SRstatusbar.IsReachable():
            self._firewall_status_text.SetLabel('Your network connection is working properly.')
        else:
            self._firewall_status_text.SetLabel('Tribler has not yet received any incoming\nconnections. Unless you\'re using a proxy, this\ncould indicate a problem with your network\nconnection.')
        self._firewall_value.SetValue(str(self.utility.session.get_listen_port()))
        # uTP
        self._enable_utp.SetValue(self.utility.session.get_libtorrent_utp())
        # proxy
        ptype, server, auth = self.utility.session.get_libtorrent_proxy_settings()
        self._lt_proxytype.SetSelection(ptype)
        if server:
            self._lt_proxyserver.SetValue(server[0])
            self._lt_proxyport.SetValue(str(server[1]))
        if auth:
            self._lt_proxyusername.SetValue(auth[0])
            self._lt_proxypassword.SetValue(auth[1])
        self.ProxyTypeChanged()

        return conn_panel, item_id

    def __create_s3(self, tree_root, sizer):
        bandwidth_panel, bp_vsizer = create_section(self, sizer, "Bandwidth")

        item_id = self._tree_ctrl.AppendItem(tree_root, "Bandwidth", data=wx.TreeItemData(bandwidth_panel))

        # Bandwidth Limits
        bp_s1_sizer = create_subsection(bandwidth_panel, bp_vsizer, "Bandwidth Limits", 1)
        bp_s1_limitupload_label = wx.StaticText(bandwidth_panel, label="Limit upload rate")
        bp_s1_sizer.Add(bp_s1_limitupload_label)
        bp_s1_hsizer1 = wx.BoxSizer(wx.HORIZONTAL)
        self._upload_ctrl = EditText(bandwidth_panel, validator=NetworkSpeedValidator())
        bp_s1_hsizer1.Add(self._upload_ctrl)
        bp_s1_p1_label = wx.StaticText(bandwidth_panel, label="KB/s")
        bp_s1_hsizer1.Add(bp_s1_p1_label, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 3)
        bp_s1_hsizer1.AddStretchSpacer(1)
        # up buttons
        for btn_label1 in ("0", "50", "100", "unlimited"):
            bp_s1_p1_btn = wx.Button(bandwidth_panel, label=btn_label1, style=wx.BU_EXACTFIT)
            bp_s1_p1_btn.Bind(wx.EVT_BUTTON, lambda event, label=btn_label1: self.setUp(label, event))
            bp_s1_hsizer1.Add(bp_s1_p1_btn)
        bp_s1_sizer.Add(bp_s1_hsizer1, 0, wx.EXPAND)

        bp_s1_limitdownload_label = wx.StaticText(bandwidth_panel, label="Limit download rate")
        bp_s1_sizer.Add(bp_s1_limitdownload_label)
        bp_s1_hsizer2 = wx.BoxSizer(wx.HORIZONTAL)
        self._download_ctrl = EditText(bandwidth_panel, validator=NetworkSpeedValidator())
        bp_s1_hsizer2.Add(self._download_ctrl)
        bp_s1_p2_label = wx.StaticText(bandwidth_panel, label="KB/s")
        bp_s1_hsizer2.Add(bp_s1_p2_label, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT, 3)
        bp_s1_hsizer2.AddStretchSpacer(1)
        # down buttons
        for btn_label2 in ("75", "300", "600", "unlimited"):
            bp_s1_p2_btn = wx.Button(bandwidth_panel, label=btn_label2, style=wx.BU_EXACTFIT)
            bp_s1_p2_btn.Bind(wx.EVT_BUTTON, lambda event, label=btn_label2: self.setDown(label, event))
            bp_s1_hsizer2.Add(bp_s1_p2_btn)
        bp_s1_sizer.Add(bp_s1_hsizer2, 0, wx.EXPAND)

        # upload/download rate
        convert = lambda v: 'unlimited' if v == 0 else ('0' if v == -1 else str(v))
        self._download_ctrl.SetValue(convert(self.utility.read_config('maxdownloadrate')))
        self._upload_ctrl.SetValue(convert(self.utility.read_config('maxuploadrate')))

        return bandwidth_panel, item_id

    def __create_s4(self, tree_root, sizer):
        seeding_panel, sd_vsizer = create_section(self, sizer, "Seeding")

        item_id = self._tree_ctrl.AppendItem(tree_root, "Seeding", data=wx.TreeItemData(seeding_panel))

        # BitTorrent-peers
        sd_s1_sizer = create_subsection(seeding_panel, sd_vsizer, "BitTorrent-peers", 2)
        self._t4t0 = wx.RadioButton(seeding_panel,
            label="Seed until UL/DL ratio >", style=wx.RB_GROUP)
        sd_s1_sizer.Add(self._t4t0, 0, wx.ALIGN_CENTER_VERTICAL)
        self._t4t0choice = wx.Choice(seeding_panel)
        self._t4t0choice.AppendItems(["0.5", "0.75", "1.0", "1.5", "2.0", "3.0", "5.0"])
        sd_s1_sizer.Add(self._t4t0choice, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL)

        self._t4t1 = wx.RadioButton(seeding_panel,
            label="Unlimited seeding")
        sd_s1_sizer.Add(self._t4t1, 0, wx.ALIGN_CENTER_VERTICAL)
        sd_s1_sizer.AddStretchSpacer()

        self._t4t2 = wx.RadioButton(seeding_panel, label="Seeding for (hours:minutes)")
        sd_s1_sizer.Add(self._t4t2, 0, wx.ALIGN_CENTER_VERTICAL)
        self._t4t2text = wx.lib.masked.textctrl.TextCtrl(seeding_panel)
        self._t4t2text.SetCtrlParameters(mask="##:##", defaultValue="00:00",
            useFixedWidthFont=False)
        sd_s1_sizer.Add(self._t4t2text)

        self._t4t3 = wx.RadioButton(seeding_panel, label="No seeding")
        sd_s1_sizer.Add(self._t4t3, 0, wx.ALIGN_CENTER_VERTICAL)

        # Tribler-peers
        sd_s2_sizer = create_subsection(seeding_panel, sd_vsizer, "Tribler-peers", 2)
        self._g2g0 = wx.RadioButton(seeding_panel,
            label="Seed to peers with UL/DL ratio", style=wx.RB_GROUP)
        sd_s2_sizer.Add(self._g2g0, 0, wx.ALIGN_CENTER_VERTICAL)
        self._g2g0choice = wx.Choice(seeding_panel)
        self._g2g0choice.AppendItems(["0.5", "0.75", "1.0", "1.5", "2.0", "3.0", "5.0"])
        sd_s2_sizer.Add(self._g2g0choice, 0, wx.EXPAND | wx.ALIGN_CENTER_VERTICAL)

        self._g2g1 = wx.RadioButton(seeding_panel,
            label="Unlimited seeding (Boost your reputation)")
        sd_s2_sizer.Add(self._g2g1, 0, wx.ALIGN_CENTER_VERTICAL)
        sd_s2_sizer.AddStretchSpacer(1)

        self._g2g2 = wx.RadioButton(seeding_panel,
            label="Seeding for (hours:minutes)")
        sd_s2_sizer.Add(self._g2g2, 0, wx.ALIGN_CENTER_VERTICAL)
        self._g2g2text = wx.lib.masked.textctrl.TextCtrl(seeding_panel)
        self._g2g2text.SetCtrlParameters(mask="##:##", defaultValue="00:00",
            useFixedWidthFont=False)
        sd_s2_sizer.Add(self._g2g2text)

        self._g2g3 = wx.RadioButton(seeding_panel,
            label="No seeding")
        sd_s2_sizer.Add(self._g2g3, 0, wx.ALIGN_CENTER_VERTICAL)

        sd_vsizer.AddStretchSpacer(1)

        sd_faq_text = wx.StaticText(seeding_panel, label="Why differ between 'normal' BitTorrent and Tribler-peers?\nBecause between Tribler-peers you will build up a repuation.\nThis is not the case for 'normal' BitTorrent-peers.")
        sd_vsizer.Add(sd_faq_text)

        # other things
        t4t_option = self.utility.read_config('t4t_option')
        getattr(self, '_t4t%d' % t4t_option).SetValue(True)
        t4t_ratio = self.utility.read_config('t4t_ratio') / 100.0
        index = self._t4t0choice.FindString(str(t4t_ratio))
        if index != wx.NOT_FOUND:
            self._t4t0choice.Select(index)

        t4t_hours = self.utility.read_config('t4t_hours')
        t4t_minutes = self.utility.read_config('t4t_mins')
        self._t4t2text.SetValue("%02d:%02d" % (t4t_hours, t4t_minutes))

        g2g_option = self.utility.read_config('g2g_option')
        getattr(self, '_g2g%d' % g2g_option).SetValue(True)
        g2g_ratio = self.utility.read_config('g2g_ratio') / 100.0
        index = self._g2g0choice.FindString(str(g2g_ratio))
        if index != wx.NOT_FOUND:
            self._g2g0choice.Select(index)

        g2g_hours = self.utility.read_config('g2g_hours')
        g2g_mins = self.utility.read_config('g2g_mins')
        self._g2g2text.SetLabel("%02d:%02d" % (g2g_hours, g2g_mins))

        return seeding_panel, item_id

    def __create_s5(self, tree_root, sizer):
        exp_panel, exp_vsizer = create_section(self, sizer, "Experimental")

        item_id = self._tree_ctrl.AppendItem(tree_root, "Experimental", data=wx.TreeItemData(exp_panel))

        # Web UI
        exp_s1_sizer = create_subsection(exp_panel, exp_vsizer, "Web UI", 2, 3)
        self._use_webui = wx.CheckBox(exp_panel, label="Enable webUI")
        exp_s1_sizer.Add(self._use_webui, 0, wx.EXPAND)
        exp_s1_sizer.AddStretchSpacer()
        exp_s1_port_label = wx.StaticText(exp_panel, label="Current port")
        exp_s1_port_label.SetMinSize(wx.Size(100, -1))
        exp_s1_sizer.Add(exp_s1_port_label, 0, wx.ALIGN_CENTER_VERTICAL)
        self._webui_port = EditText(exp_panel, validator=NumberValidator(min=1, max=65535))
        self._webui_port.SetMinSize(wx.Size(150, -1))
        exp_s1_sizer.Add(self._webui_port)

        exp_s1_faq_text = wx.StaticText(exp_panel, label="The Tribler webUI implements the same API as uTorrent.\nThus all uTorrent remotes are compatible with it.\n\nFurthermore, we additionally allow you to control Tribler\nusing your Browser. Go to http://localhost:PORT/gui to\nview your downloads in the browser.")
        exp_vsizer.Add(exp_s1_faq_text, 0, wx.EXPAND | wx.TOP, 10)

        # load values
        self._use_webui.SetValue(self.utility.read_config('use_webui'))
        self._webui_port.SetValue(str(self.utility.read_config('webui_port')))

        return exp_panel, item_id

########NEW FILE########
__FILENAME__ = SRstatusbar
# Written by Niels Zeilemaker
import wx

from Tribler.Core.simpledefs import UPLOAD, DOWNLOAD
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler

from Tribler.Main.Utility.GuiDBHandler import startWorker
from Tribler.Main.vwxGUI import warnWxThread, forceWxThread
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.widgets import HorizontalGauge, ActionButton


class SRstatusbar(wx.StatusBar):

    def __init__(self, parent):
        wx.StatusBar.__init__(self, parent, style=wx.ST_SIZEGRIP)

        # On Linux/OS X the resize handle and icons overlap, therefore we add an extra field.
        # On Windows this field is automatically set to 1 when the wx.ST_SIZEGRIP is set.
        self.SetFieldsCount(7)
        self.SetStatusStyles([wx.SB_FLAT] * 7)
        self.SetStatusWidths([-1, 250, 50, 19, 19, 19, 19])

        self._gui_image_manager = GuiImageManager.getInstance()

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.library_manager = self.guiutility.library_manager
        self.uelog = UserEventLogDBHandler.getInstance()

        self.ff_checkbox = wx.CheckBox(self, -1, 'Family filter', style=wx.ALIGN_RIGHT)
        self.ff_checkbox.Bind(wx.EVT_CHECKBOX, self.OnCheckbox)
        self.ff_checkbox.SetValue(self.guiutility.getFamilyFilter())

        self.speed_down_icon = self._gui_image_manager.getBitmap(self, u"arrow", self.GetBackgroundColour(), state=0)
        self.speed_down_sbmp = wx.StaticBitmap(self, -1, self.speed_down_icon)
        self.speed_down_sbmp.Bind(wx.EVT_RIGHT_UP, self.OnDownloadPopup)
        self.speed_down = wx.StaticText(self, -1, '')
        self.speed_down.Bind(wx.EVT_RIGHT_UP, self.OnDownloadPopup)
        self.speed_up_icon = self.speed_down_icon.ConvertToImage().Rotate90().Rotate90().ConvertToBitmap()
        self.speed_up_sbmp = wx.StaticBitmap(self, -1, self.speed_up_icon)
        self.speed_up_sbmp.Bind(wx.EVT_RIGHT_UP, self.OnUploadPopup)
        self.speed_up = wx.StaticText(self, -1, '')
        self.speed_up.Bind(wx.EVT_RIGHT_UP, self.OnUploadPopup)

        self.free_space_icon = self._gui_image_manager.getImage(u"drive.png")
        self.free_space_sbmp = wx.StaticBitmap(self, -1, self.free_space_icon)
        self.free_space = wx.StaticText(self, -1, '')

        self.searchConnectionImages = [u"progressbarEmpty.png", u"progressbarFull.png"]
        self.searchConnectionImages = [self._gui_image_manager.getImage(image) for image in self.searchConnectionImages]

        self.activityImages = [u"statusbar_activity.png", u"statusbar_noactivity.png"]
        self.activityImages = [self._gui_image_manager.getImage(image) for image in self.activityImages]

        self.connection = HorizontalGauge(self, self.searchConnectionImages[0], self.searchConnectionImages[1])
        self.activity = wx.StaticBitmap(self, -1, self.activityImages[1])
        self.activity_timer = None
        self.channelconnections = 0

        self.bmp_firewall_warning = self._gui_image_manager.getImage(u"statusbar_warning.png")
        self.bmp_firewall_ok = self._gui_image_manager.getImage(u"statusbar_ok.png")
        self.firewallStatus = ActionButton(self, -1, self.bmp_firewall_warning)
        self.firewallStatus.SetSize((16, 16))
        self.firewallStatus.SetCursor(wx.StockCursor(wx.CURSOR_DEFAULT))
        self.firewallStatus.SetToolTipString('Port status unknown')
        self.firewallStatus.Enable(False)
        self.firewallStatus.SetBitmapDisabled(self.bmp_firewall_warning)

        self.SetTransferSpeeds(0, 0)
        self.Bind(wx.EVT_SIZE, self.OnSize)

        self.library_manager.add_download_state_callback(self.RefreshTransferSpeed)

    @forceWxThread
    def RefreshFreeSpace(self, space):
        if space >= 0:
            space_str = self.utility.size_format(space, truncate=1)
            space_label = space_str.replace(' ', '')
            space_tooltip = 'You current have %s of disk space available on your default download location.' % space_str
            self.free_space.SetLabel(space_label)
            self.free_space.SetToolTipString(space_tooltip)
            self.free_space.Show(True)
            self.free_space_sbmp.SetToolTipString(space_tooltip)
            self.free_space_sbmp.Show(True)
        else:
            self.free_space.Show(False)
            self.free_space_sbmp.Show(False)
        self.Reposition()

    def RefreshTransferSpeed(self, dslist, magnetlist):
        total_down, total_up = 0.0, 0.0
        for ds in dslist:
            total_down += ds.get_current_speed(DOWNLOAD)
            total_up += ds.get_current_speed(UPLOAD)
        self.SetTransferSpeeds(total_down, total_up)

    @warnWxThread
    def SetTransferSpeeds(self, down, up):
        self.speed_down.SetLabel(self.utility.speed_format(down))
        self.speed_up.SetLabel(self.utility.speed_format(up))
        self.Reposition()

    def SetGlobalMaxSpeed(self, direction, value):
        if direction in [UPLOAD, DOWNLOAD]:
            if direction == UPLOAD:
                self.utility.write_config('maxuploadrate', value)
            else:
                self.utility.write_config('maxdownloadrate', value)
            self.guiutility.app.ratelimiter.set_global_max_speed(direction, value)

    def GetSpeedChoices(self, value):
        values = self.utility.round_range(max(0, value)) if value != 0 else range(0, 1000, 100)
        values = [value or -1 for value in values]
        if value != 0 and value not in values:
            values.append(value)
            values.sort()
        values.append(0)
        return [('unlimited' if value == 0 else ('0' if value == -1 else str(value)), value) for value in values]

    def OnDownloadPopup(self, event):
        menu = wx.Menu()
        current = self.utility.read_config('maxdownloadrate')
        value_tuples = self.GetSpeedChoices(current)

        for value_str, value in value_tuples:
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, value_str)
            menu.Bind(wx.EVT_MENU, lambda x, v=value: self.SetGlobalMaxSpeed(DOWNLOAD, v), id=itemid)
            menu.Check(itemid, current == value)

        self.speed_down.PopupMenu(menu, event.GetPosition())
        menu.Destroy()
        self.speed_down.Layout()

    def OnUploadPopup(self, event):
        menu = wx.Menu()
        current = self.utility.read_config('maxuploadrate')
        value_tuples = self.GetSpeedChoices(current)

        for value_str, value in value_tuples:
            itemid = wx.NewId()
            menu.AppendRadioItem(itemid, value_str)
            menu.Bind(wx.EVT_MENU, lambda x, v=value: self.SetGlobalMaxSpeed(UPLOAD, v), id=itemid)
            menu.Check(itemid, current == value)

        self.speed_up.PopupMenu(menu, event.GetPosition())
        menu.Destroy()
        self.speed_up.Layout()

    def OnCheckbox(self, event):
        checkbox = event.GetEventObject()
        checkbox.Enable(False)
        wx.CallLater(1000, checkbox.Enable, True)

        wx.CallLater(100, self.__toggleFF, event.GetEventObject().GetValue())

    @warnWxThread
    def __toggleFF(self, newvalue):
        if newvalue != self.guiutility.getFamilyFilter():
            self.guiutility.toggleFamilyFilter(newvalue)

            def db_callback():
                self.uelog.addEvent(message="SRstatusbar: user toggled family filter", type=2)
            startWorker(None, db_callback, retryOnBusy=True)

    @warnWxThread
    def SetConnections(self, connectionPercentage, totalConnections, channelConnections):
        self.connection.SetPercentage(connectionPercentage)
        self.connection.SetToolTipString('Connected to %d peers' % totalConnections)
        self.channelconnections = channelConnections

    def GetConnections(self):
        return self.connection.GetPercentage()
    def GetChannelConnections(self):
        return self.channelconnections

    @warnWxThread
    def onReachable(self, event=None):
        if not self.guiutility.firewall_restart:
            self.firewallStatus.SetBitmapLabel(self.bmp_firewall_ok)
            self.firewallStatus.SetBitmapDisabled(self.bmp_firewall_ok)
            self.firewallStatus.SetToolTipString('Port is working')

    @warnWxThread
    def IsReachable(self):
        if not self.guiutility.firewall_restart:
            return self.firewallStatus.GetBitmapLabel() == self.bmp_firewall_ok
        return False

    @warnWxThread
    def onActivity(self, msg):
        if self.activity_timer:
            self.activity_timer.Stop()

        def revert():
            self.activity.SetBitmap(self.activityImages[1])
            self.activity.Refresh()

        self.activity.SetBitmap(self.activityImages[0])
        self.activity.Refresh()
        self.activity.SetToolTipString(msg)
        self.activity_timer = wx.CallLater(300, revert)

    def OnSize(self, event):
        self.Reposition()

    def Reposition(self):
        self.Freeze()

        rect = self.GetFieldRect(0)
        self.ff_checkbox.SetPosition((rect.x + 2, rect.y + 2))
        self.ff_checkbox.SetSize((-1, rect.height - 4))

        rect = self.GetFieldRect(1)
        x = rect.x + rect.width - 15
        for control in reversed([self.speed_down_sbmp, self.speed_down, self.speed_up_sbmp, self.speed_up]):
            spacer = 10 if not isinstance(control, wx.StaticBitmap) else 7
            x -= control.GetSize()[0] + spacer
            yAdd = (rect.height - control.GetSize()[1]) / 2
            control.SetPosition((x, rect.y + yAdd))

        rect = self.GetFieldRect(2)
        x = rect.x + rect.width
        for control in [self.free_space, self.free_space_sbmp]:
            size = control.GetSize()
            yAdd = (rect.height - size[1]) / 2
            x -= size[0] + 5
            control.SetPosition((x, rect.y + yAdd))

        rect = self.GetFieldRect(3)
        size = self.connection.GetSize()
        yAdd = (rect.height - size[1]) / 2
        xAdd = (rect.width - size[0]) / 2
        self.connection.SetPosition((rect.x + xAdd, rect.y + yAdd))

        rect = self.GetFieldRect(4)
        size = self.activity.GetSize()
        yAdd = (rect.height - size[1]) / 2
        xAdd = (rect.width - size[0]) / 2
        self.activity.SetPosition((rect.x + xAdd, rect.y + yAdd))

        rect = self.GetFieldRect(5)
        size = self.firewallStatus.GetSize()
        yAdd = (rect.height - size[1]) / 2
        xAdd = (rect.width - size[0]) / 2
        self.firewallStatus.SetPosition((rect.x + xAdd, rect.y + yAdd))

        self.sizeChanged = False
        self.Thaw()

########NEW FILE########
__FILENAME__ = TopSearchPanel
# Written by Niels Zeilemaker
import os
import sys
import logging
import wx.animate

from Tribler import LIBRARYNAME
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import UserEventLogDBHandler, \
    TorrentDBHandler

from Tribler.Main.Utility.GuiDBTuples import CollectedTorrent, Torrent
from Tribler.Main.Utility.GuiDBHandler import startWorker, cancelWorker
from Tribler.Main.vwxGUI import forceWxThread, TRIBLER_RED, SEPARATOR_GREY, \
    GRADIENT_LGREY, GRADIENT_DGREY
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.widgets import ActionButton, FancyPanel, \
    TextCtrlAutoComplete, ProgressButton
from Tribler.Main.Dialogs.AddTorrent import AddTorrent
from Tribler.Main.Dialogs.RemoveTorrent import RemoveTorrent


class TopSearchPanelStub():

    def NextPage(self):
        pass

    def PrevPage(self):
        pass

    def SearchFocus(self):
        pass

    def Refresh(self):
        pass

    def Layout(self):
        pass


class TopSearchPanel(FancyPanel):

    def __init__(self, parent):
        self._logger = logging.getLogger(self.__class__.__name__)

        self._logger.debug("TopSearchPanel: __init__")

        self.loaded_bitmap = None

        self.guiutility = GUIUtility.getInstance()
        self.utility = self.guiutility.utility
        self.installdir = self.utility.getPath()
        self.uelog = UserEventLogDBHandler.getInstance()
        self.tdb = None
        self.collectedTorrents = {}

        FancyPanel.__init__(self, parent, border=wx.BOTTOM)
        self.SetBorderColour(SEPARATOR_GREY)
        self.SetBackgroundColour(GRADIENT_LGREY, GRADIENT_DGREY)
        self.AddComponents()
        self.Bind(wx.EVT_SIZE, self.OnResize)

    def AddComponents(self):
        self.SetForegroundColour(wx.SystemSettings.GetColour(wx.SYS_COLOUR_WINDOWTEXT))

        self._logger.debug("TopSearchPanel: OnCreate")

        gui_image_manager = GuiImageManager.getInstance()

        if sys.platform == 'darwin':
            self.searchField = wx.SearchCtrl(self, -1, "", style=wx.TE_PROCESS_ENTER | wx.NO_BORDER)
            self.searchField.Bind(wx.EVT_SEARCHCTRL_SEARCH_BTN, self.OnSearchKeyDown)
            self.searchField.Bind(wx.EVT_TEXT_ENTER, self.OnSearchKeyDown)
            self.searchField.SetDescriptiveText('Search Files or Channels')
            self.searchField.SetMinSize((400, 20))
        else:
            self.searchFieldPanel = FancyPanel(self, radius=5, border=wx.ALL)
            self.searchFieldPanel.SetBorderColour(SEPARATOR_GREY, highlight=TRIBLER_RED)
            self.searchField = TextCtrlAutoComplete(self.searchFieldPanel, style=wx.NO_BORDER, entrycallback=self.complete, selectcallback=self.OnAutoComplete)
            # Since we have set the style to wx.NO_BORDER, the default height will be too large. Therefore, we need to set the correct height.
            _, height = self.GetTextExtent("Gg")
            self.searchField.SetMinSize((-1, height))
            self.searchFieldPanel.SetMinSize((400, 25))
            self.searchFieldPanel.SetBackgroundColour(self.searchField.GetBackgroundColour())
            self.searchField.Bind(wx.EVT_KILL_FOCUS, self.searchFieldPanel.OnKillFocus)
            self.searchField.Bind(wx.EVT_TEXT_ENTER, self.OnSearchKeyDown)

        self.go = ProgressButton(self, -1)
        self.go.SetMinSize((50, 25))
        self.go.Bind(wx.EVT_LEFT_UP, self.OnSearchKeyDown)

        ag_fname = os.path.join(self.guiutility.utility.getPath(), LIBRARYNAME, 'Main', 'vwxGUI', 'images', 'search_new.gif')
        self.ag = wx.animate.GIFAnimationCtrl(self, -1, ag_fname)
        self.ag.UseBackgroundColour(True)
        self.ag.SetBackgroundColour(wx.Colour(244, 244, 244))
        self.ag.Hide()

        download_bmp = gui_image_manager.getImage(u"download.png")
        self.download_btn = ActionButton(self, -1, download_bmp)
        self.download_btn.Enable(False)
        upload_bmp = gui_image_manager.getImage(u"upload.png")
        self.upload_btn = ActionButton(self, -1, upload_bmp)
        self.upload_btn.Enable(False)
        stop_bmp = gui_image_manager.getImage(u"pause.png")
        self.stop_btn = ActionButton(self, -1, stop_bmp)
        self.stop_btn.Enable(False)
        delete_bmp = gui_image_manager.getImage(u"delete.png")
        self.delete_btn = ActionButton(self, -1, delete_bmp)
        self.delete_btn.Enable(False)
        play_bmp = gui_image_manager.getImage(u"play.png")
        self.play_btn = ActionButton(self, -1, play_bmp)
        self.play_btn.Enable(False)
        add_bmp = gui_image_manager.getImage(u"add.png")
        self.add_btn = ActionButton(self, -1, add_bmp)
        self.SetButtonHandler(self.add_btn, self.OnAdd, 'Download an external torrent.')
        settings_bmp = gui_image_manager.getImage(u"settings.png")
        self.settings_btn = ActionButton(self, -1, settings_bmp)
        self.SetButtonHandler(self.settings_btn, self.OnSettings, 'Change settings.')

        mainSizer = wx.BoxSizer(wx.HORIZONTAL)

        if sys.platform != 'darwin':
            vSizer = wx.BoxSizer(wx.VERTICAL)
            vSizer.AddStretchSpacer()
            vSizer.Add(self.searchField, 0, wx.EXPAND | wx.RESERVE_SPACE_EVEN_IF_HIDDEN | wx.LEFT | wx.RIGHT, 5)
            vSizer.AddStretchSpacer()
            self.searchFieldPanel.SetSizer(vSizer)
            vSizer.Layout()

        # Add searchbox etc.
        self.searchSizer = wx.BoxSizer(wx.VERTICAL)
        searchBoxSizer = wx.BoxSizer(wx.HORIZONTAL)
        if sys.platform == 'darwin':
            searchBoxSizer.Add(self.searchField, 1, wx.CENTER | wx.RESERVE_SPACE_EVEN_IF_HIDDEN)
        else:
            searchBoxSizer.Add(self.searchFieldPanel, 1, wx.CENTER | wx.RESERVE_SPACE_EVEN_IF_HIDDEN)
        searchBoxSizer.Add(self.go, 0, wx.CENTER | wx.LEFT | wx.RESERVE_SPACE_EVEN_IF_HIDDEN, 5)  # add searchbutton
        searchBoxSizer.Add(self.ag, 0, wx.CENTER | wx.LEFT | wx.RESERVE_SPACE_EVEN_IF_HIDDEN, 5)  # add animation
        self.searchSizer.Add(searchBoxSizer, 1, wx.EXPAND)
        # finished searchSizer, add to mainSizer
        mainSizer.Add(self.searchSizer, 0, wx.EXPAND | wx.LEFT, 10)
        mainSizer.AddSpacer((40, 0))

        # add buttons
        buttonSizer = wx.BoxSizer(wx.HORIZONTAL)
        buttonSizer.Add(self.download_btn, 0, wx.CENTER | wx.RIGHT, 5)
        buttonSizer.Add(self.upload_btn, 0, wx.CENTER | wx.RIGHT, 5)
        buttonSizer.Add(self.stop_btn, 0, wx.CENTER | wx.RIGHT, 5)
        buttonSizer.Add(self.delete_btn, 0, wx.CENTER | wx.RIGHT, 5)
        buttonSizer.Add(self.play_btn, 0, wx.CENTER | wx.RIGHT, 5)
        buttonSizer.AddSpacer((35, 0))
        buttonSizer.AddStretchSpacer()
        buttonSizer.Add(self.add_btn, 0, wx.CENTER | wx.RIGHT, 5)
        buttonSizer.Add(self.settings_btn, 0, wx.CENTER | wx.RIGHT, 5)
        mainSizer.Add(buttonSizer, 1, wx.EXPAND)

        self.SetSizer(mainSizer)
        self.Layout()

    @forceDBThread
    def LogEvent(self, *args, **kwargs):
        self.uelog.addEvent(*args, **kwargs)

    def OnResize(self, event):
        self.Refresh()
        event.Skip()

    def OnAutoComplete(self):
        self.LogEvent(message="TopSearchPanel: user used autocomplete", type=2)

    def OnSearchKeyDown(self, event=None):
        if self.go.IsEnabled():
            self._logger.debug("TopSearchPanel: OnSearchKeyDown")

            if getattr(self.searchField, 'ShowDropDown', False):
                self.searchField.ShowDropDown(False)

            self.guiutility.dosearch()

            self.go.Enable(False)
            wx.CallLater(2500, self.go.Enable, True)

    def OnSettings(self, event):
        self.guiutility.ShowPage('settings')

    def OnAdd(self, event):
        dlg = AddTorrent(None, self.guiutility.frame)
        dlg.CenterOnParent()
        dlg.ShowModal()
        dlg.Destroy()

    def OnStats(self, event):
        self.guiutility.ShowPage('stats')

    def StartSearch(self):
        if getattr(self.searchField, 'ShowDropDown', False):
            self.searchField.ShowDropDown(False)
            self.guiutility.frame.searchlist.ResetBottomWindow()

        self.Freeze()
        self.go.SetValue(0)
        self.guiutility.frame.top_bg.ag.Play()
        self.guiutility.frame.top_bg.ag.Show()
        self.Thaw()

    def ShowSearching(self, max):
        self.go.SetRange(max + 16)

        cancelWorker(u"FakeResult")
        startWorker(None, self.FakeResult, uId=u"FakeResult", delay=0.25, workerType="guiTaskQueue")

    @forceWxThread
    def FakeResult(self, times=1):
        newValue = min(self.go.GetValue() + 1, self.go.GetRange())
        if times < 16:
            self.go.SetValue(newValue)

            startWorker(None, self.FakeResult, wargs=(times + 1,), uId=u"FakeResult", delay=0.25, workerType="guiTaskQueue")

    def NewResult(self):
        maxValue = self.go.GetRange()
        newValue = min(self.go.GetValue() + 1, maxValue)
        self.guiutility.frame.top_bg.go.SetValue(newValue)

        if newValue == maxValue:
            return True
        return False

    def SetFinished(self):
        self.Freeze()
        self.ag.Stop()
        self.ag.Hide()
        self.go.SetValue(self.go.GetRange())
        self.Layout()
        self.Thaw()

    def complete(self, term):
        """autocompletes term."""
        if len(term) > 1:
            if self.tdb == None:
                self.tdb = TorrentDBHandler.getInstance()
            return self.tdb.getAutoCompleteTerms(term, max_terms=7)
        return []

    def SearchFocus(self):
        if self.guiutility.guiPage == 'home':
            if getattr(self.GetParent(), 'home', False):
                self.GetParent().home.SearchFocus()
        else:
            self.searchField.SetFocus()
            self.searchField.SelectAll()

    def AddCollectedTorrent(self, coltorrent):
        self.collectedTorrents[coltorrent.infohash] = coltorrent
        self.TorrentsChanged()

    def GetSelectedTorrents(self):
        torrents = None

        page = self.guiutility.guiPage
        if page in ['search_results', 'selectedchannel', 'playlist', 'my_files']:
            list = self.guiutility.GetSelectedPage()
            items = list.GetExpandedItems()
            torrents = [item[1].original_data for item in items if isinstance(item[1].original_data, Torrent) or isinstance(item[1].original_data, CollectedTorrent)]
        return torrents

    def TorrentsChanged(self):
        self.RefreshTorrents(self.GetSelectedTorrents())

    def RefreshTorrents(self, torrents):
        inDownloads = self.guiutility.guiPage == 'my_files'

        if torrents:
            isMultiple = len(torrents) > 1
            usedCollectedTorrents = set()
            states = [0, 0, 0, 0, 0, 0, 0]  # we have 7 different states, able to resume seeding, resume downloading, download, stop seeding, stop downloading, delete, or play
            for torrent in torrents:
                if 'stopped' in torrent.state:
                    if 'completed' in torrent.state:
                        states[0] += 1
                    else:
                        states[1] += 1

                elif not torrent.state:
                    states[2] += 1

                if 'active' in torrent.state:
                    if 'completed' in torrent.state:
                        states[3] += 1
                    else:
                        states[4] += 1

                if torrent.state or inDownloads:
                    states[5] += 1

                if "metadata" not in torrent.state and torrent.infohash in self.collectedTorrents:
                    coltorrent = self.collectedTorrents[torrent.infohash]
                    if coltorrent.isPlayable():
                        states[6] += 1

                    usedCollectedTorrents.add(torrent.infohash)
                else:
                    # If the torrent isn't collected we assume its playable and let the core cancel the VOD if it isn't.
                    states[6] += 1


            enableDownload = states[1] + states[2]
            if enableDownload:
                if isMultiple:
                    self.SetButtonHandler(self.download_btn, self.OnDownload, 'Resume downloading %d torrent(s).' % enableDownload)
                elif states[1]:
                    self.SetButtonHandler(self.download_btn, self.OnResume, 'Resume downloading this torrent.')
                else:
                    self.SetButtonHandler(self.download_btn, self.OnDownload, 'Start downloading this torrent.')
            else:
                self.SetButtonHandler(self.download_btn, None)

            enableUpload = states[0]
            if enableUpload:
                if isMultiple:
                    self.SetButtonHandler(self.upload_btn, self.OnUpload, 'Resume seeding %d torrent(s).' % enableUpload)
                else:
                    self.SetButtonHandler(self.upload_btn, self.OnUpload, 'Resume seeding this torrent.')
            else:
                self.SetButtonHandler(self.upload_btn, None)

            enableStop = states[3] + states[4]
            if enableStop:
                if isMultiple:
                    self.SetButtonHandler(self.stop_btn, self.OnStop, 'Stop %d torrent(s).' % enableStop)
                elif states[3]:
                    self.SetButtonHandler(self.stop_btn, self.OnStop, 'Stop seeding this torrent.')
                else:
                    self.SetButtonHandler(self.stop_btn, self.OnStop, 'Stop downloading this torrent.')
            else:
                self.SetButtonHandler(self.stop_btn, None)

            if states[5] > 1:
                self.SetButtonHandler(self.delete_btn, self.OnDelete, 'Delete %d torrent(s).' % states[5])
            elif states[5]:
                self.SetButtonHandler(self.delete_btn, self.OnDelete, 'Delete this torrent.')
            else:
                self.SetButtonHandler(self.delete_btn, None)

            if isMultiple:
                self.SetButtonHandler(self.play_btn, self.OnPlay, 'Start playing one of the selected torrents.')
            elif states[6]:
                self.SetButtonHandler(self.play_btn, self.OnPlay, 'Start playing this torrent.')
            else:
                self.SetButtonHandler(self.play_btn, None)

            for infohash in self.collectedTorrents.keys():
                if infohash not in usedCollectedTorrents:
                    del self.collectedTorrents[infohash]
        else:
            self.ClearButtonHandlers()

    def SetButtonHandler(self, button, handler=None, tooltip=None):
        button.Enable(bool(handler))
        if handler:
            button.Bind(wx.EVT_LEFT_UP, handler)
            if tooltip:
                button.SetToolTipString(tooltip)
            else:
                button.SetToolTip(None)
        else:
            button.SetToolTip(None)

    def ClearButtonHandlers(self):
        self.SetButtonHandler(self.download_btn, None)
        self.SetButtonHandler(self.upload_btn, None)
        self.SetButtonHandler(self.play_btn, None)
        self.SetButtonHandler(self.stop_btn, None)
        self.SetButtonHandler(self.delete_btn, None)

    def OnDownload(self, event=None, torrents=None):
        refresh_library = False
        torrents = torrents if torrents != None else self.GetSelectedTorrents()
        for torrent in torrents:
            if 'stopped' in torrent.state:
                self.guiutility.library_manager.resumeTorrent(torrent)
            else:
                if self.guiutility.frame.selectedchannellist.IsShownOnScreen():
                    self.guiutility.frame.selectedchannellist.StartDownload(torrent, None)
                else:
                    self.guiutility.frame.searchlist.StartDownload(torrent, None)

                refresh_library = True

        if event:
            button = event.GetEventObject()
            button.Enable(False)
            wx.CallLater(3000, button.Enable, True)

        if refresh_library:
            wx.CallLater(1000, self.guiutility.frame.librarylist.do_or_schedule_refresh, True)

    def OnUpload(self, event):
        for torrent in self.GetSelectedTorrents():
            if 'completed' in torrent.state:
                self.guiutility.library_manager.resumeTorrent(torrent)
        if event:
            button = event.GetEventObject()
            button.Enable(False)

    def OnPlay(self, event):
        # Select the first playable torrent or not collected torrent. Return if none can be found
        torrent = None
        for t in self.GetSelectedTorrents():
            if t.infohash in self.collectedTorrents:
                coltor = self.collectedTorrents[t.infohash]
                if coltor.isPlayable():
                    torrent = coltor
                    break
            else:
                torrent = t
                break

        if not torrent:
            return

        play_executed = False

        if self.guiutility.frame.videoparentpanel:
            self.guiutility.library_manager.playTorrent(torrent.infohash)
            play_executed = True

        else:
            self.guiutility.library_manager.playTorrent(torrent.infohash)
            play_executed = True

        if play_executed:
            if not self.guiutility.frame.searchlist.IsShownOnScreen():
                self.LogEvent(message="Torrent: torrent play from channel", type=2)
            else:
                self.LogEvent(message="Torrent: torrent play from other", type=2)

        button = event.GetEventObject()
        button.Enable(False)

    def OnResume(self, event=None):
        for torrent in self.GetSelectedTorrents():
            self.guiutility.library_manager.resumeTorrent(torrent)
        if event:
            button = event.GetEventObject()
            button.Enable(False)

    def OnStop(self, event=None):
        for torrent in self.GetSelectedTorrents():
            self.guiutility.library_manager.stopTorrent(torrent)
        if event:
            button = event.GetEventObject()
            button.Enable(False)

    def OnDelete(self, event=None, silent=False, delete=False):
        torrents = self.GetSelectedTorrents()
        if not silent:
            dlg = RemoveTorrent(None, torrents)
            buttonId = dlg.ShowModal()
        else:
            buttonId = wx.ID_DELETE if delete else wx.ID_DEFAULT

        if buttonId in [wx.ID_DEFAULT, wx.ID_DELETE]:
            for torrent in torrents:
                self.guiutility.library_manager.deleteTorrent(torrent, buttonId == wx.ID_DELETE)
                self.guiutility.frame.librarylist.RemoveItem(torrent.infohash)

            self.guiutility.frame.librarylist.GetManager().refresh()
            if self.guiutility.frame.librarylist.IsShownOnScreen():
                self.ClearButtonHandlers()
                self.guiutility.frame.librarylist.ResetBottomWindow()

        if self.guiutility.frame.librarylist.list.IsEmpty():
            self.guiutility.frame.librarylist.SetData([])

        if not silent:
            if dlg.newName:
                if dlg.newName.IsChanged():
                    dlg2 = wx.MessageDialog(None, 'Do you want to save your changes made to this torrent?', 'Save changes?', wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION)
                    if dlg2.ShowModal() == wx.ID_YES:
                        self.guiutility.channelsearch_manager.modifyTorrent(torrent.channel.id, torrent.channeltorrent_id, {'name':dlg.newName.GetValue()})
                    dlg2.Destroy()
            dlg.Destroy()

########NEW FILE########
__FILENAME__ = TorrentStateManager
import os
import json
import shutil
import hashlib
import binascii
import logging
import tempfile
from threading import currentThread, Thread

try:
    prctlimported = True
    import prctl
except ImportError, e:
    prctlimported = False

from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core.Video.VideoUtility import get_videoinfo, preferred_timecodes, \
    limit_resolution, get_thumbnail


class TorrentStateManager:
    # Code to make this a singleton
    __single = None

    def __init__(self, guiUtility):
        if TorrentStateManager.__single:
            raise RuntimeError("TorrentStateManager is singleton")
        TorrentStateManager.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

    def getInstance(*args, **kw):
        if TorrentStateManager.__single is None:
            TorrentStateManager(*args, **kw)
        return TorrentStateManager.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        TorrentStateManager.__single = None
    delInstance = staticmethod(delInstance)

    def connect(self, torrent_manager, library_manager, channelsearch_manager):
        self.torrent_manager = torrent_manager
        self.library_manager = library_manager
        self.channelsearch_manager = channelsearch_manager

    def torrentFinished(self, infohash):
        torrent = self.torrent_manager.getTorrentByInfohash(infohash)

        self.library_manager.addDownloadState(torrent)
        torrent = self.torrent_manager.loadTorrent(torrent)

        ds = torrent.ds
        dest_files = ds.get_download().get_dest_files()
        largest_file = torrent.largestvideofile

        for filename, destname in dest_files:
            if filename == largest_file:
                self._logger.info('Can run post-download scripts for %s %s %s', torrent, filename, destname)
                self.create_and_seed_metadata(destname, torrent)

    def create_and_seed_metadata(self, videofile, torrent):
        t = Thread(target=self._create_and_seed_metadata, args=(videofile, torrent), name="ThumbnailGenerator")
        t.start()

    def _create_metadata_roothash_and_contenthash(self, tempdir, torrent):
        assert isinstance(tempdir, str) or isinstance(tempdir, unicode), \
            u"tempdir is of type %s" % type(tempdir)

        from Tribler.Core.Session import Session
        session = Session.get_instance()

        torcoldir = session.get_torrent_collecting_dir()
        thumb_filenames = []
        for filename in os.listdir(tempdir):
            filepath = os.path.join(tempdir, filename)
            if not os.path.isfile(filepath):
                continue
            if not (filename.endswith(".jpg") or filename.endswith(".jpeg") or filename.endswith(".png")):
                continue
            if os.path.getsize(filepath) < 1024:
                continue
            thumb_filenames.append(filepath)
        if not thumb_filenames:
            return

        # Calculate sha1 of the thumbnails.
        contenthash = hashlib.sha1()
        for fn in thumb_filenames:
            with open(fn, 'rb') as fp:
                contenthash.update(fp.read())
        contenthash_hex = contenthash.hexdigest()

        # Move files to torcoldir/thumbs-infohash/contenthash.
        finaldir = os.path.join(torcoldir, 'thumbs-' + binascii.hexlify(torrent.infohash), contenthash_hex)
        # ignore the folder that has already been downloaded
        if os.path.exists(finaldir):
            shutil.rmtree(tempdir)
        else:
            shutil.move(tempdir, finaldir)
        thumb_filenames = [fn.replace(tempdir, finaldir) for fn in thumb_filenames]

        if len(thumb_filenames) == 1:
            mfplaceholder_path = os.path.join(finaldir, ".mfplaceholder")
            open(mfplaceholder_path, "a").close()
            thumb_filenames.append(mfplaceholder_path)

        # Create SwiftDef.
        sdef = SwiftDef()
        sdef.set_tracker("127.0.0.1:%d" % session.get_swift_dht_listen_port())
        for thumbfile in thumb_filenames:
            if os.path.exists(thumbfile):
                xi = os.path.relpath(thumbfile, torcoldir)
                sdef.add_content(thumbfile, xi)

        specpn = sdef.finalize(session.get_swift_path(), destdir=torcoldir)
        hex_roothash = sdef.get_roothash_as_hex()

        try:
            swift_filename = os.path.join(torcoldir, hex_roothash)
            shutil.move(specpn, swift_filename)
            shutil.move(specpn + '.mhash', swift_filename + '.mhash')
            shutil.move(specpn + '.mbinmap', swift_filename + '.mbinmap')
        except:
            self._logger.exception(u"Failed to move swift files: specpn=%s, swift_filename=%s", specpn, swift_filename)

        return hex_roothash, contenthash_hex


    def _create_and_seed_metadata(self, videofile, torrent):
        if prctlimported:
            prctl.set_name("Tribler" + currentThread().getName())

        # skip if we already have a video-info
        from Tribler.Core.CacheDB.SqliteCacheDBHandler import MetadataDBHandler
        metadata_db_handler = MetadataDBHandler.getInstance()
        result_list = metadata_db_handler.getMetdataDateByInfohash(torrent.infohash)
        if result_list:
            for key, _ in result_list:
                if key == 'video-info':
                    return

        from Tribler.Core.Session import Session
        self.session = Session.get_instance()
        videoanalyser = self.session.get_video_analyser_path()

        torcoldir = self.session.get_torrent_collecting_dir()
        thumbdir_root = os.path.join(torcoldir, 'thumbs-' + binascii.hexlify(torrent.infohash))

        if [f for _, _, fn in os.walk(os.path.expanduser(thumbdir_root)) for f in fn if f.startswith('ag_')]:
            self._logger.debug('create_and_seed_metadata: already downloaded thumbnails for torrent %s', torrent.name)
            return

        self._logger.debug('create_and_seed_metadata: going to seed metadata for torrent %s', torrent.name)

        # Determine duration, bitrate, and resolution from the given videofile.
        duration, bitrate, resolution = get_videoinfo(videofile, videoanalyser)
        video_info = {'duration': duration,
                      'bitrate': bitrate,
                      'resolution': resolution}

        self._logger.debug('create_and_seed_metadata: FFMPEG - duration = %d, bitrate = %d, resolution = %s', duration, bitrate, resolution)

        # Generate thumbnails.
        videoname = os.path.basename(videofile)
        tempdir = tempfile.mkdtemp()

        thumb_filenames = [os.path.join(tempdir, "ag_" + videoname + postfix) for postfix in ["-thumb%d.jpg" % i for i in range(1, 5)]]
        thumb_resolutions = [(1280, 720), (320, 240), (320, 240), (320, 240)]
        thumb_timecodes = preferred_timecodes(videofile, duration, limit_resolution(resolution, (100, 100)), videoanalyser, k=4)

        for filename, max_res, timecode in zip(thumb_filenames, thumb_resolutions, thumb_timecodes):
            thumb_res = limit_resolution(resolution, max_res)
            get_thumbnail(videofile, filename, thumb_res, videoanalyser, timecode)

            path_exists = os.path.exists(filename)
            self._logger.debug('create_and_seed_metadata: FFMPEG - thumbnail created = %s, timecode = %d', path_exists, timecode)

        # Create modification
        modifications = []
        modifications.append(('video-info', json.dumps(video_info)))

        result = self._create_metadata_roothash_and_contenthash(tempdir, torrent)
        if result:
            roothash_hex, contenthash_hex = result
            modifications.append(('swift-thumbs', json.dumps((thumb_timecodes, roothash_hex, contenthash_hex))))

        self._logger.debug('create_and_seed_metadata: modifications = %s', modifications)

        self.torrent_manager.modifyTorrent(torrent, modifications)

########NEW FILE########
__FILENAME__ = UserDownloadChoice
import json
import thread
import logging


class UserDownloadChoice:
    _singleton = None
    _singleton_lock = thread.allocate_lock()

    @classmethod
    def get_singleton(cls, *args, **kargs):
        if cls._singleton is None:
            cls._singleton_lock.acquire()
            try:
                if cls._singleton is None:
                    cls._singleton = cls(*args, **kargs)
            finally:
                cls._singleton_lock.release()
        return cls._singleton

    def __init__(self, utility=None):
        assert self._singleton is None
        self._utility = None
        self._choices = {"download_state": {}}

        self._logger = logging.getLogger(self.__class__.__name__)

        if utility:
            self.set_utility(utility)

    def set_utility(self, utility):
        self._utility = utility

        try:
            self._choices = json.loads(utility.read_config("user_download_choice", literal_eval=False))
        except:
            self._choices = {}

        # Ensure that there is a "download_state" dictionary. It
        # should contain infohash/state tuples.
        if not "download_state" in self._choices:
            self._choices["download_state"] = {}

    def flush(self):
        if self._utility:
            self._logger.debug("UserDownloadChoice: saving to config file")
            self._utility.write_config("user_download_choice", json.dumps(self._choices), flush=True)

    def set_download_state(self, infohash, choice, flush=True):
        infohash = infohash.encode('hex')
        self._choices["download_state"][infohash] = choice
        if flush:
            self.flush()

    def remove_download_state(self, infohash, flush=True):
        infohash = infohash.encode('hex')
        if infohash in self._choices["download_state"]:
            del self._choices["download_state"][infohash]
            if flush:
                self.flush()

    def get_download_state(self, infohash, default=None):
        infohash = infohash.encode('hex')
        return self._choices["download_state"].get(infohash, default)

    def get_download_states(self):
        return dict((k.decode('hex'), v) for k, v in self._choices["download_state"].iteritems())

########NEW FILE########
__FILENAME__ = validator
import wx
import string
import os

class BaseValidator(wx.PyValidator):

    def __init__(self):
        super(BaseValidator, self).__init__()

    def TransferToWindow(self):
        return True

    def TransferFromWindow(self):
        return True


class TextCtrlValidator(BaseValidator):

    CHECKTYPE_DIGIT = 1
    CHECKTYPE_ALPHA = 2

    def __init__(self, check_type=0):
        super(TextCtrlValidator, self).__init__()
        self._check_type = check_type

        self.Bind(wx.EVT_CHAR, self.OnChar)

    def Clone(self):
        return TextCtrlValidator(self._check_type)

    def Validate(self, win):
        edit_text = self.GetWindow()
        value = edit_text.GetValue()

        for ch in value:
            if self._check_type & self.CHECKTYPE_DIGIT:
                if ch not in string.digits:
                    return False
            if self._check_type & self.CHECKTYPE_ALPHA:
                if ch not in string.letters:
                    return False

        return True

    def OnChar(self, event):
        key = event.GetKeyCode()

        if key < wx.WXK_SPACE or key == wx.WXK_DELETE or key > 255:
            event.Skip()
            return

        if self._check_type & self.CHECKTYPE_DIGIT and chr(key) in string.digits:
            event.Skip()
            return

        if self._check_type & self.CHECKTYPE_ALPHA and chr(key) in string.letters:
            event.Skip()
            return

        if not wx.Validator_IsSilent():
            wx.Bell()

        return


class NumberValidator(BaseValidator):

    def __init__(self, min=None, max=None):
        super(NumberValidator, self).__init__()

        self._min = min
        self._max = max

        self.Bind(wx.EVT_CHAR, self.OnChar)

    def Clone(self):
        return NumberValidator(self._min, self._max)

    def Validate(self, win):
        edit_text = self.GetWindow()
        value = edit_text.GetValue()

        if not edit_text.IsEnabled():
            return True

        if not value:
            wx.MessageBox("Empty text", "Error",
                wx.OK | wx.ICON_ERROR, edit_text.GetParent())
            edit_text.SetValue(edit_text.original_text)
            return False
        for ch in value:
            if ch not in string.digits:
                return False

        new_value = int(value)
        if self._min is not None and new_value < self._min:
            wx.MessageBox("Number too small (%d < %d)" % (new_value, self._min), "Error",
                wx.OK | wx.ICON_ERROR, edit_text.GetParent())
            edit_text.SetValue(edit_text.original_text)
            return False

        if self._max is not None and new_value > self._max:
            wx.MessageBox("Number too big (%d > %d)" % (new_value, self._max), "Error",
                wx.OK | wx.ICON_ERROR, edit_text.GetParent())
            edit_text.SetValue(edit_text.original_text)
            return False

        return True

    def OnChar(self, event):
        key = event.GetKeyCode()
        value = event.GetEventObject().GetValue()

        if key < wx.WXK_SPACE or key == wx.WXK_DELETE or key > 255:
            event.Skip()
            return

        if chr(key) in string.digits:
            event.Skip()
            return

        if not wx.Validator_IsSilent():
            wx.Bell()

        return


class DirectoryValidator(BaseValidator):

    def __init__(self):
        super(DirectoryValidator, self).__init__()

    def Clone(self):
        return DirectoryValidator()

    def Validate(self, win):
        edit_text = self.GetWindow()
        value = edit_text.GetValue()

        is_valid = os.path.isdir(value)
        if not is_valid:
            wx.MessageBox("Invalid path [%s]" % value, "Error",
                wx.OK | wx.ICON_ERROR, edit_text.GetParent())
            edit_text.SetValue(edit_text.original_text)
        return is_valid


class NetworkSpeedValidator(BaseValidator):

    def __init__(self):
        super(NetworkSpeedValidator, self).__init__()

    def Clone(self):
        return NetworkSpeedValidator()

    def Validate(self, win):
        edit_text = self.GetWindow()
        value = edit_text.GetValue()

        if value == 'unlimited':
            return True
        if not value or any(ch not in string.digits for ch in value):
            wx.MessageBox("Empty network speed [%s]" % value, "Error",
                wx.OK | wx.ICON_ERROR, edit_text.GetParent())
            edit_text.SetValue(edit_text.original_text)
            return False
        return True

########NEW FILE########
__FILENAME__ = widgets
# Written by Niels Zeilemaker, Egbert Bouman
import sys
import math
import wx
from wx.lib.stattext import GenStaticText
from wx.lib.colourutils import AdjustColour
from wx.lib.wordwrap import wordwrap
from wx.lib.mixins.listctrl import CheckListCtrlMixin, ListCtrlAutoWidthMixin

from Tribler.Main.Utility.GuiDBHandler import startWorker
from Tribler.Main.vwxGUI import TRIBLER_RED, LIST_HIGHTLIGHT, \
    GRADIENT_LRED, GRADIENT_DRED, SEPARATOR_GREY, FILTER_GREY, \
    DEFAULT_BACKGROUND, COMPLETED_COLOUR, SEEDING_COLOUR, DOWNLOADING_COLOUR, \
    STOPPED_COLOUR
from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
from Tribler.Main.vwxGUI.GuiImageManager import GuiImageManager
from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice
from Tribler.Core.simpledefs import DLMODE_VOD


class BetterText(wx.StaticText):

    def __init__(self, *args, **kwargs):
        wx.StaticText.__init__(self, *args, **kwargs)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackGround)

    def OnEraseBackGround(self, event):
        pass

    def SetLabel(self, text):
        if text != self.GetLabel():
            wx.StaticText.SetLabel(self, text)


class MaxBetterText(wx.BoxSizer):

    def __init__(self, parent, label, maxLines=6, maxCharacters=600, name=None, button=None):
        wx.BoxSizer.__init__(self, wx.VERTICAL)

        self.fullLabel = ''
        self.expand = button
        self.parent = parent

        self.maxLines = maxLines
        self.maxCharacters = maxCharacters
        self.name = name or 'item'
        self.name = self.name.lower()

        self.label = BetterText(parent, -1, '')
        self.Add(self.label, 0, wx.EXPAND)

        self.SetLabel(label)

        if sys.platform == 'win32':  # lets do manual word wrapping
            self.label.Bind(wx.EVT_SIZE, self.OnSize)

    def Show(self, show):
        self.ShowItems(show)

    def SetLabel(self, label):
        if self.fullLabel != label:
            self.fullLabel = label
            self.shortLabel = self._limitLabel(label)

            self.label.SetLabel(self.shortLabel)

            if len(self.shortLabel) < len(self.fullLabel):
                self.hasMore = True

                if not self.expand:
                    self.expand = LinkText(self.parent, "See more >>", colours=[None, TRIBLER_RED], parentsizer=self)
                    self.expand.Bind(wx.EVT_LEFT_UP, self.OnFull)
                    self.Add(self.expand, 0, wx.ALIGN_LEFT)
                else:
                    self.expand.Bind(wx.EVT_LEFT_UP, self.OnFull)
                    self.expand.SetLabel("See more >>")
            else:
                self.hasMore = False

    def GetLabel(self):
        return self.fullLabel

    def OnFull(self, event):
        if not self.IsExpanded():
            self.expand.SetLabel("<< See less")
            self.label.SetLabel(self.fullLabel)
        else:
            self.expand.SetLabel("See more >>")
            self.label.SetLabel(self.shortLabel)

        self.parent.OnChange()

    def IsExpanded(self):
        return self.expand == None or self.expand.GetLabel().startswith('<< See less')

    def OnSize(self, event):
        width = self.label.GetSize()[0]
        bestwidth = self.label.GetBestSize()[0]

        if width > 1 and bestwidth != width:
            dc = wx.ClientDC(self.label)
            dc.SetFont(self.label.GetFont())
            label = wordwrap(self.fullLabel, width, dc, breakLongWords=True, margin=0)
            if not self.IsExpanded():
                self.shortLabel = label = self._limitLabel(label)
            self.label.SetLabel(label)

    def SetMinSize(self, minsize):
        self.label.SetMinSize(minsize)
        self.Layout()

    def find_nth(self, haystack, needle, n):
        start = haystack.find(needle)
        while start >= 0 and n > 1:
            start = haystack.find(needle, start + len(needle))
            n -= 1
        return start

    def _limitLabel(self, label):
        # find 6th line or break at 600 characters
        breakAt = self.find_nth(label, '\n', self.maxLines)
        if breakAt != -1:
            breakAt = min(breakAt, self.maxCharacters)
        else:
            breakAt = self.maxCharacters

        return label[:breakAt]


# Stripped down version of wx.lib.agw.HyperTextCtrl, thank you andrea.gavana@gmail.com
class LinkText(GenStaticText):

    def __init__(self, parent, label, fonts=[None, None], colours=[None, None], style=0, parentsizer=None):
        if parentsizer:
            self.parentsizer = parentsizer
        else:
            self.parentsizer = parent

        GenStaticText.__init__(self, parent, -1, label, style=style)
        self.SetCursor(wx.StockCursor(wx.CURSOR_HAND))

        self.SetFonts(fonts)
        self.SetColours(colours)
        self.Reset()

        self.Bind(wx.EVT_MOUSE_EVENTS, self.OnMouseEvent)
        self.Bind(wx.EVT_MOTION, self.OnMouseEvent)
        self.enter = False

    def SetFonts(self, fonts):
        self.fonts = []
        for font in fonts:
            if font is None:
                font = self.GetFont()
            self.fonts.append(font)

    def SetColours(self, colours):
        self.colours = []
        for colour in colours:
            if colour is None:
                colour = self.GetForegroundColour()
            self.colours.append(colour)

    def GetColours(self):
        return self.colours

    def Reset(self):
        self.SetFontColour(self.fonts[0], self.colours[0])
        self.enter = False

    def SetFontColour(self, font, colour):
        needRefresh = False

        if self.GetFont() != font:
            self.SetFont(font)

            needRefresh = True

        if self.GetForegroundColour() != colour:
            self.SetForegroundColour(colour)

            needRefresh = True

        if needRefresh:
            self.Refresh()
            self.parentsizer.Layout()

    def OnMouseEvent(self, event):
        if event.Moving():
            self.SetFontColour(self.fonts[1], self.colours[1])
            self.enter = True

        elif event.LeftUp() or event.LeftDown():
            pass
        else:
            self.SetFontColour(self.fonts[0], self.colours[0])
            self.enter = False

        event.Skip()

    def SetBackgroundColour(self, colour):
        GenStaticText.SetBackgroundColour(self, colour)
        self.Refresh()


class LinkStaticText(wx.BoxSizer):

    def __init__(self, parent, text, icon="bullet_go.png", icon_type=None, icon_align=wx.ALIGN_RIGHT, font_increment=0, font_colour='#0473BB'):
        wx.BoxSizer.__init__(self, wx.HORIZONTAL)
        self.parent = parent

        self.icon_type = icon_type
        self.icon_align = icon_align

        if icon:
            self.icon = wx.StaticBitmap(parent, bitmap=GuiImageManager.getInstance().getImage(icon))
            self.icon.SetCursor(wx.StockCursor(wx.CURSOR_HAND))
        elif icon_type:
            self.icon = wx.StaticBitmap(parent, bitmap=GuiImageManager.getInstance().getBitmap(parent, self.icon_type, parent.GetBackgroundColour(), state=0))
        else:
            self.icon = None

        if self.icon and icon_align == wx.ALIGN_LEFT:
            self.Add(self.icon, 0, wx.ALIGN_CENTER_VERTICAL | wx.RIGHT, 3)

        normalfont = parent.GetFont()
        normalfont.SetPointSize(normalfont.GetPointSize() + font_increment)

        selectedfont = parent.GetFont()
        selectedfont.SetPointSize(normalfont.GetPointSize() + font_increment)
        selectedfont.SetUnderlined(True)

        self.text = LinkText(parent, text, fonts=[normalfont, selectedfont], colours=[font_colour, (255, 0, 0, 255)], parentsizer=self)
        self.Add(self.text, 1, wx.ALIGN_CENTER_VERTICAL)

        if self.icon and icon_align == wx.ALIGN_RIGHT:
            self.Add(self.icon, 0, wx.ALIGN_CENTER_VERTICAL | wx.LEFT | wx.RESERVE_SPACE_EVEN_IF_HIDDEN, 3)

        if self.icon and text == '':
            self.icon.Hide()

        self.SetCursor(wx.StockCursor(wx.CURSOR_HAND))
        if parent.GetBackgroundStyle() != wx.BG_STYLE_SYSTEM:
            self.SetBackgroundColour(parent.GetBackgroundColour())

    def SetToolTipString(self, tip):
        self.text.SetToolTipString(tip)
        if self.icon:
            self.icon.SetToolTipString(tip)

    def SetLabel(self, text):
        if text != self.text.GetLabel():
            if self.icon:
                self.icon.Show(text != '')

            self.text.SetLabel(text)
            if self.icon and self.icon_align == wx.ALIGN_RIGHT:
                self.text.SetMaxSize((self.text.GetBestSize()[0], -1))

            self.Layout()

    def GetLabel(self):
        return self.text.GetLabel()

    def SetFont(self, font):
        self.text.SetFont(font)

    def GetFont(self):
        return self.text.GetFont()

    def Show(self, show):
        if self.icon:
            self.icon.Show(show)
        if self.text:
            self.text.Show(show)

    def IsShown(self):
        if self.text:
            return self.text.IsShown()
        return False

    def ShowIcon(self, show=True):
        if self.icon and self.icon.IsShown() != show:
            self.icon.Show(show)

    def IsIconShown(self):
        if self.icon:
            return self.icon.IsShown()
        return False

    def SetIconToolTipString(self, tip):
        if self.icon:
            self.icon.SetToolTipString(tip)

    def SetMinSize(self, minsize):
        self.text.SetMinSize(minsize)
        self.Layout()

    def HighLight(self, timeout=2.0):
        self.SetBackgroundColour(LIST_HIGHTLIGHT, blink=True)
        wx.CallLater(timeout * 1000, self.Revert)

    def Revert(self):
        self.SetBackgroundColour(self.originalColor, blink=True)

    def Blink(self):
        self.HighLight(0.15)
        wx.CallLater(300, self.HighLight, 0.15)

    def SetCursor(self, cursor):
        if self.icon:
            self.icon.SetCursor(cursor)

    def ClientToScreen(self, pt):
        if self.icon and self.icon_align != wx.ALIGN_RIGHT:
            return self.icon.ClientToScreen(pt)
        return self.text.ClientToScreen(pt)

    def Bind(self, event, handler, source=None, id= -1, id2= -1):
        def modified_handler(actual_event, handler=handler):
            actual_event.SetEventObject(self)
            handler(actual_event)

        self.text.Bind(event, modified_handler, source, id, id2)
        if self.icon:
            self.icon.Bind(event, modified_handler, source, id, id2)

    def Unbind(self, event):
        self.text.Unbind(event)
        if self.icon:
            self.icon.Unbind(event)

    def SetBackgroundColour(self, colour, blink=False):
        if not blink:
            self.originalColor = colour
        self.text.SetBackgroundColour(colour)

        if self.icon and self.icon_type:
            self.icon.SetBitmap(GuiImageManager.getInstance().getBitmap(self.parent, self.icon_type, colour, state=0))
            self.icon.Refresh()

    def SetForegroundColour(self, colour):
        colours = self.text.GetColours()
        colours[0] = colour
        self.text.SetColours(colours)
        font = self.GetFont()
        if self.text.enter:
            self.text.SetFontColour(font, colours[1])
        else:
            self.text.SetFontColour(font, colours[0])


class HorizontalGauge(wx.Control):

    def __init__(self, parent, background, bitmap, repeat=1, bordersize=0, size=wx.DefaultSize):
        wx.Control.__init__(self, parent, size=size, style=wx.NO_BORDER)

        self.background = background
        self.bitmap = bitmap
        self.repeat = repeat
        self.bordersize = bordersize
        self.percentage = 0
        self.hasBGColour = False

        if size == wx.DefaultSize:
            size = background.GetSize()
            self.SetMinSize((size.width * repeat, size.height))

        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetMinSize(self, size):
        w, h = size
        if w == -1:
            w = self.GetSize().x
        if h == -1:
            h = self.GetSize().y
        wx.Control.SetMinSize(self, (w, h))

    def SetPercentage(self, percentage):
        self.percentage = percentage
        self.Refresh()

    def GetPercentage(self):
        return self.percentage

    def SetBackgroundColour(self, colour):
        self.hasBGColour = True
        return wx.Control.SetBackgroundColour(self, colour)

    def OnPaint(self, event):
        dc = wx.PaintDC(self)
        if self.hasBGColour:
            dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
            dc.Clear()

        bitmapWidth, bitmapHeight = self.bitmap.GetSize()

        width, height = self.GetClientSize()
        width -= self.bordersize * 2
        width = min(width, self.repeat * bitmapWidth)

        xpos = self.bordersize
        ypos = (height - bitmapHeight) / 2

        for i in range(self.repeat):
            dc.DrawBitmap(self.background, xpos + (i * bitmapWidth), ypos, True)

        dc.SetClippingRegion(xpos, ypos, width * self.percentage, bitmapHeight)
        for i in range(self.repeat):
            dc.DrawBitmap(self.bitmap, xpos + (i * bitmapWidth), ypos, True)

    def OnEraseBackground(self, event):
        pass


class EditText(wx.TextCtrl):

    def __init__(self, parent, text="", multiline=False, validator=wx.DefaultValidator):
        style = 0
        if multiline:
            style = style | wx.TE_MULTILINE

        wx.TextCtrl.__init__(self, parent, -1, text, style=style, validator=validator)
        self.original_text = text

        self.multiline = multiline
        self.maxlength = 0

    def SetValue(self, value):
        wx.TextCtrl.SetValue(self, value)
        self.original_text = value

    def SetMaxLength(self, maxlength):
        if self.multiline:
            self.maxlength = maxlength
            self.Bind(wx.EVT_TEXT, self.OnText)
        else:
            wx.TextCtrl.SetMaxLength(self, maxlength)

    def OnText(self, event):
        value = self.GetValue()
        if len(value) > self.maxlength:
            self.SetValue(value[:self.maxlength])

    def RevertChange(self):
        self.SetValue(self.original_text)

    def IsChanged(self):
        return self.original_text != self.GetValue()

    def Saved(self):
        self.original_text = self.GetValue()

    def GetChanged(self):
        if self.IsChanged():
            return self.GetValue()


class NotebookPanel(wx.Panel):

    def __init__(self, *args, **kwargs):
        wx.Panel.__init__(self, *args, **kwargs)
        self.SetForegroundColour(self.GetParent().GetForegroundColour())

        self.sizer = wx.BoxSizer()
        self.SetSizer(self.sizer)

    def SetList(self, list, spacer=0):
        self.list = list
        self.list.IsShownOnScreen = self.IsShownOnScreen
        self.sizer.Add(list, 1, wx.EXPAND | wx.ALL, spacer)

    def IsShownOnScreen(self):
        notebook = self.GetParent()
        page = notebook.GetCurrentPage()
        return page == self

    def __getattr__(self, name):
        try:
            wx.Panel.__getattr__(self, name)
        except:
            return getattr(self.list, name)

    def Show(self, show=True, isSelected=False):
        wx.Panel.Show(self, show)
        self.list.Show(show, isShown=isSelected)
        if show:
            self.Layout()

    def Focus(self):
        self.list.Focus()

    def Reset(self):
        self.list.Reset()

    def SetupScrolling(self, *args, **kwargs):
        if hasattr(self.list, 'SetupScrolling'):
            self.list.SetupScrolling(*args, **kwargs)


class AutoWidthListCtrl(wx.ListCtrl, ListCtrlAutoWidthMixin):

    def __init__(self, parent, style):
        wx.ListCtrl.__init__(self, parent, style=style)
        ListCtrlAutoWidthMixin.__init__(self)


class BetterListCtrl(wx.ListCtrl, ListCtrlAutoWidthMixin):

    def __init__(self, parent, style=wx.LC_REPORT | wx.LC_NO_HEADER | wx.NO_BORDER, tooltip=True):
        wx.ListCtrl.__init__(self, parent, -1, style=style)
        ListCtrlAutoWidthMixin.__init__(self)
        if tooltip:
            self.Bind(wx.EVT_MOTION, self.OnMouseMotion)

    def GetListCtrl(self):
        return self

    def OnMouseMotion(self, event):
        tooltip = ''
        row, _ = self.HitTest(event.GetPosition())
        if row >= 0:
            try:
                for col in xrange(self.GetColumnCount()):
                    tooltip += self.GetItem(row, col).GetText() + "    "

                if len(tooltip) > 0:
                    tooltip = tooltip[:-4]
            except:
                pass
        self.SetToolTipString(tooltip)


class SelectableListCtrl(BetterListCtrl):

    def __init__(self, parent, style=wx.LC_REPORT | wx.LC_NO_HEADER | wx.NO_BORDER, tooltip=True):
        BetterListCtrl.__init__(self, parent, style, tooltip)
        self.allselected = False
        self.Bind(wx.EVT_KEY_DOWN, self._CopyToClipboard)

    def _CopyToClipboard(self, event):
        if event.ControlDown():
            if event.GetKeyCode() == 67:  # ctrl + c
                data = ""

                selected = self.GetFirstSelected()
                while selected != -1:
                    for col in xrange(self.GetColumnCount()):
                        data += self.GetItem(selected, col).GetText() + "\t"
                    data += "\n"
                    selected = self.GetNextSelected(selected)

                do = wx.TextDataObject()
                do.SetText(data)
                wx.TheClipboard.Open()
                wx.TheClipboard.SetData(do)
                wx.TheClipboard.Close()

            elif event.GetKeyCode() == 65:  # ctrl + a
                self.doSelectAll()
        event.Skip()

    def doSelectAll(self):
        for index in xrange(self.GetItemCount()):
            if self.allselected:
                self.Select(index, 0)
            else:
                self.Select(index, 1)
        self.allselected = not self.allselected


class CheckSelectableListCtrl(SelectableListCtrl, CheckListCtrlMixin):

    def __init__(self, parent, style=wx.LC_REPORT | wx.LC_NO_HEADER | wx.NO_BORDER, tooltip=True):
        SelectableListCtrl.__init__(self, parent, style, tooltip)
        CheckListCtrlMixin.__init__(self)
        self.Bind(wx.EVT_LIST_ITEM_ACTIVATED, self.OnItemActivated)

    def OnItemActivated(self, event):
        if not wx.GetKeyState(wx.WXK_RETURN):
            self.ToggleItem(event.m_itemIndex)

    def IsSelected(self, index):
        return self.IsChecked(index)

    def GetSelectedItems(self):
        selected = []
        for index in xrange(self.GetItemCount()):
            if self.IsChecked(index):
                selected.append(index)
        return selected

    def doSelectAll(self):
        for index in xrange(self.GetItemCount()):
            if self.allselected:
                self.CheckItem(index, False)
            else:
                self.CheckItem(index, True)
        self.allselected = not self.allselected


class TextCtrlAutoComplete(wx.TextCtrl):

    def __init__ (self, parent, entrycallback=None, selectcallback=None, **therest):
        '''
            Constructor works just like wx.TextCtrl
        '''
        if 'style' in therest:
            therest['style'] = wx.TE_PROCESS_ENTER | therest['style']
        else:
            therest['style'] = wx.TE_PROCESS_ENTER

        wx.TextCtrl.__init__(self, parent, **therest)

        self.text = ""
        self.choices = []
        self.screenheight = wx.SystemSettings.GetMetric(wx.SYS_SCREEN_Y)

        self.dropdown = wx.PopupWindow(self)
        self.dropdown.SetBackgroundColour(DEFAULT_BACKGROUND)
        sizer = wx.BoxSizer()

        self.dropdownlistbox = AutoWidthListCtrl(self.dropdown, style=wx.LC_REPORT | wx.BORDER_NONE | wx.LC_SINGLE_SEL | wx.LC_NO_HEADER)
        self.dropdownlistbox.Bind(wx.EVT_LEFT_DOWN, self.ListClick)
        self.dropdownlistbox.Bind(wx.EVT_LEFT_DCLICK, self.ListClick)
        sizer.Add(self.dropdownlistbox, 1, wx.EXPAND | wx.ALL, 3)
        self.dropdown.SetSizer(sizer)

        self.entrycallback = entrycallback
        self.selectcallback = selectcallback

        self.Bind(wx.EVT_KILL_FOCUS, self.ControlChanged, self)
        self.Bind(wx.EVT_TEXT, self.EnteredText, self)
        self.Bind(wx.EVT_KEY_DOWN, self.KeyDown, self)

        self.dropdown.Bind(wx.EVT_LISTBOX, self.ListItemSelected, self.dropdownlistbox)

    def ListClick(self, evt):
        toSel, _ = self.dropdownlistbox.HitTest(evt.GetPosition())
        if toSel == -1:
            return

        self.dropdownlistbox.Select(toSel)
        self.SetValueFromSelected()

    def SetChoices (self, choices=[""]):
        ''' Sets the choices available in the popup wx.ListBox. '''
        self.choices = choices

        # delete, if need, all the previous data
        if self.dropdownlistbox.GetColumnCount() != 0:
            self.dropdownlistbox.DeleteAllColumns()
            self.dropdownlistbox.DeleteAllItems()

        self.dropdownlistbox.InsertColumn(0, "Select")

        for num, it in enumerate(choices):
            self.dropdownlistbox.InsertStringItem(num, it)

        self.dropdownlistbox.SetColumnWidth(0, wx.LIST_AUTOSIZE)  # autosize only works after adding rows

        itemcount = min(len(choices), 7) + 2
        charheight = self.dropdownlistbox.GetCharHeight()

        self.popupsize = wx.Size(self.GetClientSize()[0], (charheight * itemcount) + 6)
        self.dropdown.SetClientSize(self.popupsize)
        self.dropdown.Layout()

    def ControlChanged(self, event):
        self.ShowDropDown(False)
        event.Skip()

    def EnteredText(self, event):
        text = event.GetString()
        if text != self.text:
            self.text = text

            if self.entrycallback:
                def wx_callback(delayedResult, text):
                    choices = delayedResult.get()
                    if text == self.text:
                        self.SetChoices(choices)
                        if len(self.choices) == 0:
                            self.ShowDropDown(False)
                        else:
                            self.ShowDropDown(True)

                def db_callback(text):
                    if text == self.text:
                        return self.entrycallback(text)
                startWorker(wx_callback, db_callback, cargs=(text,), wargs=(text,))

    def KeyDown(self, event):
        skip = True

        sel = self.dropdownlistbox.GetFirstSelected()
        visible = self.dropdown.IsShown()
        if event.GetKeyCode() == wx.WXK_DOWN:
            if sel < (self.dropdownlistbox.GetItemCount() - 1):
                self.dropdownlistbox.Select(sel + 1)
                self.ListItemVisible()

            self.ShowDropDown()
            skip = False

        if event.GetKeyCode() == wx.WXK_UP:
            if sel > 0:
                self.dropdownlistbox.Select(sel - 1)
                self.ListItemVisible()
            self.ShowDropDown()
            skip = False

        if visible:
            if event.GetKeyCode() == wx.WXK_RETURN or event.GetKeyCode() == wx.WXK_SPACE:
                if sel > -1:  # we select the current item if enter or space is pressed
                    skip = event.GetKeyCode() == wx.WXK_RETURN
                    self.SetValueFromSelected(addSpace=(event.GetKeyCode() == wx.WXK_SPACE))
                    self.ShowDropDown(False)

            if event.GetKeyCode() == wx.WXK_ESCAPE:
                self.ShowDropDown(False)
                skip = False

        if skip:
            event.Skip()

    def SetValueFromSelected(self, addSpace=False):
        '''
            Sets the wx.TextCtrl value from the selected wx.ListBox item.
            Will do nothing if no item is selected in the wx.ListBox.
        '''
        sel = self.dropdownlistbox.GetFirstSelected()
        if sel > -1:
            newval = self.dropdownlistbox.GetItemText(sel)
            if addSpace:
                newval += " "

            if newval != self.GetValue():
                self.text = newval

                self.SetValue(newval)
                self.SetInsertionPointEnd()

                self.selectcallback()

    def ShowDropDown(self, show=True):
        ''' Either display the drop down list (show = True) or hide it (show = False). '''
        if show:
            show = len(self.choices) > 0

        if show:
            focusWin = wx.Window.FindFocus()
            show = focusWin == self

        if show and not self.dropdown.IsShown():
            size = self.dropdown.GetSize()
            width, height = self.GetSizeTuple()
            x, y = self.ClientToScreenXY(0, height)
            if size.GetWidth() != width:
                size.SetWidth(width)
                self.dropdown.SetSize(size)

            if (y + size.GetHeight()) < self.screenheight:
                self.dropdown.SetPosition(wx.Point(x, y))
            else:
                self.dropdown.SetPosition(wx.Point(x, y - height - size.GetHeight()))
        self.dropdown.Show(show)

    def ListItemVisible(self):
        ''' Moves the selected item to the top of the list ensuring it is always visible. '''
        self.dropdownlistbox.EnsureVisible(self.dropdownlistbox.GetFirstSelected())

    def ListItemSelected(self, event):
        self.SetValueFromSelected()


class SwarmHealth(wx.Panel):

    def __init__(self, parent, bordersize=0, size=wx.DefaultSize, align=wx.ALIGN_LEFT):
        wx.Panel.__init__(self, parent, size=size, style=wx.NO_BORDER)
        self.bordersize = bordersize
        self.align = align

        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetRatio(self, seeders, leechers):
        ratio = 0
        pop = 0

        self.blue = 0
        if leechers <= 0 and seeders <= 0:
            self.barwidth = 0

            self.green = 0
            self.red = 0
        else:
            if leechers == 0:
                ratio = sys.maxsize
            elif seeders == 0:
                ratio = 0
            else:
                ratio = seeders / (leechers * 1.0)

            pop = seeders + leechers
            if ratio == 0 and pop == 0:
                self.barwidth = 1
                self.green = 0
                self.red = 0
            else:
                if pop > 0:
                    self.barwidth = min(max(math.log(pop * 4, 10) * 2, 1.1) / 10.0, 1)  # let it max at 25k population
                else:
                    self.barwidth = 1

                self.green = max(0, min(255, 125 + (ratio * 130)))
                self.red = max(0, min(255, 125 + ((1 - ratio) * 130)))
        self.Refresh()

        if seeders < 0:
            seeders_str = 'Unknown number of seeders'
        elif seeders == 1:
            seeders_str = '1 seeder'
        else:
            seeders_str = '%d seeders' % seeders

        if leechers < 0:
            leechers_str = 'unknown number of leechers'
        elif leechers == 1:
            leechers_str = '1 leecher'
        else:
            leechers_str = '%d leechers' % leechers

        tooltip = '%s ; %s' % (seeders_str, leechers_str)
        self.SetToolTipString(tooltip)

    def OnPaint(self, event):
        dc = wx.BufferedPaintDC(self)

        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()

        width, height = self.GetClientSize()
        width -= self.bordersize * 2
        width -= 1
        width -= width % 10
        width += 1

        if self.align == wx.ALIGN_CENTER:
            xpos = (self.GetClientSize()[0] - width) / 2
        elif self.align == wx.ALIGN_RIGHT:
            xpos = self.GetClientSize()[0] - width
        else:
            xpos = 0

        dc.SetPen(wx.Pen(self.GetParent().GetForegroundColour()))
        dc.SetBrush(wx.WHITE_BRUSH)
        dc.DrawRectangle(xpos, 0, width, height)

        dc.SetPen(wx.TRANSPARENT_PEN)

        dc.SetBrush(wx.Brush((self.red, self.green, self.blue), wx.SOLID))

        if self.barwidth > 0:
            dc.DrawRectangle(xpos + 1, 1, self.barwidth * (width - 2), height - 2)

        if self.green > 0 or self.red > 0:
            dc.SetPen(wx.WHITE_PEN)
            for i in range(1, 10):
                x = xpos + (width / 10) * i
                dc.DrawLine(x, 1, x, height - 1)

        dc.SetPen(wx.BLACK_PEN)
        dc.SetBrush(wx.TRANSPARENT_BRUSH)
        dc.DrawRectangle(xpos, 0, width, height)

    def OnEraseBackground(self, event):
        pass


class ProgressBar(wx.Panel):

    def __init__(self, parent, colours=["#ffffff", "#92cddf", "#006dc0"], size=wx.DefaultSize):
        wx.Panel.__init__(self, parent, size=size, style=wx.NO_BORDER)
        self.pens = [wx.Pen(c) for c in colours]
        self.brushes = [wx.Brush(c) for c in colours]

        for i in xrange(len(self.pens)):
            if self.pens[i].GetColour() == wx.WHITE:
                self.pens[i] = None
        self.reset()

        self.SetMaxSize((-1, 6))
        self.SetMinSize((1, 6))
        self.SetBackgroundColour(wx.WHITE)

        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

        self.completed = False
        self.prev_blocks = None

    def OnEraseBackground(self, event):
        pass  # Or None

    def OnPaint(self, evt):
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()

        x, y, maxw, maxh = self.GetClientRect()

        if len(self.blocks) > 0 and not self.completed:
            numrect = float(len(self.blocks))
            w = max(1, maxw / numrect)

            lines = [(x + i, y, x + i, maxh) for i in xrange(maxw) if self.blocks[int(i / w)]]
            pens = [self.pens[self.blocks[int(i / w)]] for i in xrange(maxw) if self.blocks[int(i / w)]]
            dc.DrawLineList(lines, pens)

        if self.completed:
            dc.SetBrush(self.brushes[2])
        else:
            dc.SetBrush(wx.TRANSPARENT_BRUSH)

        dc.SetPen(wx.BLACK_PEN)
        dc.DrawRoundedRectangle(x, y, maxw, maxh, 2)

    def set_pieces(self, blocks):
        if self.prev_blocks == blocks:
            return
        else:
            self.prev_blocks = blocks

        maxBlocks = max(self.GetClientRect().width, 100)
        haveBlocks = len(blocks)

        if haveBlocks > maxBlocks:  # we need to group the blocks
            sblocks = [0] * maxBlocks
            nrBlocksPerPixel = haveBlocks / maxBlocks
            for i in xrange(maxBlocks):
                any = False
                all = True

                for j in xrange(nrBlocksPerPixel * i, nrBlocksPerPixel * (i + 1)):
                    if blocks[j]:
                        any = True
                    else:
                        all = False
                        if any:
                            break
                if all:
                    sblocks[i] = 2
                elif any:
                    sblocks[i] = 1
        else:
            sblocks = []
            for i in xrange(haveBlocks):
                remainingPixels = maxBlocks - len(sblocks)
                remainingBlocks = haveBlocks - i
                nrPixelsToColour = int(remainingPixels / remainingBlocks)

                if blocks[i]:
                    state = 2
                else:
                    state = 0

                sblocks.extend([state] * nrPixelsToColour)
        self.set_blocks(sblocks)

    def set_blocks(self, blocks):
        self.completed = all([x == 2 for x in blocks])
        self.blocks = blocks

    def setNormalPercentage(self, perc):
        self.prev_blocks = None
        maxBlocks = max(self.GetClientRect().width, 100)

        sblocks = [2] * int(perc * maxBlocks)
        sblocks += [0] * (maxBlocks - len(sblocks))
        self.set_blocks(sblocks)

    def reset(self, colour=0):
        self.prev_blocks = None
        sblocks = [colour] * 100
        self.set_blocks(sblocks)


def _set_font(control, size_increment=0, fontweight=wx.FONTWEIGHT_NORMAL, fontcolour=None):
    font = control.GetFont()
    font.SetPointSize(font.GetPointSize() + size_increment)
    font.SetWeight(fontweight)
    control.SetFont(font)
    if fontcolour:
        control.SetForegroundColour(fontcolour)


class ActionButton(wx.Panel):

    def __init__(self, parent, id= -1, bitmap=wx.NullBitmap, hover=True, **kwargs):
        wx.Panel.__init__(self, parent, id, size=bitmap.GetSize(), **kwargs)
        self.SetBackgroundColour(parent.GetBackgroundColour())
        self.hover = hover
        self.enabled = True
        self.handler = None
        self.SetBitmapLabel(bitmap, recreate=True)
        self.Bind(wx.EVT_MOUSE_EVENTS, self.OnMouseAction)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_CHILD_FOCUS, self.OnFocus)

    def GetBitmapLabel(self):
        return self.bitmaps[0]

    def SetBitmapLabel(self, bitmap, recreate=False):
        if bitmap:
            if recreate:
                image = bitmap.ConvertToImage()
                self.bitmaps = [bitmap]
                self.bitmaps.append(wx.BitmapFromImage(image.AdjustChannels(1.0, 1.0, 1.0, 0.6)) if self.hover else bitmap)
                self.bitmaps.append(wx.BitmapFromImage(image.ConvertToGreyscale().AdjustChannels(1.0, 1.0, 1.0, 0.3)))
            else:
                self.bitmaps[0] = bitmap
            self.Refresh()

    def GetBitmapHover(self):
        return self.bitmaps[1]

    def SetBitmapHover(self, bitmap):
        if bitmap:
            self.bitmaps[1] = bitmap

    def GetBitmapDisabled(self):
        return self.bitmaps[2]

    def SetBitmapDisabled(self, bitmap):
        if bitmap:
            self.bitmaps[2] = bitmap

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        # Draw the background
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()
        if hasattr(self.GetParent(), 'bitmap'):
            if not self.GetParent().bitmap:
                wx.CallLater(100, self.Refresh)
            else:
                rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
                sub = self.GetParent().bitmap.GetSubBitmap(rect)
                dc.DrawBitmap(sub, 0, 0)
        # Draw the button using a gc (dc doesn't do transparency very well)
        bitmap = self.GetBitmap()
        gc = wx.GraphicsContext.Create(dc)
        gc.DrawBitmap(bitmap, 0, 0, *bitmap.GetSize())

    def OnMouseAction(self, event):
        if event.Entering() or event.Leaving():
            self.Refresh()
        event.Skip()

    def OnFocus(self, event):
        self.Refresh()

    def GetBitmap(self):
        if not self.IsEnabled():
            return self.bitmaps[2]
        if self.GetScreenRect().Contains(wx.GetMousePosition()):
            return self.bitmaps[1]
        return self.bitmaps[0]

    def Bind(self, event, handler):
        if event == wx.EVT_LEFT_UP:
            self.handler = handler
        wx.Panel.Bind(self, event, handler)

    def Enable(self, enable):
        if enable and self.handler:
            self.Bind(wx.EVT_LEFT_UP, self.handler)
        elif not enable:
            self.Unbind(wx.EVT_LEFT_UP)
        self.enabled = enable
        self.Refresh()

    def IsEnabled(self):
        return self.enabled


class ProgressButton(ActionButton):

    def __init__(self, parent, id= -1, label='Search', **kwargs):
        ActionButton.__init__(self, parent, id=id, bitmap=wx.EmptyBitmap(1, 1), **kwargs)
        self.icon = None
        self.icon_hl = None
        self.icon_gs = None
        self.label = label
        self.maxval = 25
        self.curval = 25
        self.ResetSize()

    def GetRange(self):
        return self.maxval

    def SetRange(self, maximum):
        self.maxval = maximum
        self.Refresh()

    def GetValue(self):
        return self.curval

    def SetValue(self, current):
        self.curval = current
        self.Refresh()

    def SetIcon(self, icon):
        if isinstance(icon, wx.Bitmap):
            self.icon = icon
            self.icon_hl = icon.ConvertToImage().AdjustChannels(1.0, 1.0, 1.0, 0.6).ConvertToBitmap()
            self.icon_gs = icon.ConvertToImage().ConvertToGreyscale().ConvertToBitmap()
            self.ResetSize()

    def ResetSize(self):
        w, h = self.GetTextExtent(self.label)
        w += 30
        h += 10
        if self.icon:
            w = w + self.icon.GetSize()[0] + 5
            h = max(h, self.icon.GetSize()[1])
        self.SetMinSize((w, h))

    def OnPaint(self, event):
        dc = wx.BufferedPaintDC(self)
        gc = wx.GraphicsContext.Create(dc)
        # Draw the background using the bitmap from the parent (if it exists)
        if not getattr(self.GetParent(), 'bitmap', None):
            # Draw the background using the backgroundcolour from the parent
            dc.SetBackground(wx.Brush(self.GetParent().GetBackgroundColour()))
            dc.Clear()
        else:
            # Draw the background using the bitmap from the parent (TopSearchPanel)
            rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
            try:
                sub = self.GetParent().bitmap.GetSubBitmap(rect)
                dc.DrawBitmap(sub, 0, 0)
            except:
                pass
        x, y, width, height = self.GetClientRect()
        # If there is currently something in progress, first paint a black&white background
        if self.curval != self.maxval:
            col1 = wx.Colour(199, 199, 199)
            col2 = wx.Colour(162, 162, 162)
            br = gc.CreateLinearGradientBrush(x, y, x, y + height, col1, col2)
            gc.SetBrush(br)
            gc.SetPen(wx.TRANSPARENT_PEN)
            path = gc.CreatePath()
            path.AddRoundedRectangle(x, y, width - 1, height - 1, 5)
            path.CloseSubpath()
            gc.DrawPath(path)
        # Depending on the state of the button, paint the progress made thus far
        highlight = self.GetScreenRect().Contains(wx.GetMousePosition())
        if not self.IsEnabled():
            col1 = wx.Colour(199, 199, 199)
            col2 = wx.Colour(162, 162, 162)
        elif highlight:
            col1 = wx.Colour(255, 169, 148)
            col2 = wx.Colour(255, 150, 127)
        else:
            col1 = GRADIENT_LRED
            col2 = GRADIENT_DRED
        br = gc.CreateLinearGradientBrush(x, y, x, y + height, col1, col2)
        gc.SetBrush(br)
        gc.SetPen(wx.TRANSPARENT_PEN)
        path = gc.CreatePath()
        if self.curval > 1:
            progress = max(self.curval * 1.0 / self.maxval, 0.15)
            path.AddRoundedRectangle(x, y, progress * width - 1, height - 1, 5)
            path.CloseSubpath()
            gc.DrawPath(path)
        # Draw the button label and icon (if any)
        font = self.GetFont()
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        dc.SetFont(font)
        dc.SetTextForeground(wx.WHITE)
        textWidth, textHeight = dc.GetFullTextExtent(self.label)[:2]
        if self.icon:
            x_icon = (width - textWidth - self.icon.GetSize()[0] - 5) / 2
            y_icon = (height - self.icon.GetSize()[1]) / 2
            if highlight:
                dc.DrawBitmap(self.icon_hl, x_icon, y_icon)
            elif not self.IsEnabled():
                dc.DrawBitmap(self.icon_gs, x_icon, y_icon)
            else:
                dc.DrawBitmap(self.icon, x_icon, y_icon)
            x = x_icon + 5 + self.icon.GetSize()[0]
            y = (height - textHeight) / 2
            dc.DrawText(self.label, x, y)
        else:
            x = (width - textWidth) / 2
            y = (height - textHeight) / 2
            dc.DrawText(self.label, x, y)


class FancyPanel(wx.Panel):

    def __init__(self, *args, **kwargs):
        self.radius = kwargs.pop('radius', 0)
        self.border = kwargs.pop('border', 0)
        wx.Panel.__init__(self, *args, **kwargs)
        self.focus = None
        self.colour1 = self.colour2 = None
        self.border_colour = self.border_highlight = None
        self.bitmap = None
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetBorderColour(self, colour, highlight=None):
        self.border_colour = colour
        if highlight:
            self.border_highlight = highlight
            self.focus = False
            self.Bind(wx.EVT_SET_FOCUS, self.OnSetFocus)
            self.Bind(wx.EVT_CHILD_FOCUS, self.OnSetFocus)
            self.Bind(wx.EVT_KILL_FOCUS, self.OnKillFocus)
            self.Bind(wx.EVT_MOUSE_EVENTS, self.OnMouseAction)
        self.Refresh()

    def SetBackgroundColour(self, colour1, colour2=None):
        self.colour1 = colour1
        self.colour2 = colour2 if colour2 else colour1
        wx.Panel.SetBackgroundColour(self, self.colour1)
        self.Refresh()

    def OnSetFocus(self, event):
        self.focus = True
        self.Refresh()

    def OnKillFocus(self, event):
        self.focus = False
        self.Refresh()

    def OnMouseAction(self, event):
        if event.Entering() or event.Leaving():
            self.Refresh()
        event.Skip()

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        x, y, width, height = self.GetClientRect()

        # Use buffered drawing and save the buffer to a bitmap
        buffer = wx.EmptyBitmap(width, height)
        dc = wx.BufferedPaintDC(self, buffer)

        # For rounded panels, paint the background for the corners first
        if self.radius > 0:
            if getattr(self.GetParent(), 'bitmap', None):
                rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
                sub = self.GetParent().bitmap.GetSubBitmap(rect)
                dc.DrawBitmap(sub, 0, 0)
            else:
                dc.SetBackground(wx.Brush(self.GetParent().GetBackgroundColour()))
                dc.Clear()

        # Next, draw gradient/bitmap/regular background
        gc = wx.GraphicsContext.Create(dc)
        gc.SetPen(wx.TRANSPARENT_PEN)
        if self.colour1 != self.colour2:
            gc.SetBrush(gc.CreateLinearGradientBrush(x, y, x, y + height, self.colour1, self.colour2))
            gc.DrawRoundedRectangle(x, y, width, height, self.radius)
        else:
            gc.SetBrush(wx.Brush(self.colour1 if self.colour1 else self.GetBackgroundColour()))
            gc.DrawRoundedRectangle(x, y, width, height, self.radius)

        # Set border colour
        gc.SetPen(wx.Pen(self.border_colour, 1, wx.SOLID) if self.border_colour else wx.TRANSPARENT_PEN)
        if self.focus != None:
            if self.focus:
                gc.SetPen(wx.Pen(self.border_highlight, 1, wx.SOLID))
            elif self.GetScreenRect().Contains(wx.GetMousePosition()):
                gc.SetPen(wx.Pen(AdjustColour(self.border_colour, -10), 1, wx.SOLID))

        # Draw border
        if self.radius > 0:
            if self.border > 0:
                gc.DrawRoundedRectangle(x, y, width - 1, height - 1, self.radius)
        else:
            if bool(self.border & wx.RIGHT):
                gc.DrawLines([(x + width - 1, y), (x + width - 1, y + height - 1)])
            if bool(self.border & wx.LEFT):
                gc.DrawLines([(x, y), (x, y + height - 1)])
            if bool(self.border & wx.TOP):
                gc.DrawLines([(x, y), (x + width - 1, y)])
            if bool(self.border & wx.BOTTOM):
                gc.DrawLines([(x, y + height - 1), (x + width - 1, y + height - 1)])

        self.bitmap = buffer


class MinMaxSlider(wx.Panel):

    def __init__(self, *args, **kwargs):
        self.slider_size = kwargs.pop('slider_size', (100, 25))
        wx.Panel.__init__(self, *args, **kwargs)
        self.SetBackgroundColour(self.GetParent().GetBackgroundColour())
        self.SetForegroundColour(self.GetParent().GetForegroundColour())
        self.base = 1.7
        self.LoadIcons()
        self.SetMinMax(0, 0)
        self.text_spacers = [self.GetTextExtent('T' * 11)[0]] * 2
        self.SetSize((sum(self.text_spacers) + self.slider_size[0], -1))
        self.Reset()
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)
        self.Bind(wx.EVT_LEFT_DOWN, self.OnLeftDown)
        self.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)

    def SetMinMax(self, min, max):
        if max < min:
            return
        self.min = min
        self.max = max
        self.Refresh()

    def GetMinMax(self):
        return (self.min, self.max)

    def SetCurrentValues(self, min_val, max_val):
        if self.max - self.min == 0 or min_val == 0:
            w, h = self.arrow_up.GetSize()
            self.arrow_up_rect = [self.range[0], self.GetClientRect()[3] / 2 + 1, w, h]
        else:
            length = self.range[1] - self.range[0]
            min_val = (min_val - self.min) / float(self.max - self.min)
            min_val = min_val * math.pow(length, self.base)
            self.arrow_up_rect[0] = math.exp((math.log(min_val) / self.base)) + self.range[0]

        if self.max - self.min == 0 or max_val == 0:
            w, h = self.arrow_down.GetSize()
            self.arrow_down_rect = [self.range[1], self.GetClientRect()[3] / 2 - h - 1, w, h]
        else:
            length = self.range[1] - self.range[0]
            max_val = (max_val - self.min) / float(self.max - self.min)
            max_val = max_val * math.pow(length, self.base)
            self.arrow_down_rect[0] = math.exp((math.log(max_val) / self.base)) + self.range[0]

        self.Refresh()

    def GetCurrentValues(self):
        length = self.range[1] - self.range[0]
        min_val = math.pow(self.arrow_up_rect[0] - self.range[0], self.base) / math.pow(length, self.base)
        max_val = math.pow(self.arrow_down_rect[0] - self.range[0], self.base) / math.pow(length, self.base)
        min_val = self.min + min_val * (self.max - self.min)
        max_val = self.min + max_val * (self.max - self.min)
        return (min_val, max_val)

    def OnLeftDown(self, event):
        x, y, w, h = self.arrow_down_rect
        if wx.Rect(x, y - 4, w, h + 4).Contains(event.GetPositionTuple()):
            self.arrow_down_drag = True
        x, y, w, h = self.arrow_up_rect
        if wx.Rect(x, y, w, h + 4).Contains(event.GetPositionTuple()):
            self.arrow_up_drag = True
        self.CaptureMouse()
        self.Bind(wx.EVT_MOTION, self.OnMotion)

    def OnLeftUp(self, event):
        self.arrow_down_drag = False
        self.arrow_up_drag = False
        self.ReleaseMouse()
        self.Unbind(wx.EVT_MOTION)
        # Call parent
        min_val, max_val = self.GetCurrentValues()
        self.GetParent().GetParent().OnSlider(min_val, max_val)

    def OnMotion(self, event):
        if event.LeftIsDown():
            self.SetIcon(event)

    def SetIcon(self, event):
        mx = event.GetPositionTuple()[0] - 3
        if self.arrow_up_drag and mx < self.arrow_down_rect[0]:
            self.arrow_up_rect[0] = max(mx, self.range[0])
        elif self.arrow_down_drag and mx > self.arrow_up_rect[0]:
            self.arrow_down_rect[0] = min(mx, self.range[1])
        self.Refresh()

    def LoadIcons(self):
        self.arrow_down = GuiImageManager.getInstance().getBitmap(self, u"slider", self.GetBackgroundColour(), state=0)
        img = self.arrow_down.ConvertToImage()
        self.arrow_up = img.Rotate90().Rotate90().ConvertToBitmap()

    def Reset(self):
        w, h = self.arrow_down.GetSize()
        self.range = [self.text_spacers[0], self.GetSize()[0] - w - self.text_spacers[1]]
        self.arrow_down_rect = [self.range[1], self.GetClientRect()[3] / 2 - h - 1, w, h]
        self.arrow_down_drag = False
        self.arrow_up_rect = [self.range[0], self.GetClientRect()[3] / 2 + 1, w, h]
        self.arrow_up_drag = False

        self.SetMinMax(0, 0)

    def SetFormatter(self, formatter):
        self.formatter = formatter

    def Format(self, i):
        return self.formatter(i)

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        dc = wx.BufferedPaintDC(self)
        bg_colour = self.GetBackgroundColour()
        fg_colour = self.GetForegroundColour()
        dc.SetBackground(wx.Brush(bg_colour))
        dc.SetTextForeground(fg_colour)
        dc.Clear()

        _, _, width, height = self.GetClientRect()
        min_val, max_val = self.GetCurrentValues()
        min_val = self.Format(min_val)
        max_val = self.Format(max_val)
        dc.SetFont(self.GetFont())
        text_width, text_height = dc.GetTextExtent(min_val)
        dc.DrawText(min_val, (self.text_spacers[0] - text_width) / 2, (height - text_height + 1) / 2)
        text_width, text_height = dc.GetTextExtent(max_val)
        dc.DrawText(max_val, width - text_width - (self.text_spacers[0] - text_width) / 2, (height - text_height + 1) / 2)

        dc.SetPen(wx.Pen(fg_colour, 2, wx.SOLID))
        dc.DrawLine(self.range[0], height / 2, self.range[1] + self.arrow_down.GetSize()[0], height / 2)

        gc = wx.GraphicsContext.Create(dc)
        gc.DrawBitmap(self.arrow_down, *self.arrow_down_rect)
        gc.DrawBitmap(self.arrow_up, *self.arrow_up_rect)


class SimpleNotebook(wx.Panel):

    def __init__(self, *args, **kwargs):
        self.show_single_tab = kwargs.pop('show_single_tab', True)
        wx.Panel.__init__(self, *args, **kwargs)
        self.SetBackgroundColour(FILTER_GREY)
        self.labels = []
        self.panels = []
        self.pshown = 0
        self.lspace = 10
        self.messagePanel = None
        self.message_on_pages = []
        self.hSizer_labels = wx.BoxSizer(wx.HORIZONTAL)
        self.hSizer_panels = wx.BoxSizer(wx.HORIZONTAL)
        self.tab_colours = {}
        self.tab_panel = wx.Panel(self, -1)
        self.tab_panel.SetSizer(self.hSizer_labels)
        self.tab_panel.SetBackgroundColour(self.GetBackgroundColour())
        self.tab_panel.SetMinSize((-1, 25))
        vSizer = wx.BoxSizer(wx.VERTICAL)
        vSizer.Add(self.tab_panel, 0, wx.EXPAND)
        vSizer.Add(self.hSizer_panels, 1, wx.EXPAND)
        self.SetSizer(vSizer)
        self.tab_panel.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def OnLeftUp(self, event):
        obj = event.GetEventObject()
        if obj in self.labels:
            self.SetSelection(self.labels.index(obj))
            self.tab_panel.Refresh()

    def GetPage(self, num_page):
        if num_page >= 0 and num_page < self.GetPageCount():
            return self.panels[num_page]
        return None

    def AddPage(self, page, text, tab_colour=None):
        self.InsertPage(self.GetPageCount(), page, text, tab_colour)

    def InsertPage(self, index, page, text, tab_colour=None):
        if not (index >= 0 and index <= self.GetPageCount()):
            return

        if tab_colour:
            self.tab_colours[index] = tab_colour

        label = LinkStaticText(self.tab_panel, text, None, font_colour=self.tab_panel.GetForegroundColour())
        label.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)
        self.hSizer_labels.Insert(index, label, 0, wx.RIGHT | wx.LEFT | wx.CENTER, self.lspace)
        self.hSizer_labels.Layout()
        page.Show(index == 0)
        self.hSizer_panels.Insert(index, page, 100, wx.EXPAND)
        self.labels.insert(index, label)
        self.panels.insert(index, page)

        if not self.show_single_tab:
            show_tab_panel = self.GetPageCount() > 1
            self.tab_panel.SetMinSize((-1, 25 if show_tab_panel else 1))
            self.hSizer_labels.ShowItems(show_tab_panel)
        self.Layout()

        if index <= self.pshown:
            if self.GetPageCount() > 1:
                self.pshown += 1
            wx.CallAfter(self.ResetTabs)

    def ResetTabs(self):
        for index, label in enumerate(self.labels):
            selected_tab = self.GetSelection()
            is_current = index == selected_tab
            fg_colour = TRIBLER_RED if is_current else self.tab_panel.GetForegroundColour()
            bg_colour = self.tab_colours.get(selected_tab, self.panels[selected_tab].GetBackgroundColour()) if is_current else self.tab_panel.GetBackgroundColour()
            label.SetForegroundColour(fg_colour)
            label.SetBackgroundColour(bg_colour)
        self.tab_panel.Refresh()

    def RemovePage(self, index):
        label = self.labels.pop(index)
        label.Show(False)
        page = self.panels.pop(index)
        page.Show(False)
        self.hSizer_labels.Remove(index)
        self.hSizer_panels.Remove(index)

        if self.GetSelection() == index:
            self.SetSelection(index - 1 if index > 0 else 0)

        if not self.show_single_tab:
            show_tab_panel = self.GetPageCount() > 1
            self.tab_panel.SetMinSize((-1, 25 if show_tab_panel else 1))
            self.hSizer_labels.ShowItems(show_tab_panel)
        self.Layout()

    def ShowPage(self, index, show):
        is_selected = self.GetSelection() == index

        label = self.labels[index]
        label.Show(show)

        if not show and is_selected:
            self.SetSelection(index - 1 if index > 0 else 0)

        self.hSizer_labels.Layout()
        self.hSizer_panels.Layout()
        self.Layout()
        self.Refresh()

    def GetPageText(self, num_page):
        if num_page >= 0 and num_page < self.GetPageCount():
            return self.labels[num_page].GetLabel()
        return ''

    def SetPageText(self, num_page, text):
        if num_page >= 0 and num_page < self.GetPageCount():
            self.labels[num_page].SetLabel(text)
            self.Layout()

    def GetPageCount(self):
        return len(self.labels)

    def GetCurrentPage(self):
        return self.GetPage(self.GetSelection())

    def GetIndexFromText(self, text):
        result = None
        for i in range(self.GetPageCount()):
            if self.GetPageText(i) == text:
                result = i
                break
        return result

    def SetSelection(self, num_page):
        if not (num_page >= 0 and num_page < self.GetPageCount()) or self.pshown == num_page:
            return

        old_page = self.GetCurrentPage()
        if old_page:
            if self.GetSelection() in self.message_on_pages:
                self.messagePanel.Show(False)
            else:
                old_page.Show(False)
            old_label = self.labels[self.pshown]
            old_label.SetForegroundColour(self.tab_panel.GetForegroundColour())
            old_label.SetBackgroundColour(self.tab_panel.GetBackgroundColour())

        new_page = self.panels[num_page]
        if num_page in self.message_on_pages:
            self.messagePanel.Show(True)
        else:
            new_page.Show(True)
        new_label = self.labels[num_page]
        new_label.SetForegroundColour(TRIBLER_RED)
        new_label.SetBackgroundColour(self.tab_colours.get(num_page, new_page.GetBackgroundColour()))
        self.Layout()
        new_page.Layout()

        event = wx.NotebookEvent(wx.EVT_NOTEBOOK_PAGE_CHANGED.typeId, 0, num_page, self.GetSelection())
        event.SetEventObject(self)
        self.pshown = num_page
        wx.PostEvent(self.GetEventHandler(), event)

    def GetSelection(self):
        return self.pshown

    def ChangeSelection(self, num_page):
        self.SetSelection(num_page)

    def CalcSizeFromPage(self, *args):
        return GUIUtility.getInstance().frame.splitter_bottom_window.GetSize()

    def SetMessagePanel(self, panel):
        if self.messagePanel:
            self.messagePanel.Show(False)
            self.hSizer_panels.Detach(self.messagePanel)
        self.messagePanel = panel
        self.hSizer_panels.Add(self.messagePanel, 100, wx.EXPAND)
        self.messagePanel.Show(self.GetSelection() in self.message_on_pages)
        self.hSizer_labels.Layout()
        self.hSizer_panels.Layout()
        self.Layout()
        self.Refresh()

    def ShowMessageOnPage(self, index, show_message):
        is_selected = self.GetSelection() == index

        panel = self.panels[index]
        panel.Show(not show_message and is_selected)

        if show_message and is_selected:
            self.messagePanel.Show(True)
        elif not show_message and is_selected:
            self.messagePanel.Show(False)

        if show_message and index not in self.message_on_pages:
            self.message_on_pages.append(index)
        elif not show_message and index in self.message_on_pages:
            self.message_on_pages.remove(index)

        self.hSizer_labels.Layout()
        self.hSizer_panels.Layout()
        self.Layout()
        self.Refresh()

    def GetThemeBackgroundColour(self):
        return self.GetBackgroundColour()

    def OnEraseBackground(self, evt):
        dc = evt.GetDC()
        if not dc:
            dc = wx.ClientDC(self)
            rect = self.GetUpdateRegion().GetBox()
            dc.SetClippingRect(rect)

        width, height = self.tab_panel.GetClientSize()
        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()

        # Draw bottom separator
        dc.SetPen(wx.Pen(SEPARATOR_GREY))
        dc.DrawLine(0, height - 1, width, height - 1)

        # If we're not showing the full tab_panel, stop here
        if not self.show_single_tab and self.GetPageCount() < 2:
            return

        # Calculate separator positions
        separator_positions = []
        visible_labels = [label for label in self.labels if label.IsShown()]
        for i in range(0, len(visible_labels) - 1):
            l1, l2 = visible_labels[i:i + 2]
            x1, x2 = l1.GetPosition().x + l1.GetSize().x, l2.GetPosition().x
            x_avg = (x1 + x2) / 2
            separator_positions.append(x_avg)
        if visible_labels:
            l = self.labels[-1]
            separator_positions.append(l.GetPosition().x + l.GetSize().x + self.lspace)

        # Draw tab highlighting
        selected_tab = self.GetSelection()
        selected_sep = selected_tab - sum([1 for index, label in enumerate(self.labels) if not label.IsShown() and index < selected_tab])
        x1 = separator_positions[selected_sep]
        x2 = separator_positions[selected_sep - 1] if selected_sep > 0 else 0
        tab_colour = self.tab_colours.get(selected_tab, self.panels[selected_tab].GetBackgroundColour())
        dc.SetBrush(wx.Brush(tab_colour))
        dc.SetPen(wx.TRANSPARENT_PEN)
        dc.DrawRectangle(x2, 0, x1 - x2, self.GetSize().y)

        # Draw top separator
        dc.SetPen(wx.Pen(SEPARATOR_GREY))
        dc.DrawLine(0, 0, width, 0)

        # Draw separators between labels
        for i, x in enumerate(separator_positions):
            if i == selected_sep or i == selected_sep - 1:
                dc.DrawLine(x, 0, x, height)
            else:
                dc.DrawLine(x, self.lspace / 2, x, height - self.lspace / 2)


class TagText(wx.Panel):

    def __init__(self, parent, id= -1, label='', fill_colour=wx.Colour(240, 255, 204), edge_colour=wx.Colour(200, 200, 200), text_colour=wx.BLACK, **kwargs):
        wx.Panel.__init__(self, parent, id, **kwargs)
        self.fill_colour = fill_colour
        self.edge_colour = edge_colour
        self.text_colour = text_colour
        self.prnt_colour = parent.GetBackgroundColour()
        self.label = label
        w, h = self.GetTextExtent(self.label)
        w += 10
        self.SetMinSize((w, h))
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetValue(self, label):
        self.label = label
        w, h = self.GetTextExtent(self.label)
        w += 10
        self.SetMinSize((w, h))
        self.Refresh()

    def SetBackgroundColour(self, colour):
        self.prnt_colour = colour
        self.Refresh()

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        # Draw the background
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.prnt_colour))
        dc.Clear()
        if getattr(self.GetParent(), 'bitmap', None):
            rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
            sub = self.GetParent().bitmap.GetSubBitmap(rect)
            dc.DrawBitmap(sub, 0, 0)

        # Draw the rounded rectangle which will contain the text.
        gc = wx.GraphicsContext.Create(dc)
        x, y, width, height = self.GetClientRect()
        gc.SetBrush(wx.Brush(self.fill_colour))
        gc.SetPen(wx.Pen(self.edge_colour, 1, wx.SOLID))
        path = gc.CreatePath()
        path.AddRoundedRectangle(x, y, width - 1, height - 1, 5)
        path.CloseSubpath()
        gc.DrawPath(path)

        # Draw the text
        font = self.GetFont()
        dc.SetFont(font)
        dc.SetTextForeground(self.text_colour)
        dc.DrawText(self.label, 5, 0)


class TorrentStatus(wx.Panel):

    def __init__(self, parent, id= -1, status='Initializing', fill_colour=wx.Colour(132, 194, 255), back_colour=wx.Colour(235, 235, 235), **kwargs):
        wx.Panel.__init__(self, parent, id, **kwargs)
        self.status = status
        self.value = None
        self.fill_colour = fill_colour
        self.back_colour = back_colour
        self.prnt_colour = parent.GetBackgroundColour()
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetMinSize(self, size):
        w, h = size
        if w == -1:
            w = self.GetSize()[0]
        if h == -1:
            h = self.GetTextExtent(self.status)[1]
        wx.Panel.SetMinSize(self, (w, h))

    def SetValue(self, value):
        if isinstance(value, float) or isinstance(value, int):
            self.value = float(value)

    def SetStatus(self, status):
        if isinstance(status, str):
            self.status = status

        if status.endswith('Seeding'):
            self.fill_colour = SEEDING_COLOUR
        if status == 'Completed':
            self.fill_colour = COMPLETED_COLOUR
        if status == 'Waiting':
            self.fill_colour = self.back_colour
        if status == 'Checking':
            self.fill_colour = self.back_colour
        if status in ['Downloading', 'Streaming']:
            self.fill_colour = DOWNLOADING_COLOUR
        if status == 'Stopped':
            self.fill_colour = STOPPED_COLOUR
        if status == 'Fetching torrent':
            self.fill_colour = self.back_colour

        self.SetMinSize((-1, -1))

    def SetBackgroundColour(self, colour):
        self.prnt_colour = colour
        self.Refresh()

    def Update(self, torrent):
        progress = torrent.progress
        torrent_state = torrent.state
        finished = progress == 1.0
        is_vod = torrent.ds.get_download().get_mode() == DLMODE_VOD if torrent.ds else False

        if torrent.ds.status == 2 or 'checking' in torrent_state:
            status = 'Checking'
        elif 'metadata' in torrent_state:
            status = 'Fetching torrent'
        elif 'seeding' in torrent_state:
            status = 'Seeding'
            if torrent.ds and UserDownloadChoice.get_singleton().get_download_state(torrent.ds.get_download().get_def().get_id()) == 'restartseed':
                status = "[F] " + status
        elif finished:
            status = 'Completed'
        elif 'allocating' in torrent_state:
            status = 'Waiting'
        elif 'downloading' in torrent_state:
            status = 'Streaming' if is_vod else 'Downloading'
        elif 'error' in torrent_state:
            status = 'Stopped on error'
        elif 'stopped' in torrent_state:
            status = 'Stopped'
        else:
            status = 'Unknown'

        self.SetValue(progress)
        self.SetStatus(status)
        self.Refresh()
        if self.value != None:
            return int(self.value * self.GetSize().width)
        return 0

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        # Draw the background
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.prnt_colour))
        dc.Clear()
        if getattr(self.GetParent(), 'bitmap', None):
            rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
            sub = self.GetParent().bitmap.GetSubBitmap(rect)
            dc.DrawBitmap(sub, 0, 0)

        # Draw an empty progress bar and text
        gc = wx.GraphicsContext.Create(dc)
        x, y, width, height = self.GetClientRect()
        gc.SetBrush(wx.Brush(self.back_colour))
        gc.SetPen(wx.TRANSPARENT_PEN)
        path = gc.CreatePath()
        path.AddRoundedRectangle(x, y, width, height, 2)
        path.CloseSubpath()
        gc.DrawPath(path)
        self.TextToDC(dc, self.TextColour(self.back_colour))

        if self.value != None:
            # Draw a full progress bar and text
            rect = wx.EmptyBitmap(width, height)
            rect_dc = wx.MemoryDC(rect)
            rect_dc.SetBackground(wx.Brush(self.prnt_colour))
            rect_dc.Clear()

            rect_gc = wx.GraphicsContext.Create(rect_dc)
            rect_gc.SetBrush(wx.Brush(self.fill_colour))
            rect_gc.SetPen(wx.TRANSPARENT_PEN)
            path = rect_gc.CreatePath()
            path.AddRoundedRectangle(x, y, width, height, 2)
            path.CloseSubpath()
            rect_gc.DrawPath(path)
            self.TextToDC(rect_dc, self.TextColour(self.fill_colour))

            # Combine the two dc's
            dc.Blit(0, 0, int(self.value * width), height, rect_dc, 0, 0)
            rect_dc.SelectObject(wx.NullBitmap)

    def TextToDC(self, dc, colour):
        font = self.GetFont()
        dc.SetFont(font)
        dc.SetTextForeground(colour)
        if self.value == None or len(self.status) > 11:
            todraw = self.status
        else:
            todraw = "%s %.1f%%" % (self.status, self.value * 100)
        dc.DrawLabel(todraw, self.GetClientRect(), alignment=wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL)

    def TextColour(self, bg):
        rgb = bg.Get()
        brightness = (rgb[0] + rgb[1] + rgb[2]) / 3
        return wx.Colour(80, 80, 80) if brightness > 150 else wx.WHITE


class TransparentText(wx.StaticText):

    def __init__(self, parent, id=wx.ID_ANY, label='', pos=wx.DefaultPosition, size=wx.DefaultSize, style=wx.TRANSPARENT_WINDOW):
        wx.StaticText.__init__(self, parent, id, label, pos, size, style)
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, lambda event: None)
        self.Bind(wx.EVT_SIZE, self.OnSize)

    def SetLabel(self, value):
        size = self.GetTextExtent(value)
        self.SetSize(size)
        wx.StaticText.SetLabel(self, value)

    def OnPaint(self, event):
        dc = wx.PaintDC(self)
        dc.SetFont(self.GetFont())
        dc.SetTextForeground(self.GetForegroundColour())
        dc.DrawLabel(self.GetLabel(), self.GetClientRect())

    def OnSize(self, event):
        self.Refresh()
        event.Skip()


class TransparentStaticBitmap(wx.StaticBitmap):

    def __init__(self, *args, **kwargs):
        wx.StaticBitmap.__init__(self, *args, **kwargs)
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, lambda event: None)
        self.Bind(wx.EVT_SIZE, self.OnSize)

    def OnPaint(self, event):
        # Use double duffered drawing to prevent flickering
        dc = wx.BufferedPaintDC(self)
        if not getattr(self.GetParent(), 'bitmap', None):
            # Draw the background using the backgroundcolour
            dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
            dc.Clear()
        else:
            # Draw the background using the bitmap from the parent
            rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
            if rect.x > 0 and rect.y > 0:
                sub = self.GetParent().bitmap.GetSubBitmap(rect)
                dc.DrawBitmap(sub, 0, 0)
        # Draw the bitmap using a gc (dc doesn't do transparency very well)
        bitmap = self.GetBitmap()
        gc = wx.GraphicsContext.Create(dc)
        gc.DrawBitmap(bitmap, 0, 0, *bitmap.GetSize())

    def OnSize(self, event):
        self.Refresh()
        event.Skip()


class TextCtrl(wx.TextCtrl):

    def __init__(self, *args, **kwargs):
        wx.TextCtrl.__init__(self, *args, **kwargs)
        self.descr_label = ''
        self.descr_shown = False
        self.descr_colour = wx.Colour(80, 80, 80)
        self.Bind(wx.EVT_CHILD_FOCUS, self.OnGetFocus)
        self.Bind(wx.EVT_SET_FOCUS, self.OnGetFocus)
        self.Bind(wx.EVT_KILL_FOCUS, self.OnKillFocus)

    def SetDescriptiveText(self, descr_label):
        self.descr_label = descr_label
        self._SetDescriptiveText()

    def _SetDescriptiveText(self):
        if not self.GetValue():
            wx.TextCtrl.SetValue(self, self.descr_label)
            self.SetForegroundColour(self.descr_colour)
            self.descr_shown = True

    def GetValue(self):
        if self.descr_shown:
            return ''
        return wx.TextCtrl.GetValue(self)

    def SetValue(self, value):
        if value:
            self.descr_shown = False
            wx.TextCtrl.SetValue(self, value)

    def OnGetFocus(self, event):
        if self.descr_shown:
            wx.TextCtrl.SetValue(self, '')
        self.SetForegroundColour(self.GetParent().GetForegroundColour())
        self.descr_shown = False

    def OnKillFocus(self, event):
        self._SetDescriptiveText()


class StaticBitmaps(wx.Panel):

    def __init__(self, *args, **kwargs):
        wx.Panel.__init__(self, *args, **kwargs)
        self.bitmaps_index = 0
        self.SetPositions()
        self.Reset()
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_MOUSE_EVENTS, self.OnMouse)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetPositions(self):
        width, height = self.GetSize()
        self.buttons = [wx.Rect(width - 27, height - 15, 14, 15),
                        wx.Rect(width - 14, height - 15, 14, 15)]
        self.pointer = wx.Rect(width - 26, 1, 25, 14)

    def OnEraseBackground(self, event):
        pass

    def OnMouse(self, event):
        if event.Entering() or event.Leaving():
            self.show_buttons = event.Entering()
            self.Refresh()

        elif event.LeftUp():
            if self.buttons[0].Contains(event.GetPosition()):
                return self.OnLeftButton()
            elif self.buttons[1].Contains(event.GetPosition()):
                return self.OnRightButton()

        event.Skip()

    def OnLeftButton(self):
        if self.bitmaps_index >= 0:
            self.bitmaps_index = self.bitmaps_index - 1 if self.bitmaps_index > 0 else len(self.bitmaps) - 1
            self.bitmap = self.bitmaps[self.bitmaps_index]
            self.Refresh()

    def OnRightButton(self):
        if self.bitmaps_index >= 0:
            self.bitmaps_index = self.bitmaps_index + 1 if self.bitmaps_index < len(self.bitmaps) - 1 else 0
            self.bitmap = self.bitmaps[self.bitmaps_index]
            self.Refresh()

    def SetBitmaps(self, bitmaps):
        if isinstance(bitmaps, list) and bitmaps:
            if self.bitmaps_index >= len(bitmaps):
                self.bitmaps_index = 0
            self.bitmaps = bitmaps
            self.bitmap = bitmaps[self.bitmaps_index]
            self.SetSize(self.bitmap.GetSize())
            self.SetPositions()
        else:
            self.Reset()
        self.Refresh()

    def Reset(self):
        self.bitmap_index = -1
        self.bitmaps = []
        self.bitmap = None
        self.show_buttons = False

    def OnPaint(self, event):
        dc = wx.BufferedPaintDC(self)
        dc.Clear()

        if not self.bitmap:
            return

        dc.DrawBitmap(self.bitmap, 0, 0)

        if self.show_buttons:
            tmpbmp = wx.EmptyBitmapRGBA(*self.buttons[0].GetSize(), red=255, green=255, blue=255, alpha=155)
            dc.DrawBitmap(tmpbmp, self.buttons[0].x, self.buttons[0].y)
            dc.DrawBitmap(tmpbmp, self.buttons[1].x, self.buttons[1].y)

            dc.SetPen(wx.BLACK_PEN)
            dc.SetBrush(wx.TRANSPARENT_BRUSH)
            dc.DrawRoundedRectangleRect(self.buttons[0], 0)
            dc.DrawRoundedRectangleRect(self.buttons[1], 0)

            arrow = GuiImageManager.getInstance().getBitmap(self, u"arrow", wx.WHITE, state=0)
            arrow_left = arrow.ConvertToImage().Rotate90(True).ConvertToBitmap()
            arrow_right = arrow.ConvertToImage().Rotate90(False).ConvertToBitmap()
            dc.DrawBitmap(arrow_left, self.buttons[0].x + 5, self.buttons[0].y + 4)
            dc.DrawBitmap(arrow_right, self.buttons[1].x + 5, self.buttons[1].y + 4)

            tmpbmp = wx.EmptyBitmapRGBA(*self.pointer.GetSize(), red=255, green=255, blue=255, alpha=155)
            dc.DrawBitmap(tmpbmp, self.pointer.x, self.pointer.y)
            dc.SetFont(self.GetFont())
            dc.DrawLabel("%d/%d" % (self.bitmaps_index + 1, len(self.bitmaps)), self.pointer, alignment=wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL)


class Graph(wx.Panel):

    def __init__(self, parent, grid_size=4, max_points=120, *args, **kwargs):
        wx.Panel.__init__(self, parent, *args, **kwargs)
        self.x_margins = (30, 10)
        self.y_margins = (10, 20)
        self.max_range = 0
        self.grid_size = grid_size
        self.config = []
        self.data = []
        self.font = self.GetFont()
        self.font.SetPointSize(self.font.GetPointSize() - 1)
        self.SetAxisLabels("", "")
        self.SetMaxPoints(max_points)
        self.SetBackgroundColour(wx.WHITE)
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)
        self.Bind(wx.EVT_SIZE, self.OnSize)

    def SetAxisLabels(self, x_label, y_label):
        self.x_label = x_label
        self.y_label = y_label

    def SetMaxPoints(self, max_points):
        self.max_points = max_points

    def AddGraph(self, colour, data=[], label=""):
        self.data.append(data)
        self.data[-1] = self.data[-1][-self.max_points:]
        self.config.append((colour, label))
        self.max_range = max(self.max_range, max(self.data[-1]) if self.data[-1] else 0)
        self.Refresh()

    def SetData(self, graph_id, data):
        self.data[graph_id] = data
        self.data[graph_id] = self.data[graph_id][-self.max_points:]
        self.max_range = max([max(column) for column in self.data if column])
        self.Refresh()

    def AppendData(self, graph_id, value):
        self.data[graph_id].append(value)

        dropped_value = None
        if len(self.data[graph_id]) > self.max_points:
            dropped_value = self.data[graph_id][0]
            self.data[graph_id] = self.data[graph_id][-self.max_points:]

        if dropped_value != None and dropped_value == self.max_range:
            self.max_range = max([max(column) for column in self.data if column])
        else:
            self.max_range = max(self.max_range, value)
        self.Refresh()

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        _, _, width, height = self.GetClientRect()
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()
        self.DrawAxis(dc, width, height)
        self.DrawGrid(dc, width, height)
        self.DrawText(dc, width, height)

        gc = wx.GraphicsContext.Create(dc)
        gc.SetBrush(wx.TRANSPARENT_BRUSH)
        self.DrawGraphs(gc, width, height)
        self.DrawLegend(gc, width, height)

    def DrawAxis(self, dc, width, height):
        dc.SetPen(wx.Pen((175, 175, 175), 1, wx.SOLID))
        dc.DrawLine(self.x_margins[0], height - self.y_margins[1], self.x_margins[0], self.y_margins[0])
        dc.DrawLine(self.x_margins[0], height - self.y_margins[1], width - self.x_margins[1], height - self.y_margins[1])

    def DrawGrid(self, dc, width, height):
        dashed_pen = wx.Pen((175, 175, 175), 1, wx.USER_DASH)
        dashed_pen.SetDashes([4, 4])
        dc.SetPen(dashed_pen)
        grid_height = (height - self.y_margins[0] - self.y_margins[1]) / self.grid_size
        for i in range(1, self.grid_size + 1):
            dc.DrawLine(self.x_margins[0], height - self.y_margins[1] - i * grid_height, width - self.x_margins[1], height - self.y_margins[1] - i * grid_height)

    def DrawText(self, dc, width, height):
        dc.SetFont(self.font)
        dc.SetTextForeground(wx.Colour(130, 130, 130))

        # Draw labels along the x/y axis
        x_width, _ = self.GetTextExtent(self.x_label)
        _, y_height = self.GetTextExtent(self.y_label)
        dc.DrawText(self.x_label, (width - self.x_margins[0] - self.x_margins[1] - x_width) / 2 + self.x_margins[0], height - self.y_margins[1])
        dc.DrawRotatedText(self.y_label, self.x_margins[0] - y_height, (height - self.y_margins[0] - self.y_margins[1]) / 2 + self.y_margins[1], 90)

        # Draw min/max values along the y axis
        miny = "0"
        maxy = str(int(self.max_range + 1))
        miny_width, miny_height = self.GetTextExtent(miny)
        maxy_width, maxy_height = self.GetTextExtent(maxy)
        dc.DrawText(miny, max(0, self.x_margins[0] - miny_width), height - self.y_margins[1] - miny_height / 2)
        dc.DrawText(maxy, max(0, self.x_margins[0] - maxy_width), self.y_margins[0] - maxy_height / 2)

    def DrawGraphs(self, gc, width, height):
        for graph_id, column in enumerate(self.data):
            if column:
                colour, _ = self.config[graph_id]
                gc.SetPen(wx.Pen(colour, 1, wx.SOLID))
                num_points = len(column)
                x_coords = [self.x_margins[0] + (i / float(self.max_points)) * (width - self.x_margins[0] - self.x_margins[1]) for i in range(0, num_points)]
                if self.max_range != 0:
                    y_coords = [height - self.y_margins[1] - ((height - self.y_margins[0] - self.y_margins[1]) * column[i] / self.max_range) for i in range(0, num_points)]
                else:
                    y_coords = [height - self.y_margins[1] for i in range(0, num_points)]
                y_coords = [min(height - self.y_margins[1] - 1, y_coord) for y_coord in y_coords]
                gc.DrawLines(zip(x_coords, y_coords))

    def DrawLegend(self, gc, width, height):
        gc.SetFont(self.font)
        gc.SetPen(wx.Pen(wx.Colour(240, 240, 240, 200)))
        gc.SetBrush(wx.Brush(wx.Colour(245, 245, 245, 150)))

        rect_width = max([self.GetTextExtent(label)[0] for _, label in self.config]) + 30
        rect_height = sum([self.GetTextExtent(label)[1] for _, label in self.config]) + 10
        gc.DrawRectangle(self.x_margins[0] + 5, self.x_margins[1] + 5, rect_width, rect_height)

        next_y = self.y_margins[0] + 10
        for colour, label in self.config:
            label_width, label_height = self.GetTextExtent(label)
            gc.SetPen(wx.Pen(colour, 1, wx.SOLID))
            gc.DrawLines([(self.x_margins[0] + 10, next_y + label_height / 2), (self.x_margins[0] + 25, next_y + label_height / 2)])
            gc.SetPen(wx.BLACK_PEN)
            gc.DrawText(label, self.x_margins[0] + 30, next_y)
            next_y += label_height

    def OnSize(self, event):
        self.Refresh()
        event.Skip()


class VideoProgress(wx.Panel):

    def __init__(self, parent, id= -1, label='Loading\n 0%', value=0.0, fill_colour=wx.Colour(220, 220, 220), edge_colour=wx.Colour(210, 210, 210), text_colour=wx.Colour(210, 210, 210), **kwargs):
        wx.Panel.__init__(self, parent, id, **kwargs)
        self.fill_colour = fill_colour
        self.edge_colour = edge_colour
        self.text_colour = text_colour
        self.prnt_colour = parent.GetBackgroundColour()
        self.label = label
        self.value = 0.0
        self.error = ''
        self.SetValue(value)
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)

    def SetValue(self, value):
        self.value = value
        self.Refresh()

    def SetError(self, error):
        self.error = error

    def SetLabel(self, label):
        self.label = label
        self.Refresh()

    def SetBackgroundColour(self, colour):
        self.prnt_colour = colour
        self.Refresh()

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.prnt_colour))
        dc.Clear()

        gc = wx.GraphicsContext.Create(dc)
        width, height = self.GetClientSize()
        radius = min(width - 5, height - 5) / 2
        pi = math.pi

        path = gc.CreatePath()
        path.AddCircle(0, 0, radius)
        path.AddCircle(0, 0, radius / 1.5)
        gc.PushState()
        gc.Translate(width / 2, height / 2)
        gc.SetBrush(wx.Brush(wx.Colour(180, 180, 180)))
        gc.SetPen(wx.Pen(self.edge_colour, 1, wx.SOLID))
        gc.DrawPath(path)

        if not self.error:
            path = gc.CreatePath()
            path.AddArc(0, 0, radius, -pi / 2, -pi / 2 + self.value * 2 * pi, True)
            x = self.value * 2 * pi - (pi / 2)
            path.AddLineToPoint(math.cos(x) * radius / 1.5, math.sin(x) * radius / 1.5)
            path.AddArc(0, 0, radius / 1.5, -pi / 2 + self.value * 2 * pi, -pi / 2, False)
            path.CloseSubpath()
            gc.PopState()
            gc.PushState()
            gc.Translate(width / 2, height / 2)
            gc.SetBrush(gc.CreateRadialGradientBrush(0, 0, 0, 0, radius, wx.Colour(255, 255, 255), self.fill_colour))
            gc.SetPen(wx.Pen(self.edge_colour, 1, wx.SOLID))
            gc.DrawPath(path)

        font = self.GetFont()
        font.SetPixelSize((0, radius / 3.5))
        font.SetWeight(wx.FONTWEIGHT_BOLD)
        dc.SetFont(font)
        dc.SetTextForeground(self.text_colour)
        dc.DrawLabel(self.error or self.label, self.GetClientRect(), alignment=wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL)


class VideoSlider(wx.Panel):

    def __init__(self, *args, **kwargs):
        wx.Panel.__init__(self, *args, **kwargs)
        self.slider_range = [10, 0]
        self.slider_radius = 9
        self.slider_position = [10, 0]
        # Colours for enabled slider
        self.colour1 = wx.Colour(241, 93, 63)
        self.colour2 = wx.Colour(246, 144, 119)
        # Colours for disabled slider
        self.colour3 = wx.Colour(170, 170, 170)
        self.colour4 = wx.Colour(220, 220, 220)
        self.dragging = False
        self.enabled = True
        self.hovering = False
        self.value = 0.0
        self.pieces = []
        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)
        self.Bind(wx.EVT_LEFT_DOWN, self.OnLeftDown)
        self.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)
        self.Bind(wx.EVT_MOTION, self.OnMotion)

    def GetValue(self):
        return self.value

    def SetValue(self, value):
        self.value = value
        if not self.dragging:
            slider_width = self.slider_range[1] - self.slider_range[0]
            self.slider_position[0] = (slider_width * self.value) + self.slider_range[0] if slider_width else self.slider_range[0]
            self.slider_position[0] = min(self.slider_range[1], self.slider_position[0])
            self.slider_position[0] = max(self.slider_range[0], self.slider_position[0])
            self.Refresh()

    def SetPieces(self, pieces):
        self.pieces = pieces
        self.Refresh()

    def PositionOnSlider(self, position=None):
        x, y = position or self.ScreenToClient(wx.GetMousePosition())
        return (x - self.slider_position[0]) ** 2 + (y - self.slider_position[1]) ** 2 < self.slider_radius ** 2

    def OnLeftDown(self, event):
        self.SetSlider(event)
        if self.PositionOnSlider(event.GetPositionTuple()):
            self.dragging = True
            self.CaptureMouse()

    def OnLeftUp(self, event):
        self.dragging = False
        self.SetValue(float(self.slider_position[0] - self.slider_range[0]) / (self.slider_range[1] - self.slider_range[0]))
        if self.HasCapture():
            self.ReleaseMouse()
        # Call parent
        self.GetParent().GetParent().Seek()

    def OnMotion(self, event):
        if event.LeftIsDown():
            self.SetSlider(event)
        if self.hovering != self.PositionOnSlider(event.GetPositionTuple()):
            self.Refresh()

    def SetSlider(self, event):
        mx = event.GetPositionTuple()[0]
        if mx > self.slider_range[0] and mx < self.slider_range[1]:
            self.slider_position[0] = mx
            self.Refresh()

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, evt):
        # Draw the background
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()
        if hasattr(self.GetParent(), 'bitmap'):
            if not self.GetParent().bitmap:
                wx.CallLater(100, self.Refresh)
            else:
                rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
                sub = self.GetParent().bitmap.GetSubBitmap(rect)
                dc.DrawBitmap(sub, 0, 0)

        width, height = self.GetClientSize()
        gc = wx.GraphicsContext.Create(dc)
        self.slider_range = [10, width - 10]
        self.slider_position[1] = height / 2
        rect_height = height / 4

        # Draw background rectangle
        gc.SetPen(wx.TRANSPARENT_PEN)
        gc.SetBrush(wx.Brush(self.colour4))
        gc.DrawRectangle(self.slider_range[0], height / 2 - rect_height / 2, self.slider_range[1] - self.slider_range[0], rect_height)

        # Draw buffer rectangle
        if self.pieces:
            gc.SetBrush(wx.Brush(self.colour3))
            slider_width = self.slider_range[1] - self.slider_range[0]
            num_pieces = len(self.pieces)
            piece_width = slider_width / float(num_pieces)
            from_piece = to_piece = int(self.value * slider_width / piece_width)
            while to_piece < num_pieces and self.pieces[to_piece]:
                to_piece += 1
            gc.DrawRectangle(self.slider_range[0] + from_piece * piece_width, height / 2 - rect_height / 2, (to_piece - from_piece) * piece_width, rect_height)

        # Draw position rectangle
        gc.SetBrush(wx.Brush(self.colour1))
        gc.DrawRectangle(self.slider_range[0], height / 2 - rect_height / 2, self.slider_position[0] - self.slider_range[0], rect_height)

        # Draw slider
        if self.IsEnabled():
            gc.SetBrush(gc.CreateLinearGradientBrush(self.slider_position[0] - self.slider_radius, 0, self.slider_position[0] + self.slider_radius , 0, self.colour1, self.colour2))
            path = gc.CreatePath()
            path.AddCircle(self.slider_position[0], self.slider_position[1], self.slider_radius)
            gc.DrawPath(path)
            self.hovering = self.PositionOnSlider()
            gc.SetBrush(wx.TRANSPARENT_BRUSH if self.hovering or self.dragging else wx.Brush(wx.Colour(244, 244, 244)))
            path = gc.CreatePath()
            path.AddCircle(self.slider_position[0], self.slider_position[1], self.slider_radius / 2)
            gc.DrawPath(path)
        else:
            gc.SetBrush(gc.CreateLinearGradientBrush(0, 0, self.slider_radius * 2 , 0, self.colour3, self.colour4))
            path = gc.CreatePath()
            path.AddCircle(self.slider_position[0], self.slider_position[1], self.slider_radius)
            gc.DrawPath(path)

    def Enable(self, enable):
        if enable:
            self.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)
            self.Bind(wx.EVT_LEFT_DOWN, self.OnLeftDown)
            self.Bind(wx.EVT_MOTION, self.OnMotion)
        elif not enable:
            self.Unbind(wx.EVT_LEFT_UP)
            self.Unbind(wx.EVT_LEFT_DOWN)
            self.Unbind(wx.EVT_MOTION)
        self.enabled = enable
        self.Refresh()

    def IsEnabled(self):
        return self.enabled

class VideoVolume(wx.Panel):

    def __init__(self, *args, **kwargs):
        wx.Panel.__init__(self, *args, **kwargs)

        self.value = 0
        self.handler = None
        self.dragging = False

        self.Bind(wx.EVT_PAINT, self.OnPaint)
        self.Bind(wx.EVT_ERASE_BACKGROUND, self.OnEraseBackground)
        self.Bind(wx.EVT_LEFT_DOWN, self.OnLeftDown)
        self.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)
        self.Bind(wx.EVT_MOTION, self.OnMotion)

    def PositionOnTriangle(self, position=None):
        x, y = position or self.ScreenToClient(wx.GetMousePosition())
        w, h = self.GetClientSize()
        return y > h - (x * h / w)

    def OnLeftDown(self, event):
        self.SetPosition(event)
        if self.PositionOnTriangle(event.GetPositionTuple()):
            self.dragging = True
            self.CaptureMouse()

    def OnLeftUp(self, event):
        self.dragging = False
        if self.HasCapture():
            self.ReleaseMouse()

    def OnMotion(self, event):
        if event.LeftIsDown():
            self.SetPosition(event)

    def SetPosition(self, event):
        mx, _ = event.GetPosition()
        value = float(mx) / self.GetClientSize().x
        if self.value != value and self.handler:
            self.handler(value)
        self.value = value
        self.Refresh()

    def SetVolumeHandler(self, handler):
        self.handler = handler

    def SetValue(self, value):
        self.value = min(max(0.0, value), 1.0)
        self.Refresh()

    def OnEraseBackground(self, event):
        pass

    def OnPaint(self, event):
        # Draw the background
        dc = wx.BufferedPaintDC(self)
        dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
        dc.Clear()
        if hasattr(self.GetParent(), 'bitmap'):
            if not self.GetParent().bitmap:
                wx.CallLater(100, self.Refresh)
            else:
                rect = self.GetRect().Intersect(wx.Rect(0, 0, *self.GetParent().bitmap.GetSize()))
                sub = self.GetParent().bitmap.GetSubBitmap(rect)
                dc.DrawBitmap(sub, 0, 0)

        w, h = self.GetClientSize()

        gc = wx.GraphicsContext.Create(dc)

        if self.value > 0.0:
            path = gc.CreatePath()
            path.MoveToPoint(0, h - 1)
            path.AddLineToPoint(self.value * w, h - 1)
            path.AddLineToPoint(self.value * w, (1 - self.value) * h)
            path.AddLineToPoint(0, h - 1)
            path.CloseSubpath()
            gc.SetPen(wx.TRANSPARENT_PEN)
            gc.SetBrush(gc.CreateLinearGradientBrush(0, 0, w, 0, wx.Colour(244, 172, 156), wx.Colour(241, 92, 62)))
            gc.DrawPath(path)

        path = gc.CreatePath()
        path.MoveToPoint(0, h - 1)
        path.AddLineToPoint(w - 1, h - 1)
        path.AddLineToPoint(w - 1, 0)
        path.AddLineToPoint(0, h - 1)
        path.CloseSubpath()
        gc.SetPen(wx.Pen(wx.Colour(241, 92, 62)))
        gc.SetBrush(wx.TRANSPARENT_BRUSH)
        gc.DrawPath(path)

########NEW FILE########
__FILENAME__ = webUI
import sys
import os
import logging
import random
from binascii import hexlify, unhexlify
import json
from functools import wraps
from traceback import print_exc
import cherrypy
from cherrypy import response
from cherrypy.lib.auth_basic import checkpassword_dict

from Tribler.Core.simpledefs import DOWNLOAD, UPLOAD


def jsonify(func):
    '''JSON decorator for CherryPy'''
    @wraps(func)
    def wrapper(*args, **kw):
        try:
            value = func(*args, **kw)
            response.headers["Content-Type"] = "application/json"
            return json.dumps(value)
        except:
            print_exc()
            raise
    return wrapper


class WebUI():
    __single = None

    def __init__(self, library_manager, torrentsearch_manager, port):
        if WebUI.__single:
            raise RuntimeError("WebUI is singleton")
        WebUI.__single = self

        self._logger = logging.getLogger(self.__class__.__name__)

        self.currentTokens = set()
        self.currentTorrents = {}

        self.library_manager = library_manager
        self.torrentsearch_manager = torrentsearch_manager
        self.guiUtility = library_manager.guiUtility
        self.port = port

        self.started = False
        self.hasauth = False

    def getInstance(*args, **kw):
        if WebUI.__single is None:
            WebUI(*args, **kw)
        return WebUI.__single
    getInstance = staticmethod(getInstance)

    def delInstance(*args, **kw):
        WebUI.__single = None
    delInstance = staticmethod(delInstance)

    def start(self):
        if not self.started:
            self.started = True

            current_dir = os.path.join(self.guiUtility.utility.getPath(), 'Tribler', 'Main', 'webUI')
            config = {'/': {
                            'tools.staticdir.root': current_dir,
                            'tools.staticdir.on': True,
                            'tools.staticdir.dir': "static",
                            'response.headers.connection': "close",
                            }
                      }

            if self.hasauth:
                userpassdict = {'hello': 'world'}
                checkpassword = checkpassword_dict(userpassdict)
                config['/'] = {'tools.auth_basic.on': True, 'tools.auth_basic.realm': 'Tribler-WebUI', 'tools.auth_basic.checkpassword': checkpassword}

            app = cherrypy.tree.mount(self, '/gui', config)
            app.log.access_log.setLevel(logging.NOTSET)
            app.log.error_log.setLevel(logging.NOTSET)

            self.server = cherrypy._cpserver.Server()
            self.server.socket_port = self.port
            self.server._socket_host = '0.0.0.0'
            self.server.thread_pool = 5
            self.server.subscribe()
            self.server.start()

    def stop(self):
        if self.started:
            self.server.stop()

    def clear_text(self, mypass):
        return mypass

    @cherrypy.expose
    @jsonify
    def index(self, **args):
        for key, value in args.iteritems():
            self._logger.debug("webUI: request %s %s", key, value)

        if len(args) == 0:
            raise cherrypy.HTTPRedirect("/gui/index.html")

        returnDict = {}
        if len(self.currentTokens) == 0:
            self.currentTokens.add(str(args['token']))

        if str(args['token']) in self.currentTokens:
            if 'action' in args:
                returnDict = self.doAction(args)

            if 'list' in args:
                returnDict = self.doList(args)

        returnDict['build'] = 1
        self._logger.debug("webUI: result %s", returnDict)
        return returnDict

    @cherrypy.expose(alias='token.html')
    def token(self, **args):
        newToken = ''.join(random.choice('0123456789ABCDEF') for i in range(60))
        self.currentTokens.add(newToken)
        self._logger.debug("webUI: newToken %s", newToken)
        return "<html><body><div id='token' style='display:none;'>%s</div></body></html>" % newToken

    def doList(self, args):
        _, torrents = self.library_manager.getHitsInCategory()

        returnDict = {}
        returnDict['label'] = []

        newTorrentList = []
        for i, torrent in enumerate(torrents):
            torrentList = []
            torrentList.append(hexlify(torrent.infohash))

            state = 0
            if 'checking' in torrent.state:
                state += 2
            else:
                state += 8

            if 'active' in torrent.state:
                state += 1 + 64 + 128

            torrentList.append(state)

            torrentList.append(torrent.name.encode('utf8'))
            torrentList.append(torrent.length)

            ds = torrent.ds
            if ds:
                progress = ds.get_progress()

                stats = ds.get_seeding_statistics()
                if stats:
                    dl = stats['total_down']
                    ul = stats['total_up']
                else:
                    dl = ds.get_total_transferred(DOWNLOAD)
                    ul = ds.get_total_transferred(UPLOAD)

                seeds, peers = ds.get_num_seeds_peers()
                downS = ds.get_current_speed('down')
                upS = ds.get_current_speed('up')
                eta = ds.get_eta() or sys.maxsize
            else:
                progress = torrent.progress
                dl = 0
                ul = 0

                seeds = peers = 0
                downS = upS = 0
                eta = sys.maxsize

            torrentList.append(int(progress * 1000))
            dl = max(0, progress * torrent.length)
            torrentList.append(dl)
            torrentList.append(ul)

            if dl == 0:
                if ul != 0:
                    ratio = sys.maxsize
                else:
                    ratio = 0
            else:
                ratio = 1.0 * ul / dl

            torrentList.append(int(ratio * 1000))
            torrentList.append(upS)
            torrentList.append(downS)
            torrentList.append(eta)
            torrentList.append('')

            torrentList.append(peers)
            torrentList.append(peers)
            torrentList.append(seeds)
            torrentList.append(seeds)
            torrentList.append(1)
            torrentList.append(i + 1)
            torrentList.append(torrent.length - dl)

            newTorrentList.append(torrentList)

        if 'cid' in args:
            cacheId = int(args['cid'])
            oldTorrentList = self.currentTorrents.get(cacheId, [])
            # step 1: create dict
            newTorrentDict = {}
            for torrent in newTorrentList:
                newTorrentDict[torrent[0]] = torrent

            # step 2: create torrentp (changed torrents) and torrentm (removed torrents)
            returnDict['torrentp'] = []
            returnDict['torrentm'] = []
            for torrent in oldTorrentList:
                key = torrent[0]
                if key not in newTorrentDict:
                    returnDict['torrentm'].append(key)
                else:
                    newtorrent = newTorrentDict[key]
                    if newtorrent != torrent:
                        returnDict['torrentp'].append(newtorrent)
                    del newTorrentDict[key]

            for torrent in newTorrentDict.itervalues():
                returnDict['torrentp'].append(torrent)

        else:
            returnDict['torrents'] = newTorrentList
            cacheId = 0

        cacheId += 1
        self.currentTorrents[cacheId] = newTorrentList
        returnDict['torrentc'] = cacheId

        keys = self.currentTorrents.keys()[:-10]
        for key in keys:
            del self.currentTorrents[key]

        return returnDict

    def doAction(self, args):
        action = args['action']

        if action == 'add-url':
            self.library_manager.startDownloadFromUrl(args['s'], useDefault=True)

        elif action == 'getprops':
            return self.doProps(args)

        elif action == 'getfiles':
            return self.doFiles(args)

        elif action == 'getsettings':
            return self.doSettings(args)

        elif 'hash' in args:
            if isinstance(args.get('hash', ''), basestring):
                infohashes = [args.get('hash', '')]
            else:
                infohashes = args['hash']

            for hash in infohashes:
                infohash = unhexlify(hash)

                torrent = self.library_manager.getTorrentFromInfohash(infohash)
                if action in ['start', 'forcestart', 'unpause']:
                    self.library_manager.resumeTorrent(torrent)
                elif action in ['stop', 'pause']:
                    self.library_manager.stopTorrent(torrent)
                elif action == 'remove':
                    self.library_manager.deleteTorrent(torrent)
                elif action == 'removedata':
                    self.library_manager.deleteTorrent(torrent, removecontent=True)

        return {}

    def doProps(self, args):
        infohash = unhexlify(args.get('hash', ''))
        torrent = self.library_manager.getTorrentFromInfohash(infohash)
        coltorrent = self.torrentsearch_manager.loadTorrent(torrent)
        returnDict = {'props': []}

        torrentDict = {}
        torrentDict['hash'] = hexlify(torrent.infohash)
        torrentDict['trackers'] = "\r\n".join(coltorrent.trackers)
        torrentDict['ulrate'] = 0
        torrentDict['dlrate'] = 0
        torrentDict['superseed'] = 1
        torrentDict['dht'] = 1
        torrentDict['pex'] = 1
        torrentDict['seed_override'] = 0

        if torrent.ds:
            stats = torrent.ds.get_seeding_statistics()
            if stats:
                dl = stats['total_down']
                ul = stats['total_up']
            else:
                dl = torrent.ds.get_total_transferred(DOWNLOAD)
                ul = torrent.ds.get_total_transferred(UPLOAD)

            if dl == 0:
                if ul != 0:
                    ratio = sys.maxsize
                else:
                    ratio = 0
            else:
                ratio = 1.0 * ul / dl

            torrentDict['seed_ratio'] = ratio
            torrentDict['seed_time'] = stats['time_seeding']
        else:
            torrentDict['seed_ratio'] = 0
            torrentDict['seed_time'] = 0
        torrentDict['ulslots'] = -1

        returnDict['props'].append(torrentDict)
        return returnDict

    def doFiles(self, args):
        infohash = unhexlify(args.get('hash', ''))
        torrent = self.library_manager.getTorrentFromInfohash(infohash)
        coltorrent = self.torrentsearch_manager.loadTorrent(torrent)
        returnDict = {'files': []}

        returnDict['files'].append(hexlify(torrent.infohash))
        if torrent.ds:
            completion = torrent.ds.get_files_completion()
        else:
            completion = []

        files = []
        for filename, size in coltorrent.files:
            file = [filename, size, 0, 2]
            for cfile, cprogress in completion:
                if cfile == filename:
                    file[2] = cprogress * size
                    break

            files.append(file)
        returnDict['files'].append(files)
        return returnDict

    def doSettings(self, args):
        return {"settings": []}

########NEW FILE########
__FILENAME__ = RateManager
# Written by Arno Bakker and ABC authors
# see LICENSE.txt for license information

import logging
from sets import Set
from threading import RLock

from Tribler.Core.simpledefs import UPLOAD, DOWNLOAD, DLSTATUS_ALLOCATING_DISKSPACE, \
    DLSTATUS_WAITING4HASHCHECK, DLSTATUS_HASHCHECKING, DLSTATUS_DOWNLOADING, \
    DLSTATUS_SEEDING, DLSTATUS_STOPPED, DLSTATUS_STOPPED_ON_ERROR
from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr


class RateManager:

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.lock = RLock()
        self.statusmap = {}
        self.currenttotal = {}
        self.dset = Set()
        self.clear_downloadstates()

    def add_downloadstate(self, ds):
        """ Returns the number of unique states currently stored """
        self._logger.debug("RateManager: add_downloadstate %s", repr(ds.get_download().get_def().get_roothash()))

        self.lock.acquire()
        try:
            d = ds.get_download()
            if d not in self.dset:
                self.statusmap[ds.get_status()].append(ds)
                for dir in [UPLOAD, DOWNLOAD]:
                    self.currenttotal[dir] += ds.get_current_speed(dir)
                self.dset.add(d)
            return len(self.dset)
        finally:
            self.lock.release()

    def add_downloadstatelist(self, dslist):
        for ds in dslist:
            self.add_downloadstate(ds)

    def adjust_speeds(self):
        """ Adjust speeds for the specified set of downloads and clears the set """
        self.lock.acquire()
        try:
            self.calc_and_set_speed_limits(DOWNLOAD)
            self.calc_and_set_speed_limits(UPLOAD)
            self.clear_downloadstates()
        finally:
            self.lock.release()

    def clear_downloadstates(self):
        self.statusmap[DLSTATUS_ALLOCATING_DISKSPACE] = []
        self.statusmap[DLSTATUS_WAITING4HASHCHECK] = []
        self.statusmap[DLSTATUS_HASHCHECKING] = []
        self.statusmap[DLSTATUS_DOWNLOADING] = []
        self.statusmap[DLSTATUS_SEEDING] = []
        self.statusmap[DLSTATUS_STOPPED] = []
        self.statusmap[DLSTATUS_STOPPED_ON_ERROR] = []
        for dir in [UPLOAD, DOWNLOAD]:
            self.currenttotal[dir] = 0
        self.dset.clear()

    #
    # Internal methods
    #
    #
    # The following methods are all called with the lock held
    #

    def calc_and_set_speed_limits(self, direct):
        """ Override this method to write you own speed management policy. """
        pass


class UserDefinedMaxAlwaysOtherwiseEquallyDividedRateManager(RateManager):

    """ This class implements a simple rate management policy that:
    1. If the API user set a desired speed for a particular download,
       the speed limit for this download is set to the desired value.
    2. For all torrents for which no desired speeds have been set,
       the global limit is equally divided amongst all downloads.
       (however small the piece of the pie may be).
    3. There are separate global limits for download speed, upload speed
       and upload speed when all torrents are seeding.
    """
    def __init__(self):
        RateManager.__init__(self)
        self.global_max_speed = {UPLOAD: 0.0, DOWNLOAD: 0.0}
        self.ltmgr = None

    def set_global_max_speed(self, direct, speed):
        self.lock.acquire()
        self.global_max_speed[direct] = speed
        self.lock.release()

    def calc_and_set_speed_limits(self, dir=UPLOAD):
        self._logger.debug("RateManager: calc_and_set_speed_limits %s", dir)

        if dir == UPLOAD:
            workingset = self.statusmap[DLSTATUS_DOWNLOADING] + self.statusmap[DLSTATUS_SEEDING]
        else:
            workingset = self.statusmap[DLSTATUS_DOWNLOADING]

        self._logger.debug("RateManager: calc_and_set_speed_limits: len workingset %s", len(workingset))

        # Limit working set to active torrents with connections:
        newws = []
        for ds in workingset:
            if ds.get_num_peers() > 0:
                newws.append(ds)
        workingset = newws

        self._logger.debug("RateManager: calc_and_set_speed_limits: len active workingset %s", len(workingset))

        # No active file, not need to calculate
        if not workingset:
            return

        globalmaxspeed = self.get_global_max_speed(dir)
        # See if global speed settings are set to unlimited
        if globalmaxspeed == 0:
            # Unlimited speed
            for ds in workingset:
                d = ds.get_download()
                d.set_max_speed(dir, d.get_max_desired_speed(dir))

        else:
            self._logger.debug("RateManager: calc_and_set_speed_limits: globalmaxspeed is %s %s", globalmaxspeed, dir)

            # User set priority is always granted, ignoring global limit
            todoset = []
            for ds in workingset:
                d = ds.get_download()
                maxdesiredspeed = d.get_max_desired_speed(dir)
                if maxdesiredspeed > 0.0:
                    d.set_max_speed(dir, maxdesiredspeed)
                else:
                    todoset.append(ds)

            if len(todoset) > 0:
                # Rest divides globalmaxspeed equally
                localmaxspeed = globalmaxspeed / float(len(todoset))  if globalmaxspeed > 0 else 0.00001
                # if too small than user's problem

                self._logger.debug("RateManager: calc_and_set_speed_limits: localmaxspeed is %s %s", localmaxspeed, dir)

                for ds in todoset:
                    d = ds.get_download()
                    d.set_max_speed(dir, localmaxspeed)


        if self.ltmgr == None and LibtorrentMgr.hasInstance():
            self.ltmgr = LibtorrentMgr.getInstance()

        if self.ltmgr:
            rate = self.global_max_speed[dir]  # unlimited == 0, stop == -1, else rate in kbytes
            libtorrent_rate = -1 if rate == 0 else (1 if rate == -1 else rate * 1024)
            if dir == UPLOAD:
                self.ltmgr.set_upload_rate_limit(libtorrent_rate)
            else:
                self.ltmgr.set_download_rate_limit(libtorrent_rate)

    def get_global_max_speed(self, dir=UPLOAD):
        return self.global_max_speed[dir]


class UserDefinedMaxAlwaysOtherwiseDividedOnDemandRateManager(UserDefinedMaxAlwaysOtherwiseEquallyDividedRateManager):

    """ This class implements a simple rate management policy that:
    1. If the API user set a desired speed for a particular download,
       the speed limit for this download is set to the desired value.
    2. For all torrents for which no desired speeds have been set,
       the global limit is divided on demand amongst all downloads.
    3. There are separate global limits for download speed, upload speed
       and upload speed when all torrents are seeding.

    TODO: if vod: give all of global limit? Do this at higher level: stop
    all dls when going to VOD
    """
    def __init__(self):
        UserDefinedMaxAlwaysOtherwiseEquallyDividedRateManager.__init__(self)

        self.ROOM = 5.0  # the amount of room in speed underutilizing downloads get

    def calc_and_set_speed_limits(self, dir=UPLOAD):
        self._logger.debug("RateManager: calc_and_set_speed_limits %s", dir)

        if dir == UPLOAD:
            workingset = self.statusmap[DLSTATUS_DOWNLOADING] + self.statusmap[DLSTATUS_SEEDING]
        else:
            workingset = self.statusmap[DLSTATUS_DOWNLOADING]

        self._logger.debug("RateManager: calc_and_set_speed_limits: len workingset %s", len(workingset))

        # Limit working set to active torrents with connections:
        newws = []
        for ds in workingset:
            if ds.get_num_peers() > 0:
                newws.append(ds)
        workingset = newws

        self._logger.debug("RateManager: calc_and_set_speed_limits: len new workingset %s", len(workingset))
        for ds in workingset:
            d = ds.get_download()
            self._logger.debug("RateManager: calc_and_set_speed_limits: working is %s", d.get_def().get_name())

        # No active file, not need to calculate
        if not workingset:
            return

        globalmaxspeed = self.get_global_max_speed(dir)
        # See if global speed settings are set to unlimited
        if globalmaxspeed == 0:
            # Unlimited speed
            for ds in workingset:
                d = ds.get_download()
                d.set_max_speed(dir, d.get_max_desired_speed(dir))

        else:
            self._logger.debug("RateManager: calc_and_set_speed_limits: globalmaxspeed is %s %s", globalmaxspeed, dir)

            # User set priority is always granted, ignoring global limit
            todoset = []
            for ds in workingset:
                d = ds.get_download()
                maxdesiredspeed = d.get_max_desired_speed(dir)
                if maxdesiredspeed > 0.0:
                    d.set_max_speed(dir, maxdesiredspeed)
                else:
                    todoset.append(ds)

            if len(todoset) > 0:
                # Rest divides globalmaxspeed based on their demand
                localmaxspeed = globalmaxspeed / float(len(todoset)) if globalmaxspeed > 0 else 0.00001
                # if too small than user's problem

                self._logger.debug("RateManager: calc_and_set_speed_limits: localmaxspeed is %s %s", localmaxspeed, dir)

                # See if underutilizers and overutilizers. If not, just divide equally
                downloadsatmax = False
                downloadsunderutil = False
                for ds in todoset:
                    d = ds.get_download()
                    currspeed = ds.get_current_speed(dir)
                    currmaxspeed = d.get_max_speed(dir)

                    newmaxspeed = currspeed + self.ROOM
                    if currspeed >= (currmaxspeed - 3.0):  # dl needs more
                        downloadsatmax = True
                    elif newmaxspeed < localmaxspeed:  # dl got quota to spare
                        downloadsunderutil = True

                if downloadsatmax and downloadsunderutil:
                    totalunused = 0.0
                    todoset2 = []
                    for ds in todoset:
                        d = ds.get_download()
                        currspeed = ds.get_current_speed(dir)

                        newmaxspeed = currspeed + self.ROOM
                        if newmaxspeed < localmaxspeed:
                            # If unterutilizing:
                            totalunused += (localmaxspeed - newmaxspeed)
                            # Give current speed + 5.0 KB/s extra so it can grow
                            self._logger.info("RateManager: calc_and_set_speed_limits: Underutil set to %s", newmaxspeed)
                            d.set_max_speed(dir, newmaxspeed)
                        else:
                            todoset2.append(ds)

                    # Divide the unused bandwidth equally amongst others
                    if len(todoset2) > 0:
                        pie = float(len(todoset2)) * localmaxspeed + totalunused
                        piece = pie / float(len(todoset2))
                        for ds in todoset:
                            d = ds.get_download()
                            self._logger.info("RateManager: calc_and_set_speed_limits: Overutil set to %s", piece)
                            d.set_max_speed(dir, piece)
                    else:
                        # what the f? No overutilizers now?
                        self._logger.info("UserDefinedMaxAlwaysOtherwiseDividedOnDemandRateManager: Internal error: No overutilizers anymore?")
                else:
                    # No over and under utilizers, just divide equally
                    for ds in todoset:
                        d = ds.get_download()
                        self._logger.info("RateManager: calc_and_set_speed_limits: Normal set to %s", piece)
                        d.set_max_speed(dir, localmaxspeed)

        if self.ltmgr == None and LibtorrentMgr.hasInstance():
            self.ltmgr = LibtorrentMgr.getInstance()

        if self.ltmgr:
            rate = self.global_max_speed[dir]  # unlimited == 0, stop == -1, else rate in kbytes
            libtorrent_rate = -1 if rate == 0 else (1 if rate == -1 else rate * 1024)
            if dir == UPLOAD:
                self.ltmgr.set_upload_rate_limit(libtorrent_rate)
            else:
                self.ltmgr.set_download_rate_limit(libtorrent_rate)


class UserDefinedMaxAlwaysOtherwiseDividedOverActiveSwarmsRateManager(UserDefinedMaxAlwaysOtherwiseEquallyDividedRateManager):

    """ This class implements a simple rate management policy that:
    1. If the API user set a desired speed for a particular download,
       the speed limit for this download is set to the desired value.
    2. For all torrents for which no desired speeds have been set,
       the global limit is divided amongst all downloads that have peers.
       Torrents without user-prefs or peers get a max equal to the global max.
       They'll get throttled again to an equal share in the next iteration
       after peers connect.
    3. There are separate global limits for download speed, upload speed
       and upload speed when all torrents are seeding.
    """
    def __init__(self):
        UserDefinedMaxAlwaysOtherwiseEquallyDividedRateManager.__init__(self)

        self.ROOM = 5.0  # the amount of room in speed underutilizing downloads get

    def calc_and_set_speed_limits(self, dir=UPLOAD):
        self._logger.debug("RateManager: calc_and_set_speed_limits %s", dir)

        if dir == UPLOAD:
            workingset = self.statusmap[DLSTATUS_DOWNLOADING] + self.statusmap[DLSTATUS_SEEDING]
        else:
            workingset = self.statusmap[DLSTATUS_DOWNLOADING]

        self._logger.debug("RateManager: set_lim: len workingset %s", len(workingset))

        # Limit working set to active torrents with connections:
        newws = []
        inactiveset = []
        for ds in workingset:
            # d = ds.get_download()
            # print >>sys.stderr,"RateManager: set_lim: Peers",d.get_def().get_name(),ds.get_num_nonseeds(),"alt",ds.get_num_seeds_peers()
            # Arno, 2010-09-16: Don't count any HTTP seeders as leechers.
            if ds.get_num_nonseeds() > 0:
                newws.append(ds)
            else:
                inactiveset.append(ds)
        workingset = newws

        self._logger.debug("RateManager: set_lim: len new workingset %s", len(workingset))
        for ds in workingset:
            d = ds.get_download()
            self._logger.debug("RateManager: set_lim: working is %s", d.get_def().get_name())

        globalmaxspeed = self.get_global_max_speed(dir)

        # TEST globalmaxspeed = 1.0
        self._logger.debug("RateManager: set_lim: globalmaxspeed is %s %s", globalmaxspeed, dir)

        # See if global speed settings are set to unlimited
        if globalmaxspeed == 0:
            # Unlimited speed
            for ds in workingset:
                d = ds.get_download()
                d.set_max_speed(dir, d.get_max_desired_speed(dir))
            for ds in inactiveset:
                d = ds.get_download()
                d.set_max_speed(dir, d.get_max_desired_speed(dir))  # 0 is default

        else:
            self._logger.debug("RateManager: set_lim: globalmaxspeed is %s %s", globalmaxspeed, dir)

            # User set priority is always granted, ignoring global limit
            todoset = []
            for ds in workingset:
                d = ds.get_download()
                maxdesiredspeed = d.get_max_desired_speed(dir)
                if maxdesiredspeed > 0.0:
                    d.set_max_speed(dir, maxdesiredspeed)
                else:
                    todoset.append(ds)

            if len(todoset) > 0:
                # Rest divides globalmaxspeed based on their demand
                localmaxspeed = globalmaxspeed / float(len(todoset)) if globalmaxspeed > 0 else 0.00001
                # if too small than user's problem

                self._logger.debug("RateManager: set_lim: localmaxspeed is %s %s", localmaxspeed, dir)

                for ds in todoset:
                    d = ds.get_download()
                    self._logger.debug("RateManager: set_lim: %s WorkQ %s", d.get_def().get_name(), localmaxspeed)
                    d.set_max_speed(dir, localmaxspeed)

            # For inactives set limit to user desired, with max of globalmaxspeed
            # or to globalmaxspeed. This way the peers have a limit already set
            # when the first peers arrive. The height of the limit will be corrected
            # here a few seconds later (see BaseApp ratelimiter).
            #
            for ds in inactiveset:
                d = ds.get_download()
                desspeed = d.get_max_desired_speed(dir)
                if desspeed == 0:
                    setspeed = globalmaxspeed
                else:
                    setspeed = min(desspeed, globalmaxspeed)
                self._logger.debug("RateManager: set_lim: %s InactQ %s", d.get_def().get_name(), setspeed)
                d.set_max_speed(dir, setspeed)

        if self.ltmgr == None and LibtorrentMgr.hasInstance():
            self.ltmgr = LibtorrentMgr.getInstance()

        if self.ltmgr:
            rate = self.global_max_speed[dir]  # unlimited == 0, stop == -1, else rate in kbytes
            libtorrent_rate = -1 if rate == 0 else (1 if rate == -1 else rate * 1024)
            if dir == UPLOAD:
                self.ltmgr.set_upload_rate_limit(libtorrent_rate)
            else:
                self.ltmgr.set_download_rate_limit(libtorrent_rate)

########NEW FILE########
__FILENAME__ = SeedingManager
# Written by Boxun Zhang
# see LICENSE.txt for license information

import logging

from Tribler.Core.simpledefs import DLSTATUS_SEEDING, DLMODE_VOD
from Tribler.Main.vwxGUI.UserDownloadChoice import UserDownloadChoice


class GlobalSeedingManager:

    def __init__(self, Read):
        self._logger = logging.getLogger(self.__class__.__name__)

        # seeding managers containing infohash:seeding_manager pairs
        self.seeding_managers = {}

        # callback to read from abc configuration file
        self.Read = Read

    def apply_seeding_policy(self, dslist):
        # Remove stopped seeds
        for infohash, seeding_manager in self.seeding_managers.items():
            if not seeding_manager.download_state.get_download().get_status() == DLSTATUS_SEEDING:
                self._logger.debug("SeedingManager: removing seeding manager %s", infohash.encode("HEX"))
                del self.seeding_managers[infohash]

        for download_state in dslist:
            # Arno, 2012-05-07: ContentDef support
            cdef = download_state.get_download().get_def()
            hash = cdef.get_id()
            if download_state.get_status() == DLSTATUS_SEEDING:
                if hash not in self.seeding_managers:
                    # apply new seeding manager
                    self._logger.debug("SeedingManager: apply seeding manager %s", hash.encode("HEX"))
                    seeding_manager = SeedingManager(download_state)

                    policy = self.Read('t4t_option') if cdef.get_def_type() == 'torrent' else self.Read('g2g_option')
                    if policy == 0:
                        # No leeching, seeding until sharing ratio is met
                        self._logger.debug("GlobalSeedingManager: RatioBasedSeeding")
                        seeding_manager.set_policy(TitForTatRatioBasedSeeding(self.Read) if cdef.get_def_type() == 'torrent' else GiveToGetRatioBasedSeeding(self.Read))

                    elif policy == 1:
                        # Unlimited seeding
                        self._logger.debug("GlobalSeedingManager: UnlimitedSeeding")
                        seeding_manager.set_policy(UnlimitedSeeding())

                    elif policy == 2:
                        # Time based seeding
                        self._logger.debug("GlobalSeedingManager: TimeBasedSeeding")
                        seeding_manager.set_policy(TitForTatTimeBasedSeeding(self.Read) if cdef.get_def_type() == 'torrent' else GiveToGetTimeBasedSeeding(self.Read))

                    else:
                        # No seeding
                        self._logger.debug("GlobalSeedingManager: NoSeeding")
                        seeding_manager.set_policy(NoSeeding())

                    self.seeding_managers[hash] = seeding_manager

                self.seeding_managers[hash].update_download_state(download_state)


class SeedingManager:

    def __init__(self, download_state):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.download_state = download_state
        self.policy = None
        self.udc = UserDownloadChoice.get_singleton()

    def update_download_state(self, download_state):
        self.download_state = download_state
        download = self.download_state.get_download()
        if download.get_def().get_def_type() == 'torrent':
            if self.udc.get_download_state(download.get_def().get_id()) != 'restartseed' and download.get_mode() != DLMODE_VOD:
                if not self.policy.apply(self.download_state, self.download_state.get_seeding_statistics()):
                    self._logger.debug("Stop seeding with libtorrent: %s", self.download_state.get_download().get_dest_files())
                    self.udc.set_download_state(download.get_def().get_id(), 'stop')
                    self.download_state.get_download().stop()
        else:
            if self.udc.get_download_state(download.get_def().get_id()) != 'restartseed' and download.get_mode() != DLMODE_VOD:
                if not self.policy.apply(self.download_state, self.download_state.get_seeding_statistics()):
                    self._logger.debug("Stop seeding with libswift: %s", self.download_state.get_download().get_dest_files())
                    self.download_state.get_download().stop()

    def set_policy(self, policy):
        self.policy = policy


class SeedingPolicy:

    def __init__(self):
        pass

    def apply(self, _, __):
        pass


class UnlimitedSeeding(SeedingPolicy):

    def __init__(self):
        SeedingPolicy.__init__(self)

    def apply(self, _, __):
        return True


class NoSeeding(SeedingPolicy):

    def __init__(self):
        SeedingPolicy.__init__(self)

    def apply(self, _, __):
        return False


class TitForTatTimeBasedSeeding(SeedingPolicy):

    def __init__(self, Read):
        self._logger = logging.getLogger(self.__class__.__name__)
        SeedingPolicy.__init__(self)
        self.Read = Read

    def apply(self, _, storage):
        current = storage["time_seeding"]
        limit = long(self.Read('t4t_hours')) * 3600 + long(self.Read('t4t_mins')) * 60
        self._logger.debug("TitForTatTimeBasedSeeding: apply: %s/ %s", current, limit)
        return current <= limit


class GiveToGetTimeBasedSeeding(SeedingPolicy):

    def __init__(self, Read):
        self._logger = logging.getLogger(self.__class__.__name__)
        SeedingPolicy.__init__(self)
        self.Read = Read

    def apply(self, _, storage):
        current = storage["time_seeding"]
        limit = long(self.Read('g2g_hours')) * 3600 + long(self.Read('g2g_mins')) * 60
        self._logger.debug("GiveToGetTimeBasedSeeding: apply: %s / %s", current, limit)
        return current <= limit


class TitForTatRatioBasedSeeding(SeedingPolicy):

    def __init__(self, Read):
        self._logger = logging.getLogger(self.__class__.__name__)
        SeedingPolicy.__init__(self)
        self.Read = Read

    def apply(self, download_state, storage):
        # No Bittorrent leeching (minimal ratio of 1.0)
        ul = storage["total_up"]
        dl = storage["total_down"]

        # set dl at min progress*length
        size_progress = download_state.get_length() * download_state.get_progress()
        dl = max(dl, size_progress)

        if dl == 0:
            # no download will result in no-upload to anyone
            ratio = 1.0
        else:
            ratio = 1.0 * ul / dl

        self._logger.debug("TitForTatRatioBasedSeeding: apply: %s %s %s", dl, ul, ratio)

        return ratio < self.Read('t4t_ratio') / 100.0


class GiveToGetRatioBasedSeeding(SeedingPolicy):

    def __init__(self, Read):
        self._logger = logging.getLogger(self.__class__.__name__)
        SeedingPolicy.__init__(self)
        self.Read = Read

    def apply(self, download_state, storage):
        ul = storage["total_up"]
        dl = storage["total_down"]

        if dl == 0:
            # no download will result in no-upload to anyone
            ratio = 1.0
        else:
            ratio = 1.0 * ul / dl

        self._logger.debug("GiveToGetRatioBasedSeedingapply: %s %s %s %s", dl, ul, ratio, self.Read('g2g_ratio', "int") / 100.0)
        return ratio < self.Read('g2g_ratio') / 100.0

########NEW FILE########
__FILENAME__ = test_seeding
# Written by Arno Bakker, heavy modified by Niels Zeilemaker
# see LICENSE.txt for license information

import os
import sys
import time
import socket
import threading

from Tribler.Test.test_as_server import TestAsServer, BASE_DIR
from Tribler.Test.btconn import BTConnection

from Tribler.Core.simpledefs import dlstatus_strings, DLSTATUS_SEEDING
from Tribler.Core.MessageID import CHOKE, EXTEND
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Session import Session


class TestSeeding(TestAsServer):

    """
    Testing seeding via new tribler API:
    """
    def setUp(self):
        """ override TestAsServer """
        TestAsServer.setUp(self)

        self.session2 = None
        self.seeding_event = threading.Event()
        self.downloading_event = threading.Event()

    def setUpPreSession(self):
        """ override TestAsServer """
        TestAsServer.setUpPreSession(self)
        self.config.set_libtorrent(True)

        self.config2 = self.config.copy()  # not really necess
        self.config2.set_state_dir(self.getStateDir(2))

        self.dscfg2 = DownloadStartupConfig()
        self.dscfg2.set_dest_dir(self.getDestDir(2))

    def setUpPostSession(self):
        pass

    def tearDown(self):
        if self.session2:
            self._shutdown_session(self.session2)
            time.sleep(10)

        TestAsServer.tearDown(self)

    def setup_seeder(self, filename='video.avi'):
        self.tdef = TorrentDef()
        self.sourcefn = os.path.join(BASE_DIR, "API", filename)
        self.tdef.add_content(self.sourcefn)
        self.tdef.set_tracker("http://fake.net/announce")
        self.tdef.finalize()

        self.torrentfn = os.path.join(self.session.get_state_dir(), "gen.torrent")
        self.tdef.save(self.torrentfn)

        print >> sys.stderr, "test: setup_seeder: name is", self.tdef.metainfo['info']['name']

        self.dscfg = DownloadStartupConfig()
        self.dscfg.set_dest_dir(os.path.join(BASE_DIR, "API"))  # basedir of the file we are seeding
        d = self.session.start_download(self.tdef, self.dscfg)
        d.set_state_callback(self.seeder_state_callback)

        print >> sys.stderr, "test: setup_seeder: starting to wait for download to reach seeding state"
        assert self.seeding_event.wait(60)

    def seeder_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: seeder:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()

        if ds.get_status() == DLSTATUS_SEEDING:
            self.seeding_event.set()

        return (1.0, False)

    def test_normal_torrent(self):
        self.setup_seeder()
        self.subtest_is_seeding()
        self.subtest_download()

    def subtest_is_seeding(self):
        infohash = self.tdef.get_infohash()
        s = BTConnection('localhost', self.session.get_listen_port(), user_infohash=infohash)
        s.read_handshake_medium_rare()

        s.send(CHOKE)
        try:
            s.s.settimeout(10.0)
            resp = s.recv()
            self.assert_(len(resp) > 0)
            self.assert_(resp[0] == EXTEND)
        except socket.timeout:
            print >> sys.stderr, "test: Timeout, peer didn't reply"
            self.assert_(False)
        s.close()

    def subtest_download(self):
        """ Now download the file via another Session """
        self.session2 = Session(self.config2, ignore_singleton=True)
        self.session2.start()

        time.sleep(5)

        tdef2 = TorrentDef.load(self.torrentfn)

        d = self.session2.start_download(tdef2, self.dscfg2)
        d.set_state_callback(self.downloader_state_callback)

        time.sleep(5)

        d.add_peer(("127.0.0.1", self.session.get_listen_port()))
        assert self.downloading_event.wait(60)

    def downloader_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: download:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()

        if ds.get_status() == DLSTATUS_SEEDING:
            # File is in
            destfn = os.path.join(self.getDestDir(2), "video.avi")
            f = open(destfn, "rb")
            realdata = f.read()
            f.close()
            f = open(self.sourcefn, "rb")
            expdata = f.read()
            f.close()

            self.assert_(realdata == expdata)
            self.downloading_event.set()
            return (1.0, True)
        return (1.0, False)

########NEW FILE########
__FILENAME__ = test_seeding_live
# Written by Arno Bakker
# see LICENSE.txt for license information
#

import sys
import time
import socket
from unittest import skip

from Tribler.Test.test_as_server import TestAsServer
from Tribler.Test.btconn import BTConnection

from Tribler.Core.simpledefs import dlstatus_strings
from Tribler.Core.MessageID import getMessageName, EXTEND, BITFIELD
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Session import Session

from Tribler.Core.Utilities.bitfield import Bitfield

DEBUG = True


class TestSeeding(TestAsServer):

    """
    Testing seeding via new tribler API:
    """

    def setUp(self):
        """ override TestAsServer """
        TestAsServer.setUp(self)
        print >> sys.stderr, "test: Giving Session time to startup"
        time.sleep(5)
        print >> sys.stderr, "test: Session should have started up"

    def setUpPreSession(self):
        """ override TestAsServer """
        TestAsServer.setUpPreSession(self)

        self.config2 = self.config.copy()
        self.config2.set_state_dir(self.getStateDir(2))

    def setUpPostSession(self):
        pass

    @skip("We need to migrate this to swift")
    def test_live_torrent(self):
        """
            I want to start a Tribler client once and then connect to
            it many times. So there must be only one test method
            to prevent setUp() from creating a new client every time.

            The code is constructed so unittest will show the name of the
            (sub)test where the error occured in the traceback it prints.
        """
        self.setup_seeder()
        time.sleep(10)
        # self.subtest_connect2downloader()
        self.subtest_download()

    def setup_seeder(self):
        self.tdef = TorrentDef()
        # semi automatic
        self.bitrate = 6144
        piecesize = 32768
        self.npieces = 12
        playtime = ((self.npieces - 1) * piecesize) / self.bitrate
        playtimestr = '0:' + str(playtime)  # DON'T WORK IF > 60 secs
        self.tdef.create_live("Test Live", self.bitrate, playtimestr)
        self.tdef.set_tracker(self.session.get_internal_tracker_url())
        self.tdef.set_piece_length(piecesize)
        self.tdef.finalize()

        print >> sys.stderr, "test: setup_seeder: name is", self.tdef.metainfo['info']['name']

        self.dscfg = DownloadStartupConfig()
        self.dscfg.set_dest_dir(self.getDestDir())

        # File source
        source = InfiniteSource(piecesize)
        self.dscfg.set_video_ratelimit(self.bitrate)
        self.dscfg.set_video_source(source)

        d = self.session.start_download(self.tdef, self.dscfg)

        d.set_state_callback(self.seeder_state_callback)

    def seeder_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: seeder:", dlstatus_strings[ds.get_status()], ds.get_progress()
        return (1.0, False)

    def subtest_download(self):
        """ Now download the file via another Session """
        self.session2 = Session(self.config2, ignore_singleton=True)

        # Allow session2 to start
        print >> sys.stderr, "test: downloader: Sleeping 3 secs to let Session2 start"
        time.sleep(3)

        tdef2 = TorrentDef.load(self.torrentfn)

        dscfg2 = DownloadStartupConfig()
        dscfg2.set_dest_dir(self.getDestDir(2))
        dscfg2.set_video_event_callback(self.downloader_vod_ready_callback)

        d = self.session2.start_download(tdef2, dscfg2)
        d.set_state_callback(self.downloader_state_callback)

        time.sleep(40)
        # To test if BITFIELD is indeed wrapping around.
        self.subtest_connect2downloader()
        time.sleep(80)

    def downloader_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: download:", dlstatus_strings[ds.get_status()], ds.get_progress()

        return (1.0, False)

    def downloader_vod_ready_callback(self, d, event, params):
        """ Called by SessionThread """
        if event == VODEVENT_START:
            stream = params["stream"]
            while True:
                # Fake video playback
                data = stream.read(self.bitrate)
                if len(data) == 0:
                    break
                time.sleep(1)

    def subtest_connect2downloader(self):

        print >> sys.stderr, "test: verifier: Connecting to seeder to check bitfield"

        infohash = self.tdef.get_infohash()
        s = BTConnection('localhost', self.session2.get_listen_port(), user_infohash=infohash)
        s.read_handshake_medium_rare()

        try:
            s.s.settimeout(10.0)
            resp = s.recv()
            self.assert_(len(resp) > 0)
            print >> sys.stderr, "test: verifier: Got message", getMessageName(resp[0])
            self.assert_(resp[0] == EXTEND)
            resp = s.recv()
            self.assert_(len(resp) > 0)
            print >> sys.stderr, "test: verifier: Got 2nd message", getMessageName(resp[0])
            self.assert_(resp[0] == BITFIELD)
            b = Bitfield(self.npieces, resp[1:])
            print >> sys.stderr, "test: verifier: Bitfield is", repr(b.toboollist())

            b2 = Bitfield(self.npieces)
            b2[0] = True
            msg = BITFIELD + b2.tostring()
            s.send(msg)

            time.sleep(5)

        except socket.timeout:
            print >> sys.stderr, "test: verifier: Timeout, peer didn't reply"
            self.assert_(False)
        s.close()


class InfiniteSource:

    def __init__(self, piece_length):
        self.emptypiece = " " * piece_length

    def read(self, len):
        return self.emptypiece[:len]

    def close(self):
        pass

########NEW FILE########
__FILENAME__ = test_seeding_swift
# Written by Arno Bakker, heavy modified by Niels Zeilemaker
# see LICENSE.txt for license information

import os
import sys
import time
import shutil
import threading
from traceback import print_exc

from Tribler.Test.test_as_server import TestAsServer, BASE_DIR

from Tribler.Core.simpledefs import DLSTATUS_SEEDING, dlstatus_strings
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Session import Session
from Tribler.Core.Swift.SwiftDef import SwiftDef


class TestSeeding(TestAsServer):

    """
    Testing seeding via new tribler API:
    """
    def setUp(self):
        """ override TestAsServer """
        TestAsServer.setUp(self)

        self.session2 = None
        self.seeding_event = threading.Event()
        self.downloading_event = threading.Event()

    def setUpPreSession(self):
        """ override TestAsServer """
        TestAsServer.setUpPreSession(self)
        self.config.set_swift_proc(True)
        self.config.set_install_dir(os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', '..', '..')))

        self.config2 = self.config.copy()  # not really necess
        self.config2.set_state_dir(self.getStateDir(2))

    def setUpPostSession(self):
        pass

    def tearDown(self):
        if self.session2:
            self._shutdown_session(self.session2)
            time.sleep(10)

        TestAsServer.tearDown(self)

    def setup_seeder(self, filenames, destdir=None, add_to_session=True):
        self.sdef = SwiftDef()
        self.sdef.set_tracker("127.0.0.1:%d" % self.session.get_swift_dht_listen_port())

        destdir = destdir or os.path.join(BASE_DIR, "API")
        self.filenames = [os.path.join(destdir, f) for f in filenames]

        for f in filenames:
            if len(filenames) == 1:
                self.sdef.add_content(os.path.join(destdir, f))
            else:
                self.sdef.add_content(os.path.join(destdir, f), f)

        specpn = self.sdef.finalize(self.session.get_swift_path(), destdir=destdir)

        metadir = self.session.get_swift_meta_dir()
        if len(filenames) == 1:
            storagepath = os.path.join(destdir, filenames[0])  # Point to file on disk
            metapath = os.path.join(metadir, os.path.split(storagepath)[1])

            try:
                shutil.move(storagepath + '.mhash', metapath + '.mhash')
                shutil.move(storagepath + '.mbinmap', metapath + '.mbinmap')
            except:
                print_exc()
        else:
            metapath = os.path.join(metadir, self.sdef.get_roothash_as_hex())
            storagepath = destdir

            # Reuse .mhash and .mbinmap (happens automatically for single-file)
            try:
                shutil.move(specpn, metapath + '.mfspec')
                shutil.move(specpn + '.mhash', metapath + '.mhash')
                shutil.move(specpn + '.mbinmap', metapath + '.mbinmap')
            except:
                print_exc()

        print >> sys.stderr, "test: setup_seeder: seeding", filenames

        if add_to_session:
            self.dscfg = DownloadStartupConfig()
            self.dscfg.set_dest_dir(storagepath)

            d = self.session.start_download(self.sdef, self.dscfg)
            d.set_state_callback(self.seeder_state_callback)

            print >> sys.stderr, "test: setup_seeder: starting to wait for download to reach seeding state"
            assert self.seeding_event.wait(60)
        return self.sdef.get_roothash()

    def seeder_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: seeder:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()

        if ds.get_status() == DLSTATUS_SEEDING:
            self.seeding_event.set()

        return (1.0, False)

    def setup_downloader(self, roothash, filenames):
        self.session2 = Session(self.config2, ignore_singleton=True)
        self.session2.start()

        time.sleep(5)

        sdef2 = SwiftDef(roothash, tracker="127.0.0.1:%d" % self.session.get_swift_tunnel_listen_port())

        self.dscfg2 = DownloadStartupConfig()
        self.dscfg2.set_dest_dir(os.path.join(self.getDestDir(2), filenames[0]) if len(filenames) == 1 else self.getDestDir(2))
        self.dscfg2.set_swift_meta_dir(self.getDestDir(2))

        d = self.session2.start_download(sdef2, self.dscfg2)
        d.set_state_callback(self.downloader_state_callback)
        assert self.downloading_event.wait(60)

    def downloader_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: downloader:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()

        if ds.get_status() == DLSTATUS_SEEDING:
            for filename in self.filenames:
                f = open(filename, "rb")
                realdata = f.read()
                f.close()
                f = open(os.path.join(BASE_DIR, "API", os.path.split(filename)[1]), "rb")
                expdata = f.read()
                f.close()
                self.assert_(realdata == expdata)

            self.downloading_event.set()
            return (1.0, True)
        return (1.0, False)

    def test_singlefile_swift(self):
        filenames = ['video.avi']
        roothash = self.setup_seeder(filenames)
        self.setup_downloader(roothash, filenames)

    def test_multifile_swift(self):
        filenames = ['video.avi', 'video2.avi']
        roothash = self.setup_seeder(filenames)
        self.setup_downloader(roothash, filenames)

    def test_multifile_swift_with_subdirs(self):
        filenames = ['video.avi', os.path.join('contentdir', 'video.avi')]
        roothash = self.setup_seeder(filenames)
        self.setup_downloader(roothash, filenames)

    def test_zerostate(self):
        tor_col_dir = self.session.get_torrent_collecting_dir()
        filenames = [os.path.join(tor_col_dir, 'video.avi')]
        shutil.copyfile(os.path.join(BASE_DIR, "API", 'video.avi'), filenames[0])

        self.session.set_swift_meta_dir(tor_col_dir)
        roothash = self.setup_seeder(['video.avi'], destdir=tor_col_dir, add_to_session=False)

        # The download needs to be put into the zerostate dir in order for Swift to find it. 
        old_storagepath = filenames[0]
        new_storagepath = os.path.join(tor_col_dir, roothash.encode('hex'))
        try:
            shutil.move(old_storagepath, new_storagepath)
            shutil.move(old_storagepath + '.mhash', new_storagepath + '.mhash')
            shutil.move(old_storagepath + '.mbinmap', new_storagepath + '.mbinmap')
        except:
            print_exc()

        self.setup_downloader(roothash, filenames)

    def test_metadir(self):
        self.session.set_swift_meta_dir(BASE_DIR)
        filenames = ['video.avi']
        self.setup_seeder(filenames)

########NEW FILE########
__FILENAME__ = test_seeding_vod
# Written by Arno Bakker, heavily modified by Niels Zeilemaker
# see LICENSE.txt for license information

import sys
import threading
from Tribler.Test.API.test_seeding import TestSeeding
from Tribler.Core.simpledefs import dlstatus_strings, DLMODE_VOD


class TestVODSeeding(TestSeeding):

    """
    Testing seeding via new tribler API:
    """
    def setUp(self):
        TestSeeding.setUp(self)
        self.vod_event = threading.Event()

    def setup_seeder(self, filename='video.avi'):
        TestSeeding.setup_seeder(self, filename)

    def subtest_download(self):
        self.dscfg2.set_mode(DLMODE_VOD)
        TestSeeding.subtest_download(self)
        assert self.vod_event.wait(60)

    def downloader_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: download:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress(), ds.get_vod_prebuffering_progress()

        if ds.get_progress() > 0:
            self.downloading_event.set()
        if ds.get_vod_prebuffering_progress() == 1.0:
            self.vod_event.set()

        return (1.0, False)

########NEW FILE########
__FILENAME__ = test_tdef
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TODO:
#

import unittest
import os
import tempfile

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Utilities.bencode import bdecode
from Tribler.Core.Utilities.utilities import isValidTorrentFile
from Tribler.Test.test_as_server import BASE_DIR

DEBUG = False

TRACKER = 'http://www.tribler.org/announce'
PLAYTIME = "0:06"
PLAYTIME_SECS = 6  # PLAYTIME in seconds


class TestTorrentDef(unittest.TestCase):

    """
    Testing TorrentDef version 0
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_add_content_file(self):
        self.subtest_add_content_file(merkle=False)
        self.subtest_add_content_file(merkle=True)

    def test_add_content_dir(self):
        self.subtest_add_content_dir(merkle=False)
        self.subtest_add_content_dir(merkle=True)

    def test_add_content_dir_and_file(self):
        self.subtest_add_content_dir_and_file(merkle=False)
        self.subtest_add_content_dir_and_file(merkle=True)

    def test_add_content_file_playtime(self):
        self.subtest_add_content_file_playtime(merkle=False)
        self.subtest_add_content_file_playtime(merkle=True)

    def test_add_content_dir_playtime(self):
        self.subtest_add_content_dir_playtime(merkle=False)
        self.subtest_add_content_dir_playtime(merkle=True)

    def test_add_content_file_thumbnail(self):
        self.subtest_add_content_file_thumbnail(merkle=False)
        self.subtest_add_content_file_thumbnail(merkle=True)

    def test_add_content_announce_list(self):
        self.subtest_add_content_announce_list(merkle=False)
        self.subtest_add_content_announce_list(merkle=True)

    def test_add_content_httpseeds(self):
        self.subtest_add_content_httpseeds(merkle=False)
        self.subtest_add_content_httpseeds(merkle=True)

    def test_add_content_piece_length(self):
        self.subtest_add_content_piece_length(merkle=False)
        self.subtest_add_content_piece_length(merkle=True)

    def test_add_content_file_save(self):
        self.subtest_add_content_file_save(merkle=False)
        self.subtest_add_content_file_save(merkle=True)

    def test_ns_metadata(self):
        dummydata = "HalloWereld"
        t = TorrentDef()
        t.set_metadata(dummydata)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn)
        t.set_tracker(TRACKER)
        t.finalize()

        [handle, filename] = tempfile.mkstemp()
        os.close(handle)
        t.save(filename)

        t2 = TorrentDef.load(filename)
        self.assert_(t2.get_metadata() == dummydata)

    def test_is_private(self):
        privatefn = os.path.join(BASE_DIR, "data", "private.torrent")
        publicfn = os.path.join(BASE_DIR, "data", "bak_single.torrent")

        t1 = TorrentDef.load(privatefn)
        t2 = TorrentDef.load(publicfn)

        self.assert_(t1.is_private() == True)
        self.assert_(t2.is_private() == False)

    def subtest_add_content_file(self, merkle=True):
        """ Add a single file to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn)
        t.set_tracker(TRACKER)
        t.finalize()

        s = os.path.getsize(fn)

        metainfo = t.get_metainfo()
        self.general_check(metainfo)

        self.assert_(metainfo['info']['name'] == "video.avi")
        self.assert_(metainfo['info']['length'] == s)

        """
        bdata = bencode(t.get_metainfo())
        f = open("gen.torrent","wb")
        f.write(bdata)
        f.close()
        """

    def subtest_add_content_dir(self, merkle=True):
        """ Add a single dir to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        dn = os.path.join(BASE_DIR, "API", "contentdir")
        t.add_content(dn, "dirintorrent")
        t.set_tracker(TRACKER)
        t.finalize()

        exps = 0
        for f in os.listdir(dn):
            if f.startswith('.'):
                continue
            p = os.path.join(dn, f)
            s = os.path.getsize(p)
            exps += s
            print "test: expected size", f, s

        print "test: expected total size of files in torrent", exps

        metainfo = t.get_metainfo()
        self.general_check(metainfo)

        self.assert_(metainfo['info']['name'] == 'dirintorrent')
        reals = 0
        for file in metainfo['info']['files']:
            s = file['length']
            print "test: real size", file['path'], s
            reals += s

        print "test: real size of files in torrent", reals

        self.assert_(exps == reals)

    def subtest_add_content_dir_and_file(self, merkle=True):
        """ Add a single dir and single file to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)

        dn = os.path.join(BASE_DIR, "API", "contentdir")
        t.add_content(dn, "dirintorrent")

        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn, os.path.join("dirintorrent", "video.avi"))

        t.set_tracker(TRACKER)
        t.finalize()

        # Check
        exps = os.path.getsize(fn)
        for f in os.listdir(dn):
            if f.startswith('.'):
                continue
            p = os.path.join(dn, f)
            exps += os.path.getsize(p)

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        self.assert_(metainfo['info']['name'] == 'dirintorrent')

        reals = 0
        for file in metainfo['info']['files']:
            reals += file['length']
        self.assert_(exps == reals)

    def subtest_add_content_file_playtime(self, merkle=True):
        """ Add a single file with playtime to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn, playtime=PLAYTIME)
        t.set_tracker(TRACKER)
        t.finalize()

        s = os.path.getsize(os.path.join(BASE_DIR, "API", "video.avi"))

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        self.assert_(metainfo['info']['playtime'] == PLAYTIME)
        azprop = metainfo['azureus_properties']
        content = azprop['Content']
        realspeedbps = content['Speed Bps']
        expspeedbps = s / PLAYTIME_SECS
        self.assert_(realspeedbps == expspeedbps)

    def subtest_add_content_dir_playtime(self, merkle=True):
        """ Add a single dir to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn1 = os.path.join(BASE_DIR, "API", "contentdir", "video.avi")
        fn2 = os.path.join(BASE_DIR, "API", "contentdir", "file.txt")
        t.add_content(fn1, os.path.join("dirintorrent", "video.avi"), playtime=PLAYTIME)
        t.add_content(fn2, os.path.join("dirintorrent", "file.txt"))
        t.set_tracker(TRACKER)
        t.finalize()

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        self.assert_(metainfo['info']['name'] == 'dirintorrent')

        s = os.path.getsize(fn1)

        files = metainfo['info']['files']
        for file in files:
            if file['path'][0] == "video.avi":
                self.assert_(file['playtime'] == PLAYTIME)

        azprop = metainfo['azureus_properties']
        content = azprop['Content']
        realspeedbps = content['Speed Bps']
        expspeedbps = s / PLAYTIME_SECS
        self.assert_(realspeedbps == expspeedbps)

    def subtest_add_content_file_thumbnail(self, merkle=True):
        """ Add a single file with thumbnail to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        thumbfn = os.path.join(BASE_DIR, "API", "thumb.jpg")
        t.add_content(fn)
        t.set_thumbnail(thumbfn)
        t.set_tracker(TRACKER)
        t.finalize()

        f = open(thumbfn, "rb")
        expthumb = f.read()
        f.close()

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        azprop = metainfo['azureus_properties']
        content = azprop['Content']
        realthumb = content['Thumbnail']
        self.assert_(realthumb == expthumb)

    def subtest_add_content_announce_list(self, merkle=True):
        """ Add a single file with announce-list to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn)
        t.set_tracker(TRACKER)
        exphier = [[TRACKER], ['http://tracker1.tribler.org:6969/announce', 'http://tracker2.tribler.org:7070/ann'], ['http://www.cs.vu.nl', 'http://www.st.ewi.tudelft.nl', 'http://www.vuze.com']]
        t.set_tracker_hierarchy(exphier)
        t.finalize()

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        realhier = metainfo['announce-list']
        self.assert_(realhier == exphier)

    def subtest_add_content_httpseeds(self, merkle=True):
        """ Add a single file with BitTornado httpseeds to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn)
        t.set_tracker(TRACKER)
        expseeds = ['http://www.cs.vu.nl/index.html', 'http://www.st.ewi.tudelft.nl/index.html']
        t.set_httpseeds(expseeds)
        t.finalize()

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        realseeds = metainfo['httpseeds']
        self.assert_(realseeds == expseeds)

    def subtest_add_content_piece_length(self, merkle=True):
        """ Add a single file with piece length to a TorrentDef """
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn)
        t.set_piece_length(2 ** 16)
        t.set_tracker(TRACKER)
        t.finalize()

        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        self.assert_(metainfo['info']['piece length'] == 2 ** 16)

    def subtest_add_content_file_save(self, merkle=True):
        """ Add a single file to a TorrentDef and save the latter"""
        t = TorrentDef()
        t.set_create_merkle_torrent(merkle)
        fn = os.path.join(BASE_DIR, "API", "video.avi")
        t.add_content(fn)
        t.set_tracker(TRACKER)
        t.finalize()

        tfn = os.path.join(os.getcwd(), "gen.torrent")
        t.save(tfn)

        f = open(tfn, "rb")
        bdata = f.read()
        f.close()
        os.remove(tfn)

        data = bdecode(bdata)
        metainfo = t.get_metainfo()
        self.general_check(metainfo)
        self.assert_(metainfo == data)

    def general_check(self, metainfo):
        self.assert_(isValidTorrentFile(metainfo))
        self.assert_(metainfo['announce'] == TRACKER)

########NEW FILE########
__FILENAME__ = bak_tribler_sdb
import os
import sys

from traceback import print_exc
from shutil import copy as copyFile, move
from Tribler.Test.test_as_server import FILES_DIR


def init_bak_tribler_sdb(backup='bak_tribler.sdb', destination= 'tribler.sdb', destination_path = FILES_DIR, overwrite = False):
    backup_path = os.path.join(FILES_DIR, backup)
    destination_path = os.path.join(destination_path, destination)

    if not os.path.isfile(backup_path) or overwrite:
        got = extract_db_files(FILES_DIR, backup_path + ".tar.gz", overwrite)
        if not got:
            print >> sys.stderr, "Missing", backup_path + ".tar.gz"
            sys.exit(1)

    for f in os.listdir(FILES_DIR):
        if f.startswith(destination):
            os.remove(os.path.join(FILES_DIR, f))

    if os.path.isfile(backup_path):
        copyFile(backup_path, destination_path)

    return destination_path


def extract_db_files(file_dir, file_name, overwrite=False):
    try:
        import tarfile
        tar = tarfile.open(file_name, 'r|gz')
        for member in tar:
            print "extract file", member
            tar.extract(member)
            dest = os.path.join(file_dir, member.name)
            dest_dir = os.path.dirname(dest)
            if not os.path.isdir(dest_dir):
                os.makedirs(dest_dir)

            if overwrite and os.path.exists(dest):
                os.remove(dest)

            move(member.name, dest)
        tar.close()
        return True
    except:
        print_exc()
        return False

########NEW FILE########
__FILENAME__ = btconn
# Written by Arno Bakker, Jie Yang
# see LICENSE.txt for license information

import socket
import logging
from binascii import b2a_hex
from struct import pack, unpack
from StringIO import StringIO

current_version = 3  # TODO: Fix this temporary hack.
lowest_version = 2

protocol_name = "BitTorrent protocol"
default_option_pattern = '\x00\x00\x00\x00\x00\x30\x00\x00'
overlay_infohash = '\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'


def toint(s):
    return long(b2a_hex(s), 16)


def tobinary(i):
    return (chr(i >> 24) + chr((i >> 16) & 0xFF) +
            chr((i >> 8) & 0xFF) + chr(i & 0xFF))


class BTConnection:

    def __init__(self, hostname, port, opensock=None, user_option_pattern=None, user_infohash=None, myid=None, mylistenport=None, myoversion=None):
        assert user_option_pattern is None or isinstance(user_option_pattern, str)
        assert user_option_pattern is None or len(user_option_pattern) == 8
        assert user_infohash is None or isinstance(user_infohash, str)
        assert user_infohash is None or len(user_infohash) == 20
        assert myid is None or isinstance(myid, str)
        assert myid is None or len(myid) == 20

        self._logger = logging.getLogger(self.__class__.__name__)

        self.hisport = port
        self.buffer = StringIO()
        if mylistenport is None:
            self.myport = 481
        else:
            self.myport = mylistenport
        if myid is None:
            self.myid = "".zfill(20)
            if myoversion is None:
                myoversion = current_version
            self.myid = self.myid[:16] + pack('<H', lowest_version) + pack('<H', myoversion)
            self.myid = self.myid[:14] + pack('<H', self.myport) + self.myid[16:]
        else:
            self.myid = myid
        self.hisid = None

        if opensock:
            self.s = opensock
        else:
            self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.s.connect((hostname, port))
        handshake = chr(len(protocol_name))
        handshake += protocol_name
        if user_option_pattern is None:
            handshake += default_option_pattern
        else:
            handshake += user_option_pattern
        if user_infohash is None:
            self.expected_infohash = overlay_infohash
        else:
            self.expected_infohash = user_infohash
        handshake += self.expected_infohash
        handshake += self.myid
        self._logger.debug(u"btconn: Sending handshake len %d", len(handshake))
        self.s.send(handshake)

    def get_my_id(self):
        return self.myid

    def get_his_id(self):
        return self.hisid

    def get_my_fake_listen_port(self):
        return self.myport

    def read_handshake(self):
        data = self._readn(68)
        assert(data[0] == chr(len(protocol_name)))
        assert(data[1:20] == protocol_name)
        assert(data[28:48] == self.expected_infohash)

        self.hisid = data[48:68]
        hisport = unpack('<H', self.hisid[14:16])[0]
        assert(hisport == self.hisport)
        low_ver = unpack('<H', self.hisid[16:18])[0]
        assert(low_ver == lowest_version)
        cur_ver = unpack('<H', self.hisid[18:20])[0]

        assert(cur_ver == current_version)

    def read_handshake_medium_rare(self, close_ok=False):
        data = self._readn(68)
        if len(data) == 0:
            if close_ok:
                return
            else:
                assert(len(data) > 0)
        assert(data[0] == chr(len(protocol_name)))
        assert(data[1:20] == protocol_name)
        assert(data[28:48] == self.expected_infohash)
        self.hisid = data[48:68]
        # don't check encoded fields

    def close(self):
        self.s.close()

    def send(self, data):
        """ send length-prefixed message """
        self.s.send(tobinary(len(data)))
        self.s.send(data)

    def recv(self):
        """ received length-prefixed message """
        size_data = self._readn(4)
        if len(size_data) == 0:
            return size_data
        size = toint(size_data)
        if size > 10000:
            self._logger.debug("btconn: waiting for message size %d", size)
        if size == 0:
            # BT keep alive message, don't report upwards
            return self.recv()
        else:
            return self._readn(size)

    def _readn(self, n):
        """ read n bytes from socket stream """
        nwant = n
        while True:
            try:
                data = self.s.recv(nwant)
            except socket.error as ex:
                if ex[0] == 10035:
                    # WSAEWOULDBLOCK on Windows
                    continue
                elif ex[0] == 10054:
                    # WSAECONNRESET on Windows
                    self._logger.exception(u"converted to EOF")
                    return ''  # convert to EOF
                else:
                    raise ex
            self._logger.debug(u"_readn got %d bytes", len(data))
            if len(data) == 0:
                # raise socket.error(ECONNRESET,'arno says connection closed')
                return data
            nwant -= len(data)
            self.buffer.write(data)
            if nwant == 0:
                break
        self.buffer.seek(0)
        data = self.buffer.read(n)
        self.buffer.seek(0)
        return data

########NEW FILE########
__FILENAME__ = test_anontunnel_community
# Written by Niels Zeilemaker
# see LICENSE.txt for license information
import os
import sys
import time

from twisted.internet import reactor
from twisted.internet.threads import blockingCallFromThread

from Tribler.Core.simpledefs import dlstatus_strings
from Tribler.Test.test_as_server import TestGuiAsServer, BASE_DIR
from Tribler.dispersy.candidate import Candidate

class TestAnonTunnelCommunity(TestGuiAsServer):

    def test_anon_download(self):
        def take_second_screenshot():
            self.screenshot()
            self.quit()

        def take_screenshot(download_time):
            self.screenshot("After an anonymous libtorrent download (took %.2f s)" % download_time)
            self.guiUtility.ShowPage('anonymity')
            self.Call(1, take_second_screenshot)

        def on_fail(expected, reason, do_assert):
            from Tribler.community.anontunnel.community import ProxyCommunity
            from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr

            dispersy = self.session.lm.dispersy
            ''' :type : Dispersy '''
            proxy_community = next(c for c in dispersy.get_communities() if isinstance(c, ProxyCommunity))

            self.guiUtility.ShowPage('anonymity')

            def do_asserts():
                self.assert_(LibtorrentMgr.getInstance().ltsession_anon is not None, "Anon session should have been created", False)
                self.assert_(len(proxy_community.circuits) >= 4, "At least 4 circuits should have been created", False)
                self.assert_(expected, reason, do_assert)

            self.Call(1, do_asserts)

        def do_create_local_torrent():
            torrentfilename = self.setupSeeder()
            start_time = time.time()
            download = self.guiUtility.frame.startDownload(torrentfilename=torrentfilename, destdir=self.getDestDir(), anon_mode=True)

            self.guiUtility.ShowPage('my_files')
            self.Call(5, lambda: download.add_peer(("127.0.0.1", self.session2.get_listen_port())))
            self.CallConditional(
                150,
                lambda: download.get_progress() == 1.0,
                lambda: take_screenshot(time.time() - start_time),
                'Anonymous download should be finished in 150 seconds',
                on_fail
            )

        self.startTest(do_create_local_torrent)

    def startTest(self, callback, min_timeout=5):
        self.getStateDir()  # getStateDir copies the bootstrap file into the statedir

        from Tribler.community.anontunnel.community import ProxyCommunity, ProxySettings
        def setup_proxies():
            proxy_communities = []
            for i in range(3, 11):
                proxy_communities.append(create_proxy(i))


            # Connect the proxies to the Tribler instance
            for community in self.lm.dispersy.get_communities():
                if isinstance(community, ProxyCommunity):
                    proxy_communities.append(community)

            candidates = []
            for session in self.sessions:
                dispersy = session.get_dispersy_instance()
                candidates.append(Candidate(dispersy.lan_address, tunnel=False))

            for community in proxy_communities:
                for candidate in candidates:
                    # We are letting dispersy deal with addins the community's candidate to itself.
                    community.add_discovered_candidate(candidate)

            callback()

        def create_proxy(index):
            from Tribler.Core.Session import Session
            from Tribler.community.anontunnel import exitstrategies, crypto

            self.setUpPreSession()
            config = self.config.copy()
            config.set_dispersy(True)
            config.set_state_dir(self.getStateDir(index))

            session = Session(config, ignore_singleton=True)
            session.start()
            self.sessions.append(session)

            while not session.lm.initComplete:
                time.sleep(1)

            dispersy = session.get_dispersy_instance()

            def load_community(session):
                keypair = dispersy.crypto.generate_key(u"NID_secp160k1")
                dispersy_member = dispersy.get_member(private_key=dispersy.crypto.key_to_bin(keypair))

                proxy_community = dispersy.define_auto_load(ProxyCommunity, dispersy_member, (None, None), load=True)[0]
                exit_strategy = exitstrategies.DefaultExitStrategy(session.lm.rawserver, proxy_community)
                proxy_community.observers.append(exit_strategy)

                return proxy_community

            return blockingCallFromThread(reactor, load_community, session)

        TestGuiAsServer.startTest(self, setup_proxies)

    def setupSeeder(self):
        from Tribler.Core.Session import Session
        from Tribler.Core.TorrentDef import TorrentDef
        from Tribler.Core.DownloadConfig import DownloadStartupConfig

        self.setUpPreSession()
        self.config.set_libtorrent(True)

        self.config2 = self.config.copy()
        self.config2.set_state_dir(self.getStateDir(2))
        self.session2 = Session(self.config2, ignore_singleton=True)
        self.session2.start()

        tdef = TorrentDef()
        tdef.add_content(os.path.join(BASE_DIR, "data", "video.avi"))
        tdef.set_tracker("http://fake.net/announce")
        tdef.finalize()
        torrentfn = os.path.join(self.session2.get_state_dir(), "gen.torrent")
        tdef.save(torrentfn)

        dscfg = DownloadStartupConfig()
        dscfg.set_dest_dir(os.path.join(BASE_DIR, "data"))  # basedir of the file we are seeding
        d = self.session2.start_download(tdef, dscfg)
        d.set_state_callback(self.seeder_state_callback)

        return torrentfn

    def seeder_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: seeder:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()
        return (5.0, False)

    def setUp(self):
        with open("bootstraptribler.txt", "w") as f:
            f.write("127.0.0.1 1")

        TestGuiAsServer.setUp(self)
        self.sessions = []
        self.session2 = None

    def tearDown(self):
        if self.session2:
            self._shutdown_session(self.session2)

        for session in self.sessions:
            self._shutdown_session(session)

        os.unlink("bootstraptribler.txt")
        time.sleep(10)
        TestGuiAsServer.tearDown(self)

########NEW FILE########
__FILENAME__ = test_as_server
# Written by Arno Bakker, Jie Yang
# Improved and Modified by Niels Zeilemaker
# see LICENSE.txt for license information

import unittest

import os
import sys
import shutil
import time
import gc
import wx
import re
import logging

from traceback import print_exc
from threading import enumerate as enumerate_threads

from Tribler.Core.Session import Session
from Tribler.Core.SessionConfig import SessionStartupConfig
from Tribler.Core.CacheDB.sqlitecachedb import SQLiteCacheDB

from nose.twistedtools import reactor

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__))))
STATE_DIR = os.path.join(BASE_DIR, "test_.Tribler")
DEST_DIR = os.path.join(BASE_DIR, "test_TriblerDownloads")
FILES_DIR = os.path.abspath(os.path.join(BASE_DIR, 'data'))

from Tribler.Core import defaults
defaults.sessdefaults['general']['state_dir'] = STATE_DIR
defaults.sessdefaults['general']['minport'] = -1
defaults.sessdefaults['general']['maxport'] = -1
defaults.sessdefaults['swift']['swifttunnellistenport'] = -1
defaults.sessdefaults['dispersy']['dispersy_port'] = -1

defaults.dldefaults["downloadconfig"]["saveas"] = DEST_DIR

DEBUG = False

OUTPUT_DIR = os.environ.get('OUTPUT_DIR', 'output')

class AbstractServer(unittest.TestCase):

    _annotate_counter = 0

    def setUp(self, annotate=True):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.setUpCleanup()
        self.annotate_dict = {}

        if annotate:
            self.annotate(self._testMethodName, start=True)

    def setUpCleanup(self):
        # Elric: If the files are still there it means that either the last run segfaulted or
        # that there was some kind of lock on those and the tearDown wasn't able to delete them.
        # In either case the test would fail, so just remove the dirs.
        for path in os.listdir(BASE_DIR):
            path = os.path.join(BASE_DIR, path)
            if path.startswith(STATE_DIR) or path.startswith(DEST_DIR):
                shutil.rmtree(unicode(path))

    def tearDown(self, annotate=True):
        self.tearDownCleanup()
        if annotate:
            self.annotate(self._testMethodName, start=False)

    def tearDownCleanup(self):
        self.setUpCleanup()

    def getStateDir(self, nr=0):
        dir = STATE_DIR + (str(nr) if nr else '')
        if not os.path.exists(dir):
            os.mkdir(dir)
        if os.path.isfile("bootstraptribler.txt"):
            shutil.copy("bootstraptribler.txt", os.path.join(dir, "bootstraptribler.txt"))
        return dir

    def getDestDir(self, nr=0):
        dir = DEST_DIR + (str(nr) if nr else '')
        if not os.path.exists(dir):
            os.mkdir(dir)
        return dir

    def annotate(self, annotation, start=True, destdir=OUTPUT_DIR):
        if not os.path.exists(destdir):
            os.makedirs(destdir)

        if start:
            self.annotate_dict[annotation] = time.time()
        else:
            filename = os.path.join(destdir, "annotations.txt")
            if os.path.exists(filename):
                f = open(filename, 'a')
            else:
                f = open(filename, 'w')
                print >> f, "annotation start end"

            AbstractServer._annotate_counter += 1
            _annotation = re.sub('[^a-zA-Z0-9_]', '_', annotation)
            _annotation = '%d_' % AbstractServer._annotate_counter + _annotation

            print >> f, _annotation, self.annotate_dict[annotation], time.time()
            f.close()


class TestAsServer(AbstractServer):

    """
    Parent class for testing the server-side of Tribler
    """

    def setUp(self):
        AbstractServer.setUp(self, annotate=False)
        self.setUpPreSession()

        self.quitting = False

        self.session = Session(self.config)
        self.session.start()

        self.hisport = self.session.get_listen_port()

        while not self.session.lm.initComplete:
            time.sleep(1)

        self.annotate(self._testMethodName, start=True)

    def setUpPreSession(self):
        """ Should set self.config_path and self.config """
        self.config = SessionStartupConfig()
        self.config.set_state_dir(self.getStateDir())
        self.config.set_torrent_checking(False)
        self.config.set_multicast_local_peer_discovery(False)
        self.config.set_megacache(False)
        self.config.set_dispersy(False)
        self.config.set_swift_proc(False)
        self.config.set_mainline_dht(False)
        self.config.set_torrent_collecting(False)
        self.config.set_libtorrent(False)
        self.config.set_dht_torrent_collecting(False)
        self.config.set_videoplayer(False)

    def tearDown(self):
        self.annotate(self._testMethodName, start=False)

        """ unittest test tear down code """
        if self.session is not None:
            self._shutdown_session(self.session)
            Session.del_instance()

        time.sleep(10)
        gc.collect()

        ts = enumerate_threads()
        print >> sys.stderr, "test_as_server: Number of threads still running", len(ts)
        for t in ts:
            print >> sys.stderr, "test_as_server: Thread still running", t.getName(), "daemon", t.isDaemon(), "instance:", t

        if SQLiteCacheDB.hasInstance():
            SQLiteCacheDB.getInstance().close_all()
            SQLiteCacheDB.delInstance()

        AbstractServer.tearDown(self, annotate=False)

    def _shutdown_session(self, session):
        session_shutdown_start = time.time()
        waittime = 60

        session.shutdown()
        while not session.has_shutdown():
            diff = time.time() - session_shutdown_start
            assert diff < waittime, "test_as_server: took too long for Session to shutdown"

            print >> sys.stderr, "test_as_server: ONEXIT Waiting for Session to shutdown, will wait for an additional %d seconds" % (waittime - diff)
            time.sleep(1)

        print >> sys.stderr, "test_as_server: Session is shutdown"

    def assert_(self, boolean, reason=None, do_assert=True):
        if not boolean:
            self.quit()
            assert boolean, reason

    def startTest(self, callback):
        self.quitting = False
        callback()

    def Call(self, seconds, callback):
        if not self.quitting:
            if seconds:
                time.sleep(seconds)
            callback()

    def CallConditional(self, timeout, condition, callback, assertMsg=None, assertCallback=None):
        t = time.time()

        def DoCheck():
            if not self.quitting:
                if time.time() - t < timeout:
                    try:
                        if condition():
                            print >> sys.stderr, "test_as_server: condition satisfied after %d seconds, calling callback '%s'" % (time.time() - t, callback.__name__)
                            callback()
                        else:
                            self.Call(0.5, DoCheck)

                    except:
                        print_exc()
                        self.assert_(False, 'Condition or callback raised an exception, quitting (%s)' % (assertMsg or "no-assert-msg"), do_assert=False)
                else:
                    print >> sys.stderr, "test_as_server: %s, condition was not satisfied in %d seconds (%s)" % ('calling callback' if assertCallback else 'quitting' , timeout, assertMsg or "no-assert-msg")
                    assertcall = assertCallback if assertCallback else self.assert_
                    assertcall(False, assertMsg if assertMsg else "Condition was not satisfied in %d seconds" % timeout, do_assert=False)
        self.Call(0, DoCheck)

    def quit(self):
        self.quitting = True

class TestGuiAsServer(TestAsServer):

    """
    Parent class for testing the gui-side of Tribler
    """

    def setUp(self):
        AbstractServer.setUp(self, annotate=False)

        self.app = wx.GetApp()
        if not self.app:
            self.app = wx.PySimpleApp(redirect=False)

        self.guiUtility = None
        self.frame = None
        self.lm = None
        self.session = None

        self.hadSession = False
        self.quitting = False

        self.asserts = []
        self.annotate(self._testMethodName, start=True)

    def assert_(self, boolean, reason, do_assert=True):
        if not boolean:
            self.screenshot("ASSERT: %s" % reason)
            self.quit()

            self.asserts.append((boolean, reason))

            if do_assert:
                assert boolean, reason

    def startTest(self, callback, min_timeout=5):
        from Tribler.Main.vwxGUI.GuiUtility import GUIUtility
        from Tribler.Main import tribler_main
        tribler_main.ALLOW_MULTIPLE = True

        self.hadSession = False
        starttime = time.time()

        def call_callback():
            took = time.time() - starttime
            if took > min_timeout:
                callback()
            else:
                self.Call(min_timeout - took, callback)

        def wait_for_frame():
            print >> sys.stderr, "tgs: GUIUtility ready, staring to wait for frame to be ready"
            self.frame = self.guiUtility.frame
            self.frame.Maximize()
            self.CallConditional(30, lambda: self.frame.ready, call_callback)

        def wait_for_init():
            print >> sys.stderr, "tgs: lm initcomplete, staring to wait for GUIUtility to be ready"
            self.guiUtility = GUIUtility.getInstance()
            self.CallConditional(30, lambda: self.guiUtility.registered, wait_for_frame)

        def wait_for_guiutility():
            print >> sys.stderr, "tgs: waiting for guiutility instance"
            self.CallConditional(30, lambda: GUIUtility.hasInstance(), wait_for_init)

        def wait_for_instance():
            print >> sys.stderr, "tgs: found instance, staring to wait for lm to be initcomplete"
            self.session = Session.get_instance()
            self.lm = self.session.lm
            self.hadSession = True
            self.CallConditional(30, lambda: self.lm.initComplete, wait_for_guiutility)

        print >> sys.stderr, "tgs: waiting for session instance"
        self.CallConditional(30, Session.has_instance, lambda: TestAsServer.startTest(self, wait_for_instance))

        # modify argv to let tribler think its running from a different directory
        sys.argv = [os.path.abspath('./.exe')]
        tribler_main.run()

        assert self.hadSession, 'Did not even create a session'

    def Call(self, seconds, callback):
        if not self.quitting:
            if seconds:
                wx.CallLater(seconds * 1000, callback)
            elif not wx.Thread_IsMain():
                wx.CallAfter(callback)
            else:
                callback()

    def quit(self):
        if self.frame:
            self.frame.OnCloseWindow()
        else:
            def do_quit():
                self.app.ExitMainLoop()
                wx.WakeUpMainThread()

            self.Call(1, do_quit)
            self.Call(2.5, self.app.Exit)

        self.quitting = True

    def tearDown(self):
        self.annotate(self._testMethodName, start=False)

        """ unittest test tear down code """
        del self.guiUtility
        del self.frame
        del self.lm
        del self.session

        time.sleep(1)
        gc.collect()

        ts = enumerate_threads()
        print >> sys.stderr, "teardown: Number of threads still running", len(ts)
        for t in ts:
            print >> sys.stderr, "teardown: Thread still running", t.getName(), "daemon", t.isDaemon(), "instance:", t

        dhtlog = os.path.join(STATE_DIR, 'pymdht.log')
        if os.path.exists(dhtlog):
            print >> sys.stderr, "teardown: content of pymdht.log"
            f = open(dhtlog, 'r')
            for line in f:
                line = line.strip()
                if line:
                    print >> sys.stderr, line
            f.close()
            print >> sys.stderr, "teardown: finished printing content of pymdht.log"

        AbstractServer.tearDown(self, annotate=False)

        for boolean, reason in self.asserts:
            assert boolean, reason

    def screenshot(self, title=None, destdir=OUTPUT_DIR, window=None):
        try:
            from PIL import Image
        except ImportError:
            self._logger.error("Could not load PIL: not making screenshots")
            return

        if window == None:
            app = wx.GetApp()
            window = app.GetTopWindow()
            if not window:
                self._logger.error("Couldn't obtain top window and no window was passed as argument, bailing out")
                return

        rect = window.GetClientRect()
        size = window.GetSize()
        rect = wx.Rect(rect.x, rect.y, size.x, size.y)

        screen = wx.WindowDC(window)
        bmp = wx.EmptyBitmap(rect.GetWidth(), rect.GetHeight() + 30)

        mem = wx.MemoryDC(bmp)
        mem.Blit(0, 30, rect.GetWidth(), rect.GetHeight(), screen, rect.GetX(), rect.GetY())

        titlerect = wx.Rect(0, 0, rect.GetWidth(), 30)
        mem.DrawRectangleRect(titlerect)
        if title:
            mem.DrawLabel(title, titlerect, wx.ALIGN_CENTER_HORIZONTAL | wx.ALIGN_CENTER_VERTICAL)
        del mem

        myWxImage = wx.ImageFromBitmap(bmp)
        im = Image.new('RGB', (myWxImage.GetWidth(), myWxImage.GetHeight()))
        im.fromstring(myWxImage.GetData())

        if not os.path.exists(destdir):
            os.makedirs(destdir)
        index = 1
        filename = os.path.join(destdir, 'Screenshot-%.2d.png' % index)
        while os.path.exists(filename):
            index += 1
            filename = os.path.join(destdir, 'Screenshot-%.2d.png' % index)
        im.save(filename)

        del bmp

########NEW FILE########
__FILENAME__ = test_gui_dialogs
# written by Niels Zeilemaker
# see LICENSE.txt for license information

import unittest
import wx
import binascii
import os
from threading import Event
from traceback import print_exc

from Tribler.Test.test_as_server import TestGuiAsServer, BASE_DIR

from Tribler.Main.Dialogs.ConfirmationDialog import ConfirmationDialog
from Tribler.Main.Dialogs.AddTorrent import AddTorrent
from Tribler.Main.Dialogs.CreateTorrent import CreateTorrent
from Tribler.Main.Dialogs.SaveAs import SaveAs
from Tribler.Main.Dialogs.RemoveTorrent import RemoveTorrent
from Tribler.Main.vwxGUI.list_item import ChannelListItem
from Tribler.Main.vwxGUI.settingsDialog import SettingsDialog


class TestGuiDialogs(TestGuiAsServer):

    def test_settings_dialog(self):

        def do_assert():
            dialog = wx.FindWindowByName('settingsDialog')
            self.assert_(isinstance(dialog, SettingsDialog), 'could not find SettingsDialog')

            self.screenshot('Screenshot of SettingsDialog', window=dialog)

            saved_event = Event()
            class FakeEvent():
                def __init__(self, event):
                    self.event = event

                def Skip(self):
                    self.event.set()
            try:
                dialog.saveAll(FakeEvent(saved_event))
            except:
                print_exc()
            dialog.EndModal(wx.ID_CANCEL)

            self.assert_(saved_event.is_set(), 'did not save dialog')
            self.Call(1, self.quit)

        def do_settings():
            self.Call(5, do_assert)
            self.frame.top_bg.OnSettings(None)

        self.startTest(do_settings, min_timeout=2)

    def test_remove_dialog(self):
        infohash = binascii.unhexlify('66ED7F30E3B30FA647ABAA19A36E7503AA071535')

        def do_assert():
            dialog = wx.FindWindowByName('RemoveTorrent')
            self.assert_(isinstance(dialog, RemoveTorrent), 'could not find RemoveTorrent')

            self.screenshot('Screenshot of RemoveTorrent', window=dialog)
            self.Call(1, lambda: dialog.EndModal(wx.ID_CANCEL))
            self.Call(2, self.quit)

        def item_shown_in_list():
            self.Call(1, do_assert)
            self.frame.librarylist.Select(infohash)
            self.frame.top_bg.OnDelete()

        def download_object_ready():
            self.CallConditional(10, lambda: infohash in self.frame.librarylist.list.items, item_shown_in_list, 'no download in librarylist')

        def do_downloadfromfile():
            self.guiUtility.showLibrary()
            self.frame.startDownload(os.path.join(BASE_DIR, "data", "Pioneer.One.S01E06.720p.x264-VODO.torrent"), self.getDestDir())

            self.CallConditional(30, lambda: self.session.get_download(infohash), download_object_ready)

        self.startTest(do_downloadfromfile)

    def test_save_dialog(self):
        def do_assert(add_dialog):
            dialog = wx.FindWindowByName('SaveAsDialog')
            self.assert_(isinstance(dialog, SaveAs), 'could not find SaveAs')

            self.screenshot('Screenshot of SaveAs', window=dialog)
            self.Call(1, lambda: dialog.EndModal(wx.ID_CANCEL))
            self.Call(2, lambda: add_dialog.EndModal(wx.ID_CANCEL))
            self.Call(3, self.quit)

        def do_save_dialog():
            dialog = wx.FindWindowByName('AddTorrentDialog')
            self.assert_(isinstance(dialog, AddTorrent), 'could not find AddTorrent')

            self.Call(1, lambda: do_assert(dialog))
            dialog.magnet.SetValue(r'http://torrent.fedoraproject.org/torrents/Fedora-20-i386-DVD.torrent')
            dialog.OnAdd(None)

        def do_add_dialog():
            self.guiUtility.utility.write_config('showsaveas', 1)

            self.Call(1, do_save_dialog)
            self.frame.top_bg.OnAdd(None)

        self.startTest(do_add_dialog)

    def test_feedbackdialog(self):
        def do_assert():
            dialog = wx.FindWindowByName('FeedbackWindow')
            self.assert_(isinstance(dialog, wx.Dialog), 'could not find FeedbackWindow')

            self.screenshot('Screenshot of FeedbackWindow', window=dialog)
            self.Call(1, lambda: dialog.EndModal(wx.ID_CANCEL))
            self.Call(2, self.quit)

        def do_error():
            self.Call(1, do_assert)
            try:
                raise RuntimeError("Unit-testing")

            except Exception, e:
                self.guiUtility.utility.app.onError(e)

        self.startTest(do_error, min_timeout=10)

    def test_add_save_create_dialog(self):
        def do_assert_create(add_dialog):
            dialog = wx.FindWindowByName('CreateTorrentDialog')
            self.assert_(isinstance(dialog, CreateTorrent), 'could not find CreateTorrent')

            self.screenshot('Screenshot of CreateTorrent', window=dialog)
            self.Call(1, lambda: dialog.EndModal(wx.ID_CANCEL))
            self.Call(2, lambda: add_dialog.EndModal(wx.ID_CANCEL))
            self.Call(3, self.quit)

        def do_assert_add():
            self.Call(1, lambda: do_assert_create(dialog))

            dialog = wx.FindWindowByName('AddTorrentDialog')
            self.assert_(isinstance(dialog, AddTorrent), 'could not find AddTorrent')

            self.screenshot('Screenshot of AddTorrent', window=dialog)
            dialog.OnCreate(None)

        def do_add_dialog():
            self.Call(1, do_assert_add)

            managefiles = self.managechannel.fileslist
            managefiles.OnAdd(None)

        def do_create():
            self.managechannel = self.frame.managechannel

            self.managechannel.name.SetValue('UNITTEST')
            self.managechannel.description.SetValue('Channel created for UNITTESTING purposes')

            self.managechannel.Save()

            self.CallConditional(60, lambda: self.frame.managechannel.channel, do_add_dialog, 'Channel instance did not arrive at managechannel')

        def disable_dispersy():
            from Tribler.dispersy.endpoint import NullEndpoint

            dispersy = self.session.get_dispersy_instance()
            dispersy._endpoint = NullEndpoint()
            dispersy._endpoint.open(dispersy)

            self.guiUtility.ShowPage('mychannel')
            self.Call(1, do_create)

        self.startTest(disable_dispersy)

    def test_confirmationdialog(self):
        def do_assert():
            dialog = wx.FindWindowByName('MFdialog')
            self.assert_(isinstance(dialog, ConfirmationDialog), 'could not find ConfirmationDialog')

            self.screenshot('Screenshot of ConfirmationDialog', window=dialog)
            self.Call(1, lambda: dialog.EndModal(wx.ID_CANCEL))
            self.Call(2, self.quit)

        def do_mark(item):
            self.assert_(isinstance(item, ChannelListItem), 'do_mark called without a ChannelListItem')

            self.Call(10, do_assert)
            self.guiUtility.MarkAsFavorite(None, item.original_data)

        def do_favorite():
            self.assert_(self.frame.searchlist.GetNrChannels() > 0, 'no channels')

            items = self.frame.searchlist.GetItems()
            for _, item in items.iteritems():
                if isinstance(item, ChannelListItem):
                    do_mark(item)
                    break
            else:
                self.assert_(False, 'could not find ChannelListItem')

        def do_search():
            items = self.frame.channellist.GetItems()
            if items:
                do_mark(items.itervalues().next())
            else:
                self.guiUtility.dosearch(u'mp3')
                self.Call(10, do_favorite)

        def wait_for_channel():
            def has_connections_or_channel():
                if self.frame.SRstatusbar.GetChannelConnections() > 10:
                    return True
                if self.frame.channellist.GetItems():
                    return True

                self.frame.channellist.GetManager().refresh()
                return False

            self.CallConditional(300, has_connections_or_channel, do_search, 'did not connect to more than 10 peers within 300s')

        self.startTest(wait_for_channel)

    def test_debugframe(self):
        def do_screenshot(dialog):
            self.screenshot('Screenshot of DispersyDebugFrame', window=dialog)

            self.Call(1, dialog.Destroy)
            self.Call(2, self.quit)

        def do_screenshot_tab():
            dialog = wx.FindWindowByName('DispersyDebugFrame')
            self.assert_(isinstance(dialog, wx.Frame), 'could not find DispersyDebugFrame')

            self.screenshot('Screenshot of DispersyDebugFrame', window=dialog)

            dialog.SwitchTab(1)
            self.Call(1, lambda: do_screenshot(dialog))

        def do_error():
            self.frame.OnOpenDebugFrame()
            self.Call(20, do_screenshot_tab)

        self.startTest(do_error, min_timeout=5)

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_gui_general
# see LICENSE.txt for license information

import unittest

from Tribler.Test.test_as_server import TestGuiAsServer

class TestGuiGeneral(TestGuiAsServer):

    def test_debugpanel(self):
        def do_assert():
            self.assert_(self.guiUtility.guiPage == 'stats', 'Debug page is not selected')
            self.screenshot('After selecting debug page')
            self.quit()

        def do_page():
            self.guiUtility.ShowPage('stats')
            self.Call(10, do_assert)

        self.startTest(do_page)

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_gui_server
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TODO: integrate with test_TimedTaskQueue

import unittest
from time import sleep

from Tribler.Main.Dialogs.GUITaskQueue import GUITaskQueue

DEBUG = False
class TestGUITaskQueue(unittest.TestCase):

    def setUp(self):
        self.ntasks = 0
        self.completed = []
        self.guiserver = GUITaskQueue()

    def tearDown(self):
        sleep(2)
        self.completed.sort()
        if self.completed != range(self.ntasks):
            if DEBUG:
                print "test failed", self.completed
            self.assert_(False)

        self.guiserver.shutdown()
        GUITaskQueue.delInstance()

    def test_simple(self):
        self.ntasks = 1

        self.guiserver.add_task(lambda: self.task(0), 0)

    def test_more(self):
        self.ntasks = 10

        for i in range(self.ntasks):
            # lambda functions are evil, this is not the same as lambda:task(i)
            self.guiserver.add_task(self.define_task(i), 0)

    def test_delay(self):
        self.ntasks = 1

        self.guiserver.add_task(lambda: self.task(0), 3)
        if DEBUG:
            print "test: sleeping 5 secs so tasks get executed"
        sleep(5)

    def test_delay2(self):
        self.ntasks = 2

        self.guiserver.add_task(lambda: self.task(1), 3)
        self.guiserver.add_task(lambda: self.task(0), 1)
        if DEBUG:
            print "test: sleeping 5 secs so tasks get executed"
        sleep(5)

    def define_task(self, num):
        return lambda: self.task(num)

    def task(self, num):
        if DEBUG:
            print "Running task", num
        self.completed.append(num)

########NEW FILE########
__FILENAME__ = test_libtorrent_download
# see LICENSE.txt for license information

import unittest
import os
from time import time

import binascii
from Tribler.Test.test_as_server import TestGuiAsServer, BASE_DIR

DEBUG = True


class TestLibtorrentDownload(TestGuiAsServer):

    def test_downloadfromfile(self):
        infohash = binascii.unhexlify('66ED7F30E3B30FA647ABAA19A36E7503AA071535')

        def make_screenshot():
            self.screenshot('After starting a libtorrent download from file')
            self.quit()

        def item_shown_in_list():
            self.CallConditional(30, lambda: self.frame.librarylist.list.GetItem(infohash).original_data.ds and self.frame.librarylist.list.GetItem(infohash).original_data.ds.progress > 0, make_screenshot, 'no download progress')

        def download_object_ready():
            self.CallConditional(10, lambda: self.frame.librarylist.list.HasItem(infohash), item_shown_in_list, 'no download in librarylist')

        def do_downloadfromfile():
            self.guiUtility.showLibrary()
            self.frame.startDownload(os.path.join(BASE_DIR, "data", "Pioneer.One.S01E06.720p.x264-VODO.torrent"), self.getDestDir())

            self.CallConditional(30, lambda: self.session.get_download(infohash), download_object_ready)

        self.startTest(do_downloadfromfile)

    def test_downloadfromurl(self):
        infohash = binascii.unhexlify('8C3760CB651C863861FA9ABE2EF70246943C1994')

        def make_screenshot():
            self.screenshot('After starting a libtorrent download from url')
            self.quit()

        def item_shown_in_list():
            self.CallConditional(30, lambda: self.frame.librarylist.list.GetItem(infohash).original_data.ds and self.frame.librarylist.list.GetItem(infohash).original_data.ds.progress > 0, make_screenshot, 'no download progress')

        def download_object_ready():
            self.CallConditional(10, lambda: self.frame.librarylist.list.HasItem(infohash), item_shown_in_list, 'no download in librarylist')

        def do_downloadfromurl():
            self.guiUtility.showLibrary()
            self.frame.startDownloadFromUrl(r'http://torrent.fedoraproject.org/torrents/Fedora-Live-Desktop-x86_64-19.torrent', self.getDestDir())

            self.CallConditional(30, lambda: self.session.get_download(infohash), download_object_ready)

        self.startTest(do_downloadfromurl)

    def test_downloadfrommagnet(self):
        infohash = binascii.unhexlify('5ac55cf1b935291f6fc92ad7afd34597498ff2f7')

        def make_screenshot():
            self.screenshot('After starting a libtorrent download from magnet')
            self.quit()

        def item_shown_in_list():
            self.CallConditional(60, lambda: self.frame.librarylist.list.GetItem(infohash).original_data.ds and self.frame.librarylist.list.GetItem(infohash).original_data.ds.progress > 0, make_screenshot, 'no download progress')

        def download_object_ready():
            self.CallConditional(10, lambda: self.frame.librarylist.list.HasItem(infohash), item_shown_in_list, 'no download in librarylist')

        def do_downloadfrommagnet():
            self.guiUtility.showLibrary()
            self.frame.startDownloadFromMagnet(r'magnet:?xt=urn:btih:5ac55cf1b935291f6fc92ad7afd34597498ff2f7&dn=Pioneer+One+S01E01+Xvid-VODO&title=', self.getDestDir())

            self.CallConditional(30, lambda: self.session.get_download(infohash), download_object_ready)

        self.startTest(do_downloadfrommagnet)

    def test_stopresumedelete(self):
        infohash = binascii.unhexlify('8C3760CB651C863861FA9ABE2EF70246943C1994')

        def do_final():
            self.screenshot('After deleting a libtorrent download')
            self.quit()

        def do_deletedownload():
            self.screenshot('After resuming a libtorrent download')

            self.frame.librarylist.list.Select(infohash)
            self.frame.top_bg.OnDelete(silent=True)
            self.CallConditional(10, lambda: not self.frame.librarylist.list.HasItem(infohash), lambda: self.Call(1, do_final), 'download not deleted')

        def do_resume():
            self.screenshot('After stopping a libtorrent download')

            self.frame.librarylist.list.Select(infohash)
            self.frame.top_bg.OnResume()
            self.CallConditional(10, lambda: 'stopped' not in self.frame.librarylist.list.GetItem(infohash).original_data.state, do_deletedownload, 'download not resumed')

        def do_stop():
            self.screenshot('After starting a libtorrent download')

            self.frame.librarylist.list.Select(infohash)
            self.frame.top_bg.OnStop()
            self.CallConditional(10, lambda : 'stopped' in self.frame.librarylist.list.GetItem(infohash).original_data.state, do_resume, 'download not stopped')

        def item_shown_in_list():
            self.CallConditional(30, lambda: self.frame.librarylist.list.GetItem(infohash).original_data.ds and self.frame.librarylist.list.GetItem(infohash).original_data.ds.progress > 0, do_stop, 'no download progress')

        def download_object_ready():
            self.CallConditional(10, lambda: self.frame.librarylist.list.HasItem(infohash), item_shown_in_list, 'no download in librarylist')

        def do_start():
            self.guiUtility.showLibrary()
            self.frame.startDownloadFromUrl(r'http://torrent.fedoraproject.org/torrents/Fedora-Live-Desktop-x86_64-19.torrent', self.getDestDir())
            self.CallConditional(60, lambda: self.session.get_download(infohash), download_object_ready)

        self.startTest(do_start)

    def test_playdownload(self):
        t = time()

        def take_screenshot(buffer_complete):
            self.screenshot("After streaming a libtorrent download (buffering took %.2f s)" % (buffer_complete - t))
            self.quit()

        def check_playlist():
            from Tribler.Core.Video.VideoPlayer import VideoPlayer
            from Tribler.Core.Video.utils import videoextdefaults

            buffer_complete = time()

            d = VideoPlayer.getInstance().get_vod_download()
            videofiles = []
            for filename in d.get_def().get_files():
                _, ext = os.path.splitext(filename)
                if ext.startswith('.'):
                    ext = ext[1:]
                if ext in videoextdefaults:
                    videofiles.append(filename)

            playlist = self.guiUtility.frame.actlist.expandedPanel_videoplayer

            do_check = lambda: len(playlist.links) == len(videofiles) and \
                               playlist.tdef.get_id() == VideoPlayer.getInstance().get_vod_download().get_def().get_id() and \
                               playlist.fileindex == VideoPlayer.getInstance().get_vod_fileindex()

            self.CallConditional(10, do_check, lambda: self.Call(5, lambda: take_screenshot(buffer_complete)), "playlist set incorrectly")

        def do_monitor():
            from Tribler.Core.Video.VideoPlayer import VideoPlayer

            self.screenshot('After starting a VOD download')
            self.CallConditional(60, lambda: VideoPlayer.getInstance().vod_playing, check_playlist, "streaming did not start")

        def do_vod():
            from Tribler.Core.Video.VideoPlayer import VideoPlayer

            self.frame.startDownload(os.path.join(BASE_DIR, "data", "Pioneer.One.S01E06.720p.x264-VODO.torrent"), self.getDestDir(), selectedFiles=[os.path.join('Sample', 'Pioneer.One.S01E06.720p.x264.Sample-VODO.mkv')], vodmode=True)
            self.guiUtility.ShowPlayer()
            self.CallConditional(30, lambda: VideoPlayer.getInstance().get_vod_download(), do_monitor, "VOD download not found")

        self.startTest(do_vod)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_magnetlink
# Written by Boudewijn Schoon
# see LICENSE.txt for license information

from binascii import hexlify
import socket
import os
import sys
import threading
import libtorrent as lt

from Tribler.Test.test_as_server import TestAsServer, BASE_DIR
from btconn import BTConnection
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Utilities.bencode import bencode, bdecode, sloppy_bdecode
from Tribler.Core.MessageID import EXTEND
from Tribler.Core.simpledefs import dlstatus_strings, DLSTATUS_SEEDING
from Tribler.Core.Libtorrent.LibtorrentMgr import LibtorrentMgr
from unittest.case import skip

DEBUG = True


class MagnetHelpers:

    def __init__(self, tdef):
        # the metadata that we will transfer
        infodata = bencode(tdef.get_metainfo()["info"])
        self.metadata_list = [infodata[index:index + 16 * 1024] for index in xrange(0, len(infodata), 16 * 1024)]
        assert len(self.metadata_list) > 100, "We need multiple pieces to test!"
        self.metadata_size = len(infodata)

    def create_good_extend_handshake(self):
        payload = {"m": {"ut_metadata": 3}, "metadata_size": self.metadata_size}
        return EXTEND + chr(0) + bencode(payload)

    def create_good_extend_metadata_request(self, metadata_id, piece):
        payload = {"msg_type": 0, "piece": piece}
        return EXTEND + chr(metadata_id) + bencode(payload)

    def create_good_extend_metadata_reply(self, metadata_id, piece):
        payload = {"msg_type": 1, "piece": piece, "total_size": len(self.metadata_list[piece])}
        return EXTEND + chr(metadata_id) + bencode(payload) + self.metadata_list[piece]

    def metadata_id_from_extend_handshake(self, data):
        assert data[0] == chr(0)
        d = bdecode(data[1:])
        assert isinstance(d, dict)
        assert 'm' in d.keys()
        m = d['m']
        assert isinstance(m, dict)
        assert "ut_metadata" in m.keys()
        val = m["ut_metadata"]
        assert isinstance(val, int)
        return val

    def read_extend_handshake(self, conn):
        response = conn.recv()
        self.assert_(len(response) > 0)
        # print >>sys.stderr,"test: Got reply", getMessageName(response[0])
        self.assert_(response[0] == EXTEND)
        return self.metadata_id_from_extend_handshake(response[1:])

    def read_extend_metadata_request(self, conn):
        while True:
            response = conn.recv()
            assert len(response) > 0
            # print >>sys.stderr,"test: Got data", getMessageName(response[0])
            if response[0] == EXTEND:
                break

        assert response[0] == EXTEND
        assert ord(response[1]) == 3

        payload = bdecode(response[2:])
        assert "msg_type" in payload
        assert payload["msg_type"] == 0
        assert "piece" in payload
        assert isinstance(payload["piece"], int)

        return payload["piece"]

    def read_extend_metadata_reply(self, conn, piece):
        while True:
            response = conn.recv()
            assert len(response) > 0
            # print >>sys.stderr,"test: Got data", getMessageName(response[0])
            if response[0] == EXTEND:
                break

        assert response[0] == EXTEND
        assert ord(response[1]) == 3

        payload, length = sloppy_bdecode(response[2:])
        assert payload["msg_type"] == 1
        assert payload["piece"] == piece
        if "data" in payload:
            assert payload["data"] == self.metadata_list[piece]
        else:
            assert response[2 + length:] == self.metadata_list[piece]

    def read_extend_metadata_reject(self, conn, piece):
        while True:
            response = conn.recv()
            assert len(response) > 0
            # print >>sys.stderr,"test: Got reject", getMessageName(response[0])
            if response[0] == EXTEND:
                break

        assert response[0] == EXTEND
        assert ord(response[1]) == 3

        payload, length = sloppy_bdecode(response[2:])
        assert payload["msg_type"] in (1, 2), [payload, response[2:2 + length]]
        assert payload["piece"] == piece, [payload, response[2:2 + length]]

        # some clients return msg_type 1, unfortunately this is not a reject but a proper response.
        # instead libtorrent warns: max outstanding piece requests reached
        if payload["msg_type"] == 1:
            assert response[2 + length:] == self.metadata_list[piece]

        # some clients return msg_type 2, we must make sure no "data" is given (i.e. the request was
        # rejected)
        if payload["msg_type"] == 2:
            assert payload["piece"] == piece, [payload, response[2:2 + length]]
            assert not "data" in payload, [payload, response[2:2 + length]]

    def read_extend_metadata_close(self, conn):
        """
        No extend metadata messages may be send and the connection
        needs to close.
        """
        conn.s.settimeout(10.0)
        while True:
            response = conn.recv()
            if len(response) == 0:
                break
            assert not (response[0] == EXTEND and response[1] == 3)

class TestMagnet(TestAsServer):

    def setUpPreSession(self):
        TestAsServer.setUpPreSession(self)
        self.config.set_libtorrent(True)

    def test_good_transfer(self):
        def do_transfer():
            def torrentdef_retrieved(tdef):
                print tdef.get_metainfo()
                event.set()

            event = threading.Event()
            assert TorrentDef.retrieve_from_magnet('magnet:?xt=urn:btih:5ac55cf1b935291f6fc92ad7afd34597498ff2f7&dn=Pioneer+One+S01E01+Xvid-VODO&title=', torrentdef_retrieved, timeout=120)
            assert event.wait(120)


        self.startTest(do_transfer)

class TestMagnetFakePeer(TestAsServer, MagnetHelpers):

    """
    A MiniBitTorrent instance is used to connect to BitTorrent clients
    and download the info part from the metadata.
    """
    def setUp(self):
        # listener for incoming connections from MiniBitTorrent
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.bind(("", self.session.get_listen_port()))
        self.server.listen(5)

        TestAsServer.setUp(self)

        # the metadata that we want to transfer
        self.tdef = TorrentDef()
        self.tdef.add_content(os.path.join(BASE_DIR, "API", "video.avi"))
        self.tdef.set_tracker("http://fake.net/announce")
        # we use a small piece length to obtain multiple pieces
        self.tdef.set_piece_length(1)
        self.tdef.finalize()

        MagnetHelpers.__init__(self, self.tdef)

    def setUpPreSession(self):
        TestAsServer.setUpPreSession(self)
        self.config.set_libtorrent(True)

    def create_good_url(self, infohash=None, title=None, tracker=None):
        url = "magnet:?xt=urn:btih:"
        if infohash:
            assert isinstance(infohash, str)
            url += hexlify(infohash)
        else:
            url += hexlify(self.tdef.get_infohash())
        if title:
            assert isinstance(title, str)
            url += "&dn=" + title
        if tracker:
            assert isinstance(tracker, str)
            url += "&tr=" + tracker
        return url

    @skip("not working, seems to return binary data")
    def test_good_transfer(self):
        def torrentdef_retrieved(tdef):
            tags["retrieved"].set()
            tags["metainfo"] = tdef.get_metainfo()

        tags = {"retrieved": threading.Event()}

        assert TorrentDef.retrieve_from_magnet(self.create_good_url(), torrentdef_retrieved, timeout=60)

        def do_supply():
            # supply fake addresses (regular dht obviously wont work here)
            ltmgr = LibtorrentMgr.getInstance()
            for infohash in ltmgr.metainfo_requests:
                handle = ltmgr.ltsession.find_torrent(lt.big_number(infohash.decode('hex')))
                handle.connect_peer(("127.0.0.1", self.session.get_listen_port()), 0)
        self.session.lm.rawserver.add_task(do_supply, delay=5.0)

        # accept incoming connection
        # self.server.settimeout(10.0)
        sock, address = self.server.accept()
        assert sock, "No incoming connection"

        # handshakes
        conn = BTConnection(address[0], address[1], opensock=sock, user_infohash=self.tdef.get_infohash())
        conn.send(self.create_good_extend_handshake())
        conn.read_handshake_medium_rare()
        metadata_id = self.read_extend_handshake(conn)

        # serve pieces
        for counter in xrange(len(self.metadata_list)):
            piece = self.read_extend_metadata_request(conn)
            assert 0 <= piece < len(self.metadata_list)
            conn.send(self.create_good_extend_metadata_reply(metadata_id, piece))

        # no more metadata request may be send and the connection must
        # be closed
        self.read_extend_metadata_close(conn)

        assert tags["retrieved"].wait(5)
        assert tags["metainfo"]["info"] == self.tdef.get_metainfo()["info"]


class TestMetadataFakePeer(TestAsServer, MagnetHelpers):

    """
    Once we are downloading a torrent, our client should respond to
    the ut_metadata extention message.  This allows other clients to
    obtain the info part of the metadata from us.
    """
    def setUp(self):
        TestAsServer.setUp(self)

        # the metadata that we want to transfer
        self.tdef = TorrentDef()
        self.tdef.add_content(os.path.join(BASE_DIR, "API", "file.wmv"))
        self.tdef.set_tracker("http://fake.net/announce")
        # we use a small piece length to obtain multiple pieces
        self.tdef.set_piece_length(1)
        self.tdef.finalize()
        self.setup_seeder()

        MagnetHelpers.__init__(self, self.tdef)

    def setUpPreSession(self):
        TestAsServer.setUpPreSession(self)
        self.config.set_libtorrent(True)

        self.config2 = self.config.copy()
        self.config2.set_state_dir(self.getStateDir(2))

    def tearDown(self):
        self.teardown_seeder()
        TestAsServer.tearDown(self)

    def setup_seeder(self):
        self.seeder_setup_complete = threading.Event()

        self.dscfg = DownloadStartupConfig()
        self.dscfg.set_dest_dir(os.path.join(BASE_DIR, "API"))
        self.download = self.session.start_download(self.tdef, self.dscfg)
        self.download.set_state_callback(self.seeder_state_callback)

        assert self.seeder_setup_complete.wait(30)

    def teardown_seeder(self):
        self.session.remove_download(self.download)

    def seeder_state_callback(self, ds):
        if ds.get_status() == DLSTATUS_SEEDING:
            self.seeder_setup_complete.set()

        d = ds.get_download()
        print >> sys.stderr, "test: seeder:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()
        return (1.0, False)

    def test_good_request(self):
        conn = BTConnection("localhost", self.session.get_listen_port(), user_infohash=self.tdef.get_infohash())
        conn.send(self.create_good_extend_handshake())
        conn.read_handshake_medium_rare()
        metadata_id = self.read_extend_handshake(conn)

        # request metadata block 0, 2, 3, and the last
        conn.send(self.create_good_extend_metadata_request(metadata_id, 0))
        conn.send(self.create_good_extend_metadata_request(metadata_id, 2))
        conn.send(self.create_good_extend_metadata_request(metadata_id, 3))
        conn.send(self.create_good_extend_metadata_request(metadata_id, len(self.metadata_list) - 1))

        self.read_extend_metadata_reply(conn, 0)
        self.read_extend_metadata_reply(conn, 2)
        self.read_extend_metadata_reply(conn, 3)
        self.read_extend_metadata_reply(conn, len(self.metadata_list) - 1)

    def test_good_flood(self):
        conn = BTConnection("localhost", self.session.get_listen_port(), user_infohash=self.tdef.get_infohash())
        conn.send(self.create_good_extend_handshake())
        conn.read_handshake_medium_rare()
        metadata_id = self.read_extend_handshake(conn)

        for counter in xrange(len(self.metadata_list) * 2):
            piece = counter % len(self.metadata_list)
            conn.send(self.create_good_extend_metadata_request(metadata_id, piece))

            if counter > len(self.metadata_list):
                self.read_extend_metadata_reject(conn, piece)
            else:
                self.read_extend_metadata_reply(conn, piece)

    def test_bad_request(self):
        self.bad_request_and_disconnect({"msg_type": 0, "piece": len(self.metadata_list)})
        self.bad_request_and_disconnect({"msg_type": 0, "piece":-1})
        self.bad_request_and_disconnect({"msg_type": 0, "piece": "1"})
        self.bad_request_and_disconnect({"msg_type": 0, "piece": [1, 2]})
        self.bad_request_and_disconnect({"msg_type": 0, "PIECE": 1})

    def bad_request_and_disconnect(self, payload):
        conn = BTConnection("localhost", self.session.get_listen_port(), user_infohash=self.tdef.get_infohash())
        conn.send(self.create_good_extend_handshake())
        conn.read_handshake_medium_rare()
        metadata_id = self.read_extend_handshake(conn)

        conn.send(EXTEND + chr(metadata_id) + bencode(payload))
        self.read_extend_metadata_close(conn)

########NEW FILE########
__FILENAME__ = test_merkle
# Written by Arno Bakker
# see LICENSE.txt for license information

import unittest

from tempfile import mkstemp
import os
from types import StringType, DictType
from math import ceil, log
from traceback import print_exc
import sha

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Merkle.merkle import MerkleTree, \
    get_tree_height, create_tree, get_hashes_for_piece
from Tribler.Core.Utilities.bencode import bdecode


DEBUG = False


class TestMerkleHashes(unittest.TestCase):

    """
    Testing Simple Merkle Hashes extension version 0, in particular:
    * The algorithmic part
    * The .torrent file part
    See test_merkle_msg.py for protocol testing.
    """

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_get_hashes_for_piece(self):
        """
            test MerkleTree.get_hashes_for_piece() method
        """
        self._test_123pieces_tree_get_hashes()
        self._test_8piece_tree_uncle_calc()

    def _test_123pieces_tree_get_hashes(self):
        for n in range(1, 64):
            piece_size = 2 ** n
            self._test_1piece_tree_get_hashes(piece_size, piece_size)
            for add in [1, piece_size - 1]:
                self._test_1piece_tree_get_hashes(piece_size, add)
                self._test_2piece_tree_get_hashes(piece_size, add)
                self._test_3piece_tree_get_hashes(piece_size, add)

    def _test_1piece_tree_get_hashes(self, piece_size, length_add):
        """ testing get_hashes_for_piece on tree with 1 piece """
        msg = "1piece_get_hashes(" + str(piece_size) +","+str(length_add)+") failed"
        npieces = 1
        total_length = length_add

        piece_hashes = ['\x01\x02\x03\x04\x05\x06\x07\x08\x07\x06\x05\x04\x03\x02\x01\x00\x01\x02\x03\x04'] * npieces
        tree = MerkleTree(piece_size, total_length, None, piece_hashes)
        for p in range(npieces):
            ohlist = tree.get_hashes_for_piece(p)
            self.assert_(len(ohlist) == 1, msg)
            self.assert_(ohlist[0][0] == 0, msg)
            self.assertEquals(ohlist[0][1], piece_hashes[0], msg)

    def _test_2piece_tree_get_hashes(self, piece_size, length_add):
        """testing get_hashes_for_piece on tree with 2 pieces """
        msg = "2piece_get_hashes(" + str(piece_size) +","+str(length_add)+") failed"
        npieces = 2
        total_length = piece_size + length_add

        piece_hashes = ['\x01\x02\x03\x04\x05\x06\x07\x08\x07\x06\x05\x04\x03\x02\x01\x00\x01\x02\x03\x04'] * npieces
        tree = MerkleTree(piece_size, total_length, None, piece_hashes)
        for p in range(npieces):
            ohlist = tree.get_hashes_for_piece(p)
            self.assert_(len(ohlist) == 3)
            ohlist.sort()
            self.assert_(ohlist[0][0] == 0, msg)
            self.assert_(ohlist[1][0] == 1, msg)
            self.assert_(ohlist[2][0] == 2, msg)
            self.assertDigestEquals(ohlist[1][1] + ohlist[2][1], ohlist[0][1], msg)

    def _test_3piece_tree_get_hashes(self, piece_size, length_add):
        """ testing get_hashes_for_piece on tree with 3 pieces """
        msg = "3piece_get_hashes(" + str(piece_size) +","+str(length_add)+") failed"
        npieces = 3
        total_length = 2 * piece_size +length_add

        piece_hashes = ['\x01\x02\x03\x04\x05\x06\x07\x08\x07\x06\x05\x04\x03\x02\x01\x00\x01\x02\x03\x04'] * npieces
        tree = MerkleTree(piece_size, total_length, None, piece_hashes)
        for p in range(npieces):
            ohlist = tree.get_hashes_for_piece(p)
            self.assert_(len(ohlist) == 4, msg)
            ohlist.sort()
            if p == 0 or p == 1:
                self.assert_(ohlist[0][0] == 0, msg)
                self.assert_(ohlist[1][0] == 2, msg)
                self.assert_(ohlist[2][0] == 3, msg)
                self.assert_(ohlist[3][0] == 4, msg)
                digest34 = self.calc_digest(ohlist[2][1] + ohlist[3][1])
                self.assertDigestEquals(digest34 + ohlist[1][1], ohlist[0][1], msg)
            else:
                self.assert_(ohlist[0][0] == 0, msg)
                self.assert_(ohlist[1][0] == 1, msg)
                self.assert_(ohlist[2][0] == 5, msg)
                self.assert_(ohlist[3][0] == 6, msg)
                digest56 = self.calc_digest(ohlist[2][1] + ohlist[3][1])
                self.assertDigestEquals(ohlist[1][1] + digest56, ohlist[0][1], msg)

    def assertDigestEquals(self, data, digest, msg=None):
        self.assertEquals(self.calc_digest(data), digest, msg)

    def calc_digest(self, data):
        digester = sha.new(data)
        return digester.digest()

    def _test_8piece_tree_uncle_calc(self):
        npieces = 8
        hashlist = self.get_indices_for_piece(0, npieces)
        assert hashlist == [7, 8, 4, 2, 0]

        hashlist = self.get_indices_for_piece(1, npieces)
        assert hashlist == [8, 7, 4, 2, 0]

        hashlist = self.get_indices_for_piece(2, npieces)
        assert hashlist == [9, 10, 3, 2, 0]

        hashlist = self.get_indices_for_piece(3, npieces)
        assert hashlist == [10, 9, 3, 2, 0]

        hashlist = self.get_indices_for_piece(4, npieces)
        assert hashlist == [11, 12, 6, 1, 0]

        hashlist = self.get_indices_for_piece(5, npieces)
        assert hashlist == [12, 11, 6, 1, 0]

        hashlist = self.get_indices_for_piece(6, npieces)
        assert hashlist == [13, 14, 5, 1, 0]

        hashlist = self.get_indices_for_piece(7, npieces)
        assert hashlist == [14, 13, 5, 1, 0]

    def get_indices_for_piece(self, index, npieces):
        height = get_tree_height(npieces)
        tree = create_tree(height)
        ohlist = get_hashes_for_piece(tree, height, index)
        list = []
        for oh in ohlist:
            list.append(oh[0])
        return list

    def test_check_hashes_update_hash_admin(self):
        """
            test MerkleTree.check_hashes() and update_hash_admin() methods
        """
        for n in range(1, 64):
            piece_size = 2 ** n
            for add in [1, piece_size - 1]:
                self._test_3piece_tree_check_hashes_update_hash_admin(piece_size, add)

    def _test_3piece_tree_check_hashes_update_hash_admin(self, piece_size, length_add):
        """ testing check_hashes and update_hash_admin tree with 3 pieces """
        msg = "3piece_check_hashes(" + str(piece_size) +","+str(length_add)+") failed"
        npieces = 3
        total_length = 2 * piece_size +length_add

        piece_hashes = ['\x01\x02\x03\x04\x05\x06\x07\x08\x07\x06\x05\x04\x03\x02\x01\x00\x01\x02\x03\x04'] * npieces
        fulltree = MerkleTree(piece_size, total_length, None, piece_hashes)
        root_hash = fulltree.get_root_hash()
        emptytree = MerkleTree(piece_size, total_length, root_hash, None)
        empty_piece_hashes = [0] * npieces

        for p in range(npieces):
            ohlist = fulltree.get_hashes_for_piece(p)
            self.assert_(emptytree.check_hashes(ohlist), msg)

        for p in range(npieces):
            ohlist = fulltree.get_hashes_for_piece(p)
            self.assert_(emptytree.check_hashes(ohlist), msg)
            emptytree.update_hash_admin(ohlist, empty_piece_hashes)

        for p in range(npieces):
            self.assert_(piece_hashes[p] == empty_piece_hashes[p], msg)

    def test_merkle_torrent(self):
        """
            test the creation of Merkle torrent files via TorrentMaker/btmakemetafile.py
        """
        piece_size = 2 ** 18
        for file_size in [1, piece_size - 1, piece_size, piece_size +1, 2*piece_size, (2*piece_size)+1]:
            self.create_merkle_torrent(file_size, piece_size)

    def create_merkle_torrent(self, file_size, piece_size):
        try:
            # 1. create file
            [handle, datafilename] = mkstemp()
            os.close(handle)
            block = "".zfill(file_size)
            fp = open(datafilename, "wb")
            fp.write(block)
            fp.close()
            torrentfilename = datafilename + '.tribe'

            # 2. Set torrent args
            tdef = TorrentDef()
            tdef.set_tracker("http://localhost:6969/announce")
            tdef.set_create_merkle_torrent(True)
            tdef.set_piece_length(int(log(piece_size, 2)))

            # 3. create Merkle torrent
            # make_meta_file(datafilename,url,params,flag,dummy_progress,1,dummy_filecallback)
            tdef.add_content(datafilename)
            tdef.finalize()
            tdef.save(torrentfilename)

            # 4. read Merkle torrent
            fp = open(torrentfilename, "rb")
            data = fp.read(10000)
            fp.close()

            # 5. test Merkle torrent
            # basic tests
            dict = bdecode(data)
            self.assert_(isinstance(dict, DictType))
            self.assert_('info' in dict)
            info = dict['info']
            self.assert_(isinstance(info, DictType))
            self.assert_('pieces' not in info)
            self.assert_('root hash' in info)
            roothash = info['root hash']
            self.assert_(isinstance(roothash, StringType))
            self.assert_(len(roothash) == 20)

            # create hash tree
            hashes = self.read_and_calc_hashes(datafilename, piece_size)
            npieces = len(hashes)
            if DEBUG:
                print "npieces is", npieces
            height = log(npieces, 2) + 1
            if height > int(height):
                height += 1
            height = int(height)
            if DEBUG:
                print "height is", height

            starto = (2 ** (height - 1)) -1

            if DEBUG:
                print "starto is", starto
            tree = [0] * ((2 ** (height)) - 1)
            if DEBUG:
                print "len tree is", len(tree)
            # put hashes in tree
            for i in range(len(hashes)):
                o = starto + i
                tree[o] = hashes[i]

            # fill unused
            nplaces = (2 ** height) - (2 ** (height -1))
            xso = starto + npieces
            xeo = starto + nplaces
            for o in range(xso, xeo):
                tree[o] = '\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'

            # calc higher level ones
            if height > 1:
                for o in range(len(tree) - starto -2, -1, -1):
                    co = self.get_child_offset(o, height)
                    if DEBUG:
                        print "offset is", o, "co is", co
                    data = tree[co] + tree[co +1]
                    digest = self.calc_digest(data)
                    tree[o] = digest
            self.assert_(tree[0], roothash)
        except Exception as e:
            print_exc()
        # finally:
        #    os.remove(datafilename)
        #    os.remove(torrentfilename)

    def read_and_calc_hashes(self, filename, piece_size):
        hashes = []
        fp = open(filename, "rb")
        while True:
            block = fp.read(piece_size)
            if len(block) == 0:
                break
            digest = self.calc_digest(block)
            hashes.append(digest)
            if len(block) != piece_size:
                break
        fp.close()
        return hashes

    def get_child_offset(self, offset, height):
        if DEBUG:
            print "get_child(", offset, ",", height, ")"
        if offset == 0:
            level = 1
        else:
            level = log(offset, 2)
            if level == int(level):
                level += 1
            else:
                level = ceil(level)
            level = int(level)
        starto = (2 ** (level - 1)) -1
        diffo = offset - starto
        diffo *= 2
        cstarto = (2 ** level) - 1
        return cstarto + diffo


def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(TestMerkleHashes))

    return suite

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_merkle_msg
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TODO: we download from Tribler
#

import unittest
import os
import sys
import time
import socket
from binascii import b2a_hex
from sha import sha
from traceback import print_exc
from types import DictType, StringType, IntType, ListType
from M2Crypto import Rand

from Tribler.Test.test_as_server import TestAsServer
from btconn import BTConnection
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Utilities.bencode import bencode, bdecode
from Tribler.Core.Utilities.bitfield import Bitfield
from Tribler.Core.MessageID import REQUEST, UNCHOKE, HAVE, INTERESTED, \
    NOT_INTERESTED, EXTEND, BITFIELD, HASHPIECE, getMessageName
from Tribler.Core.Merkle.merkle import MerkleTree

DEBUG = True

def toint(s):
    return long(b2a_hex(s), 16)

def tobinary(i):
    return (chr(i >> 24) + chr((i >> 16) & 0xFF) +
            chr((i >> 8) & 0xFF) + chr(i & 0xFF))


class TestMerkleMessage(TestAsServer):

    """
    Testing Merkle hashpiece messages for both:
    * Merkle BEP style
    * old Tribler <= 4.5.2 that did not use the Extention protocol (BEP 10).

    See BitTornado/BT1/Connecter.py
    """

    def setUp(self):
        """ override TestAsServer """
        TestAsServer.setUp(self)
        print >> sys.stderr, "test: Giving Session time to startup"
        time.sleep(5)
        print >> sys.stderr, "test: Session should have started up"

    def setUpPreSession(self):
        """ override TestAsServer """
        TestAsServer.setUpPreSession(self)
        self.config.set_megacache(False)

    def setUpPostSession(self):
        """ override TestAsServer """
        TestAsServer.setUpPostSession(self)

        # Let Tribler start downloading an non-functioning torrent, so
        # we can talk to a normal download engine.
        self.tdef = TorrentDef()
        self.sourcefn = os.path.join(os.getcwd(), "API", "video2.wmv")
        self.tdef.add_content(self.sourcefn)
        self.tdef.set_create_merkle_torrent(True)
        self.tdef.set_tracker("http://127.0.0.1:12/announce")
        self.tdef.finalize()

        self.torrentfn = os.path.join(self.session.get_state_dir(), "gen.torrent")
        self.tdef.save(self.torrentfn)

        dscfg = self.setUpDownloadConfig()

        self.session.start_download(self.tdef, dscfg)

        self.infohash = self.tdef.get_infohash()
        self.mylistenport = 4810

        self.numpieces = (self.tdef.get_length() + self.tdef.get_piece_length() - 1) / self.tdef.get_piece_length()
        b = Bitfield(self.numpieces)
        for i in range(self.numpieces):
            b[i] = True
        self.assert_(b.complete())
        self.seederbitfieldstr = b.tostring()

        # piece_hashes = ['\x01\x02\x03\x04\x05\x06\x07\x08\x07\x06\x05\x04\x03\x02\x01\x00\x01\x02\x03\x04' ] * npieces
        # Construct Merkle tree
        tdef2 = TorrentDef()
        tdef2.add_content(self.sourcefn)
        tdef2.set_create_merkle_torrent(False)
        tdef2.set_tracker("http://127.0.0.1:12/announce")
        tdef2.set_piece_length(self.tdef.get_piece_length())
        tdef2.finalize()
        metainfo = tdef2.get_metainfo()

        piecesstr = metainfo['info']['pieces']
        print >> sys.stderr, "test: pieces has len", len(piecesstr)
        piece_hashes = []
        for i in range(0, len(piecesstr), 20):
            hash = piecesstr[i:i + 20]
            print >> sys.stderr, "test: piece", i / 20, "hash", repr(hash)
            piece_hashes.append(hash)

        print >> sys.stderr, "test: Putting", len(piece_hashes), "into MerkleTree, size", self.tdef.get_piece_length(), tdef2.get_piece_length()

        self.tree = MerkleTree(self.tdef.get_piece_length(), self.tdef.get_length(), None, piece_hashes)

        f = open(self.sourcefn, "rb")
        piece1 = f.read(2 ** 18)
        piece2 = f.read(2 ** 18)
        print >> sys.stderr, "read piece1", len(piece1)
        print >> sys.stderr, "read piece2", len(piece2)
        f.close()
        hash1 = sha(piece1).digest()
        hash2 = sha(piece2).digest()
        print >> sys.stderr, "hash piece1", repr(hash1)
        print >> sys.stderr, "hash piece2", repr(hash2)
        f2 = open("piece1.bin", "wb")
        f2.write(piece2)
        f2.close()

    def setUpDownloadConfig(self):
        dscfg = DownloadStartupConfig()
        print >> sys.stderr, "test: Downloading to", self.config_path
        dscfg.set_dest_dir(self.config_path)
        dscfg.set_breakup_seed_bitfield(False)

        return dscfg

    def tearDown(self):
        TestAsServer.tearDown(self)
        try:
            os.remove('piece1.bin')
        except:
            pass

    def singtest_good_hashpiece_bepstyle(self):
        self.subtest_good_hashpiece(False)

    def singtest_good_hashpiece_oldstyle(self):
        self.subtest_good_hashpiece(True)

    def singtest_good_request_bepstyle(self):
        # Let Session download file first
        self.subtest_good_hashpiece(False)
        # Now connect as different peer and download
        print >> sys.stderr, "\n\ntest: test_good_request: STARTING"
        self._test_good_request()

    def singtest_bad_hashpiece_bepstyle(self):
        self.subtest_bad_hashpiece(False)

    def singtest_bad_hashpiece_oldstyle(self):
        self.subtest_bad_hashpiece(True)

    #
    # Good hashpiece message
    #
    def subtest_good_hashpiece(self, oldstyle):
        print >> sys.stderr, "test: Testing good hashpiece, oldstyle", oldstyle
        if oldstyle:
            self._test_good(self.create_good_hashpiece, oldstyle, self.create_good_tribler_extend_hs, infohash=self.infohash)
        else:
            options = '\x00\x00\x00\x00\x00\x10\x00\x00'
            self._test_good(self.create_good_hashpiece, oldstyle, self.create_good_nontribler_extend_hs, options=options, infohash=self.infohash)

    def _test_good(self, msg_gen_func, oldstyle, extend_hs_gen_func, options=None, infohash=None):
        if options is None and infohash is None:
            s = BTConnection('localhost', self.hisport)
        elif options is None:
            s = BTConnection('localhost', self.hisport, user_infohash=infohash)
        elif infohash is None:
            s = BTConnection('localhost', self.hisport, user_option_pattern=options)
        else:
            s = BTConnection('localhost', self.hisport, user_option_pattern=options, user_infohash=infohash)
        print >> sys.stderr, "test: test_good: Create EXTEND HS"
        msg = extend_hs_gen_func()
        print >> sys.stderr, "test: test_good: Sending EXTEND HS", repr(msg)
        s.send(msg)
        print >> sys.stderr, "test: test_good: Waiting for BT HS"
        s.read_handshake_medium_rare()

        # Tribler should send an EXTEND message back
        try:
            print >> sys.stderr, "test: Waiting for reply"
            s.s.settimeout(10.0)
            resp = s.recv()
            self.assert_(len(resp) > 0)
            print >> sys.stderr, "test: Got reply", getMessageName(resp[0])
            self.assert_(resp[0] == EXTEND)
            self.check_tribler_extend_hs(resp[1:])

            # 1. Pretend we're seeder: send BITFIELD and UNCHOKE
            msg = BITFIELD + self.seederbitfieldstr
            s.send(msg)
            msg = UNCHOKE
            s.send(msg)
            print >> sys.stderr, "test: Pretend we are seeder"
            while True:
                resp = s.recv()
                self.assert_(len(resp) > 0)
                print >> sys.stderr, "test: Got reply2", getMessageName(resp[0])
                self.assert_(resp[0] == REQUEST or resp[0] == INTERESTED or resp[0] == UNCHOKE or resp[0] == HAVE or resp[0] == NOT_INTERESTED)
                if resp[0] == REQUEST:
                    chunkid = self.check_request(resp)

                    # 2. Reply to REQUEST with HASHPIECE (oldstyle) or Tr_hashpiece
                    msg = msg_gen_func(oldstyle, chunkid)
                    s.send(msg)
                elif resp[0] == NOT_INTERESTED:
                    break

            # s.close()
        except socket.timeout:
            print >> sys.stderr, "test: Timeout, bad, peer didn't reply in time"
            self.assert_(False)

        destfn = os.path.join(self.config_path, "video2.wmv")
        sf = open(self.sourcefn, "rb")
        df = open(destfn, "rb")
        n = self.tdef.get_piece_length()
        while True:
            sdata = sf.read(n)
            if len(sdata) == 0:
                break
            ddata = df.read(n)
            self.assert_(sdata == ddata)

        time.sleep(3)
        s.close()

    def create_good_nontribler_extend_hs(self):
        """ Merkle BEP style """
        d = {}
        d['m'] = {'Tr_hashpiece': 250}
        d['p'] = self.mylistenport
        d['v'] = 'TestSweet 1.2.3.4'
        bd = bencode(d)
        return EXTEND + chr(0) + bd

    def create_good_tribler_extend_hs(self):
        """ old Tribler style """
        d = {}
        d['m'] = {'Tr_OVERLAYSWARM': 253}
        d['p'] = self.mylistenport
        d['v'] = 'Tribler 3.5.1'
        bd = bencode(d)
        return EXTEND + chr(0) + bd

    def check_tribler_extend_hs(self, data):
        self.assert_(data[0] == chr(0))
        d = bdecode(data[1:])
        self.assert_(isinstance(d, DictType))
        self.assert_('m' in d.keys())
        m = d['m']
        self.assert_(isinstance(m, DictType))
        self.assert_('Tr_hashpiece' in m.keys())
        val = m['Tr_hashpiece']
        self.assert_(isinstance(val, IntType))
        self.assert_(val == 250)

    def check_request(self, data):
        index = toint(data[1:5])
        begin = toint(data[5:9])
        length = toint(data[9:])
        return (index, begin, length)

    def create_good_hashpiece(self, oldstyle, chunkid):
        index, begin, length = chunkid
        if begin == 0:
            ohlist = self.tree.get_hashes_for_piece(index)
        else:
            ohlist = []

        chunk = self.read_chunk(index, begin, length)
        bohlist = bencode(ohlist)

        print >> sys.stderr, "test: create_good_hashpiece:", index, begin, length, "==len", len(chunk)

        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        if oldstyle:
            msg = HASHPIECE + payload
        else:
            # Offical: use the msg ID he defined in his handshake
            msg = EXTEND + HASHPIECE + payload
        return msg

    def read_chunk(self, index, begin, length):
        offset = index * self.tdef.get_piece_length() + begin
        f = open(self.sourcefn, "rb")
        f.seek(offset)
        chunk = f.read(length)
        f.close()
        return chunk

    #
    # Test whether Tribler sends good Tr_hashpiece on our requests
    #
    def _test_good_request(self):
        options = '\x00\x00\x00\x00\x00\x10\x00\x00'
        myid = Rand.rand_bytes(20)

        s = BTConnection('localhost', self.hisport, user_option_pattern=options, user_infohash=self.infohash, myid=myid)
        msg = self.create_good_nontribler_extend_hs()
        s.send(msg)
        s.read_handshake_medium_rare()

        # Tribler should send an EXTEND message back
        try:
            print >> sys.stderr, "test: Waiting for reply"
            s.s.settimeout(10.0)
            resp = s.recv()
            self.assert_(len(resp) > 0)
            print >> sys.stderr, "test: Got reply", getMessageName(resp[0])
            self.assert_(resp[0] == EXTEND)
            self.check_tribler_extend_hs(resp[1:])

            # 1. Pretend we're leecher: send INTERESTED
            msg = INTERESTED
            s.send(msg)
            print >> sys.stderr, "test: Pretend we are leecher"
            while True:
                resp = s.recv()
                self.assert_(len(resp) > 0)
                print >> sys.stderr, "test: Got reply2", getMessageName(resp[0])
                if resp[0] == EXTEND:
                    print >> sys.stderr, "test: Got EXTEND type", getMessageName(resp[1])
                self.assert_(resp[0] == UNCHOKE or resp[0] == BITFIELD or resp[0] == EXTEND or resp[0] == HAVE)
                if resp[0] == UNCHOKE:
                    # 2. Reply with REQUESTs
                    for index in range(0, self.numpieces):
                        plen = self.get_piece_length(index)

                        for begin in range(0, plen, 2 ** 14):
                            length = self.get_chunk_length(index, begin)
                            print >> sys.stderr, "RETRIEVE", index, begin, length
                            chunkid = (index, begin, length)
                            msg = self.create_request(chunkid)
                            s.send(msg)

                    # s.send(NOT_INTERESTED)

                elif resp[0] == EXTEND and resp[1] == HASHPIECE:
                    done = self.check_hashpiece(resp)
                    if done:
                        break
                elif resp[0] == BITFIELD:
                    self.check_bitfield(resp)

            # s.close()
        except socket.timeout:
            print >> sys.stderr, "test: Timeout, bad, peer didn't reply in time"
            self.assert_(False)

        time.sleep(3)
        s.close()

    def get_piece_length(self, index):
        if index == (self.numpieces - 1):
            plen = self.tdef.get_length() % self.tdef.get_piece_length()
        else:
            plen = self.tdef.get_piece_length()
        return plen

    def get_chunk_length(self, index, begin):
        plen = self.get_piece_length(index)
        length = 2 ** 14
        if index == (self.numpieces - 1):
            if (begin + 2 ** 14) > plen:
                length = plen - begin
        return length

    def create_request(self, chunkid):
        index, begin, length = chunkid
        return REQUEST + tobinary(index) + tobinary(begin) + tobinary(length)

    def check_hashpiece(self, resp):
        """ Merkle BEP style """
        print >> sys.stderr, "test: good_request: check_hashpiece"
        self.assert_(resp[0] == EXTEND)
        self.assert_(resp[1] == HASHPIECE)
        index = toint(resp[2:2 + 4])
        begin = toint(resp[6:6 + 4])
        ohlen = toint(resp[10:10 + 4])
        print >> sys.stderr, "test: good_request: check_hashpiece", index, begin, ohlen
        bohlist = resp[14:14 + ohlen]
        hisohlist = bdecode(bohlist)
        hischunk = resp[14 + ohlen:]

        if begin == 0:
            self.assert_(isinstance(hisohlist, ListType))
            for oh in hisohlist:
                self.assert_(isinstance(oh, ListType))
                self.assert_(len(oh) == 2)
                self.assert_(isinstance(oh[0], IntType))
                self.assert_(isinstance(oh[1], StringType))

            hisohlist.sort()
            print >> sys.stderr, "test: good_request: check_hashpiece", repr(hisohlist)
            myohlist = self.tree.get_hashes_for_piece(index)
            myohlist.sort()

            self.assert_(len(hisohlist) == len(myohlist))
            for i in range(0, len(hisohlist)):
                hisoh = hisohlist[i]
                myoh = myohlist[i]
                self.assert_(hisoh == myoh)
        else:
            self.assert_(len(hisohlist) == 0)

        mylength = self.get_chunk_length(index, begin)
        mychunk = self.read_chunk(index, begin, mylength)

        self.assert_(hischunk == mychunk)

        return index == self.numpieces - 1 and mylength != 2 ** 14

    def check_bitfield(self, data):
        self.assert_(data[0] == BITFIELD)
        bitmap = data[1:]
        self.assert_(len(bitmap) == 1)
        # Must have set_breakup_seed_bitfield() set to False
        self.assert_(bitmap == '\xc0')

    #
    # Bad EXTEND handshake message
    #
    def subtest_bad_hashpiece(self, oldstyle):
        if not oldstyle:
            # Test becomes equivalent to BT keep alive message (len 0, payload '')
            self._test_bad(self.create_empty, oldstyle)
        self._test_bad(self.create_ext_id_not_byte, oldstyle)
        self._test_bad(self.create_not_hashpiece, oldstyle)
        self._test_bad(self.create_not_index, oldstyle)
        self._test_bad(self.create_not_begin, oldstyle)
        self._test_bad(self.create_not_len_bohlist, oldstyle)
        self._test_bad(self.create_ohlist_not_bdecodable, oldstyle)
        self._test_bad(self.create_ohlist_wrong_no_hashes, oldstyle)
        self._test_bad(self.create_ohlist_wrong_no_root_hash, oldstyle)
        self._test_bad(self.create_ohlist_wrong_bad_offset, oldstyle)
        self._test_bad(self.create_ohlist_wrong_bad_hash, oldstyle)
        # TODO: need working peer kicking for that
        # self._test_bad(self.create_bad_chunk,oldstyle)

    #
    # Main test code for bad EXTEND handshake messages
    #
    def _test_bad(self, msg_gen_func, oldstyle):
        print >> sys.stderr, "test: test_BAD: Create EXTEND HS", repr(msg_gen_func), oldstyle
        if oldstyle:
            options = None
            exthsmsg = self.create_good_tribler_extend_hs()
        else:
            options = '\x00\x00\x00\x00\x00\x10\x00\x00'
            exthsmsg = self.create_good_nontribler_extend_hs()

        s = BTConnection('localhost', self.hisport, user_option_pattern=options, user_infohash=self.infohash)
        s.send(exthsmsg)
        s.read_handshake_medium_rare()

        # Tribler should send an EXTEND message back
        try:
            print >> sys.stderr, "test: Waiting for reply"
            s.s.settimeout(10.0)
            resp = s.recv()
            self.assert_(len(resp) > 0)
            print >> sys.stderr, "test: Got reply", getMessageName(resp[0])
            self.assert_(resp[0] == EXTEND)
            self.check_tribler_extend_hs(resp[1:])

            # 1. Pretend we're seeder: send BITFIELD and UNCHOKE
            msg = BITFIELD + self.seederbitfieldstr
            s.send(msg)
            msg = UNCHOKE
            s.send(msg)
            print >> sys.stderr, "test: Pretend we are seeder"
            while True:
                resp = s.recv()
                self.assert_(len(resp) > 0)
                print >> sys.stderr, "test: Got reply 2", getMessageName(resp[0])
                self.assert_(resp[0] == REQUEST or resp[0] == INTERESTED or resp[0] == UNCHOKE or resp[0] == HAVE or resp[0] == NOT_INTERESTED)
                if resp[0] == REQUEST:
                    chunkid = self.check_request(resp)

                    # 2. Reply to REQUEST with *bad* HASHPIECE
                    msg = msg_gen_func(chunkid)
                    if oldstyle:
                        if len(msg) == 1:
                            msg = ''
                        else:
                            msg = msg[1:]  # Strip EXTEND byte
                    s.send(msg)
                    break

            # s.close()
        except socket.timeout:
            print >> sys.stderr, "test: Timeout, bad, peer didn't reply in time"
            self.assert_(False)

        time.sleep(3)
        # Should have closed the connection
        try:
            s.send(UNCHOKE)
            self.assert_(False)
        except:
            print_exc()

        s.close()

    #
    # Bad message creators (all create Merkle BEP style, I strip first byte
    # later for oldstyle
    #
    def create_empty(self, chunkid):
        return EXTEND

    def create_ext_id_not_byte(self, chunkid):
        return EXTEND + 'Hallo kijkbuiskinderen'

    def create_not_hashpiece(self, chunkid):
        index, begin, length = chunkid
        ohlist = []
        bohlist = bencode(ohlist)
        chunk = self.read_chunk(index, begin, length)
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + chr(231) + payload

    def create_not_index(self, chunkid):
        payload = 'bla'
        return EXTEND + HASHPIECE + payload

    def create_not_begin(self, chunkid):
        index, begin, length = chunkid
        payload = tobinary(index) + 'bla'
        return EXTEND + HASHPIECE + payload

    def create_not_len_bohlist(self, chunkid):
        index, begin, length = chunkid
        payload = tobinary(index) + tobinary(begin) + 'bla'
        return EXTEND + HASHPIECE + payload

    def create_ohlist_not_bdecodable(self, chunkid):
        index, begin, length = chunkid
        bohlist = 'bla'
        chunk = '*' * (2 ** 14)
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + HASHPIECE + payload

    def create_ohlist_wrong_no_hashes(self, chunkid):
        index, begin, length = chunkid
        ohlist = [(0, '#' * 20), (1, '$' * 20)]  # should contain 3 for file2.wmv: own, sibling and root
        bohlist = bencode(ohlist)
        chunk = '*' * (2 ** 14)
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + HASHPIECE + payload

    def create_ohlist_wrong_no_root_hash(self, chunkid):
        index, begin, length = chunkid
        ohlist = self.tree.get_hashes_for_piece(index)
        newohlist = []
        # Remove root hash
        for oh in ohlist:
            if oh[0] != 0:
                newohlist.append(oh)
        ohlist = newohlist
        bohlist = bencode(ohlist)
        chunk = self.read_chunk(index, begin, length)
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + HASHPIECE + payload

    def create_ohlist_wrong_bad_offset(self, chunkid):
        index, begin, length = chunkid
        ohlist = self.tree.get_hashes_for_piece(index)
        ohlist[1][0] = 481
        bohlist = bencode(ohlist)
        chunk = self.read_chunk(index, begin, length)
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + HASHPIECE + payload

    def create_ohlist_wrong_bad_hash(self, chunkid):
        index, begin, length = chunkid
        ohlist = self.tree.get_hashes_for_piece(index)
        ohlist[1][1] = '$' * 20
        bohlist = bencode(ohlist)
        chunk = self.read_chunk(index, begin, length)
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + HASHPIECE + payload

    def create_bad_chunk(self, chunkid):
        index, begin, length = chunkid
        ohlist = self.tree.get_hashes_for_piece(index)
        bohlist = bencode(ohlist)
        chunk = '*' * length
        payload = tobinary(index) + tobinary(begin) + tobinary(len(bohlist)) + bohlist + chunk
        return EXTEND + HASHPIECE + payload


def test_suite():
    suite = unittest.TestSuite()
    # We should run the tests in a separate Python interpreter to prevent
    # problems with our singleton classes, e.g. PeerDB, etc.
    if len(sys.argv) != 2:
        print "Usage: python test_merkle_msg.py <method name>"
    else:
        suite.addTest(TestMerkleMessage(sys.argv[1]))

    return suite


def main():
    unittest.main(defaultTest='test_suite', argv=[sys.argv[0]])

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = test_metadata_community
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import os
import sys
import json
import time

from Tribler.Test.test_as_server import TestGuiAsServer, BASE_DIR

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.simpledefs import dlstatus_strings

DEBUG = True

class TestMetadataCommunity(TestGuiAsServer):

    def test_add_metadata(self):

        def do_overview():
            self.screenshot('Resulting metadata')
            self.quit()

        def do_modifications(torrentfilename):
            infohash = TorrentDef.load(torrentfilename).get_infohash()

            self.frame.librarylist.Select(infohash)
            torrent = self.guiUtility.torrentsearch_manager.getTorrentByInfohash(infohash)

            def check_for_modifications():
                modifications = self.guiUtility.torrentsearch_manager.getTorrentModifications(torrent)
                videoinfo_valid = False
                swiftthumbnails_valid = False
                for modification in modifications:
                    if modification.name == 'swift-thumbs' and modification.value:
                        swiftthumbnails_valid = True
                    if modification.name == 'video-info' and modification.value:
                        videoinfo_dict = json.loads(modification.value)
                        if videoinfo_dict['duration'] and videoinfo_dict['resolution']:
                            videoinfo_valid = (videoinfo_dict['resolution'] == [640, 480]) and (videoinfo_dict['duration'] == 6)

                return videoinfo_valid and swiftthumbnails_valid
            self.CallConditional(10, check_for_modifications, lambda: self.Call(5, do_overview), 'No valid channel modifications received')

        def do_thumbnails(torrentfilename):
            thumb_dir = os.path.join(self.session.get_torrent_collecting_dir(), 'thumbs-8bb88a02da691636a7ed929b87d467f24700e490')
            self.CallConditional(120, lambda: os.path.isdir(thumb_dir) and len(os.listdir(thumb_dir)) > 0, lambda: do_modifications(torrentfilename), 'No thumbnails were created')

        def do_download_torrent(torrentfilename):
            download = self.guiUtility.frame.startDownload(torrentfilename=torrentfilename, destdir=self.getDestDir())

            self.guiUtility.ShowPage('my_files')
            self.Call(5, lambda: download.add_peer(("127.0.0.1", self.session2.get_listen_port())))
            self.CallConditional(10, lambda: download.get_progress() == 1.0, lambda: do_thumbnails(torrentfilename), 'Failed to download torrent in time')

        def do_create_local_torrent():
            torrentfilename = self.setupSeeder()
            do_download_torrent(torrentfilename)

        self.startTest(do_create_local_torrent)

    def startTest(self, callback):

        def get_and_modify_dispersy():
            from Tribler.dispersy.endpoint import NullEndpoint

            print >> sys.stderr, "tgs: frame ready, replacing dispersy endpoint"
            dispersy = self.session.get_dispersy_instance()
            dispersy._endpoint = NullEndpoint()
            dispersy._endpoint.open(dispersy)

            callback()

        TestGuiAsServer.startTest(self, get_and_modify_dispersy)

    def setupSeeder(self):
        from Tribler.Core.Session import Session
        from Tribler.Core.TorrentDef import TorrentDef
        from Tribler.Core.DownloadConfig import DownloadStartupConfig

        self.setUpPreSession()
        self.config.set_libtorrent(True)

        self.config2 = self.config.copy()
        self.session2 = Session(self.config2, ignore_singleton=True)
        self.session2.start()

        tdef = TorrentDef()
        tdef.add_content(os.path.join(BASE_DIR, "data", "video.avi"))
        tdef.set_tracker("http://fake.net/announce")
        tdef.finalize()
        torrentfn = os.path.join(self.session.get_state_dir(), "gen.torrent")
        tdef.save(torrentfn)

        dscfg = DownloadStartupConfig()
        dscfg.set_dest_dir(os.path.join(BASE_DIR, "data"))  # basedir of the file we are seeding
        d = self.session2.start_download(tdef, dscfg)
        d.set_state_callback(self.seeder_state_callback)

        return torrentfn

    def seeder_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, "test: seeder:", repr(d.get_def().get_name()), dlstatus_strings[ds.get_status()], ds.get_progress()
        return (5.0, False)

    def setUp(self):
        TestGuiAsServer.setUp(self)
        self.session2 = None

    def tearDown(self):
        if self.session2:
            self._shutdown_session(self.session2)
            time.sleep(10)

        TestGuiAsServer.tearDown(self)

########NEW FILE########
__FILENAME__ = test_miscutils

from Tribler.Core.APIImplementation.miscutils import parse_playtime_to_secs

assert parse_playtime_to_secs("0") == 0
assert parse_playtime_to_secs("0.1") == 0
assert parse_playtime_to_secs("1:00") == 60
assert parse_playtime_to_secs("1:0.3") == 60
assert parse_playtime_to_secs("10:00") == 600
assert parse_playtime_to_secs("10:56:11") == 39371
assert parse_playtime_to_secs("10:56:11.77") == 39371

########NEW FILE########
__FILENAME__ = test_my_channel
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import os
import sys
import time

from Tribler.Test.test_as_server import TestGuiAsServer, BASE_DIR

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.simpledefs import dlstatus_strings

DEBUG = True

class TestMyChannel(TestGuiAsServer):

    def test_rss_import(self):
        def do_files_check():
            self.screenshot('Torrents imported')
            self.quit()

        def added_rss():
            self.screenshot('Rssfeed added')

            # switch to files tab
            mt_index = self.managechannel.GetPage(self.managechannel.notebook, "Manage torrents")
            self.managechannel.notebook.SetSelection(mt_index)

            managefiles = self.managechannel.fileslist
            self.CallConditional(60, lambda: len(managefiles.GetItems()) > 0, do_files_check, 'Channel did not have torrents')

        def do_rss():
            self.managechannel.rss_url.SetValue(r'http://torrent.fedoraproject.org/rss20.xml')
            self.managechannel.OnAddRss()

            # switch to manage tab
            m_index = self.managechannel.GetPage(self.managechannel.notebook, "Manage")
            self.managechannel.notebook.SetSelection(m_index)

            self.Call(1, added_rss)

        def do_create():
            self.managechannel = self.frame.managechannel

            self.managechannel.name.SetValue('UNITTEST')
            self.managechannel.description.SetValue('Channel created for UNITTESTING purposes')

            self.managechannel.Save()
            self.CallConditional(60, lambda: self.frame.managechannel.rss_url, do_rss, 'Channel instance did not arrive at managechannel')

        def do_page():
            self.guiUtility.ShowPage('mychannel')
            self.Call(1, do_create)

        self.startTest(do_page)

    def test_add_torrents_playlists(self):

        def do_overview():
            self.guiUtility.showChannel(self.managechannel.channel)
            self.screenshot('Resulting channel')
            self.quit()

        def do_create_playlist(torrentfilename):
            self.screenshot('Files have been added created')

            infohash = TorrentDef.load(torrentfilename).get_infohash()

            manageplaylist = self.managechannel.playlistlist
            manager = manageplaylist.GetManager()
            manager.createPlaylist('Unittest', 'Playlist created for Unittest', [infohash, ])

            # switch to playlist tab
            mp_index = self.managechannel.GetPage(self.managechannel.notebook, "Manage playlists")
            self.managechannel.notebook.SetSelection(mp_index)

            self.CallConditional(60, lambda: len(manageplaylist.GetItems()) == 1, do_overview, 'Channel did not have a playlist')

        def do_switch_tab(torrentfilename):
            # switch to files tab
            mt_index = self.managechannel.GetPage(self.managechannel.notebook, "Manage torrents")
            self.managechannel.notebook.SetSelection(mt_index)

            self.CallConditional(120, lambda: len(self.managechannel.fileslist.GetItems()) == 3, lambda: do_create_playlist(torrentfilename), 'Channel did not have 3 torrents')

        def do_add_torrent(torrentfilename):
            self.screenshot('Channel is created')

            managefiles = self.managechannel.fileslist
            manager = managefiles.GetManager()
            manager.startDownload(torrentfilename, fixtorrent=True)
            manager.startDownloadFromUrl(r'http://torrent.fedoraproject.org/torrents/Fedora-20-i386-DVD.torrent', fixtorrent=True)
            manager.startDownloadFromMagnet(r'magnet:?xt=urn:btih:5ac55cf1b935291f6fc92ad7afd34597498ff2f7&dn=Pioneer+One+S01E01+Xvid-VODO&title=', fixtorrent=True)

            self.CallConditional(10, lambda: self.managechannel.notebook.GetPageCount() > 1, lambda: do_switch_tab(torrentfilename))

        def do_create_local_torrent():
            torrentfilename = self.createTorrent()
            do_add_torrent(torrentfilename)

        def do_create():
            self.screenshot('After selecting mychannel page')

            self.managechannel = self.frame.managechannel

            self.managechannel.name.SetValue('UNITTEST')
            self.managechannel.description.SetValue('Channel created for UNITTESTING purposes')

            self.managechannel.Save()
            self.screenshot('After clicking save')

            self.CallConditional(60, lambda: self.frame.managechannel.channel, do_create_local_torrent, 'Channel instance did not arrive at managechannel')

        def do_page():
            self.guiUtility.ShowPage('mychannel')
            self.Call(1, do_create)

        self.startTest(do_page)

    def startTest(self, callback):

        def get_and_modify_dispersy():
            from Tribler.dispersy.endpoint import NullEndpoint

            print >> sys.stderr, "tgs: frame ready, replacing dispersy endpoint"
            dispersy = self.session.get_dispersy_instance()
            dispersy._endpoint = NullEndpoint()
            dispersy._endpoint.open(dispersy)

            callback()

        TestGuiAsServer.startTest(self, get_and_modify_dispersy)

    def createTorrent(self):
        tdef = TorrentDef()
        tdef.add_content(os.path.join(BASE_DIR, "data", "video.avi"))
        tdef.set_tracker("http://fake.net/announce")
        tdef.finalize()
        torrentfn = os.path.join(self.session.get_state_dir(), "gen.torrent")
        tdef.save(torrentfn)

        return torrentfn

########NEW FILE########
__FILENAME__ = test_osutils
import os
import sys
import unittest

if os.path.exists('test_osutils.py'):
    BASE_DIR = '..'
    sys.path.insert(1, os.path.abspath('..'))
elif os.path.exists('LICENSE.txt'):
    BASE_DIR = '.'

from Tribler.Core.osutils import fix_filebasename

fix_filebasename


class Test_OsUtils(unittest.TestCase):

    def test_fix_filebasename(self):
        default_name = '_'
        win_name_table = {
            'abcdef': 'abcdef',
          '.': default_name,
          '..': default_name,
          '': default_name,
          ' ': default_name,
          '   ': default_name,
          os.path.join('a', 'b'): 'a_b',
          '\x5c\x61': '_a',    # \x5c = '\\'
          '\x92\x97': '\x92\x97',
          '\x5c\x5c': '__',
          '\x5c\x61\x5c': '_a_',
          '\x2f\x61': '_a',    # \x2f = '/'
          '\x92\x97': '\x92\x97',
          '\x2f\x2f': '__',
          '\x2f\x61\x2f': '_a_',
          'a' * 300: 'a'*255
        }
        for c in '"*/:<>?\\|':
            win_name_table[c] = default_name

        linux_name_table = {
          'abcdef': 'abcdef',
          '.': default_name,
          '..': default_name,
          '': default_name,
          ' ': default_name,
          '   ': default_name,
          os.path.join('a', 'b'): 'a_b',
          '\x2f\x61': '_a',    # \x2f = '/'
          '\x92\x97': '\x92\x97',
          '\x2f\x2f': '__',
          '\x2f\x61\x2f': '_a_',
          'a' * 300: 'a'*255
        }

        if sys.platform.startswith('win'):
            name_table = win_name_table
        else:
            name_table = linux_name_table

        for name in name_table:
            fixedname = fix_filebasename(name)
            assert fixedname == name_table[name], (fixedname, name_table[name])

########NEW FILE########
__FILENAME__ = test_remote_search
# see LICENSE.txt for license information

import unittest
import sys

from Tribler.Test.test_as_server import TestGuiAsServer
from Tribler.Main.vwxGUI.list_item import ChannelListItem

DEBUG = True


class TestRemoteQuery(TestGuiAsServer):

    def test_remotesearch(self):
        def do_assert():
            self.screenshot('After doing mp3 search, got %d results' % self.frame.searchlist.GetNrResults())
            self.assert_(self.frame.searchlist.GetNrResults() > 0, 'no results')
            self.assert_(self.guiUtility.torrentsearch_manager.gotRemoteHits, 'no remote results')
            self.quit()

        def do_search():
            self.guiUtility.dosearch(u'mp3')
            self.Call(10, do_assert)

        self.startTest(do_search)

    def test_ffsearch(self):
        def do_assert():
            self.screenshot('After doing xxx search, got %d results' % self.frame.searchlist.GetNrResults())
            self.assert_(self.frame.searchlist.GetNrResults() == 0, 'got results')
            self.quit()

        def do_search():
            self.guiUtility.toggleFamilyFilter(True)
            self.guiUtility.dosearch(u'xxx')
            self.Call(10, do_assert)

        self.startTest(do_search)

    def test_channelsearch(self):
        def do_assert():
            self.assert_(self.guiUtility.guiPage == 'selectedchannel', 'no in selectedchannel page')

            self.screenshot('After doubleclicking first channel')
            self.quit()

        def do_doubleclick():
            self.assert_(self.frame.searchlist.GetNrChannels() > 0, 'no channels matching mp3')

            self.screenshot('After doing mp3 search, got %d results' % self.frame.searchlist.GetNrResults())
            items = self.frame.searchlist.GetItems()
            for _, item in items.iteritems():
                if isinstance(item, ChannelListItem):
                    item.OnDClick()
                    break
            else:
                self.assert_(False, 'could not find ChannelListItem')

            self.Call(10, do_assert)

        def do_search():
            self.guiUtility.dosearch(u'mp3')
            self.Call(15, do_doubleclick)

        self.startTest(do_search, searchComm=False)

    def test_remotedownload(self):
        def do_assert():
            self.screenshot('After doing vodo search + pioneer filter + selecting item + download')
            self.quit()

        def do_download():
            self.screenshot('After doing vodo search + pioneer filter + selecting item')

            self.guiUtility.utility.write_config('showsaveas', 0)

            self.frame.top_bg.OnDownload()
            self.CallConditional(120, lambda: self.frame.librarylist.GetNrResults() > 0, do_assert, 'no download in librarylist')

        def do_select():
            self.assert_(self.frame.searchlist.GetNrResults() > 0, 'no hits matching vodo + pioneer')
            self.screenshot('After doing vodo search + pioneer filter, got %d results' % self.frame.searchlist.GetNrResults())
            items = self.frame.searchlist.GetItems()
            keys = items.keys()

            self.frame.searchlist.Select(keys[0])
            self.Call(5, do_download)

        def do_filter():
            self.assert_(self.frame.searchlist.GetNrResults() > 0, 'no hits matching vodo + pioneer')
            self.screenshot('After doing vodo search, got %d results' % self.frame.searchlist.GetNrResults())
            self.frame.searchlist.GotFilter('pioneer')

            self.Call(5, do_select)

        def do_search():
            self.guiUtility.dosearch(u'vodo')
            self.Call(10, do_filter)

        self.startTest(do_search)

    def startTest(self, callback, searchComm=True):
        if searchComm:
            def wait_for_search():
                print >> sys.stderr, "tgs: frame ready, staring to wait for search to be ready"
                self.CallConditional(300, lambda: self.frame.SRstatusbar.GetConnections() > 0.75, callback, 'did not connect to 75% of expected peers within 300s')
            TestGuiAsServer.startTest(self, wait_for_search)

        else:
            def wait_for_chansearch():
                print >> sys.stderr, "tgs: frame ready, staring to wait for channelsearch to be ready"
                self.CallConditional(300, lambda: self.frame.SRstatusbar.GetChannelConnections() > 10, callback, 'did not connect to more than 10 peers within 300s', assertCallback=lambda *argv, **kwarg: callback())
            TestGuiAsServer.startTest(self, wait_for_chansearch)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_sqlitecachedb
from Tribler.Core.CacheDB.sqlitecachedb import SQLiteCacheDB
from Tribler.Test.test_as_server import AbstractServer
from Tribler.dispersy.util import blocking_call_on_reactor_thread


class TestSqliteCacheDB(AbstractServer):

    @blocking_call_on_reactor_thread
    def setUp(self):
        AbstractServer.setUp(self)
        self.sqlite_test = SQLiteCacheDB.getInstance()
        self.db_path = ':memory:'

    @blocking_call_on_reactor_thread
    def tearDown(self):
        AbstractServer.tearDown(self)
        SQLiteCacheDB.getInstance().close_all()
        SQLiteCacheDB.delInstance()

    @blocking_call_on_reactor_thread
    def test_open_db(self):
        self.sqlite_test.openDB(self.db_path, 0)

    @blocking_call_on_reactor_thread
    def test_create_db(self):
        sql = "create table person(lastname, firstname);"
        self.sqlite_test.createDBTable(sql, self.db_path)

    @blocking_call_on_reactor_thread
    def test_get_del_instance(self):
        SQLiteCacheDB.delInstance()
        sqlite_test2 = SQLiteCacheDB.getInstance()

        assert sqlite_test2 != self.sqlite_test

    @blocking_call_on_reactor_thread
    def test_insert(self):
        self.test_create_db()

        self.sqlite_test.insert('person', lastname='a', firstname='b')
        assert self.sqlite_test.size('person') == 1

    @blocking_call_on_reactor_thread
    def test_fetchone(self):
        self.test_insert()
        one = self.sqlite_test.fetchone('select * from person')
        assert one == ('a', 'b')

        one = self.sqlite_test.fetchone("select lastname from person where firstname == 'b'")
        assert one == 'a'

        one = self.sqlite_test.fetchone("select lastname from person where firstname == 'c'")
        assert one is None

    @blocking_call_on_reactor_thread
    def test_insertmany(self):
        self.test_create_db()

        values = []
        for i in range(100):
            value = (str(i), str(i ** 2))
            values.append(value)
        self.sqlite_test.insertMany('person', values)
        assert self.sqlite_test.size('person') == 100

    @blocking_call_on_reactor_thread
    def test_fetchall(self):
        self.test_insertmany()

        all = self.sqlite_test.fetchall('select * from person')
        assert len(all) == 100

        all = self.sqlite_test.fetchall("select * from person where lastname=='101'")
        assert all == []

    @blocking_call_on_reactor_thread
    def test_insertorder(self):
        self.test_insertmany()

        self.sqlite_test.insert('person', lastname='1', firstname='abc')
        one = self.sqlite_test.fetchone("select firstname from person where lastname == '1'")
        assert one == '1' or one == 'abc'

        all = self.sqlite_test.fetchall("select firstname from person where lastname == '1'")
        assert len(all) == 2

    @blocking_call_on_reactor_thread
    def test_update(self):
        self.test_insertmany()

        self.sqlite_test.update('person', "lastname == '2'", firstname='56')
        one = self.sqlite_test.fetchone("select firstname from person where lastname == '2'")
        assert one == '56', one

        self.sqlite_test.update('person', "lastname == '3'", firstname=65)
        one = self.sqlite_test.fetchone("select firstname from person where lastname == '3'")
        assert one == 65, one

        self.sqlite_test.update('person', "lastname == '4'", firstname=654, lastname=44)
        one = self.sqlite_test.fetchone("select firstname from person where lastname == 44")
        assert one == 654, one

########NEW FILE########
__FILENAME__ = test_sqlitecachedbhandler
import os
import unittest
from binascii import unhexlify
from shutil import copy as copyFile
from time import time
from unittest.case import skip

from twisted.internet import reactor
from twisted.internet.threads import blockingCallFromThread

from Tribler.Core.CacheDB.SqliteCacheDBHandler import (TorrentDBHandler, MyPreferenceDBHandler, BasicDBHandler,
                                                       PeerDBHandler, MiscDBHandler)
from Tribler.Core.CacheDB.sqlitecachedb import SQLiteCacheDB, bin2str, str2bin
from Tribler.Core.Session import Session
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Test.bak_tribler_sdb import FILES_DIR, init_bak_tribler_sdb
from Tribler.Test.test_as_server import AbstractServer
from Tribler.dispersy.util import blocking_call_on_reactor_thread


S_TORRENT_PATH_BACKUP = os.path.join(FILES_DIR, 'bak_single.torrent')
M_TORRENT_PATH_BACKUP = os.path.join(FILES_DIR, 'bak_multiple.torrent')

BUSYTIMEOUT = 5000
SQLiteCacheDB.DEBUG = False
DEBUG = False

# ------------------------------------------------------------
# The global teardown that will only be called once.
# We add this to delete the Session.
# ------------------------------------------------------------


@blocking_call_on_reactor_thread
def teardown():
    if Session.has_instance():
        Session.del_instance()


class AbstractDB(AbstractServer):

    def setUp(self):
        AbstractServer.setUp(self)

        dbpath = init_bak_tribler_sdb('bak_new_tribler.sdb', destination_path=self.getStateDir(), overwrite=True)
        self.sqlitedb = SQLiteCacheDB.getInstance()
        blockingCallFromThread(reactor, self.sqlitedb.initDB, dbpath, busytimeout=BUSYTIMEOUT)
        self.sqlitedb.waitForUpdateComplete()

    @blocking_call_on_reactor_thread
    def tearDown(self):
        if SQLiteCacheDB.hasInstance():
            SQLiteCacheDB.getInstance().close_all()
            SQLiteCacheDB.delInstance()

        AbstractServer.tearDown(self)


class TestSqliteBasicDBHandler(AbstractDB):

    def setUp(self):
        AbstractDB.setUp(self)
        self.db = BasicDBHandler(self.sqlitedb, 'Peer')

    @blocking_call_on_reactor_thread
    def test_size(self):
        size = self.db.size()  # there are 3995 peers in the table, however the upgrade scripts remove 8 superpeers
        assert size == 3987, size


class TestSqlitePeerDBHandler(AbstractDB):

    def setUp(self):
        AbstractDB.setUp(self)

        self.p1 = str2bin('MFIwEAYHKoZIzj0CAQYFK4EEABoDPgAEAAA6SYI4NHxwQ8P7P8QXgWAP+v8SaMVzF5+fSUHdAMrs6NvL5Epe1nCNSdlBHIjNjEiC5iiwSFZhRLsr')
        self.p2 = str2bin('MFIwEAYHKoZIzj0CAQYFK4EEABoDPgAEAABo69alKy95H7RHzvDCsolAurKyrVvtDdT9/DzNAGvky6YejcK4GWQXBkIoQGQgxVEgIn8dwaR9B+3U')
        fake_permid_x = 'fake_permid_x' + '0R0\x10\x00\x07*\x86H\xce=\x02\x01\x06\x05+\x81\x04\x00\x1a\x03>\x00\x04'

        self.pdb = PeerDBHandler.getInstance()

        hp = self.pdb.hasPeer(fake_permid_x)
        assert not hp

    @blocking_call_on_reactor_thread
    def tearDown(self):
        PeerDBHandler.delInstance()
        AbstractDB.tearDown(self)

    @blocking_call_on_reactor_thread
    def test_getList(self):
        peer1 = self.pdb.getPeer(self.p1)
        peer2 = self.pdb.getPeer(self.p2)
        assert isinstance(peer1, dict)
        assert isinstance(peer2, dict)
        assert peer1[u'peer_id'] == 1, peer1
        assert peer2[u'peer_id'] == 2, peer2

    @blocking_call_on_reactor_thread
    def test_addPeer(self):
        fake_permid_x = 'fake_permid_x' + '0R0\x10\x00\x07*\x86H\xce=\x02\x01\x06\x05+\x81\x04\x00\x1a\x03>\x00\x04'
        peer_x = {'permid': fake_permid_x, 'name': 'fake peer x'}
        oldsize = self.pdb.size()
        self.pdb.addPeer(fake_permid_x, peer_x)
        assert self.pdb.size() == oldsize + 1, (self.pdb.size(), oldsize + 1)

        p = self.pdb.getPeer(fake_permid_x)
        assert p['name'] == 'fake peer x'

        self.pdb.deletePeer(fake_permid_x)
        p = self.pdb.getPeer(fake_permid_x)
        assert p is None
        assert self.pdb.size() == oldsize

    @blocking_call_on_reactor_thread
    def test_aa_hasPeer(self):
        assert self.pdb.hasPeer(self.p1)
        assert self.pdb.hasPeer(self.p2)
        fake_permid_x = 'fake_permid_x' + '0R0\x10\x00\x07*\x86H\xce=\x02\x01\x06\x05+\x81\x04\x00\x1a\x03>\x00\x04'
        assert not self.pdb.hasPeer(fake_permid_x)

    @blocking_call_on_reactor_thread
    def test_deletePeer(self):
        fake_permid_x = 'fake_permid_x' + '0R0\x10\x00\x07*\x86H\xce=\x02\x01\x06\x05+\x81\x04\x00\x1a\x03>\x00\x04'
        peer_x = {'permid': fake_permid_x, 'name': 'fake peer x'}
        oldsize = self.pdb.size()
        p = self.pdb.getPeer(fake_permid_x)
        assert p is None, p

        self.pdb.addPeer(fake_permid_x, peer_x)
        assert self.pdb.size() == oldsize + 1, (self.pdb.size(), oldsize + 1)
        assert self.pdb.hasPeer(fake_permid_x)
        p = self.pdb.getPeer(fake_permid_x)
        assert p is not None

        self.pdb.deletePeer(fake_permid_x)
        assert not self.pdb.hasPeer(fake_permid_x)
        assert self.pdb.size() == oldsize

        p = self.pdb.getPeer(fake_permid_x)
        assert p is None


class TestTorrentDBHandler(AbstractDB):

    def setUp(self):
        AbstractDB.setUp(self)

        assert not MiscDBHandler.hasInstance()
        assert not TorrentDBHandler.hasInstance()

        self.misc_db = MiscDBHandler.getInstance()
        self.tdb = TorrentDBHandler.getInstance()
        self.tdb.torrent_dir = FILES_DIR
        self.tdb.mypref_db = MyPreferenceDBHandler.getInstance()

    @blocking_call_on_reactor_thread
    def tearDown(self):
        MiscDBHandler.delInstance()
        TorrentDBHandler.delInstance()
        MyPreferenceDBHandler.delInstance()

        AbstractDB.tearDown(self)

    @blocking_call_on_reactor_thread
    def test_hasTorrent(self):
        infohash_str = 'AA8cTG7ZuPsyblbRE7CyxsrKUCg='
        infohash = str2bin(infohash_str)
        assert self.tdb.hasTorrent(infohash)
        assert self.tdb.hasMetaData(infohash)
        fake_infoahsh = 'fake_infohash_100000'
        assert self.tdb.hasTorrent(fake_infoahsh) == False
        assert self.tdb.hasMetaData(fake_infoahsh) == False

    @blocking_call_on_reactor_thread
    def test_loadTorrents(self):
        res = self.tdb.getTorrents()  # only returns good torrents

        data = res[0]
        # print data
        assert data['category'][0] in self.misc_db._category_name2id_dict, data['category']
        assert data['status'] in self.misc_db._torrent_status_name2id_dict, data['status']
        assert data['source'] in self.misc_db._torrent_source_name2id_dict, data['source']
        assert len(data['infohash']) == 20

    @blocking_call_on_reactor_thread
    def test_add_update_delete_Torrent(self):
        self.addTorrent()
        self.updateTorrent()
        self.deleteTorrent()

    @blocking_call_on_reactor_thread
    def addTorrent(self):
        old_size = self.tdb.size()
        old_src_size = self.tdb._db.size('TorrentSource')
        old_tracker_size = self.tdb._db.size('TrackerInfo')

        s_infohash = unhexlify('44865489ac16e2f34ea0cd3043cfd970cc24ec09')
        m_infohash = unhexlify('ed81da94d21ad1b305133f2726cdaec5a57fed98')

        sid = self.tdb.getTorrentID(s_infohash)
        mid = self.tdb.getTorrentID(m_infohash)

        single_torrent_file_path = os.path.join(self.getStateDir(), 'single.torrent')
        multiple_torrent_file_path = os.path.join(self.getStateDir(), 'multiple.torrent')

        copyFile(S_TORRENT_PATH_BACKUP, single_torrent_file_path)
        copyFile(M_TORRENT_PATH_BACKUP, multiple_torrent_file_path)

        single_tdef = TorrentDef.load(single_torrent_file_path)
        assert s_infohash == single_tdef.get_infohash()
        src = 'http://www.rss.com/torrent.xml'
        multiple_tdef = TorrentDef.load(multiple_torrent_file_path)
        assert m_infohash == multiple_tdef.get_infohash()

        self.tdb.addExternalTorrent(single_tdef, extra_info={'filename': single_torrent_file_path})
        self.tdb.addExternalTorrent(multiple_tdef, source=src, extra_info={'filename': multiple_torrent_file_path})

        single_torrent_id = self.tdb.getTorrentID(s_infohash)
        multiple_torrent_id = self.tdb.getTorrentID(m_infohash)

        assert self.tdb.getInfohash(single_torrent_id) == s_infohash

        single_name = 'Tribler_4.1.7_src.zip'
        multiple_name = 'Tribler_4.1.7_src'

        assert self.tdb.size() == old_size + 2, old_size - self.tdb.size()
        assert old_src_size + 1 == self.tdb._db.size('TorrentSource')
        new_tracker_table_size = self.tdb._db.size('TrackerInfo')
        assert old_tracker_size < new_tracker_table_size, new_tracker_table_size - old_tracker_size

        sname = self.tdb.getOne('name', torrent_id=single_torrent_id)
        assert sname == single_name, (sname, single_name)
        mname = self.tdb.getOne('name', torrent_id=multiple_torrent_id)
        assert mname == multiple_name, (mname, multiple_name)

        s_size = self.tdb.getOne('length', torrent_id=single_torrent_id)
        assert s_size == 1583233, s_size
        m_size = self.tdb.getOne('length', torrent_id=multiple_torrent_id)
        assert m_size == 5358560, m_size

        # TODO: action is flagged as XXX causing this torrent to be XXX instead of other
        cat = self.tdb.getOne('category_id', torrent_id=multiple_torrent_id)
        # assert cat == 8, cat  # other

        sid = self.tdb._db.getOne('TorrentSource', 'source_id', name=src)
        assert sid > 1
        m_sid = self.tdb.getOne('source_id', torrent_id=multiple_torrent_id)
        assert sid == m_sid
        s_sid = self.tdb.getOne('source_id', torrent_id=single_torrent_id)
        assert 1 == s_sid
        s_status = self.tdb.getOne('status_id', torrent_id=single_torrent_id)
        assert s_status == 0

        m_comment = self.tdb.getOne('comment', torrent_id=multiple_torrent_id)
        comments = 'www.tribler.org'
        assert m_comment.find(comments) > -1
        comments = 'something not inside'
        assert m_comment.find(comments) == -1

        m_trackers = self.tdb.getTrackerListByInfohash(m_infohash)
        assert len(m_trackers) == 8
        assert 'http://tpb.tracker.thepiratebay.org:80/announce' in m_trackers, m_trackers

        s_torrent = self.tdb.getTorrent(s_infohash)
        m_torrent = self.tdb.getTorrent(m_infohash)
        assert s_torrent['name'] == 'Tribler_4.1.7_src.zip', s_torrent['name']
        assert m_torrent['name'] == 'Tribler_4.1.7_src', m_torrent['name']
        assert m_torrent['last_tracker_check'] == 0

    @blocking_call_on_reactor_thread
    def updateTorrent(self):
        s_infohash = unhexlify('44865489ac16e2f34ea0cd3043cfd970cc24ec09')
        m_infohash = unhexlify('ed81da94d21ad1b305133f2726cdaec5a57fed98')
        self.tdb.updateTorrent(m_infohash, relevance=3.1415926, category=['Videoclips'],
                               status='good', progress=23.5, seeder=123, leecher=321,
                               last_tracker_check=1234567,
                               other_key1='abcd', other_key2=123)
        multiple_torrent_id = self.tdb.getTorrentID(m_infohash)
        cid = self.tdb.getOne('category_id', torrent_id=multiple_torrent_id)
        # assert cid == 2, cid
        sid = self.tdb.getOne('status_id', torrent_id=multiple_torrent_id)
        assert sid == 1
        p = self.tdb.mypref_db.getOne('progress', torrent_id=multiple_torrent_id)
        assert p is None, p
        seeder = self.tdb.getOne('num_seeders', torrent_id=multiple_torrent_id)
        assert seeder == 123
        leecher = self.tdb.getOne('num_leechers', torrent_id=multiple_torrent_id)
        assert leecher == 321
        last_tracker_check = self.tdb.getOne('last_tracker_check', torrent_id=multiple_torrent_id)
        assert last_tracker_check == 1234567, last_tracker_check

    @blocking_call_on_reactor_thread
    def deleteTorrent(self):
        s_infohash = unhexlify('44865489ac16e2f34ea0cd3043cfd970cc24ec09')
        m_infohash = unhexlify('ed81da94d21ad1b305133f2726cdaec5a57fed98')

        assert self.tdb.deleteTorrent(s_infohash, delete_file=True)
        assert self.tdb.deleteTorrent(m_infohash)

        assert not self.tdb.hasTorrent(s_infohash)
        assert not self.tdb.hasTorrent(m_infohash)
        assert not os.path.isfile(os.path.join(self.getStateDir(), 'single.torrent'))
        m_trackers = self.tdb.getTrackerListByInfohash(m_infohash)
        assert len(m_trackers) == 0

        # fake_infoahsh = 'fake_infohash_1'+'0R0\x10\x00\x07*\x86H\xce=\x02'
        # 02/02/10 Boudewijn: infohashes must be 20 bytes long
        fake_infoahsh = 'fake_infohash_1' + '0R0\x10\x00'
        assert not self.tdb.deleteTorrent(fake_infoahsh)

        my_infohash_str_126 = 'ByJho7yj9mWY1ORWgCZykLbU1Xc='
        my_infohash = str2bin(my_infohash_str_126)
        assert not self.tdb.deleteTorrent(my_infohash)

    @blocking_call_on_reactor_thread
    def test_getCollectedTorrentHashes(self):
        res = self.tdb.getNumberCollectedTorrents()
        assert res == 4848, res

    @unittest.skip("TODO, the database thingie shouldn't be deleting files from the FS.")
    @blocking_call_on_reactor_thread
    def test_freeSpace(self):
        old_res = self.tdb.getNumberCollectedTorrents()
        self.tdb.freeSpace(20)
        res = self.tdb.getNumberCollectedTorrents()
        assert old_res - res == 20


class TestMyPreferenceDBHandler(AbstractDB):

    def setUp(self):
        AbstractDB.setUp(self)

        self.mdb = MyPreferenceDBHandler.getInstance()
        self.mdb.loadData()
        self.tdb = TorrentDBHandler.getInstance()

    @blocking_call_on_reactor_thread
    def tearDown(self):
        MiscDBHandler.delInstance()
        MyPreferenceDBHandler.delInstance()
        TorrentDBHandler.delInstance()

        AbstractDB.tearDown(self)

    @blocking_call_on_reactor_thread
    def test_getPrefList(self):
        pl = self.mdb.getMyPrefListInfohash()
        assert len(pl) == 24

    @blocking_call_on_reactor_thread
    def test_getRecentLivePrefList(self):
        pl = self.mdb.getRecentLivePrefList()
        assert len(pl) == 11, (len(pl), pl)
        infohash_str_126 = 'ByJho7yj9mWY1ORWgCZykLbU1Xc='
        assert bin2str(pl[0]) == infohash_str_126
        infohash_str_1279 = 'R+grUhp884MnFkt6NuLnnauZFsc='
        assert bin2str(pl[1]) == infohash_str_1279

        pl = self.mdb.getRecentLivePrefList(8)
        assert len(pl) == 8, (len(pl), pl)
        assert bin2str(pl[0]) == infohash_str_126
        assert bin2str(pl[1]) == infohash_str_1279

    @blocking_call_on_reactor_thread
    def test_hasMyPreference(self):
        assert self.mdb.hasMyPreference(126)
        assert self.mdb.hasMyPreference(1279)
        assert not self.mdb.hasMyPreference(1)

    @skip("We are going to rewrite the whole database thing, so its not worth the trouble fixing this now")
    @blocking_call_on_reactor_thread
    def test_addMyPreference_deletePreference(self):
        p = self.mdb.getOne(('torrent_id', 'destination_path', 'progress', 'creation_time'), torrent_id=126)
        torrent_id = p[0]
        infohash = self.tdb.getInfohash(torrent_id)
        destpath = p[1]
        progress = p[2]
        creation_time = p[3]
        self.mdb.deletePreference(torrent_id)
        pl = self.mdb.getMyPrefListInfohash()
        assert len(pl) == 22
        assert infohash not in pl

        data = {'destination_path': destpath}
        self.mdb.addMyPreference(torrent_id, data)
        p2 = self.mdb.getOne(('torrent_id', 'destination_path', 'progress', 'creation_time'), torrent_id=126)
        assert p2[0] == p[0] and p2[1] == p[1] and p2[2] == 0 and time() - p2[3] < 10, p2

        self.mdb.deletePreference(torrent_id)
        pl = self.mdb.getMyPrefListInfohash()
        assert len(pl) == 22
        assert infohash not in pl

        data = {'destination_path': destpath, 'progress': progress, 'creation_time': creation_time}
        self.mdb.addMyPreference(torrent_id, data)
        p3 = self.mdb.getOne(('torrent_id', 'destination_path', 'progress', 'creation_time'), torrent_id=126)
        assert p3 == p, p3

    @blocking_call_on_reactor_thread
    def test_updateProgress(self):
        infohash_str_126 = 'ByJho7yj9mWY1ORWgCZykLbU1Xc='
        infohash = str2bin(infohash_str_126)
        torrent_id = self.tdb.getTorrentID(infohash)
        assert torrent_id == 126
        assert self.mdb.hasMyPreference(torrent_id)
        self.mdb.updateProgress(torrent_id, 3.14)
        p = self.mdb.getOne('progress', torrent_id=torrent_id)
        assert p == 3.14

    @blocking_call_on_reactor_thread
    def test_getMyPrefListInfohash(self):
        preflist = self.mdb.getMyPrefListInfohash()
        for p in preflist:
            assert not p or len(p) == 20, len(p)
        assert len(preflist) == 24

    @blocking_call_on_reactor_thread
    def test_getMyPrefStats(self):
        res = self.mdb.getMyPrefStats()
        assert len(res) == 12
        for k in res:
            data = res[k]
            assert len(data) == 3

########NEW FILE########
__FILENAME__ = test_sqlitecachedb_upgrade
import sys

from Tribler.Core.CacheDB import sqlitecachedb
from Tribler.Core.CacheDB.sqlitecachedb import SQLiteCacheDB
from Tribler.Core.Session import Session
from Tribler.Test.bak_tribler_sdb import init_bak_tribler_sdb
from Tribler.Test.test_as_server import AbstractServer
from Tribler.dispersy.util import blocking_call_on_reactor_thread


class TestSqliteCacheDB(AbstractServer):

    @blocking_call_on_reactor_thread
    def setUp(self):
        AbstractServer.setUp(self)

        # Speed up upgrade, otherwise this test would take ages.
        self.original_values = [sqlitecachedb.INITIAL_UPGRADE_PAUSE, sqlitecachedb.SUCCESIVE_UPGRADE_PAUSE, sqlitecachedb.UPGRADE_BATCH_SIZE, sqlitecachedb.TEST_OVERRIDE]

        sqlitecachedb.INITIAL_UPGRADE_PAUSE = 10
        sqlitecachedb.SUCCESIVE_UPGRADE_PAUSE = 1
        sqlitecachedb.UPGRADE_BATCH_SIZE = sys.maxsize
        sqlitecachedb.TEST_OVERRIDE = True

    @blocking_call_on_reactor_thread
    def tearDown(self):
        if SQLiteCacheDB.hasInstance():
            SQLiteCacheDB.getInstance().close_all()
            SQLiteCacheDB.delInstance()

        if Session.has_instance():  # Upgrading will create a session instance
            Session.del_instance()

        sqlitecachedb.INITIAL_UPGRADE_PAUSE, sqlitecachedb.SUCCESIVE_UPGRADE_PAUSE, sqlitecachedb.UPGRADE_BATCH_SIZE, sqlitecachedb.TEST_OVERRIDE = self.original_values
        AbstractServer.tearDown(self)

    def test_perform_upgrade(self):
        dbpath = init_bak_tribler_sdb('bak_old_tribler.sdb', destination_path=self.getStateDir(), overwrite=True)

        # TODO(emilon): Replace this with the database decorator when the database stuff gets its own thread again
        @blocking_call_on_reactor_thread
        def do_db():
            self.sqlitedb = SQLiteCacheDB.getInstance()
            self.sqlitedb.initDB(dbpath)
        do_db()
        self.sqlitedb.waitForUpdateComplete()

########NEW FILE########
__FILENAME__ = test_status
# Written by Njaal Borch
# see LICENSE.txt for license information
import unittest
import threading

import time

from Tribler.Core.Statistics.Status import Status
from Tribler.Core.Statistics.Status import LivingLabReporter
from Tribler.Test.test_as_server import AbstractServer


class TestOnChangeStatusReporter(Status.OnChangeStatusReporter):

    name = None
    value = None

    def report(self, element):
        self.name = element.name
        self.value = element.value


class TestPeriodicStatusReporter(Status.PeriodicStatusReporter):
    last_value = None

    def report(self):
        elements = self.get_elements()
        # Actually report
        assert len(elements) == 1
        self.last_value = elements[0].get_value()


class StatusTest(AbstractServer):

    """
    Unit tests for the Status class

    """

    def testBasic(self):

        status = Status.get_status_holder("UnitTest")
        status.reset()

        self.assertNotEqual(status, None)

        self.assertEquals(status.get_name(), "UnitTest")

    def testInt(self):

        status = Status.get_status_holder("UnitTest")
        status.reset()
        self.assertNotEqual(status, None)

        i = status.create_status_element("TestInteger")
        self.assertEquals(i.get_name(), "TestInteger")

        x = status.get_status_element("TestInteger")
        self.assertEquals(x, i)

        # Test set and get values
        for j in range(0, 10):
            i.set_value(j)
            self.assertEquals(i.get_value(), j)

        # Clean up
        status.remove_status_element(i)
        try:
            status.get_status_element("TestInteger")
            self.fail("Remove does not remove status element 'TestInteger'")
        except Status.NoSuchElementException as e:
            # Expected
            pass

    def testInvalid(self):
        status = Status.get_status_holder("UnitTest")
        status.reset()

        try:
            i = status.create_status_element(None)
            self.fail("Does not throw exception with no name")
        except AssertionError as e:
            pass

        try:
            status.get_status_element(None)
            self.fail("Invalid get_status_element does not throw exception")
        except AssertionError as e:
            pass

        try:
            status.remove_status_element(None)
            self.fail("Invalid remove_status_element does not throw exception")
        except AssertionError as e:
            pass

        elem = Status.StatusElement("name", "description")
        try:
            status.remove_status_element(elem)
            self.fail("Invalid remove_status_element does not throw exception")
        except Status.NoSuchElementException as e:
            pass

    def testPolicy_ON_CHANGE(self):

        status = Status.get_status_holder("UnitTest")
        status.reset()
        reporter = TestOnChangeStatusReporter("On change")
        status.add_reporter(reporter)
        i = status.create_status_element("TestInteger")

        for x in range(0, 10):
            i.set_value(x)
            if x != reporter.value:
                self.fail("Callback does not work for ON_CHANGE policy")
            if reporter.name != "TestInteger":
                self.fail("On_Change callback get's the wrong parameter, got '%s', expected 'TestInteger'" % reporter.name)

        # Clean up
        status.remove_status_element(i)

    def testPolicy_PERIODIC(self):

        status = Status.get_status_holder("UnitTest")
        status.reset()

        reporter = TestPeriodicStatusReporter("Periodic, 0.4sec", 0.4)
        status.add_reporter(reporter)
        i = status.create_status_element("TestInteger")

        for x in range(0, 5):
            i.set_value(x)
            self.assertEquals(reporter.last_value, None)  # Not updated yet

        time.sleep(1)

        assert reporter.last_value == 4

        for x in range(5, 9):
            self.assertEquals(reporter.last_value, 4)  # Not updated yet
            i.set_value(x)
        time.sleep(1)

        self.assertEquals(reporter.last_value, 8)

        # Clean up
        status.remove_status_element(i)

        reporter.stop()

    def test_LLReporter_element(self):

        status = Status.get_status_holder("UnitTest")
        status.reset()
        reporter = TestLivingLabPeriodicReporter("Living lab test reporter", 1.0)
        status.add_reporter(reporter)
        i = status.create_status_element("TestInteger")
        i.set_value(1233)

        b = status.create_status_element("Binary")
        b.set_value("".join([chr(n) for n in range(0, 255)]))

        reporter.wait_for_post(5.0)

        reporter.stop()
        time.sleep(1)

        self.assertEquals(len(reporter.get_errors()), 0)

        status.remove_status_element(i)
        status.remove_status_element(b)

    def test_LLReporter_event(self):

        status = Status.get_status_holder("UnitTest")
        status.reset()
        reporter = TestLivingLabPeriodicReporter("Living lab test reporter", 1.0)
        status.add_reporter(reporter)
        event = status.create_event("SomeEvent")
        event.add_value("123")
        event.add_value("456")
        status.add_event(event)

        reporter.wait_for_post(5.0)

        reporter.stop()
        time.sleep(1)

        self.assertEquals(len(reporter.get_errors()), 0)

        status.remove_event(event)


class TestLivingLabPeriodicReporter(LivingLabReporter.LivingLabPeriodicReporter):

    def __init__(self, name, report_time):
        self.errors = []
        LivingLabReporter.LivingLabPeriodicReporter.__init__(self, name, report_time, "myid", self.count_errors)
        self.xml = None
        self.cond = threading.Condition()

    def wait_for_post(self, timeout):
        self.cond.acquire()
        try:
            if self.xml:
                return True

            self.cond.wait(timeout)
            if self.xml:
                return True
            raise Exception("Timeout")
        finally:
            self.cond.release()

    def post(self, xml):
        # TODO: Check the XML?
        print xml
        self.xml = xml
        self.cond.acquire()
        self.cond.notifyAll()
        self.cond.release()

    def count_errors(self, zero, error):
        print "ERROR", error
        self.errors.append(error)

    def get_errors(self):
        return self.errors

if __name__ == "__main__":

    print "Testing Status module"

    unittest.main()

    print "All done"

########NEW FILE########
__FILENAME__ = test_threadpool
# Written by Arno Bakker
# see LICENSE.txt for license information

import unittest

import sys
import time
from threading import RLock, enumerate as enumerate_threads

from Tribler.Core.APIImplementation.ThreadPool import ThreadPool
from Tribler.Test.test_as_server import AbstractServer


DEBUG = False


class TestThreadPool(AbstractServer):

    """
    Parent class for testing internal thread pool of Tribler
    """

    def setUp(self):
        AbstractServer.setUp(self)
        """ unittest test setup code """
        self.tp = ThreadPool(10)
        self.exp = []
        self.gotlock = RLock()
        self.got = []

    def tearDown(self):
        """ unittest test tear down code """
        self.tp.joinAll()

        time.sleep(2)
        self.got.sort()
        self.assertEquals(self.exp, self.got)

        ts = enumerate_threads()
        print >> sys.stderr, "test_threadpool: Number of threads still running", len(ts)
        for t in ts:
            print >> sys.stderr, "test_threadpool: Thread still running", t.getName(), "daemon", t.isDaemon(), "instance:", t
            
        AbstractServer.tearDown(self)

    def test_queueTask1(self):
        if DEBUG:
            print >> sys.stderr, "test_queueTask1:"
        self.exp = [1]
        self.tp.queueTask(lambda: self.do_task(1))

    def do_task(self, val):
        self.gotlock.acquire()
        if DEBUG:
            print >> sys.stderr, "test: got task", val
        self.got.append(val)
        self.gotlock.release()

    def test_queueTask10lambda(self):
        if DEBUG:
            print >> sys.stderr, "test_queueTask10lambda:"
        self.exp = range(1, 11)

        def wrapper(x):
            self.tp.queueTask(lambda: self.do_task(x))

        for i in range(1, 11):
            if DEBUG:
                print >> sys.stderr, "test: exp task", i
            wrapper(i)

    #
    # Confusing lambda crap, do explicit:
    #
    def test_queueTask10explicit(self):
        if DEBUG:
            print >> sys.stderr, "test_queueTask10explicit:"
        self.exp = range(1, 11)
        self.tp.queueTask(self.do_task1)
        self.tp.queueTask(self.do_task2)
        self.tp.queueTask(self.do_task3)
        self.tp.queueTask(self.do_task4)
        self.tp.queueTask(self.do_task5)
        self.tp.queueTask(self.do_task6)
        self.tp.queueTask(self.do_task7)
        self.tp.queueTask(self.do_task8)
        self.tp.queueTask(self.do_task9)
        self.tp.queueTask(self.do_task10)

    def test_joinAll(self):
        if DEBUG:
            print >> sys.stderr, "test_joinall:"
        self.exp = range(1, 6)
        if DEBUG:
            print >> sys.stderr, "test: adding tasks"
        self.tp.queueTask(self.do_task1)
        self.tp.queueTask(self.do_task2)
        self.tp.queueTask(self.do_task3)
        self.tp.queueTask(self.do_task4)
        self.tp.queueTask(self.do_task5)
        if DEBUG:
            print >> sys.stderr, "test: join all"
        self.tp.joinAll()
        if DEBUG:
            print >> sys.stderr, "test: adding post tasks, shouldn't get run"
        self.tp.queueTask(self.do_task6)
        self.tp.queueTask(self.do_task7)
        self.tp.queueTask(self.do_task8)
        self.tp.queueTask(self.do_task9)
        self.tp.queueTask(self.do_task10)

    def test_setThreadCountPlus10(self):
        if DEBUG:
            print >> sys.stderr, "test_setThreadCountPlus10:"
            print >> sys.stderr, "test: pre threads", self.tp.getThreadCount()
        self.tp.setThreadCount(20)
        if DEBUG:
            print >> sys.stderr, "test: post threads", self.tp.getThreadCount()
        time.sleep(1)
        self.test_joinAll()

    def test_setThreadCountMinus8(self):
        if DEBUG:
            print >> sys.stderr, "test_setThreadCountMinus8:"
            print >> sys.stderr, "test: pre threads", self.tp.getThreadCount()
        self.tp.setThreadCount(2)
        if DEBUG:
            print >> sys.stderr, "test: post threads", self.tp.getThreadCount()
        time.sleep(1)
        self.test_joinAll()

    def do_task1(self):
        self.gotlock.acquire()
        self.got.append(1)
        self.gotlock.release()

    def do_task2(self):
        self.gotlock.acquire()
        self.got.append(2)
        self.gotlock.release()

    def do_task3(self):
        self.gotlock.acquire()
        self.got.append(3)
        self.gotlock.release()

    def do_task4(self):
        self.gotlock.acquire()
        self.got.append(4)
        self.gotlock.release()

    def do_task5(self):
        self.gotlock.acquire()
        self.got.append(5)
        self.gotlock.release()

    def do_task6(self):
        self.gotlock.acquire()
        self.got.append(6)
        self.gotlock.release()

    def do_task7(self):
        self.gotlock.acquire()
        self.got.append(7)
        self.gotlock.release()

    def do_task8(self):
        self.gotlock.acquire()
        self.got.append(8)
        self.gotlock.release()

    def do_task9(self):
        self.gotlock.acquire()
        self.got.append(9)
        self.gotlock.release()

    def do_task10(self):
        self.gotlock.acquire()
        self.got.append(10)
        self.gotlock.release()

########NEW FILE########
__FILENAME__ = test_TimedTaskQueue
import unittest
from time import sleep

from Tribler.Utilities.TimedTaskQueue import TimedTaskQueue


class TestTimedTaskQueue(unittest.TestCase):

    def setUp(self):
        self.queue = TimedTaskQueue()

    def tearDown(self):
        self.queue.shutdown()
        del self.queue

    def test_addTask(self):
        self.count = 0
        self.queue.add_task(self.task3a, 3)
        self.queue.add_task(self.task0, 0)
        self.queue.add_task(self.task3b, 3)
        self.queue.add_task(self.task2, 1)
        sleep(6)
        assert self.count == 11

    def task0(self):
        self.count += 1
        assert self.count == 1

    def task2(self):
        self.count += 2
        assert self.count == 3

    def task3a(self):
        self.count += 4
        assert self.count == 7 or self.count == 11

    def task3b(self):
        self.count += 4
        assert self.count == 7 or self.count == 11

    def test_addTask0FIFO(self):
        self.count = 0
        self.queue.add_task(self.task0a, 0)
        self.queue.add_task(self.task0b, 0)
        self.queue.add_task(self.task0c, 0)
        self.queue.add_task(self.task0d, 0)
        sleep(6)
        assert self.count == 4

    def task0a(self):
        assert self.count == 0
        self.count = 1

    def task0b(self):
        assert self.count == 1
        self.count = 2

    def task0c(self):
        assert self.count == 2
        self.count = 3

    def task0d(self):
        assert self.count == 3
        self.count = 4

########NEW FILE########
__FILENAME__ = test_torrentcollecting
# Written by Niels Zeilemaker
# see LICENSE.txt for license information

import os
import sys
import time
from shutil import move
import threading
from traceback import print_exc

from Tribler.Test.test_as_server import TestAsServer, BASE_DIR

from Tribler.Core.simpledefs import dlstatus_strings, DLSTATUS_SEEDING
from Tribler.Core.Session import Session
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Swift.SwiftDef import SwiftDef

from Tribler.Main.globals import DefaultDownloadStartupConfig


class TestTorrentCollecting(TestAsServer):
    """
    Testing seeding via new tribler API:
    """
    def setUp(self):
        """ override TestAsServer """
        TestAsServer.setUp(self)

        self.session2 = Session(self.config2, ignore_singleton=True)
        self.session2.start()

        self.seeding_event = threading.Event()

    def setUpPreSession(self):
        """ override TestAsServer """
        TestAsServer.setUpPreSession(self)
        self.config.set_swift_proc(True)
        self.config.set_torrent_collecting(True)
        self.config.set_mainline_dht(True)

        self.config2 = self.config.copy()
        self.config2.set_state_dir(self.getStateDir(2))

    def tearDown(self):
        if self.session2:
            self._shutdown_session(self.session2)
            time.sleep(10)

        TestAsServer.tearDown(self)

    def _create_and_save_torrent(self, session, filename):
        tdef = TorrentDef()
        sourcefn = os.path.join(BASE_DIR, "API", filename)
        tdef.add_content(sourcefn)
        tdef.set_tracker("http://fake.net/announce")
        tdef.finalize()

        torrentfn = os.path.join(session.get_state_dir(), "gen.torrent")
        tdef.save(torrentfn)

        sdef, swiftpath = session.lm.rtorrent_handler._move_to_collected(torrentfn)
        return tdef.get_id() if tdef else None, sdef.get_id()

    def test_torrent_collecting(self):
        infohash, roothash = self._create_and_save_torrent(self.session, 'video2.avi')

        from Tribler.dispersy.candidate import Candidate
        candidate = Candidate(("127.0.0.1", self.session.get_swift_tunnel_listen_port()), True)

        event = threading.Event()
        starttime = time.time()
        self.session2.lm.rtorrent_handler.download_torrent(candidate, infohash, roothash, lambda filename: event.set(), prio=1, timeout=60)

        assert event.wait(60)
        print >> sys.stderr, "took", time.time() - starttime

    def seeder_state_callback(self, ds):
        d = ds.get_download()
        print >> sys.stderr, long(time.time()), "test: seeder:", `d.get_def().get_name()`, dlstatus_strings[ds.get_status()], ds.get_progress()

        if ds.get_status() == DLSTATUS_SEEDING:
            self.seeding_event.set()
        return (1.0, False)

########NEW FILE########
__FILENAME__ = test_tracker_checking
import os
from time import sleep

from Tribler.TrackerChecking.TorrentChecking import TorrentChecking

from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.CacheDB.SqliteCacheDBHandler import TorrentDBHandler, \
    MyPreferenceDBHandler

from Tribler.Test.test_as_server import BASE_DIR, TestAsServer


class TestTorrentChecking(TestAsServer):

    def setUp(self):
        TestAsServer.setUp(self)

        self.tdb = TorrentDBHandler.getInstance()
        self.tdb.mypref_db = MyPreferenceDBHandler.getInstance()

        self.torrentChecking = TorrentChecking.getInstance()
        self.torrentChecking.setTorrentSelectionInterval(5)

    def setUpPreSession(self):
        TestAsServer.setUpPreSession(self)
        self.config.set_torrent_checking(True)
        self.config.set_megacache(True)
        self.config.set_torrent_checking_period(5.0)

    # ------------------------------------------------------------
    # Unit Test for TorrentChecking thread.
    # ------------------------------------------------------------
    def test_torrent_checking(self):
        tdef = TorrentDef.load(os.path.join(BASE_DIR, "data", "Pioneer.One.S01E06.720p.x264-VODO.torrent"))
        tdef.set_tracker("http://95.211.198.141:2710/announce")
        tdef.metainfo_valid = True

        self.tdb.addExternalTorrent(tdef)
        sleep(15)

        torrent = self.tdb.getTorrent(tdef.get_infohash())
        self._logger.debug('got torrent %s', torrent)

        num_seeders = torrent['num_seeders']
        num_leechers = torrent['num_leechers']
        assert num_leechers >= 0 or num_seeders >= 0, (num_leechers, num_seeders)

########NEW FILE########
__FILENAME__ = test_url
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# * URL 2 TorrentDef
#
#  - missing fields
#  - malformed fields
#    - bad syntax
#    - bad length
#
# * TorrentDef 2 URL
#  - Creates right URL from params
#
# Move to API dir?
#

import sys
import os
import logging

from Tribler.Core.TorrentDef import TorrentDef

from Tribler.Test.test_as_server import AbstractServer

logger = logging.getLogger(__name__)

DEBUG = False


class TestP2PURLs(AbstractServer):
    """
    Testing P2P URLs version 0
    """

    def test_url_syntax(self):
        """
        URL syntax parsing
        tribe://127.2.3.42:7764/announce?SjaakCam.mpegts&k=MHowDQYJKoZIhvcNAQEBBQADaQAwZgJhAN0Khlp5ZhWC7VfLynCkKts71b8h8tZXH87PkDtJUTJaX_SS1Cddxkv63PRmKOvtAHhkTLSsWOZbSeHkOlPIq_FGg2aDLDJ05g3lQ-8mSmo05ff4SLqNUTShWO2CR2TPhQIBAw&l=HCAAAA&s=15&a=RSA&b=AAIAAA
        tribe://127.1.0.10:6969/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg
        """
        badurllist = []

        badurllist += [("ribe://127.1.0.10:6969/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "wrong scheme")]
        badurllist += [("tribe//127.1.0.10:6969/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "no colon after scheme")]
        # badurllist += [("tribe://127.1.0.10:6969/announce?trai ler.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "space not escaped")] # too strict
        # badurllist += [("tribe://localhost;10/?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "bad port spec")] # too strict
        badurllist += [("tribe://localhost:https/?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "port not int")]
        badurllist += [("tribe://localhost/trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "not query")]
        if sys.platform != "win32":
            badurllist += [("tribe://localhost?tr\xfeiler.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "char in name not URL escaped")]
        badurllist += [("tribe://localhost?Sjaak&", "query with empty key=value")]
        badurllist += [("tribe://localhost?trailer.mkv&r:TTgcifG0Ot7STCY2JL8SUOxROFo&l:AKK35A&s=15&b:AAFnGg", "key value not separated by =")]
        badurllist += [("tribe://localhost?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b:AAFnGg", "some key value not separated by =")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=", "query with malformed key value")]

        # IPv6 addresses
        badurllist += [("tribe://[FEDC:BA98:7654:3210:FEDC:BA98:7654:3210:6969/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "unclosed IPv6 literal address")]
        badurllist += [("tribe://FEDC:BA98:7654:3210:FEDC:BA98:7654:3210]:6969/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "unopened IPv6 literal address")]
        badurllist += [("tribe://[FEDC:BA98:7654:3210:FEDC:BA98:7654:3210/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "unclosed IPv6 literal address, no port")]
        badurllist += [("tribe://FEDC:BA98:7654:3210:FEDC:BA98:7654:3210]/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "unopened IPv6 literal address, no port")]

        self.run_badurllist(badurllist)

    def test_missing(self):
        badurllist = []
        badurllist += [("tribe:/", "missing all fields")]
        badurllist += [("tribe://", "missing authority")]
        badurllist += [("tribe://localhost", "missing query fields")]
        badurllist += [("tribe://localhost?", "empty query")]
        badurllist += [("tribe://localhost?Sjaak", "query just name")]
        badurllist += [("tribe://localhost?n=Sjaak", "query just name")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo", "query with just valid root hash")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A", "query with missing piece size+bitrate")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15", "query with missing bitrate")]

        # live
        badurllist += [("tribe://127.2.3.42:7764/announce?SjaakCam.mpegts&k=MHowDQYJKoZIhvcNAQEBBQADaQAwZgJhAN0Khlp5ZhWC7VfLynCkKts71b8h8tZXH87PkDtJUTJaX_SS1Cddxkv63PRmKOvtAHhkTLSsWOZbSeHkOlPIq_FGg2aDLDJ05g3lQ-8mSmo05ff4SLqNUTShWO2CR2TPhQIBAw&l=HCAAAA&s=15&b=AAIAAA", "query with missing live auth method")]

        self.run_badurllist(badurllist)

    def test_encoding(self):
        badurllist = []
        badurllist += [("tribe://localhost?Sjaak&r=\xd3]\xb7\xe3\x9e\xbb\xf3\xdd5\xdb~9\xeb\xbf=\xd3]\xb7\xe3\x9e&l=AKK35A&s=15&b=AAFnGg", "query with non-BASE64URL encoded root hash")]
        badurllist += [("tribe://127.1.0.10:6969/announce?trailer.mkv&r=TTgcifG0Ot7ST!Y2JL8SUOxROFo&l=AKK35A&s=15&b=AAFnGg", "query with invalid BASE64URL encoded root hash, contains !")]
        badurllist += [("tribe://127.1.0.10:6969/announce?trailer.mkv&r=TTgcifG0Ot7STCY2JL8SUOxROFo=&l=AKK35A&s=15&b=AAFnGg", "query with invalid BASE64URL encoded root hash, contains = padding")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=1234&s=15&b=AAFnGg", "query with non-encoded length")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=1234&b=AAFnGg", "query with non-encoded piece size")]
        badurllist += [("tribe://localhost?Sjaak&r=TTgcifG0Ot7STCY2JL8SUOxROFo&l=AKK35A&s=15&b=1234", "query with non-encoded bitrate")]

        # live
        badurllist += [("tribe://127.2.3.42:7764/announce?SjaakCam.mpegts&k=MHowDQYJKoZIhvc!AQEBBQADaQAwZgJhAN0Khlp5ZhWC7VfLynCkKts71b8h8tZXH87PkDtJUTJaX_SS1Cddxkv63PRmKOvtAHhkTLSsWOZbSeHkOlPIq_FGg2aDLDJ05g3lQ-8mSmo05ff4SLqNUTShWO2CR2TPhQIBAw&l=HCAAAA&s=15&a=RSA&b=AAIAAA", "query with invalid BASE64URL encoded live public key, contains !")]

        self.run_badurllist(badurllist)

    def run_badurllist(self, badurllist):
        for url, problem in badurllist:
            try:
                tdef = TorrentDef.load_from_url(url)
                self.assert_(tdef == None, 'Should not have accepted URL: "%s", %s ' % (url, problem))
            except AssertionError, e:
                raise e
            except:
                logger.debug("", exc_info=True)

    def test_create_vod(self):
        paramlist = []
        paramlist += [('Sjaak', 134349, 2 ** 15, "4:01")]
        paramlist += [('Sjaak', 1343490, 2 ** 15, "1:04:01")]  # long duration
        paramlist += [('Sjaak Harry', 134349, 2 ** 15, "4:01")]  # space in name
        paramlist += [(u'Serg\u00e9Harr\u014c', 134349, 2 ** 15, "4:01")]  # Unicode name
        paramlist += [(u'\u4f60\u597d', 134349, 2 ** 15, "4:01")]  # Unicode name, Ni Hao ;o)

        self.run_paramlist_vod(paramlist, "http://127.0.0.1/announce")
        # self.run_paramlist_vod(paramlist,"http://[FEDC:BA98:7654:3210:FEDC:BA98:7654:3210]/announce")

    def run_paramlist_vod(self, paramlist, tracker):
        tmpdirname = self.getStateDir()

        for name, leng, piecesize, duration in paramlist:
            # Niels: creating utf8 torrents seems to cause problems when removing them on windows?
            tmpfilename = os.path.join(tmpdirname, name)

            content = '*' * leng
            f = open(tmpfilename, "wb")
            f.write(content)
            f.close()

            tdef = TorrentDef()
            tdef.add_content(tmpfilename, playtime=duration)
            tdef.set_tracker(tracker)
            tdef.set_piece_length(piecesize)
            tdef.set_create_merkle_torrent(True)
            # Arno, 2009-10-02: Explicitly set encoding to UTF-8. Default on
            # Win32 is 'mbcs'. Python cannot properly encode this,
            # u'\u4f60\u597d.ts' becomes '??.ts' (literally, ? = char(63))
            #
            tdef.set_encoding('UTF-8')
            tdef.set_url_compat(True)
            tdef.finalize()
            logger.debug("URL %s", tdef.get_url())

            tdef2 = TorrentDef.load_from_url(tdef.get_url())

            if isinstance(name, unicode):
                utf8name = name.encode("UTF-8")
            else:
                utf8name = name

            # logger.debug("ORIG NAME %s", `utf8name`)
            # logger.debug("TDEF NAME %s", `tdef2.get_name()`)

            self.assertEqual(tdef2.get_name(), utf8name)
            self.assertEqual(tdef2.get_length(), leng)
            self.assertEqual(tdef2.get_piece_length(), piecesize)
            tbitrate = tdef2.get_bitrate()
            s = dur2s(duration)
            ebitrate = leng / s
            self.assertEqual(tbitrate, ebitrate)

# TODO: Remove this and use the utility function instead.
def dur2s(dur):
    """ [hh]mm:ss -> seconds """
    elems = dur.split(":")
    s = 0
    for i in range(0, len(elems)):
        num = int(elems[i])
        t = num * int(pow(60.0, len(elems) - i - 1))
        s += t
    return s

########NEW FILE########
__FILENAME__ = test_video_server
# Written by Arno Bakker
# see LICENSE.txt for license information
import os
import sys
import time
import socket
import random
import binascii
from traceback import print_exc

from Tribler.Test.test_as_server import BASE_DIR, TestAsServer
from Tribler.Core.Video.VideoPlayer import VideoPlayer
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.DownloadConfig import DownloadStartupConfig

DEBUG = True


class TestVideoHTTPServer(TestAsServer):

    """
    Class for testing HTTP-based video server.

    Mainly HTTP range queries.
    """

    def setUp(self):
        """ unittest test setup code """
        TestAsServer.setUp(self)
        self.port = self.session.get_videoplayer_port()
        self.sourcefn = os.path.join(BASE_DIR, "data", "video.avi")
        self.sourcesize = os.path.getsize(self.sourcefn)

        # wait 5s to allow server to start
        time.sleep(5)

    def setUpPreSession(self):
        TestAsServer.setUpPreSession(self)
        self.config.set_libtorrent(True)
        self.config.set_videoplayer(True)

    def tearDown(self):
        """ unittest test tear down code """
        TestAsServer.tearDown(self)
        time.sleep(2)

    #
    # Tests
    #
    def test_specific_range(self):
        self.range_check(115, 214, self.sourcesize)

    def test_last_100(self):
        self.range_check(self.sourcesize - 100, None, self.sourcesize)

    def test_first_100(self):
        self.range_check(None, 100, self.sourcesize)

    def test_combined(self):
        self.range_check(115, 214, self.sourcesize, setset=True)

    #
    # Internal
    #
    def register_file_stream(self):
        self.tdef = TorrentDef()
        self.tdef.add_content(self.sourcefn)
        self.tdef.set_tracker("http://127.0.0.1:12/announce")
        self.tdef.finalize()

        dscfg = DownloadStartupConfig()
        dscfg.set_dest_dir(os.path.dirname(self.sourcefn))

        download = self.session.start_download(self.tdef, dscfg)
        while not download.handle:
            time.sleep(1)

    def get_std_header(self):
        msg = "GET /%s/0 HTTP/1.1\r\n" % binascii.hexlify(self.tdef.get_infohash())
        msg += "Host: 127.0.0.1:" + str(self.port) + "\r\n"
        return msg

    def create_range_str(self, firstbyte, lastbyte):
        head = ""
        if firstbyte is not None:
            head += str(firstbyte)
        head += "-"
        if lastbyte is not None:
            head += str(lastbyte)

        return head

    def range_check(self, firstbyte, lastbyte, sourcesize, setset=False):
        if DEBUG:
            print >> sys.stderr, "test: range_test:", firstbyte, lastbyte, sourcesize, "setset", setset
        self.register_file_stream()

        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.connect(('127.0.0.1', self.port))

        head = self.get_std_header()

        head += "Range: bytes="
        head += self.create_range_str(firstbyte, lastbyte)
        if setset:
            # Make into set of byte ranges, VideoHTTPServer should refuse.
            head += ",0-99"
        head += "\r\n"

        head += "Connection: close\r\n"

        head += "\r\n"

        if firstbyte is not None and lastbyte is None:
            # 100-
            expfirstbyte = firstbyte
            explastbyte = self.sourcesize - 1
        elif firstbyte is None and lastbyte is not None:
            # -100
            expfirstbyte = self.sourcesize - lastbyte
            explastbyte = self.sourcesize - 1
        else:
            expfirstbyte = firstbyte
            explastbyte = lastbyte

        # the amount of bytes actually requested. (Content-length)
        expsize = explastbyte - expfirstbyte + 1

        if DEBUG:
            print >> sys.stderr, "test: Expecting first", expfirstbyte, "last", explastbyte, "size", sourcesize
        s.send(head)

        # Parse header
        s.settimeout(10.0)
        while True:
            line = self.readline(s)
            if DEBUG:
                print >> sys.stderr, "test: Got line", repr(line)

            if len(line) == 0:
                if DEBUG:
                    print >> sys.stderr, "test: server closed conn"
                self.assert_(False)
                return

            if line.startswith("HTTP"):
                if not setset:
                    # Python returns "HTTP/1.0 206 Partial Content\r\n" HTTP 1.0???
                    self.assert_(line.startswith("HTTP/1."))
                    self.assert_(line.find("206") != -1)  # Partial content
                else:
                    self.assert_(line.startswith("HTTP/1."))
                    self.assert_(line.find("416") != -1)  # Requested Range Not Satisfiable
                    return

            elif line.startswith("Content-Range:"):
                expline = "Content-Range: bytes " + self.create_range_str(expfirstbyte, explastbyte) + "/" + str(sourcesize) + "\r\n"
                self.assertEqual(expline, line)

            elif line.startswith("Content-Type:"):
                self.assertEqual(line, "Content-Type: video/x-msvideo\r\n")

            elif line.startswith("Content-Length:"):
                self.assertEqual(line, "Content-Length: " + str(expsize) + "\r\n")

            elif line.endswith("\r\n") and len(line) == 2:
                # End of header
                break

        data = s.recv(expsize)
        if len(data) == 0:
            if DEBUG:
                print >> sys.stderr, "test: server closed conn2"
            self.assert_(False)
            return
        else:
            f = open(self.sourcefn, "rb")
            if firstbyte is not None:
                f.seek(firstbyte)
            else:
                f.seek(lastbyte, os.SEEK_END)

            expdata = f.read(expsize)
            f.close()
            self.assert_(data, expdata)

            try:
                # Read body, reading more should EOF (we disabled persist conn)
                data = s.recv(10240)
                self.assert_(len(data) == 0)

            except socket.timeout:
                if DEBUG:
                    print >> sys.stderr, "test: Timeout, video server didn't respond with requested bytes, possibly bug in Python impl of HTTP"
                    print_exc()

    def readline(self, s):
        line = ''
        while True:
            data = s.recv(1)
            if len(data) == 0:
                return line
            else:
                line = line + data
            if data == '\n' and len(line) >= 2 and line[-2:] == '\r\n':
                return line

########NEW FILE########
__FILENAME__ = test_vod
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TODO: we download from Tribler
#

import os
import sys
from tempfile import mkstemp
from M2Crypto import Rand
from threading import Event

from Tribler.Test.test_as_server import TestAsServer
from Tribler.Core.simpledefs import dlstatus_strings, UPLOAD, DOWNLOAD, DLMODE_VOD
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.DownloadConfig import DownloadStartupConfig
from Tribler.Core.Libtorrent.LibtorrentDownloadImpl import VODFile


class TestVideoOnDemand(TestAsServer):

    """
    Testing Merkle hashpiece messages for both:
    * Merkle BEP style
    * old Tribler <= 4.5.2 that did not use the Extention protocol (BEP 10).

    See BitTornado/BT1/Connecter.py
    """

    def setUp(self):
        """ override TestAsServer """
        TestAsServer.setUp(self)

    def setUpPreSession(self):
        TestAsServer.setUpPreSession(self)
        self.config.set_libtorrent(True)

    def create_torrent(self):
        [srchandle, self.sourcefn] = mkstemp()
        self.content = Rand.rand_bytes(self.contentlen)
        os.write(srchandle, self.content)
        os.close(srchandle)

        self.tdef = TorrentDef()
        self.tdef.add_content(self.sourcefn)
        self.tdef.set_piece_length(self.piecelen)
        self.tdef.set_tracker("http://127.0.0.1:12/announce")
        self.tdef.finalize()

        self.torrentfn = os.path.join(self.session.get_state_dir(), "gen.torrent")
        self.tdef.save(self.torrentfn)

        dscfg = DownloadStartupConfig()
        destdir = os.path.dirname(self.sourcefn)
        dscfg.set_dest_dir(destdir)
        dscfg.set_mode(DLMODE_VOD)

        download = self.session.start_download(self.tdef, dscfg)
        download.set_state_callback(self.state_callback)

        self.session.set_download_states_callback(self.states_callback)

    def states_callback(self, dslist):
        ds = dslist[0]
        d = ds.get_download()
        # print >>sys.stderr,`d.get_def().get_name()`,dlstatus_strings[ds.get_status()],ds.get_progress(),"%",ds.get_error(),"up",ds.get_current_speed(UPLOAD),"down",ds.get_current_speed(DOWNLOAD)
        print >> sys.stderr, '%s %s %5.2f%% %s up %8.2fKB/s down %8.2fKB/s' % \
            (d.get_def().get_name(),
                dlstatus_strings[ds.get_status()],
                ds.get_progress() * 100,
                ds.get_error(),
                ds.get_current_speed(UPLOAD),
                ds.get_current_speed(DOWNLOAD))

        return (1.0, [])

    def state_callback(self, ds):
        download = ds.get_download()
        if ds.get_vod_prebuffering_progress() == 1.0:

            print >> sys.stderr, "Test: state_callback"

            stream = VODFile(open(download.get_content_dest(), 'rb'), download)

            # Read last piece
            lastpieceoff = ((self.contentlen - 1) / self.piecelen) * self.piecelen
            lastpiecesize = self.contentlen - lastpieceoff
            print >> sys.stderr, "Test: stream: lastpieceoff", lastpieceoff, lastpiecesize
            self.stream_read(stream, lastpieceoff, lastpiecesize, self.piecelen)

            # Read second,3rd,4th byte, only
            secoff = 1
            secsize = 3
            blocksize = 3
            self.stream_read(stream, secoff, secsize, blocksize)

            # Read last byte
            lastoff = self.contentlen - 1
            lastsize = 1
            self.stream_read(stream, lastoff, lastsize, self.piecelen)

            self.event.set()

            return (0, False)
        return (1.0, False)

    def stream_read(self, stream, off, size, blocksize):
        stream.seek(off)
        data = stream.read(blocksize)
        print >> sys.stderr, "Test: stream: Got data", len(data)
        self.assertEquals(len(data), size)
        self.assertEquals(data, self.content[off:off + size])

    def test_99(self):
        self.event = Event()
        self.contentlen = 99
        self.piecelen = 10
        self.create_torrent()

        print >> sys.stderr, "Test: Letting network thread create Download, sleeping"
        assert self.event.wait(5)

    def test_100(self):
        self.event = Event()
        self.contentlen = 100
        self.piecelen = 10
        self.create_torrent()

        print >> sys.stderr, "Test: Letting network thread create Download, sleeping"
        assert self.event.wait(5)

    def test_101(self):
        self.event = Event()
        self.contentlen = 101
        self.piecelen = 10
        self.create_torrent()

        print >> sys.stderr, "Test: Letting network thread create Download, sleeping"
        assert self.event.wait(5)

########NEW FILE########
__FILENAME__ = TorrentChecking
# ============================================================
# Written by Lipu Fei,
# optimizing the TrackerChecking module written by Niels Zeilemaker.
#
# see LICENSE.txt for license information
#
# TODO: add comments
# ============================================================
import os
import binascii
import time
import logging

import select
import socket

import threading
from threading import Thread
import Queue

from traceback import print_exc

from Tribler.Core.Session import Session
from Tribler.Core.TorrentDef import TorrentDef
from Tribler.Core.Swift.SwiftDef import SwiftDef
from Tribler.Core import NoDispersyRLock

try:
    prctlimported = True
    import prctl
except ImportError as e:
    prctlimported = False

from Tribler.TrackerChecking.TrackerUtility import getUniformedURL
from Tribler.TrackerChecking.TrackerInfoCache import TrackerInfoCache
from Tribler.TrackerChecking.TrackerSession import TrackerSession
from Tribler.TrackerChecking.TrackerSession import TRACKER_ACTION_CONNECT
from Tribler.TrackerChecking.TrackerSession import MAX_TRACKER_MULTI_SCRAPE

from Tribler.Core.Utilities.utilities import parse_magnetlink
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread, bin2str
from Tribler.Core.CacheDB.SqliteCacheDBHandler import TorrentDBHandler


# some settings
DEFAULT_MAX_GUI_REQUESTS = 5000

DEFAULT_TORRENT_SELECTION_INTERVAL = 20  # every 20 seconds, the thread will select torrents to check
DEFAULT_TORRENT_CHECK_INTERVAL = 900  # a torrent will only be checked every 15 mins

DEFAULT_MAX_TORRENT_CHECK_RETRIES = 8
DEFAULT_TORRENT_CHECK_RETRY_INTERVAL = 30

# ============================================================
# This is the single-threaded tracker checking class.
# ============================================================
class TorrentChecking(Thread):

    __single = None

    # ------------------------------------------------------------
    # Intialization.
    # ------------------------------------------------------------
    def __init__(self, \
            torrent_select_interval=DEFAULT_TORRENT_SELECTION_INTERVAL,
            torrent_check_interval=DEFAULT_TORRENT_CHECK_INTERVAL,
            max_torrrent_check_retries=DEFAULT_MAX_TORRENT_CHECK_RETRIES,
            torrrent_check_retry_interval=DEFAULT_TORRENT_CHECK_RETRY_INTERVAL):
        if TorrentChecking.__single:
            raise RuntimeError("Torrent Checking is singleton")
        TorrentChecking.__single = self

        Thread.__init__(self)

        self._logger = logging.getLogger(self.__class__.__name__)

        name = 'TorrentChecking' + self.getName()
        self.setName(name)

        self._logger.debug('Starting TorrentChecking from %s.', threading.currentThread().getName())
        self.setDaemon(True)

        self._torrentdb = TorrentDBHandler.getInstance()
        self._interrupt_socket = InterruptSocket()

        self._lock = NoDispersyRLock()
        self._session_list = []
        self._pending_response_dict = dict()

        # initialize a tracker status cache, TODO: add parameters
        self._tracker_info_cache = TrackerInfoCache()

        self._tracker_selection_idx = 0
        self._torrent_select_interval = torrent_select_interval
        self._torrent_check_interval = torrent_check_interval

        self._max_torrrent_check_retries = max_torrrent_check_retries
        self._torrrent_check_retry_interval = torrrent_check_retry_interval

        # self._max_gui_requests = DEFAULT_MAX_GUI_REQUESTS
        self._gui_request_queue = Queue.Queue()
        self._processed_gui_request_queue = Queue.Queue()

        self._should_stop = False

        self._tor_col_dir = Session.get_instance().get_torrent_collecting_dir()

    # ------------------------------------------------------------
    # (Public API)
    # The public interface to initialize and get the single instance.
    # ------------------------------------------------------------
    @staticmethod
    def getInstance(*args, **kw):
        if TorrentChecking.__single is None:
            TorrentChecking(*args, **kw)
        return TorrentChecking.__single

    # ------------------------------------------------------------
    # (Public API)
    # The public interface to delete the single instance.
    # ------------------------------------------------------------
    @staticmethod
    def delInstance():
        TorrentChecking.__single.shutdown()
        TorrentChecking.__single = None

    # ------------------------------------------------------------
    # (Public API)
    # Sets the automatic torrent selection interval.
    # ------------------------------------------------------------
    def setTorrentSelectionInterval(self, interval):
        self._torrent_select_interval = interval

    # ------------------------------------------------------------
    # (Public API)
    # The public interface to shutdown the thread.
    # ------------------------------------------------------------
    def shutdown(self):
        if not self._should_stop:
            self._should_stop = True
            self._interrupt_socket.interrupt()

    # ------------------------------------------------------------
    # (Public API)
    # The public API interface to add a torrent check request. Returns true
    # if successful, false otherwise.
    # Note that, the input argument "gui_torrent" is of class
    # "Tribler.Main.Utility.GuiDBTuples.Torrent", NOT "Core.TorrentDef"!
    # So you need to get the TorrentDef to access more information
    # ------------------------------------------------------------
    def addGuiRequest(self, gui_torrent):
        # enqueue a new GUI request
        successful = True
        try:
            gui_request = dict()
            if gui_torrent.torrent_id > 0:
                gui_request['torrent_id'] = gui_torrent.torrent_id
            gui_request['infohash'] = gui_torrent.infohash
            gui_request['trackers'] = set()
            if 'trackers' in gui_torrent:
                for tracker in gui_torrent.trackers:
                    gui_request['trackers'].add(tracker)

            self._gui_request_queue.put_nowait(gui_request)
            self._interrupt_socket.interrupt()

        except Queue.Full:
            self._logger.debug('TorrentChecking: GUI request queue is full.')
            successful = False

        except Exception as e:
            self._logger.debug('TorrentChecking: Unexpected error while adding GUI request: %s', e)
            successful = False

        return successful

    # ------------------------------------------------------------
    # Processes a GUI request.
    # ------------------------------------------------------------
    @forceDBThread
    def _processGuiRequests(self, gui_requests):
        for gui_request in gui_requests:
            infohash = gui_request['infohash']
            tracker_set = gui_request['trackers']

            if 'last_check' in gui_requests:
                last_check = gui_requests['last_check']
            else:
                last_check = self._torrentdb.getTorrent(infohash, ("torrent_id", "last_tracker_check"), False)
                last_check = last_check["last_tracker_check"]
            time_diff = time.time() - last_check
            if time_diff < self._torrent_check_interval:
                self._logger.debug("Ignoring a GUI request, time interval too short")
                continue

            if 'torrent_id' in gui_request:
                torrent_id = gui_request['torrent_id']
            else:
                torrent_id = self._torrentdb.getTorrentID(infohash)

            if torrent_id <= 0:
                self._logger.debug("TorrentChecking: ignoring gui request, no torrent_id")
                continue

            if not tracker_set:
                # get torrent's tracker list from DB
                db_tracker_list = self._getTrackerList(torrent_id, infohash)
                for tracker in db_tracker_list:
                    tracker_set.add(tracker)

            if not tracker_set:
                self._logger.debug("TorrentChecking: ignoring gui request, no trackers")
                # TODO: add method to handle torrents with no tracker
                continue

            self._processed_gui_request_queue.put((torrent_id, infohash, tracker_set))
            self._interrupt_socket.interrupt()

    def _onProcessedGuiRequests(self, gui_requests):
        # for each valid tracker, try to create new session or append
        # the request to an existing session
        for torrent_id, infohash, tracker_set in gui_requests:
            for tracker_url in tracker_set:
                self._updateTorrentTrackerMapping(torrent_id, tracker_url)
                self._createSessionForRequest(infohash, tracker_url)

    # ------------------------------------------------------------
    # Gets a list of all known trackers of a given torrent.
    # It checks the TorrentTrackerMapping table and magnet links.
    # ------------------------------------------------------------
    def _getTrackerList(self, torrent_id, infohash):
        tracker_set = set()

        # get trackers from DB (TorrentTrackerMapping table)
        db_tracker_list = self._torrentdb.getTrackerListByTorrentID(torrent_id)
        for tracker in db_tracker_list:
            tracker_set.add(tracker)

        # get trackers from its magnet link
        source_list = self._torrentdb.getTorrentCollecting(torrent_id)
        for source, in source_list:
            if not source.startswith('magnet'):
                continue

            dn, xt, trackers = parse_magnetlink(source)
            if not trackers:
                continue
            for tracker in trackers:
                tracker_set.add(tracker)

        # get trackers from its .torrent file
        result = None
        torrent = self._torrentdb.getTorrent(infohash, ['torrent_file_name', 'swift_torrent_hash'], include_mypref=False)
        if torrent:
            if torrent.get('torrent_file_name', False) and os.path.isfile(torrent['torrent_file_name']):
                result = torrent['torrent_file_name']

            elif torrent.get('swift_torrent_hash', False):
                sdef = SwiftDef(torrent['swift_torrent_hash'])
                torrent_filename = os.path.join(self._tor_col_dir, sdef.get_roothash_as_hex())

                if os.path.isfile(torrent_filename):
                    result = torrent_filename
        if result:
            try:
                torrent = TorrentDef.load(result)
                # check DHT
                if torrent.is_private():
                    dht = 'no-DHT'
                else:
                    dht = 'DHT'
                tracker_set.add(dht)

                torrent_tracker_tuple = torrent.get_trackers_as_single_tuple()
                for tracker in torrent_tracker_tuple:
                    tracker_set.add(tracker)
            except:
                pass

        checked_tracker_set = set()
        for tracker in tracker_set:
            if tracker == 'no-DHT' or tracker == 'DHT':
                continue
            tracker_url = getUniformedURL(tracker)
            if tracker_url:
                checked_tracker_set.add(tracker_url)

        return list(checked_tracker_set)

    # ------------------------------------------------------------
    # Updates the TorrentTrackerMapping table.
    # ------------------------------------------------------------
    @forceDBThread
    def _updateTorrentTrackerMapping(self, torrent_id, tracker):
        self._torrentdb.addTorrentTrackerMapping(torrent_id, tracker)

    # ------------------------------------------------------------
    # Creates a new session for a request, or append the request to an
    # existings tracker session.
    # ------------------------------------------------------------
    def _createSessionForRequest(self, infohash, tracker_url):
        # skip DHT, for now
        if tracker_url == 'no-DHT' or tracker_url == 'DHT':
            return

        # >> Step 1: Try to append the request to an existing session
        # check there is any existing session that scrapes this torrent
        request_handled = False
        with self._lock:
            for session in self._session_list:
                if session.getTracker() != tracker_url or session.hasFailed():
                    continue

                if session.hasInfohash(infohash):
                    # a torrent check is already there, ignore this request
                    request_handled = True
                    break

                if not session.hasInitiated():
                    # only append when the request is less than 74
                    if session.getInfohashListSize() < MAX_TRACKER_MULTI_SCRAPE:
                        session.addInfohash(infohash)
                        self._updatePendingResponseDict(infohash)
                        request_handled = True
                        break

        if request_handled:
            self._logger.debug('TorrentChecking: Session [%s] appended.', binascii.b2a_hex(infohash))
            return

        # >> Step 2: No session to append to, create a new one
        # create a new session for this request
        session = None
        try:
            session = TrackerSession.createSession(tracker_url, self.updateResultFromSession)

            connectionEstablished = session.establishConnection()
            if not connectionEstablished:
                raise RuntimeError('Cannot establish connection.')

            session.addInfohash(infohash)

            with self._lock:
                self._session_list.append(session)
                self._interrupt_socket.interrupt()

            # update the number of responses this torrent is expecting
            self._updatePendingResponseDict(infohash)

            self._logger.debug('TorrentChecking: Session [%s] created.', binascii.b2a_hex(infohash))

        except Exception as e:
            self._logger.debug('TorrentChecking: Failed to create session for tracker[%s]: %s', tracker_url, e)

            if session:
                session.cleanup()

            self._tracker_info_cache.updateTrackerInfo(tracker_url, False)

    # ------------------------------------------------------------
    # Updates the pending response dictionary.
    # ------------------------------------------------------------
    def _updatePendingResponseDict(self, infohash):

        if infohash in self._pending_response_dict:
            self._pending_response_dict[infohash]['remainingResponses'] += 1
            self._pending_response_dict[infohash]['updated'] = False
        else:
            self._pending_response_dict[infohash] = {'infohash': infohash, 'remainingResponses': 1, 'seeders':-2, 'leechers':-2, 'updated': False}

    # ------------------------------------------------------------
    # Updates the result of a pending request.
    # This method is only used by TrackerSession to update a retrieved result.
    # ------------------------------------------------------------
    def updateResultFromSession(self, infohash, seeders, leechers):
        response = self._pending_response_dict[infohash]
        response['last_check'] = int(time.time())
        if response['seeders'] < seeders or \
                (response['seeders'] == seeders and response['leechers'] < leechers):
            response['seeders'] = seeders
            response['leechers'] = leechers
            response['updated'] = True

    # ------------------------------------------------------------
    # Updates result into the database.
    # ------------------------------------------------------------
    @forceDBThread
    def _updateTorrentResult(self, response):
        infohash = response['infohash']
        seeders = response['seeders']
        leechers = response['leechers']
        last_check = response['last_check']

        # the torrent status logic, TODO: do it in other way
        self._logger.debug("TorrentChecking: Update result %d/%d for %s", seeders, leechers, bin2str(infohash))

        torrent_id = self._torrentdb.getTorrentID(infohash)
        retries = self._torrentdb.getTorrentCheckRetries(torrent_id)

        # the result logic
        is_good_result = False
        if seeders > 0 or leechers > 0:
            is_good_result = True

        # the status logic
        if is_good_result:
            retries = 0
            status = u'good'
        else:
            retries += 1
            if retries < self._max_torrrent_check_retries:
                status = u'unknown'
            else:
                status = u'dead'
                # prevent retries from exceeding the maximum
                retries = self._max_torrrent_check_retries

        # calculate next check time: <last-time> + <interval> * (2 ^ <retries>)
        next_check = last_check + self._torrrent_check_retry_interval * (2 ** retries)

        self._torrentdb.updateTorrentCheckResult(torrent_id,
                infohash, seeders, leechers, last_check, next_check,
                status, retries)

    # ------------------------------------------------------------
    # Updates the check result into the database
    # This is for the torrents whose checks have failed and the results
    # will be -2/-2 at last.
    # ------------------------------------------------------------
    @forceDBThread
    def _checkResponseFinal(self, response):
        seeders = response['seeders']
        leechers = response['leechers']

        # the result logic
        is_good_result = False
        if seeders > 0 or leechers > 0:
            is_good_result = True

        if is_good_result:
            return

        response['seeders'] = 0
        response['leechers'] = 0
        response['last_check'] = int(time.time())

        self._updateTorrentResult(response)

    # ------------------------------------------------------------
    # Selects torrents to check.
    # This method selects trackers in Round-Robin fashion.
    # ------------------------------------------------------------
    @forceDBThread
    def _selectTorrentsToCheck(self):
        current_time = int(time.time())
        for _ in range(self._tracker_info_cache.getTrackerInfoListSize()):
            # update the new tracker index
            self._tracker_selection_idx = (self._tracker_selection_idx + 1) % self._tracker_info_cache.getTrackerInfoListSize()

            tracker, _ = self._tracker_info_cache.getTrackerInfo(self._tracker_selection_idx)
            self._logger.debug('TorrentChecking: Should we check tracker[%s].', tracker)

            if tracker == 'no-DHT' or tracker == 'DHT' or not self._tracker_info_cache.toCheckTracker(tracker):
                continue

            self._logger.debug('TorrentChecking: Selecting torrents to check on tracker[%s].', tracker)

            # get all the torrents on this tracker
            try:
                all_torrent_list = self._torrentdb.getTorrentsOnTracker(tracker, current_time)
            except:
                print_exc()
                return

            # get the torrents that should be checked
            scheduled_torrents = 0
            for torrent_id, infohash, last_check in all_torrent_list:
                # check interval
                interval = current_time - last_check

                # recheck interval is: interval * 2^(retries)
                if interval < self._torrent_check_interval:
                    continue

                self._processed_gui_request_queue.put((torrent_id, infohash, [tracker, ]))
                scheduled_torrents += 1

            if scheduled_torrents:
                self._interrupt_socket.interrupt()
                self._logger.debug('TorrentChecking: Selected %d torrents to check on tracker[%s].', scheduled_torrents, tracker)
                break

            else:
                self._logger.debug('TorrentChecking: Selected 0 torrents to check on tracker[%s].', tracker)

    # ------------------------------------------------------------
    # The thread function.
    # ------------------------------------------------------------
    def run(self):
        # TODO: someone please check this? I am not really sure what this is.
        if prctlimported:
            prctl.set_name("Tribler" + threading.currentThread().getName())

        # wait for the tracker info cache to be initialized
        self._logger.debug('TorrentChecking: Start initializing TrackerInfoCache...')

        self._tracker_info_cache.loadCacheFromDb()

        self._logger.debug('TorrentChecking: TrackerInfoCache initialized.')
        self._logger.info('TorrentChecking: initialized.')

        last_time_select_torrent = 0
        while not self._should_stop:
            def process_queue(queue, callback):
                requests = []

                try:
                    while True:
                        requests.append(queue.get_nowait())

                except Queue.Empty:
                    pass

                except Exception as e:
                    self._logger.error('TorrentChecking: Unexpected error while handling requests %s', e)
                    print_exc()

                if requests:
                    callback(requests)

            process_queue(self._gui_request_queue, self._processGuiRequests)
            process_queue(self._processed_gui_request_queue, self._onProcessedGuiRequests)

            # torrent selection
            current_time = int(time.time())
            time_remaining = max(0, self._torrent_select_interval - (current_time - last_time_select_torrent))
            if time_remaining == 0:
                self._logger.debug('TorrentChecking: Selecting new torrent')

                try:
                    self._selectTorrentsToCheck()

                except Exception as e:
                    self._logger.error('TorrentChecking: Unexpected error during TorrentSelection: %s', e)
                    print_exc()

                last_time_select_torrent = current_time
                time_remaining = self._torrent_select_interval
            else:
                self._logger.debug('TorrentChecking: Will wait for an interrupt for %.1f', time_remaining)

            # create read and write socket check list
            # check non-blocking connection TCP sockets if they are writable
            # check UDP and TCP response sockets if they are readable
            check_read_socket_list = [self._interrupt_socket.get_socket()]
            check_write_socket_list = []

            session_dict = {}
            with self._lock:
                for session in self._session_list:
                    session_dict[session.getSocket()] = session

            for session_socket, session in session_dict.iteritems():
                if session.isTrackerType('UDP'):
                    check_read_socket_list.append(session_socket)
                else:
                    if session.isAction(TRACKER_ACTION_CONNECT):
                        check_write_socket_list.append(session_socket)
                    else:
                        check_read_socket_list.append(session_socket)

            # select
            try:
                read_socket_list, write_socket_list, error_socket_list = \
                    select.select(\
                    check_read_socket_list, check_write_socket_list, [], \
                    time_remaining)

            except Exception as e:
                self._logger.debug('TorrentChecking: Error while selecting: %s', e)

            if not self._should_stop:
                current_time = int(time.time())
                # we don't want any unexpected exception to break the loop
                try:
                    # >> Step 1: Check the sockets
                    # check writable sockets (TCP connections)
                    self._logger.debug('TorrentChecking: got %d writable sockets', len(write_socket_list))
                    for write_socket in write_socket_list:
                        session = session_dict[write_socket]
                        session.handleRequest()

                    # check readable sockets
                    self._logger.debug('TorrentChecking: got %d readable sockets', len(read_socket_list))
                    for read_socket in read_socket_list:
                        session = session_dict.get(read_socket, self._interrupt_socket)
                        session.handleRequest()

                    # >> Step 2: Handle timedout UDP sessions
                    for session in session_dict.values():
                        diff = current_time - session.getLastContact()
                        if diff > session.getRetryInterval():
                            session.increaseRetries()

                            if session.getRetries() > session.getMaxRetries():
                                session.setFailed()
                                self._logger.debug('TorrentChecking: UDP Tracker[%s] retried out.', session.getTracker())
                            else:
                                # re-establish the connection
                                session.reestablishConnection()
                                self._logger.debug('TorrentChecking: UDP Tracker[%s] retry, %d.', session.getTracker(), session.getRetries())

                    # >> Step 3: Remove completed sessions
                    with self._lock:
                        for i in range(len(self._session_list) - 1, -1, -1):
                            session = self._session_list[i]

                            if session.hasFailed() or session.hasFinished():
                                self._logger.debug('TorrentChecking: session[%s] is %s', session.getTracker(), 'failed' if session.hasFailed() else 'finished')

                                self._tracker_info_cache.updateTrackerInfo(session.getTracker(), session.hasFailed())

                                # set torrent remaining responses
                                for infohash in session.getInfohashList():
                                    self._pending_response_dict[infohash]['remainingResponses'] -= 1

                                session.cleanup()
                                self._session_list.pop(i)

                    # >> Step 4. check and update new results
                    for infohash, response in self._pending_response_dict.items():
                        if response['updated']:
                            response['updated'] = False
                            self._updateTorrentResult(response)

                        if self._pending_response_dict[infohash]['remainingResponses'] == 0:
                            self._checkResponseFinal(response)
                            del self._pending_response_dict[infohash]

                    # update tracker info cache
                    self._tracker_info_cache.updateTrackerInfoIntoDb()

                # All kinds of unexpected exceptions
                except Exception as err:
                    self._logger.error('TorrentChecking: Unexpected exception: %s', err)
                    print_exc()

                self._logger.debug('TorrentChecking: sessions: %d', len(self._session_list))
                for session in self._session_list:
                    self._logger.debug('TorrentChecking: session[%s], finished=%d, failed=%d', session.getTracker(), session.hasFinished(), session.hasFailed())

        # the thread is shutting down, kill all the tracker sessions
        for session in self._session_list:
            session.cleanup()

        self._interrupt_socket.close()
        self._logger.info('TorrentChecking: shutdown')

class InterruptSocket:

    """
    When we need the poll to return before the timeout expires, we
    will send some data to the InterruptSocket and discard the data.
    """

    def __init__(self):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.ip = "127.0.0.1"
        self.port = None
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.socket.bind((self.ip, 0))
        self.port = self.socket.getsockname()[1]
        self._logger.debug("Bound InterruptSocket on port %s", self.port)

        self.interrupt_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    def interrupt(self):
        self.interrupt_socket.sendto("+", (self.ip, self.port))

    def handleRequest(self):
        try:
            self.socket.recv(1024)
        except:
            pass

    def close(self):
        self.interrupt_socket.close()
        self.socket.close()

    def get_ip(self):
        return self.ip

    def get_port(self):
        return self.port

    def get_socket(self):
        return self.socket

########NEW FILE########
__FILENAME__ = TrackerInfoCache
# ============================================================
# written by Lipu Fei
#
# This module maintains a list of trackers and their info. These information
# is also stored in the database.
#
# It provides two APIs: one is to update a tracker's info, the other is to
# check if a tracker is worth checking now. Because some trackers are gone
# or unreachable by some reason, it wastes a lot of time to check those
# "dead" trackers over and over again.
# ============================================================

import time
import logging

from Tribler.Core.Session import Session
from Tribler.Core.CacheDB.Notifier import NTFY_TRACKERINFO, NTFY_INSERT
from Tribler.Core.CacheDB.sqlitecachedb import forceDBThread, forceAndReturnDBThread
from Tribler.Core.CacheDB.SqliteCacheDBHandler import TorrentDBHandler
from Tribler.Core import NoDispersyRLock

# some default configurations
DEFAULT_MAX_TRACKER_FAILURES = 5  # A tracker that have failed for this
                                        # times will be regarded as "dead"
DEFAULT_DEAD_TRACKER_RETRY_INTERVAL = 60  # A "dead" tracker will be retired
                                         # every 60 seconds

# ============================================================
# This class maintains the tracker infomation cache.
# ============================================================
class TrackerInfoCache(object):

    # ------------------------------------------------------------
    # Initialization.
    # ------------------------------------------------------------
    def __init__(self, \
            max_failures=DEFAULT_MAX_TRACKER_FAILURES, \
            dead_tracker_recheck_interval=60):
        self._logger = logging.getLogger(self.__class__.__name__)

        self._torrentdb = TorrentDBHandler.getInstance()
        self._tracker_info_dict = dict()

        self._tracker_update_request_dict = dict()

        self._max_tracker_failures = max_failures
        self._dead_tracker_recheck_Interval = dead_tracker_recheck_interval

        self._lock = NoDispersyRLock()

        session = Session.get_instance()
        session.add_observer(self.newTrackerCallback, NTFY_TRACKERINFO, [NTFY_INSERT, ])

    # ------------------------------------------------------------
    # Loads and initializes the cache from database.
    # ------------------------------------------------------------
    def loadCacheFromDb(self):
        @forceAndReturnDBThread
        def do_db():
            return self._torrentdb.getTrackerInfoList()

        tracker_info_list = do_db()

        # no need to use the lock when reloading
        self._lock.acquire()
        # update tracker info
        for tracker_info in tracker_info_list:
            tracker, alive, last_check, failures = tracker_info
            self._tracker_info_dict[tracker] = {'last_check':last_check, 'failures':failures, 'alive':alive, 'updated':False}

        self._lock.release()

    # ------------------------------------------------------------
    # The callback function when a new tracker has been inserted.
    # ------------------------------------------------------------
    def newTrackerCallback(self, subject, changeType, objectID, *args):
        # DB upgrade complete, reload everthing from DB
        if not objectID:
            self.loadCacheFromDb()
            return

        # create new trackers
        with self._lock:
            # new tracker insertion callback
            for tracker in objectID:
                self._logger.debug('New tracker[%s].', tracker)
                self._tracker_info_dict[tracker] = {'last_check':0, 'failures':0, 'alive':True, 'updated':False}

                # check all the pending update requests
                if tracker not in self._tracker_update_request_dict:
                    continue

                for request in self._tracker_update_request_dict[tracker]:
                    self._logger.debug('Handling new tracker[%s] request: %s', tracker, request)
                    self.updateTrackerInfo(tracker, request)
                del self._tracker_update_request_dict[tracker]

    # ------------------------------------------------------------
    # (Public API)
    # Checks if a tracker is worth checking now.
    # ------------------------------------------------------------
    def toCheckTracker(self, tracker):
        currentTime = int(time.time())

        tracker_dict = self._tracker_info_dict.get(tracker, {'alive': True, 'last_check':0})
        if tracker_dict['alive']:
            return True

        interval = currentTime - tracker_dict['last_check']
        return interval >= self._dead_tracker_recheck_Interval

    # ------------------------------------------------------------
    # (Public API)
    # Updates or a tracker's information. If the tracker does not
    # exist, it will be created.
    # ------------------------------------------------------------
    def updateTrackerInfo(self, tracker, success):
        currentTime = int(time.time())

        with self._lock:
            if tracker in self._tracker_info_dict:
                tracker_info = self._tracker_info_dict[tracker]
            else:
                # put into a request queue and update after the tracker has been
                # added by the DB thread.
                if tracker not in self._tracker_update_request_dict:
                    self._tracker_update_request_dict[tracker] = list()
                self._tracker_update_request_dict[tracker].append(success)
                return

            tracker_info['last_check'] = currentTime
            # reset the failures count if successful
            if success:
                tracker_info['failures'] = 0
            else:
                tracker_info['failures'] += 1

            # determine if a tracker is alive
            if tracker_info['failures'] >= self._max_tracker_failures:
                alive = False
            else:
                alive = True
            tracker_info['alive'] = alive

            self._tracker_info_dict[tracker]['updated'] = True

    # ------------------------------------------------------------
    # (Public API)
    # Updates the tracker status into the DB in batch.
    # ------------------------------------------------------------
    def updateTrackerInfoIntoDb(self):
        self._lock.acquire()

        # store all recently updated tracker info into DB
        update_list = list()
        for tracker, info in self._tracker_info_dict.items():
            if not info['updated']:
                continue

            data = (info['last_check'], info['failures'], info['alive'], tracker)
            update_list.append(data)

            info['updated'] = False
        self._lock.release()

        @forceDBThread
        def do_db():
            self._torrentdb.updateTrackerInfo(update_list)

        if update_list:
            do_db()

    # ------------------------------------------------------------
    # Gets the size of the tracker info list.
    # ------------------------------------------------------------
    def getTrackerInfoListSize(self):
        return len(self._tracker_info_dict.keys())

    # ------------------------------------------------------------
    # Gets the a specific tracker info.
    # ------------------------------------------------------------
    def getTrackerInfo(self, index):
        return self._tracker_info_dict.items()[index]

########NEW FILE########
__FILENAME__ = TrackerSession
# ============================================================
# Written by Lipu Fei
# optimizing the TrackerChecking module written by Niels Zeilemaker.
#
# The tracker session modules.
# ============================================================
from abc import ABCMeta, abstractmethod

import sys
import struct
import binascii
import random
import urllib
import time
import logging

import socket
from threading import RLock

from Tribler.Core.Utilities.bencode import bdecode
from traceback import print_exc
from Tribler.Core import NoDispersyRLock

# Although these are the actions for UDP trackers, they can still be used as
# identifiers.
TRACKER_ACTION_CONNECT = 0
TRACKER_ACTION_ANNOUNCE = 1
TRACKER_ACTION_SCRAPE = 2

MAX_INT32 = 2 ** 16 - 1

UDP_TRACKER_INIT_CONNECTION_ID = 0x41727101980
UDP_TRACKER_RECHECK_INTERVAL = 15
UDP_TRACKER_MAX_RETRIES = 8

HTTP_TRACKER_RECHECK_INTERVAL = 60
HTTP_TRACKER_MAX_RETRIES = 0

MAX_TRACKER_MULTI_SCRAPE = 74

# some settings

# ============================================================
# The abstract TrackerSession class. It represents a session with a tracker.
# ============================================================
class TrackerSession(object):

    __metaclass__ = ABCMeta

    # ----------------------------------------
    # Initializes a TrackerSession.
    # ----------------------------------------
    def __init__(self, tracker, tracker_type, tracker_address, announce_page, \
            update_result_callback):
        self._logger = logging.getLogger(self.__class__.__name__)

        self._tracker = tracker
        self._tracker_type = tracker_type
        self._tracker_address = tracker_address
        self._announce_page = announce_page

        self._socket = None
        self._infohash_list = list()
        self._initiated = False
        self._action = None
        self._update_result_callback = update_result_callback

        self._finished = False
        self._failed = False
        self._retries = 0
        self._last_contact = 0

    # ----------------------------------------
    # Cleans up this tracker session.
    # ----------------------------------------
    def cleanup(self):
        if self._socket:
            self._socket.close()

    # ----------------------------------------
    # A factory method that creates a new session from a given tracker URL.
    # ----------------------------------------
    @staticmethod
    def createSession(tracker_url, update_result_callback):
        tracker_type, tracker_address, announce_page = \
           TrackerSession.parseTrackerUrl(tracker_url)

        if tracker_type == 'UDP':
            session = UdpTrackerSession(tracker_url, tracker_address, \
                announce_page, update_result_callback)
        else:
            session = HttpTrackerSession(tracker_url, tracker_address, \
                announce_page, update_result_callback)
        return session

    # ----------------------------------------
    # Parses a tracker URL to retrieve (1) the tracker type (HTTP or UDP),
    # (2) the tracker address which includes the IP address and the port
    # number, and (3) the tracker page which is something like '/announce',
    # '/announce.php', etc.
    # ----------------------------------------
    @staticmethod
    def parseTrackerUrl(tracker_url):
        # get tracker type
        if tracker_url.startswith('http'):
            tracker_type = 'HTTP'
        elif tracker_url.startswith('udp'):
            tracker_type = 'UDP'
        else:
            raise RuntimeError('Unexpected tracker type.')

        # get URL information
        url_fields = tracker_url.split('://')[1]
        # some UDP trackers may not have 'announce' at the end.
        if url_fields.find('/') == -1:
            if tracker_type == 'UDP':
                hostname_part = url_fields
                announce_page = None
            else:
                raise RuntimeError('Invalid tracker URL (%s).' % tracker_url)
        else:
            hostname_part, announce_page = url_fields.split('/', 1)

        # get port number if exists, otherwise, use HTTP default 80
        if hostname_part.find(':') != -1:
            hostname, port = hostname_part.split(':', 1)
            try:
                port = int(port)
            except:
                raise RuntimeError('Invalid port number.')
        elif tracker_type == 'HTTP':
            hostname = hostname_part
            port = 80
        else:
            raise RuntimeError('No port number for UDP tracker URL.')

        try:
            hostname = socket.gethostbyname(hostname)
        except:
            raise RuntimeError('Cannot resolve tracker URL.')

        return tracker_type, (hostname, port), announce_page

    # ----------------------------------------
    # (Public API) Handles the request, invoking the corresponding method.
    # ----------------------------------------
    def handleRequest(self):
        if self._action == TRACKER_ACTION_CONNECT:
            return self.handleConnection()
        else:
            return self.handleResponse()

    # ----------------------------------------
    # (Public API) Gets the tracker URL of this tracker session.
    # ----------------------------------------
    def getTracker(self):
        return self._tracker

    # ----------------------------------------
    # (Public API) Checks if this tracker session is of a specific
    # tracker type.
    # ----------------------------------------
    def isTrackerType(self, tracker_type):
        return self._tracker_type == tracker_type

    # ----------------------------------------
    # (Public API) Checks if this tracker session is in a specific
    # action.
    # ----------------------------------------
    def isAction(self, action):
        return self._action == action

    # ----------------------------------------
    # (Public API) Gets the socket of this tracker session.
    # ----------------------------------------
    def getSocket(self):
        return self._socket

    # ----------------------------------------
    # (Public API) Checks if this tracker session has initiated
    # (which means no more infohashes can be appended).
    # ----------------------------------------
    def hasInitiated(self):
        return self._initiated

    # ----------------------------------------
    # (Public API) Checks if this tracker session has finished.
    # ----------------------------------------
    def hasFinished(self):
        return self._finished

    # ----------------------------------------
    # (Public API) Sets the finished flag and closes the socket.
    # ----------------------------------------
    def setFinished(self):
        self._socket.close()
        self._finished = True

    # ----------------------------------------
    # (Public API) Checks if this tracker session has failed.
    # ----------------------------------------
    def hasFailed(self):
        return self._failed

    # ----------------------------------------
    # (Public API) Sets the failed flag.
    # ----------------------------------------
    def setFailed(self):
        self._socket.close()
        self._failed = True

    # ----------------------------------------
    # (Public API) Appends an infohash into the infohash list.
    # ----------------------------------------
    def addInfohash(self, infohash):
        return self._infohash_list.append(infohash)

    # ----------------------------------------
    # (Public API) Checks if an infohash is in the infohash list.
    # ----------------------------------------
    def hasInfohash(self, infohash):
        return infohash in self._infohash_list

    # ----------------------------------------
    # (Public API) Gets the infohash list.
    # ----------------------------------------
    def getInfohashList(self):
        return self._infohash_list

    # ----------------------------------------
    # (Public API) Gets the infohash list size.
    # ----------------------------------------
    def getInfohashListSize(self):
        return len(self._infohash_list)

    # ----------------------------------------
    # Gets the last time this session made a contact with the tracker.
    # ----------------------------------------
    def getLastContact(self):
        return self._last_contact

    # ----------------------------------------
    # Gets the retry count.
    # ----------------------------------------
    def getRetries(self):
        return self._retries

    # ----------------------------------------
    # Increases the retry count by 1.
    # ----------------------------------------
    def increaseRetries(self):
        self._retries += 1

    # ========================================
    # Abstract methods.
    # ========================================
    @abstractmethod
    def establishConnection(self):
        """Establishes a connection to the tracker."""
        pass

    @abstractmethod
    def reestablishConnection(self):
        """Re-Establishes a connection to the tracker."""
        pass

    @abstractmethod
    def handleConnection(self):
        """Handles a connection response."""
        pass

    @abstractmethod
    def handleResponse(self):
        """Does process when a response message is available."""
        pass

    @abstractmethod
    def getMaxRetries(self):
        """Nr of retries before a session is marked as failed"""
        pass

    @abstractmethod
    def getRetryInterval(self):
        """Interval between retries"""
        pass

# ============================================================
# The HTTP tracker session class which is responsible to do scrape on an HTTP
# tracker.
#
# Note: This class is not thread-safe right now. If you want to make this a
# standalone thread-safe module, you can add a static lock for the transaction
# ID handling functions.
# ============================================================
class HttpTrackerSession(TrackerSession):

    # ----------------------------------------
    # Initializes a UDPTrackerSession.
    # ----------------------------------------
    def __init__(self, tracker, tracker_address, announce_page, \
            update_result_callback):
        TrackerSession.__init__(self, tracker, \
            'HTTP', tracker_address, announce_page, \
            update_result_callback)

        self._header_buffer = None
        self._message_buffer = None
        self._content_encoding = None
        self._content_length = None
        self._received_length = None

    # ----------------------------------------
    # Gets the max retry count.
    # ----------------------------------------
    def getMaxRetries(self):
        return HTTP_TRACKER_MAX_RETRIES

    # ----------------------------------------
    # Gets interval between retries, in seconds.
    # ----------------------------------------
    def getRetryInterval(self):
        return HTTP_TRACKER_RECHECK_INTERVAL

    # ----------------------------------------
    # Establishes connection.
    # ----------------------------------------
    def establishConnection(self):
        self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self._socket.setblocking(0)

        return self.reestablishConnection()

    # ----------------------------------------
    # Re-establishes connection.
    # ----------------------------------------
    def reestablishConnection(self):
        # an exception may be raised if the socket is non-blocking
        try:
            self._socket.connect(self._tracker_address)

        except Exception as e:
            # Error number 115 means the opertion is in progress.
            if e[0] not in [115, 10035]:
                self._logger.debug('TrackerSession: Failed to connect to HTTP tracker [%s,%s]: %s', self._tracker, self._tracker_address, str(e))
                self.setFailed()
                return False

        self._action = TRACKER_ACTION_CONNECT
        self._last_contact = int(time.time())
        return True

    # ----------------------------------------
    # Handles a connection response.
    # ----------------------------------------
    def handleConnection(self):
        # create the HTTP GET message
        # Note: some trackers have strange URLs, e.g.,
        #       http://moviezone.ws/announce.php?passkey=8ae51c4b47d3e7d0774a720fa511cc2a
        #       which has some sort of 'key' as parameter, so we need to check
        #       if there is already a parameter available
        message = 'GET '
        message += '/' + self._announce_page.replace('announce', 'scrape')
        if message.find('?') == -1:
            message += '?'
        else:
            message += '&'

        # append the infohashes as parameters
        for infohash in self._infohash_list:
            message += 'info_hash='
            message += urllib.quote(infohash)
            message += '&'
        message = message[:-1]  # remove the last AND '&'
        message += ' HTTP/1.1\r\n'
        message += '\r\n'

        try:
            self._socket.sendall(message)

        except Exception as e:
            self._logger.debug('TrackerSession: Failed to send HTTP SCRAPE message: %s', e)
            self.setFailed()

        self._logger.debug('TrackerSession: send %s', message)

        # no more requests can be appended to this session
        self._action = TRACKER_ACTION_SCRAPE
        self._initiated = True

    # ----------------------------------------
    # Handles a scrape response.
    # ----------------------------------------
    def handleResponse(self):
        try:
            # TODO: this buffer size may be changed
            response = self._socket.recv(8192)

        except Exception as e:
            self._logger.debug('TrackerSession: Failed to receive HTTP SCRAPE response: %s', e)
            self.setFailed()
            return

        self._logger.debug('TrackerSession: Got [%s] as a response', response)

        if not response:
            self.setFailed()
            return

        # for the header message, we need to parse the content length in case
        # if the HTTP packets are partial.
        if not self._message_buffer:
            # append the header part
            if not self._header_buffer:
                self._header_buffer = response
            else:
                self._header_buffer += response

            # check if the header part is over
            if self._header_buffer.find('\r\n\r\n') != -1:
                self._header_buffer, self._message_buffer = \
                    self._header_buffer.split('\r\n\r\n', 1)

                self._received_length = len(self._message_buffer)
                self._processHeader()

        # the remaining part
        else:
            self._message_buffer += response
            self._received_length += len(response)


        # check the read count
        if self._received_length >= self._content_length:
            # process the retrieved information
            success = self._processScrapeResponse()
            if success:
                self.setFinished()
            else:
                self.setFailed()

        # wait for more
        else:
            pass

    # ----------------------------------------
    # Processes the header of the received SCRAPE response message.
    # ----------------------------------------
    def _processHeader(self):
        # get and check HTTP response code
        protocol, code, msg = self._header_buffer.split(' ', 2)
        if code == '301' or code == '302':
            idx = self._header_buffer.find('Location: ')
            if idx == -1:
                self.setFailed()
            else:
                new_location = (self._header_buffer[idx:].split('\r\n')[0]).split(' ')[1]
                try:
                    idx = new_location.find('info_hash=')
                    if idx != -1:
                        new_location = new_location[:idx]
                    if new_location[-1] != '/':
                        new_location += "/"
                    new_location += "announce"

                    tracker_type, tracker_address, announce_page = TrackerSession.parseTrackerUrl(new_location)
                    if tracker_type != self._tracker_type:
                        raise RuntimeError('cannot redirect to different trackertype')

                    else:
                        self._logger.debug('TrackerSession: we are being redirected %s', new_location)

                        self._tracker_address = tracker_address
                        self._announce_page = announce_page
                        self._socket.close()

                        self.reestablishConnection()

                except RuntimeError as runerr:
                    self._logger.debug(u'Runtime Error [%s], Tracker: %s, Tracker Address: %s, Tracker Announce: %s',
                        runerr, self._tracker, self._tracker_address, self._announce_page)
                    self.setFailed()

                except Exception as err:
                    self._logger.exception(u'Failed to process HTTP tracker header: [%s], Tracker: %s, Tracker Address: %s, Tracker Announce: %s',
                        err, self._tracker, self._tracker_address, self._announce_page)
                    self._logger.debug(u'Header: %s', self._header_buffer)
                    self._logger.debug('TrackerSession: cannot redirect trackertype changed %s', new_location)
                    self.setFailed()
            return

        if code != '200':
            # error response code
            self._logger.debug('TrackerSession: Error HTTP SCRAPE response code [%s, %s].', code, msg)
            self.setFailed()
            return

        # check the content type
        idx = self._header_buffer.find('Content-Encoding: ')
        if idx == -1:
            # assuming it is plain text or something similar
            self._content_encoding = 'plain'
        else:
            encoding = (self._header_buffer[idx:].split('\r\n')[0]).split(' ')[1]
            self._content_encoding = encoding

        # get the content length
        idx = self._header_buffer.find('Content-Length: ')
        if idx == -1:
            # assume that the content is small

            # process the retrieved information
            success = self._processScrapeResponse()
            if success:
                self.setFinished()
            else:
                self.setFailed()

        else:
            idx = idx + len('Content-Length: ')
            self._content_length = \
                int(self._header_buffer[idx:].split('\r\n', 1)[0].strip())

    # ----------------------------------------
    # Processes the complete received SCRAPE response message.
    # ----------------------------------------
    def _processScrapeResponse(self):
        # parse the retrived results
        try:
            response_dict = bdecode(self._message_buffer)
        except Exception as e:
            self._logger.debug('TrackerSession: Failed to decode bcode[%s].' % self._message_buffer)
            return False

        unprocessed_infohash_list = self._infohash_list[:]
        if 'files' in response_dict:
            for infohash in response_dict['files'].keys():
                downloaded = response_dict['files'][infohash].get('downloaded', 0)
                complete = response_dict['files'][infohash].get('complete', 0)
                incomplete = response_dict['files'][infohash].get('incomplete', 0)

                seeders = downloaded
                leechers = incomplete

                # handle the retrieved information
                self._update_result_callback(infohash, seeders, leechers)

                # remove this infohash in the infohash list of this session
                if infohash in unprocessed_infohash_list:
                    unprocessed_infohash_list.remove(infohash)

        elif 'failure reason' in response_dict:
            self._logger.debug('TrackerSession: Failure as reported by tracker [%s]', response_dict['failure reason'])

            return False

        # handle the infohashes with no result
        # (considers as the torrents with seeders/leechers=0/0)
        for infohash in unprocessed_infohash_list:
            seeders, leechers = 0, 0
            # handle the retrieved information
            self._update_result_callback(infohash, seeders, leechers)
        return True


# ============================================================
# The UDP tracker session class which is responsible to do scrape on a UDP
# tracker.
# ============================================================
class UdpTrackerSession(TrackerSession):

    # A list of transaction IDs that have been used
    # in order to avoid conflict.
    __active_session_dict = dict()
    __lock = NoDispersyRLock()

    # ----------------------------------------
    # Generates a new transaction ID for a given session.
    # ----------------------------------------
    @staticmethod
    def generateTransactionId(session):
        UdpTrackerSession.__lock.acquire()
        while True:
            # make sure there is no duplicated transaction IDs
            transaction_id = random.randint(0, MAX_INT32)
            if not transaction_id in UdpTrackerSession.__active_session_dict.items():
                UdpTrackerSession.__active_session_dict[session] = transaction_id
                session.transactionId = transaction_id
                break
        UdpTrackerSession.__lock.release()

    # ----------------------------------------
    # Removes the transaction ID of a given session from the list.
    # ----------------------------------------
    @staticmethod
    def removeTransactionId(session):
        UdpTrackerSession.__lock.acquire()
        if session in UdpTrackerSession.__active_session_dict:
            del UdpTrackerSession.__active_session_dict[session]
        UdpTrackerSession.__lock.release()

    # ----------------------------------------
    # Initializes a UdpTrackerSession.
    # ----------------------------------------
    def __init__(self, tracker, tracker_address, announce_page, \
            update_result_callback):
        TrackerSession.__init__(self, tracker, \
            'UDP', tracker_address, announce_page, update_result_callback)

        self._connection_id = 0
        self._transaction_id = 0

    # ----------------------------------------
    # Cleans up this UDP tracker session.
    # ----------------------------------------
    def cleanup(self):
        UdpTrackerSession.removeTransactionId(self)
        TrackerSession.cleanup(self)

    # ----------------------------------------
    # Gets the max retry count.
    # ----------------------------------------
    def getMaxRetries(self):
        return UDP_TRACKER_MAX_RETRIES

    # ----------------------------------------
    # Gets interval between retries, in seconds.
    # ----------------------------------------
    def getRetryInterval(self):
        return UDP_TRACKER_RECHECK_INTERVAL * (2 ** self.getRetries())

    # ----------------------------------------
    # Establishes connection.
    # ----------------------------------------
    def establishConnection(self):
        self._socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self._socket.setblocking(0)
        self._socket.connect(self._tracker_address)

        return self.reestablishConnection()

    # ----------------------------------------
    # Re-establishes connection.
    # ----------------------------------------
    def reestablishConnection(self):
        # prepare connection message
        self._connection_id = UDP_TRACKER_INIT_CONNECTION_ID
        self._action = TRACKER_ACTION_CONNECT
        UdpTrackerSession.generateTransactionId(self)

        message = struct.pack('!qii', \
            self._connection_id, self._action, self._transaction_id)
        try:
            self._socket.send(message)
        except Exception as e:
            self._logger.debug('TrackerSession: Failed to send message to UDP tracker [%s]: %s', self._tracker, str(e))
            self.setFailed()
            return False

        self._last_contact = int(time.time())
        return True

    # ----------------------------------------
    # Handles a connection response.
    # ----------------------------------------
    def handleConnection(self):
        try:
            # TODO: this number may be increased
            response = self._socket.recv(32)
        except Exception as e:
            self._logger.debug('TrackerSession: Failed to receive UDP CONNECT response: %s', e)
            self.setFailed()
            return

        # check message size
        if len(response) < 16:
            self._logger.debug('TrackerSession: Invalid response for UDP CONNECT [%s].', response)
            self.setFailed()
            return

        # check the response
        action, transaction_id = \
            struct.unpack_from('!ii', response, 0)
        if action != self._action or transaction_id != self._transaction_id:
            # get error message
            errmsg_length = len(response) - 8
            error_message = \
                struct.unpack_from('!' + str(errmsg_length) + 's', response, 8)

            self._logger.debug('TrackerSession: Error response for UDP CONNECT [%s]: %s.', response, error_message)
            self.setFailed()
            return

        # update action and IDs
        self._connection_id = struct.unpack_from('!q', response, 8)[0]
        self._action = TRACKER_ACTION_SCRAPE
        UdpTrackerSession.generateTransactionId(self)

        # pack and send the message
        format = '!qii' + ('20s' * len(self._infohash_list))
        message = struct.pack(format, \
            self._connection_id, self._action, self._transaction_id, \
            *self._infohash_list)

        try:
            self._socket.send(message)
        except Exception as e:
            self._logger.debug('TrackerSession: Failed to send UDP SCRAPE message: %s', e)
            self.setFailed()
            return

        # no more requests can be appended to this session
        self._initiated = True
        self._last_contact = int(time.time())

    # ----------------------------------------
    # Handles a scrape response.
    # ----------------------------------------
    def handleResponse(self):
        try:
            # 74 infohashes are roughly 896 bytes
            # TODO: the number may be changed
            response = self._socket.recv(1024)
        except Exception as e:
            self._logger.debug('TrackerSession: Failed to receive UDP SCRAPE response: %s', e)
            self.setFailed()
            return

        # check message size
        if len(response) < 8:
            self._logger.debug('TrackerSession: Invalid response for UDP SCRAPE [%s].', response)
            self.setFailed()
            return

        # check response
        action, transaction_id = struct.unpack_from('!ii', response, 0)
        if action != self._action or transaction_id != self._transaction_id:
            # get error message
            errmsg_length = len(response) - 8
            error_message = \
                struct.unpack_from('!' + str(errmsg_length) + 's', response, 8)

            self._logger.debug('TrackerSession: Error response for UDP SCRAPE [%s]: [%s].', response, error_message)
            self.setFailed()
            return

        # get results
        if len(response) - 8 != len(self._infohash_list) * 12:
            self._logger.debug('UDP SCRAPE response mismatch: [%s]', response)
            self.setFailed()
            return

        offset = 8
        for infohash in self._infohash_list:
            seeders, completed, leechers = \
                struct.unpack_from('!iii', response, offset)
            offset += 12

            # handle the retrieved information
            self._update_result_callback(infohash, seeders, leechers)

        # close this socket and remove its transaction ID from the list
        UdpTrackerSession.removeTransactionId(self)
        self.setFinished()

########NEW FILE########
__FILENAME__ = TrackerUtility
# ============================================================
# Written by Lipu Fei
#
# Utility functions for tracker checking.
# ============================================================

import re
import logging

logger = logging.getLogger(__name__)

url_regex = re.compile(
    r'^(?:http|udp)://' # http:// or udp
    r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|' #domain...
    r'localhost|' #localhost...
    r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})' # ...or ip
    r'(?::\d+)?' # optional port
    r'(?:/?|[/?]\S+)$', re.IGNORECASE)

# ------------------------------------------------------------
# Convert a given tracker's URL into a uniformed version:
#    <type>://<host>:<port>/<page>
# For example:
#    udp://tracker.openbittorrent.com:80
#    http://tracker.openbittorrent.com:80/announce
# ------------------------------------------------------------
def getUniformedURL(tracker_url):
    # check if there is any strange binary in URL
    try:
        unicode(tracker_url)
    except Exception:
        logger.exception(u"Bad URL")
        return None

    tracker_url = tracker_url.strip()
    if tracker_url.endswith('/'):
        tracker_url = tracker_url[:-1]

    # get tracker type
    if tracker_url.startswith('http://'):
        tracker_type = 'http'
        remaning_part = tracker_url[7:]
    elif tracker_url.startswith('udp://'):
        tracker_type = 'udp'
        remaning_part = tracker_url[6:]
    else:
        return None

    # host, port, and page
    if remaning_part.find('/') == -1:
        if tracker_type == 'http':
            return None
        host_part = remaning_part
        page_part = None
    else:
        host_part, page_part = remaning_part.split('/', 1)

    if host_part.find(':') == -1:
        if tracker_type == 'udp':
            return None
        else:
            host = host_part
            port = 80
    else:
        host, port = host_part.split(':', 1)

    try:
        port = int(port)
    except:
        return None

    page = page_part

    if tracker_type == 'http':
        uniformed_url = '%s://%s:%d/%s' % (tracker_type, host, port, page)
    else:
        uniformed_url = '%s://%s:%d' % (tracker_type, host, port)

    if not url_regex.match(uniformed_url):
        return None
    else:
        return uniformed_url
########NEW FILE########
__FILENAME__ = FastI2I
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# Simpler way of communicating with a separate process running swift via
# its CMDGW interface
#

import logging
from threading import Thread, Lock, currentThread, Event
import socket
from traceback import print_exc
try:
    prctlimported = True
    import prctl
except ImportError as e:
    prctlimported = False

from Tribler.dispersy.util import attach_profiler


class FastI2IConnection(Thread):

    def __init__(self, port, readlinecallback, closecallback):
        Thread.__init__(self)

        self._logger = logging.getLogger(self.__class__.__name__)

        name = "FastI2I" + self.getName()
        self.setName(name)
        self.setDaemon(True)

        self.port = port
        self.readlinecallback = readlinecallback
        self.closecallback = closecallback

        self.sock = None
        self.sock_connected = Event()
        # Socket only every read by self
        self.buffer = ''
        # write lock on socket
        self.lock = Lock()

        self.start()
        assert self.sock_connected.wait(60) or self.sock_connected.is_set(), 'Did not connect to socket within 60s.'

    @attach_profiler
    def run(self):

        if prctlimported:
            prctl.set_name("Tribler" + currentThread().getName())

        try:
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.connect(("127.0.0.1", self.port))
            self.sock_connected.set()
            while True:
                data = self.sock.recv(10240)
                if len(data) == 0:
                    break
                self.data_came_in(data)
        except:
            print_exc()
            self.close()

    def stop(self):
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.connect(('127.0.0.1', self.port))
            s.send('')
            s.close()
        except:
            pass

    def data_came_in(self, data):
        """ Read \r\n ended lines from data and call readlinecallback(self,line) """
        # data may come in in parts, not lines! Or multiple lines at same time

        self._logger.debug("fasti2i: data_came_in %s %s", repr(data), len(data))

        if len(self.buffer) == 0:
            self.buffer = data
        else:
            self.buffer = self.buffer + data
        self.read_lines()

    def read_lines(self):
        while True:
            cmd, separator, self.buffer = self.buffer.partition("\r\n")
            if separator:
                if self.readlinecallback(self, cmd):
                    # 01/05/12 Boudewijn: when a positive value is returned we immediately return to
                    # allow more bytes to be pushed into the buffer
                    self.buffer = "".join((cmd, separator, self.buffer))

                    # 06/05/13 Boudewijn: we must return to read the remainder of the data.  note
                    # that the remainder (all bytes behind the first separator) must be removed from
                    # self.buffer during the readlinecallback call
                    break

            else:
                self.buffer = cmd
                break

    def write(self, data):
        """ Called by any thread """
        self.lock.acquire()
        try:
            if self.sock is not None:
                self.sock.send(data)
        finally:
            self.lock.release()

    def close(self):
        if self.sock is not None:
            self.sock.close()
            self.closecallback(self.port)
            self.sock = None
            self.sock_connected.clear()

########NEW FILE########
__FILENAME__ = Instance2Instance
# Written by Arno Bakker, Diego Rabaioli
# see LICENSE.txt for license information
""" Communication layer between other instance or Web plugin e.g. for starting Downloads. """

# Protocol V1: Tribler 4.5.0:
# - [4 byte length of cmd][cmd]
# Protocol V2: SwarmPlugin
# - [cmd]\r\n
#
#
import socket
import logging
from traceback import print_exc
from threading import Thread, Event, currentThread
from Tribler.Core.RawServer.RawServer import RawServer
try:
    prctlimported = True
    import prctl
except ImportError as e:
    prctlimported = False


class Instance2InstanceServer(Thread):

    def __init__(self, i2iport, connhandler, timeout=300.0):
        Thread.__init__(self)

        self._logger = logging.getLogger(self.__class__.__name__)

        name = 'Instance2Instance' + self.getName()
        self.setDaemon(True)
        self.setName(name)

        self.i2iport = i2iport
        self.connhandler = connhandler

        self._logger.info("Instance2Instance binding to %s:%d", "127.0.0.1", self.i2iport)
        self.i2idoneflag = Event()
        self.rawserver = RawServer(self.i2idoneflag,
                                   timeout / 5.0,
                                   timeout,
                                   ipv6_enable=False,
                                   failfunc=self.rawserver_fatalerrorfunc,
                                   errorfunc=self.rawserver_nonfatalerrorfunc)

        # Only accept local connections
        self.rawserver.bind(self.i2iport, bind=['127.0.0.1'], reuse=True)
        self.rawserver.add_task(self.rawserver_keepalive, 10)

    def rawserver_keepalive(self):
        """ Hack to prevent rawserver sleeping in select() for a long time, not
        processing any tasks on its queue at startup time

        Called by Instance2Instance thread """
        self.rawserver.add_task(self.rawserver_keepalive, 1)

    def shutdown(self):
        self.connhandler.shutdown()
        self.i2idoneflag.set()

    #
    # Following methods are called by Instance2Instance thread
    #
    def rawserver_fatalerrorfunc(self, e):
        """ Called by network thread """
        self._logger.debug("i2is: RawServer fatal error func called %s", e)
        print_exc()

    def rawserver_nonfatalerrorfunc(self, e):
        """ Called by network thread """
        self._logger.debug("i2is: RawServer non fatal error func called %s", e)
        print_exc()
        # Could log this somewhere, or phase it out

    def run(self):

        if prctlimported:
            prctl.set_name("Tribler" + currentThread().getName())

        try:
            try:
                self._logger.debug("i2is: Ready to receive remote commands on %s", self.i2iport)
                self.rawserver.listen_forever(self)
            except:
                print_exc()
        finally:
            self.rawserver.shutdown()

    def external_connection_made(self, s):
        try:
            self._logger.debug("i2is: external_connection_made")
            self.connhandler.external_connection_made(s)
        except:
            print_exc()
            s.close()

    def connection_flushed(self, s):
        self.connhandler.connection_flushed(s)

    def connection_lost(self, s):
        self._logger.debug("i2is: connection_lost ------------------------------------------------")
        self.connhandler.connection_lost(s)

    def data_came_in(self, s, data):
        try:
            self.connhandler.data_came_in(s, data)
        except:
            print_exc()
            s.close()

    def add_task(self, func, t):
        self.rawserver.add_task(func, t)

    def start_connection(self, dns):
        return self.rawserver.start_connection_raw(dns, handler=self.connhandler)


class InstanceConnectionHandler:

    def __init__(self, readlinecallback=None):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.readlinecallback = readlinecallback
        self.singsock2ic = {}  # Maps Tribler/Core/BitTornado/SocketHandler.py:SingleSocket to InstanceConnection

    def set_readlinecallback(self, readlinecallback):
        self.readlinecallback = readlinecallback

    def external_connection_made(self, s):
        # Extra check in case bind() no work
        self._logger.debug("i2is: ich: ext_conn_made")
        peername = s.get_ip()
        if peername != "127.0.0.1":
            self._logger.info("i2is: ich: ext_conn_made: Refusing non-local connection from %s", peername)
            s.close()

        ic = InstanceConnection(s, self, self.readlinecallback)
        self.singsock2ic[s] = ic

    def connection_flushed(self, s):
        pass

    def connection_lost(self, s):
        """ Called when peer closes connection and when we close the connection """
        self._logger.debug("i2is: ich: connection_lost ------------------------------------------------")

        # Extra check in case bind() no work
        peername = s.get_ip()
        if peername != "127.0.0.1":
            self._logger.info("i2is: ich: connection_lost: Refusing non-local connection from %s", peername)
            return

        del self.singsock2ic[s]

    def data_came_in(self, s, data):
        self._logger.debug("i2is: ich: data_came_in")

        ic = self.singsock2ic[s]
        try:
            ic.data_came_in(data)
        except:
            print_exc()

    def shutdown(self):
        for ic in self.singsock2ic.values():
            ic.shutdown()

    def set_server(self, i2is):
        self.i2is = i2is

    def start_connection(self, dns, ic):
        s = self.i2is.start_connection(dns)
        self.singsock2ic[s] = ic
        return s


class InstanceConnection:

    def __init__(self, singsock, connhandler, readlinecallback):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.singsock = singsock
        self.connhandler = connhandler
        self.readlinecallback = readlinecallback
        self.buffer = ''

    def data_came_in(self, data):
        """ Read \r\n ended lines from data and call readlinecallback(self,line) """
        # data may come in in parts, not lines! Or multiple lines at same time

        self._logger.debug("i2is: ic: data_came_in", repr(data), len(data))

        if len(self.buffer) == 0:
            self.buffer = data
        else:
            self.buffer = self.buffer + data
        self.read_lines()

    def read_lines(self):
        while True:
            cmd, separator, self.buffer = self.buffer.partition("\r\n")
            if separator:
                if self.readlinecallback(self, cmd):
                    # 01/05/12 Boudewijn: when a positive value is returned we immediately return to
                    # allow more bytes to be pushed into the buffer
                    self.buffer = "".join((cmd, separator, self.buffer))

                    # 06/05/13 Boudewijn: we must return to read the remainder of the data.  note
                    # that the remainder (all bytes behind the first separator) must be removed from
                    # self.buffer during the readlinecallback call
                    break

            else:
                self.buffer = cmd
                break

    def write(self, data):
        if self.singsock is not None:
            self.singsock.write(data)

    def close(self):
        if self.singsock is not None:
            self.singsock.close()
            self.connhandler.connection_lost(self.singsock)
            self.singsock = None


class Instance2InstanceClient:

    def __init__(self, port, cmd, param):
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.connect(('127.0.0.1', port))
        msg = cmd + ' ' +param+'\r\n'
        s.send(msg)
        s.close()

########NEW FILE########
__FILENAME__ = SingleInstanceChecker
# Written by Jelle Roozenburg, Arno Bakker
# see LICENSE.txt for license information

import sys
import commands
import wx
import logging


class SingleInstanceChecker(object):

    """ Looks for a process with argument basename.py """

    def __init__(self, basename):
        super(SingleInstanceChecker, self).__init__()

        self._logger = logging.getLogger(self.__class__.__name__)

        if sys.platform != 'linux2':
            self._wx_instance_name = "tribler-" + wx.GetUserId()
            self._wx_checker = wx.SingleInstanceChecker(self._wx_instance_name)

        self._basename = basename

    def IsAnotherRunning(self):
        if sys.platform == 'linux2':
            return self.__get_process_num_on_linux()
        else:
            return self.__get_process_num_on_other()

    def __get_process_num_on_other(self):
        return self._wx_checker.IsAnotherRunning()

    def __get_process_num_on_linux(self):
        cmd = 'pgrep -fl "%s\.py" | grep -v pgrep' % (self._basename)
        progressInfo = commands.getoutput(cmd)

        self._logger.info(u"Linux cmd returned %s", progressInfo)

        numProcesses = len(progressInfo.split('\n'))
        return numProcesses > 1

########NEW FILE########
__FILENAME__ = TimedTaskQueue
# Written by Arno Bakker
# see LICENSE.txt for license information
#
# TimedTaskQueue is a server that executes tasks on behalf of e.g. the GUI that
# are too time consuming to be run by the actual GUI Thread (MainThread). Note
# that you still need to delegate the actual updating of the GUI to the
# MainThread via the wx.CallAfter mechanism.
#
import logging

from threading import Thread, Condition, RLock, currentThread
from traceback import print_exc, print_stack, format_stack
from time import time
try:
    prctlimported = True
    import prctl
except ImportError as e:
    prctlimported = False


class TimedTaskQueue:

    __single = None

    def __init__(self, nameprefix="TimedTaskQueue", isDaemon=True):
        self._logger = logging.getLogger(self.__class__.__name__)

        self.cond = Condition(RLock())
        self.queue = []
        self.count = 0.0  # serves to keep task that were scheduled at the same time in FIFO order
        self.thread = Thread(target=self.run)
        self.thread.setDaemon(isDaemon)
        self.thread.setName(nameprefix +self.thread.getName())
        self.thread.start()

        if __debug__:
            self.callstack = {}  # callstack by self.count

    def shutdown(self, immediately=False):
        self.add_task("stop", -time() if immediately else 0)
        self.add_task = lambda task, t=0, id=None: None

    def add_task(self, task, t=0, id=None):
        """ t parameter is now usable, unlike before.
            If id is given, all the existing tasks with the same id will be removed
            before inserting this task
        """

        if task is None:
            print_stack()

        self.cond.acquire()
        when = time() + t

        debug_call_name = task.__name__ if hasattr(task, "__name__") else str(task)
        self._logger.debug("ttqueue: ADD EVENT %s %s %s", t, task, debug_call_name)

        if __debug__:
            self.callstack[self.count] = format_stack()

        if id != None:  # remove all redundant tasks
            self.queue = filter(lambda item: item[3] != id, self.queue)
        self.queue.append((when, self.count, task, id))
        self.count += 1.0
        self.cond.notify()
        self.cond.release()

    def remove_task(self, id):
        self.cond.acquire()
        self.queue = filter(lambda item: item[3] != id, self.queue)
        self.cond.notify()
        self.cond.release()

    def does_task_exist(self, id):
        return any(item[3] == id for item in self.queue)

    def get_nr_tasks(self):
        return len(self.queue)

    def run(self):
        """ Run by server thread """

        if prctlimported:
            prctl.set_name("Tribler" + currentThread().getName())

        while True:
            task = None
            timeout = None
            flag = False
            self.cond.acquire()
            while True:
                while len(self.queue) == 0 or flag:
                    flag = False
                    if timeout is None:
                        # Wait until something is queued
                        self.cond.wait()
                    else:
                        # Wait till first event is due
                        self.cond.wait(timeout)
                # A new event was added or an event is due
                self.queue.sort()

                (when, count, task, id) = self.queue[0]
                self._logger.debug("ttqueue: EVENT IN QUEUE %s %s", when, task)
                now = time()
                if now < when:
                    # Event not due, wait some more
                    self._logger.debug("ttqueue: EVENT NOT TILL %s", when - now)
                    timeout = when - now
                    flag = True
                else:
                    # Event due, execute
                    self._logger.debug("ttqueue: EVENT DUE")
                    self.queue.pop(0)
                    if __debug__:
                        assert count in self.callstack
                        stack = self.callstack.pop(count)
                    break
            self.cond.release()

            # Execute task outside lock
            try:
                # 'stop' and 'quit' are only used for unit test
                if task == 'stop':
                    break
                elif task == 'quit':
                    if len(self.queue) == 0:
                        break
                    else:
                        (when, count, task, id) = self.queue[-1]
                        t = when - time() +0.001
                        self.add_task('quit', t)
                else:
                    t1 = time()

                    task()

                    took = time() - t1
                    if took > 0.2:
                        debug_call_name = task.__name__ if hasattr(task, "__name__") else str(task)
                        self._logger.debug("ttqueue: EVENT TOOK %s %s", took, debug_call_name)
            except:
                print_exc()
                if __debug__:
                    self._logger.debug("<<<<<<<<<<<<<<<<")
                    self._logger.debug("TASK QUEUED FROM")
                    self._logger.debug("".join(stack))
                    self._logger.debug(">>>>>>>>>>>>>>>>")

########NEW FILE########
__FILENAME__ = vlc
#! /usr/bin/python

# Python ctypes bindings for VLC
#
# Copyright (C) 2009-2012 the VideoLAN team
# $Id: $
#
# Authors: Olivier Aubert <olivier.aubert at liris.cnrs.fr>
#          Jean Brouwers <MrJean1 at gmail.com>
#          Geoff Salmon <geoff.salmon at gmail.com>
#
# This library is free software; you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as
# published by the Free Software Foundation; either version 2.1 of the
# License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston MA 02110-1301 USA

"""This module provides bindings for the LibVLC public API, see
U{http://wiki.videolan.org/LibVLC}.

You can find the documentation and a README file with some examples
at U{http://www.advene.org/download/python-ctypes/}.

Basically, the most important class is L{Instance}, which is used
to create a libvlc instance.  From this instance, you then create
L{MediaPlayer} and L{MediaListPlayer} instances.

Alternatively, you may create instances of the L{MediaPlayer} and
L{MediaListPlayer} class directly and an instance of L{Instance}
will be implicitly created.  The latter can be obtained using the
C{get_instance} method of L{MediaPlayer} and L{MediaListPlayer}.
"""

import ctypes
from ctypes.util import find_library
import os
import sys

# Used by EventManager in override.py
from inspect import getargspec

__version__ = "N/A"
build_date  = "Tue Jul  2 10:35:53 2013"

if sys.version_info[0] > 2:
    str = str
    unicode = str
    bytes = bytes
    basestring = (str, bytes)
    PYTHON3 = True
    def str_to_bytes(s):
        """Translate string or bytes to bytes.
        """
        if isinstance(s, str):
            return bytes(s, sys.getfilesystemencoding())
        else:
            return s

    def bytes_to_str(b):
        """Translate bytes to string.
        """
        if isinstance(b, bytes):
            return b.decode(sys.getfilesystemencoding())
        else:
            return b
else:
    str = str
    unicode = unicode
    bytes = str
    basestring = basestring
    PYTHON3 = False
    def str_to_bytes(s):
        """Translate string or bytes to bytes.
        """
        if isinstance(s, unicode):
            return s.encode(sys.getfilesystemencoding())
        else:
            return s

    def bytes_to_str(b):
        """Translate bytes to unicode string.
        """
        if isinstance(b, str):
            return unicode(b, sys.getfilesystemencoding())
        else:
            return b

# Internal guard to prevent internal classes to be directly
# instanciated.
_internal_guard = object()

def find_lib():
    dll = None
    plugin_path = None
    if sys.platform.startswith('linux'):
        p = find_library('vlc')
        try:
            dll = ctypes.CDLL(p)
        except OSError:  # may fail
            dll = ctypes.CDLL('libvlc.so.5')
    elif sys.platform.startswith('win'):
        p = find_library('libvlc.dll')
        if p is None:
            # for Tribler VLC
            if os.path.exists('VLC\\libvlc.dll'):
                plugin_path = 'VLC'
            if plugin_path is None:
                try:  # some registry settings
                    import _winreg as w  # leaner than win32api, win32con
                    for r in w.HKEY_LOCAL_MACHINE, w.HKEY_CURRENT_USER:
                        try:
                            r = w.OpenKey(r, 'Software\\VideoLAN\\VLC')
                            plugin_path, _ = w.QueryValueEx(r, 'InstallDir')
                            w.CloseKey(r)
                            break
                        except w.error:
                            pass
                except ImportError:  # no PyWin32
                    pass
            if plugin_path is None:
                 # try some standard locations.
                for p in ('Program Files\\VideoLan\\', 'VideoLan\\',
                          'Program Files\\',           ''):
                    p = 'C:\\' + p + 'VLC\\libvlc.dll'
                    if os.path.exists(p):
                        plugin_path = os.path.dirname(p)
                        break
            if plugin_path is not None:  # try loading
                p = os.getcwd()
                os.chdir(plugin_path)
                 # if chdir failed, this will raise an exception
                dll = ctypes.CDLL('libvlc.dll')
                 # restore cwd after dll has been loaded
                os.chdir(p)
            else:  # may fail
                dll = ctypes.CDLL('libvlc.dll')
        else:
            plugin_path = os.path.dirname(p)
            dll = ctypes.CDLL(p)

    elif sys.platform.startswith('darwin'):
        # FIXME: should find a means to configure path
        d = '/Applications/VLC.app/Contents/MacOS/'
        p = d + 'lib/libvlc.dylib'
        if os.path.exists(p):
            dll = ctypes.CDLL(p)
            d += 'modules'
            if os.path.isdir(d):
                plugin_path = d
        else:  # hope, some PATH is set...
            dll = ctypes.CDLL('libvlc.dylib')

    else:
        raise NotImplementedError('%s: %s not supported' % (sys.argv[0], sys.platform))

    return (dll, plugin_path)

# plugin_path used on win32 and MacOS in override.py
dll, plugin_path  = find_lib()

class VLCException(Exception):
    """Exception raised by libvlc methods.
    """
    pass

try:
    _Ints = (int, long)
except NameError:  # no long in Python 3+
    _Ints =  int
_Seqs = (list, tuple)

# Default instance. It is used to instanciate classes directly in the
# OO-wrapper.
_default_instance = None

def get_default_instance():
    """Return the default VLC.Instance.
    """
    global _default_instance
    if _default_instance is None:
        _default_instance = Instance()
    return _default_instance

_Cfunctions = {}  # from LibVLC __version__
_Globals = globals()  # sys.modules[__name__].__dict__

def _Cfunction(name, flags, errcheck, *types):
    """(INTERNAL) New ctypes function binding.
    """
    if hasattr(dll, name) and name in _Globals:
        p = ctypes.CFUNCTYPE(*types)
        f = p((name, dll), flags)
        if errcheck is not None:
            f.errcheck = errcheck
        # replace the Python function
        # in this module, but only when
        # running as python -O or -OO
        if __debug__:
            _Cfunctions[name] = f
        else:
            _Globals[name] = f
        return f
    raise NameError('no function %r' % (name,))

def _Cobject(cls, ctype):
    """(INTERNAL) New instance from ctypes.
    """
    o = object.__new__(cls)
    o._as_parameter_ = ctype
    return o

def _Constructor(cls, ptr=_internal_guard):
    """(INTERNAL) New wrapper from ctypes.
    """
    if ptr == _internal_guard:
        raise VLCException("(INTERNAL) ctypes class. You should get references for this class through methods of the LibVLC API.")
    if ptr is None or ptr == 0:
        return None
    return _Cobject(cls, ctypes.c_void_p(ptr))

class _Cstruct(ctypes.Structure):
    """(INTERNAL) Base class for ctypes structures.
    """
    _fields_ = []  # list of 2-tuples ('name', ctyptes.<type>)

    def __str__(self):
        l = [' %s:\t%s' % (n, getattr(self, n)) for n, _ in self._fields_]
        return '\n'.join([self.__class__.__name__] + l)

    def __repr__(self):
        return '%s.%s' % (self.__class__.__module__, self)

class _Ctype(object):
    """(INTERNAL) Base class for ctypes.
    """
    @staticmethod
    def from_param(this):  # not self
        """(INTERNAL) ctypes parameter conversion method.
        """
        if this is None:
            return None
        return this._as_parameter_

class ListPOINTER(object):
    """Just like a POINTER but accept a list of ctype as an argument.
    """
    def __init__(self, etype):
        self.etype = etype

    def from_param(self, param):
        if isinstance(param, _Seqs):
            return (self.etype * len(param))(*param)

# errcheck functions for some native functions.
def string_result(result, func, arguments):
    """Errcheck function. Returns a string and frees the original pointer.

    It assumes the result is a char *.
    """
    if result:
        # make a python string copy
        s = bytes_to_str(ctypes.string_at(result))
        # free original string ptr
        libvlc_free(result)
        return s
    return None

def class_result(classname):
    """Errcheck function. Returns a function that creates the specified class.
    """
    def wrap_errcheck(result, func, arguments):
        if result is None:
            return None
        return classname(result)
    return wrap_errcheck

# Wrapper for the opaque struct libvlc_log_t
class Log(ctypes.Structure):
    pass
Log_ptr = ctypes.POINTER(Log)

# FILE* ctypes wrapper, copied from
# http://svn.python.org/projects/ctypes/trunk/ctypeslib/ctypeslib/contrib/pythonhdr.py
class FILE(ctypes.Structure):
    pass
FILE_ptr = ctypes.POINTER(FILE)

if PYTHON3:
    PyFile_FromFd = ctypes.pythonapi.PyFile_FromFd
    PyFile_FromFd.restype = ctypes.py_object
    PyFile_FromFd.argtypes = [ctypes.c_int,
                              ctypes.c_char_p,
                              ctypes.c_char_p,
                              ctypes.c_int,
                              ctypes.c_char_p,
                              ctypes.c_char_p,
                              ctypes.c_char_p,
                              ctypes.c_int ]

    PyFile_AsFd = ctypes.pythonapi.PyObject_AsFileDescriptor
    PyFile_AsFd.restype = ctypes.c_int
    PyFile_AsFd.argtypes = [ctypes.py_object]
else:
    PyFile_FromFile = ctypes.pythonapi.PyFile_FromFile
    PyFile_FromFile.restype = ctypes.py_object
    PyFile_FromFile.argtypes = [FILE_ptr,
                                ctypes.c_char_p,
                                ctypes.c_char_p,
                                ctypes.CFUNCTYPE(ctypes.c_int, FILE_ptr)]

    PyFile_AsFile = ctypes.pythonapi.PyFile_AsFile
    PyFile_AsFile.restype = FILE_ptr
    PyFile_AsFile.argtypes = [ctypes.py_object]

 # Generated enum types #

class _Enum(ctypes.c_uint):
    '''(INTERNAL) Base class
    '''
    _enum_names_ = {}

    def __str__(self):
        n = self._enum_names_.get(self.value, '') or ('FIXME_(%r)' % (self.value,))
        return '.'.join((self.__class__.__name__, n))

    def __hash__(self):
        return self.value

    def __repr__(self):
        return '.'.join((self.__class__.__module__, self.__str__()))

    def __eq__(self, other):
        return ( (isinstance(other, _Enum) and self.value == other.value)
              or (isinstance(other, _Ints) and self.value == other) )

    def __ne__(self, other):
        return not self.__eq__(other)

class LogLevel(_Enum):
    '''Logging messages level.
\note future libvlc versions may define new levels.
    '''
    _enum_names_ = {
        0: 'DEBUG',
        2: 'NOTICE',
        3: 'WARNING',
        4: 'ERROR',
    }
LogLevel.DEBUG   = LogLevel(0)
LogLevel.ERROR   = LogLevel(4)
LogLevel.NOTICE  = LogLevel(2)
LogLevel.WARNING = LogLevel(3)

class EventType(_Enum):
    '''Event types.
    '''
    _enum_names_ = {
        0: 'MediaMetaChanged',
        1: 'MediaSubItemAdded',
        2: 'MediaDurationChanged',
        3: 'MediaParsedChanged',
        4: 'MediaFreed',
        5: 'MediaStateChanged',
        0x100: 'MediaPlayerMediaChanged',
        257: 'MediaPlayerNothingSpecial',
        258: 'MediaPlayerOpening',
        259: 'MediaPlayerBuffering',
        260: 'MediaPlayerPlaying',
        261: 'MediaPlayerPaused',
        262: 'MediaPlayerStopped',
        263: 'MediaPlayerForward',
        264: 'MediaPlayerBackward',
        265: 'MediaPlayerEndReached',
        266: 'MediaPlayerEncounteredError',
        267: 'MediaPlayerTimeChanged',
        268: 'MediaPlayerPositionChanged',
        269: 'MediaPlayerSeekableChanged',
        270: 'MediaPlayerPausableChanged',
        271: 'MediaPlayerTitleChanged',
        272: 'MediaPlayerSnapshotTaken',
        273: 'MediaPlayerLengthChanged',
        274: 'MediaPlayerVout',
        0x200: 'MediaListItemAdded',
        513: 'MediaListWillAddItem',
        514: 'MediaListItemDeleted',
        515: 'MediaListWillDeleteItem',
        0x300: 'MediaListViewItemAdded',
        769: 'MediaListViewWillAddItem',
        770: 'MediaListViewItemDeleted',
        771: 'MediaListViewWillDeleteItem',
        0x400: 'MediaListPlayerPlayed',
        1025: 'MediaListPlayerNextItemSet',
        1026: 'MediaListPlayerStopped',
        0x500: 'MediaDiscovererStarted',
        1281: 'MediaDiscovererEnded',
        0x600: 'VlmMediaAdded',
        1537: 'VlmMediaRemoved',
        1538: 'VlmMediaChanged',
        1539: 'VlmMediaInstanceStarted',
        1540: 'VlmMediaInstanceStopped',
        1541: 'VlmMediaInstanceStatusInit',
        1542: 'VlmMediaInstanceStatusOpening',
        1543: 'VlmMediaInstanceStatusPlaying',
        1544: 'VlmMediaInstanceStatusPause',
        1545: 'VlmMediaInstanceStatusEnd',
        1546: 'VlmMediaInstanceStatusError',
    }
EventType.MediaDiscovererEnded          = EventType(1281)
EventType.MediaDiscovererStarted        = EventType(0x500)
EventType.MediaDurationChanged          = EventType(2)
EventType.MediaFreed                    = EventType(4)
EventType.MediaListItemAdded            = EventType(0x200)
EventType.MediaListItemDeleted          = EventType(514)
EventType.MediaListPlayerNextItemSet    = EventType(1025)
EventType.MediaListPlayerPlayed         = EventType(0x400)
EventType.MediaListPlayerStopped        = EventType(1026)
EventType.MediaListViewItemAdded        = EventType(0x300)
EventType.MediaListViewItemDeleted      = EventType(770)
EventType.MediaListViewWillAddItem      = EventType(769)
EventType.MediaListViewWillDeleteItem   = EventType(771)
EventType.MediaListWillAddItem          = EventType(513)
EventType.MediaListWillDeleteItem       = EventType(515)
EventType.MediaMetaChanged              = EventType(0)
EventType.MediaParsedChanged            = EventType(3)
EventType.MediaPlayerBackward           = EventType(264)
EventType.MediaPlayerBuffering          = EventType(259)
EventType.MediaPlayerEncounteredError   = EventType(266)
EventType.MediaPlayerEndReached         = EventType(265)
EventType.MediaPlayerForward            = EventType(263)
EventType.MediaPlayerLengthChanged      = EventType(273)
EventType.MediaPlayerMediaChanged       = EventType(0x100)
EventType.MediaPlayerNothingSpecial     = EventType(257)
EventType.MediaPlayerOpening            = EventType(258)
EventType.MediaPlayerPausableChanged    = EventType(270)
EventType.MediaPlayerPaused             = EventType(261)
EventType.MediaPlayerPlaying            = EventType(260)
EventType.MediaPlayerPositionChanged    = EventType(268)
EventType.MediaPlayerSeekableChanged    = EventType(269)
EventType.MediaPlayerSnapshotTaken      = EventType(272)
EventType.MediaPlayerStopped            = EventType(262)
EventType.MediaPlayerTimeChanged        = EventType(267)
EventType.MediaPlayerTitleChanged       = EventType(271)
EventType.MediaPlayerVout               = EventType(274)
EventType.MediaStateChanged             = EventType(5)
EventType.MediaSubItemAdded             = EventType(1)
EventType.VlmMediaAdded                 = EventType(0x600)
EventType.VlmMediaChanged               = EventType(1538)
EventType.VlmMediaInstanceStarted       = EventType(1539)
EventType.VlmMediaInstanceStatusEnd     = EventType(1545)
EventType.VlmMediaInstanceStatusError   = EventType(1546)
EventType.VlmMediaInstanceStatusInit    = EventType(1541)
EventType.VlmMediaInstanceStatusOpening = EventType(1542)
EventType.VlmMediaInstanceStatusPause   = EventType(1544)
EventType.VlmMediaInstanceStatusPlaying = EventType(1543)
EventType.VlmMediaInstanceStopped       = EventType(1540)
EventType.VlmMediaRemoved               = EventType(1537)

class Meta(_Enum):
    '''Meta data types.
    '''
    _enum_names_ = {
        0: 'Title',
        1: 'Artist',
        2: 'Genre',
        3: 'Copyright',
        4: 'Album',
        5: 'TrackNumber',
        6: 'Description',
        7: 'Rating',
        8: 'Date',
        9: 'Setting',
        10: 'URL',
        11: 'Language',
        12: 'NowPlaying',
        13: 'Publisher',
        14: 'EncodedBy',
        15: 'ArtworkURL',
        16: 'TrackID',
    }
Meta.Album       = Meta(4)
Meta.Artist      = Meta(1)
Meta.ArtworkURL  = Meta(15)
Meta.Copyright   = Meta(3)
Meta.Date        = Meta(8)
Meta.Description = Meta(6)
Meta.EncodedBy   = Meta(14)
Meta.Genre       = Meta(2)
Meta.Language    = Meta(11)
Meta.NowPlaying  = Meta(12)
Meta.Publisher   = Meta(13)
Meta.Rating      = Meta(7)
Meta.Setting     = Meta(9)
Meta.Title       = Meta(0)
Meta.TrackID     = Meta(16)
Meta.TrackNumber = Meta(5)
Meta.URL         = Meta(10)

class State(_Enum):
    '''Note the order of libvlc_state_t enum must match exactly the order of
See mediacontrol_playerstatus, See input_state_e enums,
and videolan.libvlc.state (at bindings/cil/src/media.cs).
expected states by web plugins are:
idle/close=0, opening=1, buffering=2, playing=3, paused=4,
stopping=5, ended=6, error=7.
    '''
    _enum_names_ = {
        0: 'NothingSpecial',
        1: 'Opening',
        2: 'Buffering',
        3: 'Playing',
        4: 'Paused',
        5: 'Stopped',
        6: 'Ended',
        7: 'Error',
    }
State.Buffering      = State(2)
State.Ended          = State(6)
State.Error          = State(7)
State.NothingSpecial = State(0)
State.Opening        = State(1)
State.Paused         = State(4)
State.Playing        = State(3)
State.Stopped        = State(5)

class TrackType(_Enum):
    '''N/A
    '''
    _enum_names_ = {
        -1: 'unknown',
        0: 'audio',
        1: 'video',
        2: 'text',
    }
TrackType.audio   = TrackType(0)
TrackType.text    = TrackType(2)
TrackType.unknown = TrackType(-1)
TrackType.video   = TrackType(1)

class PlaybackMode(_Enum):
    '''Defines playback modes for playlist.
    '''
    _enum_names_ = {
        0: 'default',
        1: 'loop',
        2: 'repeat',
    }
PlaybackMode.default = PlaybackMode(0)
PlaybackMode.loop    = PlaybackMode(1)
PlaybackMode.repeat  = PlaybackMode(2)

class VideoMarqueeOption(_Enum):
    '''Marq options definition.
    '''
    _enum_names_ = {
        0: 'Enable',
        1: 'Text',
        2: 'Color',
        3: 'Opacity',
        4: 'Position',
        5: 'Refresh',
        6: 'Size',
        7: 'Timeout',
        8: 'marquee_X',
        9: 'marquee_Y',
    }
VideoMarqueeOption.Color     = VideoMarqueeOption(2)
VideoMarqueeOption.Enable    = VideoMarqueeOption(0)
VideoMarqueeOption.Opacity   = VideoMarqueeOption(3)
VideoMarqueeOption.Position  = VideoMarqueeOption(4)
VideoMarqueeOption.Refresh   = VideoMarqueeOption(5)
VideoMarqueeOption.Size      = VideoMarqueeOption(6)
VideoMarqueeOption.Text      = VideoMarqueeOption(1)
VideoMarqueeOption.Timeout   = VideoMarqueeOption(7)
VideoMarqueeOption.marquee_X = VideoMarqueeOption(8)
VideoMarqueeOption.marquee_Y = VideoMarqueeOption(9)

class NavigateMode(_Enum):
    '''Navigation mode.
    '''
    _enum_names_ = {
        0: 'activate',
        1: 'up',
        2: 'down',
        3: 'left',
        4: 'right',
    }
NavigateMode.activate = NavigateMode(0)
NavigateMode.down     = NavigateMode(2)
NavigateMode.left     = NavigateMode(3)
NavigateMode.right    = NavigateMode(4)
NavigateMode.up       = NavigateMode(1)

class VideoLogoOption(_Enum):
    '''Option values for libvlc_video_{get,set}_logo_{int,string}.
    '''
    _enum_names_ = {
        0: 'enable',
        1: 'file',
        2: 'logo_x',
        3: 'logo_y',
        4: 'delay',
        5: 'repeat',
        6: 'opacity',
        7: 'position',
    }
VideoLogoOption.delay    = VideoLogoOption(4)
VideoLogoOption.enable   = VideoLogoOption(0)
VideoLogoOption.file     = VideoLogoOption(1)
VideoLogoOption.logo_x   = VideoLogoOption(2)
VideoLogoOption.logo_y   = VideoLogoOption(3)
VideoLogoOption.opacity  = VideoLogoOption(6)
VideoLogoOption.position = VideoLogoOption(7)
VideoLogoOption.repeat   = VideoLogoOption(5)

class VideoAdjustOption(_Enum):
    '''Option values for libvlc_video_{get,set}_adjust_{int,float,bool}.
    '''
    _enum_names_ = {
        0: 'Enable',
        1: 'Contrast',
        2: 'Brightness',
        3: 'Hue',
        4: 'Saturation',
        5: 'Gamma',
    }
VideoAdjustOption.Brightness = VideoAdjustOption(2)
VideoAdjustOption.Contrast   = VideoAdjustOption(1)
VideoAdjustOption.Enable     = VideoAdjustOption(0)
VideoAdjustOption.Gamma      = VideoAdjustOption(5)
VideoAdjustOption.Hue        = VideoAdjustOption(3)
VideoAdjustOption.Saturation = VideoAdjustOption(4)

class AudioOutputDeviceTypes(_Enum):
    '''Audio device types.
    '''
    _enum_names_ = {
        -1: 'Error',
        1: 'Mono',
        2: 'Stereo',
        4: '_2F2R',
        5: '_3F2R',
        6: '_5_1',
        7: '_6_1',
        8: '_7_1',
        10: 'SPDIF',
    }
AudioOutputDeviceTypes.Error  = AudioOutputDeviceTypes(-1)
AudioOutputDeviceTypes.Mono   = AudioOutputDeviceTypes(1)
AudioOutputDeviceTypes.SPDIF  = AudioOutputDeviceTypes(10)
AudioOutputDeviceTypes.Stereo = AudioOutputDeviceTypes(2)
AudioOutputDeviceTypes._2F2R  = AudioOutputDeviceTypes(4)
AudioOutputDeviceTypes._3F2R  = AudioOutputDeviceTypes(5)
AudioOutputDeviceTypes._5_1   = AudioOutputDeviceTypes(6)
AudioOutputDeviceTypes._6_1   = AudioOutputDeviceTypes(7)
AudioOutputDeviceTypes._7_1   = AudioOutputDeviceTypes(8)

class AudioOutputChannel(_Enum):
    '''Audio channels.
    '''
    _enum_names_ = {
        -1: 'Error',
        1: 'Stereo',
        2: 'RStereo',
        3: 'Left',
        4: 'Right',
        5: 'Dolbys',
    }
AudioOutputChannel.Dolbys  = AudioOutputChannel(5)
AudioOutputChannel.Error   = AudioOutputChannel(-1)
AudioOutputChannel.Left    = AudioOutputChannel(3)
AudioOutputChannel.RStereo = AudioOutputChannel(2)
AudioOutputChannel.Right   = AudioOutputChannel(4)
AudioOutputChannel.Stereo  = AudioOutputChannel(1)

class Callback(ctypes.c_void_p):
    """Callback function notification
\param p_event the event triggering the callback
    """
    pass
class LogCb(ctypes.c_void_p):
    """Callback prototype for LibVLC log message handler.
\param data data pointer as given to L{libvlc_log_set}()
\param level message level (@ref enum libvlc_log_level)
\param ctx message context (meta-informations about the message)
\param fmt printf() format string (as defined by ISO C11)
\param args variable argument list for the format
\note Log message handlers <b>must</b> be thread-safe.
\warning The message context pointer, the format string parameters and the
         variable arguments are only valid until the callback returns.
    """
    pass
class VideoLockCb(ctypes.c_void_p):
    """Callback prototype to allocate and lock a picture buffer.
Whenever a new video frame needs to be decoded, the lock callback is
invoked. Depending on the video chroma, one or three pixel planes of
adequate dimensions must be returned via the second parameter. Those
planes must be aligned on 32-bytes boundaries.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}() [IN]
\param planes start address of the pixel planes (LibVLC allocates the array
            of void pointers, this callback must initialize the array) [OUT]
\return a private pointer for the display and unlock callbacks to identify
        the picture buffers
    """
    pass
class VideoUnlockCb(ctypes.c_void_p):
    """Callback prototype to unlock a picture buffer.
When the video frame decoding is complete, the unlock callback is invoked.
This callback might not be needed at all. It is only an indication that the
application can now read the pixel values if it needs to.
\warning A picture buffer is unlocked after the picture is decoded,
but before the picture is displayed.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}() [IN]
\param picture private pointer returned from the @ref libvlc_video_lock_cb
               callback [IN]
\param planes pixel planes as defined by the @ref libvlc_video_lock_cb
              callback (this parameter is only for convenience) [IN]
    """
    pass
class VideoDisplayCb(ctypes.c_void_p):
    """Callback prototype to display a picture.
When the video frame needs to be shown, as determined by the media playback
clock, the display callback is invoked.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}() [IN]
\param picture private pointer returned from the @ref libvlc_video_lock_cb
               callback [IN]
    """
    pass
class VideoFormatCb(ctypes.c_void_p):
    """Callback prototype to configure picture buffers format.
This callback gets the format of the video as output by the video decoder
and the chain of video filters (if any). It can opt to change any parameter
as it needs. In that case, LibVLC will attempt to convert the video format
(rescaling and chroma conversion) but these operations can be CPU intensive.
\param opaque pointer to the private pointer passed to
              L{libvlc_video_set_callbacks}() [IN/OUT]
\param chroma pointer to the 4 bytes video format identifier [IN/OUT]
\param width pointer to the pixel width [IN/OUT]
\param height pointer to the pixel height [IN/OUT]
\param pitches table of scanline pitches in bytes for each pixel plane
               (the table is allocated by LibVLC) [OUT]
\param lines table of scanlines count for each plane [OUT]
\return the number of picture buffers allocated, 0 indicates failure
\note
For each pixels plane, the scanline pitch must be bigger than or equal to
the number of bytes per pixel multiplied by the pixel width.
Similarly, the number of scanlines must be bigger than of equal to
the pixel height.
Furthermore, we recommend that pitches and lines be multiple of 32
to not break assumption that might be made by various optimizations
in the video decoders, video filters and/or video converters.
    """
    pass
class VideoCleanupCb(ctypes.c_void_p):
    """Callback prototype to configure picture buffers format.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}()
              (and possibly modified by @ref libvlc_video_format_cb) [IN]
    """
    pass
class AudioPlayCb(ctypes.c_void_p):
    """Callback prototype for audio playback.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param samples pointer to the first audio sample to play back [IN]
\param count number of audio samples to play back
\param pts expected play time stamp (see libvlc_delay())
    """
    pass
class AudioPauseCb(ctypes.c_void_p):
    """Callback prototype for audio pause.
\note The pause callback is never called if the audio is already paused.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param pts time stamp of the pause request (should be elapsed already)
    """
    pass
class AudioResumeCb(ctypes.c_void_p):
    """Callback prototype for audio resumption (i.e. restart from pause).
\note The resume callback is never called if the audio is not paused.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param pts time stamp of the resumption request (should be elapsed already)
    """
    pass
class AudioFlushCb(ctypes.c_void_p):
    """Callback prototype for audio buffer flush
(i.e. discard all pending buffers and stop playback as soon as possible).
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
    """
    pass
class AudioDrainCb(ctypes.c_void_p):
    """Callback prototype for audio buffer drain
(i.e. wait for pending buffers to be played).
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
    """
    pass
class AudioSetVolumeCb(ctypes.c_void_p):
    """Callback prototype for audio volume change.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param volume software volume (1. = nominal, 0. = mute)
\param mute muted flag
    """
    pass
class AudioSetupCb(ctypes.c_void_p):
    """Callback prototype to setup the audio playback.
This is called when the media player needs to create a new audio output.
\param opaque pointer to the data pointer passed to
              L{libvlc_audio_set_callbacks}() [IN/OUT]
\param format 4 bytes sample format [IN/OUT]
\param rate sample rate [IN/OUT]
\param channels channels count [IN/OUT]
\return 0 on success, anything else to skip audio playback
    """
    pass
class AudioCleanupCb(ctypes.c_void_p):
    """Callback prototype for audio playback cleanup.
This is called when the media player no longer needs an audio output.
\param opaque data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
    """
    pass
class CallbackDecorators(object):
    "Class holding various method decorators for callback functions."
    Callback = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p)
    Callback.__doc__ = '''Callback function notification
\param p_event the event triggering the callback
    ''' 
    LogCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int, Log_ptr, ctypes.c_char_p, ctypes.c_void_p)
    LogCb.__doc__ = '''Callback prototype for LibVLC log message handler.
\param data data pointer as given to L{libvlc_log_set}()
\param level message level (@ref enum libvlc_log_level)
\param ctx message context (meta-informations about the message)
\param fmt printf() format string (as defined by ISO C11)
\param args variable argument list for the format
\note Log message handlers <b>must</b> be thread-safe.
\warning The message context pointer, the format string parameters and the
         variable arguments are only valid until the callback returns.
    ''' 
    VideoLockCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ListPOINTER(ctypes.c_void_p))
    VideoLockCb.__doc__ = '''Callback prototype to allocate and lock a picture buffer.
Whenever a new video frame needs to be decoded, the lock callback is
invoked. Depending on the video chroma, one or three pixel planes of
adequate dimensions must be returned via the second parameter. Those
planes must be aligned on 32-bytes boundaries.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}() [IN]
\param planes start address of the pixel planes (LibVLC allocates the array
            of void pointers, this callback must initialize the array) [OUT]
\return a private pointer for the display and unlock callbacks to identify
        the picture buffers
    ''' 
    VideoUnlockCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ListPOINTER(ctypes.c_void_p))
    VideoUnlockCb.__doc__ = '''Callback prototype to unlock a picture buffer.
When the video frame decoding is complete, the unlock callback is invoked.
This callback might not be needed at all. It is only an indication that the
application can now read the pixel values if it needs to.
\warning A picture buffer is unlocked after the picture is decoded,
but before the picture is displayed.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}() [IN]
\param picture private pointer returned from the @ref libvlc_video_lock_cb
               callback [IN]
\param planes pixel planes as defined by the @ref libvlc_video_lock_cb
              callback (this parameter is only for convenience) [IN]
    ''' 
    VideoDisplayCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p)
    VideoDisplayCb.__doc__ = '''Callback prototype to display a picture.
When the video frame needs to be shown, as determined by the media playback
clock, the display callback is invoked.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}() [IN]
\param picture private pointer returned from the @ref libvlc_video_lock_cb
               callback [IN]
    ''' 
    VideoFormatCb = ctypes.CFUNCTYPE(ctypes.POINTER(ctypes.c_uint), ListPOINTER(ctypes.c_void_p), ctypes.c_char_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint))
    VideoFormatCb.__doc__ = '''Callback prototype to configure picture buffers format.
This callback gets the format of the video as output by the video decoder
and the chain of video filters (if any). It can opt to change any parameter
as it needs. In that case, LibVLC will attempt to convert the video format
(rescaling and chroma conversion) but these operations can be CPU intensive.
\param opaque pointer to the private pointer passed to
              L{libvlc_video_set_callbacks}() [IN/OUT]
\param chroma pointer to the 4 bytes video format identifier [IN/OUT]
\param width pointer to the pixel width [IN/OUT]
\param height pointer to the pixel height [IN/OUT]
\param pitches table of scanline pitches in bytes for each pixel plane
               (the table is allocated by LibVLC) [OUT]
\param lines table of scanlines count for each plane [OUT]
\return the number of picture buffers allocated, 0 indicates failure
\note
For each pixels plane, the scanline pitch must be bigger than or equal to
the number of bytes per pixel multiplied by the pixel width.
Similarly, the number of scanlines must be bigger than of equal to
the pixel height.
Furthermore, we recommend that pitches and lines be multiple of 32
to not break assumption that might be made by various optimizations
in the video decoders, video filters and/or video converters.
    ''' 
    VideoCleanupCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p)
    VideoCleanupCb.__doc__ = '''Callback prototype to configure picture buffers format.
\param opaque private pointer as passed to L{libvlc_video_set_callbacks}()
              (and possibly modified by @ref libvlc_video_format_cb) [IN]
    ''' 
    AudioPlayCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_uint, ctypes.c_int64)
    AudioPlayCb.__doc__ = '''Callback prototype for audio playback.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param samples pointer to the first audio sample to play back [IN]
\param count number of audio samples to play back
\param pts expected play time stamp (see libvlc_delay())
    ''' 
    AudioPauseCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int64)
    AudioPauseCb.__doc__ = '''Callback prototype for audio pause.
\note The pause callback is never called if the audio is already paused.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param pts time stamp of the pause request (should be elapsed already)
    ''' 
    AudioResumeCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int64)
    AudioResumeCb.__doc__ = '''Callback prototype for audio resumption (i.e. restart from pause).
\note The resume callback is never called if the audio is not paused.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param pts time stamp of the resumption request (should be elapsed already)
    ''' 
    AudioFlushCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_int64)
    AudioFlushCb.__doc__ = '''Callback prototype for audio buffer flush
(i.e. discard all pending buffers and stop playback as soon as possible).
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
    ''' 
    AudioDrainCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p)
    AudioDrainCb.__doc__ = '''Callback prototype for audio buffer drain
(i.e. wait for pending buffers to be played).
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
    ''' 
    AudioSetVolumeCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p, ctypes.c_float, ctypes.c_bool)
    AudioSetVolumeCb.__doc__ = '''Callback prototype for audio volume change.
\param data data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
\param volume software volume (1. = nominal, 0. = mute)
\param mute muted flag
    ''' 
    AudioSetupCb = ctypes.CFUNCTYPE(ctypes.POINTER(ctypes.c_int), ListPOINTER(ctypes.c_void_p), ctypes.c_char_p, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint))
    AudioSetupCb.__doc__ = '''Callback prototype to setup the audio playback.
This is called when the media player needs to create a new audio output.
\param opaque pointer to the data pointer passed to
              L{libvlc_audio_set_callbacks}() [IN/OUT]
\param format 4 bytes sample format [IN/OUT]
\param rate sample rate [IN/OUT]
\param channels channels count [IN/OUT]
\return 0 on success, anything else to skip audio playback
    ''' 
    AudioCleanupCb = ctypes.CFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p)
    AudioCleanupCb.__doc__ = '''Callback prototype for audio playback cleanup.
This is called when the media player no longer needs an audio output.
\param opaque data pointer as passed to L{libvlc_audio_set_callbacks}() [IN]
    ''' 
cb = CallbackDecorators
 # End of generated enum types #

 # From libvlc_structures.h

class AudioOutput(_Cstruct):

    def __str__(self):
        return '%s(%s:%s)' % (self.__class__.__name__, self.name, self.description)

AudioOutput._fields_ = [  # recursive struct
    ('name',        ctypes.c_char_p),
    ('description', ctypes.c_char_p),
    ('next',        ctypes.POINTER(AudioOutput)),
    ]

class LogMessage(_Cstruct):
    _fields_ = [
        ('size',     ctypes.c_uint  ),
        ('severity', ctypes.c_int   ),
        ('type',     ctypes.c_char_p),
        ('name',     ctypes.c_char_p),
        ('header',   ctypes.c_char_p),
        ('message',  ctypes.c_char_p),
    ]

    def __init__(self):
        super(LogMessage, self).__init__()
        self.size = ctypes.sizeof(self)

    def __str__(self):
        return '%s(%d:%s): %s' % (self.__class__.__name__, self.severity, self.type, self.message)

class MediaEvent(_Cstruct):
    _fields_ = [
        ('media_name',    ctypes.c_char_p),
        ('instance_name', ctypes.c_char_p),
    ]

class MediaStats(_Cstruct):
    _fields_ = [
        ('read_bytes',          ctypes.c_int  ),
        ('input_bitrate',       ctypes.c_float),
        ('demux_read_bytes',    ctypes.c_int  ),
        ('demux_bitrate',       ctypes.c_float),
        ('demux_corrupted',     ctypes.c_int  ),
        ('demux_discontinuity', ctypes.c_int  ),
        ('decoded_video',       ctypes.c_int  ),
        ('decoded_audio',       ctypes.c_int  ),
        ('displayed_pictures',  ctypes.c_int  ),
        ('lost_pictures',       ctypes.c_int  ),
        ('played_abuffers',     ctypes.c_int  ),
        ('lost_abuffers',       ctypes.c_int  ),
        ('sent_packets',        ctypes.c_int  ),
        ('sent_bytes',          ctypes.c_int  ),
        ('send_bitrate',        ctypes.c_float),
    ]

class MediaTrackInfo(_Cstruct):
    _fields_ = [
        ('codec',              ctypes.c_uint32),
        ('id',                 ctypes.c_int   ),
        ('type',               TrackType      ),
        ('profile',            ctypes.c_int   ),
        ('level',              ctypes.c_int   ),
        ('channels_or_height', ctypes.c_uint  ),
        ('rate_or_width',      ctypes.c_uint  ),
    ]

class AudioTrack(_Cstruct):
    _fields_ = [
        ('channels', ctypes.c_uint),
        ('rate', ctypes.c_uint),
        ]

class VideoTrack(_Cstruct):
    _fields_ = [
        ('height', ctypes.c_uint),
        ('width', ctypes.c_uint),
        ('sar_num', ctypes.c_uint),
        ('sar_den', ctypes.c_uint),
        ('frame_rate_num', ctypes.c_uint),
        ('frame_rate_den', ctypes.c_uint),
        ]

class SubtitleTrack(_Cstruct):
    _fields_ = [
        ('encoding', ctypes.c_char_p),
        ]

class MediaTrackTracks(ctypes.Union):
    _fields_ = [
        ('audio', ctypes.POINTER(AudioTrack)),
        ('video', ctypes.POINTER(VideoTrack)),
        ('subtitle', ctypes.POINTER(SubtitleTrack)),
        ]

class MediaTrack(_Cstruct):
    _anonymous_ = ("u",)
    _fields_ = [
        ('codec',              ctypes.c_uint32),
        ('original_fourcc',    ctypes.c_uint32),
        ('id',                 ctypes.c_int   ),
        ('type',               TrackType      ),
        ('profile',            ctypes.c_int   ),
        ('level',              ctypes.c_int   ),

        ('u',                  MediaTrackTracks),
        ('bitrate',            ctypes.c_uint),
        ('language',           ctypes.c_char_p),
        ('description',        ctypes.c_char_p),
        ]

class PlaylistItem(_Cstruct):
    _fields_ = [
        ('id',   ctypes.c_int   ),
        ('uri',  ctypes.c_char_p),
        ('name', ctypes.c_char_p),
    ]

    def __str__(self):
        return '%s #%d %s (uri %s)' % (self.__class__.__name__, self.id, self.name, self.uri)

class Position(object):
    """Enum-like, immutable window position constants.

       See e.g. VideoMarqueeOption.Position.
    """
    Center       = 0
    Left         = 1
    CenterLeft   = 1
    Right        = 2
    CenterRight  = 2
    Top          = 4
    TopCenter    = 4
    TopLeft      = 5
    TopRight     = 6
    Bottom       = 8
    BottomCenter = 8
    BottomLeft   = 9
    BottomRight  = 10
    def __init__(self, *unused):
        raise TypeError('constants only')
    def __setattr__(self, *unused):  #PYCHOK expected
        raise TypeError('immutable constants')

class Rectangle(_Cstruct):
    _fields_ = [
        ('top',    ctypes.c_int),
        ('left',   ctypes.c_int),
        ('bottom', ctypes.c_int),
        ('right',  ctypes.c_int),
    ]

class TrackDescription(_Cstruct):

    def __str__(self):
        return '%s(%d:%s)' % (self.__class__.__name__, self.id, self.name)

TrackDescription._fields_ = [  # recursive struct
    ('id',   ctypes.c_int   ),
    ('name', ctypes.c_char_p),
    ('next', ctypes.POINTER(TrackDescription)),
    ]

def track_description_list(head):
    """Convert a TrackDescription linked list to a Python list (and release the former).
    """
    r = []
    if head:
        item = head
        while item:
            item = item.contents
            r.append((item.id, item.name))
            item = item.next
        try:
            libvlc_track_description_release(head)
        except NameError:
            libvlc_track_description_list_release(head)

    return r

class EventUnion(ctypes.Union):
    _fields_ = [
        ('meta_type',    ctypes.c_uint    ),
        ('new_child',    ctypes.c_uint    ),
        ('new_duration', ctypes.c_longlong),
        ('new_status',   ctypes.c_int     ),
        ('media',        ctypes.c_void_p  ),
        ('new_state',    ctypes.c_uint    ),
        # Media instance
        ('new_position', ctypes.c_float   ),
        ('new_time',     ctypes.c_longlong),
        ('new_title',    ctypes.c_int     ),
        ('new_seekable', ctypes.c_longlong),
        ('new_pausable', ctypes.c_longlong),
        # FIXME: Skipped MediaList and MediaListView...
        ('filename',     ctypes.c_char_p  ),
        ('new_length',   ctypes.c_longlong),
        ('media_event',  MediaEvent       ),
    ]

class Event(_Cstruct):
    _fields_ = [
        ('type',   EventType      ),
        ('object', ctypes.c_void_p),
        ('u',      EventUnion     ),
    ]

class ModuleDescription(_Cstruct):

    def __str__(self):
        return '%s %s (%s)' % (self.__class__.__name__, self.shortname, self.name)

ModuleDescription._fields_ = [  # recursive struct
    ('name',      ctypes.c_char_p),
    ('shortname', ctypes.c_char_p),
    ('longname',  ctypes.c_char_p),
    ('help',      ctypes.c_char_p),
    ('next',      ctypes.POINTER(ModuleDescription)),
    ]

def module_description_list(head):
    """Convert a ModuleDescription linked list to a Python list (and release the former).
    """
    r = []
    if head:
        item = head
        while item:
            item = item.contents
            r.append((item.name, item.shortname, item.longname, item.help))
            item = item.next
        libvlc_module_description_list_release(head)
    return r

class AudioOutputDevice(_Cstruct):

    def __str__(self):
        return '%s(%d:%s)' % (self.__class__.__name__, self.id, self.name)

AudioOutputDevice._fields_ = [  # recursive struct
    ('next', ctypes.POINTER(AudioOutputDevice)),
    ('device',   ctypes.c_char_p   ),
    ('description', ctypes.c_char_p),
    ]

 # End of header.py #

class EventManager(_Ctype):
    '''Create an event manager with callback handler.

    This class interposes the registration and handling of
    event notifications in order to (a) remove the need for
    decorating each callback functions with the decorator
    '@callbackmethod', (b) allow any number of positional
    and/or keyword arguments to the callback (in addition
    to the Event instance) and (c) to preserve the Python
    objects such that the callback and argument objects
    remain alive (i.e. are not garbage collected) until
    B{after} the notification has been unregistered.

    @note: Only a single notification can be registered
    for each event type in an EventManager instance.
    
    '''

    _callback_handler = None
    _callbacks = {}

    def __new__(cls, ptr=_internal_guard):
        if ptr == _internal_guard:
            raise VLCException("(INTERNAL) ctypes class.\nYou should get a reference to EventManager through the MediaPlayer.event_manager() method.")
        return _Constructor(cls, ptr)

    def event_attach(self, eventtype, callback, *args, **kwds):
        """Register an event notification.

        @param eventtype: the desired event type to be notified about.
        @param callback: the function to call when the event occurs.
        @param args: optional positional arguments for the callback.
        @param kwds: optional keyword arguments for the callback.
        @return: 0 on success, ENOMEM on error.

        @note: The callback function must have at least one argument,
        an Event instance.  Any other, optional positional and keyword
        arguments are in B{addition} to the first one.
        """
        if not isinstance(eventtype, EventType):
            raise VLCException("%s required: %r" % ('EventType', eventtype))
        if not hasattr(callback, '__call__'):  # callable()
            raise VLCException("%s required: %r" % ('callable', callback))
         # check that the callback expects arguments
        if not any(getargspec(callback)[:2]):  # list(...)
            raise VLCException("%s required: %r" % ('argument', callback))

        if self._callback_handler is None:
            _called_from_ctypes = ctypes.CFUNCTYPE(None, ctypes.POINTER(Event), ctypes.c_void_p)
            @_called_from_ctypes
            def _callback_handler(event, k):
                """(INTERNAL) handle callback call from ctypes.

                @note: We cannot simply make this an EventManager
                method since ctypes does not prepend self as the
                first parameter, hence this closure.
                """
                try: # retrieve Python callback and arguments
                    call, args, kwds = self._callbacks[k]
                     # deref event.contents to simplify callback code
                    call(event.contents, *args, **kwds)
                except KeyError:  # detached?
                    pass
            self._callback_handler = _callback_handler
            self._callbacks = {}

        k = eventtype.value
        r = libvlc_event_attach(self, k, self._callback_handler, k)
        if not r:
            self._callbacks[k] = (callback, args, kwds)
        return r

    def event_detach(self, eventtype):
        """Unregister an event notification.

        @param eventtype: the event type notification to be removed.
        """
        if not isinstance(eventtype, EventType):
            raise VLCException("%s required: %r" % ('EventType', eventtype))

        k = eventtype.value
        if k in self._callbacks:
            del self._callbacks[k] # remove, regardless of libvlc return value
            libvlc_event_detach(self, k, self._callback_handler, k)

class Instance(_Ctype):
    '''Create a new Instance instance.

    It may take as parameter either:
      - a string
      - a list of strings as first parameters
      - the parameters given as the constructor parameters (must be strings)
    
    '''

    def __new__(cls, *args):
        if len(args) == 1:
            # Only 1 arg. It is either a C pointer, or an arg string,
            # or a tuple.
            i = args[0]
            if isinstance(i, _Ints):
                return _Constructor(cls, i)
            elif isinstance(i, basestring):
                args = i.strip().split()
            elif isinstance(i, _Seqs):
                args = i
            else:
                raise VLCException('Instance %r' % (args,))

        if not args and plugin_path is not None:
             # no parameters passed, for win32 and MacOS,
             # specify the plugin_path if detected earlier
            args = ['vlc', '--plugin-path=' + plugin_path]
        if PYTHON3:
            args = [ str_to_bytes(a) for a in args ]
        return libvlc_new(len(args), args)

    def media_player_new(self, uri=None):
        """Create a new MediaPlayer instance.

        @param uri: an optional URI to play in the player.
        """
        p = libvlc_media_player_new(self)
        if uri:
            p.set_media(self.media_new(uri))
        p._instance = self
        return p

    def media_list_player_new(self):
        """Create a new MediaListPlayer instance.
        """
        p = libvlc_media_list_player_new(self)
        p._instance = self
        return p

    def media_new(self, mrl, *options):
        """Create a new Media instance.

        If mrl contains a colon (:) preceded by more than 1 letter, it
        will be treated as a URL. Else, it will be considered as a
        local path. If you need more control, directly use
        media_new_location/media_new_path methods.

        Options can be specified as supplementary string parameters, e.g.

        C{m = i.media_new('foo.avi', 'sub-filter=marq{marquee=Hello}', 'vout-filter=invert')}

        Alternatively, the options can be added to the media using the Media.add_options method:

        C{m.add_options('foo.avi', 'sub-filter=marq@test{marquee=Hello}', 'video-filter=invert')}

        @param options: optional media option=value strings
        """
        if ':' in mrl and mrl.index(':') > 1:
            # Assume it is a URL
            m = libvlc_media_new_location(self, str_to_bytes(mrl))
        else:
            # Else it should be a local path.
            m = libvlc_media_new_path(self, str_to_bytes(os.path.normpath(mrl)))
        for o in options:
            libvlc_media_add_option(m, str_to_bytes(o))
        m._instance = self
        return m

    def media_list_new(self, mrls=None):
        """Create a new MediaList instance.
        @param mrls: optional list of MRL strings
        """
        l = libvlc_media_list_new(self)
        # We should take the lock, but since we did not leak the
        # reference, nobody else can access it.
        if mrls:
            for m in mrls:
                l.add_media(m)
        l._instance = self
        return l

    def audio_output_enumerate_devices(self):
        """Enumerate the defined audio output devices.

        @return: list of dicts {name:, description:, devices:}
        """
        r = []
        head = libvlc_audio_output_list_get(self)
        if head:
            i = head
            while i:
                i = i.contents
                d = [{'id':       libvlc_audio_output_device_id      (self, i.name, d),
                      'longname': libvlc_audio_output_device_longname(self, i.name, d)}
                   for d in range(libvlc_audio_output_device_count   (self, i.name))]
                r.append({'name': i.name, 'description': i.description, 'devices': d})
                i = i.next
            libvlc_audio_output_list_release(head)
        return r

    def audio_filter_list_get(self):
        """Returns a list of available audio filters.

        """
        return module_description_list(libvlc_audio_filter_list_get(self))

    def video_filter_list_get(self):
        """Returns a list of available video filters.

        """
        return module_description_list(libvlc_video_filter_list_get(self))


    def release(self):
        '''Decrement the reference count of a libvlc instance, and destroy it
        if it reaches zero.
        '''
        return libvlc_release(self)

    def retain(self):
        '''Increments the reference count of a libvlc instance.
        The initial reference count is 1 after L{new}() returns.
        '''
        return libvlc_retain(self)

    def add_intf(self, name):
        '''Try to start a user interface for the libvlc instance.
        @param name: interface name, or NULL for default.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_add_intf(self, str_to_bytes(name))

    def set_user_agent(self, name, http):
        '''Sets the application name. LibVLC passes this as the user agent string
        when a protocol requires it.
        @param name: human-readable application name, e.g. "FooBar player 1.2.3".
        @param http: HTTP User Agent, e.g. "FooBar/1.2.3 Python/2.6.0".
        @version: LibVLC 1.1.1 or later.
        '''
        return libvlc_set_user_agent(self, str_to_bytes(name), str_to_bytes(http))

    def log_unset(self):
        '''Unsets the logging callback for a LibVLC instance. This is rarely needed:
        the callback is implicitly unset when the instance is destroyed.
        This function will wait for any pending callbacks invocation to complete
        (causing a deadlock if called from within the callback).
        @version: LibVLC 2.1.0 or later.
        '''
        return libvlc_log_unset(self)

    def log_set(self, data, p_instance):
        '''Sets the logging callback for a LibVLC instance.
        This function is thread-safe: it will wait for any pending callbacks
        invocation to complete.
        @param data: opaque data pointer for the callback function @note Some log messages (especially debug) are emitted by LibVLC while is being initialized. These messages cannot be captured with this interface. @warning A deadlock may occur if this function is called from the callback.
        @param p_instance: libvlc instance.
        @version: LibVLC 2.1.0 or later.
        '''
        return libvlc_log_set(self, data, p_instance)

    def log_set_file(self, stream):
        '''Sets up logging to a file.
        @param stream: FILE pointer opened for writing (the FILE pointer must remain valid until L{log_unset}()).
        @version: LibVLC 2.1.0 or later.
        '''
        return libvlc_log_set_file(self, stream)

    def media_new_location(self, psz_mrl):
        '''Create a media with a certain given media resource location,
        for instance a valid URL.
        @note: To refer to a local file with this function,
        the file://... URI syntax B{must} be used (see IETF RFC3986).
        We recommend using L{media_new_path}() instead when dealing with
        local files.
        See L{media_release}.
        @param psz_mrl: the media location.
        @return: the newly created media or NULL on error.
        '''
        return libvlc_media_new_location(self, str_to_bytes(psz_mrl))

    def media_new_path(self, path):
        '''Create a media for a certain file path.
        See L{media_release}.
        @param path: local filesystem path.
        @return: the newly created media or NULL on error.
        '''
        return libvlc_media_new_path(self, str_to_bytes(path))

    def media_new_fd(self, fd):
        '''Create a media for an already open file descriptor.
        The file descriptor shall be open for reading (or reading and writing).
        Regular file descriptors, pipe read descriptors and character device
        descriptors (including TTYs) are supported on all platforms.
        Block device descriptors are supported where available.
        Directory descriptors are supported on systems that provide fdopendir().
        Sockets are supported on all platforms where they are file descriptors,
        i.e. all except Windows.
        @note: This library will B{not} automatically close the file descriptor
        under any circumstance. Nevertheless, a file descriptor can usually only be
        rendered once in a media player. To render it a second time, the file
        descriptor should probably be rewound to the beginning with lseek().
        See L{media_release}.
        @param fd: open file descriptor.
        @return: the newly created media or NULL on error.
        @version: LibVLC 1.1.5 and later.
        '''
        return libvlc_media_new_fd(self, fd)

    def media_new_as_node(self, psz_name):
        '''Create a media as an empty node with a given name.
        See L{media_release}.
        @param psz_name: the name of the node.
        @return: the new empty media or NULL on error.
        '''
        return libvlc_media_new_as_node(self, str_to_bytes(psz_name))

    def media_discoverer_new_from_name(self, psz_name):
        '''Discover media service by name.
        @param psz_name: service name.
        @return: media discover object or NULL in case of error.
        '''
        return libvlc_media_discoverer_new_from_name(self, str_to_bytes(psz_name))

    def media_library_new(self):
        '''Create an new Media Library object.
        @return: a new object or NULL on error.
        '''
        return libvlc_media_library_new(self)

    def audio_output_list_get(self):
        '''Gets the list of available audio outputs.
        @return: list of available audio outputs. It must be freed it with In case of error, NULL is returned.
        '''
        return libvlc_audio_output_list_get(self)

    def audio_output_device_list_get(self, aout):
        '''Gets a list of audio output devices for a given audio output.
        See L{audio_output_device_set}().
        @note: Not all audio outputs support this. In particular, an empty (NULL)
        list of devices does B{not} imply that the specified audio output does
        not work.
        @note: The list might not be exhaustive.
        @warning: Some audio output devices in the list might not actually work in
        some circumstances. By default, it is recommended to not specify any
        explicit audio device.
        @param psz_aout: audio output name (as returned by L{audio_output_list_get}()).
        @return: A NULL-terminated linked list of potential audio output devices. It must be freed it with L{audio_output_device_list_release}().
        @version: LibVLC 2.1.0 or later.
        '''
        return libvlc_audio_output_device_list_get(self, str_to_bytes(aout))

    def vlm_release(self):
        '''Release the vlm instance related to the given L{Instance}.
        '''
        return libvlc_vlm_release(self)

    def vlm_add_broadcast(self, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):
        '''Add a broadcast, with one input.
        @param psz_name: the name of the new broadcast.
        @param psz_input: the input MRL.
        @param psz_output: the output MRL (the parameter to the "sout" variable).
        @param i_options: number of additional options.
        @param ppsz_options: additional options.
        @param b_enabled: boolean for enabling the new broadcast.
        @param b_loop: Should this broadcast be played in loop ?
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_add_broadcast(self, str_to_bytes(psz_name), str_to_bytes(psz_input), str_to_bytes(psz_output), i_options, ppsz_options, b_enabled, b_loop)

    def vlm_add_vod(self, psz_name, psz_input, i_options, ppsz_options, b_enabled, psz_mux):
        '''Add a vod, with one input.
        @param psz_name: the name of the new vod media.
        @param psz_input: the input MRL.
        @param i_options: number of additional options.
        @param ppsz_options: additional options.
        @param b_enabled: boolean for enabling the new vod.
        @param psz_mux: the muxer of the vod media.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_add_vod(self, str_to_bytes(psz_name), str_to_bytes(psz_input), i_options, ppsz_options, b_enabled, str_to_bytes(psz_mux))

    def vlm_del_media(self, psz_name):
        '''Delete a media (VOD or broadcast).
        @param psz_name: the media to delete.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_del_media(self, str_to_bytes(psz_name))

    def vlm_set_enabled(self, psz_name, b_enabled):
        '''Enable or disable a media (VOD or broadcast).
        @param psz_name: the media to work on.
        @param b_enabled: the new status.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_set_enabled(self, str_to_bytes(psz_name), b_enabled)

    def vlm_set_output(self, psz_name, psz_output):
        '''Set the output for a media.
        @param psz_name: the media to work on.
        @param psz_output: the output MRL (the parameter to the "sout" variable).
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_set_output(self, str_to_bytes(psz_name), str_to_bytes(psz_output))

    def vlm_set_input(self, psz_name, psz_input):
        '''Set a media's input MRL. This will delete all existing inputs and
        add the specified one.
        @param psz_name: the media to work on.
        @param psz_input: the input MRL.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_set_input(self, str_to_bytes(psz_name), str_to_bytes(psz_input))

    def vlm_add_input(self, psz_name, psz_input):
        '''Add a media's input MRL. This will add the specified one.
        @param psz_name: the media to work on.
        @param psz_input: the input MRL.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_add_input(self, str_to_bytes(psz_name), str_to_bytes(psz_input))

    def vlm_set_loop(self, psz_name, b_loop):
        '''Set a media's loop status.
        @param psz_name: the media to work on.
        @param b_loop: the new status.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_set_loop(self, str_to_bytes(psz_name), b_loop)

    def vlm_set_mux(self, psz_name, psz_mux):
        '''Set a media's vod muxer.
        @param psz_name: the media to work on.
        @param psz_mux: the new muxer.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_set_mux(self, str_to_bytes(psz_name), str_to_bytes(psz_mux))

    def vlm_change_media(self, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):
        '''Edit the parameters of a media. This will delete all existing inputs and
        add the specified one.
        @param psz_name: the name of the new broadcast.
        @param psz_input: the input MRL.
        @param psz_output: the output MRL (the parameter to the "sout" variable).
        @param i_options: number of additional options.
        @param ppsz_options: additional options.
        @param b_enabled: boolean for enabling the new broadcast.
        @param b_loop: Should this broadcast be played in loop ?
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_change_media(self, str_to_bytes(psz_name), str_to_bytes(psz_input), str_to_bytes(psz_output), i_options, ppsz_options, b_enabled, b_loop)

    def vlm_play_media(self, psz_name):
        '''Play the named broadcast.
        @param psz_name: the name of the broadcast.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_play_media(self, str_to_bytes(psz_name))

    def vlm_stop_media(self, psz_name):
        '''Stop the named broadcast.
        @param psz_name: the name of the broadcast.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_stop_media(self, str_to_bytes(psz_name))

    def vlm_pause_media(self, psz_name):
        '''Pause the named broadcast.
        @param psz_name: the name of the broadcast.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_pause_media(self, str_to_bytes(psz_name))

    def vlm_seek_media(self, psz_name, f_percentage):
        '''Seek in the named broadcast.
        @param psz_name: the name of the broadcast.
        @param f_percentage: the percentage to seek to.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_vlm_seek_media(self, str_to_bytes(psz_name), f_percentage)

    def vlm_show_media(self, psz_name):
        '''Return information about the named media as a JSON
        string representation.
        This function is mainly intended for debugging use,
        if you want programmatic access to the state of
        a vlm_media_instance_t, please use the corresponding
        libvlc_vlm_get_media_instance_xxx -functions.
        Currently there are no such functions available for
        vlm_media_t though.
        @param psz_name: the name of the media, if the name is an empty string, all media is described.
        @return: string with information about named media, or NULL on error.
        '''
        return libvlc_vlm_show_media(self, str_to_bytes(psz_name))

    def vlm_get_media_instance_position(self, psz_name, i_instance):
        '''Get vlm_media instance position by name or instance id.
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: position as float or -1. on error.
        '''
        return libvlc_vlm_get_media_instance_position(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_media_instance_time(self, psz_name, i_instance):
        '''Get vlm_media instance time by name or instance id.
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: time as integer or -1 on error.
        '''
        return libvlc_vlm_get_media_instance_time(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_media_instance_length(self, psz_name, i_instance):
        '''Get vlm_media instance length by name or instance id.
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: length of media item or -1 on error.
        '''
        return libvlc_vlm_get_media_instance_length(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_media_instance_rate(self, psz_name, i_instance):
        '''Get vlm_media instance playback rate by name or instance id.
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: playback rate or -1 on error.
        '''
        return libvlc_vlm_get_media_instance_rate(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_media_instance_title(self, psz_name, i_instance):
        '''Get vlm_media instance title number by name or instance id.
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: title as number or -1 on error.
        @bug: will always return 0.
        '''
        return libvlc_vlm_get_media_instance_title(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_media_instance_chapter(self, psz_name, i_instance):
        '''Get vlm_media instance chapter number by name or instance id.
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: chapter as number or -1 on error.
        @bug: will always return 0.
        '''
        return libvlc_vlm_get_media_instance_chapter(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_media_instance_seekable(self, psz_name, i_instance):
        '''Is libvlc instance seekable ?
        @param psz_name: name of vlm media instance.
        @param i_instance: instance id.
        @return: 1 if seekable, 0 if not, -1 if media does not exist.
        @bug: will always return 0.
        '''
        return libvlc_vlm_get_media_instance_seekable(self, str_to_bytes(psz_name), i_instance)

    def vlm_get_event_manager(self):
        '''Get libvlc_event_manager from a vlm media.
        The p_event_manager is immutable, so you don't have to hold the lock.
        @return: libvlc_event_manager.
        '''
        return libvlc_vlm_get_event_manager(self)

class Media(_Ctype):
    '''Create a new Media instance.
    
    Usage: Media(MRL, *options)

    See vlc.Instance.media_new documentation for details.
    
    '''

    def __new__(cls, *args):
        if args:
            i = args[0]
            if isinstance(i, _Ints):
                return _Constructor(cls, i)
            if isinstance(i, Instance):
                return i.media_new(*args[1:])

        o = get_default_instance().media_new(*args)
        return o

    def get_instance(self):
        return getattr(self, '_instance', None)

    def add_options(self, *options):
        """Add a list of options to the media.

        Options must be written without the double-dash, e.g.:

        C{m.add_options('sub-filter=marq@test{marquee=Hello}', 'video-filter=invert')}

        Alternatively, the options can directly be passed in the Instance.media_new method:

        C{m = instance.media_new('foo.avi', 'sub-filter=marq@test{marquee=Hello}', 'video-filter=invert')}

        @param options: optional media option=value strings
        """
        for o in options:
            self.add_option(o)


    def add_option(self, psz_options):
        '''Add an option to the media.
        This option will be used to determine how the media_player will
        read the media. This allows to use VLC's advanced
        reading/streaming options on a per-media basis.
        @note: The options are listed in 'vlc --long-help' from the command line,
        e.g. "-sout-all". Keep in mind that available options and their semantics
        vary across LibVLC versions and builds.
        @warning: Not all options affects L{Media} objects:
        Specifically, due to architectural issues most audio and video options,
        such as text renderer options, have no effects on an individual media.
        These options must be set through L{new}() instead.
        @param psz_options: the options (as a string).
        '''
        return libvlc_media_add_option(self, str_to_bytes(psz_options))

    def add_option_flag(self, psz_options, i_flags):
        '''Add an option to the media with configurable flags.
        This option will be used to determine how the media_player will
        read the media. This allows to use VLC's advanced
        reading/streaming options on a per-media basis.
        The options are detailed in vlc --long-help, for instance
        "--sout-all". Note that all options are not usable on medias:
        specifically, due to architectural issues, video-related options
        such as text renderer options cannot be set on a single media. They
        must be set on the whole libvlc instance instead.
        @param psz_options: the options (as a string).
        @param i_flags: the flags for this option.
        '''
        return libvlc_media_add_option_flag(self, str_to_bytes(psz_options), i_flags)

    def retain(self):
        '''Retain a reference to a media descriptor object (libvlc_media_t). Use
        L{release}() to decrement the reference count of a
        media descriptor object.
        '''
        return libvlc_media_retain(self)

    def release(self):
        '''Decrement the reference count of a media descriptor object. If the
        reference count is 0, then L{release}() will release the
        media descriptor object. It will send out an libvlc_MediaFreed event
        to all listeners. If the media descriptor object has been released it
        should not be used again.
        '''
        return libvlc_media_release(self)

    def get_mrl(self):
        '''Get the media resource locator (mrl) from a media descriptor object.
        @return: string with mrl of media descriptor object.
        '''
        return libvlc_media_get_mrl(self)

    def duplicate(self):
        '''Duplicate a media descriptor object.
        '''
        return libvlc_media_duplicate(self)

    def get_meta(self, e_meta):
        '''Read the meta of the media.
        If the media has not yet been parsed this will return NULL.
        This methods automatically calls L{parse_async}(), so after calling
        it you may receive a libvlc_MediaMetaChanged event. If you prefer a synchronous
        version ensure that you call L{parse}() before get_meta().
        See L{parse}
        See L{parse_async}
        See libvlc_MediaMetaChanged.
        @param e_meta: the meta to read.
        @return: the media's meta.
        '''
        return libvlc_media_get_meta(self, e_meta)

    def set_meta(self, e_meta, psz_value):
        '''Set the meta of the media (this function will not save the meta, call
        L{save_meta} in order to save the meta).
        @param e_meta: the meta to write.
        @param psz_value: the media's meta.
        '''
        return libvlc_media_set_meta(self, e_meta, str_to_bytes(psz_value))

    def save_meta(self):
        '''Save the meta previously set.
        @return: true if the write operation was successful.
        '''
        return libvlc_media_save_meta(self)

    def get_state(self):
        '''Get current state of media descriptor object. Possible media states
        are defined in libvlc_structures.c ( libvlc_NothingSpecial=0,
        libvlc_Opening, libvlc_Buffering, libvlc_Playing, libvlc_Paused,
        libvlc_Stopped, libvlc_Ended,
        libvlc_Error).
        See libvlc_state_t.
        @return: state of media descriptor object.
        '''
        return libvlc_media_get_state(self)

    def get_stats(self, p_stats):
        '''Get the current statistics about the media.
        @param p_stats:: structure that contain the statistics about the media (this structure must be allocated by the caller).
        @return: true if the statistics are available, false otherwise \libvlc_return_bool.
        '''
        return libvlc_media_get_stats(self, p_stats)

    def subitems(self):
        '''Get subitems of media descriptor object. This will increment
        the reference count of supplied media descriptor object. Use
        L{list_release}() to decrement the reference counting.
        @return: list of media descriptor subitems or NULL.
        '''
        return libvlc_media_subitems(self)

    def event_manager(self):
        '''Get event manager from media descriptor object.
        NOTE: this function doesn't increment reference counting.
        @return: event manager object.
        '''
        return libvlc_media_event_manager(self)

    def get_duration(self):
        '''Get duration (in ms) of media descriptor object item.
        @return: duration of media item or -1 on error.
        '''
        return libvlc_media_get_duration(self)

    def parse(self):
        '''Parse a media.
        This fetches (local) meta data and tracks information.
        The method is synchronous.
        See L{parse_async}
        See L{get_meta}
        See libvlc_media_get_tracks_info.
        '''
        return libvlc_media_parse(self)

    def parse_async(self):
        '''Parse a media.
        This fetches (local) meta data and tracks information.
        The method is the asynchronous of L{parse}().
        To track when this is over you can listen to libvlc_MediaParsedChanged
        event. However if the media was already parsed you will not receive this
        event.
        See L{parse}
        See libvlc_MediaParsedChanged
        See L{get_meta}
        See libvlc_media_get_tracks_info.
        '''
        return libvlc_media_parse_async(self)

    def is_parsed(self):
        '''Get Parsed status for media descriptor object.
        See libvlc_MediaParsedChanged.
        @return: true if media object has been parsed otherwise it returns false \libvlc_return_bool.
        '''
        return libvlc_media_is_parsed(self)

    def set_user_data(self, p_new_user_data):
        '''Sets media descriptor's user_data. user_data is specialized data
        accessed by the host application, VLC.framework uses it as a pointer to
        an native object that references a L{Media} pointer.
        @param p_new_user_data: pointer to user data.
        '''
        return libvlc_media_set_user_data(self, p_new_user_data)

    def get_user_data(self):
        '''Get media descriptor's user_data. user_data is specialized data
        accessed by the host application, VLC.framework uses it as a pointer to
        an native object that references a L{Media} pointer.
        '''
        return libvlc_media_get_user_data(self)

    def tracks_get(self, tracks):
        '''Get media descriptor's elementary streams description
        Note, you need to call L{parse}() or play the media at least once
        before calling this function.
        Not doing this will result in an empty array.
        @param tracks: address to store an allocated array of Elementary Streams descriptions (must be freed with L{tracks_release}.
        @return: the number of Elementary Streams (zero on error).
        @version: LibVLC 2.1.0 and later.
        '''
        return libvlc_media_tracks_get(self, tracks)

    def player_new_from_media(self):
        '''Create a Media Player object from a Media.
        @return: a new media player object, or NULL on error.
        '''
        return libvlc_media_player_new_from_media(self)

class MediaDiscoverer(_Ctype):
    '''N/A
    '''

    def __new__(cls, ptr=_internal_guard):
        '''(INTERNAL) ctypes wrapper constructor.
        '''
        return _Constructor(cls, ptr)
    def release(self):
        '''Release media discover object. If the reference count reaches 0, then
        the object will be released.
        '''
        return libvlc_media_discoverer_release(self)

    def localized_name(self):
        '''Get media service discover object its localized name.
        @return: localized name.
        '''
        return libvlc_media_discoverer_localized_name(self)

    def media_list(self):
        '''Get media service discover media list.
        @return: list of media items.
        '''
        return libvlc_media_discoverer_media_list(self)

    def event_manager(self):
        '''Get event manager from media service discover object.
        @return: event manager object.
        '''
        return libvlc_media_discoverer_event_manager(self)

    def is_running(self):
        '''Query if media service discover object is running.
        @return: true if running, false if not \libvlc_return_bool.
        '''
        return libvlc_media_discoverer_is_running(self)

class MediaLibrary(_Ctype):
    '''N/A
    '''

    def __new__(cls, ptr=_internal_guard):
        '''(INTERNAL) ctypes wrapper constructor.
        '''
        return _Constructor(cls, ptr)
    def release(self):
        '''Release media library object. This functions decrements the
        reference count of the media library object. If it reaches 0,
        then the object will be released.
        '''
        return libvlc_media_library_release(self)

    def retain(self):
        '''Retain a reference to a media library object. This function will
        increment the reference counting for this object. Use
        L{release}() to decrement the reference count.
        '''
        return libvlc_media_library_retain(self)

    def load(self):
        '''Load media library.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_media_library_load(self)

    def media_list(self):
        '''Get media library subitems.
        @return: media list subitems.
        '''
        return libvlc_media_library_media_list(self)

class MediaList(_Ctype):
    '''Create a new MediaList instance.
    
    Usage: MediaList(list_of_MRLs)

    See vlc.Instance.media_list_new documentation for details.
    
    '''

    def __new__(cls, *args):
        if args:
            i = args[0]
            if isinstance(i, _Ints):
                return _Constructor(cls, i)
            if isinstance(i, Instance):
                return i.media_list_new(*args[1:])

        o = get_default_instance().media_list_new(*args)
        return o

    def get_instance(self):
        return getattr(self, '_instance', None)
    
    def add_media(self, mrl):
        """Add media instance to media list.
        
        The L{lock} should be held upon entering this function.
        @param mrl: a media instance or a MRL.
        @return: 0 on success, -1 if the media list is read-only.
        """
        if isinstance(mrl, basestring):
            mrl = (self.get_instance() or get_default_instance()).media_new(mrl)
        return libvlc_media_list_add_media(self, mrl)


    def release(self):
        '''Release media list created with L{new}().
        '''
        return libvlc_media_list_release(self)

    def retain(self):
        '''Retain reference to a media list.
        '''
        return libvlc_media_list_retain(self)

    def set_media(self, p_md):
        '''Associate media instance with this media list instance.
        If another media instance was present it will be released.
        The L{lock} should NOT be held upon entering this function.
        @param p_md: media instance to add.
        '''
        return libvlc_media_list_set_media(self, p_md)

    def media(self):
        '''Get media instance from this media list instance. This action will increase
        the refcount on the media instance.
        The L{lock} should NOT be held upon entering this function.
        @return: media instance.
        '''
        return libvlc_media_list_media(self)

    def insert_media(self, p_md, i_pos):
        '''Insert media instance in media list on a position
        The L{lock} should be held upon entering this function.
        @param p_md: a media instance.
        @param i_pos: position in array where to insert.
        @return: 0 on success, -1 if the media list is read-only.
        '''
        return libvlc_media_list_insert_media(self, p_md, i_pos)

    def remove_index(self, i_pos):
        '''Remove media instance from media list on a position
        The L{lock} should be held upon entering this function.
        @param i_pos: position in array where to insert.
        @return: 0 on success, -1 if the list is read-only or the item was not found.
        '''
        return libvlc_media_list_remove_index(self, i_pos)

    def count(self):
        '''Get count on media list items
        The L{lock} should be held upon entering this function.
        @return: number of items in media list.
        '''
        return libvlc_media_list_count(self)

    def __len__(self):
        return libvlc_media_list_count(self)

    def item_at_index(self, i_pos):
        '''List media instance in media list at a position
        The L{lock} should be held upon entering this function.
        @param i_pos: position in array where to insert.
        @return: media instance at position i_pos, or NULL if not found. In case of success, L{media_retain}() is called to increase the refcount on the media.
        '''
        return libvlc_media_list_item_at_index(self, i_pos)

    def __getitem__(self, i):
        return libvlc_media_list_item_at_index(self, i)

    def __iter__(self):
        for i in range(len(self)):
            yield self[i]

    def index_of_item(self, p_md):
        '''Find index position of List media instance in media list.
        Warning: the function will return the first matched position.
        The L{lock} should be held upon entering this function.
        @param p_md: media instance.
        @return: position of media instance or -1 if media not found.
        '''
        return libvlc_media_list_index_of_item(self, p_md)

    def is_readonly(self):
        '''This indicates if this media list is read-only from a user point of view.
        @return: 1 on readonly, 0 on readwrite \libvlc_return_bool.
        '''
        return libvlc_media_list_is_readonly(self)

    def lock(self):
        '''Get lock on media list items.
        '''
        return libvlc_media_list_lock(self)

    def unlock(self):
        '''Release lock on media list items
        The L{lock} should be held upon entering this function.
        '''
        return libvlc_media_list_unlock(self)

    def event_manager(self):
        '''Get libvlc_event_manager from this media list instance.
        The p_event_manager is immutable, so you don't have to hold the lock.
        @return: libvlc_event_manager.
        '''
        return libvlc_media_list_event_manager(self)

class MediaListPlayer(_Ctype):
    '''Create a new MediaListPlayer instance.

    It may take as parameter either:
      - a vlc.Instance
      - nothing
    
    '''

    def __new__(cls, arg=None):
        if arg is None:
            i = get_default_instance()
        elif isinstance(arg, Instance):
            i = arg
        elif isinstance(arg, _Ints):
            return _Constructor(cls, arg)
        else:
            raise TypeError('MediaListPlayer %r' % (arg,))

        return i.media_list_player_new()

    def get_instance(self):
        """Return the associated Instance.
        """
        return self._instance  #PYCHOK expected


    def release(self):
        '''Release a media_list_player after use
        Decrement the reference count of a media player object. If the
        reference count is 0, then L{release}() will
        release the media player object. If the media player object
        has been released, then it should not be used again.
        '''
        return libvlc_media_list_player_release(self)

    def retain(self):
        '''Retain a reference to a media player list object. Use
        L{release}() to decrement reference count.
        '''
        return libvlc_media_list_player_retain(self)

    def event_manager(self):
        '''Return the event manager of this media_list_player.
        @return: the event manager.
        '''
        return libvlc_media_list_player_event_manager(self)

    def set_media_player(self, p_mi):
        '''Replace media player in media_list_player with this instance.
        @param p_mi: media player instance.
        '''
        return libvlc_media_list_player_set_media_player(self, p_mi)

    def set_media_list(self, p_mlist):
        '''Set the media list associated with the player.
        @param p_mlist: list of media.
        '''
        return libvlc_media_list_player_set_media_list(self, p_mlist)

    def play(self):
        '''Play media list.
        '''
        return libvlc_media_list_player_play(self)

    def pause(self):
        '''Toggle pause (or resume) media list.
        '''
        return libvlc_media_list_player_pause(self)

    def is_playing(self):
        '''Is media list playing?
        @return: true for playing and false for not playing \libvlc_return_bool.
        '''
        return libvlc_media_list_player_is_playing(self)

    def get_state(self):
        '''Get current libvlc_state of media list player.
        @return: libvlc_state_t for media list player.
        '''
        return libvlc_media_list_player_get_state(self)

    def play_item_at_index(self, i_index):
        '''Play media list item at position index.
        @param i_index: index in media list to play.
        @return: 0 upon success -1 if the item wasn't found.
        '''
        return libvlc_media_list_player_play_item_at_index(self, i_index)

    def __getitem__(self, i):
        return libvlc_media_list_player_play_item_at_index(self, i)

    def __iter__(self):
        for i in range(len(self)):
            yield self[i]

    def play_item(self, p_md):
        '''Play the given media item.
        @param p_md: the media instance.
        @return: 0 upon success, -1 if the media is not part of the media list.
        '''
        return libvlc_media_list_player_play_item(self, p_md)

    def stop(self):
        '''Stop playing media list.
        '''
        return libvlc_media_list_player_stop(self)

    def next(self):
        '''Play next item from media list.
        @return: 0 upon success -1 if there is no next item.
        '''
        return libvlc_media_list_player_next(self)

    def previous(self):
        '''Play previous item from media list.
        @return: 0 upon success -1 if there is no previous item.
        '''
        return libvlc_media_list_player_previous(self)

    def set_playback_mode(self, e_mode):
        '''Sets the playback mode for the playlist.
        @param e_mode: playback mode specification.
        '''
        return libvlc_media_list_player_set_playback_mode(self, e_mode)

class MediaPlayer(_Ctype):
    '''Create a new MediaPlayer instance.

    It may take as parameter either:
      - a string (media URI), options... In this case, a vlc.Instance will be created.
      - a vlc.Instance, a string (media URI), options...
    
    '''

    def __new__(cls, *args):
        if len(args) == 1 and isinstance(args[0], _Ints):
            return _Constructor(cls, args[0])
        
        if args and isinstance(args[0], Instance):
            instance = args[0]
            args = args[1:]
        else:
            instance = get_default_instance()

        o = instance.media_player_new()
        if args:
            o.set_media(instance.media_new(*args))
        return o

    def get_instance(self):
        """Return the associated Instance.
        """
        return self._instance  #PYCHOK expected

    def set_mrl(self, mrl, *options):
        """Set the MRL to play.

        @param mrl: The MRL
        @param options: optional media option=value strings
        @return: the Media object
        """
        m = self.get_instance().media_new(mrl, *options)
        self.set_media(m)
        return m

    def video_get_spu_description(self):
        """Get the description of available video subtitles.
        """
        return track_description_list(libvlc_video_get_spu_description(self))

    def video_get_title_description(self):
        """Get the description of available titles.
        """
        return track_description_list(libvlc_video_get_title_description(self))

    def video_get_chapter_description(self, title):
        """Get the description of available chapters for specific title.

        @param title: selected title (int)
        """
        return track_description_list(libvlc_video_get_chapter_description(self, title))

    def video_get_track_description(self):
        """Get the description of available video tracks.
        """
        return track_description_list(libvlc_video_get_track_description(self))

    def audio_get_track_description(self):
        """Get the description of available audio tracks.
        """
        return track_description_list(libvlc_audio_get_track_description(self))

    def video_get_size(self, num=0):
        """Get the video size in pixels as 2-tuple (width, height).

        @param num: video number (default 0).
        """
        r = libvlc_video_get_size(self, num)
        if isinstance(r, tuple) and len(r) == 2:
            return r
        else:
            raise VLCException('invalid video number (%s)' % (num,))

    def set_hwnd(self, drawable):
        """Set a Win32/Win64 API window handle (HWND).

        Specify where the media player should render its video
        output. If LibVLC was built without Win32/Win64 API output
        support, then this has no effects.
           
        @param drawable: windows handle of the drawable.
        """
        if not isinstance(drawable, ctypes.c_void_p):
            drawable = ctypes.c_void_p(int(drawable))
        libvlc_media_player_set_hwnd(self, drawable)
            
    def video_get_width(self, num=0):
        """Get the width of a video in pixels.

        @param num: video number (default 0).
        """
        return self.video_get_size(num)[0]

    def video_get_height(self, num=0):
        """Get the height of a video in pixels.

        @param num: video number (default 0).
        """
        return self.video_get_size(num)[1]

    def video_get_cursor(self, num=0):
        """Get the mouse pointer coordinates over a video as 2-tuple (x, y).

        Coordinates are expressed in terms of the decoded video resolution,
        B{not} in terms of pixels on the screen/viewport.  To get the
        latter, you must query your windowing system directly.

        Either coordinate may be negative or larger than the corresponding
        size of the video, if the cursor is outside the rendering area.

        @warning: The coordinates may be out-of-date if the pointer is not
        located on the video rendering area.  LibVLC does not track the
        mouse pointer if the latter is outside the video widget.

        @note: LibVLC does not support multiple mouse pointers (but does
        support multiple input devices sharing the same pointer).

        @param num: video number (default 0).
        """
        r = libvlc_video_get_cursor(self, num)
        if isinstance(r, tuple) and len(r) == 2:
            return r
        raise VLCException('invalid video number (%s)' % (num,))


    def release(self):
        '''Release a media_player after use
        Decrement the reference count of a media player object. If the
        reference count is 0, then L{release}() will
        release the media player object. If the media player object
        has been released, then it should not be used again.
        '''
        return libvlc_media_player_release(self)

    def retain(self):
        '''Retain a reference to a media player object. Use
        L{release}() to decrement reference count.
        '''
        return libvlc_media_player_retain(self)

    def set_media(self, p_md):
        '''Set the media that will be used by the media_player. If any,
        previous md will be released.
        @param p_md: the Media. Afterwards the p_md can be safely destroyed.
        '''
        return libvlc_media_player_set_media(self, p_md)

    def get_media(self):
        '''Get the media used by the media_player.
        @return: the media associated with p_mi, or NULL if no media is associated.
        '''
        return libvlc_media_player_get_media(self)

    def event_manager(self):
        '''Get the Event Manager from which the media player send event.
        @return: the event manager associated with p_mi.
        '''
        return libvlc_media_player_event_manager(self)

    def is_playing(self):
        '''is_playing.
        @return: 1 if the media player is playing, 0 otherwise \libvlc_return_bool.
        '''
        return libvlc_media_player_is_playing(self)

    def play(self):
        '''Play.
        @return: 0 if playback started (and was already started), or -1 on error.
        '''
        return libvlc_media_player_play(self)

    def set_pause(self, do_pause):
        '''Pause or resume (no effect if there is no media).
        @param do_pause: play/resume if zero, pause if non-zero.
        @version: LibVLC 1.1.1 or later.
        '''
        return libvlc_media_player_set_pause(self, do_pause)

    def pause(self):
        '''Toggle pause (no effect if there is no media).
        '''
        return libvlc_media_player_pause(self)

    def stop(self):
        '''Stop (no effect if there is no media).
        '''
        return libvlc_media_player_stop(self)

    def video_set_callbacks(self, lock, unlock, display, opaque):
        '''Set callbacks and private data to render decoded video to a custom area
        in memory.
        Use L{video_set_format}() or L{video_set_format_callbacks}()
        to configure the decoded format.
        @param lock: callback to lock video memory (must not be NULL).
        @param unlock: callback to unlock video memory (or NULL if not needed).
        @param display: callback to display video (or NULL if not needed).
        @param opaque: private pointer for the three callbacks (as first parameter).
        @version: LibVLC 1.1.1 or later.
        '''
        return libvlc_video_set_callbacks(self, lock, unlock, display, opaque)

    def video_set_format(self, chroma, width, height, pitch):
        '''Set decoded video chroma and dimensions.
        This only works in combination with L{video_set_callbacks}(),
        and is mutually exclusive with L{video_set_format_callbacks}().
        @param chroma: a four-characters string identifying the chroma (e.g. "RV32" or "YUYV").
        @param width: pixel width.
        @param height: pixel height.
        @param pitch: line pitch (in bytes).
        @version: LibVLC 1.1.1 or later.
        @bug: All pixel planes are expected to have the same pitch. To use the YCbCr color space with chrominance subsampling, consider using L{video_set_format_callbacks}() instead.
        '''
        return libvlc_video_set_format(self, str_to_bytes(chroma), width, height, pitch)

    def video_set_format_callbacks(self, setup, cleanup):
        '''Set decoded video chroma and dimensions. This only works in combination with
        L{video_set_callbacks}().
        @param setup: callback to select the video format (cannot be NULL).
        @param cleanup: callback to release any allocated resources (or NULL).
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_video_set_format_callbacks(self, setup, cleanup)

    def set_nsobject(self, drawable):
        '''Set the NSView handler where the media player should render its video output.
        Use the vout called "macosx".
        The drawable is an NSObject that follow the VLCOpenGLVideoViewEmbedding
        protocol:
        @begincode
        \@protocol VLCOpenGLVideoViewEmbedding <NSObject>
        - (void)addVoutSubview:(NSView *)view;
        - (void)removeVoutSubview:(NSView *)view;
        \@end
        @endcode
        Or it can be an NSView object.
        If you want to use it along with Qt4 see the QMacCocoaViewContainer. Then
        the following code should work:
        @begincode
        
            NSView *video = [[NSView alloc] init];
            QMacCocoaViewContainer *container = new QMacCocoaViewContainer(video, parent);
            L{set_nsobject}(mp, video);
            [video release];
        
        @endcode
        You can find a live example in VLCVideoView in VLCKit.framework.
        @param drawable: the drawable that is either an NSView or an object following the VLCOpenGLVideoViewEmbedding protocol.
        '''
        return libvlc_media_player_set_nsobject(self, drawable)

    def get_nsobject(self):
        '''Get the NSView handler previously set with L{set_nsobject}().
        @return: the NSView handler or 0 if none where set.
        '''
        return libvlc_media_player_get_nsobject(self)

    def set_agl(self, drawable):
        '''Set the agl handler where the media player should render its video output.
        @param drawable: the agl handler.
        '''
        return libvlc_media_player_set_agl(self, drawable)

    def get_agl(self):
        '''Get the agl handler previously set with L{set_agl}().
        @return: the agl handler or 0 if none where set.
        '''
        return libvlc_media_player_get_agl(self)

    def set_xwindow(self, drawable):
        '''Set an X Window System drawable where the media player should render its
        video output. If LibVLC was built without X11 output support, then this has
        no effects.
        The specified identifier must correspond to an existing Input/Output class
        X11 window. Pixmaps are B{not} supported. The caller shall ensure that
        the X11 server is the same as the one the VLC instance has been configured
        with. This function must be called before video playback is started;
        otherwise it will only take effect after playback stop and restart.
        @param drawable: the ID of the X window.
        '''
        return libvlc_media_player_set_xwindow(self, drawable)

    def get_xwindow(self):
        '''Get the X Window System window identifier previously set with
        L{set_xwindow}(). Note that this will return the identifier
        even if VLC is not currently using it (for instance if it is playing an
        audio-only input).
        @return: an X window ID, or 0 if none where set.
        '''
        return libvlc_media_player_get_xwindow(self)

    def get_hwnd(self):
        '''Get the Windows API window handle (HWND) previously set with
        L{set_hwnd}(). The handle will be returned even if LibVLC
        is not currently outputting any video to it.
        @return: a window handle or NULL if there are none.
        '''
        return libvlc_media_player_get_hwnd(self)

    def audio_set_callbacks(self, play, pause, resume, flush, drain, opaque):
        '''Set callbacks and private data for decoded audio.
        Use L{audio_set_format}() or L{audio_set_format_callbacks}()
        to configure the decoded audio format.
        @param play: callback to play audio samples (must not be NULL).
        @param pause: callback to pause playback (or NULL to ignore).
        @param resume: callback to resume playback (or NULL to ignore).
        @param flush: callback to flush audio buffers (or NULL to ignore).
        @param drain: callback to drain audio buffers (or NULL to ignore).
        @param opaque: private pointer for the audio callbacks (as first parameter).
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_audio_set_callbacks(self, play, pause, resume, flush, drain, opaque)

    def audio_set_volume_callback(self, set_volume):
        '''Set callbacks and private data for decoded audio.
        Use L{audio_set_format}() or L{audio_set_format_callbacks}()
        to configure the decoded audio format.
        @param set_volume: callback to apply audio volume, or NULL to apply volume in software.
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_audio_set_volume_callback(self, set_volume)

    def audio_set_format_callbacks(self, setup, cleanup):
        '''Set decoded audio format. This only works in combination with
        L{audio_set_callbacks}().
        @param setup: callback to select the audio format (cannot be NULL).
        @param cleanup: callback to release any allocated resources (or NULL).
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_audio_set_format_callbacks(self, setup, cleanup)

    def audio_set_format(self, format, rate, channels):
        '''Set decoded audio format.
        This only works in combination with L{audio_set_callbacks}(),
        and is mutually exclusive with L{audio_set_format_callbacks}().
        @param format: a four-characters string identifying the sample format (e.g. "S16N" or "FL32").
        @param rate: sample rate (expressed in Hz).
        @param channels: channels count.
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_audio_set_format(self, str_to_bytes(format), rate, channels)

    def get_length(self):
        '''Get the current movie length (in ms).
        @return: the movie length (in ms), or -1 if there is no media.
        '''
        return libvlc_media_player_get_length(self)

    def get_time(self):
        '''Get the current movie time (in ms).
        @return: the movie time (in ms), or -1 if there is no media.
        '''
        return libvlc_media_player_get_time(self)

    def set_time(self, i_time):
        '''Set the movie time (in ms). This has no effect if no media is being played.
        Not all formats and protocols support this.
        @param i_time: the movie time (in ms).
        '''
        return libvlc_media_player_set_time(self, i_time)

    def get_position(self):
        '''Get movie position as percentage between 0.0 and 1.0.
        @return: movie position, or -1. in case of error.
        '''
        return libvlc_media_player_get_position(self)

    def set_position(self, f_pos):
        '''Set movie position as percentage between 0.0 and 1.0.
        This has no effect if playback is not enabled.
        This might not work depending on the underlying input format and protocol.
        @param f_pos: the position.
        '''
        return libvlc_media_player_set_position(self, f_pos)

    def set_chapter(self, i_chapter):
        '''Set movie chapter (if applicable).
        @param i_chapter: chapter number to play.
        '''
        return libvlc_media_player_set_chapter(self, i_chapter)

    def get_chapter(self):
        '''Get movie chapter.
        @return: chapter number currently playing, or -1 if there is no media.
        '''
        return libvlc_media_player_get_chapter(self)

    def get_chapter_count(self):
        '''Get movie chapter count.
        @return: number of chapters in movie, or -1.
        '''
        return libvlc_media_player_get_chapter_count(self)

    def will_play(self):
        '''Is the player able to play.
        @return: boolean \libvlc_return_bool.
        '''
        return libvlc_media_player_will_play(self)

    def get_chapter_count_for_title(self, i_title):
        '''Get title chapter count.
        @param i_title: title.
        @return: number of chapters in title, or -1.
        '''
        return libvlc_media_player_get_chapter_count_for_title(self, i_title)

    def set_title(self, i_title):
        '''Set movie title.
        @param i_title: title number to play.
        '''
        return libvlc_media_player_set_title(self, i_title)

    def get_title(self):
        '''Get movie title.
        @return: title number currently playing, or -1.
        '''
        return libvlc_media_player_get_title(self)

    def get_title_count(self):
        '''Get movie title count.
        @return: title number count, or -1.
        '''
        return libvlc_media_player_get_title_count(self)

    def previous_chapter(self):
        '''Set previous chapter (if applicable).
        '''
        return libvlc_media_player_previous_chapter(self)

    def next_chapter(self):
        '''Set next chapter (if applicable).
        '''
        return libvlc_media_player_next_chapter(self)

    def get_rate(self):
        '''Get the requested movie play rate.
        @warning: Depending on the underlying media, the requested rate may be
        different from the real playback rate.
        @return: movie play rate.
        '''
        return libvlc_media_player_get_rate(self)

    def set_rate(self, rate):
        '''Set movie play rate.
        @param rate: movie play rate to set.
        @return: -1 if an error was detected, 0 otherwise (but even then, it might not actually work depending on the underlying media protocol).
        '''
        return libvlc_media_player_set_rate(self, rate)

    def get_state(self):
        '''Get current movie state.
        @return: the current state of the media player (playing, paused, ...) See libvlc_state_t.
        '''
        return libvlc_media_player_get_state(self)

    def get_fps(self):
        '''Get movie fps rate.
        @return: frames per second (fps) for this playing movie, or 0 if unspecified.
        '''
        return libvlc_media_player_get_fps(self)

    def has_vout(self):
        '''How many video outputs does this media player have?
        @return: the number of video outputs.
        '''
        return libvlc_media_player_has_vout(self)

    def is_seekable(self):
        '''Is this media player seekable?
        @return: true if the media player can seek \libvlc_return_bool.
        '''
        return libvlc_media_player_is_seekable(self)

    def can_pause(self):
        '''Can this media player be paused?
        @return: true if the media player can pause \libvlc_return_bool.
        '''
        return libvlc_media_player_can_pause(self)

    def next_frame(self):
        '''Display the next frame (if supported).
        '''
        return libvlc_media_player_next_frame(self)

    def navigate(self, navigate):
        '''Navigate through DVD Menu.
        @param navigate: the Navigation mode.
        @version: libVLC 2.0.0 or later.
        '''
        return libvlc_media_player_navigate(self, navigate)

    def toggle_fullscreen(self):
        '''Toggle fullscreen status on non-embedded video outputs.
        @warning: The same limitations applies to this function
        as to L{set_fullscreen}().
        '''
        return libvlc_toggle_fullscreen(self)

    def set_fullscreen(self, b_fullscreen):
        '''Enable or disable fullscreen.
        @warning: With most window managers, only a top-level windows can be in
        full-screen mode. Hence, this function will not operate properly if
        L{set_xwindow}() was used to embed the video in a
        non-top-level window. In that case, the embedding window must be reparented
        to the root window B{before} fullscreen mode is enabled. You will want
        to reparent it back to its normal parent when disabling fullscreen.
        @param b_fullscreen: boolean for fullscreen status.
        '''
        return libvlc_set_fullscreen(self, b_fullscreen)

    def get_fullscreen(self):
        '''Get current fullscreen status.
        @return: the fullscreen status (boolean) \libvlc_return_bool.
        '''
        return libvlc_get_fullscreen(self)

    def video_set_key_input(self, on):
        '''Enable or disable key press events handling, according to the LibVLC hotkeys
        configuration. By default and for historical reasons, keyboard events are
        handled by the LibVLC video widget.
        @note: On X11, there can be only one subscriber for key press and mouse
        click events per window. If your application has subscribed to those events
        for the X window ID of the video widget, then LibVLC will not be able to
        handle key presses and mouse clicks in any case.
        @warning: This function is only implemented for X11 and Win32 at the moment.
        @param on: true to handle key press events, false to ignore them.
        '''
        return libvlc_video_set_key_input(self, on)

    def video_set_mouse_input(self, on):
        '''Enable or disable mouse click events handling. By default, those events are
        handled. This is needed for DVD menus to work, as well as a few video
        filters such as "puzzle".
        See L{video_set_key_input}().
        @warning: This function is only implemented for X11 and Win32 at the moment.
        @param on: true to handle mouse click events, false to ignore them.
        '''
        return libvlc_video_set_mouse_input(self, on)

    def video_get_scale(self):
        '''Get the current video scaling factor.
        See also L{video_set_scale}().
        @return: the currently configured zoom factor, or 0. if the video is set to fit to the output window/drawable automatically.
        '''
        return libvlc_video_get_scale(self)

    def video_set_scale(self, f_factor):
        '''Set the video scaling factor. That is the ratio of the number of pixels on
        screen to the number of pixels in the original decoded video in each
        dimension. Zero is a special value; it will adjust the video to the output
        window/drawable (in windowed mode) or the entire screen.
        Note that not all video outputs support scaling.
        @param f_factor: the scaling factor, or zero.
        '''
        return libvlc_video_set_scale(self, f_factor)

    def video_get_aspect_ratio(self):
        '''Get current video aspect ratio.
        @return: the video aspect ratio or NULL if unspecified (the result must be released with free() or L{free}()).
        '''
        return libvlc_video_get_aspect_ratio(self)

    def video_set_aspect_ratio(self, psz_aspect):
        '''Set new video aspect ratio.
        @param psz_aspect: new video aspect-ratio or NULL to reset to default @note Invalid aspect ratios are ignored.
        '''
        return libvlc_video_set_aspect_ratio(self, str_to_bytes(psz_aspect))

    def video_get_spu(self):
        '''Get current video subtitle.
        @return: the video subtitle selected, or -1 if none.
        '''
        return libvlc_video_get_spu(self)

    def video_get_spu_count(self):
        '''Get the number of available video subtitles.
        @return: the number of available video subtitles.
        '''
        return libvlc_video_get_spu_count(self)

    def video_set_spu(self, i_spu):
        '''Set new video subtitle.
        @param i_spu: video subtitle track to select (i_id from track description).
        @return: 0 on success, -1 if out of range.
        '''
        return libvlc_video_set_spu(self, i_spu)

    def video_set_subtitle_file(self, psz_subtitle):
        '''Set new video subtitle file.
        @param psz_subtitle: new video subtitle file.
        @return: the success status (boolean).
        '''
        return libvlc_video_set_subtitle_file(self, str_to_bytes(psz_subtitle))

    def video_get_spu_delay(self):
        '''Get the current subtitle delay. Positive values means subtitles are being
        displayed later, negative values earlier.
        @return: time (in microseconds) the display of subtitles is being delayed.
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_video_get_spu_delay(self)

    def video_set_spu_delay(self, i_delay):
        '''Set the subtitle delay. This affects the timing of when the subtitle will
        be displayed. Positive values result in subtitles being displayed later,
        while negative values will result in subtitles being displayed earlier.
        The subtitle delay will be reset to zero each time the media changes.
        @param i_delay: time (in microseconds) the display of subtitles should be delayed.
        @return: 0 on success, -1 on error.
        @version: LibVLC 2.0.0 or later.
        '''
        return libvlc_video_set_spu_delay(self, i_delay)

    def video_get_crop_geometry(self):
        '''Get current crop filter geometry.
        @return: the crop filter geometry or NULL if unset.
        '''
        return libvlc_video_get_crop_geometry(self)

    def video_set_crop_geometry(self, psz_geometry):
        '''Set new crop filter geometry.
        @param psz_geometry: new crop filter geometry (NULL to unset).
        '''
        return libvlc_video_set_crop_geometry(self, str_to_bytes(psz_geometry))

    def video_get_teletext(self):
        '''Get current teletext page requested.
        @return: the current teletext page requested.
        '''
        return libvlc_video_get_teletext(self)

    def video_set_teletext(self, i_page):
        '''Set new teletext page to retrieve.
        @param i_page: teletex page number requested.
        '''
        return libvlc_video_set_teletext(self, i_page)

    def toggle_teletext(self):
        '''Toggle teletext transparent status on video output.
        '''
        return libvlc_toggle_teletext(self)

    def video_get_track_count(self):
        '''Get number of available video tracks.
        @return: the number of available video tracks (int).
        '''
        return libvlc_video_get_track_count(self)

    def video_get_track(self):
        '''Get current video track.
        @return: the video track ID (int) or -1 if no active input.
        '''
        return libvlc_video_get_track(self)

    def video_set_track(self, i_track):
        '''Set video track.
        @param i_track: the track ID (i_id field from track description).
        @return: 0 on success, -1 if out of range.
        '''
        return libvlc_video_set_track(self, i_track)

    def video_take_snapshot(self, num, psz_filepath, i_width, i_height):
        '''Take a snapshot of the current video window.
        If i_width AND i_height is 0, original size is used.
        If i_width XOR i_height is 0, original aspect-ratio is preserved.
        @param num: number of video output (typically 0 for the first/only one).
        @param psz_filepath: the path where to save the screenshot to.
        @param i_width: the snapshot's width.
        @param i_height: the snapshot's height.
        @return: 0 on success, -1 if the video was not found.
        '''
        return libvlc_video_take_snapshot(self, num, str_to_bytes(psz_filepath), i_width, i_height)

    def video_set_deinterlace(self, psz_mode):
        '''Enable or disable deinterlace filter.
        @param psz_mode: type of deinterlace filter, NULL to disable.
        '''
        return libvlc_video_set_deinterlace(self, str_to_bytes(psz_mode))

    def video_get_marquee_int(self, option):
        '''Get an integer marquee option value.
        @param option: marq option to get See libvlc_video_marquee_int_option_t.
        '''
        return libvlc_video_get_marquee_int(self, option)

    def video_get_marquee_string(self, option):
        '''Get a string marquee option value.
        @param option: marq option to get See libvlc_video_marquee_string_option_t.
        '''
        return libvlc_video_get_marquee_string(self, option)

    def video_set_marquee_int(self, option, i_val):
        '''Enable, disable or set an integer marquee option
        Setting libvlc_marquee_Enable has the side effect of enabling (arg !0)
        or disabling (arg 0) the marq filter.
        @param option: marq option to set See libvlc_video_marquee_int_option_t.
        @param i_val: marq option value.
        '''
        return libvlc_video_set_marquee_int(self, option, i_val)

    def video_set_marquee_string(self, option, psz_text):
        '''Set a marquee string option.
        @param option: marq option to set See libvlc_video_marquee_string_option_t.
        @param psz_text: marq option value.
        '''
        return libvlc_video_set_marquee_string(self, option, str_to_bytes(psz_text))

    def video_get_logo_int(self, option):
        '''Get integer logo option.
        @param option: logo option to get, values of libvlc_video_logo_option_t.
        '''
        return libvlc_video_get_logo_int(self, option)

    def video_set_logo_int(self, option, value):
        '''Set logo option as integer. Options that take a different type value
        are ignored.
        Passing libvlc_logo_enable as option value has the side effect of
        starting (arg !0) or stopping (arg 0) the logo filter.
        @param option: logo option to set, values of libvlc_video_logo_option_t.
        @param value: logo option value.
        '''
        return libvlc_video_set_logo_int(self, option, value)

    def video_set_logo_string(self, option, psz_value):
        '''Set logo option as string. Options that take a different type value
        are ignored.
        @param option: logo option to set, values of libvlc_video_logo_option_t.
        @param psz_value: logo option value.
        '''
        return libvlc_video_set_logo_string(self, option, str_to_bytes(psz_value))

    def video_get_adjust_int(self, option):
        '''Get integer adjust option.
        @param option: adjust option to get, values of libvlc_video_adjust_option_t.
        @version: LibVLC 1.1.1 and later.
        '''
        return libvlc_video_get_adjust_int(self, option)

    def video_set_adjust_int(self, option, value):
        '''Set adjust option as integer. Options that take a different type value
        are ignored.
        Passing libvlc_adjust_enable as option value has the side effect of
        starting (arg !0) or stopping (arg 0) the adjust filter.
        @param option: adust option to set, values of libvlc_video_adjust_option_t.
        @param value: adjust option value.
        @version: LibVLC 1.1.1 and later.
        '''
        return libvlc_video_set_adjust_int(self, option, value)

    def video_get_adjust_float(self, option):
        '''Get float adjust option.
        @param option: adjust option to get, values of libvlc_video_adjust_option_t.
        @version: LibVLC 1.1.1 and later.
        '''
        return libvlc_video_get_adjust_float(self, option)

    def video_set_adjust_float(self, option, value):
        '''Set adjust option as float. Options that take a different type value
        are ignored.
        @param option: adust option to set, values of libvlc_video_adjust_option_t.
        @param value: adjust option value.
        @version: LibVLC 1.1.1 and later.
        '''
        return libvlc_video_set_adjust_float(self, option, value)

    def audio_output_set(self, psz_name):
        '''Sets the audio output.
        @note: Any change will take be effect only after playback is stopped and
        restarted. Audio output cannot be changed while playing.
        @param psz_name: name of audio output, use psz_name of See L{AudioOutput}.
        @return: 0 if function succeded, -1 on error.
        '''
        return libvlc_audio_output_set(self, str_to_bytes(psz_name))

    def audio_output_device_set(self, psz_audio_output, psz_device_id):
        '''Configures an explicit audio output device for a given audio output plugin.
        A list of possible devices can be obtained with
        L{audio_output_device_list_get}().
        @note: This function does not select the specified audio output plugin.
        L{audio_output_set}() is used for that purpose.
        @warning: The syntax for the device parameter depends on the audio output.
        This is not portable. Only use this function if you know what you are doing.
        Some audio outputs do not support this function (e.g. PulseAudio, WASAPI).
        Some audio outputs require further parameters (e.g. ALSA: channels map).
        @param psz_audio_output: - name of audio output, See L{AudioOutput}.
        @param psz_device_id: device.
        @return: Nothing. Errors are ignored.
        '''
        return libvlc_audio_output_device_set(self, str_to_bytes(psz_audio_output), str_to_bytes(psz_device_id))

    def audio_toggle_mute(self):
        '''Toggle mute status.
        '''
        return libvlc_audio_toggle_mute(self)

    def audio_get_mute(self):
        '''Get current mute status.
        @return: the mute status (boolean) if defined, -1 if undefined/unapplicable.
        '''
        return libvlc_audio_get_mute(self)

    def audio_set_mute(self, status):
        '''Set mute status.
        @param status: If status is true then mute, otherwise unmute @warning This function does not always work. If there are no active audio playback stream, the mute status might not be available. If digital pass-through (S/PDIF, HDMI...) is in use, muting may be unapplicable. Also some audio output plugins do not support muting at all. @note To force silent playback, disable all audio tracks. This is more efficient and reliable than mute.
        '''
        return libvlc_audio_set_mute(self, status)

    def audio_get_volume(self):
        '''Get current software audio volume.
        @return: the software volume in percents (0 = mute, 100 = nominal / 0dB).
        '''
        return libvlc_audio_get_volume(self)

    def audio_set_volume(self, i_volume):
        '''Set current software audio volume.
        @param i_volume: the volume in percents (0 = mute, 100 = 0dB).
        @return: 0 if the volume was set, -1 if it was out of range.
        '''
        return libvlc_audio_set_volume(self, i_volume)

    def audio_get_track_count(self):
        '''Get number of available audio tracks.
        @return: the number of available audio tracks (int), or -1 if unavailable.
        '''
        return libvlc_audio_get_track_count(self)

    def audio_get_track(self):
        '''Get current audio track.
        @return: the audio track ID or -1 if no active input.
        '''
        return libvlc_audio_get_track(self)

    def audio_set_track(self, i_track):
        '''Set current audio track.
        @param i_track: the track ID (i_id field from track description).
        @return: 0 on success, -1 on error.
        '''
        return libvlc_audio_set_track(self, i_track)

    def audio_get_channel(self):
        '''Get current audio channel.
        @return: the audio channel See libvlc_audio_output_channel_t.
        '''
        return libvlc_audio_get_channel(self)

    def audio_set_channel(self, channel):
        '''Set current audio channel.
        @param channel: the audio channel, See libvlc_audio_output_channel_t.
        @return: 0 on success, -1 on error.
        '''
        return libvlc_audio_set_channel(self, channel)

    def audio_get_delay(self):
        '''Get current audio delay.
        @return: the audio delay (microseconds).
        @version: LibVLC 1.1.1 or later.
        '''
        return libvlc_audio_get_delay(self)

    def audio_set_delay(self, i_delay):
        '''Set current audio delay. The audio delay will be reset to zero each time the media changes.
        @param i_delay: the audio delay (microseconds).
        @return: 0 on success, -1 on error.
        @version: LibVLC 1.1.1 or later.
        '''
        return libvlc_audio_set_delay(self, i_delay)


 # LibVLC __version__ functions #

def libvlc_errmsg():
    '''A human-readable error message for the last LibVLC error in the calling
    thread. The resulting string is valid until another error occurs (at least
    until the next LibVLC call).
    @warning
    This will be NULL if there was no error.
    '''
    f = _Cfunctions.get('libvlc_errmsg', None) or \
        _Cfunction('libvlc_errmsg', (), None,
                    ctypes.c_char_p)
    return f()

def libvlc_clearerr():
    '''Clears the LibVLC error status for the current thread. This is optional.
    By default, the error status is automatically overridden when a new error
    occurs, and destroyed when the thread exits.
    '''
    f = _Cfunctions.get('libvlc_clearerr', None) or \
        _Cfunction('libvlc_clearerr', (), None,
                    None)
    return f()

def libvlc_vprinterr(fmt, ap):
    '''Sets the LibVLC error status and message for the current thread.
    Any previous error is overridden.
    @param fmt: the format string.
    @param ap: the arguments.
    @return: a nul terminated string in any case.
    '''
    f = _Cfunctions.get('libvlc_vprinterr', None) or \
        _Cfunction('libvlc_vprinterr', ((1,), (1,),), None,
                    ctypes.c_char_p, ctypes.c_char_p, ctypes.c_void_p)
    return f(fmt, ap)

def libvlc_new(argc, argv):
    '''Create and initialize a libvlc instance.
    This functions accept a list of "command line" arguments similar to the
    main(). These arguments affect the LibVLC instance default configuration.
    @param argc: the number of arguments (should be 0).
    @param argv: list of arguments (should be NULL).
    @return: the libvlc instance or NULL in case of error.
    @version Arguments are meant to be passed from the command line to LibVLC, just like VLC media player does. The list of valid arguments depends on the LibVLC version, the operating system and platform, and set of available LibVLC plugins. Invalid or unsupported arguments will cause the function to fail (i.e. return NULL). Also, some arguments may alter the behaviour or otherwise interfere with other LibVLC functions. @warning There is absolutely no warranty or promise of forward, backward and cross-platform compatibility with regards to L{libvlc_new}() arguments. We recommend that you do not use them, other than when debugging.
    '''
    f = _Cfunctions.get('libvlc_new', None) or \
        _Cfunction('libvlc_new', ((1,), (1,),), class_result(Instance),
                    ctypes.c_void_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p))
    return f(argc, argv)

def libvlc_release(p_instance):
    '''Decrement the reference count of a libvlc instance, and destroy it
    if it reaches zero.
    @param p_instance: the instance to destroy.
    '''
    f = _Cfunctions.get('libvlc_release', None) or \
        _Cfunction('libvlc_release', ((1,),), None,
                    None, Instance)
    return f(p_instance)

def libvlc_retain(p_instance):
    '''Increments the reference count of a libvlc instance.
    The initial reference count is 1 after L{libvlc_new}() returns.
    @param p_instance: the instance to reference.
    '''
    f = _Cfunctions.get('libvlc_retain', None) or \
        _Cfunction('libvlc_retain', ((1,),), None,
                    None, Instance)
    return f(p_instance)

def libvlc_add_intf(p_instance, name):
    '''Try to start a user interface for the libvlc instance.
    @param p_instance: the instance.
    @param name: interface name, or NULL for default.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_add_intf', None) or \
        _Cfunction('libvlc_add_intf', ((1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p)
    return f(p_instance, name)

def libvlc_set_user_agent(p_instance, name, http):
    '''Sets the application name. LibVLC passes this as the user agent string
    when a protocol requires it.
    @param p_instance: LibVLC instance.
    @param name: human-readable application name, e.g. "FooBar player 1.2.3".
    @param http: HTTP User Agent, e.g. "FooBar/1.2.3 Python/2.6.0".
    @version: LibVLC 1.1.1 or later.
    '''
    f = _Cfunctions.get('libvlc_set_user_agent', None) or \
        _Cfunction('libvlc_set_user_agent', ((1,), (1,), (1,),), None,
                    None, Instance, ctypes.c_char_p, ctypes.c_char_p)
    return f(p_instance, name, http)

def libvlc_get_version():
    '''Retrieve libvlc version.
    Example: "1.1.0-git The Luggage".
    @return: a string containing the libvlc version.
    '''
    f = _Cfunctions.get('libvlc_get_version', None) or \
        _Cfunction('libvlc_get_version', (), None,
                    ctypes.c_char_p)
    return f()

def libvlc_get_compiler():
    '''Retrieve libvlc compiler version.
    Example: "gcc version 4.2.3 (Ubuntu 4.2.3-2ubuntu6)".
    @return: a string containing the libvlc compiler version.
    '''
    f = _Cfunctions.get('libvlc_get_compiler', None) or \
        _Cfunction('libvlc_get_compiler', (), None,
                    ctypes.c_char_p)
    return f()

def libvlc_get_changeset():
    '''Retrieve libvlc changeset.
    Example: "aa9bce0bc4".
    @return: a string containing the libvlc changeset.
    '''
    f = _Cfunctions.get('libvlc_get_changeset', None) or \
        _Cfunction('libvlc_get_changeset', (), None,
                    ctypes.c_char_p)
    return f()

def libvlc_free(ptr):
    '''Frees an heap allocation returned by a LibVLC function.
    If you know you're using the same underlying C run-time as the LibVLC
    implementation, then you can call ANSI C free() directly instead.
    @param ptr: the pointer.
    '''
    f = _Cfunctions.get('libvlc_free', None) or \
        _Cfunction('libvlc_free', ((1,),), None,
                    None, ctypes.c_void_p)
    return f(ptr)

def libvlc_event_attach(p_event_manager, i_event_type, f_callback, user_data):
    '''Register for an event notification.
    @param p_event_manager: the event manager to which you want to attach to. Generally it is obtained by vlc_my_object_event_manager() where my_object is the object you want to listen to.
    @param i_event_type: the desired event to which we want to listen.
    @param f_callback: the function to call when i_event_type occurs.
    @param user_data: user provided data to carry with the event.
    @return: 0 on success, ENOMEM on error.
    '''
    f = _Cfunctions.get('libvlc_event_attach', None) or \
        _Cfunction('libvlc_event_attach', ((1,), (1,), (1,), (1,),), None,
                    ctypes.c_int, EventManager, ctypes.c_uint, Callback, ctypes.c_void_p)
    return f(p_event_manager, i_event_type, f_callback, user_data)

def libvlc_event_detach(p_event_manager, i_event_type, f_callback, p_user_data):
    '''Unregister an event notification.
    @param p_event_manager: the event manager.
    @param i_event_type: the desired event to which we want to unregister.
    @param f_callback: the function to call when i_event_type occurs.
    @param p_user_data: user provided data to carry with the event.
    '''
    f = _Cfunctions.get('libvlc_event_detach', None) or \
        _Cfunction('libvlc_event_detach', ((1,), (1,), (1,), (1,),), None,
                    None, EventManager, ctypes.c_uint, Callback, ctypes.c_void_p)
    return f(p_event_manager, i_event_type, f_callback, p_user_data)

def libvlc_event_type_name(event_type):
    '''Get an event's type name.
    @param event_type: the desired event.
    '''
    f = _Cfunctions.get('libvlc_event_type_name', None) or \
        _Cfunction('libvlc_event_type_name', ((1,),), None,
                    ctypes.c_char_p, ctypes.c_uint)
    return f(event_type)

def libvlc_log_get_context(ctx):
    '''Gets debugging informations about a log message: the name of the VLC module
    emitting the message and the message location within the source code.
    The returned module name and file name will be NULL if unknown.
    The returned line number will similarly be zero if unknown.
    @param ctx: message context (as passed to the @ref libvlc_log_cb callback).
    @return: module module name storage (or NULL), file source code file name storage (or NULL), line source code file line number storage (or NULL).
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_log_get_context', None) or \
        _Cfunction('libvlc_log_get_context', ((1,), (2,), (2,), (2,),), None,
                    None, Log_ptr, ListPOINTER(ctypes.c_char_p), ListPOINTER(ctypes.c_char_p), ctypes.POINTER(ctypes.c_uint))
    return f(ctx)

def libvlc_log_get_object(ctx, id):
    '''Gets VLC object informations about a log message: the type name of the VLC
    object emitting the message, the object header if any and a temporaly-unique
    object identifier. These informations are mainly meant for B{manual}
    troubleshooting.
    The returned type name may be "generic" if unknown, but it cannot be NULL.
    The returned header will be NULL if unset; in current versions, the header
    is used to distinguish for VLM inputs.
    The returned object ID will be zero if the message is not associated with
    any VLC object.
    @param ctx: message context (as passed to the @ref libvlc_log_cb callback).
    @return: name object name storage (or NULL), header object header (or NULL), line source code file line number storage (or NULL).
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_log_get_object', None) or \
        _Cfunction('libvlc_log_get_object', ((1,), (2,), (2,), (1,),), None,
                    None, Log_ptr, ListPOINTER(ctypes.c_char_p), ListPOINTER(ctypes.c_char_p), ctypes.POINTER(ctypes.c_uint))
    return f(ctx, id)

def libvlc_log_unset(p_instance):
    '''Unsets the logging callback for a LibVLC instance. This is rarely needed:
    the callback is implicitly unset when the instance is destroyed.
    This function will wait for any pending callbacks invocation to complete
    (causing a deadlock if called from within the callback).
    @param p_instance: libvlc instance.
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_log_unset', None) or \
        _Cfunction('libvlc_log_unset', ((1,),), None,
                    None, Instance)
    return f(p_instance)

def libvlc_log_set(cb, data, p_instance):
    '''Sets the logging callback for a LibVLC instance.
    This function is thread-safe: it will wait for any pending callbacks
    invocation to complete.
    @param cb: callback function pointer.
    @param data: opaque data pointer for the callback function @note Some log messages (especially debug) are emitted by LibVLC while is being initialized. These messages cannot be captured with this interface. @warning A deadlock may occur if this function is called from the callback.
    @param p_instance: libvlc instance.
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_log_set', None) or \
        _Cfunction('libvlc_log_set', ((1,), (1,), (1,),), None,
                    None, Instance, LogCb, ctypes.c_void_p)
    return f(cb, data, p_instance)

def libvlc_log_set_file(p_instance, stream):
    '''Sets up logging to a file.
    @param p_instance: libvlc instance.
    @param stream: FILE pointer opened for writing (the FILE pointer must remain valid until L{libvlc_log_unset}()).
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_log_set_file', None) or \
        _Cfunction('libvlc_log_set_file', ((1,), (1,),), None,
                    None, Instance, FILE_ptr)
    return f(p_instance, stream)

def libvlc_module_description_list_release(p_list):
    '''Release a list of module descriptions.
    @param p_list: the list to be released.
    '''
    f = _Cfunctions.get('libvlc_module_description_list_release', None) or \
        _Cfunction('libvlc_module_description_list_release', ((1,),), None,
                    None, ctypes.POINTER(ModuleDescription))
    return f(p_list)

def libvlc_audio_filter_list_get(p_instance):
    '''Returns a list of audio filters that are available.
    @param p_instance: libvlc instance.
    @return: a list of module descriptions. It should be freed with L{libvlc_module_description_list_release}(). In case of an error, NULL is returned. See L{ModuleDescription} See L{libvlc_module_description_list_release}.
    '''
    f = _Cfunctions.get('libvlc_audio_filter_list_get', None) or \
        _Cfunction('libvlc_audio_filter_list_get', ((1,),), None,
                    ctypes.POINTER(ModuleDescription), Instance)
    return f(p_instance)

def libvlc_video_filter_list_get(p_instance):
    '''Returns a list of video filters that are available.
    @param p_instance: libvlc instance.
    @return: a list of module descriptions. It should be freed with L{libvlc_module_description_list_release}(). In case of an error, NULL is returned. See L{ModuleDescription} See L{libvlc_module_description_list_release}.
    '''
    f = _Cfunctions.get('libvlc_video_filter_list_get', None) or \
        _Cfunction('libvlc_video_filter_list_get', ((1,),), None,
                    ctypes.POINTER(ModuleDescription), Instance)
    return f(p_instance)

def libvlc_clock():
    '''Return the current time as defined by LibVLC. The unit is the microsecond.
    Time increases monotonically (regardless of time zone changes and RTC
    adjustements).
    The origin is arbitrary but consistent across the whole system
    (e.g. the system uptim, the time since the system was booted).
    @note: On systems that support it, the POSIX monotonic clock is used.
    '''
    f = _Cfunctions.get('libvlc_clock', None) or \
        _Cfunction('libvlc_clock', (), None,
                    ctypes.c_int64)
    return f()

def libvlc_media_new_location(p_instance, psz_mrl):
    '''Create a media with a certain given media resource location,
    for instance a valid URL.
    @note: To refer to a local file with this function,
    the file://... URI syntax B{must} be used (see IETF RFC3986).
    We recommend using L{libvlc_media_new_path}() instead when dealing with
    local files.
    See L{libvlc_media_release}.
    @param p_instance: the instance.
    @param psz_mrl: the media location.
    @return: the newly created media or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_new_location', None) or \
        _Cfunction('libvlc_media_new_location', ((1,), (1,),), class_result(Media),
                    ctypes.c_void_p, Instance, ctypes.c_char_p)
    return f(p_instance, psz_mrl)

def libvlc_media_new_path(p_instance, path):
    '''Create a media for a certain file path.
    See L{libvlc_media_release}.
    @param p_instance: the instance.
    @param path: local filesystem path.
    @return: the newly created media or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_new_path', None) or \
        _Cfunction('libvlc_media_new_path', ((1,), (1,),), class_result(Media),
                    ctypes.c_void_p, Instance, ctypes.c_char_p)
    return f(p_instance, path)

def libvlc_media_new_fd(p_instance, fd):
    '''Create a media for an already open file descriptor.
    The file descriptor shall be open for reading (or reading and writing).
    Regular file descriptors, pipe read descriptors and character device
    descriptors (including TTYs) are supported on all platforms.
    Block device descriptors are supported where available.
    Directory descriptors are supported on systems that provide fdopendir().
    Sockets are supported on all platforms where they are file descriptors,
    i.e. all except Windows.
    @note: This library will B{not} automatically close the file descriptor
    under any circumstance. Nevertheless, a file descriptor can usually only be
    rendered once in a media player. To render it a second time, the file
    descriptor should probably be rewound to the beginning with lseek().
    See L{libvlc_media_release}.
    @param p_instance: the instance.
    @param fd: open file descriptor.
    @return: the newly created media or NULL on error.
    @version: LibVLC 1.1.5 and later.
    '''
    f = _Cfunctions.get('libvlc_media_new_fd', None) or \
        _Cfunction('libvlc_media_new_fd', ((1,), (1,),), class_result(Media),
                    ctypes.c_void_p, Instance, ctypes.c_int)
    return f(p_instance, fd)

def libvlc_media_new_as_node(p_instance, psz_name):
    '''Create a media as an empty node with a given name.
    See L{libvlc_media_release}.
    @param p_instance: the instance.
    @param psz_name: the name of the node.
    @return: the new empty media or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_new_as_node', None) or \
        _Cfunction('libvlc_media_new_as_node', ((1,), (1,),), class_result(Media),
                    ctypes.c_void_p, Instance, ctypes.c_char_p)
    return f(p_instance, psz_name)

def libvlc_media_add_option(p_md, psz_options):
    '''Add an option to the media.
    This option will be used to determine how the media_player will
    read the media. This allows to use VLC's advanced
    reading/streaming options on a per-media basis.
    @note: The options are listed in 'vlc --long-help' from the command line,
    e.g. "-sout-all". Keep in mind that available options and their semantics
    vary across LibVLC versions and builds.
    @warning: Not all options affects L{Media} objects:
    Specifically, due to architectural issues most audio and video options,
    such as text renderer options, have no effects on an individual media.
    These options must be set through L{libvlc_new}() instead.
    @param p_md: the media descriptor.
    @param psz_options: the options (as a string).
    '''
    f = _Cfunctions.get('libvlc_media_add_option', None) or \
        _Cfunction('libvlc_media_add_option', ((1,), (1,),), None,
                    None, Media, ctypes.c_char_p)
    return f(p_md, psz_options)

def libvlc_media_add_option_flag(p_md, psz_options, i_flags):
    '''Add an option to the media with configurable flags.
    This option will be used to determine how the media_player will
    read the media. This allows to use VLC's advanced
    reading/streaming options on a per-media basis.
    The options are detailed in vlc --long-help, for instance
    "--sout-all". Note that all options are not usable on medias:
    specifically, due to architectural issues, video-related options
    such as text renderer options cannot be set on a single media. They
    must be set on the whole libvlc instance instead.
    @param p_md: the media descriptor.
    @param psz_options: the options (as a string).
    @param i_flags: the flags for this option.
    '''
    f = _Cfunctions.get('libvlc_media_add_option_flag', None) or \
        _Cfunction('libvlc_media_add_option_flag', ((1,), (1,), (1,),), None,
                    None, Media, ctypes.c_char_p, ctypes.c_uint)
    return f(p_md, psz_options, i_flags)

def libvlc_media_retain(p_md):
    '''Retain a reference to a media descriptor object (libvlc_media_t). Use
    L{libvlc_media_release}() to decrement the reference count of a
    media descriptor object.
    @param p_md: the media descriptor.
    '''
    f = _Cfunctions.get('libvlc_media_retain', None) or \
        _Cfunction('libvlc_media_retain', ((1,),), None,
                    None, Media)
    return f(p_md)

def libvlc_media_release(p_md):
    '''Decrement the reference count of a media descriptor object. If the
    reference count is 0, then L{libvlc_media_release}() will release the
    media descriptor object. It will send out an libvlc_MediaFreed event
    to all listeners. If the media descriptor object has been released it
    should not be used again.
    @param p_md: the media descriptor.
    '''
    f = _Cfunctions.get('libvlc_media_release', None) or \
        _Cfunction('libvlc_media_release', ((1,),), None,
                    None, Media)
    return f(p_md)

def libvlc_media_get_mrl(p_md):
    '''Get the media resource locator (mrl) from a media descriptor object.
    @param p_md: a media descriptor object.
    @return: string with mrl of media descriptor object.
    '''
    f = _Cfunctions.get('libvlc_media_get_mrl', None) or \
        _Cfunction('libvlc_media_get_mrl', ((1,),), string_result,
                    ctypes.c_void_p, Media)
    return f(p_md)

def libvlc_media_duplicate(p_md):
    '''Duplicate a media descriptor object.
    @param p_md: a media descriptor object.
    '''
    f = _Cfunctions.get('libvlc_media_duplicate', None) or \
        _Cfunction('libvlc_media_duplicate', ((1,),), class_result(Media),
                    ctypes.c_void_p, Media)
    return f(p_md)

def libvlc_media_get_meta(p_md, e_meta):
    '''Read the meta of the media.
    If the media has not yet been parsed this will return NULL.
    This methods automatically calls L{libvlc_media_parse_async}(), so after calling
    it you may receive a libvlc_MediaMetaChanged event. If you prefer a synchronous
    version ensure that you call L{libvlc_media_parse}() before get_meta().
    See L{libvlc_media_parse}
    See L{libvlc_media_parse_async}
    See libvlc_MediaMetaChanged.
    @param p_md: the media descriptor.
    @param e_meta: the meta to read.
    @return: the media's meta.
    '''
    f = _Cfunctions.get('libvlc_media_get_meta', None) or \
        _Cfunction('libvlc_media_get_meta', ((1,), (1,),), string_result,
                    ctypes.c_void_p, Media, Meta)
    return f(p_md, e_meta)

def libvlc_media_set_meta(p_md, e_meta, psz_value):
    '''Set the meta of the media (this function will not save the meta, call
    L{libvlc_media_save_meta} in order to save the meta).
    @param p_md: the media descriptor.
    @param e_meta: the meta to write.
    @param psz_value: the media's meta.
    '''
    f = _Cfunctions.get('libvlc_media_set_meta', None) or \
        _Cfunction('libvlc_media_set_meta', ((1,), (1,), (1,),), None,
                    None, Media, Meta, ctypes.c_char_p)
    return f(p_md, e_meta, psz_value)

def libvlc_media_save_meta(p_md):
    '''Save the meta previously set.
    @param p_md: the media desriptor.
    @return: true if the write operation was successful.
    '''
    f = _Cfunctions.get('libvlc_media_save_meta', None) or \
        _Cfunction('libvlc_media_save_meta', ((1,),), None,
                    ctypes.c_int, Media)
    return f(p_md)

def libvlc_media_get_state(p_md):
    '''Get current state of media descriptor object. Possible media states
    are defined in libvlc_structures.c ( libvlc_NothingSpecial=0,
    libvlc_Opening, libvlc_Buffering, libvlc_Playing, libvlc_Paused,
    libvlc_Stopped, libvlc_Ended,
    libvlc_Error).
    See libvlc_state_t.
    @param p_md: a media descriptor object.
    @return: state of media descriptor object.
    '''
    f = _Cfunctions.get('libvlc_media_get_state', None) or \
        _Cfunction('libvlc_media_get_state', ((1,),), None,
                    State, Media)
    return f(p_md)

def libvlc_media_get_stats(p_md, p_stats):
    '''Get the current statistics about the media.
    @param p_md:: media descriptor object.
    @param p_stats:: structure that contain the statistics about the media (this structure must be allocated by the caller).
    @return: true if the statistics are available, false otherwise \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_get_stats', None) or \
        _Cfunction('libvlc_media_get_stats', ((1,), (1,),), None,
                    ctypes.c_int, Media, ctypes.POINTER(MediaStats))
    return f(p_md, p_stats)

def libvlc_media_subitems(p_md):
    '''Get subitems of media descriptor object. This will increment
    the reference count of supplied media descriptor object. Use
    L{libvlc_media_list_release}() to decrement the reference counting.
    @param p_md: media descriptor object.
    @return: list of media descriptor subitems or NULL.
    '''
    f = _Cfunctions.get('libvlc_media_subitems', None) or \
        _Cfunction('libvlc_media_subitems', ((1,),), class_result(MediaList),
                    ctypes.c_void_p, Media)
    return f(p_md)

def libvlc_media_event_manager(p_md):
    '''Get event manager from media descriptor object.
    NOTE: this function doesn't increment reference counting.
    @param p_md: a media descriptor object.
    @return: event manager object.
    '''
    f = _Cfunctions.get('libvlc_media_event_manager', None) or \
        _Cfunction('libvlc_media_event_manager', ((1,),), class_result(EventManager),
                    ctypes.c_void_p, Media)
    return f(p_md)

def libvlc_media_get_duration(p_md):
    '''Get duration (in ms) of media descriptor object item.
    @param p_md: media descriptor object.
    @return: duration of media item or -1 on error.
    '''
    f = _Cfunctions.get('libvlc_media_get_duration', None) or \
        _Cfunction('libvlc_media_get_duration', ((1,),), None,
                    ctypes.c_longlong, Media)
    return f(p_md)

def libvlc_media_parse(p_md):
    '''Parse a media.
    This fetches (local) meta data and tracks information.
    The method is synchronous.
    See L{libvlc_media_parse_async}
    See L{libvlc_media_get_meta}
    See libvlc_media_get_tracks_info.
    @param p_md: media descriptor object.
    '''
    f = _Cfunctions.get('libvlc_media_parse', None) or \
        _Cfunction('libvlc_media_parse', ((1,),), None,
                    None, Media)
    return f(p_md)

def libvlc_media_parse_async(p_md):
    '''Parse a media.
    This fetches (local) meta data and tracks information.
    The method is the asynchronous of L{libvlc_media_parse}().
    To track when this is over you can listen to libvlc_MediaParsedChanged
    event. However if the media was already parsed you will not receive this
    event.
    See L{libvlc_media_parse}
    See libvlc_MediaParsedChanged
    See L{libvlc_media_get_meta}
    See libvlc_media_get_tracks_info.
    @param p_md: media descriptor object.
    '''
    f = _Cfunctions.get('libvlc_media_parse_async', None) or \
        _Cfunction('libvlc_media_parse_async', ((1,),), None,
                    None, Media)
    return f(p_md)

def libvlc_media_is_parsed(p_md):
    '''Get Parsed status for media descriptor object.
    See libvlc_MediaParsedChanged.
    @param p_md: media descriptor object.
    @return: true if media object has been parsed otherwise it returns false \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_is_parsed', None) or \
        _Cfunction('libvlc_media_is_parsed', ((1,),), None,
                    ctypes.c_int, Media)
    return f(p_md)

def libvlc_media_set_user_data(p_md, p_new_user_data):
    '''Sets media descriptor's user_data. user_data is specialized data
    accessed by the host application, VLC.framework uses it as a pointer to
    an native object that references a L{Media} pointer.
    @param p_md: media descriptor object.
    @param p_new_user_data: pointer to user data.
    '''
    f = _Cfunctions.get('libvlc_media_set_user_data', None) or \
        _Cfunction('libvlc_media_set_user_data', ((1,), (1,),), None,
                    None, Media, ctypes.c_void_p)
    return f(p_md, p_new_user_data)

def libvlc_media_get_user_data(p_md):
    '''Get media descriptor's user_data. user_data is specialized data
    accessed by the host application, VLC.framework uses it as a pointer to
    an native object that references a L{Media} pointer.
    @param p_md: media descriptor object.
    '''
    f = _Cfunctions.get('libvlc_media_get_user_data', None) or \
        _Cfunction('libvlc_media_get_user_data', ((1,),), None,
                    ctypes.c_void_p, Media)
    return f(p_md)

def libvlc_media_tracks_get(p_md, tracks):
    '''Get media descriptor's elementary streams description
    Note, you need to call L{libvlc_media_parse}() or play the media at least once
    before calling this function.
    Not doing this will result in an empty array.
    @param p_md: media descriptor object.
    @param tracks: address to store an allocated array of Elementary Streams descriptions (must be freed with L{libvlc_media_tracks_release}.
    @return: the number of Elementary Streams (zero on error).
    @version: LibVLC 2.1.0 and later.
    '''
    f = _Cfunctions.get('libvlc_media_tracks_get', None) or \
        _Cfunction('libvlc_media_tracks_get', ((1,), (1,),), None,
                    ctypes.c_uint, Media, ctypes.POINTER(ctypes.POINTER(MediaTrack)))
    return f(p_md, tracks)

def libvlc_media_tracks_release(p_tracks, i_count):
    '''Release media descriptor's elementary streams description array.
    @param p_tracks: tracks info array to release.
    @param i_count: number of elements in the array.
    @version: LibVLC 2.1.0 and later.
    '''
    f = _Cfunctions.get('libvlc_media_tracks_release', None) or \
        _Cfunction('libvlc_media_tracks_release', ((1,), (1,),), None,
                    None, ctypes.POINTER(MediaTrack), ctypes.c_uint)
    return f(p_tracks, i_count)

def libvlc_media_discoverer_new_from_name(p_inst, psz_name):
    '''Discover media service by name.
    @param p_inst: libvlc instance.
    @param psz_name: service name.
    @return: media discover object or NULL in case of error.
    '''
    f = _Cfunctions.get('libvlc_media_discoverer_new_from_name', None) or \
        _Cfunction('libvlc_media_discoverer_new_from_name', ((1,), (1,),), class_result(MediaDiscoverer),
                    ctypes.c_void_p, Instance, ctypes.c_char_p)
    return f(p_inst, psz_name)

def libvlc_media_discoverer_release(p_mdis):
    '''Release media discover object. If the reference count reaches 0, then
    the object will be released.
    @param p_mdis: media service discover object.
    '''
    f = _Cfunctions.get('libvlc_media_discoverer_release', None) or \
        _Cfunction('libvlc_media_discoverer_release', ((1,),), None,
                    None, MediaDiscoverer)
    return f(p_mdis)

def libvlc_media_discoverer_localized_name(p_mdis):
    '''Get media service discover object its localized name.
    @param p_mdis: media discover object.
    @return: localized name.
    '''
    f = _Cfunctions.get('libvlc_media_discoverer_localized_name', None) or \
        _Cfunction('libvlc_media_discoverer_localized_name', ((1,),), string_result,
                    ctypes.c_void_p, MediaDiscoverer)
    return f(p_mdis)

def libvlc_media_discoverer_media_list(p_mdis):
    '''Get media service discover media list.
    @param p_mdis: media service discover object.
    @return: list of media items.
    '''
    f = _Cfunctions.get('libvlc_media_discoverer_media_list', None) or \
        _Cfunction('libvlc_media_discoverer_media_list', ((1,),), class_result(MediaList),
                    ctypes.c_void_p, MediaDiscoverer)
    return f(p_mdis)

def libvlc_media_discoverer_event_manager(p_mdis):
    '''Get event manager from media service discover object.
    @param p_mdis: media service discover object.
    @return: event manager object.
    '''
    f = _Cfunctions.get('libvlc_media_discoverer_event_manager', None) or \
        _Cfunction('libvlc_media_discoverer_event_manager', ((1,),), class_result(EventManager),
                    ctypes.c_void_p, MediaDiscoverer)
    return f(p_mdis)

def libvlc_media_discoverer_is_running(p_mdis):
    '''Query if media service discover object is running.
    @param p_mdis: media service discover object.
    @return: true if running, false if not \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_discoverer_is_running', None) or \
        _Cfunction('libvlc_media_discoverer_is_running', ((1,),), None,
                    ctypes.c_int, MediaDiscoverer)
    return f(p_mdis)

def libvlc_media_library_new(p_instance):
    '''Create an new Media Library object.
    @param p_instance: the libvlc instance.
    @return: a new object or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_library_new', None) or \
        _Cfunction('libvlc_media_library_new', ((1,),), class_result(MediaLibrary),
                    ctypes.c_void_p, Instance)
    return f(p_instance)

def libvlc_media_library_release(p_mlib):
    '''Release media library object. This functions decrements the
    reference count of the media library object. If it reaches 0,
    then the object will be released.
    @param p_mlib: media library object.
    '''
    f = _Cfunctions.get('libvlc_media_library_release', None) or \
        _Cfunction('libvlc_media_library_release', ((1,),), None,
                    None, MediaLibrary)
    return f(p_mlib)

def libvlc_media_library_retain(p_mlib):
    '''Retain a reference to a media library object. This function will
    increment the reference counting for this object. Use
    L{libvlc_media_library_release}() to decrement the reference count.
    @param p_mlib: media library object.
    '''
    f = _Cfunctions.get('libvlc_media_library_retain', None) or \
        _Cfunction('libvlc_media_library_retain', ((1,),), None,
                    None, MediaLibrary)
    return f(p_mlib)

def libvlc_media_library_load(p_mlib):
    '''Load media library.
    @param p_mlib: media library object.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_media_library_load', None) or \
        _Cfunction('libvlc_media_library_load', ((1,),), None,
                    ctypes.c_int, MediaLibrary)
    return f(p_mlib)

def libvlc_media_library_media_list(p_mlib):
    '''Get media library subitems.
    @param p_mlib: media library object.
    @return: media list subitems.
    '''
    f = _Cfunctions.get('libvlc_media_library_media_list', None) or \
        _Cfunction('libvlc_media_library_media_list', ((1,),), class_result(MediaList),
                    ctypes.c_void_p, MediaLibrary)
    return f(p_mlib)

def libvlc_media_list_new(p_instance):
    '''Create an empty media list.
    @param p_instance: libvlc instance.
    @return: empty media list, or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_list_new', None) or \
        _Cfunction('libvlc_media_list_new', ((1,),), class_result(MediaList),
                    ctypes.c_void_p, Instance)
    return f(p_instance)

def libvlc_media_list_release(p_ml):
    '''Release media list created with L{libvlc_media_list_new}().
    @param p_ml: a media list created with L{libvlc_media_list_new}().
    '''
    f = _Cfunctions.get('libvlc_media_list_release', None) or \
        _Cfunction('libvlc_media_list_release', ((1,),), None,
                    None, MediaList)
    return f(p_ml)

def libvlc_media_list_retain(p_ml):
    '''Retain reference to a media list.
    @param p_ml: a media list created with L{libvlc_media_list_new}().
    '''
    f = _Cfunctions.get('libvlc_media_list_retain', None) or \
        _Cfunction('libvlc_media_list_retain', ((1,),), None,
                    None, MediaList)
    return f(p_ml)

def libvlc_media_list_set_media(p_ml, p_md):
    '''Associate media instance with this media list instance.
    If another media instance was present it will be released.
    The L{libvlc_media_list_lock} should NOT be held upon entering this function.
    @param p_ml: a media list instance.
    @param p_md: media instance to add.
    '''
    f = _Cfunctions.get('libvlc_media_list_set_media', None) or \
        _Cfunction('libvlc_media_list_set_media', ((1,), (1,),), None,
                    None, MediaList, Media)
    return f(p_ml, p_md)

def libvlc_media_list_media(p_ml):
    '''Get media instance from this media list instance. This action will increase
    the refcount on the media instance.
    The L{libvlc_media_list_lock} should NOT be held upon entering this function.
    @param p_ml: a media list instance.
    @return: media instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_media', None) or \
        _Cfunction('libvlc_media_list_media', ((1,),), class_result(Media),
                    ctypes.c_void_p, MediaList)
    return f(p_ml)

def libvlc_media_list_add_media(p_ml, p_md):
    '''Add media instance to media list
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    @param p_md: a media instance.
    @return: 0 on success, -1 if the media list is read-only.
    '''
    f = _Cfunctions.get('libvlc_media_list_add_media', None) or \
        _Cfunction('libvlc_media_list_add_media', ((1,), (1,),), None,
                    ctypes.c_int, MediaList, Media)
    return f(p_ml, p_md)

def libvlc_media_list_insert_media(p_ml, p_md, i_pos):
    '''Insert media instance in media list on a position
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    @param p_md: a media instance.
    @param i_pos: position in array where to insert.
    @return: 0 on success, -1 if the media list is read-only.
    '''
    f = _Cfunctions.get('libvlc_media_list_insert_media', None) or \
        _Cfunction('libvlc_media_list_insert_media', ((1,), (1,), (1,),), None,
                    ctypes.c_int, MediaList, Media, ctypes.c_int)
    return f(p_ml, p_md, i_pos)

def libvlc_media_list_remove_index(p_ml, i_pos):
    '''Remove media instance from media list on a position
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    @param i_pos: position in array where to insert.
    @return: 0 on success, -1 if the list is read-only or the item was not found.
    '''
    f = _Cfunctions.get('libvlc_media_list_remove_index', None) or \
        _Cfunction('libvlc_media_list_remove_index', ((1,), (1,),), None,
                    ctypes.c_int, MediaList, ctypes.c_int)
    return f(p_ml, i_pos)

def libvlc_media_list_count(p_ml):
    '''Get count on media list items
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    @return: number of items in media list.
    '''
    f = _Cfunctions.get('libvlc_media_list_count', None) or \
        _Cfunction('libvlc_media_list_count', ((1,),), None,
                    ctypes.c_int, MediaList)
    return f(p_ml)

def libvlc_media_list_item_at_index(p_ml, i_pos):
    '''List media instance in media list at a position
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    @param i_pos: position in array where to insert.
    @return: media instance at position i_pos, or NULL if not found. In case of success, L{libvlc_media_retain}() is called to increase the refcount on the media.
    '''
    f = _Cfunctions.get('libvlc_media_list_item_at_index', None) or \
        _Cfunction('libvlc_media_list_item_at_index', ((1,), (1,),), class_result(Media),
                    ctypes.c_void_p, MediaList, ctypes.c_int)
    return f(p_ml, i_pos)

def libvlc_media_list_index_of_item(p_ml, p_md):
    '''Find index position of List media instance in media list.
    Warning: the function will return the first matched position.
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    @param p_md: media instance.
    @return: position of media instance or -1 if media not found.
    '''
    f = _Cfunctions.get('libvlc_media_list_index_of_item', None) or \
        _Cfunction('libvlc_media_list_index_of_item', ((1,), (1,),), None,
                    ctypes.c_int, MediaList, Media)
    return f(p_ml, p_md)

def libvlc_media_list_is_readonly(p_ml):
    '''This indicates if this media list is read-only from a user point of view.
    @param p_ml: media list instance.
    @return: 1 on readonly, 0 on readwrite \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_list_is_readonly', None) or \
        _Cfunction('libvlc_media_list_is_readonly', ((1,),), None,
                    ctypes.c_int, MediaList)
    return f(p_ml)

def libvlc_media_list_lock(p_ml):
    '''Get lock on media list items.
    @param p_ml: a media list instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_lock', None) or \
        _Cfunction('libvlc_media_list_lock', ((1,),), None,
                    None, MediaList)
    return f(p_ml)

def libvlc_media_list_unlock(p_ml):
    '''Release lock on media list items
    The L{libvlc_media_list_lock} should be held upon entering this function.
    @param p_ml: a media list instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_unlock', None) or \
        _Cfunction('libvlc_media_list_unlock', ((1,),), None,
                    None, MediaList)
    return f(p_ml)

def libvlc_media_list_event_manager(p_ml):
    '''Get libvlc_event_manager from this media list instance.
    The p_event_manager is immutable, so you don't have to hold the lock.
    @param p_ml: a media list instance.
    @return: libvlc_event_manager.
    '''
    f = _Cfunctions.get('libvlc_media_list_event_manager', None) or \
        _Cfunction('libvlc_media_list_event_manager', ((1,),), class_result(EventManager),
                    ctypes.c_void_p, MediaList)
    return f(p_ml)

def libvlc_media_list_player_new(p_instance):
    '''Create new media_list_player.
    @param p_instance: libvlc instance.
    @return: media list player instance or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_new', None) or \
        _Cfunction('libvlc_media_list_player_new', ((1,),), class_result(MediaListPlayer),
                    ctypes.c_void_p, Instance)
    return f(p_instance)

def libvlc_media_list_player_release(p_mlp):
    '''Release a media_list_player after use
    Decrement the reference count of a media player object. If the
    reference count is 0, then L{libvlc_media_list_player_release}() will
    release the media player object. If the media player object
    has been released, then it should not be used again.
    @param p_mlp: media list player instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_release', None) or \
        _Cfunction('libvlc_media_list_player_release', ((1,),), None,
                    None, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_retain(p_mlp):
    '''Retain a reference to a media player list object. Use
    L{libvlc_media_list_player_release}() to decrement reference count.
    @param p_mlp: media player list object.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_retain', None) or \
        _Cfunction('libvlc_media_list_player_retain', ((1,),), None,
                    None, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_event_manager(p_mlp):
    '''Return the event manager of this media_list_player.
    @param p_mlp: media list player instance.
    @return: the event manager.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_event_manager', None) or \
        _Cfunction('libvlc_media_list_player_event_manager', ((1,),), class_result(EventManager),
                    ctypes.c_void_p, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_set_media_player(p_mlp, p_mi):
    '''Replace media player in media_list_player with this instance.
    @param p_mlp: media list player instance.
    @param p_mi: media player instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_set_media_player', None) or \
        _Cfunction('libvlc_media_list_player_set_media_player', ((1,), (1,),), None,
                    None, MediaListPlayer, MediaPlayer)
    return f(p_mlp, p_mi)

def libvlc_media_list_player_set_media_list(p_mlp, p_mlist):
    '''Set the media list associated with the player.
    @param p_mlp: media list player instance.
    @param p_mlist: list of media.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_set_media_list', None) or \
        _Cfunction('libvlc_media_list_player_set_media_list', ((1,), (1,),), None,
                    None, MediaListPlayer, MediaList)
    return f(p_mlp, p_mlist)

def libvlc_media_list_player_play(p_mlp):
    '''Play media list.
    @param p_mlp: media list player instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_play', None) or \
        _Cfunction('libvlc_media_list_player_play', ((1,),), None,
                    None, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_pause(p_mlp):
    '''Toggle pause (or resume) media list.
    @param p_mlp: media list player instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_pause', None) or \
        _Cfunction('libvlc_media_list_player_pause', ((1,),), None,
                    None, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_is_playing(p_mlp):
    '''Is media list playing?
    @param p_mlp: media list player instance.
    @return: true for playing and false for not playing \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_is_playing', None) or \
        _Cfunction('libvlc_media_list_player_is_playing', ((1,),), None,
                    ctypes.c_int, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_get_state(p_mlp):
    '''Get current libvlc_state of media list player.
    @param p_mlp: media list player instance.
    @return: libvlc_state_t for media list player.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_get_state', None) or \
        _Cfunction('libvlc_media_list_player_get_state', ((1,),), None,
                    State, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_play_item_at_index(p_mlp, i_index):
    '''Play media list item at position index.
    @param p_mlp: media list player instance.
    @param i_index: index in media list to play.
    @return: 0 upon success -1 if the item wasn't found.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_play_item_at_index', None) or \
        _Cfunction('libvlc_media_list_player_play_item_at_index', ((1,), (1,),), None,
                    ctypes.c_int, MediaListPlayer, ctypes.c_int)
    return f(p_mlp, i_index)

def libvlc_media_list_player_play_item(p_mlp, p_md):
    '''Play the given media item.
    @param p_mlp: media list player instance.
    @param p_md: the media instance.
    @return: 0 upon success, -1 if the media is not part of the media list.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_play_item', None) or \
        _Cfunction('libvlc_media_list_player_play_item', ((1,), (1,),), None,
                    ctypes.c_int, MediaListPlayer, Media)
    return f(p_mlp, p_md)

def libvlc_media_list_player_stop(p_mlp):
    '''Stop playing media list.
    @param p_mlp: media list player instance.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_stop', None) or \
        _Cfunction('libvlc_media_list_player_stop', ((1,),), None,
                    None, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_next(p_mlp):
    '''Play next item from media list.
    @param p_mlp: media list player instance.
    @return: 0 upon success -1 if there is no next item.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_next', None) or \
        _Cfunction('libvlc_media_list_player_next', ((1,),), None,
                    ctypes.c_int, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_previous(p_mlp):
    '''Play previous item from media list.
    @param p_mlp: media list player instance.
    @return: 0 upon success -1 if there is no previous item.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_previous', None) or \
        _Cfunction('libvlc_media_list_player_previous', ((1,),), None,
                    ctypes.c_int, MediaListPlayer)
    return f(p_mlp)

def libvlc_media_list_player_set_playback_mode(p_mlp, e_mode):
    '''Sets the playback mode for the playlist.
    @param p_mlp: media list player instance.
    @param e_mode: playback mode specification.
    '''
    f = _Cfunctions.get('libvlc_media_list_player_set_playback_mode', None) or \
        _Cfunction('libvlc_media_list_player_set_playback_mode', ((1,), (1,),), None,
                    None, MediaListPlayer, PlaybackMode)
    return f(p_mlp, e_mode)

def libvlc_media_player_new(p_libvlc_instance):
    '''Create an empty Media Player object.
    @param p_libvlc_instance: the libvlc instance in which the Media Player should be created.
    @return: a new media player object, or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_player_new', None) or \
        _Cfunction('libvlc_media_player_new', ((1,),), class_result(MediaPlayer),
                    ctypes.c_void_p, Instance)
    return f(p_libvlc_instance)

def libvlc_media_player_new_from_media(p_md):
    '''Create a Media Player object from a Media.
    @param p_md: the media. Afterwards the p_md can be safely destroyed.
    @return: a new media player object, or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_media_player_new_from_media', None) or \
        _Cfunction('libvlc_media_player_new_from_media', ((1,),), class_result(MediaPlayer),
                    ctypes.c_void_p, Media)
    return f(p_md)

def libvlc_media_player_release(p_mi):
    '''Release a media_player after use
    Decrement the reference count of a media player object. If the
    reference count is 0, then L{libvlc_media_player_release}() will
    release the media player object. If the media player object
    has been released, then it should not be used again.
    @param p_mi: the Media Player to free.
    '''
    f = _Cfunctions.get('libvlc_media_player_release', None) or \
        _Cfunction('libvlc_media_player_release', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_retain(p_mi):
    '''Retain a reference to a media player object. Use
    L{libvlc_media_player_release}() to decrement reference count.
    @param p_mi: media player object.
    '''
    f = _Cfunctions.get('libvlc_media_player_retain', None) or \
        _Cfunction('libvlc_media_player_retain', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_media(p_mi, p_md):
    '''Set the media that will be used by the media_player. If any,
    previous md will be released.
    @param p_mi: the Media Player.
    @param p_md: the Media. Afterwards the p_md can be safely destroyed.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_media', None) or \
        _Cfunction('libvlc_media_player_set_media', ((1,), (1,),), None,
                    None, MediaPlayer, Media)
    return f(p_mi, p_md)

def libvlc_media_player_get_media(p_mi):
    '''Get the media used by the media_player.
    @param p_mi: the Media Player.
    @return: the media associated with p_mi, or NULL if no media is associated.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_media', None) or \
        _Cfunction('libvlc_media_player_get_media', ((1,),), class_result(Media),
                    ctypes.c_void_p, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_event_manager(p_mi):
    '''Get the Event Manager from which the media player send event.
    @param p_mi: the Media Player.
    @return: the event manager associated with p_mi.
    '''
    f = _Cfunctions.get('libvlc_media_player_event_manager', None) or \
        _Cfunction('libvlc_media_player_event_manager', ((1,),), class_result(EventManager),
                    ctypes.c_void_p, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_is_playing(p_mi):
    '''is_playing.
    @param p_mi: the Media Player.
    @return: 1 if the media player is playing, 0 otherwise \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_player_is_playing', None) or \
        _Cfunction('libvlc_media_player_is_playing', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_play(p_mi):
    '''Play.
    @param p_mi: the Media Player.
    @return: 0 if playback started (and was already started), or -1 on error.
    '''
    f = _Cfunctions.get('libvlc_media_player_play', None) or \
        _Cfunction('libvlc_media_player_play', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_pause(mp, do_pause):
    '''Pause or resume (no effect if there is no media).
    @param mp: the Media Player.
    @param do_pause: play/resume if zero, pause if non-zero.
    @version: LibVLC 1.1.1 or later.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_pause', None) or \
        _Cfunction('libvlc_media_player_set_pause', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_int)
    return f(mp, do_pause)

def libvlc_media_player_pause(p_mi):
    '''Toggle pause (no effect if there is no media).
    @param p_mi: the Media Player.
    '''
    f = _Cfunctions.get('libvlc_media_player_pause', None) or \
        _Cfunction('libvlc_media_player_pause', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_stop(p_mi):
    '''Stop (no effect if there is no media).
    @param p_mi: the Media Player.
    '''
    f = _Cfunctions.get('libvlc_media_player_stop', None) or \
        _Cfunction('libvlc_media_player_stop', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_callbacks(mp, lock, unlock, display, opaque):
    '''Set callbacks and private data to render decoded video to a custom area
    in memory.
    Use L{libvlc_video_set_format}() or L{libvlc_video_set_format_callbacks}()
    to configure the decoded format.
    @param mp: the media player.
    @param lock: callback to lock video memory (must not be NULL).
    @param unlock: callback to unlock video memory (or NULL if not needed).
    @param display: callback to display video (or NULL if not needed).
    @param opaque: private pointer for the three callbacks (as first parameter).
    @version: LibVLC 1.1.1 or later.
    '''
    f = _Cfunctions.get('libvlc_video_set_callbacks', None) or \
        _Cfunction('libvlc_video_set_callbacks', ((1,), (1,), (1,), (1,), (1,),), None,
                    None, MediaPlayer, VideoLockCb, VideoUnlockCb, VideoDisplayCb, ctypes.c_void_p)
    return f(mp, lock, unlock, display, opaque)

def libvlc_video_set_format(mp, chroma, width, height, pitch):
    '''Set decoded video chroma and dimensions.
    This only works in combination with L{libvlc_video_set_callbacks}(),
    and is mutually exclusive with L{libvlc_video_set_format_callbacks}().
    @param mp: the media player.
    @param chroma: a four-characters string identifying the chroma (e.g. "RV32" or "YUYV").
    @param width: pixel width.
    @param height: pixel height.
    @param pitch: line pitch (in bytes).
    @version: LibVLC 1.1.1 or later.
    @bug: All pixel planes are expected to have the same pitch. To use the YCbCr color space with chrominance subsampling, consider using L{libvlc_video_set_format_callbacks}() instead.
    '''
    f = _Cfunctions.get('libvlc_video_set_format', None) or \
        _Cfunction('libvlc_video_set_format', ((1,), (1,), (1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_char_p, ctypes.c_uint, ctypes.c_uint, ctypes.c_uint)
    return f(mp, chroma, width, height, pitch)

def libvlc_video_set_format_callbacks(mp, setup, cleanup):
    '''Set decoded video chroma and dimensions. This only works in combination with
    L{libvlc_video_set_callbacks}().
    @param mp: the media player.
    @param setup: callback to select the video format (cannot be NULL).
    @param cleanup: callback to release any allocated resources (or NULL).
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_video_set_format_callbacks', None) or \
        _Cfunction('libvlc_video_set_format_callbacks', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, VideoFormatCb, VideoCleanupCb)
    return f(mp, setup, cleanup)

def libvlc_media_player_set_nsobject(p_mi, drawable):
    '''Set the NSView handler where the media player should render its video output.
    Use the vout called "macosx".
    The drawable is an NSObject that follow the VLCOpenGLVideoViewEmbedding
    protocol:
    @begincode
    \@protocol VLCOpenGLVideoViewEmbedding <NSObject>
    - (void)addVoutSubview:(NSView *)view;
    - (void)removeVoutSubview:(NSView *)view;
    \@end
    @endcode
    Or it can be an NSView object.
    If you want to use it along with Qt4 see the QMacCocoaViewContainer. Then
    the following code should work:
    @begincode
    
        NSView *video = [[NSView alloc] init];
        QMacCocoaViewContainer *container = new QMacCocoaViewContainer(video, parent);
        L{libvlc_media_player_set_nsobject}(mp, video);
        [video release];
    
    @endcode
    You can find a live example in VLCVideoView in VLCKit.framework.
    @param p_mi: the Media Player.
    @param drawable: the drawable that is either an NSView or an object following the VLCOpenGLVideoViewEmbedding protocol.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_nsobject', None) or \
        _Cfunction('libvlc_media_player_set_nsobject', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_void_p)
    return f(p_mi, drawable)

def libvlc_media_player_get_nsobject(p_mi):
    '''Get the NSView handler previously set with L{libvlc_media_player_set_nsobject}().
    @param p_mi: the Media Player.
    @return: the NSView handler or 0 if none where set.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_nsobject', None) or \
        _Cfunction('libvlc_media_player_get_nsobject', ((1,),), None,
                    ctypes.c_void_p, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_agl(p_mi, drawable):
    '''Set the agl handler where the media player should render its video output.
    @param p_mi: the Media Player.
    @param drawable: the agl handler.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_agl', None) or \
        _Cfunction('libvlc_media_player_set_agl', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint32)
    return f(p_mi, drawable)

def libvlc_media_player_get_agl(p_mi):
    '''Get the agl handler previously set with L{libvlc_media_player_set_agl}().
    @param p_mi: the Media Player.
    @return: the agl handler or 0 if none where set.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_agl', None) or \
        _Cfunction('libvlc_media_player_get_agl', ((1,),), None,
                    ctypes.c_uint32, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_xwindow(p_mi, drawable):
    '''Set an X Window System drawable where the media player should render its
    video output. If LibVLC was built without X11 output support, then this has
    no effects.
    The specified identifier must correspond to an existing Input/Output class
    X11 window. Pixmaps are B{not} supported. The caller shall ensure that
    the X11 server is the same as the one the VLC instance has been configured
    with. This function must be called before video playback is started;
    otherwise it will only take effect after playback stop and restart.
    @param p_mi: the Media Player.
    @param drawable: the ID of the X window.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_xwindow', None) or \
        _Cfunction('libvlc_media_player_set_xwindow', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint32)
    return f(p_mi, drawable)

def libvlc_media_player_get_xwindow(p_mi):
    '''Get the X Window System window identifier previously set with
    L{libvlc_media_player_set_xwindow}(). Note that this will return the identifier
    even if VLC is not currently using it (for instance if it is playing an
    audio-only input).
    @param p_mi: the Media Player.
    @return: an X window ID, or 0 if none where set.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_xwindow', None) or \
        _Cfunction('libvlc_media_player_get_xwindow', ((1,),), None,
                    ctypes.c_uint32, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_hwnd(p_mi, drawable):
    '''Set a Win32/Win64 API window handle (HWND) where the media player should
    render its video output. If LibVLC was built without Win32/Win64 API output
    support, then this has no effects.
    @param p_mi: the Media Player.
    @param drawable: windows handle of the drawable.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_hwnd', None) or \
        _Cfunction('libvlc_media_player_set_hwnd', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_void_p)
    return f(p_mi, drawable)

def libvlc_media_player_get_hwnd(p_mi):
    '''Get the Windows API window handle (HWND) previously set with
    L{libvlc_media_player_set_hwnd}(). The handle will be returned even if LibVLC
    is not currently outputting any video to it.
    @param p_mi: the Media Player.
    @return: a window handle or NULL if there are none.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_hwnd', None) or \
        _Cfunction('libvlc_media_player_get_hwnd', ((1,),), None,
                    ctypes.c_void_p, MediaPlayer)
    return f(p_mi)

def libvlc_audio_set_callbacks(mp, play, pause, resume, flush, drain, opaque):
    '''Set callbacks and private data for decoded audio.
    Use L{libvlc_audio_set_format}() or L{libvlc_audio_set_format_callbacks}()
    to configure the decoded audio format.
    @param mp: the media player.
    @param play: callback to play audio samples (must not be NULL).
    @param pause: callback to pause playback (or NULL to ignore).
    @param resume: callback to resume playback (or NULL to ignore).
    @param flush: callback to flush audio buffers (or NULL to ignore).
    @param drain: callback to drain audio buffers (or NULL to ignore).
    @param opaque: private pointer for the audio callbacks (as first parameter).
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_set_callbacks', None) or \
        _Cfunction('libvlc_audio_set_callbacks', ((1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,
                    None, MediaPlayer, AudioPlayCb, AudioPauseCb, AudioResumeCb, AudioFlushCb, AudioDrainCb, ctypes.c_void_p)
    return f(mp, play, pause, resume, flush, drain, opaque)

def libvlc_audio_set_volume_callback(mp, set_volume):
    '''Set callbacks and private data for decoded audio.
    Use L{libvlc_audio_set_format}() or L{libvlc_audio_set_format_callbacks}()
    to configure the decoded audio format.
    @param mp: the media player.
    @param set_volume: callback to apply audio volume, or NULL to apply volume in software.
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_set_volume_callback', None) or \
        _Cfunction('libvlc_audio_set_volume_callback', ((1,), (1,),), None,
                    None, MediaPlayer, AudioSetVolumeCb)
    return f(mp, set_volume)

def libvlc_audio_set_format_callbacks(mp, setup, cleanup):
    '''Set decoded audio format. This only works in combination with
    L{libvlc_audio_set_callbacks}().
    @param mp: the media player.
    @param setup: callback to select the audio format (cannot be NULL).
    @param cleanup: callback to release any allocated resources (or NULL).
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_set_format_callbacks', None) or \
        _Cfunction('libvlc_audio_set_format_callbacks', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, AudioSetupCb, AudioCleanupCb)
    return f(mp, setup, cleanup)

def libvlc_audio_set_format(mp, format, rate, channels):
    '''Set decoded audio format.
    This only works in combination with L{libvlc_audio_set_callbacks}(),
    and is mutually exclusive with L{libvlc_audio_set_format_callbacks}().
    @param mp: the media player.
    @param format: a four-characters string identifying the sample format (e.g. "S16N" or "FL32").
    @param rate: sample rate (expressed in Hz).
    @param channels: channels count.
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_set_format', None) or \
        _Cfunction('libvlc_audio_set_format', ((1,), (1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_char_p, ctypes.c_uint, ctypes.c_uint)
    return f(mp, format, rate, channels)

def libvlc_media_player_get_length(p_mi):
    '''Get the current movie length (in ms).
    @param p_mi: the Media Player.
    @return: the movie length (in ms), or -1 if there is no media.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_length', None) or \
        _Cfunction('libvlc_media_player_get_length', ((1,),), None,
                    ctypes.c_longlong, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_get_time(p_mi):
    '''Get the current movie time (in ms).
    @param p_mi: the Media Player.
    @return: the movie time (in ms), or -1 if there is no media.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_time', None) or \
        _Cfunction('libvlc_media_player_get_time', ((1,),), None,
                    ctypes.c_longlong, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_time(p_mi, i_time):
    '''Set the movie time (in ms). This has no effect if no media is being played.
    Not all formats and protocols support this.
    @param p_mi: the Media Player.
    @param i_time: the movie time (in ms).
    '''
    f = _Cfunctions.get('libvlc_media_player_set_time', None) or \
        _Cfunction('libvlc_media_player_set_time', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_longlong)
    return f(p_mi, i_time)

def libvlc_media_player_get_position(p_mi):
    '''Get movie position as percentage between 0.0 and 1.0.
    @param p_mi: the Media Player.
    @return: movie position, or -1. in case of error.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_position', None) or \
        _Cfunction('libvlc_media_player_get_position', ((1,),), None,
                    ctypes.c_float, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_position(p_mi, f_pos):
    '''Set movie position as percentage between 0.0 and 1.0.
    This has no effect if playback is not enabled.
    This might not work depending on the underlying input format and protocol.
    @param p_mi: the Media Player.
    @param f_pos: the position.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_position', None) or \
        _Cfunction('libvlc_media_player_set_position', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_float)
    return f(p_mi, f_pos)

def libvlc_media_player_set_chapter(p_mi, i_chapter):
    '''Set movie chapter (if applicable).
    @param p_mi: the Media Player.
    @param i_chapter: chapter number to play.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_chapter', None) or \
        _Cfunction('libvlc_media_player_set_chapter', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_chapter)

def libvlc_media_player_get_chapter(p_mi):
    '''Get movie chapter.
    @param p_mi: the Media Player.
    @return: chapter number currently playing, or -1 if there is no media.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_chapter', None) or \
        _Cfunction('libvlc_media_player_get_chapter', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_get_chapter_count(p_mi):
    '''Get movie chapter count.
    @param p_mi: the Media Player.
    @return: number of chapters in movie, or -1.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_chapter_count', None) or \
        _Cfunction('libvlc_media_player_get_chapter_count', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_will_play(p_mi):
    '''Is the player able to play.
    @param p_mi: the Media Player.
    @return: boolean \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_player_will_play', None) or \
        _Cfunction('libvlc_media_player_will_play', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_get_chapter_count_for_title(p_mi, i_title):
    '''Get title chapter count.
    @param p_mi: the Media Player.
    @param i_title: title.
    @return: number of chapters in title, or -1.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_chapter_count_for_title', None) or \
        _Cfunction('libvlc_media_player_get_chapter_count_for_title', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_title)

def libvlc_media_player_set_title(p_mi, i_title):
    '''Set movie title.
    @param p_mi: the Media Player.
    @param i_title: title number to play.
    '''
    f = _Cfunctions.get('libvlc_media_player_set_title', None) or \
        _Cfunction('libvlc_media_player_set_title', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_title)

def libvlc_media_player_get_title(p_mi):
    '''Get movie title.
    @param p_mi: the Media Player.
    @return: title number currently playing, or -1.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_title', None) or \
        _Cfunction('libvlc_media_player_get_title', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_get_title_count(p_mi):
    '''Get movie title count.
    @param p_mi: the Media Player.
    @return: title number count, or -1.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_title_count', None) or \
        _Cfunction('libvlc_media_player_get_title_count', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_previous_chapter(p_mi):
    '''Set previous chapter (if applicable).
    @param p_mi: the Media Player.
    '''
    f = _Cfunctions.get('libvlc_media_player_previous_chapter', None) or \
        _Cfunction('libvlc_media_player_previous_chapter', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_next_chapter(p_mi):
    '''Set next chapter (if applicable).
    @param p_mi: the Media Player.
    '''
    f = _Cfunctions.get('libvlc_media_player_next_chapter', None) or \
        _Cfunction('libvlc_media_player_next_chapter', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_get_rate(p_mi):
    '''Get the requested movie play rate.
    @warning: Depending on the underlying media, the requested rate may be
    different from the real playback rate.
    @param p_mi: the Media Player.
    @return: movie play rate.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_rate', None) or \
        _Cfunction('libvlc_media_player_get_rate', ((1,),), None,
                    ctypes.c_float, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_set_rate(p_mi, rate):
    '''Set movie play rate.
    @param p_mi: the Media Player.
    @param rate: movie play rate to set.
    @return: -1 if an error was detected, 0 otherwise (but even then, it might not actually work depending on the underlying media protocol).
    '''
    f = _Cfunctions.get('libvlc_media_player_set_rate', None) or \
        _Cfunction('libvlc_media_player_set_rate', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_float)
    return f(p_mi, rate)

def libvlc_media_player_get_state(p_mi):
    '''Get current movie state.
    @param p_mi: the Media Player.
    @return: the current state of the media player (playing, paused, ...) See libvlc_state_t.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_state', None) or \
        _Cfunction('libvlc_media_player_get_state', ((1,),), None,
                    State, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_get_fps(p_mi):
    '''Get movie fps rate.
    @param p_mi: the Media Player.
    @return: frames per second (fps) for this playing movie, or 0 if unspecified.
    '''
    f = _Cfunctions.get('libvlc_media_player_get_fps', None) or \
        _Cfunction('libvlc_media_player_get_fps', ((1,),), None,
                    ctypes.c_float, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_has_vout(p_mi):
    '''How many video outputs does this media player have?
    @param p_mi: the media player.
    @return: the number of video outputs.
    '''
    f = _Cfunctions.get('libvlc_media_player_has_vout', None) or \
        _Cfunction('libvlc_media_player_has_vout', ((1,),), None,
                    ctypes.c_uint, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_is_seekable(p_mi):
    '''Is this media player seekable?
    @param p_mi: the media player.
    @return: true if the media player can seek \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_player_is_seekable', None) or \
        _Cfunction('libvlc_media_player_is_seekable', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_can_pause(p_mi):
    '''Can this media player be paused?
    @param p_mi: the media player.
    @return: true if the media player can pause \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_media_player_can_pause', None) or \
        _Cfunction('libvlc_media_player_can_pause', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_next_frame(p_mi):
    '''Display the next frame (if supported).
    @param p_mi: the media player.
    '''
    f = _Cfunctions.get('libvlc_media_player_next_frame', None) or \
        _Cfunction('libvlc_media_player_next_frame', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_media_player_navigate(p_mi, navigate):
    '''Navigate through DVD Menu.
    @param p_mi: the Media Player.
    @param navigate: the Navigation mode.
    @version: libVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_media_player_navigate', None) or \
        _Cfunction('libvlc_media_player_navigate', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint)
    return f(p_mi, navigate)

def libvlc_track_description_list_release(p_track_description):
    '''Release (free) L{TrackDescription}.
    @param p_track_description: the structure to release.
    '''
    f = _Cfunctions.get('libvlc_track_description_list_release', None) or \
        _Cfunction('libvlc_track_description_list_release', ((1,),), None,
                    None, ctypes.POINTER(TrackDescription))
    return f(p_track_description)

def libvlc_toggle_fullscreen(p_mi):
    '''Toggle fullscreen status on non-embedded video outputs.
    @warning: The same limitations applies to this function
    as to L{libvlc_set_fullscreen}().
    @param p_mi: the media player.
    '''
    f = _Cfunctions.get('libvlc_toggle_fullscreen', None) or \
        _Cfunction('libvlc_toggle_fullscreen', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_set_fullscreen(p_mi, b_fullscreen):
    '''Enable or disable fullscreen.
    @warning: With most window managers, only a top-level windows can be in
    full-screen mode. Hence, this function will not operate properly if
    L{libvlc_media_player_set_xwindow}() was used to embed the video in a
    non-top-level window. In that case, the embedding window must be reparented
    to the root window B{before} fullscreen mode is enabled. You will want
    to reparent it back to its normal parent when disabling fullscreen.
    @param p_mi: the media player.
    @param b_fullscreen: boolean for fullscreen status.
    '''
    f = _Cfunctions.get('libvlc_set_fullscreen', None) or \
        _Cfunction('libvlc_set_fullscreen', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_int)
    return f(p_mi, b_fullscreen)

def libvlc_get_fullscreen(p_mi):
    '''Get current fullscreen status.
    @param p_mi: the media player.
    @return: the fullscreen status (boolean) \libvlc_return_bool.
    '''
    f = _Cfunctions.get('libvlc_get_fullscreen', None) or \
        _Cfunction('libvlc_get_fullscreen', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_key_input(p_mi, on):
    '''Enable or disable key press events handling, according to the LibVLC hotkeys
    configuration. By default and for historical reasons, keyboard events are
    handled by the LibVLC video widget.
    @note: On X11, there can be only one subscriber for key press and mouse
    click events per window. If your application has subscribed to those events
    for the X window ID of the video widget, then LibVLC will not be able to
    handle key presses and mouse clicks in any case.
    @warning: This function is only implemented for X11 and Win32 at the moment.
    @param p_mi: the media player.
    @param on: true to handle key press events, false to ignore them.
    '''
    f = _Cfunctions.get('libvlc_video_set_key_input', None) or \
        _Cfunction('libvlc_video_set_key_input', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint)
    return f(p_mi, on)

def libvlc_video_set_mouse_input(p_mi, on):
    '''Enable or disable mouse click events handling. By default, those events are
    handled. This is needed for DVD menus to work, as well as a few video
    filters such as "puzzle".
    See L{libvlc_video_set_key_input}().
    @warning: This function is only implemented for X11 and Win32 at the moment.
    @param p_mi: the media player.
    @param on: true to handle mouse click events, false to ignore them.
    '''
    f = _Cfunctions.get('libvlc_video_set_mouse_input', None) or \
        _Cfunction('libvlc_video_set_mouse_input', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint)
    return f(p_mi, on)

def libvlc_video_get_size(p_mi, num):
    '''Get the pixel dimensions of a video.
    @param p_mi: media player.
    @param num: number of the video (starting from, and most commonly 0).
    @return: px pixel width, py pixel height.
    '''
    f = _Cfunctions.get('libvlc_video_get_size', None) or \
        _Cfunction('libvlc_video_get_size', ((1,), (1,), (2,), (2,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_uint, ctypes.POINTER(ctypes.c_uint), ctypes.POINTER(ctypes.c_uint))
    return f(p_mi, num)

def libvlc_video_get_cursor(p_mi, num):
    '''Get the mouse pointer coordinates over a video.
    Coordinates are expressed in terms of the decoded video resolution,
    B{not} in terms of pixels on the screen/viewport (to get the latter,
    you can query your windowing system directly).
    Either of the coordinates may be negative or larger than the corresponding
    dimension of the video, if the cursor is outside the rendering area.
    @warning: The coordinates may be out-of-date if the pointer is not located
    on the video rendering area. LibVLC does not track the pointer if it is
    outside of the video widget.
    @note: LibVLC does not support multiple pointers (it does of course support
    multiple input devices sharing the same pointer) at the moment.
    @param p_mi: media player.
    @param num: number of the video (starting from, and most commonly 0).
    @return: px abscissa, py ordinate.
    '''
    f = _Cfunctions.get('libvlc_video_get_cursor', None) or \
        _Cfunction('libvlc_video_get_cursor', ((1,), (1,), (2,), (2,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_uint, ctypes.POINTER(ctypes.c_int), ctypes.POINTER(ctypes.c_int))
    return f(p_mi, num)

def libvlc_video_get_scale(p_mi):
    '''Get the current video scaling factor.
    See also L{libvlc_video_set_scale}().
    @param p_mi: the media player.
    @return: the currently configured zoom factor, or 0. if the video is set to fit to the output window/drawable automatically.
    '''
    f = _Cfunctions.get('libvlc_video_get_scale', None) or \
        _Cfunction('libvlc_video_get_scale', ((1,),), None,
                    ctypes.c_float, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_scale(p_mi, f_factor):
    '''Set the video scaling factor. That is the ratio of the number of pixels on
    screen to the number of pixels in the original decoded video in each
    dimension. Zero is a special value; it will adjust the video to the output
    window/drawable (in windowed mode) or the entire screen.
    Note that not all video outputs support scaling.
    @param p_mi: the media player.
    @param f_factor: the scaling factor, or zero.
    '''
    f = _Cfunctions.get('libvlc_video_set_scale', None) or \
        _Cfunction('libvlc_video_set_scale', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_float)
    return f(p_mi, f_factor)

def libvlc_video_get_aspect_ratio(p_mi):
    '''Get current video aspect ratio.
    @param p_mi: the media player.
    @return: the video aspect ratio or NULL if unspecified (the result must be released with free() or L{libvlc_free}()).
    '''
    f = _Cfunctions.get('libvlc_video_get_aspect_ratio', None) or \
        _Cfunction('libvlc_video_get_aspect_ratio', ((1,),), string_result,
                    ctypes.c_void_p, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_aspect_ratio(p_mi, psz_aspect):
    '''Set new video aspect ratio.
    @param p_mi: the media player.
    @param psz_aspect: new video aspect-ratio or NULL to reset to default @note Invalid aspect ratios are ignored.
    '''
    f = _Cfunctions.get('libvlc_video_set_aspect_ratio', None) or \
        _Cfunction('libvlc_video_set_aspect_ratio', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_char_p)
    return f(p_mi, psz_aspect)

def libvlc_video_get_spu(p_mi):
    '''Get current video subtitle.
    @param p_mi: the media player.
    @return: the video subtitle selected, or -1 if none.
    '''
    f = _Cfunctions.get('libvlc_video_get_spu', None) or \
        _Cfunction('libvlc_video_get_spu', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_video_get_spu_count(p_mi):
    '''Get the number of available video subtitles.
    @param p_mi: the media player.
    @return: the number of available video subtitles.
    '''
    f = _Cfunctions.get('libvlc_video_get_spu_count', None) or \
        _Cfunction('libvlc_video_get_spu_count', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_video_get_spu_description(p_mi):
    '''Get the description of available video subtitles.
    @param p_mi: the media player.
    @return: list containing description of available video subtitles.
    '''
    f = _Cfunctions.get('libvlc_video_get_spu_description', None) or \
        _Cfunction('libvlc_video_get_spu_description', ((1,),), None,
                    ctypes.POINTER(TrackDescription), MediaPlayer)
    return f(p_mi)

def libvlc_video_set_spu(p_mi, i_spu):
    '''Set new video subtitle.
    @param p_mi: the media player.
    @param i_spu: video subtitle track to select (i_id from track description).
    @return: 0 on success, -1 if out of range.
    '''
    f = _Cfunctions.get('libvlc_video_set_spu', None) or \
        _Cfunction('libvlc_video_set_spu', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_spu)

def libvlc_video_set_subtitle_file(p_mi, psz_subtitle):
    '''Set new video subtitle file.
    @param p_mi: the media player.
    @param psz_subtitle: new video subtitle file.
    @return: the success status (boolean).
    '''
    f = _Cfunctions.get('libvlc_video_set_subtitle_file', None) or \
        _Cfunction('libvlc_video_set_subtitle_file', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_char_p)
    return f(p_mi, psz_subtitle)

def libvlc_video_get_spu_delay(p_mi):
    '''Get the current subtitle delay. Positive values means subtitles are being
    displayed later, negative values earlier.
    @param p_mi: media player.
    @return: time (in microseconds) the display of subtitles is being delayed.
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_video_get_spu_delay', None) or \
        _Cfunction('libvlc_video_get_spu_delay', ((1,),), None,
                    ctypes.c_int64, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_spu_delay(p_mi, i_delay):
    '''Set the subtitle delay. This affects the timing of when the subtitle will
    be displayed. Positive values result in subtitles being displayed later,
    while negative values will result in subtitles being displayed earlier.
    The subtitle delay will be reset to zero each time the media changes.
    @param p_mi: media player.
    @param i_delay: time (in microseconds) the display of subtitles should be delayed.
    @return: 0 on success, -1 on error.
    @version: LibVLC 2.0.0 or later.
    '''
    f = _Cfunctions.get('libvlc_video_set_spu_delay', None) or \
        _Cfunction('libvlc_video_set_spu_delay', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int64)
    return f(p_mi, i_delay)

def libvlc_video_get_title_description(p_mi):
    '''Get the description of available titles.
    @param p_mi: the media player.
    @return: list containing description of available titles.
    '''
    f = _Cfunctions.get('libvlc_video_get_title_description', None) or \
        _Cfunction('libvlc_video_get_title_description', ((1,),), None,
                    ctypes.POINTER(TrackDescription), MediaPlayer)
    return f(p_mi)

def libvlc_video_get_chapter_description(p_mi, i_title):
    '''Get the description of available chapters for specific title.
    @param p_mi: the media player.
    @param i_title: selected title.
    @return: list containing description of available chapter for title i_title.
    '''
    f = _Cfunctions.get('libvlc_video_get_chapter_description', None) or \
        _Cfunction('libvlc_video_get_chapter_description', ((1,), (1,),), None,
                    ctypes.POINTER(TrackDescription), MediaPlayer, ctypes.c_int)
    return f(p_mi, i_title)

def libvlc_video_get_crop_geometry(p_mi):
    '''Get current crop filter geometry.
    @param p_mi: the media player.
    @return: the crop filter geometry or NULL if unset.
    '''
    f = _Cfunctions.get('libvlc_video_get_crop_geometry', None) or \
        _Cfunction('libvlc_video_get_crop_geometry', ((1,),), string_result,
                    ctypes.c_void_p, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_crop_geometry(p_mi, psz_geometry):
    '''Set new crop filter geometry.
    @param p_mi: the media player.
    @param psz_geometry: new crop filter geometry (NULL to unset).
    '''
    f = _Cfunctions.get('libvlc_video_set_crop_geometry', None) or \
        _Cfunction('libvlc_video_set_crop_geometry', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_char_p)
    return f(p_mi, psz_geometry)

def libvlc_video_get_teletext(p_mi):
    '''Get current teletext page requested.
    @param p_mi: the media player.
    @return: the current teletext page requested.
    '''
    f = _Cfunctions.get('libvlc_video_get_teletext', None) or \
        _Cfunction('libvlc_video_get_teletext', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_teletext(p_mi, i_page):
    '''Set new teletext page to retrieve.
    @param p_mi: the media player.
    @param i_page: teletex page number requested.
    '''
    f = _Cfunctions.get('libvlc_video_set_teletext', None) or \
        _Cfunction('libvlc_video_set_teletext', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_page)

def libvlc_toggle_teletext(p_mi):
    '''Toggle teletext transparent status on video output.
    @param p_mi: the media player.
    '''
    f = _Cfunctions.get('libvlc_toggle_teletext', None) or \
        _Cfunction('libvlc_toggle_teletext', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_video_get_track_count(p_mi):
    '''Get number of available video tracks.
    @param p_mi: media player.
    @return: the number of available video tracks (int).
    '''
    f = _Cfunctions.get('libvlc_video_get_track_count', None) or \
        _Cfunction('libvlc_video_get_track_count', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_video_get_track_description(p_mi):
    '''Get the description of available video tracks.
    @param p_mi: media player.
    @return: list with description of available video tracks, or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_video_get_track_description', None) or \
        _Cfunction('libvlc_video_get_track_description', ((1,),), None,
                    ctypes.POINTER(TrackDescription), MediaPlayer)
    return f(p_mi)

def libvlc_video_get_track(p_mi):
    '''Get current video track.
    @param p_mi: media player.
    @return: the video track ID (int) or -1 if no active input.
    '''
    f = _Cfunctions.get('libvlc_video_get_track', None) or \
        _Cfunction('libvlc_video_get_track', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_video_set_track(p_mi, i_track):
    '''Set video track.
    @param p_mi: media player.
    @param i_track: the track ID (i_id field from track description).
    @return: 0 on success, -1 if out of range.
    '''
    f = _Cfunctions.get('libvlc_video_set_track', None) or \
        _Cfunction('libvlc_video_set_track', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_track)

def libvlc_video_take_snapshot(p_mi, num, psz_filepath, i_width, i_height):
    '''Take a snapshot of the current video window.
    If i_width AND i_height is 0, original size is used.
    If i_width XOR i_height is 0, original aspect-ratio is preserved.
    @param p_mi: media player instance.
    @param num: number of video output (typically 0 for the first/only one).
    @param psz_filepath: the path where to save the screenshot to.
    @param i_width: the snapshot's width.
    @param i_height: the snapshot's height.
    @return: 0 on success, -1 if the video was not found.
    '''
    f = _Cfunctions.get('libvlc_video_take_snapshot', None) or \
        _Cfunction('libvlc_video_take_snapshot', ((1,), (1,), (1,), (1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_uint, ctypes.c_char_p, ctypes.c_int, ctypes.c_int)
    return f(p_mi, num, psz_filepath, i_width, i_height)

def libvlc_video_set_deinterlace(p_mi, psz_mode):
    '''Enable or disable deinterlace filter.
    @param p_mi: libvlc media player.
    @param psz_mode: type of deinterlace filter, NULL to disable.
    '''
    f = _Cfunctions.get('libvlc_video_set_deinterlace', None) or \
        _Cfunction('libvlc_video_set_deinterlace', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_char_p)
    return f(p_mi, psz_mode)

def libvlc_video_get_marquee_int(p_mi, option):
    '''Get an integer marquee option value.
    @param p_mi: libvlc media player.
    @param option: marq option to get See libvlc_video_marquee_int_option_t.
    '''
    f = _Cfunctions.get('libvlc_video_get_marquee_int', None) or \
        _Cfunction('libvlc_video_get_marquee_int', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_uint)
    return f(p_mi, option)

def libvlc_video_get_marquee_string(p_mi, option):
    '''Get a string marquee option value.
    @param p_mi: libvlc media player.
    @param option: marq option to get See libvlc_video_marquee_string_option_t.
    '''
    f = _Cfunctions.get('libvlc_video_get_marquee_string', None) or \
        _Cfunction('libvlc_video_get_marquee_string', ((1,), (1,),), string_result,
                    ctypes.c_void_p, MediaPlayer, ctypes.c_uint)
    return f(p_mi, option)

def libvlc_video_set_marquee_int(p_mi, option, i_val):
    '''Enable, disable or set an integer marquee option
    Setting libvlc_marquee_Enable has the side effect of enabling (arg !0)
    or disabling (arg 0) the marq filter.
    @param p_mi: libvlc media player.
    @param option: marq option to set See libvlc_video_marquee_int_option_t.
    @param i_val: marq option value.
    '''
    f = _Cfunctions.get('libvlc_video_set_marquee_int', None) or \
        _Cfunction('libvlc_video_set_marquee_int', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint, ctypes.c_int)
    return f(p_mi, option, i_val)

def libvlc_video_set_marquee_string(p_mi, option, psz_text):
    '''Set a marquee string option.
    @param p_mi: libvlc media player.
    @param option: marq option to set See libvlc_video_marquee_string_option_t.
    @param psz_text: marq option value.
    '''
    f = _Cfunctions.get('libvlc_video_set_marquee_string', None) or \
        _Cfunction('libvlc_video_set_marquee_string', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint, ctypes.c_char_p)
    return f(p_mi, option, psz_text)

def libvlc_video_get_logo_int(p_mi, option):
    '''Get integer logo option.
    @param p_mi: libvlc media player instance.
    @param option: logo option to get, values of libvlc_video_logo_option_t.
    '''
    f = _Cfunctions.get('libvlc_video_get_logo_int', None) or \
        _Cfunction('libvlc_video_get_logo_int', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_uint)
    return f(p_mi, option)

def libvlc_video_set_logo_int(p_mi, option, value):
    '''Set logo option as integer. Options that take a different type value
    are ignored.
    Passing libvlc_logo_enable as option value has the side effect of
    starting (arg !0) or stopping (arg 0) the logo filter.
    @param p_mi: libvlc media player instance.
    @param option: logo option to set, values of libvlc_video_logo_option_t.
    @param value: logo option value.
    '''
    f = _Cfunctions.get('libvlc_video_set_logo_int', None) or \
        _Cfunction('libvlc_video_set_logo_int', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint, ctypes.c_int)
    return f(p_mi, option, value)

def libvlc_video_set_logo_string(p_mi, option, psz_value):
    '''Set logo option as string. Options that take a different type value
    are ignored.
    @param p_mi: libvlc media player instance.
    @param option: logo option to set, values of libvlc_video_logo_option_t.
    @param psz_value: logo option value.
    '''
    f = _Cfunctions.get('libvlc_video_set_logo_string', None) or \
        _Cfunction('libvlc_video_set_logo_string', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint, ctypes.c_char_p)
    return f(p_mi, option, psz_value)

def libvlc_video_get_adjust_int(p_mi, option):
    '''Get integer adjust option.
    @param p_mi: libvlc media player instance.
    @param option: adjust option to get, values of libvlc_video_adjust_option_t.
    @version: LibVLC 1.1.1 and later.
    '''
    f = _Cfunctions.get('libvlc_video_get_adjust_int', None) or \
        _Cfunction('libvlc_video_get_adjust_int', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_uint)
    return f(p_mi, option)

def libvlc_video_set_adjust_int(p_mi, option, value):
    '''Set adjust option as integer. Options that take a different type value
    are ignored.
    Passing libvlc_adjust_enable as option value has the side effect of
    starting (arg !0) or stopping (arg 0) the adjust filter.
    @param p_mi: libvlc media player instance.
    @param option: adust option to set, values of libvlc_video_adjust_option_t.
    @param value: adjust option value.
    @version: LibVLC 1.1.1 and later.
    '''
    f = _Cfunctions.get('libvlc_video_set_adjust_int', None) or \
        _Cfunction('libvlc_video_set_adjust_int', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint, ctypes.c_int)
    return f(p_mi, option, value)

def libvlc_video_get_adjust_float(p_mi, option):
    '''Get float adjust option.
    @param p_mi: libvlc media player instance.
    @param option: adjust option to get, values of libvlc_video_adjust_option_t.
    @version: LibVLC 1.1.1 and later.
    '''
    f = _Cfunctions.get('libvlc_video_get_adjust_float', None) or \
        _Cfunction('libvlc_video_get_adjust_float', ((1,), (1,),), None,
                    ctypes.c_float, MediaPlayer, ctypes.c_uint)
    return f(p_mi, option)

def libvlc_video_set_adjust_float(p_mi, option, value):
    '''Set adjust option as float. Options that take a different type value
    are ignored.
    @param p_mi: libvlc media player instance.
    @param option: adust option to set, values of libvlc_video_adjust_option_t.
    @param value: adjust option value.
    @version: LibVLC 1.1.1 and later.
    '''
    f = _Cfunctions.get('libvlc_video_set_adjust_float', None) or \
        _Cfunction('libvlc_video_set_adjust_float', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_uint, ctypes.c_float)
    return f(p_mi, option, value)

def libvlc_audio_output_list_get(p_instance):
    '''Gets the list of available audio outputs.
    @param p_instance: libvlc instance.
    @return: list of available audio outputs. It must be freed it with In case of error, NULL is returned.
    '''
    f = _Cfunctions.get('libvlc_audio_output_list_get', None) or \
        _Cfunction('libvlc_audio_output_list_get', ((1,),), None,
                    ctypes.POINTER(AudioOutput), Instance)
    return f(p_instance)

def libvlc_audio_output_list_release(p_list):
    '''Frees the list of available audio outputs.
    @param p_list: list with audio outputs for release.
    '''
    f = _Cfunctions.get('libvlc_audio_output_list_release', None) or \
        _Cfunction('libvlc_audio_output_list_release', ((1,),), None,
                    None, ctypes.POINTER(AudioOutput))
    return f(p_list)

def libvlc_audio_output_set(p_mi, psz_name):
    '''Sets the audio output.
    @note: Any change will take be effect only after playback is stopped and
    restarted. Audio output cannot be changed while playing.
    @param p_mi: media player.
    @param psz_name: name of audio output, use psz_name of See L{AudioOutput}.
    @return: 0 if function succeded, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_audio_output_set', None) or \
        _Cfunction('libvlc_audio_output_set', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_char_p)
    return f(p_mi, psz_name)

def libvlc_audio_output_device_list_get(p_instance, aout):
    '''Gets a list of audio output devices for a given audio output.
    See L{libvlc_audio_output_device_set}().
    @note: Not all audio outputs support this. In particular, an empty (NULL)
    list of devices does B{not} imply that the specified audio output does
    not work.
    @note: The list might not be exhaustive.
    @warning: Some audio output devices in the list might not actually work in
    some circumstances. By default, it is recommended to not specify any
    explicit audio device.
    @param p_instance: libvlc instance.
    @param psz_aout: audio output name (as returned by L{libvlc_audio_output_list_get}()).
    @return: A NULL-terminated linked list of potential audio output devices. It must be freed it with L{libvlc_audio_output_device_list_release}().
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_output_device_list_get', None) or \
        _Cfunction('libvlc_audio_output_device_list_get', ((1,), (1,),), None,
                    ctypes.POINTER(AudioOutputDevice), Instance, ctypes.c_char_p)
    return f(p_instance, aout)

def libvlc_audio_output_device_list_release(p_list):
    '''Frees a list of available audio output devices.
    @param p_list: list with audio outputs for release.
    @version: LibVLC 2.1.0 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_output_device_list_release', None) or \
        _Cfunction('libvlc_audio_output_device_list_release', ((1,),), None,
                    None, ctypes.POINTER(AudioOutputDevice))
    return f(p_list)

def libvlc_audio_output_device_set(p_mi, psz_audio_output, psz_device_id):
    '''Configures an explicit audio output device for a given audio output plugin.
    A list of possible devices can be obtained with
    L{libvlc_audio_output_device_list_get}().
    @note: This function does not select the specified audio output plugin.
    L{libvlc_audio_output_set}() is used for that purpose.
    @warning: The syntax for the device parameter depends on the audio output.
    This is not portable. Only use this function if you know what you are doing.
    Some audio outputs do not support this function (e.g. PulseAudio, WASAPI).
    Some audio outputs require further parameters (e.g. ALSA: channels map).
    @param p_mi: media player.
    @param psz_audio_output: - name of audio output, See L{AudioOutput}.
    @param psz_device_id: device.
    @return: Nothing. Errors are ignored.
    '''
    f = _Cfunctions.get('libvlc_audio_output_device_set', None) or \
        _Cfunction('libvlc_audio_output_device_set', ((1,), (1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_char_p, ctypes.c_char_p)
    return f(p_mi, psz_audio_output, psz_device_id)

def libvlc_audio_toggle_mute(p_mi):
    '''Toggle mute status.
    @param p_mi: media player @warning Toggling mute atomically is not always possible: On some platforms, other processes can mute the VLC audio playback stream asynchronously. Thus, there is a small race condition where toggling will not work. See also the limitations of L{libvlc_audio_set_mute}().
    '''
    f = _Cfunctions.get('libvlc_audio_toggle_mute', None) or \
        _Cfunction('libvlc_audio_toggle_mute', ((1,),), None,
                    None, MediaPlayer)
    return f(p_mi)

def libvlc_audio_get_mute(p_mi):
    '''Get current mute status.
    @param p_mi: media player.
    @return: the mute status (boolean) if defined, -1 if undefined/unapplicable.
    '''
    f = _Cfunctions.get('libvlc_audio_get_mute', None) or \
        _Cfunction('libvlc_audio_get_mute', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_audio_set_mute(p_mi, status):
    '''Set mute status.
    @param p_mi: media player.
    @param status: If status is true then mute, otherwise unmute @warning This function does not always work. If there are no active audio playback stream, the mute status might not be available. If digital pass-through (S/PDIF, HDMI...) is in use, muting may be unapplicable. Also some audio output plugins do not support muting at all. @note To force silent playback, disable all audio tracks. This is more efficient and reliable than mute.
    '''
    f = _Cfunctions.get('libvlc_audio_set_mute', None) or \
        _Cfunction('libvlc_audio_set_mute', ((1,), (1,),), None,
                    None, MediaPlayer, ctypes.c_int)
    return f(p_mi, status)

def libvlc_audio_get_volume(p_mi):
    '''Get current software audio volume.
    @param p_mi: media player.
    @return: the software volume in percents (0 = mute, 100 = nominal / 0dB).
    '''
    f = _Cfunctions.get('libvlc_audio_get_volume', None) or \
        _Cfunction('libvlc_audio_get_volume', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_audio_set_volume(p_mi, i_volume):
    '''Set current software audio volume.
    @param p_mi: media player.
    @param i_volume: the volume in percents (0 = mute, 100 = 0dB).
    @return: 0 if the volume was set, -1 if it was out of range.
    '''
    f = _Cfunctions.get('libvlc_audio_set_volume', None) or \
        _Cfunction('libvlc_audio_set_volume', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_volume)

def libvlc_audio_get_track_count(p_mi):
    '''Get number of available audio tracks.
    @param p_mi: media player.
    @return: the number of available audio tracks (int), or -1 if unavailable.
    '''
    f = _Cfunctions.get('libvlc_audio_get_track_count', None) or \
        _Cfunction('libvlc_audio_get_track_count', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_audio_get_track_description(p_mi):
    '''Get the description of available audio tracks.
    @param p_mi: media player.
    @return: list with description of available audio tracks, or NULL.
    '''
    f = _Cfunctions.get('libvlc_audio_get_track_description', None) or \
        _Cfunction('libvlc_audio_get_track_description', ((1,),), None,
                    ctypes.POINTER(TrackDescription), MediaPlayer)
    return f(p_mi)

def libvlc_audio_get_track(p_mi):
    '''Get current audio track.
    @param p_mi: media player.
    @return: the audio track ID or -1 if no active input.
    '''
    f = _Cfunctions.get('libvlc_audio_get_track', None) or \
        _Cfunction('libvlc_audio_get_track', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_audio_set_track(p_mi, i_track):
    '''Set current audio track.
    @param p_mi: media player.
    @param i_track: the track ID (i_id field from track description).
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_audio_set_track', None) or \
        _Cfunction('libvlc_audio_set_track', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int)
    return f(p_mi, i_track)

def libvlc_audio_get_channel(p_mi):
    '''Get current audio channel.
    @param p_mi: media player.
    @return: the audio channel See libvlc_audio_output_channel_t.
    '''
    f = _Cfunctions.get('libvlc_audio_get_channel', None) or \
        _Cfunction('libvlc_audio_get_channel', ((1,),), None,
                    ctypes.c_int, MediaPlayer)
    return f(p_mi)

def libvlc_audio_set_channel(p_mi, channel):
    '''Set current audio channel.
    @param p_mi: media player.
    @param channel: the audio channel, See libvlc_audio_output_channel_t.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_audio_set_channel', None) or \
        _Cfunction('libvlc_audio_set_channel', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int)
    return f(p_mi, channel)

def libvlc_audio_get_delay(p_mi):
    '''Get current audio delay.
    @param p_mi: media player.
    @return: the audio delay (microseconds).
    @version: LibVLC 1.1.1 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_get_delay', None) or \
        _Cfunction('libvlc_audio_get_delay', ((1,),), None,
                    ctypes.c_int64, MediaPlayer)
    return f(p_mi)

def libvlc_audio_set_delay(p_mi, i_delay):
    '''Set current audio delay. The audio delay will be reset to zero each time the media changes.
    @param p_mi: media player.
    @param i_delay: the audio delay (microseconds).
    @return: 0 on success, -1 on error.
    @version: LibVLC 1.1.1 or later.
    '''
    f = _Cfunctions.get('libvlc_audio_set_delay', None) or \
        _Cfunction('libvlc_audio_set_delay', ((1,), (1,),), None,
                    ctypes.c_int, MediaPlayer, ctypes.c_int64)
    return f(p_mi, i_delay)

def libvlc_vlm_release(p_instance):
    '''Release the vlm instance related to the given L{Instance}.
    @param p_instance: the instance.
    '''
    f = _Cfunctions.get('libvlc_vlm_release', None) or \
        _Cfunction('libvlc_vlm_release', ((1,),), None,
                    None, Instance)
    return f(p_instance)

def libvlc_vlm_add_broadcast(p_instance, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):
    '''Add a broadcast, with one input.
    @param p_instance: the instance.
    @param psz_name: the name of the new broadcast.
    @param psz_input: the input MRL.
    @param psz_output: the output MRL (the parameter to the "sout" variable).
    @param i_options: number of additional options.
    @param ppsz_options: additional options.
    @param b_enabled: boolean for enabling the new broadcast.
    @param b_loop: Should this broadcast be played in loop ?
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_add_broadcast', None) or \
        _Cfunction('libvlc_vlm_add_broadcast', ((1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p), ctypes.c_int, ctypes.c_int)
    return f(p_instance, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop)

def libvlc_vlm_add_vod(p_instance, psz_name, psz_input, i_options, ppsz_options, b_enabled, psz_mux):
    '''Add a vod, with one input.
    @param p_instance: the instance.
    @param psz_name: the name of the new vod media.
    @param psz_input: the input MRL.
    @param i_options: number of additional options.
    @param ppsz_options: additional options.
    @param b_enabled: boolean for enabling the new vod.
    @param psz_mux: the muxer of the vod media.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_add_vod', None) or \
        _Cfunction('libvlc_vlm_add_vod', ((1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p), ctypes.c_int, ctypes.c_char_p)
    return f(p_instance, psz_name, psz_input, i_options, ppsz_options, b_enabled, psz_mux)

def libvlc_vlm_del_media(p_instance, psz_name):
    '''Delete a media (VOD or broadcast).
    @param p_instance: the instance.
    @param psz_name: the media to delete.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_del_media', None) or \
        _Cfunction('libvlc_vlm_del_media', ((1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p)
    return f(p_instance, psz_name)

def libvlc_vlm_set_enabled(p_instance, psz_name, b_enabled):
    '''Enable or disable a media (VOD or broadcast).
    @param p_instance: the instance.
    @param psz_name: the media to work on.
    @param b_enabled: the new status.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_set_enabled', None) or \
        _Cfunction('libvlc_vlm_set_enabled', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, b_enabled)

def libvlc_vlm_set_output(p_instance, psz_name, psz_output):
    '''Set the output for a media.
    @param p_instance: the instance.
    @param psz_name: the media to work on.
    @param psz_output: the output MRL (the parameter to the "sout" variable).
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_set_output', None) or \
        _Cfunction('libvlc_vlm_set_output', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)
    return f(p_instance, psz_name, psz_output)

def libvlc_vlm_set_input(p_instance, psz_name, psz_input):
    '''Set a media's input MRL. This will delete all existing inputs and
    add the specified one.
    @param p_instance: the instance.
    @param psz_name: the media to work on.
    @param psz_input: the input MRL.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_set_input', None) or \
        _Cfunction('libvlc_vlm_set_input', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)
    return f(p_instance, psz_name, psz_input)

def libvlc_vlm_add_input(p_instance, psz_name, psz_input):
    '''Add a media's input MRL. This will add the specified one.
    @param p_instance: the instance.
    @param psz_name: the media to work on.
    @param psz_input: the input MRL.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_add_input', None) or \
        _Cfunction('libvlc_vlm_add_input', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)
    return f(p_instance, psz_name, psz_input)

def libvlc_vlm_set_loop(p_instance, psz_name, b_loop):
    '''Set a media's loop status.
    @param p_instance: the instance.
    @param psz_name: the media to work on.
    @param b_loop: the new status.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_set_loop', None) or \
        _Cfunction('libvlc_vlm_set_loop', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, b_loop)

def libvlc_vlm_set_mux(p_instance, psz_name, psz_mux):
    '''Set a media's vod muxer.
    @param p_instance: the instance.
    @param psz_name: the media to work on.
    @param psz_mux: the new muxer.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_set_mux', None) or \
        _Cfunction('libvlc_vlm_set_mux', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p)
    return f(p_instance, psz_name, psz_mux)

def libvlc_vlm_change_media(p_instance, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop):
    '''Edit the parameters of a media. This will delete all existing inputs and
    add the specified one.
    @param p_instance: the instance.
    @param psz_name: the name of the new broadcast.
    @param psz_input: the input MRL.
    @param psz_output: the output MRL (the parameter to the "sout" variable).
    @param i_options: number of additional options.
    @param ppsz_options: additional options.
    @param b_enabled: boolean for enabling the new broadcast.
    @param b_loop: Should this broadcast be played in loop ?
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_change_media', None) or \
        _Cfunction('libvlc_vlm_change_media', ((1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_char_p, ctypes.c_int, ListPOINTER(ctypes.c_char_p), ctypes.c_int, ctypes.c_int)
    return f(p_instance, psz_name, psz_input, psz_output, i_options, ppsz_options, b_enabled, b_loop)

def libvlc_vlm_play_media(p_instance, psz_name):
    '''Play the named broadcast.
    @param p_instance: the instance.
    @param psz_name: the name of the broadcast.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_play_media', None) or \
        _Cfunction('libvlc_vlm_play_media', ((1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p)
    return f(p_instance, psz_name)

def libvlc_vlm_stop_media(p_instance, psz_name):
    '''Stop the named broadcast.
    @param p_instance: the instance.
    @param psz_name: the name of the broadcast.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_stop_media', None) or \
        _Cfunction('libvlc_vlm_stop_media', ((1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p)
    return f(p_instance, psz_name)

def libvlc_vlm_pause_media(p_instance, psz_name):
    '''Pause the named broadcast.
    @param p_instance: the instance.
    @param psz_name: the name of the broadcast.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_pause_media', None) or \
        _Cfunction('libvlc_vlm_pause_media', ((1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p)
    return f(p_instance, psz_name)

def libvlc_vlm_seek_media(p_instance, psz_name, f_percentage):
    '''Seek in the named broadcast.
    @param p_instance: the instance.
    @param psz_name: the name of the broadcast.
    @param f_percentage: the percentage to seek to.
    @return: 0 on success, -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_seek_media', None) or \
        _Cfunction('libvlc_vlm_seek_media', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_float)
    return f(p_instance, psz_name, f_percentage)

def libvlc_vlm_show_media(p_instance, psz_name):
    '''Return information about the named media as a JSON
    string representation.
    This function is mainly intended for debugging use,
    if you want programmatic access to the state of
    a vlm_media_instance_t, please use the corresponding
    libvlc_vlm_get_media_instance_xxx -functions.
    Currently there are no such functions available for
    vlm_media_t though.
    @param p_instance: the instance.
    @param psz_name: the name of the media, if the name is an empty string, all media is described.
    @return: string with information about named media, or NULL on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_show_media', None) or \
        _Cfunction('libvlc_vlm_show_media', ((1,), (1,),), string_result,
                    ctypes.c_void_p, Instance, ctypes.c_char_p)
    return f(p_instance, psz_name)

def libvlc_vlm_get_media_instance_position(p_instance, psz_name, i_instance):
    '''Get vlm_media instance position by name or instance id.
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: position as float or -1. on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_position', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_position', ((1,), (1,), (1,),), None,
                    ctypes.c_float, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_media_instance_time(p_instance, psz_name, i_instance):
    '''Get vlm_media instance time by name or instance id.
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: time as integer or -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_time', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_time', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_media_instance_length(p_instance, psz_name, i_instance):
    '''Get vlm_media instance length by name or instance id.
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: length of media item or -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_length', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_length', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_media_instance_rate(p_instance, psz_name, i_instance):
    '''Get vlm_media instance playback rate by name or instance id.
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: playback rate or -1 on error.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_rate', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_rate', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_media_instance_title(p_instance, psz_name, i_instance):
    '''Get vlm_media instance title number by name or instance id.
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: title as number or -1 on error.
    @bug: will always return 0.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_title', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_title', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_media_instance_chapter(p_instance, psz_name, i_instance):
    '''Get vlm_media instance chapter number by name or instance id.
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: chapter as number or -1 on error.
    @bug: will always return 0.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_chapter', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_chapter', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_media_instance_seekable(p_instance, psz_name, i_instance):
    '''Is libvlc instance seekable ?
    @param p_instance: a libvlc instance.
    @param psz_name: name of vlm media instance.
    @param i_instance: instance id.
    @return: 1 if seekable, 0 if not, -1 if media does not exist.
    @bug: will always return 0.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_media_instance_seekable', None) or \
        _Cfunction('libvlc_vlm_get_media_instance_seekable', ((1,), (1,), (1,),), None,
                    ctypes.c_int, Instance, ctypes.c_char_p, ctypes.c_int)
    return f(p_instance, psz_name, i_instance)

def libvlc_vlm_get_event_manager(p_instance):
    '''Get libvlc_event_manager from a vlm media.
    The p_event_manager is immutable, so you don't have to hold the lock.
    @param p_instance: a libvlc instance.
    @return: libvlc_event_manager.
    '''
    f = _Cfunctions.get('libvlc_vlm_get_event_manager', None) or \
        _Cfunction('libvlc_vlm_get_event_manager', ((1,),), class_result(EventManager),
                    ctypes.c_void_p, Instance)
    return f(p_instance)


# 4 function(s) blacklisted:
#  libvlc_audio_output_get_device_type
#  libvlc_audio_output_set_device_type
#  libvlc_printerr
#  libvlc_set_exit_handler

# 17 function(s) not wrapped as methods:
#  libvlc_audio_output_device_list_release
#  libvlc_audio_output_list_release
#  libvlc_clearerr
#  libvlc_clock
#  libvlc_errmsg
#  libvlc_event_type_name
#  libvlc_free
#  libvlc_get_changeset
#  libvlc_get_compiler
#  libvlc_get_version
#  libvlc_log_get_context
#  libvlc_log_get_object
#  libvlc_media_tracks_release
#  libvlc_module_description_list_release
#  libvlc_new
#  libvlc_track_description_list_release
#  libvlc_vprinterr

# Start of footer.py #

# Backward compatibility
def callbackmethod(callback):
    """Now obsolete @callbackmethod decorator."""
    return callback

# libvlc_free is not present in some versions of libvlc. If it is not
# in the library, then emulate it by calling libc.free
if not hasattr(dll, 'libvlc_free'):
    # need to find the free function in the C runtime. This is
    # platform specific.
    # For Linux and MacOSX
    libc_path = find_library('c')
    if libc_path:
        libc = ctypes.CDLL(libc_path)
        libvlc_free = libc.free
    else:
        # On win32, it is impossible to guess the proper lib to call
        # (msvcrt, mingw...). Just ignore the call: it will memleak,
        # but not prevent to run the application.
        def libvlc_free(p):
            pass

    # ensure argtypes is right, because default type of int won't work
    # on 64-bit systems
    libvlc_free.argtypes = [ ctypes.c_void_p ]

# Version functions
def _dot2int(v):
    '''(INTERNAL) Convert 'i.i.i[.i]' str to int.
    '''
    t = [int(i) for i in v.split('.')]
    if len(t) == 3:
        t.append(0)
    elif len(t) != 4:
        raise ValueError('"i.i.i[.i]": %r' % (v,))
    if min(t) < 0 or max(t) > 255:
        raise ValueError('[0..255]: %r' % (v,))
    i = t.pop(0)
    while t:
        i = (i << 8) + t.pop(0)
    return i

def hex_version():
    """Return the version of these bindings in hex or 0 if unavailable.
    """
    try:
        return _dot2int(__version__.split('-')[-1])
    except (NameError, ValueError):
        return 0

def libvlc_hex_version():
    """Return the libvlc version in hex or 0 if unavailable.
    """
    try:
        return _dot2int(bytes_to_str(libvlc_get_version()).split()[0])
    except ValueError:
        return 0


def debug_callback(event, *args, **kwds):
    '''Example callback, useful for debugging.
    '''
    l = ['event %s' % (event.type,)]
    if args:
        l.extend(map(str, args))
    if kwds:
        l.extend(sorted('%s=%s' % t for t in kwds.items()))
    print('Debug callback (%s)' % ', '.join(l))

if __name__ == '__main__':

    try:
        from msvcrt import getch
    except ImportError:
        import termios
        import tty

        def getch():  # getchar(), getc(stdin)  #PYCHOK flake
            fd = sys.stdin.fileno()
            old = termios.tcgetattr(fd)
            try:
                tty.setraw(fd)
                ch = sys.stdin.read(1)
            finally:
                termios.tcsetattr(fd, termios.TCSADRAIN, old)
            return ch

    def end_callback(event):
        print('End of media stream (event %s)' % event.type)
        sys.exit(0)

    echo_position = False
    def pos_callback(event, player):
        if echo_position:
            sys.stdout.write('\r%s to %.2f%% (%.2f%%)' % (event.type,
                                                          event.u.new_position * 100,
                                                          player.get_position() * 100))
            sys.stdout.flush()

    def print_version():
        """Print libvlc version"""
        try:
            print('Build date: %s (%#x)' % (build_date, hex_version()))
            print('LibVLC version: %s (%#x)' % (bytes_to_str(libvlc_get_version()), libvlc_hex_version()))
            print('LibVLC compiler: %s' % bytes_to_str(libvlc_get_compiler()))
            if plugin_path:
                print('Plugin path: %s' % plugin_path)
        except:
            print('Error: %s' % sys.exc_info()[1])

    if sys.argv[1:] and sys.argv[1] not in ('-h', '--help'):

        movie = os.path.expanduser(sys.argv[1])
        if not os.access(movie, os.R_OK):
            print('Error: %s file not readable' % movie)
            sys.exit(1)

        instance = Instance("--sub-source marq")
        try:
            media = instance.media_new(movie)
        except NameError:
            print('NameError: %s (%s vs LibVLC %s)' % (sys.exc_info()[1],
                                                       __version__,
                                                       libvlc_get_version()))
            sys.exit(1)
        player = instance.media_player_new()
        player.set_media(media)
        player.play()

        # Some marquee examples.  Marquee requires '--sub-source marq' in the
        # Instance() call above.  See <http://www.videolan.org/doc/play-howto/en/ch04.html>
        player.video_set_marquee_int(VideoMarqueeOption.Enable, 1)
        player.video_set_marquee_int(VideoMarqueeOption.Size, 24)  # pixels
        player.video_set_marquee_int(VideoMarqueeOption.Position, Position.Bottom)
        if False:  # only one marquee can be specified
            player.video_set_marquee_int(VideoMarqueeOption.Timeout, 5000)  # millisec, 0==forever
            t = media.get_mrl()  # movie
        else:  # update marquee text periodically
            player.video_set_marquee_int(VideoMarqueeOption.Timeout, 0)  # millisec, 0==forever
            player.video_set_marquee_int(VideoMarqueeOption.Refresh, 1000)  # millisec (or sec?)
            ##t = '$L / $D or $P at $T'
            t = '%Y-%m-%d  %H:%M:%S'
        player.video_set_marquee_string(VideoMarqueeOption.Text, str_to_bytes(t))

        # Some event manager examples.  Note, the callback can be any Python
        # callable and does not need to be decorated.  Optionally, specify
        # any number of positional and/or keyword arguments to be passed
        # to the callback (in addition to the first one, an Event instance).
        event_manager = player.event_manager()
        event_manager.event_attach(EventType.MediaPlayerEndReached,      end_callback)
        event_manager.event_attach(EventType.MediaPlayerPositionChanged, pos_callback, player)

        def mspf():
            """Milliseconds per frame."""
            return int(1000 // (player.get_fps() or 25))

        def print_info():
            """Print information about the media"""
            try:
                print_version()
                media = player.get_media()
                print('State: %s' % player.get_state())
                print('Media: %s' % bytes_to_str(media.get_mrl()))
                print('Track: %s/%s' % (player.video_get_track(), player.video_get_track_count()))
                print('Current time: %s/%s' % (player.get_time(), media.get_duration()))
                print('Position: %s' % player.get_position())
                print('FPS: %s (%d ms)' % (player.get_fps(), mspf()))
                print('Rate: %s' % player.get_rate())
                print('Video size: %s' % str(player.video_get_size(0)))  # num=0
                print('Scale: %s' % player.video_get_scale())
                print('Aspect ratio: %s' % player.video_get_aspect_ratio())
               #print('Window:' % player.get_hwnd()
            except Exception:
                print('Error: %s' % sys.exc_info()[1])

        def sec_forward():
            """Go forward one sec"""
            player.set_time(player.get_time() + 1000)

        def sec_backward():
            """Go backward one sec"""
            player.set_time(player.get_time() - 1000)

        def frame_forward():
            """Go forward one frame"""
            player.set_time(player.get_time() + mspf())

        def frame_backward():
            """Go backward one frame"""
            player.set_time(player.get_time() - mspf())

        def print_help():
            """Print help"""
            print('Single-character commands:')
            for k, m in sorted(keybindings.items()):
                m = (m.__doc__ or m.__name__).splitlines()[0]
                print('  %s: %s.' % (k, m.rstrip('.')))
            print('0-9: go to that fraction of the movie')

        def quit_app():
            """Stop and exit"""
            sys.exit(0)

        def toggle_echo_position():
            """Toggle echoing of media position"""
            global echo_position
            echo_position = not echo_position

        keybindings = {
            ' ': player.pause,
            '+': sec_forward,
            '-': sec_backward,
            '.': frame_forward,
            ',': frame_backward,
            'f': player.toggle_fullscreen,
            'i': print_info,
            'p': toggle_echo_position,
            'q': quit_app,
            '?': print_help,
            }

        print('Press q to quit, ? to get help.%s' % os.linesep)
        while True:
            k = getch()
            print('> %s' % k)
            if k in keybindings:
                keybindings[k]()
            elif k.isdigit():
                 # jump to fraction of the movie.
                player.set_position(float('0.'+k))

    else:
        print('Usage: %s <movie_filename>' % sys.argv[0])
        print('Once launched, type ? for help.')
        print('')
        print_version()

########NEW FILE########
__FILENAME__ = locate-python
#!/usr/bin/env python
#
# Written by Lipu Fei, 2014-01-29
#
# This file prints the directory where Python is installed.
#
import os
import sys

if __name__ == "__main__":
    print os.path.abspath(os.path.dirname(sys.executable))
########NEW FILE########
