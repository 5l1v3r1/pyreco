__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# python-gearman documentation build configuration file, created by
# sphinx-quickstart on Wed Aug 25 14:44:14 2010.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))
import gearman

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'python-gearman'
copyright = u'2010, Matthew Tai'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = gearman.__version__
# The full version, including alpha/beta/rc tags.
release = gearman.__version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'python-gearmandoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'python-gearman.tex', u'python-gearman Documentation',
   u'Matthew Tai, Eskil Olsen', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'python-gearman', u'python-gearman Documentation',
     [u'Matthew Tai, Eskil Olsen'], 1)
]

########NEW FILE########
__FILENAME__ = admin_client
import logging
import time

from gearman import util

from gearman.connection_manager import GearmanConnectionManager
from gearman.admin_client_handler import GearmanAdminClientCommandHandler
from gearman.errors import ConnectionError, InvalidAdminClientState, ServerUnavailable
from gearman.protocol import GEARMAN_COMMAND_ECHO_RES, GEARMAN_COMMAND_ECHO_REQ, \
    GEARMAN_SERVER_COMMAND_STATUS, GEARMAN_SERVER_COMMAND_VERSION, GEARMAN_SERVER_COMMAND_WORKERS, \
    GEARMAN_SERVER_COMMAND_MAXQUEUE, GEARMAN_SERVER_COMMAND_SHUTDOWN, GEARMAN_SERVER_COMMAND_GETPID, \
    GEARMAN_SERVER_COMMAND_CANCEL_JOB, GEARMAN_SERVER_COMMAND_SHOW_JOBS, GEARMAN_SERVER_COMMAND_SHOW_UNIQUE_JOBS

gearman_logger = logging.getLogger(__name__)

ECHO_STRING = "ping? pong!"
DEFAULT_ADMIN_CLIENT_TIMEOUT = 10.0

class GearmanAdminClient(GearmanConnectionManager):
    """GearmanAdminClient :: Interface to send/receive administrative commands to a Gearman server

    This client acts as a BLOCKING client and each call will poll until it receives a satisfactory server response

    http://gearman.org/index.php?id=protocol
    See section 'Administrative Protocol'
    """
    command_handler_class = GearmanAdminClientCommandHandler

    def __init__(self, host_list=None, poll_timeout=DEFAULT_ADMIN_CLIENT_TIMEOUT):
        super(GearmanAdminClient, self).__init__(host_list=host_list)
        self.poll_timeout = poll_timeout

        self.current_connection = util.unlist(self.connection_list)
        self.current_handler = None

    def establish_admin_connection(self):
        try:
            self.establish_connection(self.current_connection)
        except ConnectionError:
            raise ServerUnavailable('Found no valid connections in list: %r' % self.connection_list)

        self.current_handler = self.connection_to_handler_map[self.current_connection]

    def ping_server(self):
        """Sends off a debugging string to execute an application ping on the Gearman server"""
        start_time = time.time()

        self.establish_admin_connection()
        self.current_handler.send_echo_request(ECHO_STRING)
        server_response = self.wait_until_server_responds(GEARMAN_COMMAND_ECHO_REQ)
        if server_response != ECHO_STRING:
            raise InvalidAdminClientState("Echo string mismatch: got %s, expected %s" % (server_response, ECHO_STRING))

        elapsed_time = time.time() - start_time
        return elapsed_time

    def send_maxqueue(self, task, max_size):
        """Sends a request to change the maximum queue size for a given task"""

        self.establish_admin_connection()
        self.current_handler.send_text_command('%s %s %s' % (GEARMAN_SERVER_COMMAND_MAXQUEUE, task, max_size))
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_MAXQUEUE)

    def send_shutdown(self, graceful=True):
        """Sends a request to shutdown the connected gearman server"""
        actual_command = GEARMAN_SERVER_COMMAND_SHUTDOWN
        if graceful:
            actual_command += ' graceful'

        self.establish_admin_connection()
        self.current_handler.send_text_command(actual_command)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_SHUTDOWN)

    def get_status(self):
        """Retrieves a list of all registered tasks and reports how many items/workers are in the queue"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_STATUS)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_STATUS)

    def get_version(self):
        """Retrieves the version number of the Gearman server"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_VERSION)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_VERSION)

    def get_workers(self):
        """Retrieves a list of workers and reports what tasks they're operating on"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_WORKERS)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_WORKERS)

    def wait_until_server_responds(self, expected_type):
        current_handler = self.current_handler
        def continue_while_no_response(any_activity):
            return (not current_handler.response_ready)

        self.poll_connections_until_stopped([self.current_connection], continue_while_no_response, timeout=self.poll_timeout)
        if not self.current_handler.response_ready:
            raise InvalidAdminClientState('Admin client timed out after %f second(s)' % self.poll_timeout)

        cmd_type, cmd_resp = self.current_handler.pop_response()
        if cmd_type != expected_type:
            raise InvalidAdminClientState('Received an unexpected response... got command %r, expecting command %r' % (cmd_type, expected_type))

        return cmd_resp

    def get_pid(self):
        """Retrieves the process ID"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_GETPID)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_GETPID)

    def cancel_job(self, handle):
        """Cancels a job"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_CANCEL_JOB+" "+handle)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_CANCEL_JOB)

    def get_jobs(self):
        """Retrieves a list of jobs"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_SHOW_JOBS)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_SHOW_JOBS)

    def get_unique_jobs(self):
        """Retrieves a list of unique jobs"""
        self.establish_admin_connection()
        self.current_handler.send_text_command(GEARMAN_SERVER_COMMAND_SHOW_UNIQUE_JOBS)
        return self.wait_until_server_responds(GEARMAN_SERVER_COMMAND_SHOW_UNIQUE_JOBS)

########NEW FILE########
__FILENAME__ = admin_client_handler
import collections
import logging

from gearman.command_handler import GearmanCommandHandler
from gearman.errors import ProtocolError, InvalidAdminClientState
from gearman.protocol import GEARMAN_COMMAND_ECHO_REQ, GEARMAN_COMMAND_TEXT_COMMAND, \
    GEARMAN_SERVER_COMMAND_STATUS, GEARMAN_SERVER_COMMAND_VERSION, \
    GEARMAN_SERVER_COMMAND_WORKERS, GEARMAN_SERVER_COMMAND_MAXQUEUE, GEARMAN_SERVER_COMMAND_SHUTDOWN, \
    GEARMAN_SERVER_COMMAND_GETPID, GEARMAN_SERVER_COMMAND_SHOW_JOBS, GEARMAN_SERVER_COMMAND_CANCEL_JOB, \
    GEARMAN_SERVER_COMMAND_SHOW_UNIQUE_JOBS

gearman_logger = logging.getLogger(__name__)

EXPECTED_GEARMAN_SERVER_COMMANDS = set([GEARMAN_SERVER_COMMAND_STATUS, GEARMAN_SERVER_COMMAND_VERSION, \
    GEARMAN_SERVER_COMMAND_WORKERS, GEARMAN_SERVER_COMMAND_MAXQUEUE, GEARMAN_SERVER_COMMAND_SHUTDOWN, \
    GEARMAN_SERVER_COMMAND_GETPID, GEARMAN_SERVER_COMMAND_SHOW_JOBS, GEARMAN_SERVER_COMMAND_CANCEL_JOB, \
    GEARMAN_SERVER_COMMAND_SHOW_UNIQUE_JOBS])

class GearmanAdminClientCommandHandler(GearmanCommandHandler):
    """Special GEARMAN_COMMAND_TEXT_COMMAND command handler that'll parse text responses from the server"""
    STATUS_FIELDS = 4
    WORKERS_FIELDS = 4
    JOB_FIELDS = 4
    UNIQUE_JOB_FIELDS = 1

    def __init__(self, connection_manager=None):
        super(GearmanAdminClientCommandHandler, self).__init__(connection_manager=connection_manager)
        self._sent_commands = collections.deque()
        self._recv_responses = collections.deque()

        self._status_response = []
        self._workers_response = []

    #######################################################################
    ##### Public interface methods to be called by GearmanAdminClient #####
    #######################################################################

    @property
    def response_ready(self):
        return bool(self._recv_responses)

    def pop_response(self):
        if not self._sent_commands or not self._recv_responses:
            raise InvalidAdminClientState('Attempted to pop a response for a command that is not ready')

        sent_command = self._sent_commands.popleft()
        recv_response = self._recv_responses.popleft()
        return sent_command, recv_response

    def send_text_command(self, command_line):
        """Send our administrative text command"""
        expected_server_command = None
        for server_command in EXPECTED_GEARMAN_SERVER_COMMANDS:
            if command_line.startswith(server_command):
                expected_server_command = server_command
                break

        if not expected_server_command:
            raise ProtocolError('Attempted to send an unknown server command: %r' % command_line)

        self._sent_commands.append(expected_server_command)

        output_text = '%s\n' % command_line
        self.send_command(GEARMAN_COMMAND_TEXT_COMMAND, raw_text=output_text)

    def send_echo_request(self, echo_string):
        """Send our administrative text command"""
        self._sent_commands.append(GEARMAN_COMMAND_ECHO_REQ)

        self.send_command(GEARMAN_COMMAND_ECHO_REQ, data=echo_string)

    ###########################################################
    ### Callbacks when we receive a command from the server ###
    ###########################################################

    def recv_echo_res(self, data):
        self._recv_responses.append(data)
        return False

    def recv_text_command(self, raw_text):
        """Catch GEARMAN_COMMAND_TEXT_COMMAND's and forward them onto their respective recv_server_* callbacks"""
        if not self._sent_commands:
            raise InvalidAdminClientState('Received an unexpected server response')

        # Peek at the first command
        cmd = self._sent_commands[0]
        cmd_type = cmd.replace(" ", "_")
        recv_server_command_function_name = 'recv_server_%s' % cmd_type

        cmd_callback = getattr(self, recv_server_command_function_name, None)
        if not cmd_callback:
            gearman_logger.error('Could not handle command: %r - %r' % (cmd_type, raw_text))
            raise ValueError('Could not handle command: %r - %r' % (cmd_type, raw_text))

        # This must match the parameter names as defined in the command handler
        completed_work = cmd_callback(raw_text)
        return completed_work

    def recv_server_status(self, raw_text):
        """Slowly assemble a server status message line by line"""
        # If we received a '.', we've finished parsing this status message
        # Pack up our output and reset our response queue
        if raw_text == '.':
            output_response = tuple(self._status_response)
            self._recv_responses.append(output_response)
            self._status_response = []
            return False

        # If we didn't get a final response, split our line and interpret all the data
        split_tokens = raw_text.split('\t')
        if len(split_tokens) != self.STATUS_FIELDS:
            raise ProtocolError('Received %d tokens, expected %d tokens: %r' % (len(split_tokens), self.STATUS_FIELDS, split_tokens))

        # Label our fields and make the results Python friendly
        task, queued_count, running_count, worker_count = split_tokens

        status_dict = {}
        status_dict['task'] = task
        status_dict['queued'] = int(queued_count)
        status_dict['running'] = int(running_count)
        status_dict['workers'] = int(worker_count)
        self._status_response.append(status_dict)
        return True

    def recv_server_version(self, raw_text):
        """Version response is a simple passthrough"""
        self._recv_responses.append(raw_text)
        return False

    def recv_server_workers(self, raw_text):
        """Slowly assemble a server workers message line by line"""
        # If we received a '.', we've finished parsing this workers message
        # Pack up our output and reset our response queue
        if raw_text == '.':
            output_response = tuple(self._workers_response)
            self._recv_responses.append(output_response)
            self._workers_response = []
            return False

        split_tokens = raw_text.split(' ')
        if len(split_tokens) < self.WORKERS_FIELDS:
            raise ProtocolError('Received %d tokens, expected >= 4 tokens: %r' % (len(split_tokens), split_tokens))

        if split_tokens[3] != ':':
            raise ProtocolError('Malformed worker response: %r' % (split_tokens, ))

        # Label our fields and make the results Python friendly
        worker_dict = {}
        worker_dict['file_descriptor'] = split_tokens[0]
        worker_dict['ip'] = split_tokens[1]
        worker_dict['client_id'] = split_tokens[2]
        worker_dict['tasks'] = tuple(split_tokens[4:])
        self._workers_response.append(worker_dict)
        return True

    def recv_server_maxqueue(self, raw_text):
        """Maxqueue response is a simple passthrough"""
        if raw_text != 'OK':
            raise ProtocolError("Expected 'OK', received: %s" % raw_text)

        self._recv_responses.append(raw_text)
        return False

    def recv_server_shutdown(self, raw_text):
        """Shutdown response is a simple passthrough"""
        self._recv_responses.append(None)
        return False
    
    def recv_server_getpid(self, raw_text):
        """PID response is a simple passthrough"""
        self._recv_responses.append(raw_text)
        return False

    def recv_server_show_jobs(self, raw_text):
        """Slowly assemble a show jobs message line by line"""
        # If we received a '.', we've finished parsing this status message
        # Pack up our output and reset our response queue
        if raw_text == '.':
            output_response = tuple(self._status_response)
            self._recv_responses.append(output_response)
            self._status_response = []
            return False

        # If we didn't get a final response, split our line and interpret all the data
        split_tokens = raw_text.split('\t')
        if len(split_tokens) != self.JOB_FIELDS:
            raise ProtocolError('Received %d tokens, expected %d tokens: %r' % (len(split_tokens), self.JOB_FIELDS, split_tokens))

        # Label our fields and make the results Python friendly
        handle, queued_count, canceled_count, enabled_count = split_tokens

        job_dict = {}
        job_dict['handle'] = handle
        job_dict['queued'] = int(queued_count)
        job_dict['canceled'] = int(canceled_count)
        job_dict['enabled'] = int(enabled_count)
        self._status_response.append(job_dict)
        return True

    def recv_server_cancel_job(self, raw_text):
        """Cancel job response is a simple passthrough"""
        self._recv_responses.append(raw_text)
        return False

    def recv_server_show_unique_jobs(self, raw_text):
        """Slowly assemble a server show unique jobs message line by line"""
        # If we received a '.', we've finished parsing this status message
        # Pack up our output and reset our response queue
        if raw_text == '.':
            output_response = tuple(self._status_response)
            self._recv_responses.append(output_response)
            self._status_response = []
            return False

        # If we didn't get a final response, split our line and interpret all the data
        split_tokens = raw_text.split('\t')
        if len(split_tokens) != self.UNIQUE_JOB_FIELDS:
            raise ProtocolError('Received %d tokens, expected %d tokens: %r' % (len(split_tokens), self.UNIQUE_JOB_FIELDS, split_tokens))

        # Label our fields and make the results Python friendly
        unique = split_tokens

        job_dict = {}
        job_dict['unique'] = unique
        self._status_response.append(job_dict)
        return True

########NEW FILE########
__FILENAME__ = client
import collections
from gearman import compat
import logging
import os
import random
import weakref

import gearman.util

from gearman.connection_manager import GearmanConnectionManager
from gearman.client_handler import GearmanClientCommandHandler
from gearman.constants import PRIORITY_NONE, PRIORITY_LOW, PRIORITY_HIGH, JOB_UNKNOWN, JOB_PENDING
from gearman.errors import ConnectionError, ExceededConnectionAttempts, ServerUnavailable

gearman_logger = logging.getLogger(__name__)

# This number must be <= GEARMAN_UNIQUE_SIZE in gearman/libgearman/constants.h
RANDOM_UNIQUE_BYTES = 16

class GearmanClient(GearmanConnectionManager):
    """
    GearmanClient :: Interface to submit jobs to a Gearman server
    """
    command_handler_class = GearmanClientCommandHandler

    def __init__(self, host_list=None, random_unique_bytes=RANDOM_UNIQUE_BYTES):
        super(GearmanClient, self).__init__(host_list=host_list)

        self.random_unique_bytes = random_unique_bytes

        # The authoritative copy of all requests that this client knows about
        # Ignores the fact if a request has been bound to a connection or not
        self.request_to_rotating_connection_queue = weakref.WeakKeyDictionary(compat.defaultdict(collections.deque))

    def submit_job(self, task, data, unique=None, priority=PRIORITY_NONE, background=False, wait_until_complete=True, max_retries=0, poll_timeout=None):
        """Submit a single job to any gearman server"""
        job_info = dict(task=task, data=data, unique=unique, priority=priority)
        completed_job_list = self.submit_multiple_jobs([job_info], background=background, wait_until_complete=wait_until_complete, max_retries=max_retries, poll_timeout=poll_timeout)
        return gearman.util.unlist(completed_job_list)

    def submit_multiple_jobs(self, jobs_to_submit, background=False, wait_until_complete=True, max_retries=0, poll_timeout=None):
        """Takes a list of jobs_to_submit with dicts of

        {'task': task, 'data': data, 'unique': unique, 'priority': priority}
        """
        assert type(jobs_to_submit) in (list, tuple, set), "Expected multiple jobs, received 1?"

        # Convert all job dicts to job request objects
        requests_to_submit = [self._create_request_from_dictionary(job_info, background=background, max_retries=max_retries) for job_info in jobs_to_submit]

        return self.submit_multiple_requests(requests_to_submit, wait_until_complete=wait_until_complete, poll_timeout=poll_timeout)

    def submit_multiple_requests(self, job_requests, wait_until_complete=True, poll_timeout=None):
        """Take GearmanJobRequests, assign them connections, and request that they be done.

        * Blocks until our jobs are accepted (should be fast) OR times out
        * Optionally blocks until jobs are all complete

        You MUST check the status of your requests after calling this function as "timed_out" or "state == JOB_UNKNOWN" maybe True
        """
        assert type(job_requests) in (list, tuple, set), "Expected multiple job requests, received 1?"
        stopwatch = gearman.util.Stopwatch(poll_timeout)

        # We should always wait until our job is accepted, this should be fast
        time_remaining = stopwatch.get_time_remaining()
        processed_requests = self.wait_until_jobs_accepted(job_requests, poll_timeout=time_remaining)

        # Optionally, we'll allow a user to wait until all jobs are complete with the same poll_timeout
        time_remaining = stopwatch.get_time_remaining()
        if wait_until_complete and bool(time_remaining != 0.0):
            processed_requests = self.wait_until_jobs_completed(processed_requests, poll_timeout=time_remaining)

        return processed_requests

    def wait_until_jobs_accepted(self, job_requests, poll_timeout=None):
        """Go into a select loop until all our jobs have moved to STATE_PENDING"""
        assert type(job_requests) in (list, tuple, set), "Expected multiple job requests, received 1?"

        def is_request_pending(current_request):
            return bool(current_request.state == JOB_PENDING)

        # Poll until we know we've gotten acknowledgement that our job's been accepted
        # If our connection fails while we're waiting for it to be accepted, automatically retry right here
        def continue_while_jobs_pending(any_activity):
            for current_request in job_requests:
                if current_request.state == JOB_UNKNOWN:
                    self.send_job_request(current_request)

            return compat.any(is_request_pending(current_request) for current_request in job_requests)

        self.poll_connections_until_stopped(self.connection_list, continue_while_jobs_pending, timeout=poll_timeout)

        # Mark any job still in the queued state to poll_timeout
        for current_request in job_requests:
            current_request.timed_out = is_request_pending(current_request)

        return job_requests

    def wait_until_jobs_completed(self, job_requests, poll_timeout=None):
        """Go into a select loop until all our jobs have completed or failed"""
        assert type(job_requests) in (list, tuple, set), "Expected multiple job requests, received 1?"

        def is_request_incomplete(current_request):
            return not current_request.complete

        # Poll until we get responses for all our functions
        # Do NOT attempt to auto-retry connection failures as we have no idea how for a worker got
        def continue_while_jobs_incomplete(any_activity):
            for current_request in job_requests:
                if is_request_incomplete(current_request) and current_request.state != JOB_UNKNOWN:
                    return True

            return False

        self.poll_connections_until_stopped(self.connection_list, continue_while_jobs_incomplete, timeout=poll_timeout)

        # Mark any job still in the queued state to poll_timeout
        for current_request in job_requests:
            current_request.timed_out = is_request_incomplete(current_request)

            if not current_request.timed_out:
                self.request_to_rotating_connection_queue.pop(current_request, None)

        return job_requests

    def get_job_status(self, current_request, poll_timeout=None):
        """Fetch the job status of a single request"""
        request_list = self.get_job_statuses([current_request], poll_timeout=poll_timeout)
        return gearman.util.unlist(request_list)

    def get_job_statuses(self, job_requests, poll_timeout=None):
        """Fetch the job status of a multiple requests"""
        assert type(job_requests) in (list, tuple, set), "Expected multiple job requests, received 1?"
        for current_request in job_requests:
            current_request.status['last_time_received'] = current_request.status.get('time_received')

            current_connection = current_request.job.connection
            current_command_handler = self.connection_to_handler_map[current_connection]

            current_command_handler.send_get_status_of_job(current_request)

        return self.wait_until_job_statuses_received(job_requests, poll_timeout=poll_timeout)

    def wait_until_job_statuses_received(self, job_requests, poll_timeout=None):
        """Go into a select loop until we received statuses on all our requests"""
        assert type(job_requests) in (list, tuple, set), "Expected multiple job requests, received 1?"
        def is_status_not_updated(current_request):
            current_status = current_request.status
            return bool(current_status.get('time_received') == current_status.get('last_time_received'))

        # Poll to make sure we send out our request for a status update
        def continue_while_status_not_updated(any_activity):
            for current_request in job_requests:
                if is_status_not_updated(current_request) and current_request.state != JOB_UNKNOWN:
                    return True

            return False

        self.poll_connections_until_stopped(self.connection_list, continue_while_status_not_updated, timeout=poll_timeout)

        for current_request in job_requests:
            current_request.status = current_request.status or {}
            current_request.timed_out = is_status_not_updated(current_request)

        return job_requests

    def _create_request_from_dictionary(self, job_info, background=False, max_retries=0):
        """Takes a dictionary with fields  {'task': task, 'unique': unique, 'data': data, 'priority': priority, 'background': background}"""
        # Make sure we have a unique identifier for ALL our tasks
        job_unique = job_info.get('unique')
        if not job_unique:
            job_unique = os.urandom(self.random_unique_bytes).encode('hex')

        current_job = self.job_class(connection=None, handle=None, task=job_info['task'], unique=job_unique, data=job_info['data'])

        initial_priority = job_info.get('priority', PRIORITY_NONE)

        max_attempts = max_retries + 1
        current_request = self.job_request_class(current_job, initial_priority=initial_priority, background=background, max_attempts=max_attempts)
        return current_request

    def establish_request_connection(self, current_request):
        """Return a live connection for the given hash"""
        # We'll keep track of the connections we're attempting to use so if we ever have to retry, we can use this history
        rotating_connections = self.request_to_rotating_connection_queue.get(current_request, None)
        if not rotating_connections:
            shuffled_connection_list = list(self.connection_list)
            random.shuffle(shuffled_connection_list)

            rotating_connections = collections.deque(shuffled_connection_list)
            self.request_to_rotating_connection_queue[current_request] = rotating_connections

        failed_connections = 0
        chosen_connection = None
        for possible_connection in rotating_connections:
            try:
                chosen_connection = self.establish_connection(possible_connection)
                break
            except ConnectionError:
                # Rotate our server list so we'll skip all our broken servers
                failed_connections += 1

        if not chosen_connection:
            raise ServerUnavailable('Found no valid connections: %r' % self.connection_list)

        # Rotate our server list so we'll skip all our broken servers
        rotating_connections.rotate(-failed_connections)
        return chosen_connection

    def send_job_request(self, current_request):
        """Attempt to send out a job request"""
        if current_request.connection_attempts >= current_request.max_connection_attempts:
            raise ExceededConnectionAttempts('Exceeded %d connection attempt(s) :: %r' % (current_request.max_connection_attempts, current_request))

        chosen_connection = self.establish_request_connection(current_request)

        current_request.job.connection = chosen_connection
        current_request.connection_attempts += 1
        current_request.timed_out = False

        current_command_handler = self.connection_to_handler_map[chosen_connection]
        current_command_handler.send_job_request(current_request)
        return current_request

########NEW FILE########
__FILENAME__ = client_handler
import collections
import time
import logging
import weakref

from gearman.command_handler import GearmanCommandHandler
from gearman.constants import JOB_UNKNOWN, JOB_PENDING, JOB_CREATED, JOB_FAILED, JOB_COMPLETE
from gearman.errors import InvalidClientState
from gearman.protocol import GEARMAN_COMMAND_GET_STATUS, submit_cmd_for_background_priority

gearman_logger = logging.getLogger(__name__)

class GearmanClientCommandHandler(GearmanCommandHandler):
    """Maintains the state of this connection on behalf of a GearmanClient"""
    def __init__(self, connection_manager=None):
        super(GearmanClientCommandHandler, self).__init__(connection_manager=connection_manager)

        # When we first submit jobs, we don't have a handle assigned yet... these handles will be returned in the order of submission
        self.requests_awaiting_handles = collections.deque()
        self.handle_to_request_map = weakref.WeakValueDictionary()

    ##################################################################
    ##### Public interface methods to be called by GearmanClient #####
    ##################################################################
    def send_job_request(self, current_request):
        """Register a newly created job request"""
        self._assert_request_state(current_request, JOB_UNKNOWN)

        gearman_job = current_request.job

        # Handle the I/O for requesting a job - determine which COMMAND we need to send
        cmd_type = submit_cmd_for_background_priority(current_request.background, current_request.priority)

        outbound_data = self.encode_data(gearman_job.data)
        self.send_command(cmd_type, task=gearman_job.task, unique=gearman_job.unique, data=outbound_data)

        # Once this command is sent, our request needs to wait for a handle
        current_request.state = JOB_PENDING

        self.requests_awaiting_handles.append(current_request)

    def send_get_status_of_job(self, current_request):
        """Forward the status of a job"""
        self._register_request(current_request)
        self.send_command(GEARMAN_COMMAND_GET_STATUS, job_handle=current_request.job.handle)

    def on_io_error(self):
        for pending_request in self.requests_awaiting_handles:
            pending_request.state = JOB_UNKNOWN

        for inflight_request in self.handle_to_request_map.itervalues():
            inflight_request.state = JOB_UNKNOWN

    def _register_request(self, current_request):
        self.handle_to_request_map[current_request.job.handle] = current_request

    ##################################################################
    ## Gearman command callbacks with kwargs defined by protocol.py ##
    ##################################################################
    def _assert_request_state(self, current_request, expected_state):
        if current_request.state != expected_state:
            raise InvalidClientState('Expected handle (%s) to be in state %r, got %r' % (current_request.job.handle, expected_state, current_request.state))

    def recv_job_created(self, job_handle):
        if not self.requests_awaiting_handles:
            raise InvalidClientState('Received a job_handle with no pending requests')

        # If our client got a JOB_CREATED, our request now has a server handle
        current_request = self.requests_awaiting_handles.popleft()
        self._assert_request_state(current_request, JOB_PENDING)

        # Update the state of this request
        current_request.job.handle = job_handle
        current_request.state = JOB_CREATED
        self._register_request(current_request)

        return True

    def recv_work_data(self, job_handle, data):
        # Queue a WORK_DATA update
        current_request = self.handle_to_request_map[job_handle]
        self._assert_request_state(current_request, JOB_CREATED)

        current_request.data_updates.append(self.decode_data(data))

        return True

    def recv_work_warning(self, job_handle, data):
        # Queue a WORK_WARNING update
        current_request = self.handle_to_request_map[job_handle]
        self._assert_request_state(current_request, JOB_CREATED)

        current_request.warning_updates.append(self.decode_data(data))

        return True

    def recv_work_status(self, job_handle, numerator, denominator):
        # Queue a WORK_STATUS update
        current_request = self.handle_to_request_map[job_handle]
        self._assert_request_state(current_request, JOB_CREATED)

        # The protocol spec is ambiguous as to what type the numerator and denominator is...
        # But according to Eskil, gearmand interprets these as integers
        current_request.status = {
            'handle': job_handle,
            'known': True,
            'running': True,
            'numerator': int(numerator),
            'denominator': int(denominator),
            'time_received': time.time()
        }
        return True

    def recv_work_complete(self, job_handle, data):
        # Update the state of our request and store our returned result
        current_request = self.handle_to_request_map[job_handle]
        self._assert_request_state(current_request, JOB_CREATED)

        current_request.result = self.decode_data(data)
        current_request.state = JOB_COMPLETE

        return True

    def recv_work_fail(self, job_handle):
        # Update the state of our request and mark this job as failed
        current_request = self.handle_to_request_map[job_handle]
        self._assert_request_state(current_request, JOB_CREATED)

        current_request.state = JOB_FAILED

        return True

    def recv_work_exception(self, job_handle, data):
        # Using GEARMAND_COMMAND_WORK_EXCEPTION is not recommended at time of this writing [2010-02-24]
        # http://groups.google.com/group/gearman/browse_thread/thread/5c91acc31bd10688/529e586405ed37fe
        #
        current_request = self.handle_to_request_map[job_handle]
        self._assert_request_state(current_request, JOB_CREATED)

        current_request.exception = self.decode_data(data)

        return True

    def recv_status_res(self, job_handle, known, running, numerator, denominator):
        # If we received a STATUS_RES update about this request, update our known status
        current_request = self.handle_to_request_map[job_handle]

        job_known = bool(known == '1')
        # Make our status response Python friendly
        current_request.status = {
            'handle': job_handle,
            'known': job_known,
            'running': bool(running == '1'),
            'numerator': int(numerator),
            'denominator': int(denominator),
            'time_received': time.time()
        }

        return True

########NEW FILE########
__FILENAME__ = command_handler
import logging
from gearman.errors import UnknownCommandError
from gearman.protocol import get_command_name

gearman_logger = logging.getLogger(__name__)

class GearmanCommandHandler(object):
    """A command handler manages the state which we should be in given a certain stream of commands

    GearmanCommandHandler does no I/O and only understands sending/receiving commands
    """
    def __init__(self, connection_manager=None):
        self.connection_manager = connection_manager

    def initial_state(self, *largs, **kwargs):
        """Called by a Connection Manager after we've been instantiated and we're ready to send off commands"""
        pass

    def on_io_error(self):
        pass

    def decode_data(self, data):
        """Convenience function :: handle binary string -> object unpacking"""
        return self.connection_manager.data_encoder.decode(data)

    def encode_data(self, data):
        """Convenience function :: handle object -> binary string packing"""
        return self.connection_manager.data_encoder.encode(data)

    def fetch_commands(self):
        """Called by a Connection Manager to notify us that we have pending commands"""
        continue_working = True
        while continue_working:
            cmd_tuple = self.connection_manager.read_command(self)
            if cmd_tuple is None:
                break

            cmd_type, cmd_args = cmd_tuple
            continue_working = self.recv_command(cmd_type, **cmd_args)

    def send_command(self, cmd_type, **cmd_args):
        """Hand off I/O to the connection mananger"""
        self.connection_manager.send_command(self, cmd_type, cmd_args)

    def recv_command(self, cmd_type, **cmd_args):
        """Maps any command to a recv_* callback function"""
        completed_work = None

        gearman_command_name = get_command_name(cmd_type)
        if bool(gearman_command_name == cmd_type) or not gearman_command_name.startswith('GEARMAN_COMMAND_'):
            unknown_command_msg = 'Could not handle command: %r - %r' % (gearman_command_name, cmd_args)
            gearman_logger.error(unknown_command_msg)
            raise ValueError(unknown_command_msg)

        recv_command_function_name = gearman_command_name.lower().replace('gearman_command_', 'recv_')

        cmd_callback = getattr(self, recv_command_function_name, None)
        if not cmd_callback:
            missing_callback_msg = 'Could not handle command: %r - %r' % (get_command_name(cmd_type), cmd_args)
            gearman_logger.error(missing_callback_msg)
            raise UnknownCommandError(missing_callback_msg)

        # Expand the arguments as passed by the protocol
        # This must match the parameter names as defined in the command handler
        completed_work = cmd_callback(**cmd_args)
        return completed_work

    def recv_error(self, error_code, error_text):
        """When we receive an error from the server, notify the connection manager that we have a gearman error"""
        return self.connection_manager.on_gearman_error(error_code, error_text)

########NEW FILE########
__FILENAME__ = compat
"""
Gearman compatibility module
"""

# Required for python2.4 backward compatibilty
# Add a module attribute called "any" which is equivalent to "any"
try:
    any = any
except NameError:
    def any(iterable):
        """Return True if any element of the iterable is true. If the iterable is empty, return False"""
        for element in iterable:
            if element:
                return True
        return False

# Required for python2.4 backward compatibilty
# Add a module attribute called "all" which is equivalent to "all"
try:
    all = all
except NameError:
    def all(iterable):
        """Return True if all elements of the iterable are true (or if the iterable is empty)"""
        for element in iterable:
            if not element:
                return False
        return True

# Required for python2.4 backward compatibilty
# Add a class called "defaultdict" which is equivalent to "collections.defaultdict"
try:
    from collections import defaultdict
except ImportError:
    class defaultdict(dict):
        """A pure-Python version of Python 2.5's defaultdict
        taken from http://code.activestate.com/recipes/523034-emulate-collectionsdefaultdict/"""
        def __init__(self, default_factory=None, * a, ** kw):
            if (default_factory is not None and
                not hasattr(default_factory, '__call__')):
                raise TypeError('first argument must be callable')
            dict.__init__(self, * a, ** kw)
            self.default_factory = default_factory
        def __getitem__(self, key):
            try:
                return dict.__getitem__(self, key)
            except KeyError:
                return self.__missing__(key)
        def __missing__(self, key):
            if self.default_factory is None:
                raise KeyError(key)
            self[key] = value = self.default_factory()
            return value
        def __reduce__(self):
            if self.default_factory is None:
                args = tuple()
            else:
                args = self.default_factory,
            return type(self), args, None, None, self.items()
        def copy(self):
            return self.__copy__()
        def __copy__(self):
            return type(self)(self.default_factory, self)
        def __deepcopy__(self, memo):
            import copy
            return type(self)(self.default_factory,
                              copy.deepcopy(self.items()))
        def __repr__(self):
            return 'defaultdict(%s, %s)' % (self.default_factory,
                                            dict.__repr__(self))

########NEW FILE########
__FILENAME__ = connection
import array
import collections
import logging
import socket
import ssl
import struct
import time

from gearman.errors import ConnectionError, ProtocolError, ServerUnavailable
from gearman.constants import DEFAULT_GEARMAN_PORT, _DEBUG_MODE_
from gearman.protocol import GEARMAN_PARAMS_FOR_COMMAND, GEARMAN_COMMAND_TEXT_COMMAND, NULL_CHAR, \
    get_command_name, pack_binary_command, parse_binary_command, parse_text_command, pack_text_command

gearman_logger = logging.getLogger(__name__)

class GearmanConnection(object):
    """A connection between a client/worker and a server.  Can be used to reconnect (unlike a socket)

    Wraps a socket and provides the following functionality:
        Full read/write methods for Gearman BINARY commands and responses
        Full read/write methods for Gearman SERVER commands and responses (using GEARMAN_COMMAND_TEXT_COMMAND)

        Manages raw data buffers for socket-level operations
        Manages command buffers for gearman-level operations

    All I/O and buffering should be done in this class
    """
    connect_cooldown_seconds = 1.0

    def __init__(self, host=None, port=DEFAULT_GEARMAN_PORT, keyfile=None, certfile=None, ca_certs=None):
        port = port or DEFAULT_GEARMAN_PORT
        self.gearman_host = host
        self.gearman_port = port
        self.keyfile = keyfile
        self.certfile = certfile
        self.ca_certs = ca_certs

        if host is None:
            raise ServerUnavailable("No host specified")

        # All 3 files must be given before SSL can be used
        self.use_ssl = False
        if all([self.keyfile, self.certfile, self.ca_certs]):
            self.use_ssl = True

        self._reset_connection()

    def _reset_connection(self):
        """Reset the state of this connection"""
        self.connected = False
        self.gearman_socket = None

        self.allowed_connect_time = 0.0

        self._is_client_side = None
        self._is_server_side = None

        # Reset all our raw data buffers
        self._incoming_buffer = array.array('c')
        self._outgoing_buffer = ''

        # Toss all commands we may have sent or received
        self._incoming_commands = collections.deque()
        self._outgoing_commands = collections.deque()

    def fileno(self):
        """Implements fileno() for use with select.select()"""
        if not self.gearman_socket:
            self.throw_exception(message='no socket set')

        return self.gearman_socket.fileno()

    def get_address(self):
        """Returns the host and port"""
        return (self.gearman_host, self.gearman_port)

    def writable(self):
        """Returns True if we have data to write"""
        return self.connected and bool(self._outgoing_commands or self._outgoing_buffer)

    def readable(self):
        """Returns True if we might have data to read"""
        return self.connected

    def connect(self):
        """Connect to the server. Raise ConnectionError if connection fails."""
        if self.connected:
            self.throw_exception(message='connection already established')

        current_time = time.time()
        if current_time < self.allowed_connect_time:
            self.throw_exception(message='attempted to connect before required cooldown')

        self.allowed_connect_time = current_time + self.connect_cooldown_seconds

        self._reset_connection()

        self._create_client_socket()

        self.connected = True
        self._is_client_side = True
        self._is_server_side = False

    def _create_client_socket(self):
        """Creates a client side socket and subsequently binds/configures our socket options"""
        try:
            client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

            if self.use_ssl:
                client_socket = ssl.wrap_socket(client_socket,
                                                keyfile=self.keyfile,
                                                certfile=self.certfile,
                                                ca_certs=self.ca_certs,
                                                cert_reqs=ssl.CERT_REQUIRED,
                                                ssl_version=ssl.PROTOCOL_TLSv1)

            client_socket.connect((self.gearman_host, self.gearman_port))
        except socket.error, socket_exception:
            self.throw_exception(exception=socket_exception)

        self.set_socket(client_socket)

    def set_socket(self, current_socket):
        """Setup common options for all Gearman-related sockets"""
        if self.gearman_socket:
            self.throw_exception(message='socket already bound')

        current_socket.setblocking(0)
        current_socket.settimeout(0.0)
        current_socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, struct.pack('L', 1))
        self.gearman_socket = current_socket

    def read_command(self):
        """Reads a single command from the command queue"""
        if not self._incoming_commands:
            return None

        return self._incoming_commands.popleft()

    def read_commands_from_buffer(self):
        """Reads data from buffer --> command_queue"""
        received_commands = 0
        while True:
            cmd_type, cmd_args, cmd_len = self._unpack_command(self._incoming_buffer)
            if not cmd_len:
                break

            received_commands += 1

            # Store our command on the command queue
            # Move the self._incoming_buffer forward by the number of bytes we just read
            self._incoming_commands.append((cmd_type, cmd_args))
            self._incoming_buffer = self._incoming_buffer[cmd_len:]

        return received_commands

    def read_data_from_socket(self, bytes_to_read=4096):
        """Reads data from socket --> buffer"""
        if not self.connected:
            self.throw_exception(message='disconnected')

        recv_buffer = ''

        while True:
            try:
                recv_buffer = self.gearman_socket.recv(bytes_to_read)
            except ssl.SSLError as e:
                # if we would block, ignore the error
                if e.errno == ssl.SSL_ERROR_WANT_READ:
                    continue
                elif e.errno == ssl.SSL_ERROR_WANT_WRITE:
                    continue
                else:
                    self.throw_exception(exception=e)
            except socket.error, socket_exception:
                self.throw_exception(exception=socket_exception)

            if len(recv_buffer) == 0:
                self.throw_exception(message='remote disconnected')
            break

        # SSL has an internal buffer we need to empty out
        if self.use_ssl:
            remaining = self.gearman_socket.pending()
            while remaining:
                recv_buffer += self.gearman_socket.recv(remaining)
                remaining = self.gearman_socket.pending()

        self._incoming_buffer.fromstring(recv_buffer)
        return len(self._incoming_buffer)

    def _unpack_command(self, given_buffer):
        """Conditionally unpack a binary command or a text based server command"""
        assert self._is_client_side is not None, "Ambiguous connection state"

        if not given_buffer:
            cmd_type = None
            cmd_args = None
            cmd_len = 0
        elif given_buffer[0] == NULL_CHAR:
            # We'll be expecting a response if we know we're a client side command
            is_response = bool(self._is_client_side)
            cmd_type, cmd_args, cmd_len = parse_binary_command(given_buffer, is_response=is_response)
        else:
            cmd_type, cmd_args, cmd_len = parse_text_command(given_buffer)

        if _DEBUG_MODE_ and cmd_type is not None:
            gearman_logger.debug('%s - Recv - %s - %r', hex(id(self)), get_command_name(cmd_type), cmd_args)

        return cmd_type, cmd_args, cmd_len

    def send_command(self, cmd_type, cmd_args):
        """Adds a single gearman command to the outgoing command queue"""
        self._outgoing_commands.append((cmd_type, cmd_args))

    def send_commands_to_buffer(self):
        """Sends and packs commands -> buffer"""
        if not self._outgoing_commands:
            return

        packed_data = [self._outgoing_buffer]
        while self._outgoing_commands:
            cmd_type, cmd_args = self._outgoing_commands.popleft()
            packed_command = self._pack_command(cmd_type, cmd_args)
            packed_data.append(packed_command)

        self._outgoing_buffer = ''.join(packed_data)

    def send_data_to_socket(self):
        """Send data from buffer -> socket

        Returns remaining size of the output buffer
        """
        if not self.connected:
            self.throw_exception(message='disconnected')

        if not self._outgoing_buffer:
            return 0

        while True:
            try:
                bytes_sent = self.gearman_socket.send(self._outgoing_buffer)
            except ssl.SSLError as e:
                if e.errno == ssl.SSL_ERROR_WANT_READ:
                    continue
                elif e.errno == ssl.SSL_ERROR_WANT_WRITE:
                    continue
                else:
                    self.throw_exception(exception=e)
            except socket.error, socket_exception:
                self.throw_exception(exception=socket_exception)

            if bytes_sent == 0:
                self.throw_exception(message='remote disconnected')
            break

        self._outgoing_buffer = self._outgoing_buffer[bytes_sent:]
        return len(self._outgoing_buffer)

    def _pack_command(self, cmd_type, cmd_args):
        """Converts a command to its raw binary format"""
        if cmd_type not in GEARMAN_PARAMS_FOR_COMMAND:
            raise ProtocolError('Unknown command: %r' % get_command_name(cmd_type))

        if _DEBUG_MODE_:
            gearman_logger.debug('%s - Send - %s - %r', hex(id(self)), get_command_name(cmd_type), cmd_args)

        if cmd_type == GEARMAN_COMMAND_TEXT_COMMAND:
            return pack_text_command(cmd_type, cmd_args)
        else:
            # We'll be sending a response if we know we're a server side command
            is_response = bool(self._is_server_side)
            return pack_binary_command(cmd_type, cmd_args, is_response)

    def close(self):
        """Shutdown our existing socket and reset all of our connection data"""
        try:
            if self.gearman_socket:
                self.gearman_socket.close()
        except socket.error:
            pass

        self._reset_connection()

    def throw_exception(self, message=None, exception=None):
        # Mark us as disconnected but do NOT call self._reset_connection()
        # Allows catchers of ConnectionError a chance to inspect the last state of this connection
        self.connected = False

        if exception:
            message = repr(exception)

        rewritten_message = "<%s:%d> %s" % (self.gearman_host, self.gearman_port, message)
        raise ConnectionError(rewritten_message)

    def __repr__(self):
        return ('<GearmanConnection %s:%d connected=%s>' %
            (self.gearman_host, self.gearman_port, self.connected))

########NEW FILE########
__FILENAME__ = connection_manager
import logging

import gearman.io
import gearman.util
from gearman.connection import GearmanConnection
from gearman.constants import _DEBUG_MODE_
from gearman.errors import ConnectionError, GearmanError, ServerUnavailable
from gearman.job import GearmanJob, GearmanJobRequest
from gearman import compat

gearman_logger = logging.getLogger(__name__)

class DataEncoder(object):
    @classmethod
    def encode(cls, encodable_object):
        raise NotImplementedError

    @classmethod
    def decode(cls, decodable_string):
        raise NotImplementedError

class NoopEncoder(DataEncoder):
    """Provide common object dumps for all communications over gearman"""
    @classmethod
    def _enforce_byte_string(cls, given_object):
        if type(given_object) != str:
            raise TypeError("Expecting byte string, got %r" % type(given_object))

    @classmethod
    def encode(cls, encodable_object):
        cls._enforce_byte_string(encodable_object)
        return encodable_object

    @classmethod
    def decode(cls, decodable_string):
        cls._enforce_byte_string(decodable_string)
        return decodable_string

class GearmanConnectionManager(object):
    """Abstract base class for any Gearman-type client that needs to connect/listen to multiple connections

    Mananges and polls a group of gearman connections
    Forwards all communication between a connection and a command handler
    The state of a connection is represented within the command handler

    Automatically encodes all 'data' fields as specified in protocol.py
    """
    command_handler_class = None
    connection_class = GearmanConnection

    job_class = GearmanJob
    job_request_class = GearmanJobRequest

    data_encoder = NoopEncoder

    def __init__(self, host_list=None):
        assert self.command_handler_class is not None, 'GearmanClientBase did not receive a command handler class'

        self.connection_list = []

        host_list = host_list or []
        for element in host_list:
            # old style host:port pair
            if isinstance(element, str):
                self.add_connection(element)
            elif isinstance(element, dict):
                if not all (k in element for k in ('host', 'port', 'keyfile', 'certfile', 'ca_certs')):
                    raise GearmanError("Incomplete SSL connection definition")
                self.add_ssl_connection(element['host'], element['port'],
                                        element['keyfile'], element['certfile'],
                                        element['ca_certs'])

        self.handler_to_connection_map = {}
        self.connection_to_handler_map = {}

        self.handler_initial_state = {}

    def shutdown(self):
        # Shutdown all our connections one by one
        for gearman_connection in self.connection_list:
            gearman_connection.close()

    ###################################
    # Connection management functions #
    ###################################

    def add_ssl_connection(self, host, port, keyfile, certfile, ca_certs):
        """Add a new SSL connection to this connection manager"""
        client_connection = self.connection_class(host=host,
                                                  port=port,
                                                  keyfile=keyfile,
                                                  certfile=certfile,
                                                  ca_certs=ca_certs)
        self.connection_list.append(client_connection)
        return client_connection

    def add_connection(self, hostport_tuple):
        """Add a new connection to this connection manager"""
        gearman_host, gearman_port = gearman.util.disambiguate_server_parameter(hostport_tuple)

        client_connection = self.connection_class(host=gearman_host, port=gearman_port)
        self.connection_list.append(client_connection)

        return client_connection

    def establish_connection(self, current_connection):
        """Attempt to connect... if not previously connected, create a new CommandHandler to manage this connection's state
        !NOTE! This function can throw a ConnectionError which deriving ConnectionManagers should catch
        """
        assert current_connection in self.connection_list, "Unknown connection - %r" % current_connection
        if current_connection.connected:
            return current_connection

        # !NOTE! May throw a ConnectionError
        current_connection.connect()

        # Initiate a new command handler every time we start a new connection
        current_handler = self.command_handler_class(connection_manager=self)

        # Handler to connection map for CommandHandler -> Connection interactions
        # Connection to handler map for Connection -> CommandHandler interactions
        self.handler_to_connection_map[current_handler] = current_connection
        self.connection_to_handler_map[current_connection] = current_handler

        current_handler.initial_state(**self.handler_initial_state)
        return current_connection

    def poll_connections_once(self, poller, connection_map, timeout=None):
        # a timeout of -1 when used with epoll will block until there
        # is activity. Select does not support negative timeouts, so this
        # is translated to a timeout=None when falling back to select
        timeout = timeout or -1 

        readable = set()
        writable = set()
        errors = set()
        for fileno, events in poller.poll(timeout=timeout):
            conn = connection_map.get(fileno)
            if not conn:
                continue
            if events & gearman.io.READ:
                readable.add(conn)
            if events & gearman.io.WRITE:
                writable.add(conn)
            if events & gearman.io.ERROR:
                errors.add(conn)

        return readable, writable, errors

    def handle_connection_activity(self, rd_connections, wr_connections, ex_connections):
        """Process all connection activity... executes all handle_* callbacks"""
        dead_connections = set()
        for current_connection in rd_connections:
            try:
                self.handle_read(current_connection)
            except ConnectionError:
                dead_connections.add(current_connection)

        for current_connection in wr_connections:
            try:
                self.handle_write(current_connection)
            except ConnectionError:
                dead_connections.add(current_connection)

        for current_connection in ex_connections:
            self.handle_error(current_connection)

        for current_connection in dead_connections:
            self.handle_error(current_connection)

        failed_connections = ex_connections | dead_connections
        return rd_connections, wr_connections, failed_connections

    def _register_connections_with_poller(self, connections, poller):
        for conn in connections:
            # possible that not all connections have been established yet
            if not conn.gearman_socket:
                continue
            events = 0
            if conn.readable():
                events |= gearman.io.READ
            if conn.writable():
                events |= gearman.io.WRITE
            poller.register(conn, events)

    def poll_connections_until_stopped(self, submitted_connections, callback_fxn, timeout=None):
        """Continue to poll our connections until we receive a stopping condition"""
        stopwatch = gearman.util.Stopwatch(timeout)
        submitted_connections = set(submitted_connections)
        connection_map = {}

        any_activity = False
        callback_ok = callback_fxn(any_activity)
        connection_ok = compat.any(current_connection.connected for current_connection in submitted_connections)
        poller = gearman.io.get_connection_poller()
        if connection_ok:
            self._register_connections_with_poller(submitted_connections, 
                    poller)
            connection_map = dict([(c.fileno(), c) for c in
                submitted_connections if c.connected])

        while connection_ok and callback_ok:
            time_remaining = stopwatch.get_time_remaining()
            if time_remaining == 0.0:
                break

            # Do a single robust select and handle all connection activity
            read_connections, write_connections, dead_connections = self.poll_connections_once(poller, connection_map, timeout=time_remaining)

            # Handle reads and writes and close all of the dead connections
            read_connections, write_connections, dead_connections = self.handle_connection_activity(read_connections, write_connections, dead_connections)

            any_activity = compat.any([read_connections, write_connections, dead_connections])

            # Do not retry dead connections on the next iteration of the loop, as we closed them in handle_error
            submitted_connections -= dead_connections

            callback_ok = callback_fxn(any_activity)
            connection_ok = compat.any(current_connection.connected for current_connection in submitted_connections)

        poller.close()

        # We should raise here if we have no alive connections (don't go into a select polling loop with no connections)
        if not connection_ok:
            raise ServerUnavailable('Found no valid connections in list: %r' % self.connection_list)

        return bool(connection_ok and callback_ok)

    def handle_read(self, current_connection):
        """Handle all our pending socket data"""
        current_handler = self.connection_to_handler_map[current_connection]

        # Transfer data from socket -> buffer
        current_connection.read_data_from_socket()

        # Transfer command from buffer -> command queue
        current_connection.read_commands_from_buffer()

        # Notify the handler that we have commands to fetch
        current_handler.fetch_commands()

    def handle_write(self, current_connection):
        # Transfer command from command queue -> buffer
        current_connection.send_commands_to_buffer()

        # Transfer data from buffer -> socket
        current_connection.send_data_to_socket()

    def handle_error(self, current_connection):
        dead_handler = self.connection_to_handler_map.pop(current_connection, None)
        if dead_handler:
            dead_handler.on_io_error()

        self.handler_to_connection_map.pop(dead_handler, None)
        current_connection.close()

    ##################################
    # Callbacks for Command Handlers #
    ##################################

    def read_command(self, command_handler):
        """CommandHandlers call this function to fetch pending commands

        NOTE: CommandHandlers have NO knowledge as to which connection they're representing
              ConnectionManagers must forward inbound commands to CommandHandlers
        """
        gearman_connection = self.handler_to_connection_map[command_handler]
        cmd_tuple = gearman_connection.read_command()
        if cmd_tuple is None:
            return cmd_tuple

        cmd_type, cmd_args = cmd_tuple
        return cmd_type, cmd_args

    def send_command(self, command_handler, cmd_type, cmd_args):
        """CommandHandlers call this function to send pending commands

        NOTE: CommandHandlers have NO knowledge as to which connection they're representing
              ConnectionManagers must forward outbound commands to Connections
        """
        gearman_connection = self.handler_to_connection_map[command_handler]
        gearman_connection.send_command(cmd_type, cmd_args)

    def on_gearman_error(self, error_code, error_text):
        gearman_logger.error('Received error from server: %s: %s' % (error_code, error_text))
        return False

########NEW FILE########
__FILENAME__ = constants
_DEBUG_MODE_ = False
DEFAULT_GEARMAN_PORT = 4730

PRIORITY_NONE = None
PRIORITY_LOW  = 'LOW'
PRIORITY_HIGH = 'HIGH'

JOB_UNKNOWN  = 'UNKNOWN'  # Request state is currently unknown, either unsubmitted or connection failed
JOB_PENDING  = 'PENDING'  # Request has been submitted, pending handle
JOB_CREATED  = 'CREATED'  # Request has been accepted
JOB_FAILED   = 'FAILED'   # Request received an explicit fail
JOB_COMPLETE = 'COMPLETE' # Request received an explicit complete

########NEW FILE########
__FILENAME__ = errors
class GearmanError(Exception):
    pass

class ConnectionError(GearmanError):
    pass

class ServerUnavailable(GearmanError):
    pass

class ProtocolError(GearmanError):
    pass

class UnknownCommandError(GearmanError):
    pass

class ExceededConnectionAttempts(GearmanError):
    pass

class InvalidClientState(GearmanError):
    pass

class InvalidWorkerState(GearmanError):
    pass

class InvalidAdminClientState(GearmanError):
    pass

########NEW FILE########
__FILENAME__ = io
import select

import gearman.errors
import gearman.util

# epoll event types
_EPOLLIN = 0x01
_EPOLLOUT = 0x04
_EPOLLERR = 0x08
_EPOLLHUP = 0x10

READ = _EPOLLIN
WRITE = _EPOLLOUT
ERROR = _EPOLLERR | _EPOLLHUP

def get_connection_poller():
    """
    Returns a select.epoll-like object. Depending on the platform, this will
    either be:
        - On modern Linux system, with python >= 2.6: select.epoll
        - On all other systems: gearman.io._Select: an object that mimics
          select.epoll, but uses select.select
    """
    if hasattr(select, "epoll"):
        return select.epoll()
    else:
        return _Select()

def _find_bad_connections(connections):
    """
    Find any bad connections in a list of connections. 
    
    For use with select.select. 
    
    When select throws an exception, it's likely that one of the sockets
    passed in has died. In order to find the bad connections, they must be
    checked individually. This will do so and return a list of any bad
    connections found.
    """
    bad = []
    for conn in connections:
        try:
            _, _, _ = gearman.util.select([conn], [], [], timeout=0)
        except (select.error, gearman.errors.ConnectionError):
            bad.append(conn)
    return bad

class _Select(object):
    """
    A `select.epoll`-like object that uses select.select.

    Used as a fallback when epoll is not available. Inspired by tornado's
    fallback mechanism
    """

    def __init__(self):
        self.read = set()
        self.write = set()
        self.error = set()

    def close(self):
        """
        Close the _Select object. For parity with select.epoll. Does nothing
        here.
        """
        pass

    def register(self, fd, evmask):
        """
        Register a file descriptor for polling. 

        fd: a file descriptor (socket) to be registers
        evmask: a bit set describing the desired events to report

        Events are similar to those accepted by select.epoll:
            - gearman.io.READ: report when fd is readable (i.e.: a socket.recv
              operation likely won't block, and will yield some data)
            - gearman.io.WRITE: report when fd is writable (i.e.: a socket.send
              operation likely won't block, and will be able to write some
              data)
            - gearman.io.ERROR: report when fd is in an error state
        """
        if fd in self.read or fd in self.write or fd in self.error:
            raise ValueError("Connection already registered: %d" % fd.fileno())
        if evmask & READ:
            self.read.add(fd)
        if evmask & WRITE:
            self.write.add(fd)
        if evmask & ERROR:
            self.error.add(fd)

    def modify(self, fd, evmask):
        """
        Update the IO events that should be reported for a given file
        descriptor. See _Select.register for details on these events
        """
        self.unregister(fd)
        self.register(fd, evmask)

    def unregister(self, fd):
        """
        Stop tracking events for a given file descriptor
        """
        self.read.discard(fd)
        self.write.discard(fd)
        self.error.discard(fd)

    def poll(self, timeout):
        """
        Wait for events for any of the of register file descriptors. The
        maximum time to wait is specified by the timeout value.

        A timeout < 0 will block indefinitely. A timeout of 0 will not block at
        all. And, a timeout > 0 will block for at most that many seconds. The
        timeout parameter may be a floating point number.
        """
        readable = set()
        writable = set()
        errors = set()

        if timeout is not None and timeout < 0.0:
            # for parity with epoll, negative timeout = block until there
            # is activity
            timeout = None

        connections = (self.read|self.write|self.error)
        
        success = False
        while not success and connections:
            connections -= errors
            try:
                r, w, e = gearman.util.select(self.read, 
                        self.write, self.error, timeout)
                readable = set(r)
                writable = set(w)
                errors |= set(e) #this set could already be populated
                success = True
            except (select.error, gearman.errors.ConnectionError):
                bad_conns = _find_bad_connections(connections)
                map(self.read.discard, bad_conns)
                map(self.write.discard, bad_conns)
                map(self.error.discard, bad_conns)
                errors |= set(bad_conns)
                

        events = {}
        for conn in readable:
            events[conn.fileno()] = events.get(conn.fileno(), 0) | READ
        for conn in writable:
            events[conn.fileno()] = events.get(conn.fileno(), 0) | WRITE
        for conn in errors:
            events[conn.fileno()] = events.get(conn.fileno(), 0) | ERROR

        return events.items()


########NEW FILE########
__FILENAME__ = job
import collections
from gearman.constants import PRIORITY_NONE, JOB_UNKNOWN, JOB_PENDING, JOB_CREATED, JOB_FAILED, JOB_COMPLETE

class GearmanJob(object):
    """Represents the basics of a job... used in GearmanClient / GearmanWorker to represent job states"""
    def __init__(self, connection, handle, task, unique, data):
        self.connection = connection
        self.handle = handle

        self.task = task
        self.unique = unique
        self.data = data

    def to_dict(self):
        return dict(task=self.task, job_handle=self.handle, unique=self.unique, data=self.data)

    def __repr__(self):
        return '<GearmanJob connection/handle=(%r, %r), task=%s, unique=%s, data=%r>' % (self.connection, self.handle, self.task, self.unique, self.data)

class GearmanJobRequest(object):
    """Represents a job request... used in GearmanClient to represent job states"""
    def __init__(self, gearman_job, initial_priority=PRIORITY_NONE, background=False, max_attempts=1):
        self.gearman_job = gearman_job

        self.priority = initial_priority
        self.background = background

        self.connection_attempts = 0
        self.max_connection_attempts = max_attempts

        self.initialize_request()

    def initialize_request(self):
        # Holds WORK_COMPLETE responses
        self.result = None

        # Holds WORK_EXCEPTION responses
        self.exception = None

        # Queues to hold WORK_WARNING, WORK_DATA responses
        self.warning_updates = collections.deque()
        self.data_updates = collections.deque()

        # Holds WORK_STATUS / STATUS_REQ responses
        self.status = {}

        self.state = JOB_UNKNOWN
        self.timed_out = False

    def reset(self):
        self.initialize_request()
        self.connection = None
        self.handle = None

    @property
    def status_updates(self):
        """Deprecated since 2.0.1, removing in next major release"""
        output_queue = collections.deque()
        if self.status:
            output_queue.append((self.status.get('numerator', 0), self.status.get('denominator', 0)))

        return output_queue

    @property
    def server_status(self):
        """Deprecated since 2.0.1, removing in next major release"""
        return self.status

    @property
    def job(self):
        return self.gearman_job

    @property
    def complete(self):
        background_complete = bool(self.background and self.state in (JOB_CREATED))
        foreground_complete = bool(not self.background and self.state in (JOB_FAILED, JOB_COMPLETE))

        actually_complete = background_complete or foreground_complete
        return actually_complete

    def __repr__(self):
        formatted_representation = '<GearmanJobRequest task=%r, unique=%r, priority=%r, background=%r, state=%r, timed_out=%r>'
        return formatted_representation % (self.job.task, self.job.unique, self.priority, self.background, self.state, self.timed_out)

########NEW FILE########
__FILENAME__ = protocol
import struct
from gearman.constants import PRIORITY_NONE, PRIORITY_LOW, PRIORITY_HIGH
from gearman.errors import ProtocolError
from gearman import compat
# Protocol specific constants
NULL_CHAR = '\x00'
MAGIC_RES_STRING = '%sRES' % NULL_CHAR
MAGIC_REQ_STRING = '%sREQ' % NULL_CHAR

COMMAND_HEADER_SIZE = 12

# Gearman commands 1-9
GEARMAN_COMMAND_CAN_DO = 1
GEARMAN_COMMAND_CANT_DO = 2
GEARMAN_COMMAND_RESET_ABILITIES = 3
GEARMAN_COMMAND_PRE_SLEEP = 4
GEARMAN_COMMAND_NOOP = 6
GEARMAN_COMMAND_SUBMIT_JOB = 7
GEARMAN_COMMAND_JOB_CREATED = 8
GEARMAN_COMMAND_GRAB_JOB = 9

# Gearman commands 10-19
GEARMAN_COMMAND_NO_JOB = 10
GEARMAN_COMMAND_JOB_ASSIGN = 11
GEARMAN_COMMAND_WORK_STATUS = 12
GEARMAN_COMMAND_WORK_COMPLETE = 13
GEARMAN_COMMAND_WORK_FAIL = 14
GEARMAN_COMMAND_GET_STATUS = 15
GEARMAN_COMMAND_ECHO_REQ = 16
GEARMAN_COMMAND_ECHO_RES = 17
GEARMAN_COMMAND_SUBMIT_JOB_BG = 18
GEARMAN_COMMAND_ERROR = 19

# Gearman commands 20-29
GEARMAN_COMMAND_STATUS_RES = 20
GEARMAN_COMMAND_SUBMIT_JOB_HIGH = 21
GEARMAN_COMMAND_SET_CLIENT_ID = 22
GEARMAN_COMMAND_CAN_DO_TIMEOUT = 23
GEARMAN_COMMAND_ALL_YOURS = 24
GEARMAN_COMMAND_WORK_EXCEPTION = 25
GEARMAN_COMMAND_OPTION_REQ = 26
GEARMAN_COMMAND_OPTION_RES = 27
GEARMAN_COMMAND_WORK_DATA = 28
GEARMAN_COMMAND_WORK_WARNING = 29

# Gearman commands 30-39
GEARMAN_COMMAND_GRAB_JOB_UNIQ = 30
GEARMAN_COMMAND_JOB_ASSIGN_UNIQ = 31
GEARMAN_COMMAND_SUBMIT_JOB_HIGH_BG = 32
GEARMAN_COMMAND_SUBMIT_JOB_LOW = 33
GEARMAN_COMMAND_SUBMIT_JOB_LOW_BG = 34

# Fake command code
GEARMAN_COMMAND_TEXT_COMMAND = 9999

GEARMAN_PARAMS_FOR_COMMAND = {
    # Gearman commands 1-9
    GEARMAN_COMMAND_CAN_DO: ['task'],
    GEARMAN_COMMAND_CANT_DO: ['task'],
    GEARMAN_COMMAND_RESET_ABILITIES: [],
    GEARMAN_COMMAND_PRE_SLEEP: [],
    GEARMAN_COMMAND_NOOP: [],
    GEARMAN_COMMAND_SUBMIT_JOB: ['task', 'unique', 'data'],
    GEARMAN_COMMAND_JOB_CREATED: ['job_handle'],
    GEARMAN_COMMAND_GRAB_JOB: [],

    # Gearman commands 10-19
    GEARMAN_COMMAND_NO_JOB: [],
    GEARMAN_COMMAND_JOB_ASSIGN: ['job_handle', 'task', 'data'],
    GEARMAN_COMMAND_WORK_STATUS: ['job_handle', 'numerator', 'denominator'],
    GEARMAN_COMMAND_WORK_COMPLETE: ['job_handle', 'data'],
    GEARMAN_COMMAND_WORK_FAIL: ['job_handle'],
    GEARMAN_COMMAND_GET_STATUS: ['job_handle'],
    GEARMAN_COMMAND_ECHO_REQ: ['data'],
    GEARMAN_COMMAND_ECHO_RES: ['data'],
    GEARMAN_COMMAND_SUBMIT_JOB_BG: ['task', 'unique', 'data'],
    GEARMAN_COMMAND_ERROR: ['error_code', 'error_text'],

    # Gearman commands 20-29
    GEARMAN_COMMAND_STATUS_RES: ['job_handle', 'known', 'running', 'numerator', 'denominator'],
    GEARMAN_COMMAND_SUBMIT_JOB_HIGH: ['task', 'unique', 'data'],
    GEARMAN_COMMAND_SET_CLIENT_ID: ['client_id'],
    GEARMAN_COMMAND_CAN_DO_TIMEOUT: ['task', 'timeout'],
    GEARMAN_COMMAND_ALL_YOURS: [],
    GEARMAN_COMMAND_WORK_EXCEPTION: ['job_handle', 'data'],
    GEARMAN_COMMAND_OPTION_REQ: ['option_name'],
    GEARMAN_COMMAND_OPTION_RES: ['option_name'],
    GEARMAN_COMMAND_WORK_DATA: ['job_handle', 'data'],
    GEARMAN_COMMAND_WORK_WARNING: ['job_handle', 'data'],

    # Gearman commands 30-39
    GEARMAN_COMMAND_GRAB_JOB_UNIQ: [],
    GEARMAN_COMMAND_JOB_ASSIGN_UNIQ: ['job_handle', 'task', 'unique', 'data'],
    GEARMAN_COMMAND_SUBMIT_JOB_HIGH_BG: ['task', 'unique', 'data'],
    GEARMAN_COMMAND_SUBMIT_JOB_LOW: ['task', 'unique', 'data'],
    GEARMAN_COMMAND_SUBMIT_JOB_LOW_BG: ['task', 'unique', 'data'],

    # Fake gearman command
    GEARMAN_COMMAND_TEXT_COMMAND: ['raw_text']
}

GEARMAN_COMMAND_TO_NAME = {
    GEARMAN_COMMAND_CAN_DO: 'GEARMAN_COMMAND_CAN_DO',
    GEARMAN_COMMAND_CANT_DO: 'GEARMAN_COMMAND_CANT_DO',
    GEARMAN_COMMAND_RESET_ABILITIES: 'GEARMAN_COMMAND_RESET_ABILITIES',
    GEARMAN_COMMAND_PRE_SLEEP: 'GEARMAN_COMMAND_PRE_SLEEP',
    GEARMAN_COMMAND_NOOP: 'GEARMAN_COMMAND_NOOP',
    GEARMAN_COMMAND_SUBMIT_JOB: 'GEARMAN_COMMAND_SUBMIT_JOB',
    GEARMAN_COMMAND_JOB_CREATED: 'GEARMAN_COMMAND_JOB_CREATED',
    GEARMAN_COMMAND_GRAB_JOB: 'GEARMAN_COMMAND_GRAB_JOB',

    # Gearman commands 10-19
    GEARMAN_COMMAND_NO_JOB: 'GEARMAN_COMMAND_NO_JOB',
    GEARMAN_COMMAND_JOB_ASSIGN: 'GEARMAN_COMMAND_JOB_ASSIGN',
    GEARMAN_COMMAND_WORK_STATUS: 'GEARMAN_COMMAND_WORK_STATUS',
    GEARMAN_COMMAND_WORK_COMPLETE: 'GEARMAN_COMMAND_WORK_COMPLETE',
    GEARMAN_COMMAND_WORK_FAIL: 'GEARMAN_COMMAND_WORK_FAIL',
    GEARMAN_COMMAND_GET_STATUS: 'GEARMAN_COMMAND_GET_STATUS',
    GEARMAN_COMMAND_ECHO_REQ: 'GEARMAN_COMMAND_ECHO_REQ',
    GEARMAN_COMMAND_ECHO_RES: 'GEARMAN_COMMAND_ECHO_RES',
    GEARMAN_COMMAND_SUBMIT_JOB_BG: 'GEARMAN_COMMAND_SUBMIT_JOB_BG',
    GEARMAN_COMMAND_ERROR: 'GEARMAN_COMMAND_ERROR',

    # Gearman commands 20-29
    GEARMAN_COMMAND_STATUS_RES: 'GEARMAN_COMMAND_STATUS_RES',
    GEARMAN_COMMAND_SUBMIT_JOB_HIGH: 'GEARMAN_COMMAND_SUBMIT_JOB_HIGH',
    GEARMAN_COMMAND_SET_CLIENT_ID: 'GEARMAN_COMMAND_SET_CLIENT_ID',
    GEARMAN_COMMAND_CAN_DO_TIMEOUT: 'GEARMAN_COMMAND_CAN_DO_TIMEOUT',
    GEARMAN_COMMAND_ALL_YOURS: 'GEARMAN_COMMAND_ALL_YOURS',
    GEARMAN_COMMAND_WORK_EXCEPTION: 'GEARMAN_COMMAND_WORK_EXCEPTION',
    GEARMAN_COMMAND_OPTION_REQ: 'GEARMAN_COMMAND_OPTION_REQ',
    GEARMAN_COMMAND_OPTION_RES: 'GEARMAN_COMMAND_OPTION_RES',
    GEARMAN_COMMAND_WORK_DATA: 'GEARMAN_COMMAND_WORK_DATA',
    GEARMAN_COMMAND_WORK_WARNING: 'GEARMAN_COMMAND_WORK_WARNING',

    # Gearman commands 30-39
    GEARMAN_COMMAND_GRAB_JOB_UNIQ: 'GEARMAN_COMMAND_GRAB_JOB_UNIQ',
    GEARMAN_COMMAND_JOB_ASSIGN_UNIQ: 'GEARMAN_COMMAND_JOB_ASSIGN_UNIQ',
    GEARMAN_COMMAND_SUBMIT_JOB_HIGH_BG: 'GEARMAN_COMMAND_SUBMIT_JOB_HIGH_BG',
    GEARMAN_COMMAND_SUBMIT_JOB_LOW: 'GEARMAN_COMMAND_SUBMIT_JOB_LOW',
    GEARMAN_COMMAND_SUBMIT_JOB_LOW_BG: 'GEARMAN_COMMAND_SUBMIT_JOB_LOW_BG',

    GEARMAN_COMMAND_TEXT_COMMAND: 'GEARMAN_COMMAND_TEXT_COMMAND'
}

GEARMAN_SERVER_COMMAND_STATUS = 'status'
GEARMAN_SERVER_COMMAND_VERSION = 'version'
GEARMAN_SERVER_COMMAND_WORKERS = 'workers'
GEARMAN_SERVER_COMMAND_MAXQUEUE = 'maxqueue'
GEARMAN_SERVER_COMMAND_SHUTDOWN = 'shutdown'
GEARMAN_SERVER_COMMAND_GETPID = 'getpid'
GEARMAN_SERVER_COMMAND_SHOW_JOBS = 'show jobs'
GEARMAN_SERVER_COMMAND_SHOW_UNIQUE_JOBS = 'show unique jobs'
GEARMAN_SERVER_COMMAND_CANCEL_JOB = 'cancel job'

def get_command_name(cmd_type):
    return GEARMAN_COMMAND_TO_NAME.get(cmd_type, cmd_type)

def submit_cmd_for_background_priority(background, priority):
    cmd_type_lookup = {
        (True, PRIORITY_NONE): GEARMAN_COMMAND_SUBMIT_JOB_BG,
        (True, PRIORITY_LOW): GEARMAN_COMMAND_SUBMIT_JOB_LOW_BG,
        (True, PRIORITY_HIGH): GEARMAN_COMMAND_SUBMIT_JOB_HIGH_BG,
        (False, PRIORITY_NONE): GEARMAN_COMMAND_SUBMIT_JOB,
        (False, PRIORITY_LOW): GEARMAN_COMMAND_SUBMIT_JOB_LOW,
        (False, PRIORITY_HIGH): GEARMAN_COMMAND_SUBMIT_JOB_HIGH
    }
    lookup_tuple = (background, priority)
    cmd_type = cmd_type_lookup[lookup_tuple]
    return cmd_type

def parse_binary_command(in_buffer, is_response=True):
    """Parse data and return (command type, command arguments dict, command size)
    or (None, None, data) if there's not enough data for a complete command.
    """
    in_buffer_size = len(in_buffer)
    magic = None
    cmd_type = None
    cmd_args = None
    cmd_len = 0
    expected_packet_size = None

    # If we don't have enough data to parse, error early
    if in_buffer_size < COMMAND_HEADER_SIZE:
        return cmd_type, cmd_args, cmd_len

    # By default, we'll assume we're dealing with a gearman command
    magic, cmd_type, cmd_len = struct.unpack('!4sII', in_buffer[:COMMAND_HEADER_SIZE])

    received_bad_response = is_response and bool(magic != MAGIC_RES_STRING)
    received_bad_request = not is_response and bool(magic != MAGIC_REQ_STRING)
    if received_bad_response or received_bad_request:
        raise ProtocolError('Malformed Magic')

    expected_cmd_params = GEARMAN_PARAMS_FOR_COMMAND.get(cmd_type, None)

    # GEARMAN_COMMAND_TEXT_COMMAND is a faked command that we use to support server text-based commands
    if expected_cmd_params is None or cmd_type == GEARMAN_COMMAND_TEXT_COMMAND:
        raise ProtocolError('Received unknown binary command: %s' % cmd_type)

    # If everything indicates this is a valid command, we should check to see if we have enough stuff to read in our buffer
    expected_packet_size = COMMAND_HEADER_SIZE + cmd_len
    if in_buffer_size < expected_packet_size:
        return None, None, 0

    binary_payload = in_buffer[COMMAND_HEADER_SIZE:expected_packet_size]
    split_arguments = []

    if len(expected_cmd_params) > 0:
        binary_payload = binary_payload.tostring()
        split_arguments = binary_payload.split(NULL_CHAR, len(expected_cmd_params) - 1)
    elif binary_payload:
        raise ProtocolError('Expected no binary payload: %s' % get_command_name(cmd_type))

    # This is a sanity check on the binary_payload.split() phase
    # We should never be able to get here with any VALID gearman data
    if len(split_arguments) != len(expected_cmd_params):
        raise ProtocolError('Received %d argument(s), expecting %d argument(s): %s' % (len(split_arguments), len(expected_cmd_params), get_command_name(cmd_type)))

    # Iterate through the split arguments and assign them labels based on their order
    cmd_args = dict((param_label, param_value) for param_label, param_value in zip(expected_cmd_params, split_arguments))
    return cmd_type, cmd_args, expected_packet_size


def pack_binary_command(cmd_type, cmd_args, is_response=False):
    """Packs the given command using the parameter ordering specified in GEARMAN_PARAMS_FOR_COMMAND.
    *NOTE* Expects that all arguments in cmd_args are already str's.
    """
    expected_cmd_params = GEARMAN_PARAMS_FOR_COMMAND.get(cmd_type, None)
    if expected_cmd_params is None or cmd_type == GEARMAN_COMMAND_TEXT_COMMAND:
        raise ProtocolError('Received unknown binary command: %s' % get_command_name(cmd_type))

    expected_parameter_set = set(expected_cmd_params)
    received_parameter_set = set(cmd_args.keys())
    if expected_parameter_set != received_parameter_set:
        raise ProtocolError('Received arguments did not match expected arguments: %r != %r' % (expected_parameter_set, received_parameter_set))

    # Select the right expected magic
    if is_response:
        magic = MAGIC_RES_STRING
    else:
        magic = MAGIC_REQ_STRING

    # !NOTE! str should be replaced with bytes in Python 3.x
    # We will iterate in ORDER and str all our command arguments
    if compat.any(type(param_value) != str for param_value in cmd_args.itervalues()):
        raise ProtocolError('Received non-binary arguments: %r' % cmd_args)

    data_items = [cmd_args[param] for param in expected_cmd_params]

    # Now check that all but the last argument are free of \0 as per the protocol spec.
    if compat.any('\0' in argument for argument in data_items[:-1]):
        raise ProtocolError('Received arguments with NULL byte in non-final argument')

    binary_payload = NULL_CHAR.join(data_items)

    # Pack the header in the !4sII format then append the binary payload
    payload_size = len(binary_payload)
    packing_format = '!4sII%ds' % payload_size
    return struct.pack(packing_format, magic, cmd_type, payload_size, binary_payload)

def parse_text_command(in_buffer):
    """Parse a text command and return a single line at a time"""
    cmd_type = None
    cmd_args = None
    cmd_len = 0
    if '\n' not in in_buffer:
        return cmd_type, cmd_args, cmd_len

    text_command, in_buffer = in_buffer.tostring().split('\n', 1)
    if NULL_CHAR in text_command:
        raise ProtocolError('Received unexpected character: %s' % text_command)

    # Fake gearman command "TEXT_COMMAND" used to process server admin client responses
    cmd_type = GEARMAN_COMMAND_TEXT_COMMAND
    cmd_args = dict(raw_text=text_command)
    cmd_len = len(text_command) + 1

    return cmd_type, cmd_args, cmd_len

def pack_text_command(cmd_type, cmd_args):
    """Parse a text command and return a single line at a time"""
    if cmd_type != GEARMAN_COMMAND_TEXT_COMMAND:
        raise ProtocolError('Unknown cmd_type: Received %s, expecting %s' % (get_command_name(cmd_type), get_command_name(GEARMAN_COMMAND_TEXT_COMMAND)))

    cmd_line = cmd_args.get('raw_text')
    if cmd_line is None:
        raise ProtocolError('Did not receive arguments any valid arguments: %s' % cmd_args)

    return str(cmd_line)

########NEW FILE########
__FILENAME__ = util
#!/usr/bin/env python
"""
Gearman Client Utils
"""
import errno
import select as select_lib
import time

from gearman.constants import DEFAULT_GEARMAN_PORT

class Stopwatch(object):
    """Timer class that keeps track of time remaining"""
    def __init__(self, time_remaining):
        if time_remaining is not None:
            self.stop_time = time.time() + time_remaining
        else:
            self.stop_time = None

    def get_time_remaining(self):
        if self.stop_time is None:
            return None

        current_time = time.time()
        if not self.has_time_remaining(current_time):
            return 0.0

        time_remaining = self.stop_time - current_time
        return time_remaining

    def has_time_remaining(self, time_comparison=None):
        time_comparison = time_comparison or self.get_time_remaining()
        if self.stop_time is None:
            return True

        return bool(time_comparison < self.stop_time)

def disambiguate_server_parameter(hostport_tuple):
    """Takes either a tuple of (address, port) or a string of 'address:port' and disambiguates them for us"""
    if type(hostport_tuple) is tuple:
        gearman_host, gearman_port = hostport_tuple
    elif ':' in hostport_tuple:
        gearman_host, gearman_possible_port = hostport_tuple.split(':')
        gearman_port = int(gearman_possible_port)
    else:
        gearman_host = hostport_tuple
        gearman_port = DEFAULT_GEARMAN_PORT

    return gearman_host, gearman_port

def select(rlist, wlist, xlist, timeout=None):
    """Behave similar to select.select, except ignoring certain types of exceptions"""
    rd_list = []
    wr_list = []
    ex_list = []

    select_args = [rlist, wlist, xlist]
    if timeout is not None:
        select_args.append(timeout)

    try:
        rd_list, wr_list, ex_list = select_lib.select(*select_args)
    except select_lib.error, exc:
        # Ignore interrupted system call, reraise anything else
        if exc[0] != errno.EINTR:
            raise

    return rd_list, wr_list, ex_list

def unlist(given_list):
    """Convert the (possibly) single item list into a single item"""
    list_size = len(given_list)
    if list_size == 0:
        return None
    elif list_size == 1:
        return given_list[0]
    else:
        raise ValueError(list_size)

########NEW FILE########
__FILENAME__ = worker
import logging
import random
import sys

from gearman import compat
from gearman.connection_manager import GearmanConnectionManager
from gearman.worker_handler import GearmanWorkerCommandHandler
from gearman.errors import ConnectionError

gearman_logger = logging.getLogger(__name__)

POLL_TIMEOUT_IN_SECONDS = 60.0

class GearmanWorker(GearmanConnectionManager):
    """
    GearmanWorker :: Interface to accept jobs from a Gearman server
    """
    command_handler_class = GearmanWorkerCommandHandler

    def __init__(self, host_list=None):
        super(GearmanWorker, self).__init__(host_list=host_list)

        self.randomized_connections = None

        self.worker_abilities = {}
        self.worker_client_id = None
        self.command_handler_holding_job_lock = None

        self._update_initial_state()

    def _update_initial_state(self):
        self.handler_initial_state['abilities'] = self.worker_abilities.keys()
        self.handler_initial_state['client_id'] = self.worker_client_id

    ########################################################
    ##### Public methods for general GearmanWorker use #####
    ########################################################
    def register_task(self, task, callback_function):
        """Register a function with this worker

        def function_callback(calling_gearman_worker, current_job):
            return current_job.data
        """
        self.worker_abilities[task] = callback_function
        self._update_initial_state()

        for command_handler in self.handler_to_connection_map.iterkeys():
            command_handler.set_abilities(self.handler_initial_state['abilities'])

        return task

    def unregister_task(self, task):
        """Unregister a function with worker"""
        self.worker_abilities.pop(task, None)
        self._update_initial_state()

        for command_handler in self.handler_to_connection_map.iterkeys():
            command_handler.set_abilities(self.handler_initial_state['abilities'])

        return task

    def set_client_id(self, client_id):
        """Notify the server that we should be identified as this client ID"""
        self.worker_client_id = client_id
        self._update_initial_state()

        for command_handler in self.handler_to_connection_map.iterkeys():
            command_handler.set_client_id(self.handler_initial_state['client_id'])

        return client_id

    def work(self, poll_timeout=POLL_TIMEOUT_IN_SECONDS):
        """Loop indefinitely, complete tasks from all connections."""
        continue_working = True
        worker_connections = []

        # We're going to track whether a previous call to our closure indicated
        # we were processing a job. This is just a list of possibly a single
        # element indicating we had a job. It's a list so that through the
        # magic of closures we can reference and write to it each call.
        # This is all so that we can determine when we've finished processing a job
        # correctly.
        had_job = []

        def continue_while_connections_alive(any_activity):
            if had_job and not self.has_job_lock():
                return self.after_poll(any_activity) and self.after_job()

            del had_job[:]
            if self.has_job_lock():
                had_job.append(True)

            return self.after_poll(any_activity)

        # Shuffle our connections after the poll timeout
        while continue_working:
            worker_connections = self.establish_worker_connections()
            continue_working = self.poll_connections_until_stopped(worker_connections, continue_while_connections_alive, timeout=poll_timeout)

        # If we were kicked out of the worker loop, we should shutdown all our connections
        for current_connection in worker_connections:
            current_connection.close()

    def shutdown(self):
        self.command_handler_holding_job_lock = None
        super(GearmanWorker, self).shutdown()

    ###############################################################
    ## Methods to override when dealing with connection polling ##
    ##############################################################
    def establish_worker_connections(self):
        """Return a shuffled list of connections that are alive, and try to reconnect to dead connections if necessary."""
        self.randomized_connections = list(self.connection_list)
        random.shuffle(self.randomized_connections)

        output_connections = []
        for current_connection in self.randomized_connections:
            try:
                valid_connection = self.establish_connection(current_connection)
                output_connections.append(valid_connection)
            except ConnectionError:
                pass

        return output_connections

    def after_poll(self, any_activity):
        """Polling callback to notify any outside listeners whats going on with the GearmanWorker.

        Return True to continue polling, False to exit the work loop"""
        return True

    def after_job(self):
        """Callback to notify any outside listeners that a GearmanWorker has completed the current job.

        This is useful for accomplishing work or stopping the GearmanWorker in between jobs.

        Return True to continue polling, False to exit the work loop
        """
        return True

    def handle_error(self, current_connection):
        """If we discover that a connection has a problem, we better release the job lock"""
        current_handler = self.connection_to_handler_map.get(current_connection)
        if current_handler:
            self.set_job_lock(current_handler, lock=False)

        super(GearmanWorker, self).handle_error(current_connection)

    #############################################################
    ## Public methods so Gearman jobs can send Gearman updates ##
    #############################################################
    def _get_handler_for_job(self, current_job):
        return self.connection_to_handler_map[current_job.connection]

    def wait_until_updates_sent(self, multiple_gearman_jobs, poll_timeout=None):
        connection_set = set([current_job.connection for current_job in multiple_gearman_jobs])
        def continue_while_updates_pending(any_activity):
            return compat.any(current_connection.writable() for current_connection in connection_set)

        self.poll_connections_until_stopped(connection_set, continue_while_updates_pending, timeout=poll_timeout)

    def send_job_status(self, current_job, numerator, denominator, poll_timeout=None):
        """Send a Gearman JOB_STATUS update for an inflight job"""
        current_handler = self._get_handler_for_job(current_job)
        current_handler.send_job_status(current_job, numerator=numerator, denominator=denominator)

        self.wait_until_updates_sent([current_job], poll_timeout=poll_timeout)

    def send_job_complete(self, current_job, data, poll_timeout=None):
        current_handler = self._get_handler_for_job(current_job)
        current_handler.send_job_complete(current_job, data=data)

        self.wait_until_updates_sent([current_job], poll_timeout=poll_timeout)

    def send_job_failure(self, current_job, poll_timeout=None):
        """Removes a job from the queue if its backgrounded"""
        current_handler = self._get_handler_for_job(current_job)
        current_handler.send_job_failure(current_job)

        self.wait_until_updates_sent([current_job], poll_timeout=poll_timeout)

    def send_job_exception(self, current_job, data, poll_timeout=None):
        """Removes a job from the queue if its backgrounded"""
        # Using GEARMAND_COMMAND_WORK_EXCEPTION is not recommended at time of this writing [2010-02-24]
        # http://groups.google.com/group/gearman/browse_thread/thread/5c91acc31bd10688/529e586405ed37fe
        #
        current_handler = self._get_handler_for_job(current_job)
        current_handler.send_job_exception(current_job, data=data)
        current_handler.send_job_failure(current_job)

        self.wait_until_updates_sent([current_job], poll_timeout=poll_timeout)

    def send_job_data(self, current_job, data, poll_timeout=None):
        """Send a Gearman JOB_DATA update for an inflight job"""
        current_handler = self._get_handler_for_job(current_job)
        current_handler.send_job_data(current_job, data=data)

        self.wait_until_updates_sent([current_job], poll_timeout=poll_timeout)

    def send_job_warning(self, current_job, data, poll_timeout=None):
        """Send a Gearman JOB_WARNING update for an inflight job"""
        current_handler = self._get_handler_for_job(current_job)
        current_handler.send_job_warning(current_job, data=data)

        self.wait_until_updates_sent([current_job], poll_timeout=poll_timeout)

    #####################################################
    ##### Callback methods for GearmanWorkerHandler #####
    #####################################################
    def create_job(self, command_handler, job_handle, task, unique, data):
        """Create a new job using our self.job_class"""
        current_connection = self.handler_to_connection_map[command_handler]
        return self.job_class(current_connection, job_handle, task, unique, data)

    def on_job_execute(self, current_job):
        try:
            function_callback = self.worker_abilities[current_job.task]
            job_result = function_callback(self, current_job)
        except Exception:
            return self.on_job_exception(current_job, sys.exc_info())

        return self.on_job_complete(current_job, job_result)

    def on_job_exception(self, current_job, exc_info):
        self.send_job_failure(current_job)
        return False

    def on_job_complete(self, current_job, job_result):
        self.send_job_complete(current_job, job_result)
        return True

    def set_job_lock(self, command_handler, lock):
        """Set a worker level job lock so we don't try to hold onto 2 jobs at anytime"""
        if command_handler not in self.handler_to_connection_map:
            return False

        failed_lock = bool(lock and self.command_handler_holding_job_lock is not None)
        failed_unlock = bool(not lock and self.command_handler_holding_job_lock != command_handler)

        # If we've already been locked, we should say the lock failed
        # If we're attempting to unlock something when we don't have a lock, we're in a bad state
        if failed_lock or failed_unlock:
            return False

        if lock:
            self.command_handler_holding_job_lock = command_handler
        else:
            self.command_handler_holding_job_lock = None

        return True
    
    def has_job_lock(self):
        return bool(self.command_handler_holding_job_lock is not None)
    
    def check_job_lock(self, command_handler):
        """Check to see if we hold the job lock"""
        return bool(self.command_handler_holding_job_lock == command_handler)

########NEW FILE########
__FILENAME__ = worker_handler
import logging

from gearman.command_handler import GearmanCommandHandler
from gearman.errors import InvalidWorkerState
from gearman.protocol import GEARMAN_COMMAND_PRE_SLEEP, GEARMAN_COMMAND_RESET_ABILITIES, GEARMAN_COMMAND_CAN_DO, GEARMAN_COMMAND_SET_CLIENT_ID, GEARMAN_COMMAND_GRAB_JOB_UNIQ, \
    GEARMAN_COMMAND_WORK_STATUS, GEARMAN_COMMAND_WORK_COMPLETE, GEARMAN_COMMAND_WORK_FAIL, GEARMAN_COMMAND_WORK_EXCEPTION, GEARMAN_COMMAND_WORK_WARNING, GEARMAN_COMMAND_WORK_DATA

gearman_logger = logging.getLogger(__name__)

class GearmanWorkerCommandHandler(GearmanCommandHandler):
    """GearmanWorker state machine on a per connection basis

    A worker can be in the following distinct states:
        SLEEP         -> Doing nothing, can be awoken
        AWAKE         -> Transitional state (for NOOP)
        AWAITING_JOB  -> Holding worker level job lock and awaiting a server response
        EXECUTING_JOB -> Transitional state (for ASSIGN_JOB)
    """
    def __init__(self, connection_manager=None):
        super(GearmanWorkerCommandHandler, self).__init__(connection_manager=connection_manager)

        self._handler_abilities = []
        self._client_id = None

    def initial_state(self, abilities=None, client_id=None):
        self.set_client_id(client_id)
        self.set_abilities(abilities)

        self._sleep()

    ##################################################################
    ##### Public interface methods to be called by GearmanWorker #####
    ##################################################################
    def set_abilities(self, connection_abilities_list):
        assert type(connection_abilities_list) in (list, tuple)
        self._handler_abilities = connection_abilities_list

        self.send_command(GEARMAN_COMMAND_RESET_ABILITIES)
        for task in self._handler_abilities:
            self.send_command(GEARMAN_COMMAND_CAN_DO, task=task)

    def set_client_id(self, client_id):
        self._client_id = client_id

        if self._client_id is not None:
            self.send_command(GEARMAN_COMMAND_SET_CLIENT_ID, client_id=self._client_id)

    ###############################################################
    #### Convenience methods for typical gearman jobs to call #####
    ###############################################################
    def send_job_status(self, current_job, numerator, denominator):
        assert type(numerator) in (int, float), 'Numerator must be a numeric value'
        assert type(denominator) in (int, float), 'Denominator must be a numeric value'
        self.send_command(GEARMAN_COMMAND_WORK_STATUS, job_handle=current_job.handle, numerator=str(numerator), denominator=str(denominator))

    def send_job_complete(self, current_job, data):
        """Removes a job from the queue if its backgrounded"""
        self.send_command(GEARMAN_COMMAND_WORK_COMPLETE, job_handle=current_job.handle, data=self.encode_data(data))

    def send_job_failure(self, current_job):
        """Removes a job from the queue if its backgrounded"""
        self.send_command(GEARMAN_COMMAND_WORK_FAIL, job_handle=current_job.handle)

    def send_job_exception(self, current_job, data):
        # Using GEARMAND_COMMAND_WORK_EXCEPTION is not recommended at time of this writing [2010-02-24]
        # http://groups.google.com/group/gearman/browse_thread/thread/5c91acc31bd10688/529e586405ed37fe
        #
        self.send_command(GEARMAN_COMMAND_WORK_EXCEPTION, job_handle=current_job.handle, data=self.encode_data(data))

    def send_job_data(self, current_job, data):
        self.send_command(GEARMAN_COMMAND_WORK_DATA, job_handle=current_job.handle, data=self.encode_data(data))

    def send_job_warning(self, current_job, data):
        self.send_command(GEARMAN_COMMAND_WORK_WARNING, job_handle=current_job.handle, data=self.encode_data(data))

    ###########################################################
    ### Callbacks when we receive a command from the server ###
    ###########################################################
    def _grab_job(self):
        self.send_command(GEARMAN_COMMAND_GRAB_JOB_UNIQ)

    def _sleep(self):
        self.send_command(GEARMAN_COMMAND_PRE_SLEEP)

    def _check_job_lock(self):
        return self.connection_manager.check_job_lock(self)

    def _acquire_job_lock(self):
        return self.connection_manager.set_job_lock(self, lock=True)

    def _release_job_lock(self):
        if not self.connection_manager.set_job_lock(self, lock=False):
            raise InvalidWorkerState("Unable to release job lock for %r" % self)

        return True

    def recv_noop(self):
        """Transition from being SLEEP --> AWAITING_JOB / SLEEP

          AWAITING_JOB -> AWAITING_JOB :: Noop transition, we're already awaiting a job
        SLEEP -> AWAKE -> AWAITING_JOB :: Transition if we can acquire the worker job lock
        SLEEP -> AWAKE -> SLEEP        :: Transition if we can NOT acquire a worker job lock
        """
        if self._check_job_lock():
            pass
        elif self._acquire_job_lock():
            self._grab_job()
        else:
            self._sleep()

        return True

    def recv_no_job(self):
        """Transition from being AWAITING_JOB --> SLEEP

        AWAITING_JOB -> SLEEP :: Always transition to sleep if we have nothing to do
        """
        self._release_job_lock()
        self._sleep()

        return True

    def recv_job_assign_uniq(self, job_handle, task, unique, data):
        """Transition from being AWAITING_JOB --> EXECUTE_JOB --> SLEEP

        AWAITING_JOB -> EXECUTE_JOB -> SLEEP :: Always transition once we're given a job
        """
        assert task in self._handler_abilities, '%s not found in %r' % (task, self._handler_abilities)

        # After this point, we know this connection handler is holding onto the job lock so we don't need to acquire it again
        if not self.connection_manager.check_job_lock(self):
            raise InvalidWorkerState("Received a job when we weren't expecting one")

        gearman_job = self.connection_manager.create_job(self, job_handle, task, unique, self.decode_data(data))

        # Create a new job
        self.connection_manager.on_job_execute(gearman_job)

        # Release the job lock once we're doing and go back to sleep
        self._release_job_lock()
        self._sleep()

        return True

    def recv_job_assign(self, job_handle, task, data):
        """JOB_ASSIGN and JOB_ASSIGN_UNIQ are essentially the same"""
        return self.recv_job_assign_uniq(job_handle=job_handle, task=task, unique=None, data=data)

########NEW FILE########
__FILENAME__ = admin_client_tests
import unittest

from gearman.admin_client import GearmanAdminClient, ECHO_STRING
from gearman.admin_client_handler import GearmanAdminClientCommandHandler

from gearman.errors import InvalidAdminClientState, ProtocolError
from gearman.protocol import GEARMAN_COMMAND_ECHO_RES, GEARMAN_COMMAND_ECHO_REQ, GEARMAN_COMMAND_TEXT_COMMAND, \
    GEARMAN_SERVER_COMMAND_STATUS, GEARMAN_SERVER_COMMAND_VERSION, GEARMAN_SERVER_COMMAND_WORKERS, GEARMAN_SERVER_COMMAND_MAXQUEUE, GEARMAN_SERVER_COMMAND_SHUTDOWN

from tests._core_testing import _GearmanAbstractTest, MockGearmanConnectionManager, MockGearmanConnection

class MockGearmanAdminClient(GearmanAdminClient, MockGearmanConnectionManager):
    pass

class CommandHandlerStateMachineTest(_GearmanAbstractTest):
    """Test the public interface a GearmanWorker may need to call in order to update state on a GearmanWorkerCommandHandler"""
    connection_manager_class = MockGearmanAdminClient
    command_handler_class = GearmanAdminClientCommandHandler

    def setUp(self):
        super(CommandHandlerStateMachineTest, self).setUp()
        self.connection_manager.current_connection = self.connection
        self.connection_manager.current_handler = self.command_handler

    def test_send_illegal_server_commands(self):
        self.assertRaises(ProtocolError, self.send_server_command, "This is not a server command")

    def test_ping_server(self):
        self.command_handler.send_echo_request(ECHO_STRING)
        self.assert_sent_command(GEARMAN_COMMAND_ECHO_REQ, data=ECHO_STRING)
        self.assertEqual(self.command_handler._sent_commands[0], GEARMAN_COMMAND_ECHO_REQ)

        self.command_handler.recv_command(GEARMAN_COMMAND_ECHO_RES, data=ECHO_STRING)
        server_response = self.pop_response(GEARMAN_COMMAND_ECHO_REQ)
        self.assertEquals(server_response, ECHO_STRING)

    def test_state_and_protocol_errors_for_status(self):
        self.send_server_command(GEARMAN_SERVER_COMMAND_STATUS)

        # Test premature popping as this we aren't until ready we see the '.'
        self.assertRaises(InvalidAdminClientState, self.pop_response, GEARMAN_SERVER_COMMAND_STATUS)

        # Test malformed server status
        self.assertRaises(ProtocolError, self.recv_server_response, '\t'.join(['12', 'IP-A', 'CLIENT-A']))

        self.recv_server_response('.')

        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_STATUS)
        self.assertEquals(server_response, tuple())

    def test_multiple_status(self):
        self.send_server_command(GEARMAN_SERVER_COMMAND_STATUS)
        self.recv_server_response('\t'.join(['test_function', '1', '5', '17']))
        self.recv_server_response('\t'.join(['another_function', '2', '4', '23']))
        self.recv_server_response('.')

        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_STATUS)
        self.assertEquals(len(server_response), 2)

        test_response, another_response = server_response
        self.assertEquals(test_response['task'], 'test_function')
        self.assertEquals(test_response['queued'], 1)
        self.assertEquals(test_response['running'], 5)
        self.assertEquals(test_response['workers'],  17)

        self.assertEquals(another_response['task'], 'another_function')
        self.assertEquals(another_response['queued'], 2)
        self.assertEquals(another_response['running'], 4)
        self.assertEquals(another_response['workers'],  23)

    def test_version(self):
        expected_version = '0.12345'

        self.send_server_command(GEARMAN_SERVER_COMMAND_VERSION)
        self.recv_server_response(expected_version)

        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_VERSION)
        self.assertEquals(expected_version, server_response)

    def test_state_and_protocol_errors_for_workers(self):
        self.send_server_command(GEARMAN_SERVER_COMMAND_WORKERS)

        # Test premature popping as this we aren't until ready we see the '.'
        self.assertRaises(InvalidAdminClientState, self.pop_response, GEARMAN_SERVER_COMMAND_WORKERS)

        # Test malformed responses
        self.assertRaises(ProtocolError, self.recv_server_response, ' '.join(['12', 'IP-A', 'CLIENT-A']))
        self.assertRaises(ProtocolError, self.recv_server_response, ' '.join(['12', 'IP-A', 'CLIENT-A', 'NOT:']))

        self.recv_server_response('.')

        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_WORKERS)
        self.assertEquals(server_response, tuple())

    def test_multiple_workers(self):
        self.send_server_command(GEARMAN_SERVER_COMMAND_WORKERS)
        self.recv_server_response(' '.join(['12', 'IP-A', 'CLIENT-A', ':', 'function-A', 'function-B']))
        self.recv_server_response(' '.join(['13', 'IP-B', 'CLIENT-B', ':', 'function-C']))
        self.recv_server_response('.')

        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_WORKERS)
        self.assertEquals(len(server_response), 2)

        test_response, another_response = server_response
        self.assertEquals(test_response['file_descriptor'], '12')
        self.assertEquals(test_response['ip'], 'IP-A')
        self.assertEquals(test_response['client_id'], 'CLIENT-A')
        self.assertEquals(test_response['tasks'],  ('function-A', 'function-B'))

        self.assertEquals(another_response['file_descriptor'], '13')
        self.assertEquals(another_response['ip'], 'IP-B')
        self.assertEquals(another_response['client_id'], 'CLIENT-B')
        self.assertEquals(another_response['tasks'],  ('function-C', ))

    def test_maxqueue(self):
        self.send_server_command(GEARMAN_SERVER_COMMAND_MAXQUEUE)
        self.assertRaises(ProtocolError, self.recv_server_response, 'NOT OK')

        # Pop prematurely
        self.assertRaises(InvalidAdminClientState, self.pop_response, GEARMAN_SERVER_COMMAND_MAXQUEUE)

        self.recv_server_response('OK')
        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_MAXQUEUE)
        self.assertEquals(server_response, 'OK')

    def test_shutdown(self):
        self.send_server_command(GEARMAN_SERVER_COMMAND_SHUTDOWN)

        # Pop prematurely
        self.assertRaises(InvalidAdminClientState, self.pop_response, GEARMAN_SERVER_COMMAND_SHUTDOWN)

        self.recv_server_response(None)
        server_response = self.pop_response(GEARMAN_SERVER_COMMAND_SHUTDOWN)
        self.assertEquals(server_response, None)

    def send_server_command(self, expected_command):
        self.command_handler.send_text_command(expected_command)
        expected_line = "%s\n" % expected_command
        self.assert_sent_command(GEARMAN_COMMAND_TEXT_COMMAND, raw_text=expected_line)

        self.assertEqual(self.command_handler._sent_commands[0], expected_command)

    def recv_server_response(self, response_line):
        self.command_handler.recv_command(GEARMAN_COMMAND_TEXT_COMMAND, raw_text=response_line)

    def pop_response(self, expected_command):
        server_cmd, server_response = self.command_handler.pop_response()
        self.assertEquals(expected_command, server_cmd)

        return server_response

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = client_tests
import collections
import random
import unittest

from gearman.client import GearmanClient
from gearman.client_handler import GearmanClientCommandHandler

from gearman.constants import PRIORITY_NONE, PRIORITY_HIGH, PRIORITY_LOW, JOB_UNKNOWN, JOB_PENDING, JOB_CREATED, JOB_FAILED, JOB_COMPLETE
from gearman.errors import ExceededConnectionAttempts, ServerUnavailable, InvalidClientState
from gearman.protocol import submit_cmd_for_background_priority, GEARMAN_COMMAND_STATUS_RES, GEARMAN_COMMAND_GET_STATUS, GEARMAN_COMMAND_JOB_CREATED, \
    GEARMAN_COMMAND_WORK_STATUS, GEARMAN_COMMAND_WORK_FAIL, GEARMAN_COMMAND_WORK_COMPLETE, GEARMAN_COMMAND_WORK_DATA, GEARMAN_COMMAND_WORK_WARNING

from tests._core_testing import _GearmanAbstractTest, MockGearmanConnectionManager, MockGearmanConnection

class MockGearmanClient(GearmanClient, MockGearmanConnectionManager):
    pass

class ClientTest(_GearmanAbstractTest):
    """Test the public client interface"""
    connection_manager_class = MockGearmanClient
    command_handler_class = GearmanClientCommandHandler

    def setUp(self):
        super(ClientTest, self).setUp()
        self.original_handle_connection_activity = self.connection_manager.handle_connection_activity

    def tearDown(self):
        super(ClientTest, self).tearDown()
        self.connection_manager.handle_connection_activity = self.original_handle_connection_activity

    def generate_job_request(self, submitted=True, accepted=True):
        current_request = super(ClientTest, self).generate_job_request()
        if submitted or accepted:
            self.connection_manager.establish_request_connection(current_request)
            self.command_handler.send_job_request(current_request)

        if submitted and accepted:
            self.command_handler.recv_command(GEARMAN_COMMAND_JOB_CREATED, job_handle=current_request.job.handle)
            self.assert_(current_request.job.handle in self.command_handler.handle_to_request_map)

        return current_request

    def test_establish_request_connection_complex(self):
        # Spin up a bunch of imaginary gearman connections
        failed_connection = MockGearmanConnection()
        failed_connection._fail_on_bind = True

        failed_then_retried_connection = MockGearmanConnection()
        failed_then_retried_connection._fail_on_bind = True

        good_connection = MockGearmanConnection()
        good_connection.connect()

        # Register all our connections
        self.connection_manager.connection_list = [failed_connection, failed_then_retried_connection, good_connection]

        # When we first create our request, our client shouldn't know anything about it
        current_request = self.generate_job_request(submitted=False, accepted=False)
        self.failIf(current_request in self.connection_manager.request_to_rotating_connection_queue)

        # Make sure that when we start up, we get our good connection
        chosen_connection = self.connection_manager.establish_request_connection(current_request)
        self.assertEqual(chosen_connection, good_connection)

        self.assertFalse(failed_connection.connected)
        self.assertFalse(failed_then_retried_connection.connected)
        self.assertTrue(good_connection.connected)

        # No state changed so we should still go to the correct connection
        chosen_connection = self.connection_manager.establish_request_connection(current_request)
        self.assertEqual(chosen_connection, good_connection)

        # Pretend like our good connection died so we'll need to choose somethign else
        good_connection._reset_connection()
        good_connection._fail_on_bind = True

        failed_then_retried_connection._fail_on_bind = False
        failed_then_retried_connection.connect()

        # Make sure we rotate good_connection and failed_connection out
        chosen_connection = self.connection_manager.establish_request_connection(current_request)
        self.assertEqual(chosen_connection, failed_then_retried_connection)
        self.assertFalse(failed_connection.connected)
        self.assertTrue(failed_then_retried_connection.connected)
        self.assertFalse(good_connection.connected)

    def test_establish_request_connection_dead(self):
        self.connection_manager.connection_list = []
        self.connection_manager.command_handlers = {}

        current_request = self.generate_job_request(submitted=False, accepted=False)

        # No connections == death
        self.assertRaises(ServerUnavailable, self.connection_manager.establish_request_connection, current_request)

        # Spin up a bunch of imaginary gearman connections
        failed_connection = MockGearmanConnection()
        failed_connection._fail_on_bind = True
        self.connection_manager.connection_list.append(failed_connection)

        # All failed connections == death
        self.assertRaises(ServerUnavailable, self.connection_manager.establish_request_connection, current_request)

    def test_auto_retry_behavior(self):
        current_request = self.generate_job_request(submitted=False, accepted=False)

        def fail_then_create_jobs(rx_conns, wr_conns, ex_conns):
            if self.connection_manager.current_failures < self.connection_manager.expected_failures:
                self.connection_manager.current_failures += 1

                # We're going to down this connection and reset state
                self.assertTrue(self.connection.connected)
                self.connection_manager.handle_error(self.connection)
                self.assertFalse(self.connection.connected)

                # We're then going to IMMEDIATELY pull this connection back up
                # So we don't bail out of the "self.connection_manager.poll_connections_until_stopped" loop
                self.connection_manager.establish_connection(self.connection)
            else:
                self.assertEquals(current_request.state, JOB_PENDING)
                self.command_handler.recv_command(GEARMAN_COMMAND_JOB_CREATED, job_handle=current_request.job.handle)

            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = fail_then_create_jobs
        self.connection_manager.expected_failures = 5

        # Now that we've setup our rety behavior, we need to reset the entire state of our experiment
        # First pass should succeed as we JUST touch our max attempts
        self.connection_manager.current_failures = current_request.connection_attempts = 0
        current_request.max_connection_attempts = self.connection_manager.expected_failures + 1
        current_request.state = JOB_UNKNOWN

        accepted_jobs = self.connection_manager.wait_until_jobs_accepted([current_request])
        self.assertEquals(current_request.state, JOB_CREATED)
        self.assertEquals(current_request.connection_attempts, current_request.max_connection_attempts)

        # Second pass should fail as we JUST exceed our max attempts
        self.connection_manager.current_failures = current_request.connection_attempts = 0
        current_request.max_connection_attempts = self.connection_manager.expected_failures
        current_request.state = JOB_UNKNOWN

        self.assertRaises(ExceededConnectionAttempts, self.connection_manager.wait_until_jobs_accepted, [current_request])
        self.assertEquals(current_request.state, JOB_UNKNOWN)
        self.assertEquals(current_request.connection_attempts, current_request.max_connection_attempts)

    def test_multiple_fg_job_submission(self):
        submitted_job_count = 5
        expected_job_list = [self.generate_job() for _ in xrange(submitted_job_count)]
        def mark_jobs_created(rx_conns, wr_conns, ex_conns):
            for current_job in expected_job_list:
                self.command_handler.recv_command(GEARMAN_COMMAND_JOB_CREATED, job_handle=current_job.handle)

            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = mark_jobs_created

        job_dictionaries = [current_job.to_dict() for current_job in expected_job_list]

        # Test multiple job submission
        job_requests = self.connection_manager.submit_multiple_jobs(job_dictionaries, wait_until_complete=False)
        for current_request, expected_job in zip(job_requests, expected_job_list):
            current_job = current_request.job
            self.assert_jobs_equal(current_job, expected_job)

            self.assertEqual(current_request.priority, PRIORITY_NONE)
            self.assertEqual(current_request.background, False)
            self.assertEqual(current_request.state, JOB_CREATED)

            self.assertFalse(current_request.complete)

    def test_single_bg_job_submission(self):
        expected_job = self.generate_job()
        def mark_job_created(rx_conns, wr_conns, ex_conns):
            self.command_handler.recv_command(GEARMAN_COMMAND_JOB_CREATED, job_handle=expected_job.handle)
            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = mark_job_created
        job_request = self.connection_manager.submit_job(expected_job.task, expected_job.data, unique=expected_job.unique, background=True, priority=PRIORITY_LOW, wait_until_complete=False)

        current_job = job_request.job
        self.assert_jobs_equal(current_job, expected_job)

        self.assertEqual(job_request.priority, PRIORITY_LOW)
        self.assertEqual(job_request.background, True)
        self.assertEqual(job_request.state, JOB_CREATED)

        self.assertTrue(job_request.complete)

    def test_single_fg_job_submission_timeout(self):
        expected_job = self.generate_job()
        def job_failed_submission(rx_conns, wr_conns, ex_conns):
            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = job_failed_submission
        job_request = self.connection_manager.submit_job(expected_job.task, expected_job.data, unique=expected_job.unique, priority=PRIORITY_HIGH, poll_timeout=0.01)

        self.assertEqual(job_request.priority, PRIORITY_HIGH)
        self.assertEqual(job_request.background, False)
        self.assertEqual(job_request.state, JOB_PENDING)

        self.assertFalse(job_request.complete)
        self.assertTrue(job_request.timed_out)

    def test_wait_for_multiple_jobs_to_complete_or_timeout(self):
        completed_request = self.generate_job_request()
        failed_request = self.generate_job_request()
        timeout_request = self.generate_job_request()

        self.update_requests = True
        def multiple_job_updates(rx_conns, wr_conns, ex_conns):
            # Only give a single status update and have the 3rd job handle timeout
            if self.update_requests:
                self.command_handler.recv_command(GEARMAN_COMMAND_WORK_COMPLETE, job_handle=completed_request.job.handle, data='12345')
                self.command_handler.recv_command(GEARMAN_COMMAND_WORK_FAIL, job_handle=failed_request.job.handle)
                self.update_requests = False

            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = multiple_job_updates

        finished_requests = self.connection_manager.wait_until_jobs_completed([completed_request, failed_request, timeout_request], poll_timeout=0.01)
        del self.update_requests

        finished_completed_request, finished_failed_request, finished_timeout_request = finished_requests

        self.assert_jobs_equal(finished_completed_request.job, completed_request.job)
        self.assertEqual(finished_completed_request.state, JOB_COMPLETE)
        self.assertEqual(finished_completed_request.result, '12345')
        self.assertFalse(finished_completed_request.timed_out)
        #self.assert_(finished_completed_request.job.handle not in self.command_handler.handle_to_request_map)

        self.assert_jobs_equal(finished_failed_request.job, failed_request.job)
        self.assertEqual(finished_failed_request.state, JOB_FAILED)
        self.assertEqual(finished_failed_request.result, None)
        self.assertFalse(finished_failed_request.timed_out)
        #self.assert_(finished_failed_request.job.handle not in self.command_handler.handle_to_request_map)

        self.assertEqual(finished_timeout_request.state, JOB_CREATED)
        self.assertEqual(finished_timeout_request.result, None)
        self.assertTrue(finished_timeout_request.timed_out)
        self.assert_(finished_timeout_request.job.handle in self.command_handler.handle_to_request_map)

    def test_get_job_status(self):
        single_request = self.generate_job_request()

        def retrieve_status(rx_conns, wr_conns, ex_conns):
            self.command_handler.recv_command(GEARMAN_COMMAND_STATUS_RES, job_handle=single_request.job.handle, known='1', running='0', numerator='0', denominator='1')
            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = retrieve_status

        job_request = self.connection_manager.get_job_status(single_request)
        request_status = job_request.status
        self.failUnless(request_status)
        self.assertTrue(request_status['known'])
        self.assertFalse(request_status['running'])
        self.assertEqual(request_status['numerator'], 0)
        self.assertEqual(request_status['denominator'], 1)
        self.assertFalse(job_request.timed_out)

    def test_get_job_status_unknown(self):
        single_request = self.generate_job_request()
        current_handle = single_request.job.handle
        self.command_handler.recv_command(GEARMAN_COMMAND_WORK_FAIL, job_handle=current_handle)

        def retrieve_status(rx_conns, wr_conns, ex_conns):
            self.command_handler.recv_command(GEARMAN_COMMAND_STATUS_RES, job_handle=current_handle, known='0', running='0', numerator='0', denominator='1')
            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = retrieve_status

        job_request = self.connection_manager.get_job_status(single_request)
        request_status = job_request.status
        self.failUnless(request_status)
        self.assertFalse(request_status['known'])
        self.assertFalse(request_status['running'])
        self.assertEqual(request_status['numerator'], 0)
        self.assertEqual(request_status['denominator'], 1)
        self.assertFalse(job_request.timed_out)
        #self.assert_(current_handle not in self.command_handler.handle_to_request_map)

    def test_get_job_status_timeout(self):
        single_request = self.generate_job_request()

        def retrieve_status_timeout(rx_conns, wr_conns, ex_conns):
            return rx_conns, wr_conns, ex_conns

        self.connection_manager.handle_connection_activity = retrieve_status_timeout

        job_request = self.connection_manager.get_job_status(single_request, poll_timeout=0.01)
        self.assertTrue(job_request.timed_out)


class ClientCommandHandlerInterfaceTest(_GearmanAbstractTest):
    """Test the public interface a GearmanClient may need to call in order to update state on a GearmanClientCommandHandler"""
    connection_manager_class = MockGearmanClient
    command_handler_class = GearmanClientCommandHandler

    def test_send_job_request(self):
        current_request = self.generate_job_request()
        gearman_job = current_request.job

        for priority in (PRIORITY_NONE, PRIORITY_HIGH, PRIORITY_LOW):
            for background in (False, True):
                current_request.reset()
                current_request.priority = priority
                current_request.background = background

                self.command_handler.send_job_request(current_request)

                queued_request = self.command_handler.requests_awaiting_handles.popleft()
                self.assertEqual(queued_request, current_request)

                expected_cmd_type = submit_cmd_for_background_priority(background, priority)
                self.assert_sent_command(expected_cmd_type, task=gearman_job.task, data=gearman_job.data, unique=gearman_job.unique)

    def test_get_status_of_job(self):
        current_request = self.generate_job_request()

        self.command_handler.send_get_status_of_job(current_request)

        self.assert_sent_command(GEARMAN_COMMAND_GET_STATUS, job_handle=current_request.job.handle)


class ClientCommandHandlerStateMachineTest(_GearmanAbstractTest):
    """Test single state transitions within a GearmanWorkerCommandHandler"""
    connection_manager_class = MockGearmanClient
    command_handler_class = GearmanClientCommandHandler

    def generate_job_request(self, submitted=True, accepted=True):
        current_request = super(ClientCommandHandlerStateMachineTest, self).generate_job_request()
        if submitted or accepted:
            self.command_handler.requests_awaiting_handles.append(current_request)
            current_request.state = JOB_PENDING

        if submitted and accepted:
            self.command_handler.recv_command(GEARMAN_COMMAND_JOB_CREATED, job_handle=current_request.job.handle)

        return current_request

    def test_received_job_created(self):
        current_request = self.generate_job_request(accepted=False)

        new_handle = str(random.random())
        self.command_handler.recv_command(GEARMAN_COMMAND_JOB_CREATED, job_handle=new_handle)

        self.assertEqual(current_request.job.handle, new_handle)
        self.assertEqual(current_request.state, JOB_CREATED)
        self.assertEqual(self.command_handler.handle_to_request_map[new_handle], current_request)

    def test_received_job_created_out_of_order(self):
        self.assertEqual(self.command_handler.requests_awaiting_handles, collections.deque())

        # Make sure we bail cuz we have an empty queue
        self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_JOB_CREATED, job_handle=None)

    def test_required_state_pending(self):
        current_request = self.generate_job_request(submitted=False, accepted=False)

        new_handle = str(random.random())

        invalid_states = [JOB_UNKNOWN, JOB_CREATED, JOB_COMPLETE, JOB_FAILED]
        for bad_state in invalid_states:
            current_request.state = bad_state

            # We only want to check the state of request... not die if we don't have any pending requests
            self.command_handler.requests_awaiting_handles.append(current_request)

            self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_JOB_CREATED, job_handle=new_handle)

    def test_required_state_queued(self):
        current_request = self.generate_job_request()

        job_handle = current_request.job.handle
        new_data = str(random.random())

        invalid_states = [JOB_UNKNOWN, JOB_PENDING, JOB_COMPLETE, JOB_FAILED]
        for bad_state in invalid_states:
            current_request.state = bad_state

            # All these commands expect to be in JOB_CREATED
            self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_WORK_DATA, job_handle=job_handle, data=new_data)

            self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_WORK_WARNING, job_handle=job_handle, data=new_data)

            self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_WORK_STATUS, job_handle=job_handle, numerator=0, denominator=1)

            self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_WORK_COMPLETE, job_handle=job_handle, data=new_data)

            self.assertRaises(InvalidClientState, self.command_handler.recv_command, GEARMAN_COMMAND_WORK_FAIL, job_handle=job_handle)

    def test_in_flight_work_updates(self):
        current_request = self.generate_job_request()

        job_handle = current_request.job.handle
        new_data = str(random.random())

        # Test WORK_DATA
        self.command_handler.recv_command(GEARMAN_COMMAND_WORK_DATA, job_handle=job_handle, data=new_data)
        self.assertEqual(current_request.data_updates.popleft(), new_data)
        self.assertEqual(current_request.state, JOB_CREATED)

        # Test WORK_WARNING
        self.command_handler.recv_command(GEARMAN_COMMAND_WORK_WARNING, job_handle=job_handle, data=new_data)
        self.assertEqual(current_request.warning_updates.popleft(), new_data)
        self.assertEqual(current_request.state, JOB_CREATED)

        # Test WORK_STATUS
        self.command_handler.recv_command(GEARMAN_COMMAND_WORK_STATUS, job_handle=job_handle, numerator=0, denominator=1)

        self.assertEqual(current_request.status_updates.popleft(), (0, 1))
        self.assertEqual(current_request.state, JOB_CREATED)

    def test_work_complete(self):
        current_request = self.generate_job_request()

        job_handle = current_request.job.handle
        new_data = str(random.random())
        self.command_handler.recv_command(GEARMAN_COMMAND_WORK_COMPLETE, job_handle=job_handle, data=new_data)

        self.assertEqual(current_request.result, new_data)
        self.assertEqual(current_request.state, JOB_COMPLETE)

    def test_work_fail(self):
        current_request = self.generate_job_request()

        job_handle = current_request.job.handle
        new_data = str(random.random())
        self.command_handler.recv_command(GEARMAN_COMMAND_WORK_FAIL, job_handle=job_handle)

        self.assertEqual(current_request.state, JOB_FAILED)

    def test_status_request(self):
        current_request = self.generate_job_request()

        job_handle = current_request.job.handle

        self.assertEqual(current_request.status, {})

        self.command_handler.recv_command(GEARMAN_COMMAND_STATUS_RES, job_handle=job_handle, known='1', running='1', numerator='0', denominator='1')

        self.assertEqual(current_request.status['handle'], job_handle)
        self.assertTrue(current_request.status['known'])
        self.assertTrue(current_request.status['running'])
        self.assertEqual(current_request.status['numerator'], 0)
        self.assertEqual(current_request.status['denominator'], 1)

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = protocol_tests
import array
import struct
import unittest

from gearman import protocol

from gearman.connection import GearmanConnection
from gearman.constants import JOB_PENDING, JOB_CREATED, JOB_FAILED, JOB_COMPLETE
from gearman.errors import ConnectionError, ServerUnavailable, ProtocolError

from tests._core_testing import _GearmanAbstractTest

class ProtocolBinaryCommandsTest(unittest.TestCase):
    #######################
    # Begin parsing tests #
    #######################
    def test_parsing_errors(self):
        malformed_command_buffer = "%sAAAABBBBCCCC"

        # Raise malformed magic exceptions
        self.assertRaises(
            ProtocolError,
            protocol.parse_binary_command,
            array.array("c", malformed_command_buffer % "DDDD")
        )
        self.assertRaises(
            ProtocolError,
            protocol.parse_binary_command,
            array.array("c", malformed_command_buffer % protocol.MAGIC_RES_STRING),
            is_response=False
        )
        self.assertRaises(
            ProtocolError,
            protocol.parse_binary_command,
            array.array("c", malformed_command_buffer % protocol.MAGIC_REQ_STRING),
            is_response=True
        )

        # Raise unknown command errors
        unassigned_gearman_command = 1234
        unknown_command_buffer = struct.pack('!4sII', protocol.MAGIC_RES_STRING, unassigned_gearman_command, 0)
        unknown_command_buffer = array.array("c", unknown_command_buffer)
        self.assertRaises(ProtocolError, protocol.parse_binary_command, unknown_command_buffer)

        # Raise an error on our imaginary GEARMAN_COMMAND_TEXT_COMMAND
        imaginary_command_buffer = struct.pack('!4sII4s', protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_TEXT_COMMAND, 4, 'ABCD')
        imaginary_command_buffer = array.array("c", imaginary_command_buffer)
        self.assertRaises(ProtocolError, protocol.parse_binary_command, imaginary_command_buffer)

        # Raise an error on receiving an unexpected payload
        unexpected_payload_command_buffer = struct.pack('!4sII4s', protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_NOOP, 4, 'ABCD')
        unexpected_payload_command_buffer = array.array("c", unexpected_payload_command_buffer)
        self.assertRaises(ProtocolError, protocol.parse_binary_command, unexpected_payload_command_buffer)

    def test_parsing_request(self):
        # Test parsing a request for a job (server side parsing)
        grab_job_command_buffer = struct.pack('!4sII', protocol.MAGIC_REQ_STRING, protocol.GEARMAN_COMMAND_GRAB_JOB_UNIQ, 0)
        grab_job_command_buffer = array.array("c", grab_job_command_buffer)
        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(grab_job_command_buffer, is_response=False)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_GRAB_JOB_UNIQ)
        self.assertEquals(cmd_args, dict())
        self.assertEquals(cmd_len, len(grab_job_command_buffer))

    def test_parsing_without_enough_data(self):
        # Test that we return with nothing to do... received a partial packet
        not_enough_data_command_buffer = struct.pack('!4s', protocol.MAGIC_RES_STRING)
        not_enough_data_command_buffer = array.array("c", not_enough_data_command_buffer)
        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(not_enough_data_command_buffer)
        self.assertEquals(cmd_type, None)
        self.assertEquals(cmd_args, None)
        self.assertEquals(cmd_len, 0)

        # Test that we return with nothing to do... received a partial packet (expected binary payload of size 4, got 0)
        not_enough_data_command_buffer = struct.pack('!4sII', protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_ECHO_RES, 4)
        not_enough_data_command_buffer = array.array("c", not_enough_data_command_buffer)
        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(not_enough_data_command_buffer)
        self.assertEquals(cmd_type, None)
        self.assertEquals(cmd_args, None)
        self.assertEquals(cmd_len, 0)

    def test_parsing_no_args(self):
        noop_command_buffer = struct.pack('!4sII', protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_NOOP, 0)
        noop_command_buffer = array.array("c", noop_command_buffer)
        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(noop_command_buffer)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_NOOP)
        self.assertEquals(cmd_args, dict())
        self.assertEquals(cmd_len, len(noop_command_buffer))

    def test_parsing_single_arg(self):
        echoed_string = 'abcd'
        echo_command_buffer = struct.pack('!4sII4s', protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_ECHO_RES, 4, echoed_string)
        echo_command_buffer = array.array("c", echo_command_buffer)
        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(echo_command_buffer)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_ECHO_RES)
        self.assertEquals(cmd_args, dict(data=echoed_string))
        self.assertEquals(cmd_len, len(echo_command_buffer))

    def test_parsing_single_arg_with_extra_data(self):
        echoed_string = 'abcd'
        excess_bytes = 5
        excess_data = echoed_string + (protocol.NULL_CHAR * excess_bytes)
        excess_echo_command_buffer = struct.pack('!4sII9s', protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_ECHO_RES, 4, excess_data)
        excess_echo_command_buffer = array.array("c", excess_echo_command_buffer)

        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(excess_echo_command_buffer)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_ECHO_RES)
        self.assertEquals(cmd_args, dict(data=echoed_string))
        self.assertEquals(cmd_len, len(excess_echo_command_buffer) - excess_bytes)

    def test_parsing_multiple_args(self):
        # Tests ordered argument processing and proper NULL_CHAR splitting
        expected_data = protocol.NULL_CHAR * 4
        binary_payload = protocol.NULL_CHAR.join(['test', 'function', 'identifier', expected_data])
        payload_size = len(binary_payload)

        uniq_command_buffer = struct.pack('!4sII%ds' % payload_size, protocol.MAGIC_RES_STRING, protocol.GEARMAN_COMMAND_JOB_ASSIGN_UNIQ, payload_size, binary_payload)
        uniq_command_buffer = array.array("c", uniq_command_buffer)
        cmd_type, cmd_args, cmd_len = protocol.parse_binary_command(uniq_command_buffer)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_JOB_ASSIGN_UNIQ)
        self.assertEquals(cmd_args, dict(job_handle='test', task='function', unique='identifier', data=expected_data))
        self.assertEquals(cmd_len, len(uniq_command_buffer))

    #######################
    # Begin packing tests #
    #######################
    def test_packing_errors(self):
        # Assert we get an unknown command
        cmd_type = 1234
        cmd_args = dict()
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we get a fake command
        cmd_type = protocol.GEARMAN_COMMAND_TEXT_COMMAND
        cmd_args = dict()
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we get arg mismatch, got 1, expecting 0
        cmd_type = protocol.GEARMAN_COMMAND_GRAB_JOB
        cmd_args = dict(extra='arguments')
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we get arg mismatch, got 0, expecting 1
        cmd_type = protocol.GEARMAN_COMMAND_JOB_CREATED
        cmd_args = dict()
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we get arg mismatch (name), got 1, expecting 1
        cmd_type = protocol.GEARMAN_COMMAND_JOB_CREATED
        cmd_args = dict(extra='arguments')
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we get a non-string argument
        cmd_type = protocol.GEARMAN_COMMAND_JOB_CREATED
        cmd_args = dict(job_handle=12345)
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we get a non-string argument (expecting BYTES)
        cmd_type = protocol.GEARMAN_COMMAND_JOB_CREATED
        cmd_args = dict(job_handle=unicode(12345))
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we check for NULLs in all but the "last" argument, where last depends on the cmd_type.
        cmd_type = protocol.GEARMAN_COMMAND_SUBMIT_JOB
        cmd_args = dict(task='funct\x00ion', data='abcd', unique='12345')
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

        # Assert we check for NULLs in all but the "last" argument, where last depends on the cmd_type.
        cmd_type = protocol.GEARMAN_COMMAND_SUBMIT_JOB
        cmd_args = dict(task='function', data='ab\x00cd', unique='12345')
        protocol.pack_binary_command(cmd_type, cmd_args) # Should not raise, 'data' is last.

        # Assert we check for NULLs in all but the "last" argument, where last depends on the cmd_type.
        cmd_type = protocol.GEARMAN_COMMAND_SUBMIT_JOB
        cmd_args = dict(task='function', data='abcd', unique='123\x0045')
        self.assertRaises(ProtocolError, protocol.pack_binary_command, cmd_type, cmd_args)

    def test_packing_response(self):
        # Test packing a response for a job (server side packing)
        cmd_type = protocol.GEARMAN_COMMAND_NO_JOB
        cmd_args = dict()

        expected_command_buffer = struct.pack('!4sII', protocol.MAGIC_RES_STRING, cmd_type, 0)
        packed_command_buffer = protocol.pack_binary_command(cmd_type, cmd_args, is_response=True)
        self.assertEquals(packed_command_buffer, expected_command_buffer)

    def test_packing_no_arg(self):
        cmd_type = protocol.GEARMAN_COMMAND_NOOP
        cmd_args = dict()

        expected_command_buffer = struct.pack('!4sII', protocol.MAGIC_REQ_STRING, cmd_type, 0)
        packed_command_buffer = protocol.pack_binary_command(cmd_type, cmd_args)
        self.assertEquals(packed_command_buffer, expected_command_buffer)

    def test_packing_single_arg(self):
        cmd_type = protocol.GEARMAN_COMMAND_ECHO_REQ
        cmd_args = dict(data='abcde')

        expected_payload_size = len(cmd_args['data'])
        expected_format = '!4sII%ds' % expected_payload_size

        expected_command_buffer = struct.pack(expected_format, protocol.MAGIC_REQ_STRING, cmd_type, expected_payload_size, cmd_args['data'])
        packed_command_buffer = protocol.pack_binary_command(cmd_type, cmd_args)
        self.assertEquals(packed_command_buffer, expected_command_buffer)

    def test_packing_multiple_args(self):
        cmd_type = protocol.GEARMAN_COMMAND_SUBMIT_JOB
        cmd_args = dict(task='function', unique='12345', data='abcd')

        ordered_parameters = [cmd_args['task'], cmd_args['unique'], cmd_args['data']]

        expected_payload = protocol.NULL_CHAR.join(ordered_parameters)
        expected_payload_size = len(expected_payload)
        expected_format = '!4sII%ds' % expected_payload_size
        expected_command_buffer = struct.pack(expected_format, protocol.MAGIC_REQ_STRING, cmd_type, expected_payload_size, expected_payload)

        packed_command_buffer = protocol.pack_binary_command(cmd_type, cmd_args)
        self.assertEquals(packed_command_buffer, expected_command_buffer)

class ProtocolTextCommandsTest(unittest.TestCase):
	#######################
    # Begin parsing tests #
    #######################
    def test_parsing_errors(self):
        received_data = array.array("c", "Hello\x00there\n")
        self.assertRaises(ProtocolError, protocol.parse_text_command, received_data)

    def test_parsing_without_enough_data(self):
        received_data = array.array("c", "Hello there")
        cmd_type, cmd_response, cmd_len = protocol.parse_text_command(received_data)
        self.assertEquals(cmd_type, None)
        self.assertEquals(cmd_response, None)
        self.assertEquals(cmd_len, 0)

    def test_parsing_single_line(self):
        received_data = array.array("c", "Hello there\n")
        cmd_type, cmd_response, cmd_len = protocol.parse_text_command(received_data)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_TEXT_COMMAND)
        self.assertEquals(cmd_response, dict(raw_text=received_data.tostring().strip()))
        self.assertEquals(cmd_len, len(received_data))

    def test_parsing_multi_line(self):
        sentence_one = array.array("c", "Hello there\n")
        sentence_two = array.array("c", "My name is bob\n")
        received_data = sentence_one + sentence_two

        cmd_type, cmd_response, cmd_len = protocol.parse_text_command(received_data)
        self.assertEquals(cmd_type, protocol.GEARMAN_COMMAND_TEXT_COMMAND)
        self.assertEquals(cmd_response, dict(raw_text=sentence_one.tostring().strip()))
        self.assertEquals(cmd_len, len(sentence_one))

    def test_packing_errors(self):
        # Test bad command type
        cmd_type = protocol.GEARMAN_COMMAND_NOOP
        cmd_args = dict()
        self.assertRaises(ProtocolError, protocol.pack_text_command, cmd_type, cmd_args)

        # Test missing args
        cmd_type = protocol.GEARMAN_COMMAND_TEXT_COMMAND
        cmd_args = dict()
        self.assertRaises(ProtocolError, protocol.pack_text_command, cmd_type, cmd_args)

        # Test misnamed parameter dict
        cmd_type = protocol.GEARMAN_COMMAND_TEXT_COMMAND
        cmd_args = dict(bad_text='abcdefghij')
        self.assertRaises(ProtocolError, protocol.pack_text_command, cmd_type, cmd_args)

    #######################
    # Begin packing tests #
    #######################
    def test_packing_single_line(self):
        expected_string = 'Hello world'
        cmd_type = protocol.GEARMAN_COMMAND_TEXT_COMMAND
        cmd_args = dict(raw_text=expected_string)

        packed_command = protocol.pack_text_command(cmd_type, cmd_args)
        self.assertEquals(packed_command, expected_string)

class GearmanConnectionTest(unittest.TestCase):
    """Tests the base CommandHandler class that underpins all other CommandHandlerTests"""
    def test_recv_command(self):
        pass

class GearmanCommandHandlerTest(_GearmanAbstractTest):
    """Tests the base CommandHandler class that underpins all other CommandHandlerTests"""
    def _test_recv_command(self):
        # recv_echo_res and recv_error are predefined on the CommandHandler
        self.command_handler.recv_command(protocol.GEARMAN_COMMAND_NOOP)
        self.assert_recv_command(protocol.GEARMAN_COMMAND_NOOP)

        # The mock handler never implemented 'recv_all_yours' so we should get an attribute error here
        self.assertRaises(ValueError, self.command_handler.recv_command, protocol.GEARMAN_COMMAND_ALL_YOURS)

    def _test_send_command(self):
        self.command_handler.send_command(protocol.GEARMAN_COMMAND_NOOP)
        self.assert_sent_command(protocol.GEARMAN_COMMAND_NOOP)

        # The mock handler never implemented 'recv_all_yours' so we should get an attribute error here
        self.command_handler.send_command(protocol.GEARMAN_COMMAND_ECHO_REQ, text='hello world')
        self.assert_sent_command(protocol.GEARMAN_COMMAND_ECHO_REQ, text='hello world')

    def assert_recv_command(self, expected_cmd_type, **expected_cmd_args):
        cmd_type, cmd_args = self.command_handler.recv_command_queue.popleft()
        self.assert_commands_equal(cmd_type, expected_cmd_type)
        self.assertEqual(cmd_args, expected_cmd_args)

    def assert_sent_command(self, expected_cmd_type, **expected_cmd_args):
        # All commands should be sent via the CommandHandler
        handler_cmd_type, handler_cmd_args = self.command_handler.sent_command_queue.popleft()
        self.assert_commands_equal(handler_cmd_type, expected_cmd_type)
        self.assertEqual(handler_cmd_args, expected_cmd_args)

        super(GearmanCommandHandlerTest, self).assert_sent_command(expected_cmd_type, **expected_cmd_args)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = worker_tests
import collections
from gearman import compat
import unittest

from gearman.worker import GearmanWorker
from gearman.worker_handler import GearmanWorkerCommandHandler

from gearman.errors import ServerUnavailable, InvalidWorkerState
from gearman.protocol import get_command_name, GEARMAN_COMMAND_RESET_ABILITIES, GEARMAN_COMMAND_CAN_DO, GEARMAN_COMMAND_SET_CLIENT_ID, \
    GEARMAN_COMMAND_NOOP, GEARMAN_COMMAND_PRE_SLEEP, GEARMAN_COMMAND_NO_JOB, GEARMAN_COMMAND_GRAB_JOB_UNIQ, GEARMAN_COMMAND_JOB_ASSIGN_UNIQ, \
    GEARMAN_COMMAND_WORK_STATUS, GEARMAN_COMMAND_WORK_FAIL, GEARMAN_COMMAND_WORK_COMPLETE, GEARMAN_COMMAND_WORK_DATA, GEARMAN_COMMAND_WORK_EXCEPTION, GEARMAN_COMMAND_WORK_WARNING

from tests._core_testing import _GearmanAbstractTest, MockGearmanConnectionManager, MockGearmanConnection

class MockGearmanWorker(MockGearmanConnectionManager, GearmanWorker):
    def __init__(self, *largs, **kwargs):
        super(MockGearmanWorker, self).__init__(*largs, **kwargs)
        self.worker_job_queues = compat.defaultdict(collections.deque)

    def on_job_execute(self, current_job):
        current_handler = self.connection_to_handler_map[current_job.connection]
        self.worker_job_queues[current_handler].append(current_job)

class _GearmanAbstractWorkerTest(_GearmanAbstractTest):
    connection_manager_class = MockGearmanWorker
    command_handler_class = GearmanWorkerCommandHandler

    def setup_command_handler(self):
        super(_GearmanAbstractWorkerTest, self).setup_command_handler()
        self.assert_sent_abilities([])
        self.assert_sent_command(GEARMAN_COMMAND_PRE_SLEEP)

    def assert_sent_abilities(self, expected_abilities):
        observed_abilities = set()

        self.assert_sent_command(GEARMAN_COMMAND_RESET_ABILITIES)
        for ability in expected_abilities:
            cmd_type, cmd_args = self.connection._outgoing_commands.popleft()

            self.assertEqual(get_command_name(cmd_type), get_command_name(GEARMAN_COMMAND_CAN_DO))
            observed_abilities.add(cmd_args['task'])

        self.assertEqual(observed_abilities, set(expected_abilities))

    def assert_sent_client_id(self, expected_client_id):
        self.assert_sent_command(GEARMAN_COMMAND_SET_CLIENT_ID, client_id=expected_client_id)

class WorkerTest(_GearmanAbstractWorkerTest):
    """Test the public worker interface"""
    def test_registering_functions(self):
        # Tests that the abilities were set on the GearmanWorker AND the GearmanWorkerCommandHandler
        # Does NOT test that commands were actually sent out as that is tested in GearmanWorkerCommandHandlerInterfaceTest.test_set_abilities
        def fake_callback_one(worker_command_handler, current_job):
            pass

        def fake_callback_two(worker_command_handler, current_job):
            pass

        # Register a single callback
        self.connection_manager.register_task('fake_callback_one', fake_callback_one)
        self.failUnless('fake_callback_one' in self.connection_manager.worker_abilities)
        self.failIf('fake_callback_two' in self.connection_manager.worker_abilities)
        self.assertEqual(self.connection_manager.worker_abilities['fake_callback_one'], fake_callback_one)
        self.assertEqual(self.command_handler._handler_abilities, ['fake_callback_one'])

        # Register another callback and make sure the command_handler sees the same functions
        self.connection_manager.register_task('fake_callback_two', fake_callback_two)
        self.failUnless('fake_callback_one' in self.connection_manager.worker_abilities)
        self.failUnless('fake_callback_two' in self.connection_manager.worker_abilities)
        self.assertEqual(self.connection_manager.worker_abilities['fake_callback_one'], fake_callback_one)
        self.assertEqual(self.connection_manager.worker_abilities['fake_callback_two'], fake_callback_two)
        self.assertEqual(self.command_handler._handler_abilities, ['fake_callback_one', 'fake_callback_two'])

        # Unregister a callback and make sure the command_handler sees the same functions
        self.connection_manager.unregister_task('fake_callback_one')
        self.failIf('fake_callback_one' in self.connection_manager.worker_abilities)
        self.failUnless('fake_callback_two' in self.connection_manager.worker_abilities)
        self.assertEqual(self.connection_manager.worker_abilities['fake_callback_two'], fake_callback_two)
        self.assertEqual(self.command_handler._handler_abilities, ['fake_callback_two'])

    def test_setting_client_id(self):
        new_client_id = 'HELLO'

        # Make sure nothing is set
        self.assertEqual(self.connection_manager.worker_client_id, None)
        self.assertEqual(self.command_handler._client_id, None)

        self.connection_manager.set_client_id(new_client_id)

        # Make sure both the client and the connection handler reflect the new state
        self.assertEqual(self.connection_manager.worker_client_id, new_client_id)
        self.assertEqual(self.command_handler._client_id, new_client_id)

    def test_establish_worker_connections(self):
        self.connection_manager.connection_list = []
        self.connection_manager.command_handlers = {}

        # Spin up a bunch of imaginary gearman connections
        good_connection = MockGearmanConnection()
        good_connection.connect()
        good_connection._fail_on_bind = False

        failed_then_retried_connection = MockGearmanConnection()
        failed_then_retried_connection._fail_on_bind = False

        failed_connection = MockGearmanConnection()
        failed_connection._fail_on_bind = True

        # Register all our connections
        self.connection_manager.connection_list = [good_connection, failed_then_retried_connection, failed_connection]

        # The only alive connections should be the ones that ultimately be connection.connected
        alive_connections = self.connection_manager.establish_worker_connections()
        self.assertTrue(good_connection in alive_connections)
        self.assertTrue(failed_then_retried_connection in alive_connections)
        self.assertFalse(failed_connection in alive_connections)

    def test_establish_worker_connections_dead(self):
        self.connection_manager.connection_list = []
        self.connection_manager.command_handlers = {}

        # We have no connections so there will never be any work to do
        self.assertRaises(ServerUnavailable, self.connection_manager.work)

        # We were started with a dead connection, make sure we bail again
        dead_connection = MockGearmanConnection()
        dead_connection._fail_on_bind = True
        dead_connection.connected = False
        self.connection_manager.connection_list = [dead_connection]

        self.assertRaises(ServerUnavailable, self.connection_manager.work)


class WorkerCommandHandlerInterfaceTest(_GearmanAbstractWorkerTest):
    """Test the public interface a GearmanWorker may need to call in order to update state on a GearmanWorkerCommandHandler"""

    def test_on_connect(self):
        expected_abilities = ['function_one', 'function_two', 'function_three']
        expected_client_id = 'my_client_id'

        self.connection.connected = False

        self.connection_manager.set_client_id(expected_client_id)
        self.connection_manager.unregister_task('__test_ability__')
        for task in expected_abilities:
            self.connection_manager.register_task(task, None)

        # We were disconnected, connect and wipe pending commands
        self.connection_manager.establish_connection(self.connection)

        # When we attempt a new connection, make sure we get a new command handler
        self.assertNotEquals(self.command_handler, self.connection_manager.connection_to_handler_map[self.connection])

        self.assert_sent_client_id(expected_client_id)
        self.assert_sent_abilities(expected_abilities)
        self.assert_sent_command(GEARMAN_COMMAND_PRE_SLEEP)
        self.assert_no_pending_commands()

    def test_set_abilities(self):
        expected_abilities = ['function_one', 'function_two', 'function_three']

        # We were disconnected, connect and wipe pending commands
        self.command_handler.set_abilities(expected_abilities)
        self.assert_sent_abilities(expected_abilities)
        self.assert_no_pending_commands()

    def test_set_client_id(self):
        expected_client_id = 'my_client_id'

        handler_initial_state = {}
        handler_initial_state['abilities'] = []
        handler_initial_state['client_id'] = None

        # We were disconnected, connect and wipe pending commands
        self.command_handler.set_client_id(expected_client_id)
        self.assert_sent_client_id(expected_client_id)
        self.assert_no_pending_commands()

    def test_send_functions(self):
        current_job = self.generate_job()

        # Test GEARMAN_COMMAND_WORK_STATUS
        self.command_handler.send_job_status(current_job, 0, 1)
        self.assert_sent_command(GEARMAN_COMMAND_WORK_STATUS, job_handle=current_job.handle, numerator='0', denominator='1')

        # Test GEARMAN_COMMAND_WORK_COMPLETE
        self.command_handler.send_job_complete(current_job, 'completion data')
        self.assert_sent_command(GEARMAN_COMMAND_WORK_COMPLETE, job_handle=current_job.handle, data='completion data')

        # Test GEARMAN_COMMAND_WORK_FAIL
        self.command_handler.send_job_failure(current_job)
        self.assert_sent_command(GEARMAN_COMMAND_WORK_FAIL, job_handle=current_job.handle)

        # Test GEARMAN_COMMAND_WORK_EXCEPTION
        self.command_handler.send_job_exception(current_job, 'exception data')
        self.assert_sent_command(GEARMAN_COMMAND_WORK_EXCEPTION, job_handle=current_job.handle, data='exception data')

        # Test GEARMAN_COMMAND_WORK_DATA
        self.command_handler.send_job_data(current_job, 'job data')
        self.assert_sent_command(GEARMAN_COMMAND_WORK_DATA, job_handle=current_job.handle, data='job data')

        # Test GEARMAN_COMMAND_WORK_WARNING
        self.command_handler.send_job_warning(current_job, 'job warning')
        self.assert_sent_command(GEARMAN_COMMAND_WORK_WARNING, job_handle=current_job.handle, data='job warning')

class WorkerCommandHandlerStateMachineTest(_GearmanAbstractWorkerTest):
    """Test multiple state transitions within a GearmanWorkerCommandHandler

    End to end tests without a server
    """
    connection_manager_class = MockGearmanWorker
    command_handler_class = GearmanWorkerCommandHandler

    def setup_connection_manager(self):
        super(WorkerCommandHandlerStateMachineTest, self).setup_connection_manager()
        self.connection_manager.register_task('__test_ability__', None)

    def setup_command_handler(self):
        super(_GearmanAbstractWorkerTest, self).setup_command_handler()
        self.assert_sent_abilities(['__test_ability__'])
        self.assert_sent_command(GEARMAN_COMMAND_PRE_SLEEP)

    def test_wakeup_work(self):
        self.move_to_state_wakeup()

        self.move_to_state_job_assign_uniq(self.generate_job_dict())

        self.move_to_state_wakeup()

        self.move_to_state_no_job()

    def test_wakeup_sleep_wakup_work(self):
        self.move_to_state_wakeup()

        self.move_to_state_no_job()

        self.move_to_state_wakeup()

        self.move_to_state_job_assign_uniq(self.generate_job_dict())

        self.move_to_state_wakeup()

        self.move_to_state_no_job()

    def test_multiple_wakeup_then_no_work(self):
        # Awaken the state machine... then give it no work
        self.move_to_state_wakeup()

        for _ in range(5):
            self.command_handler.recv_command(GEARMAN_COMMAND_NOOP)

        self.assert_job_lock(is_locked=True)

        # Pretend like the server has no work... do nothing
        # Moving to state NO_JOB will make sure there's only 1 item on the queue
        self.move_to_state_no_job()

    def test_multiple_work(self):
        self.move_to_state_wakeup()

        self.move_to_state_job_assign_uniq(self.generate_job_dict())

        self.move_to_state_wakeup()

        self.move_to_state_job_assign_uniq(self.generate_job_dict())

        self.move_to_state_wakeup()

        self.move_to_state_job_assign_uniq(self.generate_job_dict())

        self.move_to_state_wakeup()

        # After this job completes, we're going to greedily ask for more jobs
        self.move_to_state_no_job()

    def test_worker_already_locked(self):
        other_connection = MockGearmanConnection()
        self.connection_manager.connection_list.append(other_connection)
        self.connection_manager.establish_connection(other_connection)

        other_handler = self.connection_manager.connection_to_handler_map[other_connection]
        other_handler.recv_command(GEARMAN_COMMAND_NOOP)

        # Make sure other handler has a lock
        self.assertEqual(self.connection_manager.command_handler_holding_job_lock, other_handler)

        # Make sure OUR handler has nothing incoming
        self.assert_no_pending_commands()

        # Make sure we try to grab a job but fail...so go back to sleep
        self.command_handler.recv_command(GEARMAN_COMMAND_NOOP)
        self.assert_sent_command(GEARMAN_COMMAND_PRE_SLEEP)

        # Make sure other handler still has lock
        self.assertEqual(self.connection_manager.command_handler_holding_job_lock, other_handler)

        # Make the other handler release its lock
        other_handler.recv_command(GEARMAN_COMMAND_NO_JOB)

        # Ensure that the lock has been freed
        self.assert_job_lock(is_locked=False)

        # Try to do work after we have our lock released
        self.move_to_state_wakeup()

        self.move_to_state_job_assign_uniq(self.generate_job_dict())

        self.move_to_state_wakeup()

        self.move_to_state_no_job()

    def move_to_state_wakeup(self):
        self.assert_no_pending_commands()
        self.assert_job_lock(is_locked=False)

        self.command_handler.recv_command(GEARMAN_COMMAND_NOOP)

    def move_to_state_no_job(self):
        """Move us to the NO_JOB state...

        1) We should've most recently sent only a single GEARMAN_COMMAND_GRAB_JOB_UNIQ
        2) We should be awaiting job assignment
        3) Once we receive a NO_JOB, we should say we're going back to sleep"""
        self.assert_awaiting_job()

        self.command_handler.recv_command(GEARMAN_COMMAND_NO_JOB)

        # We should be asleep... which means no pending jobs and we're not awaiting job assignment
        self.assert_sent_command(GEARMAN_COMMAND_PRE_SLEEP)
        self.assert_no_pending_commands()
        self.assert_job_lock(is_locked=False)

    def move_to_state_job_assign_uniq(self, fake_job):
        """Move us to the JOB_ASSIGN_UNIQ state...

        1) We should've most recently sent only a single GEARMAN_COMMAND_GRAB_JOB_UNIQ
        2) We should be awaiting job assignment
        3) The job we receive should be the one we expected"""
        self.assert_awaiting_job()

        ### NOTE: This recv_command does NOT send out a GEARMAN_COMMAND_JOB_COMPLETE or GEARMAN_COMMAND_JOB_FAIL
        ###           as we're using a MockGearmanConnectionManager with a method that only queues the job
        self.command_handler.recv_command(GEARMAN_COMMAND_JOB_ASSIGN_UNIQ, **fake_job)

        current_job = self.connection_manager.worker_job_queues[self.command_handler].popleft()
        self.assertEqual(current_job.handle, fake_job['job_handle'])
        self.assertEqual(current_job.task, fake_job['task'])
        self.assertEqual(current_job.unique, fake_job['unique'])
        self.assertEqual(current_job.data, fake_job['data'])

        # At the end of recv_command(GEARMAN_COMMAND_JOB_ASSIGN_UNIQ)
        self.assert_job_lock(is_locked=False)
        self.assert_sent_command(GEARMAN_COMMAND_PRE_SLEEP)

    def assert_awaiting_job(self):
        self.assert_sent_command(GEARMAN_COMMAND_GRAB_JOB_UNIQ)
        self.assert_no_pending_commands()

    def assert_job_lock(self, is_locked):
        expected_value = (is_locked and self.command_handler) or None
        self.assertEqual(self.connection_manager.command_handler_holding_job_lock, expected_value)

if __name__ == '__main__':
    unittest.main()


########NEW FILE########
__FILENAME__ = _core_testing
import collections
import random
import unittest

import gearman.util
from gearman.command_handler import GearmanCommandHandler
from gearman.connection import GearmanConnection
from gearman.connection_manager import GearmanConnectionManager, NoopEncoder

from gearman.constants import PRIORITY_NONE, PRIORITY_HIGH, PRIORITY_LOW, DEFAULT_GEARMAN_PORT, JOB_UNKNOWN, JOB_CREATED
from gearman.errors import ConnectionError
from gearman.job import GearmanJob, GearmanJobRequest
from gearman.protocol import get_command_name

class MockGearmanConnection(GearmanConnection):
    def __init__(self, host=None, port=DEFAULT_GEARMAN_PORT):
        host = host or '__testing_host__'
        super(MockGearmanConnection, self).__init__(host=host, port=port)

        self._fail_on_bind = False
        self._fail_on_read = False
        self._fail_on_write = False

    def _create_client_socket(self):
        if self._fail_on_bind:
            self.throw_exception(message='mock bind failure')

    def read_data_from_socket(self):
        if self._fail_on_read:
            self.throw_exception(message='mock read failure')

    def send_data_to_socket(self):
        if self._fail_on_write:
            self.throw_exception(message='mock write failure')

    def fileno(self):
        # 73 is the best number, so why not?
        return 73

    def __repr__(self):
        return ('<GearmanConnection %s:%d connected=%s> (%s)' %
            (self.gearman_host, self.gearman_port, self.connected, id(self)))

class MockGearmanConnectionManager(GearmanConnectionManager):
    """Handy mock client base to test Worker/Client/Abstract ClientBases"""
    def poll_connections_once(self, poller, connection_map, timeout=None):
        return set(), set(), set()

    def _register_connections_with_poller(self, connections, poller):
        pass

class _GearmanAbstractTest(unittest.TestCase):
    connection_class = MockGearmanConnection
    connection_manager_class = MockGearmanConnectionManager
    command_handler_class = None

    job_class = GearmanJob
    job_request_class = GearmanJobRequest

    def setUp(self):
        # Create a new MockGearmanTestClient on the fly
        self.setup_connection_manager()
        self.setup_connection()
        self.setup_command_handler()

    def setup_connection_manager(self):
        testing_attributes = {'command_handler_class': self.command_handler_class, 'connection_class': self.connection_class}
        testing_client_class = type('MockGearmanTestingClient', (self.connection_manager_class, ), testing_attributes)

        self.connection_manager = testing_client_class()

    def setup_connection(self):
        self.connection = self.connection_class()
        self.connection_manager.connection_list = [self.connection]

    def setup_command_handler(self):
        self.connection_manager.establish_connection(self.connection)
        self.command_handler = self.connection_manager.connection_to_handler_map[self.connection]

    def generate_job(self):
        return self.job_class(self.connection, handle=str(random.random()), task='__test_ability__', unique=str(random.random()), data=str(random.random()))

    def generate_job_dict(self):
        current_job = self.generate_job()
        return current_job.to_dict()

    def generate_job_request(self, priority=PRIORITY_NONE, background=False):
        job_handle = str(random.random())
        current_job = self.job_class(connection=self.connection, handle=job_handle, task='__test_ability__', unique=str(random.random()), data=str(random.random()))
        current_request = self.job_request_class(current_job, initial_priority=priority, background=background)

        self.assertEqual(current_request.state, JOB_UNKNOWN)

        return current_request

    def assert_jobs_equal(self, job_actual, job_expected):
        # Validates that GearmanJobs are essentially equal
        self.assertEqual(job_actual.handle, job_expected.handle)
        self.assertEqual(job_actual.task, job_expected.task)
        self.assertEqual(job_actual.unique, job_expected.unique)
        self.assertEqual(job_actual.data, job_expected.data)

    def assert_sent_command(self, expected_cmd_type, **expected_cmd_args):
        # Make sure any commands we're passing through the CommandHandler gets properly passed through to the client base
        client_cmd_type, client_cmd_args = self.connection._outgoing_commands.popleft()
        self.assert_commands_equal(client_cmd_type, expected_cmd_type)
        self.assertEqual(client_cmd_args, expected_cmd_args)

    def assert_no_pending_commands(self):
        self.assertEqual(self.connection._outgoing_commands, collections.deque())

    def assert_commands_equal(self, cmd_type_actual, cmd_type_expected):
        self.assertEqual(get_command_name(cmd_type_actual), get_command_name(cmd_type_expected))

########NEW FILE########
