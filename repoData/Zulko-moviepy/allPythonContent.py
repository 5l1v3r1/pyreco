__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# MoviePy documentation build configuration file, created by
# sphinx-quickstart on Sat Jul 13 14:47:48 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo',
              'sphinx.ext.viewcode', 'sphinx.ext.autosummary','numpydoc']

numpydoc_class_members_toctree= False
numpydoc_show_class_members= False
autosummary_generate= True

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'MoviePy'
copyright = u'2013, Zulko'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.2'
# The full version, including alpha/beta/rc tags.
release = '0.2'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
sys.path.append(os.path.abspath('_themes'))
sys.path.append("../moviepy")
html_theme_path = ['_themes']
html_theme = 'kr'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
html_logo = '_static/logo_small.jpeg'

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'MoviePydoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'MoviePy.tex', u'MoviePy Documentation',
   u'Zulko', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'moviepy', u'MoviePy Documentation',
     [u'Zulko'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'MoviePy', u'MoviePy Documentation',
   u'Zulko', 'MoviePy', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'MoviePy'
epub_author = u'Zulko'
epub_publisher = u'Zulko'
epub_copyright = u'2013, Zulko'

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# A tuple containing the cover image and cover page html template filenames.
#epub_cover = ()

# A sequence of (type, uri, title) tuples for the guide element of content.opf.
#epub_guide = ()

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True

# Fix unsupported image types using the PIL.
#epub_fix_images = False

# Scale large images.
#epub_max_image_width = 0

# If 'no', URL addresses will not be shown.
#epub_show_urls = 'inline'

# If false, no index is generated.
#epub_use_index = True

#autodoc_member_order = 'bysource'

########NEW FILE########
__FILENAME__ = clips_array
from moviepy.editor import *



########NEW FILE########
__FILENAME__ = compo_from_image
from moviepy.editor import *
from moviepy.video.tools.segmenting import findObjects

# Load the image specifying the regions.
im = ImageClip("../../ultracompositing/motif.png")

# Loacate the regions, return a list of ImageClips
regions = findObjects(im)


# Load 7 clips from the US National Parks. Public Domain :D
clips = [VideoFileClip(n, audio=False).subclip(18,22) for n in
     [ "../../videos/romo_0004.mov",
      "../../videos/apis-0001.mov",
      "../../videos/romo_0001.mov",
      "../../videos/elma_s0003.mov",
      "../../videos/elma_s0002.mov",
      "../../videos/calo-0007.mov",
      "../../videos/grsm_0005.mov"]]

# fit each clip into its region
comp_clips =  [c.resize(r.size).\
                 set_mask(r.mask).\
                 set_pos(r.screenpos)
               for c,r in zip(clips,regions)]

cc = CompositeVideoClip(comp_clips,im.size)
cc.resize(0.6).to_videofile("../../bigcompo.avi")

# Note that this particular composition takes quite a long time of
# rendering (about 20s on my computer for just 4s of video).

########NEW FILE########
__FILENAME__ = example_with_sound
"""
Description of the video:
The screen is split in two parts showing Carry and Audrey at the phone,
talking at the same time, because it is actually two scenes of a same
movie put together.
"""

from moviepy.editor import *
from moviepy.video.tools.drawing import color_split


duration = 6 # duration of the final clip

# LOAD THE MAIN SCENE
# this small video contains the two scenes that we will put together.

main_clip = VideoFileClip("../../videos/charadePhone.mp4")
W,H = main_clip.size



# MAKE THE LEFT CLIP : cut, crop, add a mask 
                            
mask = color_split((2*W/3,H),
                   p1=(W/3,H), p2=(2*W/3,0),
                   col1=1, col2=0,
                   grad_width=2)
                   
mask_clip = ImageClip(mask, ismask=True)
                   
clip_left = (main_clip.coreader()
                      .subclip(0,duration)
                      .crop( x1=60, x2=60 + 2*W/3)
                      .set_mask(mask_clip))


# MAKE THE RIGHT CLIP : cut, crop, add a mask 
                   
mask = color_split((2*W/3,H),
                   p1=(2,H), p2=(W/3+2,0),
                   col1=0, col2=1,
                   grad_width=2)

mask_clip = ImageClip(mask, ismask=True)

clip_right = (main_clip.coreader()
                       .subclip(21,21+duration)
                       .crop(x1=70, x2=70+2*W/3)
                       .set_mask(mask_clip))




# ASSEMBLE AND WRITE THE MOVIE TO A FILE

cc = CompositeVideoClip([clip_right.set_pos('right').volumex(0.4),
                         clip_left.set_pos('left').volumex(0.4)],
                         size = (W,H))
#cc.preview()
cc.to_videofile("../../biphone3.avi",fps=24, codec='mpeg4')

########NEW FILE########
__FILENAME__ = headblur
import pickle

from moviepy.editor import *
from moviepy.video.tools.tracking import manual_tracking, to_fxfy


# LOAD THE CLIP (subclip 6'51 - 7'01 of a chaplin movie)
clip = VideoFileClip("../../videos/chaplin.mp4").subclip((6,51.7),(7,01.3))

# MANUAL TRACKING OF THE HEAD

# the three next lines are for the manual tracking and its saving
# to a file, it must be commented once the tracking has been done
# (after the first run of the script for instance).
# Note that we save the list (ti,xi,yi), not the functions fx and fy
# (that we will need) because they have dependencies.

#txy, (fx,fy) = manual_tracking(clip, fps=6)
#with open("../../chaplin_txy.dat",'w+') as f:
#    pickle.dump(txy)



# IF THE MANUAL TRACKING HAS BEEN PREVIOUSLY DONE,
# LOAD THE TRACKING DATA AND CONVERT IT TO FUNCTIONS x(t),fy(t)

with open("../../chaplin_txy.dat",'r') as f:
    fx,fy = to_fxfy( pickle.load(f) )


# BLUR CHAPLIN'S HEAD IN THE CLIP

clip_blurred = clip.fx( vfx.headblur, fx, fy, 25)


# Generate the text, put in on a grey background

txt = TextClip("Hey you ! \n You're blurry!", color='grey70',
               size = clip.size, bg_color='grey20',
               font = "Century-Schoolbook-Italic", fontsize=40)
               
               
# Concatenate the Chaplin clip with the text clip, add audio

final = concatenate([clip_blurred,txt.set_duration(3)]).\
          set_audio(clip.audio)

# We write the result to a file. Here we raise the bitrate so that
# the final video is not too ugly.

final.to_videofile('../../blurredChaplin.avi', bitrate="3000k")

########NEW FILE########
__FILENAME__ = logo
from moviepy.editor import *

import numpy as np

w,h = moviesize = (720,380)

duration = 1

def f(t,size, a = np.pi/3, thickness = 20):
    w,h = size
    v = thickness* np.array([np.cos(a),np.sin(a)])[::-1]
    center = [int(t*w/duration),h/2]
    return biGradientScreen(size,center,v,0.6,0.0)

logo = ImageClip("../../videos/logo_descr.png").\
         resize(width=w/2).\
         set_mask(mask)
         
screen = logo.on_color(moviesize, color = (0,0,0), pos='center')

shade = ColorClip(moviesize,col=(0,0,0))
mask_frame = lambda t : f(t,moviesize,duration)
shade.mask = VideoClip(ismask=True, get_frame = mask_frame)
                    
cc = CompositeVideoClip([im.set_pos(2*["center"]),shade],
                         size = moviesize)

cc.subclip(0,duration).to_videofile("moviepy_logo.avi",fps=24)

########NEW FILE########
__FILENAME__ = masked_credits
from moviepy.editor import *
from moviepy.video.tools.credits import credits1

# Load the mountains clip, cut it, slow it down, make it look darker
clip = VideoFileClip('../../videos/badl-0001.mov', audio=False).\
           subclip(37,46).\
           speedx( 0.4).\
           fx( vfx.colorx, 0.7)

# Save the first frame to later make a mask with GIMP (only once)
#~ clip.save_frame('../../credits/mountainMask2.png')


# Load the mountain mask made with GIMP
mountainmask = ImageClip('../../credits/mountainMask2.png',ismask=True)

# Generate the credits from a text file
credits = credits1('../../credits/credits.txt',3*clip.w/4)
scrolling_credits = credits.set_pos(lambda t:('center',-10*t))


# Make the credits scroll. Here, 10 pixels per second
final = CompositeVideoClip([clip,
                            scrolling_credits,
                            clip.set_mask(mountainmask)])
                            
final.subclip(8,10).to_videofile("../../credits_mountains.avi")

########NEW FILE########
__FILENAME__ = moving_letters
import numpy as np
from moviepy.editor import *
from moviepy.video.tools.segmenting import findObjects

# WE CREATE THE TEXT THAT IS GOING TO MOVE, WE CENTER IT.

screensize = (720,460)
txtClip = TextClip('Cool effect',color='white', font="Amiri-Bold",
                   kerning = 5, fontsize=100)
cvc = CompositeVideoClip( [txtClip.set_pos('center')],
                        size=screensize, transparent=True)

# THE NEXT FOUR FUNCTIONS DEFINE FOUR WAYS OF MOVING THE LETTERS


# helper function
rotMatrix = lambda a: np.array( [[np.cos(a),np.sin(a)], 
                                 [-np.sin(a),np.cos(a)]] )

def vortex(screenpos,i,nletters):
    d = lambda t : 1.0/(0.3+t**8) #damping
    a = i*np.pi/ nletters # angle of the movement
    v = rotMatrix(a).dot([-1,0])
    if i%2 : v[1] = -v[1]
    return lambda t: screenpos+400*d(t)*rotMatrix(0.5*d(t)*a).dot(v)
    
def cascade(screenpos,i,nletters):
    v = np.array([0,-1])
    d = lambda t : 1 if t<0 else abs(np.sinc(t)/(1+t**4))
    return lambda t: screenpos+v*400*d(t-0.15*i)

def arrive(screenpos,i,nletters):
    v = np.array([-1,0])
    d = lambda t : max(0, 3-3*t)
    return lambda t: screenpos-400*v*d(t-0.2*i)
    
def vortexout(screenpos,i,nletters):
    d = lambda t : max(0,t) #damping
    a = i*np.pi/ nletters # angle of the movement
    v = rotMatrix(a).dot([-1,0])
    if i%2 : v[1] = -v[1]
    return lambda t: screenpos+400*d(t-0.1*i)*rotMatrix(-0.2*d(t)*a).dot(v)



# WE USE THE PLUGIN findObjects TO LOCATE AND SEPARATE EACH LETTER

letters = findObjects(cvc) # a list of ImageClips


# WE ANIMATE THE LETTERS

def moveLetters(letters, funcpos):
    return [ letter.set_pos(funcpos(letter.screenpos,i,len(letters)))
              for i,letter in enumerate(letters)]

clips = [ CompositeVideoClip( moveLetters(letters,funcpos),
                              size = screensize).subclip(0,5)
          for funcpos in [vortex, cascade, arrive, vortexout] ]

# WE CONCATENATE EVERYTHING AND WRITE TO A FILE

concatenate(clips).to_videofile('../../coolTextEffects.avi',
                                fps=25, codec='mpeg4')


########NEW FILE########
__FILENAME__ = painting_effect
""" requires scikit-image installed (for vfx.painting) """
 
from moviepy.editor import *

# WE TAKE THE SUBCLIPS WHICH ARE 2 SECONDS BEFORE & AFTER THE FREEZE

charade = VideoFileClip("../../videos/charade.mp4")
tfreeze = cvsecs(19,21) # Time of the freeze, 19'21

# when using several subclips of a same clip, it can be faster
# to create 'coreaders' of the clip (=other entrance points).
clip_before = charade.coreader().subclip(tfreeze -2,tfreeze)
clip_after = charade.coreader().subclip(tfreeze ,tfreeze +2)


# THE FRAME TO FREEZE

im_freeze = charade.to_ImageClip(tfreeze)
painting = charade.fx( vfx.painting, saturation = 1.6,black = 0.006).\
                   to_ImageClip(tfreeze)
                 
txt = TextClip('Audrey',font='Amiri-regular',fontsize=35)

painting_txt = CompositeVideoClip([painting,txt.set_pos((10,180))]).\
                   add_mask().\
                   set_duration(3).\
                   crossfadein( 0.5).\
                   crossfadeout( 0.5)

# FADEIN/FADEOUT EFFECT ON THE PAINTED IMAGE

painting_fading = CompositeVideoClip([im_freeze,painting_txt])

# FINAL CLIP AND RENDERING

final_clip =  concatenate([ clip_before,
                            painting_fading.set_duration(3),
                            clip_after])

final_clip.to_videofile('../../audrey.avi',fps=charade.fps,
                        codec = "mpeg4", audio_bitrate="3000k")

########NEW FILE########
__FILENAME__ = soundtrack
""" A simple test script on how to put a soundtrack to a movie """
from moviepy.editor import *


# We load a movie and replace the sound with some music:

movie = VideoFileClip("../../videos/dam.mov").\
        set_audio( AudioFileClip("../../sounds/startars.ogg") )


# If the soundtrack is longer than the movie, then at the end of the clip
# it will freeze on the last frame and wait for the clip to finish.
# If you don't want that, uncomment the next line:

#~ movie.audio = movie.audio.set_duration(movie.duration)

movie.to_videofile("../../test_soundtrack.avi", codec="mpeg4")


########NEW FILE########
__FILENAME__ = star_worms
"""
Description of the video:
Mimic of Star Wars' opening title. A text with a (false)
perspective effect goes towards the end of space, on a
background made of stars. Slight fading effect on the text.

"""

import numpy as np
from skimage import transform as tf

from moviepy.editor import *
from moviepy.video.tools.drawing import color_gradient


# RESOLUTION

w = 720
h = w*9/16 # 16/9 screen
moviesize = w,h



# THE RAW TEXT
txt = "\n".join([
"A long time ago, in a faraway galaxy,",
"there lived a prince and a princess",
"who had never seen the stars, for they",
"lived deep underground.",
"",
"Many years before, the prince's",
"grandfather had ventured out to the",
"surface and had been burnt to ashes by",
"solar winds.",
"",
"One day, as the princess was coding",
"and the prince was shopping online, a",
"meteor landed just a few megameters",
"from the couple's flat."
])


# Add blanks
txt = 10*"\n" +txt + 10*"\n"


# CREATE THE TEXT IMAGE


clip_txt = TextClip(txt,color='white', align='West',fontsize=25,
                    font='Xolonium-Bold', method='label')


# SCROLL THE TEXT IMAGE BY CROPPING A MOVING AREA

txt_speed = 27
fl = lambda gf,t : gf(t)[int(txt_speed*t):int(txt_speed*t)+h,:]
moving_txt= clip_txt.fl(fl, apply_to=['mask'])


# ADD A VANISHING EFFECT ON THE TEXT WITH A GRADIENT MASK

grad = color_gradient(moving_txt.size,p1=(0,2*h/3),
                p2=(0,h/4),col1=0.0,col2=1.0)
gradmask = ImageClip(grad,ismask=True)
fl = lambda pic : np.minimum(pic,gradmask.img)
moving_txt.mask = moving_txt.mask.fl_image(fl)


# WARP THE TEXT INTO A TRAPEZOID (PERSPECTIVE EFFECT)

def trapzWarp(pic,cx,cy,ismask=False):
    """ Complicated function (will be latex packaged as a fx) """
    Y,X = pic.shape[:2]
    src = np.array([[0,0],[X,0],[X,Y],[0,Y]])
    dst = np.array([[cx*X,cy*Y],[(1-cx)*X,cy*Y],[X,Y],[0,Y]])
    tform = tf.ProjectiveTransform()
    tform.estimate(src,dst)
    im = tf.warp(pic, tform.inverse, output_shape=(Y,X))
    return im if ismask else (im*255).astype('uint8')

fl_im = lambda pic : trapzWarp(pic,0.2,0.3)
fl_mask = lambda pic : trapzWarp(pic,0.2,0.3, ismask=True)
warped_txt= moving_txt.fl_image(fl_im)
warped_txt.mask = warped_txt.mask.fl_image(fl_mask)


# BACKGROUND IMAGE, DARKENED AT 60%

stars = ImageClip('../../videos/stars.jpg')
stars_darkened = stars.fl_image(lambda pic: (0.6*pic).astype('int16'))


# COMPOSE THE MOVIE

final = CompositeVideoClip([
         stars, warped_txt.set_pos(('center','bottom'))],
         size = moviesize)


# WRITE TO A FILE

final.set_duration(8).to_videofile("starworms.avi", fps=5)

# This script is heavy (30s of computations to render 8s of video)



"""=====================================================================

    CODE FOR THE VIDEO TUTORIAL

  We will now code the video tutorial for this video.
  When you think about it, it is a code for a video explaining how to
  make another video using some code (this is so meta !).
  This code uses the variables of the previous code (it should be placed
  after that previous code to work).

====================================================================="""



def annotate(clip,txt,txt_color='white',bg_color=(0,0,255)):
    """ Writes a text at the bottom of the clip. """
    
    txtclip = TextClip(txt, fontsize=20, font='Ubuntu-bold',
                       color=txt_color)
                       
    txtclip = txtclip.on_color((clip.w,txtclip.h+6), color=(0,0,255),
                        pos=(6,'center'))
                        
    cvc =  CompositeVideoClip([clip , txtclip.set_pos((0,'bottom'))])
    
    return cvc.set_duration(clip.duration)


def resizeCenter(clip):
    return clip.resize( height=h).set_pos('center')

    
def composeCenter(clip):
    return CompositeVideoClip([clip.set_pos('center')],size=moviesize)



annotated_clips = [ annotate(clip,text) for clip,text in [
               
(composeCenter(resizeCenter(stars)).subclip(0,3),
    "This is a public domain picture of stars"),

(CompositeVideoClip([stars],moviesize).subclip(0,3),
    "We only keep one part."),

(CompositeVideoClip([stars_darkened],moviesize).subclip(0,3),
    "We darken it a little."),

(composeCenter(resizeCenter(clip_txt)).subclip(0,3),
    "We generate a text image."),

(composeCenter(moving_txt.set_mask(None)).subclip(6,9),
    "We scroll the text by cropping a moving region of it."),

(composeCenter(gradmask.to_RGB()).subclip(0,2),
    "We add this mask to the clip."),

(composeCenter(moving_txt).subclip(6,9),
    "Here is the result"),

(composeCenter(warped_txt).subclip(6,9),
    "We now warp this clip in a trapezoid."),

(final.subclip(6,9),
    "We finally superimpose with the stars.")
]]

# Concatenate and write to a file

concatenate(annotated_clips).to_videofile('tutorial.avi', fps=5)


########NEW FILE########
__FILENAME__ = the_end
from moviepy.editor import *
from moviepy.video.tools.drawing import circle

clip = VideoFileClip("../../videos/badl-0006.mov", audio=False).\
           subclip(26,31).\
           add_mask()
           
w,h = clip.size

# The mask is a circle with vanishing radius r(t) = 800-200*t               
clip.mask.get_frame = lambda t: circle(screensize=(clip.w,clip.h),
                                       center=(clip.w/2,clip.h/4),
                                       radius=max(0,int(800-200*t)),
                                       col1=1, col2=0, blur=4)


the_end = TextClip("The End", font="Amiri-bold", color="white",
                   fontsize=70).set_duration(clip.duration)

final = CompositeVideoClip([the_end.set_pos('center'),clip],
                           size =clip.size)
                           
final.to_videofile("../../theEnd.avi")

########NEW FILE########
__FILENAME__ = ukulele_concerto
from moviepy.editor import *

# UKULELE CLIP, OBTAINED BY CUTTING AND CROPPING
# RAW FOOTAGE

ukulele = VideoFileClip("../../videos/moi_ukulele.MOV", audio=False).\
               subclip(60+33, 60+50).\
               crop(486, 180, 1196, 570)

w,h = moviesize = ukulele.size

# THE PIANO FOOTAGE IS DOWNSIZED, HAS A WHITE MARGIN, IS
# IN THE BOTTOM RIGHT CORNER 

piano = (VideoFileClip("../../videos/douceamb.mp4",audio=False).
         subclip(30,50).
         resize((w/3,h/3)).    # one third of the total screen
         margin( 6,color=(255,255,255)).  #white margin
         margin( bottom=20, right=20, opacity=0). # transparent
         set_pos(('right','bottom')) )



# A CLIP WITH A TEXT AND A BLACK SEMI-OPAQUE BACKGROUND

txt = TextClip("V. Zulkoninov - Ukulele Sonata", font='Amiri-regular',
	               color='white',fontsize=24)

txt_col = txt.on_color(size=(ukulele.w + txt.w,txt.h-10),
                  color=(0,0,0), pos=(6,'center'), col_opacity=0.6)


# THE TEXT CLIP IS ANIMATED.
# I am *NOT* explaining the formula, understands who can/want.
txt_mov = txt_col.set_pos( lambda t: (max(w/30,int(w-0.5*w*t)),
                                  max(5*h/6,int(100*t))) )



# FINAL ASSEMBLY
final = CompositeVideoClip([ukulele,txt_mov,piano])
final.subclip(0,5).to_videofile("../../ukulele.avi",fps=24,codec='libx264')

########NEW FILE########
__FILENAME__ = AudioClip
import sys
from copy import copy

import numpy as np
from moviepy.audio.io.ffmpeg_audiowriter import ffmpeg_audiowrite
from moviepy.decorators import requires_duration

from moviepy.Clip import Clip


# optimize range in function of Python's version
if sys.version_info < (3,):
    range = xrange


class AudioClip(Clip):
    """Base class for audio clips.
    
    See ``SoundClip`` and ``CompositeSoundClip`` for usable classes.
    
    An AudioClip is a Clip with a ``get_frame``  attribute of
    the form `` t -> [ f_t ]`` for mono sound and
    ``t-> [ f1_t, f2_t ]`` for stereo sound (the arrays are Numpy arrays).
    The `f_t` are floats between -1 and 1. These bounds can be
    trespassed wihtout problems (the program will put the
    sound back into the bounds at conversion time, without much impact). 
    
    Parameters
    -----------
    
    get_frame
      A function `t-> frame at time t`. The frame does not mean much
      for a sound, it is just a float. What 'makes' the sound are
      the variations of that float in the time.
        
    nchannels
      Number of channels (one or two for mono or stereo).
    
    Examples
    ---------
    
    >>> # Plays the note A (a sine wave of frequency 404HZ)
    >>> import numpy as np
    >>> gf = lambda t : 2*[ np.sin(404 * 2 * np.pi * t) ]
    >>> clip = AudioClip().set_get_frame(gf)
    >>> clip.set_duration(5).preview()
                     
    """
    
    def __init__(self, get_frame = None):
        Clip.__init__(self)
        if get_frame:
            self.get_frame = get_frame
            frame0 = self.get_frame(0)
            if hasattr(frame0, '__iter__'):
                self.nchannels = len(list(frame0))
            else:
                self.nchannels = 1

    @requires_duration
    def to_soundarray(self,tt=None,fps=None, nbytes=2):
        """
        Transforms the sound into an array that can be played by pygame
        or written in a wav file. See ``AudioClip.preview``.
        
        Parameters
        ------------
        
        fps
          Frame rate of the sound for the conversion.
          44100 for top quality.
        
        nbytes
          Number of bytes to encode the sound: 1 for 8bit sound,
          2 for 16bit, 4 for 32bit sound.
          
        """
        if tt is None:
            tt = np.arange(0,self.duration, 1.0/fps)

        #print tt.max() - tt.min(), tt.min(), tt.max()
        
        snd_array = self.get_frame(tt)
        snd_array = np.maximum(-0.99,
                       np.minimum(0.99,snd_array))
        inttype = {1:'int8',2:'int16', 4:'int32'}[nbytes]
        return (2**(8*nbytes-1)*snd_array).astype(inttype)
    
    
    
    @requires_duration
    def to_audiofile(self,filename, fps=44100, nbytes=2,
                     buffersize=2000, codec='libvorbis',
                     bitrate=None, verbose=True):
        """ 
        codecs  = {        'libmp3lame': 'mp3',
                       'libvorbis':'ogg',
                       'libfdk_aac':'m4a',
                       'pcm_s16le':'wav',
                       'pcm_s32le': 'wav'}
        """
                         
        return ffmpeg_audiowrite(self,filename, fps, nbytes, buffersize,
                      codec, bitrate, verbose)


class AudioArrayClip(AudioClip):
    """
    
    An audio clip made from a sound array.
    
    Parameters
    -----------
    
    array
      A Numpy array representing the sound, of size Nx1 for mono,
      Nx2 for stereo.
       
    fps
      Frames per second : speed at which the sound is supposed to be
      played.
    
    """
    
    def __init__(self, array, fps):
        
        Clip.__init__(self)
        self.array = array
        self.fps = fps
        self.duration = 1.0 * len(array) / fps
        
        
        def get_frame(t):
            """ complicated, but must be able to handle the case where t
            is a list of the form sin(t) """
            
            if isinstance(t, np.ndarray):
                array_inds = (self.fps*t).astype(int)
                in_array = (array_inds>0) & (array_inds < len(self.array))
                result = np.zeros((len(t),2))
                result[in_array] = self.array[array_inds[in_array]]
                return result
            else:
                i = int(self.fps * t)
                if i < 0 or i >= len(self.array):
                    return 0*self.array[0]
                else:
                    return self.array[i]

        self.get_frame = get_frame
        self.nchannels = len(list(self.get_frame(0)))
        
        
class CompositeAudioClip(AudioClip):

    """ Clip made by composing several AudioClips.
    
    An audio clip made by putting together several audio clips.
    
    Parameters
    ------------
    
    clips
      List of audio clips, which may start playing at different times or
      together. If all have their ``duration`` attribute set, the
      duration of the composite clip is computed automatically.
    
    """

    def __init__(self, clips):

        Clip.__init__(self)
        self.clips = clips
        
        ends = [c.end for c in self.clips]
        self.nchannels = max([c.nchannels for c in self.clips])
        if not any([(e is None) for e in ends]):
            self.duration = max(ends)
            self.end = max(ends)

        def get_frame(t):
            # buggy
            
            
            played_parts = [c.is_playing(t) for c in self.clips]
            
            sounds= [c.get_frame(t - c.start)*np.array([part]).T
                     for c,part in zip(self.clips, played_parts)
                     if (part is not False) ]
                     
            if isinstance(t,np.ndarray):
                zero = np.zeros((len(t),self.nchannels))
                
            else:
                zero = np.zeros(self.nchannels)
                
            return zero + sum(sounds)

        self.get_frame = get_frame

########NEW FILE########
__FILENAME__ = audio_fadein
from moviepy.decorators import audio_video_fx
import numpy as np

@audio_video_fx
def audio_fadein(clip, duration):
    """ Return an audio (or video) clip that is first mute, then the
        sound arrives progressively over ``duration`` seconds. """
    def fading(gf,t):
        gft = gf(t)
        
        if np.isscalar(t):
            factor = min(1.0 * t / duration, 1)
            factor = np.array([factor,factor])
        else:
            factor = np.minimum(1.0 * t / duration, 1)
            factor = np.vstack([factor,factor]).T
        return factor * gft
    return clip.fl(fading, keep_duration = True)

########NEW FILE########
__FILENAME__ = audio_fadeout
from moviepy.decorators import audio_video_fx, requires_duration
import numpy as np

@audio_video_fx
@requires_duration
def audio_fadeout(clip, duration):
    """ Return a sound clip where the sound fades out progressively
        over ``duration`` seconds at the end of the clip. """
    
    def fading(gf,t):
        gft = gf(t)
        
        if np.isscalar(t):
            factor = min(1.0 * (clip.duration - t) / duration, 1)
            factor = np.array([factor,factor])
        else:
            factor = np.minimum( 1.0 * (clip.duration - t) / duration, 1)
            factor = np.vstack([factor,factor]).T
        return factor * gft
    
    return clip.fl(fading, keep_duration = True)

########NEW FILE########
__FILENAME__ = audio_left_right
import numpy as np

def audio_left_right(audioclip, left=1, right=1, merge=False):
    """
    For a stereo audioclip, this function enables to change the volume
    of the left and right channel separately (with the factors `left`
    and `right`)
    Makes a stereo audio clip in which the volume of left and right
    is controlable
    """
    funleft = (lambda t: left) if np.isscalar(left) else left
    funright = (lambda t: right) if np.isscalar(right) else right
    

########NEW FILE########
__FILENAME__ = volumex
from moviepy.decorators import audio_video_fx

@audio_video_fx
def volumex(clip, factor):
    """ Returns a (video or audio) clip with increased sound volume """ 
    return clip.fl(lambda gf, t: factor * gf(t), keep_duration = True)

########NEW FILE########
__FILENAME__ = AudioFileClip
from __future__ import division

import numpy as np

from moviepy.audio.AudioClip import AudioClip
from moviepy.audio.io.readers import FFMPEG_AudioReader

class AudioFileClip(AudioClip):

    """
    An audio clip read from a sound file, or an array.
    The whole file is not loaded in memory. Instead, only a portion is
    read and stored in memory. this portion includes frames before
    and after the last frames read, so that it is fast to read the sound
    backward and forward.
    
    Parameters
    ------------
    
    snd
      Either a soundfile name (of any extension supported by ffmpeg)
      or an array representing a sound. If the soundfile is not a .wav,
      it will be converted to .wav first, using the ``fps`` and
      ``bitrate`` arguments. 
    
    buffersize:
      Size to load in memory (in number of frames)
    
    temp_wav:
      Name for the temporary wav file in case conversion is required.
      If not provided, the default will be filename.wav with some prefix.
      If the temp_wav already exists it will not be rewritten.
        
        
    Attributes
    ------------
    
    nbytes
      Number of bits per frame of the original audio file.
      
    fps
      Number of frames per second in the audio file
      
    buffersize
      See Parameters.
      
    Examples
    ----------
    
    >>> snd = SoundClip("song.wav")
    >>> snd = SoundClip("song.mp3", fps = 44100, bitrate=3000)
    >>> snd = SoundClip(mySoundArray,fps=44100) # from a numeric array
    
    """

    def __init__(self, filename, buffersize=200000, nbytes=2, fps=44100):
        

        AudioClip.__init__(self)
            
        self.filename = filename
        self.reader = FFMPEG_AudioReader(filename,fps=fps,nbytes=nbytes,
                                         buffersize=buffersize)
        self.fps = fps
        self.duration = self.reader.duration
        self.end = self.duration
        
        
        self.get_frame =  lambda t: self.reader.get_frame(t)
        self.nchannels = self.reader.nchannels
    
    
    def coreader(self):
        """ Returns a copy of the AudioFileClip, i.e. a new entrance point
            to the audio file. Use copy when you have different clips
            watching the audio file at different times. """
        return AudioFileClip(self.filename,self.buffersize)

########NEW FILE########
__FILENAME__ = ffmpeg_audiowriter
from __future__ import division

import sys
import numpy as np
import subprocess as sp

try:
    from subprocess import DEVNULL # py3k
except ImportError:
    import os
    DEVNULL = open(os.devnull, 'wb')

from tqdm import tqdm
from moviepy.conf import FFMPEG_BINARY
from moviepy.decorators import requires_duration

from moviepy.tools import sys_write_flush

class FFMPEG_AudioWriter:
    """
    A class to write an AudioClip into an audio file.
    
    Parameters
    ------------
    
    filename
      Name of any video or audio file, like ``video.mp4`` or ``sound.wav`` etc.
    
    size
      Size (width,height) in pixels of the output video.
    
    fps_input
      Frames per second of the input audio (given by the AUdioClip being
      written down).
    
    codec
      Name of the ffmpeg codec to use for the output.
    
    bitrate:
      A string indicating the bitrate of the final video. Only
      relevant for codecs which accept a bitrate.
      
    """
    
    
        
    def __init__(self, filename, fps_input, nbytes=2,
                 nchannels = 2, codec='libfdk_aac', bitrate=None,
                 input_video=None,logfile=None):
        
        self.filename = filename

        if logfile is None:
          logfile = DEVNULL

        cmd = ([ FFMPEG_BINARY, '-y',
            "-loglevel", "panic" if logfile==DEVNULL else "info",
            "-f", 's%dle'%(8*nbytes),
            "-acodec",'pcm_s%dle'%(8*nbytes),
            '-ar', "%d"%fps_input,
            '-ac',"%d"%nchannels,
            '-i', '-']
            + (['-vn'] if input_video==None else
                 [ "-i", input_video, '-vcodec', 'copy'])
            + ['-acodec', codec]
            + ['-ar', "%d"%fps_input]
            + ['-strict', '-2']  # needed to support codec 'aac'
            + (['-ab',bitrate] if (bitrate!=None) else [])
            + [ filename ])
        

        self.proc = sp.Popen(cmd, stdin=sp.PIPE,
                                  stderr=logfile,
                                  stdout=DEVNULL)

        
    def write_frames(self,frames_array):
        self.proc.stdin.write(frames_array.tostring())
        
        
    def close(self):
        self.proc.stdin.close()
        #self.proc.stderr.close()
        #self.proc.stdout.close()
        self.proc.wait()
        del self.proc
        
        
        
@requires_duration       
def ffmpeg_audiowrite(clip, filename, fps, nbytes, buffersize,
                      codec='libvorbis', bitrate=None,
                      write_logfile = False, verbose=True):
    """
    A function that wraps the FFMPEG_AudioWriter to write an AudioClip
    to a file.
    """
    
    def verbose_print(s):
        if verbose: sys_write_flush(s)

    if write_logfile:
        logfile = open(filename + ".log", 'w+')
    else:
        logfile = DEVNULL
        
    verbose_print("Writing audio in %s\n"%filename)
     
    writer = FFMPEG_AudioWriter(filename, fps, nbytes, clip.nchannels,
                                codec=codec, bitrate=bitrate,
                                logfile=logfile)
                                
    totalsize = int(fps*clip.duration)
    
    if (totalsize % buffersize == 0):
        nchunks = totalsize // buffersize
    else:
        nchunks = totalsize // buffersize + 1
        
    pospos = list(range(0, totalsize,  buffersize))+[totalsize]
    
    for i in tqdm(range(nchunks)):
        tt = (1.0/fps)*np.arange(pospos[i],pospos[i+1])
        sndarray = clip.to_soundarray(tt, nbytes= nbytes)
        writer.write_frames(sndarray)


    writer.close()
    
    if write_logfile:
        logfile.close()

    verbose_print("Done writing Audio in %s !\n"%filename)

########NEW FILE########
__FILENAME__ = preview
import time
import numpy as np

from moviepy.decorators import requires_duration

import pygame as pg

pg.init()
pg.display.set_caption('MoviePy')


@requires_duration
def preview(clip, fps=22050,  buffersize=4000, nbytes= 2,
                 audioFlag=None, videoFlag=None):
    """
    Plays the sound clip with pygame.
    
    Parameters
    -----------
    
    fps
       Frame rate of the sound. 44100 gives top quality, but may cause
       problems if your computer is not fast enough and your clip is
       complicated. If the sound jumps during the preview, lower it
       (11025 is still fine, 5000 is tolerable).
        
    buffersize
      The sound is not generated all at once, but rather made by bunches
      of frames (chunks). ``buffersize`` is the size of such a chunk.
      Try varying it if you meet audio problems (but you shouldn't
      have to).
    
    nbytes:
      Number of bytes to encode the sound: 1 for 8bit sound, 2 for
      16bit, 4 for 32bit sound. 2 bytes is fine.
    
    audioFlag, videoFlag:
      Instances of class threading events that are used to synchronize
      video and audio during ``VideoClip.preview()``.
    
    """
                 
    pg.mixer.quit()
    
    pg.mixer.init(fps, -8 * nbytes, clip.nchannels, 1024)
    totalsize = int(fps*clip.duration)
    pospos = np.array(list(range(0, totalsize,  buffersize))+[totalsize])
    tt = (1.0/fps)*np.arange(pospos[0],pospos[1])
    sndarray = clip.to_soundarray(tt,nbytes)
    chunk = pg.sndarray.make_sound(sndarray)
    
    if (audioFlag !=None) and (videoFlag!= None):
        audioFlag.set()
        videoFlag.wait()
        
    channel = chunk.play()
    for i in range(1,len(pospos)-1):
        tt = (1.0/fps)*np.arange(pospos[i],pospos[i+1])
        sndarray = clip.to_soundarray(tt,nbytes)
        chunk = pg.sndarray.make_sound(sndarray)
        while channel.get_queue():
            time.sleep(0.003)
            if (videoFlag!= None):
                if not videoFlag.is_set():
                    channel.stop()
                    del channel
                    return
        channel.queue(chunk)

########NEW FILE########
__FILENAME__ = readers
import subprocess as sp
import re

import numpy as np
from moviepy.tools import cvsecs

from moviepy.video.io.ffmpeg_reader import ffmpeg_parse_infos
from moviepy.conf import FFMPEG_BINARY

    
class FFMPEG_AudioReader:
    """
    A class to read the audio in either video files or audio files
    using ffmpeg. ffmpeg will read any audio and transform them into
    raw data.
    
    Parameters
    ------------
    
    filename
      Name of any video or audio file, like ``video.mp4`` or
      ``sound.wav`` etc.
      
    buffersize
      The size of the buffer to use. Should be bigger than the buffer
      used by ``to_audiofile``
    
    print_infos
      Print the ffmpeg infos on the file being read (for debugging)
      
    fps
      Desired frames per second in the decoded signal that will be
      received from ffmpeg
      
    nbytes
      Desired number of bytes (1,2,4) in the signal that will be
      received from ffmpeg
          
    """
        
    def __init__(self, filename, buffersize, print_infos=False,
                 fps=44100, nbytes=2, nchannels=2):
        
        self.filename = filename
        self.nbytes = nbytes
        self.fps = fps
        self.f = 's%dle'%(8*nbytes)
        self.acodec = 'pcm_s%dle'%(8*nbytes)
        self.nchannels = nchannels
        infos = ffmpeg_parse_infos(filename)
        self.duration = infos['duration']
        if 'video_duration' in infos:
            self.duration = infos['video_duration']
        else:
            self.duration = infos['duration']
        self.infos = infos
        self.proc = None
        
        self.nframes = int(self.fps * self.duration)
        self.buffersize= min( self.nframes, buffersize )
        self.buffer= None
        self.buffer_startframe = 1
        self.initialize()
        self.buffer_around(1)
    
    
    
    def initialize(self, starttime = 0):
        """ Opens the file, creates the pipe. """
    
        self.close_proc() # if any
        
        if starttime !=0 :
            offset = min(1,starttime)
            i_arg = ["-ss", "%.05f"%(starttime-offset),
                    '-i', self.filename, '-vn',
                    "-ss", "%.05f"%offset]
        else:
            i_arg = [ '-i', self.filename,  '-vn']
             
        
        cmd = ([FFMPEG_BINARY] + i_arg + 
               [ '-loglevel', 'error',
                 '-f', self.f,
                '-acodec', self.acodec,
                '-ar', "%d"%self.fps,
                '-ac', '%d'%self.nchannels, '-'])
        self.proc = sp.Popen( cmd, bufsize=self.buffersize,
                                   stdout=sp.PIPE,
                                   stderr=sp.PIPE)
        self.pos = int(self.fps*starttime+1)
     
     
     
    def skip_chunk(self,chunksize):
        s = self.proc.stdout.read(self.nchannels*chunksize*self.nbytes)
        self.proc.stdout.flush()
        self.pos = self.pos+chunksize
        
        
        
    def read_chunk(self,chunksize):
        L = self.nchannels*chunksize*self.nbytes
        s = self.proc.stdout.read(L)
        dt = {1: 'int8',2:'int16',4:'int32'}[self.nbytes]
        result = np.fromstring(s, dtype=dt)
        result = (1.0*result / 2**(8*self.nbytes-1)).\
                                 reshape((len(result)/self.nchannels,
                                          self.nchannels))
        self.proc.stdout.flush()
        self.pos = self.pos+chunksize
        return result
                    
    def seek(self,pos):
        """
        Reads a frame at time t. Note for coders: getting an arbitrary
        frame in the video with ffmpeg can be painfully slow if some
        decoding has to be done. This function tries to avoid fectching
        arbitrary frames whenever possible, by moving between adjacent
        frames.
        """
        if (pos < self.pos) or (pos> (self.pos+1000000)):
            t = 1.0*pos/self.fps

            self.initialize(t)
        elif pos > self.pos:
            #print pos
            self.skip_chunk(pos-self.pos)
        # last case standing: pos = current pos
        self.pos = pos
    
    def close_proc(self):
        if self.proc is not None:
            self.proc.terminate()
            for std in [ self.proc.stdout,
                         self.proc.stderr]:
                std.close()
            del self.proc
    
    def get_frame(self, tt):
        
        buffersize = self.buffersize
        if isinstance(tt,np.ndarray):
            # lazy implementation, but should not cause problems in
            # 99.99 %  of the cases
            
            
            # elements of t that are actually in the range of the
            # audio file.
            
            in_time = (tt>=0) & (tt < self.duration)
            
            # The np.round in the next line is super-important.
            # Removing it results in artifacts in the noise.
            frames = np.round((self.fps*tt+1)).astype(int)[in_time]
            fr_min, fr_max = frames.min(), frames.max()
            
            if not (0 <=
                     (fr_min - self.buffer_startframe)
                          < len(self.buffer)):
                self.buffer_around(fr_min)
            elif not (0 <=
                        (fr_max - self.buffer_startframe)
                             < len(self.buffer)):
                self.buffer_around(fr_max)
                
            try:
                result = np.zeros((len(tt),self.nchannels))
                result[in_time] = self.buffer[frames - self.buffer_startframe]
                return result
            except IndexError as error:
                print ("Error: wrong indices in video buffer. Maybe"+
                       " buffer too small.")
                raise error
                
        else:
            
            ind = int(self.fps*tt)
            if ind<0 or ind> self.nframes: # out of time: return 0
                return np.zeros(self.nchannels)
                
            if not (0 <= (ind - self.buffer_startframe) <len(self.buffer)):
                # out of the buffer: recenter the buffer
                self.buffer_around(ind)
                
            # read the frame in the buffer
            return self.buffer[ind - self.buffer_startframe]
                

    def buffer_around(self,framenumber):
        """
        Fills the buffer with frames, centered on ``framenumber``
        if possible
        """

        # start-frame for the buffer
        new_bufferstart = max(0,  framenumber - self.buffersize // 2)
        
        
        if (self.buffer!=None):
            current_f_end  = self.buffer_startframe + self.buffersize
            if (new_bufferstart <
                        current_f_end  <
                               new_bufferstart + self.buffersize):
                # We already have one bit of what must be read
                conserved = current_f_end - new_bufferstart + 1
                chunksize = self.buffersize-conserved
                array = self.read_chunk(chunksize)
                self.buffer = np.vstack([self.buffer[-conserved:], array])
            else:
                self.seek(new_bufferstart)
                self.buffer =  self.read_chunk(self.buffersize)
        else:
            self.seek(new_bufferstart)
            self.buffer =  self.read_chunk(self.buffersize)
        
        self.buffer_startframe = new_bufferstart
    
    
    def __del__(self):
        self.close_proc()
        
        


########NEW FILE########
__FILENAME__ = Clip
"""
This module implements the central object of MoviePy, the Clip, and
all the methods that are common to the two subclasses of Clip, VideoClip
and AudioClip.
"""

from copy import copy
import numpy as np

from moviepy.decorators import ( apply_to_mask,
                                 apply_to_audio,
                                 time_can_be_tuple,
                                 outplace)


class Clip:

    """
        
     Base class of all clips (VideoClips and AudioClips).
      
       
     Attributes
     -----------
     
     start:
       When the clip is included in a composition, time of the
       composition at which the clip starts playing (in seconds). 
     
     end:
       When the clip is included in a composition, time of the
       composition at which the clip starts playing (in seconds).
     
     duration:
       Duration of the clip (in seconds). Some clips are infinite, in
       this case their duration will be ``None``.
     
     """
    
    # prefix for all tmeporary video and audio files.
    # You can overwrite it with 
    # >>> Clip._TEMP_FILES_PREFIX = "temp_"
    
    _TEMP_FILES_PREFIX = 'TEMP_MPY_'

    def __init__(self):

        self.start = 0
        self.end = None
        self.duration = None
        
        
    def copy(self):
        """ Shallow copy of the clip. 
        
        Returns a shwallow copy of the clip whose mask and audio will
        be shallow copies of the clip's mask and audio if they exist.
        
        This method is intensively used to produce new clips every time
        there is an outplace transformation of the clip (clip.resize,
        clip.subclip, etc.)
        """
        
        newclip = copy(self)
        if hasattr(self, 'audio'):
            newclip.audio = copy(self.audio)
        if hasattr(self, 'mask'):
            newclip.mask = copy(self.mask)
            
        return newclip



    def fl(self, fun, apply_to=[] , keep_duration=True):
        """ General processing of a clip.
        
        Returns a new Clip whose frames are a transformation
        (through function ``fun``) of the frames of the current clip.
        
        Parameters
        -----------
        
        fun
          A function with signature (gf,t -> frame) where ``gf`` will
          represent the current clip's ``get_frame`` method,
          i.e. ``gf`` is a function (t->image). Parameter `t` is a time
          in seconds, `frame` is a picture (=Numpy array) which will be
          returned by the transformed clip (see examples below).
           
        apply_to
          Can be either ``'mask'``, or ``'audio'``, or
          ``['mask','audio']``.
          Specifies if the filter ``fl`` should also be applied to the
          audio or the mask of the clip, if any.
        
        keep_duration
          Set to True if the transformation does not change the
          ``duration`` of the clip.
          
        Examples
        --------
        
        In the following ``newclip`` a 100 pixels-high clip whose video
        content scrolls from the top to the bottom of the frames of
        ``clip``.
        
        >>> fl = lambda gf,t : gf(t)[int(t):int(t)+50, :]
        >>> newclip = clip.fl(fl, apply_to='mask')
        
        """

        gf = copy(self.get_frame)
        newclip = self.set_get_frame(lambda t: fun(gf, t))
        
        if not keep_duration:
            newclip.duration = None
            newclip.end = None
            
        if isinstance(apply_to, str):
            apply_to = [apply_to]

        for attr in apply_to:
            if hasattr(newclip, attr):
                a = getattr(newclip, attr)
                if a != None:
                    new_a =  a.fl(fun, keep_duration=keep_duration)
                    setattr(newclip, attr, new_a)
                    
        return newclip

    
    
    def fl_time(self, t_func, apply_to=[], keep_duration=False):
        """
        Returns a Clip instance playing the content of the current clip
        but with a modified timeline, time ``t`` being replaced by another
        time `t_func(t)`.
        
        Parameters
        -----------
        
        t_func:
          A function ``t-> new_t``
        
        apply_to:
          Can be either 'mask', or 'audio', or ['mask','audio'].
          Specifies if the filter ``fl`` should also be applied to the
          audio or the mask of the clip, if any.
        
        keep_duration:
          ``False`` (default) if the transformation modifies the
          ``duration`` of the clip.
          
        Examples
        --------
        
        >>> # plays the clip (and its mask and sound) twice faster
        >>> newclip = clip.fl_time(lambda: 2*t, apply_to=['mask','audio'])
        >>>
        >>> # plays the clip starting at t=3, and backwards:
        >>> newclip = clip.fl_time(lambda: 3-t)
        
        """
        
        return self.fl(lambda gf, t: gf(t_func(t)), apply_to,
                                    keep_duration=keep_duration)
    
    
    
    def fx(self, func, *args, **kwargs):
        """
        
        Returns the result of ``func(self, *args, **kwargs)``.
        for instance
        
        >>> newclip = clip.fx(resize, 0.2, method='bilinear')
        
        is equivalent to
        
        >>> newclip = resize(clip, 0.2, method='bilinear')
        
        The motivation of fx is to keep the name of the effect near its
        parameters, when the effects are chained:
        
        >>> from moviepy.video.fx import volumex, resize, mirrorx
        >>> clip.fx( volumex, 0.5).fx( resize, 0.3).fx( mirrorx )
        >>> # Is equivalent, but clearer than
        >>> resize( volumex( mirrorx( clip ), 0.5), 0.3)
        
        """
        
        return func(self, *args, **kwargs)
            
    
    
    @apply_to_mask
    @apply_to_audio
    @time_can_be_tuple
    @outplace
    def set_start(self, t, change_end=True):
        """
        Returns a copy of the clip, with the ``start`` attribute set
        to ``t`` (in seconds).
        
        If ``change_end=True`` and the clip has a ``duration`` attribute,
        the ``end`` atrribute of the clip will be updated to
        ``start+duration``.
        
        If ``change_end=False`` and the clip has a ``end`` attribute,
        the ``duration`` attribute of the clip will be updated to 
        ``end-start``
        
        These changes are also applied to the ``audio`` and ``mask``
        clips of the current clip, if they exist.
        """
        
        self.start = t
        if (self.duration != None) and change_end:
            self.end = t + self.duration
        elif (self.end !=None):
            self.duration = self.end - self.start
    
    
    
    @apply_to_mask
    @apply_to_audio
    @time_can_be_tuple
    @outplace
    def set_end(self, t):
        """
        Returns a copy of the clip, with the ``end`` attribute set to
        ``t``. Also sets the duration of the mask and audio, if any,
        of the returned clip.
        """
        self.end = t
        if self.start is None:
            if self.duration != None:
                self.start = max(0, t - newclip.duration)
        else:
            self.duration = self.end - self.start


    
    @apply_to_mask
    @apply_to_audio
    @time_can_be_tuple
    @outplace
    def set_duration(self, t, change_end=True):
        """
        Returns a copy of the clip, with the  ``duration`` attribute
        set to ``t``.
        Also sets the duration of the mask and audio, if any, of the
        returned clip.
        """
        self.duration = t
        if change_end:
            self.end = None if (t is None) else (self.start + t)
        else:
            if duration is None:
                raise Exception("Cannot change clip start when new"
                                 "duration is None")
            self.start = self.end - t


    @outplace
    def set_get_frame(self, gf):
        """
        Sets a ``get_frame`` attribute for the clip. Useful for setting
        arbitrary/complicated videoclips.
        """
        self.get_frame = gf
    
    
    
    @time_can_be_tuple
    def is_playing(self, t):
        """
        
        If t is a number, returns true if t is between the start and
        the end of the clip.
        If t is a numpy array, returns False if none of the t is in
        theclip, else returns a vector [b_1, b_2, b_3...] where b_i
        is true iff tti is in the clip. 
        """
        
        if isinstance(t, np.ndarray):
            # is the whole list of t outside the clip ?
            tmin, tmax = t.min(), t.max()
            
            if (self.end != None) and (tmin >= self.end) :
                return False
            
            if tmax < self.start:
                return False
            
            # If we arrive here, a part of t falls in the clip
            result = 1 * (t >= self.start)
            if (self.end != None):
                result *= (t <= self.end)
            return result
        
        else:
            
            return( (t >= self.start) and
                    ((self.end is None) or (t < self.end) ) )
    
    @time_can_be_tuple
    @apply_to_mask
    @apply_to_audio
    def subclip(self, t_start=0, t_end=None):
        """
        Returns a clip playing the content of the current clip
        between times ``t_start`` and ``t_end`` (in seconds).
        If ``t_end`` is not provided, it is assumed to be the duration
        of the clip (potentially infinite).
        If ``t_end`` is a negative value, it is reset to
        ``clip.duration + t_end. ``. For instance: ::
        
            >>> # cut the last two seconds of the clip:
            >>> newclip = clip.subclip(0,-2)
        
        If ``t_end`` is provided or if the clip has a duration attribute,
        the duration of the returned clip is set automatically.
        
        The ``mask`` and ``audio`` of the resulting subclip will be
        subclips of ``mask`` and ``audio`` the original clip, if
        they exist.
        """

        if (self.duration is not None) and (t_start>self.duration):
            raise ValueError("t_start (%.02f) "%t_start +
                             "should be smaller than the clip's "+
                             "duration (%.02f)."%self.duration)

        newclip = self.fl_time(lambda t: t + t_start, apply_to=[])
        if (t_end is None) and (self.duration is not None):
            t_end = self.duration
        elif t_end<0:
            if self.duration is None:
                print ("Error: subclip with negative times can only be"+
                        "extracted from clips with a ``duration``")
            else:
                t_end = self.duration + t_end
        if (t_end is not None):
            newclip.duration = t_end - t_start
            newclip.end = newclip.start + newclip.duration
            
        return newclip
    
    
    
    @apply_to_mask
    @apply_to_audio
    @time_can_be_tuple
    def cutout(self, ta, tb):
        """
        Returns a clip playing the content of the current clip but
        skips the extract between ``ta`` and ``tb`` (in seconds).
        If the original clip has a ``duration`` attribute set,
        the duration of the returned clip  is automatically computed as
        `` duration - (tb - ta)``.
        
        The resulting clip's ``audio`` and ``mask`` will also be cutout
        if they exist.
        """
        
        fl = lambda t: t + (0 if (t < ta) else tb - ta)
        newclip = self.fl_time(fl)
        if self.duration != None:
            return newclip.set_duration(self.duration - (tb - ta))
        else:
            return newclip

########NEW FILE########
__FILENAME__ = conf
"""
Instructions
--------------

This file enables you to specify a configuration for MoviePy. In
particular you can enter the path to the FFMPEG and ImageMagick
binaries.

FFMPEG_BINARY
    Normally you can leave this one to its default (None) and MoviePy
    will detect automatically the right name, which will be either
    'ffmpeg' (on linux) or 'ffmpeg.exe' (on windows)
    
IMAGEMAGICK_BINARY
    For linux users, 'convert' should be fine.
    For Windows users, you must specify the path to the ImageMagick
    'convert' binary. For instance:
    "C:\Program Files\ImageMagick-6.8.8-Q16\convert" 

You can run this file to check that FFMPEG has been detected.
"""

FFMPEG_BINARY = None
IMAGEMAGICK_BINARY = 'convert'



# =====================================================================
# CODE. Don't write anything below this line :O

import subprocess as sp

def try_cmd(cmd):    
        try:
            proc = sp.Popen(cmd,
                             stdout=sp.PIPE,
                             stderr=sp.PIPE)
            proc.communicate()
        except:
            return False
        else:
            return True


if FFMPEG_BINARY is None:
    
    if try_cmd(['ffmpeg']):
        FFMPEG_BINARY = 'ffmpeg'
    elif try_cmd(['ffmpeg.exe']):
        FFMPEG_BINARY = 'ffmpeg.exe'
    else:
        raise IOError("FFMPEG binary not found. Try installing MoviePy"\
                       " manually and specify the path to the binary in"\
                       " the file conf.py")

if __name__ == "__main__":
    if try_cmd([FFMPEG_BINARY]):
        print( "MoviePy : ffmpeg successfully found." )
    else:
        print( "MoviePy : can't find ffmpeg." )
        
        

########NEW FILE########
__FILENAME__ = decorators
"""
all decorators used in moviepy go there
"""

import decorator
from moviepy.tools import cvsecs



@decorator.decorator
def outplace(f, clip, *a, **k):
    """ Enables to make operations outplace """
    newclip = clip.copy()
    f(newclip, *a, **k)
    return newclip
    


@decorator.decorator
def apply_to_mask(f, clip, *a, **k):
    """ This decorator will apply the same function f to the mask of
        the clip created with f """
        
    newclip = f(clip, *a, **k)
    if hasattr(newclip, 'mask') and (newclip.mask != None):
        newclip.mask = f(newclip.mask, *a, **k)
    return newclip



@decorator.decorator
def apply_to_audio(f, clip, *a, **k):
    """ This decorator will apply the function f to the audio of
        the clip created with f """
        
    newclip = f(clip, *a, **k)
    if hasattr(newclip, 'audio') and (newclip.audio != None):
        newclip.audio = f(newclip.audio, *a, **k)
    return newclip
    
    

@decorator.decorator
def add_mask_if_none(f, clip, *a, **k):
    """ Add a mask to the clip if there is none. """
        
    if clip.mask is None:
        clip = clip.add_mask()
    return f(clip, *a, **k)



@decorator.decorator
def requires_duration(f, clip, *a, **k):
    """ Raise an error if the clip has no duration."""
    
    if clip.duration is None:
        raise ValueError("Attribute 'duration' not set")
    else:
        return f(clip, *a, **k)



@decorator.decorator
def audio_video_fx(f, clip, *a, **k):
    """ Use an audio function on a video/audio clip
    
    This decorator tells that the function f (audioclip -> audioclip)
    can be also used on a video clip, at which case it returns a
    videoclip with unmodified video and modified audio.
    """
    
    if hasattr(clip, "audio"):
        newclip = clip.copy()
        if clip.audio != None:
            newclip.audio =  f(clip.audio, *a, **k)
        return newclip
    else:
        return f(clip, *a, **k)



@decorator.decorator
def time_can_be_tuple(f, clip, *a, **k):
    """
    All tuples in the arguments of f will be considered as time and
    converted to seconds.
    """
    
    fun = lambda e: e if (not isinstance(e,tuple)) else cvsecs(*e)
    a = map(fun,a)
    k = dict( [(m, fun(n)) for m,n in k.items()])
    return f(clip, *a, **k)

########NEW FILE########
__FILENAME__ = editor
"""
This file is meant to make it easy to load the main features of
MoviePy by simply typing:

>>> from moviepy.editor import *

In particular it will load many effects from the video.fx and audio.fx
folders and turn them into VideoClip methods, so that instead of
>>> clip.fx( vfx.resize, 2 ) # or equivalently vfx.resize(clip, 2)
we can write
>>> clip.resize(2)

It also starts a PyGame session (if PyGame is installed) and enables
clip.preview().
"""

# Note that these imports could have been performed in the __init__.py
# file, but this would make the loading of moviepy slower.

# Clips

from .video.io.VideoFileClip import VideoFileClip
from .video.io.ImageSequenceClip import ImageSequenceClip
from .video.VideoClip import VideoClip, ImageClip, ColorClip, TextClip
from .video.compositing.CompositeVideoClip import CompositeVideoClip
from .video.compositing.concatenate import concatenate

from .audio.AudioClip import AudioClip, CompositeAudioClip
from .audio.io.AudioFileClip import AudioFileClip

# FX

import moviepy.video.fx as vfx
import moviepy.audio.fx as afx
import moviepy.video.compositing.transitions as transfx

# Tools

import moviepy.video.tools as videotools
import moviepy.video.io.ffmpeg_tools as ffmpeg_tools
from .tools import cvsecs

try:
    from .video.io.sliders import sliders
except ImportError:
    pass

# The next loop transforms many effects into VideoClip methods so that
# they can be walled with myclip.resize(width=500) instead of 
# myclip.fx( vfx.resize, width= 500)
for method in ["vfx.crop",
               "vfx.loop",
               "vfx.resize",
               "vfx.margin",
               "vfx.fadein",
               "vfx.fadeout",
               "vfx.speedx",
               "afx.volumex",
               "afx.audio_fadein",
               "afx.audio_fadeout",
               "transfx.crossfadein",
               "transfx.crossfadeout"]:
    exec("VideoClip.%s = %s"%( method.split('.')[1], method))


for method in ["afx.audio_fadein",
               "afx.audio_fadeout",
               "vfx.loop",
               "afx.volumex"]:
    exec("AudioClip.%s = %s"%( method.split('.')[1], method))


#-----------------------------------------------------------------
# Previews: try to import pygame


# Add methods preview and show (only if pygame installed)
try:
    from moviepy.video.io.preview import show, preview
except ImportError:
    def preview(self, *args, **kwargs):
        """NOT AVAILABLE : clip.preview requires Pygame installed."""
        raise ImportError("clip.preview requires Pygame installed")
    def show(self, *args, **kwargs):
        """NOT AVAILABLE : clip.show requires Pygame installed."""
        raise ImportError("clip.show requires Pygame installed")


VideoClip.preview = preview
VideoClip.show = show

try:
    from moviepy.audio.io.preview import preview
except ImportError:
    def preview(self, *args, **kwargs):
        """ NOT AVAILABLE : clip.preview requires Pygame installed."""
        raise ImportError("clip.preview requires Pygame installed")

AudioClip.preview = preview

        


########NEW FILE########
__FILENAME__ = tools
"""
Misc. useful functions that can be used at many places in the program.
"""

import subprocess as sp
import sys

def sys_write_flush(s):
    """ writes and flushes witout delay a text in the console """
    sys.stdout.write(s)
    sys.stdout.flush()


def subprocess_call(cmd, verbose=True, errorprint=True):
    """
    executes the subprocess command
    """
    
    def verboseprint(s):
        if verbose: sys_write_flush(s)
    
    verboseprint( "\nMoviePy Running:\n>>> "+ " ".join(cmd) )
    
    proc = sp.Popen(cmd, stderr = sp.PIPE)
                         
    out, err = proc.communicate() # proc.wait()
    proc.stderr.close()
    
    if proc.returncode:
        if errorprint:
            sys_write_flush( "\nMoviePy: WARNING !\n"
                    "   The following command returned an error:\n")
            sys_write_flush( err.decode('utf8'))
        raise IOError
    else:
        verboseprint( "\n... command successful.\n")
    
    del proc


def cvsecs(*args):
    """
    Converts a time to second. Either cvsecs(min,secs) or
    cvsecs(hours,mins,secs).
    >>> cvsecs(5.5) # -> 5.5 seconds
    >>> cvsecs(10, 4.5) # -> 604.5 seconds
    >>> cvsecs(1, 0, 5) # -> 3605 seconds
    """
    if len(args) == 1:
        return args[0]
    elif len(args) == 2:
        return 60*args[0]+args[1]
    elif len(args) ==3:
        return 3600*args[0]+60*args[1]+args[2]

########NEW FILE########
__FILENAME__ = version
__version__ = "0.2.1.7.21"

########NEW FILE########
__FILENAME__ = CompositeVideoClip
import numpy as np
from moviepy.video.VideoClip import VideoClip, ColorClip
from moviepy.audio.AudioClip import CompositeAudioClip

#  CompositeVideoClip

class CompositeVideoClip(VideoClip):

    """ 
    
    A VideoClip made of other videoclips displayed together. This is the
    base class for most compositions.

    :param size: The size (height x width) of the final clip.

    :param clips: A list of videoclips. Each clip of the list will
       be displayed below the clips appearing after it in the list.
       For each clip:
       
       - The attribute ``pos`` determines where the clip is placed.
          See ``VideoClip.set_pos``
       - The mask of the clip determines which parts are visible.
        
       Finally, if all the clips in the list have their ``duration``
       attribute set, then the duration of the composite video clip
       is computed automatically

    :param transparent: if False, the clips are overlaid on a surface
      of the color `bg_color`. If True, the clips are overlaid on
      a transparent surface, so that all pixels that are transparent
      for all clips will be transparent in the composite clip. More
      precisely, the mask of the composite clip is then the composite
      of the masks of the different clips. Only use `transparent=True`
      when you intend to use your composite clip as part of another
      composite clip and you care about its transparency.
      
    """

    def __init__(self, clips, size=None, bg_color=None, transparent=False,
                 ismask=False):
                     
        if size is None:
            size = clips[0].size
        
        if bg_color is None:
            bg_color = 0.0 if ismask else (0, 0, 0)
        
        VideoClip.__init__(self)
        
        self.size = size
        self.ismask = ismask
        self.clips = clips
        self.transparent = transparent
        self.bg_color = bg_color
        self.bg = ColorClip(size, col=self.bg_color).get_frame(0)
        
        # compute duration
        ends = [c.end for c in self.clips]
        if not any([(e is None) for e in ends]):
            self.duration = max(ends)
            self.end = max(ends)

        # compute audio
        audioclips = [v.audio for v in self.clips if v.audio != None]
        if len(audioclips) > 0:
            self.audio = CompositeAudioClip(audioclips)

        # compute mask
        if transparent:
            maskclips = [c.mask.set_pos(c.pos) for c in self.clips
                         if c.mask is not None]
            self.mask = CompositeVideoClip(maskclips,self.size,
                                        transparent=False, ismask=True)

        def gf(t):
            """ The clips playing at time `t` are blitted over one
                another. """

            f = self.bg
            for c in self.playing_clips(t):
                    f = c.blit_on(f, t)
            return f

        self.get_frame = gf

    def playing_clips(self, t=0):
        """ Returns a list of the clips in the composite clips that are
            actually playing at the given time `t`. """
        return [c for c in self.clips if c.is_playing(t)]



def clips_array(array, rows_widths=None, cols_widths=None,
                transparent = False, bg_color = (0,0,0)):
    
    array = np.array(array)
    sizes_array = np.array([[c.size for c in line] for line in array])
    
    if rows_widths == None:
        rows_widths = sizes_array[:,:,1].max(axis=1)
    if cols_widths == None:
        cols_widths = sizes_array[:,:,0].max(axis=0)
    
    xx = np.cumsum([0]+list(cols_widths)) 
    yy = np.cumsum([0]+list(rows_widths))
    
    for j,(x,cw) in list(enumerate(zip(xx[:-1],cols_widths))):
        for i,(y,rw) in list(enumerate(zip(yy[:-1],rows_widths))):
            clip = array[i,j]
            w,h = clip.size
            if (w < cw) or (h < rw):
                clip = (CompositeVideoClip([clip.set_pos('center')],
                                          size = (cw,rw),
                                          transparent = transparent,
                                          bg_color = (bg_color)).
                                     set_duration(clip.duration))
                
            array[i,j] = clip.set_pos((x,y))           
                 
    return CompositeVideoClip(array.flatten(), size = (xx[-1],yy[-1]),
                              transparent=transparent,
                              bg_color = bg_color)
    
    

########NEW FILE########
__FILENAME__ = concatenate
import numpy as np

from moviepy.video.VideoClip import VideoClip
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
from moviepy.audio.AudioClip import CompositeAudioClip

from moviepy.video.compositing.on_color import on_color 

def concatenate(clipslist, method = 'chain', transition=None,
           bg_color=(0, 0, 0), transparent=False, ismask=False, crossover = 0):
    """ Concatenates several video clips
    
    Returns a video clip made by clip by concatenating several video clips.
    (Concatenated means that they will be played one after another).
    if the clips do not have the same resolution, the final
    resolution will be such that no clip has to be resized. As
    a consequence the final clip has the height of the highest
    clip and the width of the widest clip of the list. All the
    clips with smaller dimensions will appear centered. The border
    will be transparent if mask=True, else it will be of the
    color specified by ``bg_color``.
    
    Returns a VideoClip instance if all clips have the same size and
    there is no transition, else a composite clip.
    
    Parameters
    -----------

    clipslist
      A list of video clips which must all have their ``duration``
      attributes set.
    
    transition
      A clip that will be played between each two clips of the list.  
    
    bg_color
      Color of the background, if any.

    transparent
      If True, the resulting clip's mask will be the concatenation of
      the masks of the clips in the list. If the clips do not have the
      same resolution, the border around the smaller clips will be
      transparent.
    
                       
    """
    
    if transition != None:
        l = [[v, transition] for v in clipslist[:-1]]
        clipslist = reduce(lambda x, y: x + y, l) + [clipslist[-1]]
        transition = None
    
    tt = np.cumsum([0] + [c.duration for c in clipslist])
    sizes = [v.size for v in clipslist]
    w = max([r[0] for r in sizes])
    h = max([r[1] for r in sizes])
    
    if method == 'chain':
        result = VideoClip(ismask = ismask)
        result.size = (w,h)

        def gf(t):
            i = max([i for i, e in enumerate(tt) if e <= t])
            return clipslist[i].get_frame(t - tt[i])
        
        result.get_frame = gf
        if (len(set(map(tuple,sizes)))>1) and (bg_color is not None):
            # If not all clips have the same size, flatten the result
            # on some color
            result = result.fx( on_color, (w,h), bg_color, 'center')
        
    elif method == 'compose':
        tt = np.maximum(0, tt - crossover*np.arange(len(tt)))
        result = concatenate( [c.set_start(t).set_pos('center')
                                    for (c, t) in zip(clipslist, tt)],
                   size = (w, h), bg_color=bg_color, ismask=ismask,
                   transparent=transparent)
    
    result.tt = tt
    result.clipslist = clipslist
    result.start_times = tt[:-1]
    result.start, result.duration, result.end = 0, tt[-1] , tt[-1]
    
    # Compute the mask if any
    
    if transparent and (not ismask):
        # add a mask to the clips which have none
        clips_withmask = [(c if (c.mask!=None) else c.add_mask())
                          for c in clipslist] 
        result.mask = concatenate([c.mask for c in clips_withmask],
                    bg_color=0, ismask=True, transparent=False)
                    
                    
    # Compute the audio, if any.
    
    audio_t = [(c.audio,t) for c,t in zip(clipslist,tt) if c.audio!=None]
    if len(audio_t)>0:
        result.audio = CompositeAudioClip([a.set_start(t)
                                for a,t in audio_t])
    return result

########NEW FILE########
__FILENAME__ = on_color
from moviepy.video.VideoClip import ColorClip
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip

def on_color(clip, size=None, color=(0, 0, 0), pos=None, col_opacity=None):
    """ 
    Returns a clip made of the current clip overlaid on a color
    clip of a possibly bigger size. Can serve to flatten transparent
    clips (ideal for previewing clips with masks).
    
    :param size: size of the final clip. By default it will be the
       size of the current clip.
    :param bg_color: the background color of the final clip
    :param pos: the position of the clip in the final clip.
    :param col_opacity: should the added zones be transparent ?
    """
    
    if size is None:
        size = clip.size
    if pos is None:
        pos = 'center'
    colorclip = ColorClip(size, color)
    if col_opacity:
        colorclip = colorclip.with_mask().set_opacity(col_opacity)

    return CompositeVideoClip([colorclip, clip.set_pos(pos)],
                              transparent=(col_opacity != None))

########NEW FILE########
__FILENAME__ = positioning
"""
This module provides classes that make positioning easy
"""

# class ClipPosition:

########NEW FILE########
__FILENAME__ = transitions
"""
Here is the current catalogue. These are meant
to be used with clip.fx. There are available as transfx.crossfadein etc.
if you load them with ``from moviepy.all import *``
"""

from moviepy.decorators import requires_duration, add_mask_if_none
from .CompositeVideoClip import CompositeVideoClip
from moviepy.video.fx.fadein import fadein
from moviepy.video.fx.fadeout import fadeout

@add_mask_if_none
def crossfadein(clip, duration):
    """
    Makes the clip appear progressively, over ``duration`` seconds.
    Only works when the clip is included in a CompositeVideoClip.
    """
    newclip = clip.copy()
    newclip.mask = clip.mask.fx(fadein, duration)
    return newclip


@requires_duration
@add_mask_if_none
def crossfadeout(clip, duration):
    """
    Makes the clip disappear progressively, over ``duration`` seconds.
    Only works when the clip is included in a CompositeVideoClip.
    """
    newclip = clip.copy()
    newclip.mask = clip.mask.fx(fadeout, duration)
    return newclip










@requires_duration
def make_loopable(clip, cross_duration):
    """ Makes the clip fade in progressively at its own end, this way
    it can be looped indefinitely. ``cross`` is the duration in seconds
    of the fade-in.  """  
    d = clip.duration
    clip2 = clip.fx(crossfadein, cross_duration).\
                 set_start(d - cross_duration)
    return CompositeVideoClip([ clip, clip2 ]).\
                 subclip(cross_duration,d)

########NEW FILE########
__FILENAME__ = blackwhite
import numpy as np

def blackwhite(clip, RGB = [1,1,1], preserve_luminosity=True):
    """ Desaturates the picture, makes it black and white.
        If RBG is 'CRT_phosphor' a special set of values is used.
        preserve_luminosity does nothing right now.
        method = sum (TODO: others) """
    if RGB == 'CRT_phosphor':
        RGB = [0.2125, 0.7154, 0.0721]
        
    return clip.fl_image(lambda im: np.dstack(3*[im.sum(axis=2)/3]) )

########NEW FILE########
__FILENAME__ = blink
def blink(clip, d_on, d_off):
    """
    Makes the clip blink. At each blink it will be displayed ``d_on``
    seconds and disappear ``d_off`` seconds. Will only work in
    composite clips.
    """
    newclip = copy(clip)
    if newclip.mask is None:
        newclip = newclip.with_mask()
    D = d_on + d_off
    newclip.mask = newclip.mask.fl( lambda gf,t: gf(t)*((t % D) < d_on))
    return newclip

########NEW FILE########
__FILENAME__ = colorx
import numpy as np

def colorx(clip, factor):
    """ multiplies the clip's colors by the given factor, can be used
        to decrease or increase the clip's brightness (is that the
        reight word ?)
    """
    return clip.fl_image( lambda pic: np.minimum(255,(factor*pic)).
                                                        astype('uint8'))

########NEW FILE########
__FILENAME__ = crop
def crop(clip, x1=None, y1=None, x2=None, y2=None,
         width = None, height=None,
         x_center= None, y_center=None):
    """
    Returns a new clip in which just a rectangular subregion of the
    original clip is conserved. x1,y1 indicates the top left corner and
    x2,y2 is the lower right corner of the croped region.
    All coordinates are in pixels. Float numbers are accepted.
    
    To crop an arbitrary rectangle:
    
    >>> crop(clip, x1=50, y1=60, x2=460, y2=275)
    
    Only remove the part above y=30:
    
    >>> crop(clip, y1=30)
    
    Crop a rectangle that starts 10 pixels left and is 200px wide
    
    >>> crop(clip, x1=10, width=200)
    
    Crop a rectangle centered in x,y=(300,400), width=50, height=150 :
    
    >>> crop(clip,  x_center=300 , y_center=400,
                        width=50, height=150)
    
    Any combination of the above should work, like for this rectangle
    centered in x=300, with explicit y-boundaries:
    
    >>> crop(x_center=300, width=400, y1=100, y2=600)
    
    """
    
    
    if width:
        if x1 is not None:
            x2 = x1+width
        else:
            x1 = x2-width
    
    if height:
        if y1 is not None:
            y2 = y1+height
        else:
            y1 = y2 - height
    
    if x_center:
        x1, x2 = x_center - width/2, x_center + width/2
    
    if y_center:
        y1, y2 = y_center - height/2, y_center + height/2
    
    if x1 is None:
        x1 = 0
    if y1 is None:
        y1 = 0
    if x2 is None:
        x2 = clip.size[0]
    if y2 is None:
        y2 = clip.size[1]
    
    return clip.fl_image(
            lambda pic: pic[int(y1):int(y2), int(x1):int(x2)],
            apply_to=['mask'])

########NEW FILE########
__FILENAME__ = even_size
import numpy as np

from moviepy.decorators import apply_to_mask

@apply_to_mask
def even_size(clip):
    """ Crops the clip to make dimensions even.

    """

    w,h = clip.size

    if (w%2 == 0) and (h%2==0):
        return clip
    
    if (w%2 != 0) and (h%2!=0):
        fl_image = lambda a : a[:-1,:-1,:]
    elif (w%2 != 0):
        fl_image = lambda a : a[:,:-1,:]
    else:
        fl_image = lambda a : a[:-1,:,:]

    return clip.fl_image(fl_image)



########NEW FILE########
__FILENAME__ = fadein
                                                        
def fadein(clip, duration):
    """ Makes the clip fade to black progressively, over ``duration``
    seconds. For more advanced fading, see 
    ``moviepy.video.composition.crossfadein`` """
    
    return clip.fl(lambda gf, t: min(1.0 * t / duration, 1) * gf(t))

########NEW FILE########
__FILENAME__ = fadeout
from moviepy.decorators import requires_duration

@requires_duration
def fadeout(clip, duration):
    """
    Makes the clip fade to black progressively, over ``duration`` seconds.
    For more advanced fading, see ``composition.crossfade``
    """
    fading = lambda t: min(1.0 * (clip.duration - t) / duration, 1)
    return clip.fl(lambda gf, t: fading(t) * gf(t))


    

                     

########NEW FILE########
__FILENAME__ = freeze_at_end
from moviepy.decorators import requires_duration
from moviepy.video.VideoClip import ImageClip
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip


@requires_duration
def freeze_at_end(clip, freeze_duration=None, total_duration=None):
    """
    Makes the clip freeze on its last frame.  With ``duration`` you can
    specify the duration of the freeze. With ``total_duration`` you can
    specify the total duration of the clip and the freeze (i.e. the
    duration of the freeze is automatically calculated). If neither
    is provided, the freeze will have an infinite length.
    """
    
    freezed_clip = ImageClip(clip.get_frame(clip.end))
    if total_duration:
        freeze_duration = total_duration - clip.duration
    if freeze_duration:
        freezed_clip = freezed_clip.set_duration(freeze_duration)
    
    return CompositeVideoClip([clip,freezed_clip.set_start(clip.end)])

########NEW FILE########
__FILENAME__ = freeze_at_start
from moviepy.decorators import requires_duration
from moviepy.video.VideoClip import ImageClip
from moviepy.video.compositing.concatenate import concatenate

@requires_duration
def freeze_at_start(clip, freeze_duration=None, total_duration=None):
    """ Momentarily freeze the clip on its first frame.

    With ``duration``you can specify the duration of the freeze.
    With ``total_duration`` you can specify the total duration of
    the clip and the freeze (i.e. the duration of the freeze is
    automatically calculated). If neither is provided, the freeze
    will have an infinite length.
    """
    
    freezed_clip = ImageClip(clip.get_frame(0))
    if clip.mask:
        freezed_clip.mask = ImageClip(clip.mask.get_frame(0))
    
    if total_duration:
        freeze_duration = total_duration - clip.duration
    if freeze_duration:
        freezed_clip = freezed_clip.set_duration(freeze_duration)
    
    return concatenate([freezed_clip, clip])

########NEW FILE########
__FILENAME__ = gamma_corr

def gamma_corr(clip, gamma):
    """ Gamma-correction of a video clip """
    def fl(im):
        corrected = (255*(1.0*im/255)**gamma)
        return corrected.astype('uint8')
    
    return clip.fl_image(fl)

########NEW FILE########
__FILENAME__ = headblur
import numpy as np


#------- CHECKING DEPENDENCIES ----------------------------------------- 
try:
    import cv2
    headblur_possible = True
except:
    headblur_possible = False
#-----------------------------------------------------------------------


def headblur(clip,fx,fy,r_zone,r_blur=None):
    """
    Returns a filter that will blurr a moving part (a head ?) of
    the frames. The position of the blur at time t is
    defined by (fx(t), fy(t)), the radius of the blurring
    by ``r_zone`` and the intensity of the blurring by ``r_blur``.
    Requires OpenCV for the circling and the blurring.
    Automatically deals with the case where part of the image goes
    offscreen.
    """
    
    if r_blur==None: r_blur = 2*r_zone/3
    
    def fl(gf,t):
        
        im = gf(t)
        h,w,d = im.shape
        x,y = int(fx(t)),int(fy(t))
        x1,x2 = max(0,x-r_zone),min(x+r_zone,w)
        y1,y2 = max(0,y-r_zone),min(y+r_zone,h)
        region_size = y2-y1,x2-x1
        
        mask = np.zeros(region_size).astype('uint8')
        cv2.circle(mask, (r_zone,r_zone), r_zone, 255, -1,
                   lineType=cv2.CV_AA)
                               
        mask = np.dstack(3*[(1.0/255)*mask])
        
        orig = im[y1:y2, x1:x2]
        blurred = cv2.blur(orig,(r_blur, r_blur))
        im[y1:y2, x1:x2] = mask*blurred + (1-mask)*orig
        return im
    
    return clip.fl(fl)



#------- OVERWRITE IF REQUIREMENTS NOT MET -----------------------------
if not headblur_possible:
    doc = headblur.__doc__
    def headblur(clip,fx,fy,r_zone,r_blur=None):
        raise IOError("fx painting needs scikit-image or scipy")
    
    headblur.__doc__ = doc
#----------------------------------------------------------------------- 

########NEW FILE########
__FILENAME__ = loop
from moviepy.decorators import (apply_to_mask,
                                 apply_to_audio,
                                 requires_duration)


@requires_duration
@apply_to_mask
@apply_to_audio
def loop(self, n=None, duration=None):
    """
    Returns a clip that plays the current clip in an infinite loop.
    Ideal for clips coming from gifs.
    
    Parameters
    ------------
    n
      Number of times the clip should be played. If `None` the
      the clip will loop indefinitely (i.e. with no set duration).

    duration
      Total duration of the clip. Can be specified instead of n.
    """
    result = self.fl_time(lambda t: t % self.duration)
    if n:
        duration = n*self.duration
    if duration:
        result.duration = duration
    return result

########NEW FILE########
__FILENAME__ = lum_contrast
def lum_contrast(clip, lum = 0, contrast=0, contrast_thr=127):
    """ luminosity-contrast correction of a clip """
    
    def fl_image(im):
        im = 1.0*im # float conversion
        corrected = im + lum + factor*(im-thr)
        corrected[corrected < 0] = 0
        corrected[corrected > 255] = 255
        return corrected.astype('uint8')
    
    return clip.fl_image(fl_image)

########NEW FILE########
__FILENAME__ = make_loopable
import moviepy.video.compositing.transitions as transfx

def make_loopable(clip, cross):
    """
    Makes the clip fade in progressively at its own end, this way
    it can be looped indefinitely. ``cross`` is the duration in seconds
    of the fade-in.  """  
    d = clip.duration
    clip2 = clip.fx(transfx.crossfadein, cross).\
                 set_start(d - cross)
    return CompositeVideoClip([ clip, clip2 ]).\
                 subclip(cross,d)

########NEW FILE########
__FILENAME__ = margin
import numpy as np
from moviepy.decorators import apply_to_mask
from moviepy.video.VideoClip import ImageClip


@apply_to_mask
def margin(clip, mar=None, left=0, right=0, top=0,
           bottom=0, color=(0, 0, 0), opacity = 1.0):
    """
    Draws an external margin all around the frame.
    
    :param mar: if not ``None``, then the new clip has a margin of
        size ``mar`` in pixels on the left, right, top, and bottom.
        
    :param left, right, top, bottom: width of the margin in pixel
        in these directions.
        
    :param color: color of the margin.
    
    :param mask_margin: value of the mask on the margin. Setting
        this value to 0 yields transparent margins.
    
    """

    if (opacity != 1.0) and (clip.mask is None) and not (clip.ismask):
        clip = clip.add_mask()

    if mar != None:
        left = right = top = bottom = mar
    
    def make_bg(w,h):
        new_w, new_h = w + left + right, h + top + bottom
        if clip.ismask:
            shape = (new_h, new_w)
            bg = ( np.tile(opacity, (new_h, new_w))
                       .astype(float)
                       .reshape(shape))
        else:
            shape = (new_h, new_w, 3)
            bg = np.tile(color, (new_h, new_w)).reshape(shape)
        return bg
        
    if isinstance(clip, ImageClip):
        
        im =  make_bg(clip.w,clip.h)
        im[top:top + clip.h, left:left + clip.w] = clip.img
        return clip.fl_image(lambda pic:im)
        
    else:
        
        def fl(gf, t):
            pic = gf(t)
            h,w = pic.shape[:2]
            im = make_bg(w,h)
            im[top:top + h, left:left + w] = pic
            return im
        return clip.fl(fl)
            
    

########NEW FILE########
__FILENAME__ = mirror_x

def mirror_x(clip, apply_to= "mask"):
    """ flips the clip horizontally (and its mask too, by default) """
    return clip.fl_image(lambda gf, t: gf(t)[:,::-1],
                          apply_to = apply_to)

########NEW FILE########
__FILENAME__ = mirror_y
def mirror_y(clip, apply_to= "mask"):
    """ flips the clip vertically (and its mask too, by default) """
    return clip.fl_image(lambda gf, t : gf(t)[::-1],
                          apply_to = apply_to)

########NEW FILE########
__FILENAME__ = painting
#------- CHECKING DEPENDENCIES ----------------------------------------- 
painting_possible = True
try:
    from skimage.filter import sobel
except:
    try:
        from scipy.ndimage.filters import sobel
    except:
        painting_possible = False
#-----------------------------------------------------------------------    



import numpy as np

def to_painting(image,saturation = 1.4,black = 0.006):
    """ transforms any photo into some kind of painting """
    edges = sobel(image.mean(axis=2))
    darkening =  black*(255*np.dstack(3*[edges]))
    painting = saturation*image-darkening
    return np.maximum(0,np.minimum(255,painting)).astype('uint8')
    
def painting(clip, saturation = 1.4,black = 0.006):
    """
    Transforms any photo into some kind of painting. Saturation
    tells at which point the colors of the result should be
    flashy. ``black`` gives the anount of black lines wanted.
    Requires Scikit-image or Scipy installed.
    """
    return clip.fl_image(lambda im : to_painting(im,saturation,black))
        


#------- OVERWRITE IF REQUIREMENTS NOT MET -----------------------------

if not painting_possible:
    doc = painting.__doc__
    def painting(clip, newsize=None, height=None, width=None):
        raise IOError("fx painting needs scikit-image or scipy")
    
    painting.__doc__ = doc
#----------------------------------------------------------------------- 


########NEW FILE########
__FILENAME__ = resize
resize_possible = True

try:
    # TRY USING OpenCV AS RESIZER
    import cv2
    resizer = lambda pic, newsize : cv2.resize(pic.astype('uint8'),
                tuple(map(int, newsize)),
                interpolation=cv2.INTER_AREA)
                
except ImportError:
    
    
    try:
        # TRY USING PIL/PILLOW AS RESIZER
        from PIL import Image
        import numpy as np
        def resizer(pic, newsize):
            newsize = list(map(int, newsize))[::-1]
            shape = pic.shape
            if len(shape)==3:
                newshape = (newsize[0],newsize[1], shape[2] )
            else:
                newshape = (newsize[0],newsize[1])
                
            pilim = Image.fromarray(pic)
            resized_pil = pilim.resize(newsize[::-1], Image.ANTIALIAS)
            arr = np.fromstring(resized_pil.tostring(), dtype='uint8')
            return arr.reshape(newshape)
            
    except ImportError:
        # TRY USING SCIPY AS RESIZER
        try:
            from scipy.misc import imresize
            resizer = lambda pic, newsize : imresize(pic,
                                            map(int, newsize[::-1]))
                                               
        except ImportError:
            resize_possible = False
            
        
        
    
from moviepy.decorators import apply_to_mask
   
    
@apply_to_mask
def resize(clip, newsize=None, height=None, width=None):
    """ 
    Returns a video clip that is a resized version of the clip.
    
    Parameters
    ------------
    
    newsize:
      Can be either 
        - ``(height,width)`` in pixels or a float representing
        - A scaling factor, like 0.5
        - A function of time returning one of these.
            
    width:
      width of the new clip in pixel. The height is then computed so
      that the width/height ratio is conserved. 
            
    height:
      height of the new clip in pixel. The width is then computed so
      that the width/height ratio is conserved.
    
    Examples
    ----------
             
    >>> myClip.resize( (460,720) ) # New resolution: (460,720)
    >>> myClip.resize(0.6) # width and heigth multiplied by 0.6
    >>> myClip.resize(width=800) # height computed automatically.
    >>> myClip.resize(lambda t : 1+0.02*t) # slow swelling of the clip
    
    """
    w, h = clip.size
    
    if newsize != None:
        
        def trans_newsize(ns):
            
            if isinstance(ns, (int, float)):
                return [ns * w, ns * h]
            else:
                return ns
                
        if hasattr(newsize, "__call__"):
            
            newsize2 = lambda t : trans_newsize(newsize(t))
            
            if clip.ismask:
                
                fun = lambda gf,t: (1.0*resizer((255 * gf(t))
                                            .astype('uint8'),
                                   newsize2(t))/255)
            else:
                
                fun = lambda gf,t: resizer(gf(t).astype('uint8'),
                                          newsize2(t))
                
            return clip.fl(fun, keep_duration=True, apply_to='mask')
            
        else:
            
            newsize = trans_newsize(newsize)
        

    elif height != None:
        
        newsize = [w * height / h, height]
        
    elif width != None:
        
        newsize = [width, h * width / w]
        
        
        
    if clip.ismask:
        
        fl = lambda pic: 1.0*resizer((255 * pic).astype('uint8'),
            newsize)/255
            
    else:
        
        fl = lambda pic: resizer(pic.astype('uint8'), newsize)

    return clip.fl_image(fl, apply_to='mask')


if not resize_possible:
    
    doc = resize.__doc__
    def resize(clip, newsize=None, height=None, width=None):
        raise ImportError("fx resize needs OpenCV or Scipy or PIL")
    resize.__doc__ = doc

########NEW FILE########
__FILENAME__ = rotation
import numpy as np

def rotation(clip, angle, apply_to_mask=True, unit='deg'):
    
    if unit == 'rad':
        angle = 360*angle/(2*3.14159)
    
    transpo = [1,0] if clip.ismask else [1,0,2]
    angle_transfo = {
        90 : lambda im : np.transpose(im, axes=transpo)[::-1],
        -90: lambda im : np.transpose(im, axes=transpo)[:,::-1],
        180: lambda im : im[::-1,::-1]}
    
    if angle in angle_transfo:
        newclip =  clip.fl_image( angle_transfo[angle])
    else:
        raise ValueError('Angle not supported, only 90, -90, 180')
    
    if apply_to_mask and (newclip.mask is not None):
        newclip.mask = newclip.mask.fx( rotation, angle,
                                        apply_to_mask=False,
                                        unit=unit)
    
    return newclip

########NEW FILE########
__FILENAME__ = scroll

def scroll(clip, h=None, w=None, x_speed=0, y_speed=0,
           x_start=0, y_start=0, apply_to="mask"):
    """ Scrolls horizontally or vertically a clip, e.g. to make end
        credits """
    if h is None: h = clip.h
    if w is None: w = clip.w
    def f(gf,t):
        x = x_start+int(x_speed*t)
        y = y_start+ int(y_speed*t)
        return gf(t)[y:y+h, x:x+w]
    return clip.fl(f, apply_to = apply_to)

########NEW FILE########
__FILENAME__ = speedx
from moviepy.decorators import apply_to_mask,apply_to_audio

@apply_to_mask
@apply_to_audio
def speedx(clip, factor = None, final_duration=None):
    """
    Returns a clip playing the current clip but at a speed multiplied
    by ``factor``. Instead of factor one can indicate the desired
    ``final_duration`` of the clip, and the factor will be automatically
    computed.
    The same effect is applied to the clip's audio and mask if any.
    """
    
    if final_duration:
        factor = 1.0* clip.duration / final_duration
        
    newclip = clip.fl_time(lambda t: factor * t)
    
    if clip.duration != None:
        newclip = newclip.set_duration(1.0 * clip.duration / factor)
    
    return newclip

########NEW FILE########
__FILENAME__ = time_mirror
from moviepy.decorators import (apply_to_mask, apply_to_audio,
                                 requires_duration)


@requires_duration
@apply_to_mask
@apply_to_audio
def time_mirror(self):
    """
    Returns a clip that plays the current clip backwards.
    The clip must have its ``duration`` attribute set.
    The same effect is applied to the clip's audio and mask if any.
    """
    return self.fl_time(lambda t: self.duration - t, keep_duration=True)

########NEW FILE########
__FILENAME__ = time_symetrize
from moviepy.decorators import (apply_to_mask, apply_to_audio,
                                 requires_duration)
from moviepy.video.compositing.concatenate import concatenate
from .time_mirror import time_mirror

@requires_duration
@apply_to_mask
def time_symetrize(clip):
    """
    Returns a clip that plays the current clip once forwards and
    then once backwards. This is very practival to make video that
    loop well, e.g. to create animated GIFs.
    This effect is automatically applied to the clip's mask and audio
    if they exist.
    """
    return concatenate([clip, clip.fx( time_mirror )])

########NEW FILE########
__FILENAME__ = ffmpeg_reader
from __future__ import division

import subprocess as sp
import re

import numpy as np
from moviepy.conf import FFMPEG_BINARY  # ffmpeg, ffmpeg.exe, etc...
from moviepy.tools import cvsecs


class FFMPEG_VideoReader:

    def __init__(self, filename, print_infos=False, bufsize = None,
                 pix_fmt="rgb24"):

        self.filename = filename
        infos = ffmpeg_parse_infos(filename, print_infos)
        self.fps = infos['video_fps']
        self.size = infos['video_size']
        self.duration = infos['video_duration']
        self.nframes = infos['video_nframes']

        self.infos = infos

        self.pix_fmt = pix_fmt
        if pix_fmt == 'rgba':
            self.depth = 4
        else:
            self.depth = 3

        if bufsize is None:
            w, h = self.size
            bufsize = self.depth * w * h + 100

        self.proc= None
        self.bufsize= bufsize
        self.initialize()


        self.pos = 1
        self.lastread = self.read_frame()


    def initialize(self, starttime=0):
        """Opens the file, creates the pipe. """
        
        self.close() # if any
        
        if starttime !=0 :
            offset = min(1,starttime)
            i_arg = ['-ss', "%.03f" % (starttime - offset),
                    '-i', self.filename,
                    '-ss', "%.03f" % offset]
        else:
            i_arg = [ '-i', self.filename]
        
        
        cmd = ([FFMPEG_BINARY]+ i_arg +
                ['-loglevel', 'error', 
                '-f', 'image2pipe',
                "-pix_fmt", self.pix_fmt,
                '-vcodec', 'rawvideo', '-'])
        
        
        self.proc = sp.Popen(cmd, bufsize= self.bufsize,
                                   stdout=sp.PIPE,
                                   stderr=sp.PIPE)





    def skip_frames(self, n=1):
        """Reads and throws away n frames """
        w, h = self.size
        for i in range(n):
            self.proc.stdout.read(self.depth*w*h)
            self.proc.stdout.flush()
        self.pos += n


    def read_frame(self):
        w, h = self.size
        nbytes= self.depth*w*h
        try:
            # Normally, the reader should not read after the last frame.
            # if it does, raise an error.
            s = self.proc.stdout.read(nbytes)
            assert len(s) == nbytes
            result = np.fromstring(s,
                             dtype='uint8').reshape((h, w, len(s)//(w*h)))
            #self.proc.stdout.flush()
            
        except IOError as err:
            
            self.proc.terminate()
            serr = self.proc.stderr.read()
            print( "stderr: %s" %serr)
            raise err

        self.lastread = result

        return result

    def get_frame(self, t):
        """ Read a file video frame at time t.
        
        Note for coders: getting an arbitrary frame in the video with
        ffmpeg can be painfully slow if some decoding has to be done.
        This function tries to avoid fectching arbitrary frames whenever
        possible, by moving between adjacent frames.
            """
        if t < 0:
            t = 0
        elif t > self.duration:
            t = self.duration
        

        # these definitely need to be rechecked sometime. Seems to work.
        pos = int(np.round(self.fps*t))+1
        if pos > self.nframes+1:
            raise ValueError("Video file %s has only %d frames but frame"
                              " #%d asked"%(self.filename, self.nframes, pos))
        

        
        if pos == self.pos:
            return self.lastread
        else:
            if(pos < self.pos) or (pos > self.pos+100):
                self.initialize(t)
            else:
                self.skip_frames(pos-self.pos-1)
            result = self.read_frame()
            self.pos = pos
            return result
    
    def close(self):
        if self.proc is not None:
            self.proc.terminate()
            self.proc.stdout.close()
            self.proc.stderr.close()
            del self.proc
    
    def __del__(self):
        self.close()
        del self.lastread
    


def ffmpeg_read_image(filename, with_mask=True):
    """ Read one image from a file.
    
    Wraps FFMPEG_Videoreader to read just one image. Returns an
    ImageClip.
    
    Parameters
    -----------
    
    filename
      Name of the image file. Can be of any format supported by ffmpeg.
    
    with_mask
      If the image has a transparency layer, ``with_mask=true`` will save
      this layer as the mask of the returned ImageClip
    
    """
    if with_mask:
        pix_fmt = 'rgba'
    else:
        pix_fmt = "rgb24"
    reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt)
    im = reader.lastread
    del reader
    return im

def ffmpeg_parse_infos(filename, print_infos=False):
    """Get file infos using ffmpeg.

    Returns a dictionnary with the fields:
    "video_found", "video_fps", "duration", "video_nframes",
    "video_duration"
    "audio_found", "audio_fps"

    "video_duration" is slightly smaller than "duration" to avoid
    fetching the uncomplete frames at the end, which raises an error.

    """
    

    # open the file in a pipe, provoke an error, read output
    proc = sp.Popen([FFMPEG_BINARY, "-i", filename, "-"],
            bufsize=10**6,
            stdout=sp.PIPE,
            stderr=sp.PIPE)

    proc.stdout.readline()
    proc.terminate()
    infos = proc.stderr.read().decode('utf8')
    if print_infos:
        # print the whole info text returned by FFMPEG
        print( infos )


    lines = infos.splitlines()
    if "No such file or directory" in lines[-1]:
        raise IOError("%s not found ! Wrong path ?"%filename)
    
    result = dict()
    

    # get duration (in seconds)
    line = [l for l in lines if 'Duration: ' in l][0]
    match = re.search(" [0-9][0-9]:[0-9][0-9]:[0-9][0-9].[0-9][0-9]", line)
    hms = map(float, line[match.start()+1:match.end()].split(':'))
    result['duration'] = cvsecs(*hms)

    # get the output line that speaks about video
    lines_video = [l for l in lines if ' Video: ' in l]
    
    result['video_found'] = lines_video != []
    
    if result['video_found']:
        
        line = lines_video[0]

        # get the size, of the form 460x320 (w x h)
        match = re.search(" [0-9]*x[0-9]*(,| )", line)
        s = list(map(int, line[match.start():match.end()-1].split('x')))
        result['video_size'] = s


        # get the frame rate
        try:
            match = re.search("( [0-9]*.| )[0-9]* tbr", line)
            result['video_fps'] = float(line[match.start():match.end()].split(' ')[1])
        except:
            match = re.search("( [0-9]*.| )[0-9]* fps", line)
            result['video_fps'] = float(line[match.start():match.end()].split(' ')[1])

        result['video_nframes'] = int(result['duration']*result['video_fps'])
        result['video_duration'] = result['video_nframes'] / result['video_fps']
    
    lines_audio = [l for l in lines if ' Audio: ' in l]
    
    result['audio_found'] = lines_audio != []
    
    if result['audio_found']:
        line = lines_audio[0]
        try:
            match = re.search(" [0-9]* Hz", line)
            result['audio_fps'] = int(line[match.start()+1:match.end()])
        except:
            result['audio_fps'] = 'unknown'

    return result

########NEW FILE########
__FILENAME__ = ffmpeg_tools
""" Misc. bindings to ffmpeg and ImageMagick."""

import os
import sys
import subprocess as sp

from moviepy.tools import subprocess_call
    

def ffmpeg_movie_from_frames(filename, folder, fps, digits=6):
    """
    Writes a movie out of the frames (picture files) in a folder.
    Almost deprecated.
    """
    s = "%" + "%02d" % digits + "d.png"
    cmd = ["ffmpeg", "-y", "-f","image2",
             "-r", "%d"%fps,
             "-i", os.path.join(folder,folder) + '/' + s,
             "-b", "%dk"%bitrate,
             "-r", "%d"%self.fps,
             filename]
    
    subprocess_call(cmd)


def ffmpeg_extract_subclip(filename, t1, t2, targetname=None):
    """ makes a new video file playing video file ``filename`` between
        the times ``t1`` and ``t2``. """
    name,ext = os.path.splitext(filename)
    if not targetname:
        T1, T2 = [int(1000*t) for t in [t1, t2]]
        targetname = name+ "%sSUB%d_%d.%s"(name, T1, T2, ext)
    
    cmd = ["ffmpeg","-y",
      "-i", filename,
      "-ss", "%0.2f"%t1,
      "-t", "%0.2f"%(t2-t1),
      "-vcodec", "copy", "-acodec", "copy", targetname]
    
    subprocess_call(cmd)


def ffmpeg_merge_video_audio(video,audio,output, vcodec='copy',
                             acodec='copy', ffmpeg_output=False,
                             verbose = True):
    """ merges video file ``video`` and audio file ``audio`` into one
        movie file ``output``. """
    cmd = ["ffmpeg", "-y", "-i", audio,"-i", video,
             "-vcodec", vcodec, "-acodec", acodec, output]
             
    subprocess_call(cmd, verbose = verbose)
    

def ffmpeg_extract_audio(inputfile,output,bitrate=3000,fps=44100):
    """ extract the sound from a video file and save it in ``output`` """
    cmd = ["ffmpeg", "-y", "-i", inputfile, "-ab", "%dk"%bitrate,
         "-ar", "%d"%fps, output]
    subprocess_call(cmd)
    

def ffmpeg_resize(video,output,size):
    """ resizes ``video`` to new size ``size`` and write the result
        in file ``output``. """
    cmd= ["ffmpeg", "-i", video, "-vf", "scale=%d:%d"%(res[0], res[1]),
             output]
             
    subprocess_call(cmd)


########NEW FILE########
__FILENAME__ = ffmpeg_writer
"""
On the long term this will implement several methods to make videos
out of VideoClips
"""

import sys
import numpy as np
import subprocess as sp

try:
    from subprocess import DEVNULL # py3k
except ImportError:
    import os
    DEVNULL = open(os.devnull, 'wb')



from tqdm import tqdm

from moviepy.conf import FFMPEG_BINARY
from moviepy.tools import sys_write_flush




class FFMPEG_VideoWriter:
    """ A class for FFMPEG-based video writing.
    
    A class to write videos using ffmpeg. ffmpeg will write in a large
    choice of formats.
    
    Parameters
    -----------
    
    filename
      Any filename like 'video.mp4' etc. but if you want to avoid
      complications it is recommended to use the generic extension
      '.avi' for all your videos.
    
    size
      Size (width,height) of the output video in pixels.
      
    fps
      Frames per second in the output video file.
      
    codec
      FFMPEG codec. It seems that in terms of quality the hierarchy is
      'rawvideo' = 'png' > 'mpeg4' > 'libx264'
      'png' manages the same lossless quality as 'rawvideo' but yields
      smaller files. Type ``ffmpeg -codecs`` in a terminal to get a list
      of accepted codecs.

      Note for default 'libx264': by default the pixel format yuv420p
      is used. If the video dimensions are not both even (e.g. 720x405)
      another pixel format is used, and this can cause problem in some
      video readers.

    bitrate
      Only relevant for codecs which accept a bitrate. "5000k" offers
      nice results in general.
    
    withmask
      Boolean. Set to ``True`` if there is a mask in the video to be
      encoded.
      
    """
    
    
        
    def __init__(self, filename, size, fps, codec="libx264",
                  bitrate=None, withmask=False, logfile=None):

        if logfile is None:
          logfile = DEVNULL

        self.filename = filename

        cmd = (
            [ FFMPEG_BINARY, '-y',
            "-loglevel", "panic" if logfile==DEVNULL else "info",
            "-f", 'rawvideo',
            "-vcodec","rawvideo",
            '-s', "%dx%d"%(size[0],size[1]),
            '-pix_fmt', "rgba" if withmask else "rgb24",
            '-r', "%.02f"%fps,
            '-i', '-', '-an',
            '-vcodec', codec]
            + (['-b',bitrate] if (bitrate!=None) else [])

            # http://trac.ffmpeg.org/ticket/658
            + (['-pix_fmt', 'yuv420p']
                  if ((codec == 'libx264') and
                     (size[0]%2 == 0) and
                     (size[1]%2 == 0))
                     
               else [])

            + [ '-r', "%d"%fps, filename ]
            )

        self.proc = sp.Popen(cmd, stdin=sp.PIPE,
                                  stderr=logfile,
                                  stdout=DEVNULL)

        
    def write_frame(self,img_array):
        """ Writes 1 frame in the file ! """
        self.proc.stdin.write(img_array.tostring())
        #self.proc.stdin.flush()
        
    def close(self):
        self.proc.stdin.close()
        #self.proc.stdout.close()
        #self.proc.stderr.close()
        self.proc.wait()
        
        del self.proc
        
def ffmpeg_write_video(clip, filename, fps, codec="libx264", bitrate=None,
                  withmask=False, write_logfile=False, verbose=True):
    
    def verbose_print(s):
        if verbose: sys_write_flush(s)
    
    if write_logfile:
        logfile = open(filename + ".log", 'w+')
    else:
        logfile = DEVNULL


    verbose_print("\nWriting video into %s\n"%filename)
    writer = FFMPEG_VideoWriter(filename, clip.size, fps, codec = codec,
             bitrate=bitrate, logfile=logfile)
             
    nframes = int(clip.duration*fps)
    
    for i in tqdm(range(nframes)):
        frame = clip.get_frame(1.0*i/fps)
        if withmask:
            mask = (255*clip.mask.get_frame(1.0*i/fps))
            frame = np.dstack([frame,mask])
            
        writer.write_frame(frame.astype("uint8"))
    
    writer.close()

    if write_logfile:
      logfile.close()
    
    verbose_print("Done writing video in %s !"%filename)
        
        
def ffmpeg_write_image(filename, image, logfile=False):
    """ Writes an image (HxWx3 or HxWx4 numpy array) to a file, using
        ffmpeg. """


    cmd = [ FFMPEG_BINARY, '-y',
           '-s', "%dx%d"%(image.shape[:2][::-1]),
           "-f", 'rawvideo',
           '-pix_fmt', "rgba" if (image.shape[2] == 4) else "rgb24",
           '-i','-', filename]
    
    if logfile: 
        log_file = open(filename + ".log", 'w+')
    else:
        log_file = DEVNULL


    proc = sp.Popen( cmd, stdin=sp.PIPE, stderr=log_file)
    proc.communicate(image.tostring()) # proc.wait()
    
    if proc.returncode:
        err = "\n".join(["MoviePy running : %s"%cmd,
                          "WARNING: this command returned an error:",
                          proc.stderr.read().decode('utf8')])
        raise IOError(err)


    
    del proc

########NEW FILE########
__FILENAME__ = imageMagick_tools
import os
import subprocess
from moviepy.tools import subprocess_call

def gif_to_directory(gif_file,dirName=None):
    """
    Stores all the frames of the given .gif file
    into the directory ``dirName``. If ``dirName``
    is not provided, the directory has the same name
    as the .gif file. Supports transparency.
    Returns the directory name.

    Example:

    >>> d = gif_to_directory("animated-earth.gif")
    >>> clip = DirectoryClip(d,fps=3)

    """

    if dirName is None:
        name, ext = os.path.splitext(gif_file)
        dirName = name

    try:
        os.mkdir(dirName)
    except:
        pass

    subprocess_call(["convert", "-coalesce", gif_file,
             os.path.join(dirName,"%04d.png")])

########NEW FILE########
__FILENAME__ = ImageSequenceClip
from ..VideoClip import VideoClip
from .ffmpeg_reader import ffmpeg_read_image
import os

class ImageSequenceClip(VideoClip):
    """
    
    A VideoClip made from a series of images.
    

    Parameters
    -----------

    sequence
      Can be one of these:
      - The name of a folder (containing only pictures). The pictures
        will be considered in alphanumerical order.
      - A list of names of image files.
      - A list of Numpy arrays representing images. In this last case,
        masks are not supported currently.


    fps
      Number of picture frames to read per second.

    with_mask
      Should the alpha layer of PNG images be considered as a mask ?

    ismask
      Will this sequence of pictures be used as an animated mask.

    
    """


    def __init__(self, sequence, fps, with_mask=True, ismask=False):

        # CODE WRITTEN AS IT CAME, MAY BE IMPROVED IN THE FUTURE

        VideoClip.__init__(self, ismask=ismask)

        # Parse the data

        fromfiles = True

        if isinstance(sequence, list):
            if not isinstance(sequence[0], str):
                # sequence is a list of numpy arrays
                fromfiles = False
        else:
            # sequence is a folder name
            sequence = sorted([os.path.join(sequence, f)
                        for f in os.listdir(sequence)])

        self.fps = fps
        self.duration = 1.0* len(sequence) / self.fps
        self.end = self.duration
        self.sequence = sequence

        if fromfiles:

            self.lastpos = None
            self.lastimage = None

            def get_frame(t):
            
                pos = int(self.fps*t)
                if pos != self.lastpos:
                    self.lastimage = ffmpeg_read_image(
                                           self.sequence[pos], 
                                           with_mask=False)
                    self.lastpos = pos
                
                return self.lastimage

            if with_mask and (get_frame(0).shape[2]==4):

                self.mask = VideoClip(ismask=True)

                def mask_get_frame(t):
            
                    pos = int(self.fps*t)
                    if pos != self.lastpos:
                        self.mask.lastimage = ffmpeg_read_image(
                                                self.sequence[pos], 
                                                with_mask=True)[:,:,3]
                    self.mask.lastpos = pos

                    return self.mask.lastimage

                self.mask.get_frame = mask_get_frame
                self.mask.size = mask_get_frame(0).shape[:2][::-1]


        else:

            def get_frame(t):
            
                pos = int(self.fps*t)
                return self.sequence[pos]
        
            
        self.get_frame = get_frame
        self.size = get_frame(0).shape[:2][::-1]

########NEW FILE########
__FILENAME__ = preview
from moviepy.decorators import requires_duration
import threading
import time
import pygame as pg
import numpy as np


pg.init()
pg.display.set_caption('MoviePy')

def imdisplay(imarray, screen=None):
    """Splashes the given image array on the given pygame screen """
    a = pg.surfarray.make_surface(imarray.swapaxes(0, 1))
    if screen == None:
        screen = pg.display.set_mode(imarray.shape[:2][::-1])
    screen.blit(a, (0, 0))
    pg.display.flip()


def show(clip, t=0, with_mask=True):
    """
    Splashes the frame of clip corresponding to time ``t``.
    
    Parameters
    ------------
    
    t
      Time in seconds of the frame to display.
    
    with_mask
      ``False`` if the clip has a mask but you want to see the clip
      without the mask.
    
    """

    if clip.ismask:
        clip = clip.to_RGB()
    if with_mask and (clip.mask != None):
        import moviepy.video.compositing.CompositeVideoClip as cvc
        clip = cvc.CompositeVideoClip([clip.set_pos((0,0))])
    imdisplay(clip.get_frame(t))


@requires_duration
def preview(clip, fps=15, audio=True, audio_fps=22050,
             audio_buffersize=3000, audio_nbytes=2):
    """ 
    Displays the clip in a window, at the given frames per second
    (of movie) rate. It will avoid that the clip be played faster
    than normal, but it cannot avoid the clip to be played slower
    than normal if the computations are complex. In this case, try
    reducing the ``fps``.
    
    Parameters
    ------------
    
    fps
      Number of frames per seconds in the displayed video.
        
    audio
      ``True`` (default) if you want the clip's audio be played during
      the preview.
        
    audiofps
      The frames per second to use when generating the audio sound.
      
    """
    
    import pygame as pg
    
    if clip.ismask:
        clip = clip.to_RGB()
    
    # compute and splash the first image
    screen = pg.display.set_mode(clip.size)
    
    audio = audio and (clip.audio != None)
    
    if audio:
        # the sound will be played in parrallel. We are not
        # parralellizing it on different CPUs because it seems that
        # pygame and openCV already use several cpus it seems.
        
        # two synchro-flags to tell whether audio and video are ready
        videoFlag = threading.Event()
        audioFlag = threading.Event()
        # launch the thread
        audiothread = threading.Thread(target=clip.audio.preview,
            args = (audio_fps,audio_buffersize, audio_nbytes,
                    audioFlag, videoFlag))
        audiothread.start()
    
    img = clip.get_frame(0)
    imdisplay(img, screen)
    if audio: # synchronize with audio
        videoFlag.set() # say to the audio: video is ready
        audioFlag.wait() # wait for the audio to be ready
    
    result = []
    
    t0 = time.time()
    for t in np.arange(1.0 / fps, clip.duration, 1.0 / fps):
        
        img = clip.get_frame(t)
        
        for event in pg.event.get():
            if event.type == pg.KEYDOWN:
                if (event.key == pg.K_ESCAPE):
                    
                    if audio:
                        videoFlag.clear()
                    print( "Keyboard interrupt" )
                    return result
                    
            elif event.type == pg.MOUSEBUTTONDOWN:
                x,y = pg.mouse.get_pos()
                rgb = img[y,x]
                result.append({'time':t, 'position':(x,y),
                                'color':rgb})
                print( "time, position, color : ", "%.03f, %s, %s"%(
                             t,str((x,y)),str(rgb)))
                    
        t1 = time.time()
        time.sleep(max(0, t - (t1-t0)) )
        imdisplay(img, screen)

def image_preview(clip):
    
    clip.show()
    result=[]
    while True:
        for event in pg.event.get():
            if event.type == pg.KEYDOWN:
                if (event.key == pg.K_ESCAPE):
                    videoFlag.clear()
                    print( "Keyboard interrupt" )
                    return result
            elif event.type == pg.MOUSEBUTTONDOWN:
                 x,y = pg.mouse.get_pos()
                 rgb = img[y,x]
                 result.append({'time':t, 'position':(x,y),
                            'color':rgb})
                 print( "time, position, color : ", "%.03f, %s, %s"%(
                         t,str((x,y)),str(rgb)))
    return result
    

########NEW FILE########
__FILENAME__ = sliders
import matplotlib.pyplot as plt
from matplotlib.widgets import Slider, Button

def sliders(f, sliders_properties, wait_for_validation = False):
    """ A light GUI to manually explore and tune the outputs of 
        a function.
        slider_properties is a list of dicts (arguments for Slider )
        
        def volume(x,y,z):
            return x*y*z
    
        intervals = [ { 'label' :  'width',  'valmin': 1 , 'valmax': 5 },
                  { 'label' :  'height',  'valmin': 1 , 'valmax': 5 },
                  { 'label' :  'depth',  'valmin': 1 , 'valmax': 5 } ]
        inputExplorer(volume,intervals)
    """
        
    nVars = len(sliders_properties)
    slider_width = 1.0/nVars
    
    # CREATE THE CANVAS
    
    figure,ax = plt.subplots(1)
    figure.canvas.set_window_title( "Inputs for '%s'"%(f.func_name) )
    
    # choose an appropriate height
    
    width,height = figure.get_size_inches()
    height = min(0.5*nVars,8)
    figure.set_size_inches(width,height,forward = True)
    
    
    # hide the axis
    ax.set_frame_on(False)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    

    # CREATE THE SLIDERS
    
    sliders = []
    
    for i, properties in enumerate(sliders_properties):
        
        ax = plt.axes([0.1 , 0.95-0.9*(i+1)*slider_width,
                       0.8 , 0.8* slider_width])
        if not isinstance(properties,dict):
            properties =dict(zip(['label','valmin', 'valmax', 'valinit'],
                             properties))
        sliders.append( Slider(ax=ax, **properties) )
    
    
    # CREATE THE CALLBACK FUNCTIONS
    
    def on_changed(event) : 
        
        res = f(*(s.val for s in sliders))
        
        if res is not None:
            
            print( res )
    
    def on_key_press(event):
        
        if event.key is 'enter':
            
            on_changed(event)   
    
    figure.canvas.mpl_connect('key_press_event', on_key_press)
    
    # AUTOMATIC UPDATE ?
    
    if not wait_for_validation:
        
        for s in sliders :
            
            s.on_changed(on_changed)
    
    
    # DISPLAY THE SLIDERS
    
    plt.show()

########NEW FILE########
__FILENAME__ = VideoFileClip
import os

from moviepy.video.VideoClip import VideoClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.Clip import Clip
from moviepy.video.io.ffmpeg_reader import FFMPEG_VideoReader

class VideoFileClip(VideoClip):

    """
    
    A video clip originating from a movie file. For instance: ::
    
        >>> clip = VideofileClip("myHolidays.mp4")
        >>> clip2 = VideofileClip("myMaskVideo.avi",ismask = True)
    
    
    Parameters
    ------------
    
    filename:
      The name of the video file. It can have any extension supported
      by ffmpeg: .ogv, .mp4, .mpeg, .avi, .mov etc.
    
    ismask:
      Set this to `True` if the clip is going to be used as a mask.
      
    has_mask:
      Set this to 'True' if there is a mask included in the videofile.
      Video files rarely contain masks, but some video codecs enable
      that. For istance if you have a MoviePy VideoClip with a mask you
      can save it to a videofile with a mask. (see also 
      ``VideoClip.to_videofile`` for more details).
    
    audio:
      Set to `False` if the clip doesn't have any audio or if you do not
      wish to read the audio.
      
    Attributes
    -----------
    
    filename:
      Name of the original video file.
    
    fps:
      Frames per second in the original file. 
        
    """

    def __init__(self, filename, ismask=False, has_mask=False,
                 audio=True, audio_buffersize = 200000,
                 audio_fps=44100, audio_nbytes=2, verbose=False):
        
        VideoClip.__init__(self, ismask)
        
        # Make a reader
        pix_fmt= "rgba" if has_mask else "rgb24"
        self.reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt)
        
        # Make some of the reader's attributes accessible from the clip
        self.duration = self.reader.duration
        self.end = self.reader.duration
        
        self.fps = self.reader.fps
        self.size = self.reader.size
        self.get_frame = lambda t: self.reader.get_frame(t)
        
        # Make a reader for the audio, if any.
        if audio and self.reader.infos['audio_found']:
            self.audio = AudioFileClip(filename,
                                       buffersize= audio_buffersize,
                                       fps = audio_fps,
                                       nbytes = audio_nbytes)

########NEW FILE########
__FILENAME__ = credits
"""
This module contains different fonctions to make end and opening
credits, even though it is difficult to fill everyone needs in this
matter.
"""

from moviepy.video.VideoClip import TextClip, ImageClip
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
from moviepy.video.fx import resize

def credits1(creditfile,width,stretch=30,color='white',
                 stroke_color='black', stroke_width=2,
                 font='Impact-Normal',fontsize=60):
    """
    
    
    Parameters
    -----------
    
    creditfile
      A text file whose content must be as follows: ::
        
        # This is a comment
        # The next line says : leave 4 blank lines
        .blank 4
        
        ..Executive Story Editor
        MARCEL DURAND
        
        ..Associate Producers
        MARTIN MARCEL
        DIDIER MARTIN
        
        ..Music Supervisor
        JEAN DIDIER
    
    width
      Total width of the credits text in pixels
      
    gap
      Gap in pixels between the jobs and the names.
    
    **txt_kw
      Additional argument passed to TextClip (font, colors, etc.)
    
    
    
        
    Returns
    ---------
    
    image
       An ImageClip instance that looks like this and can be scrolled
       to make some credits :
        
        Executive Story Editor    MARCEL DURAND
           Associate Producers    MARTIN MARCEL
                                  DIDIER MARTIN
              Music Supervisor    JEAN DIDIER
              
    """
    
    
    # PARSE THE TXT FILE
    
    with open(creditfile) as f:
        lines = f.readlines()
    
    lines = filter(lambda x:not x.startswith('\n'),lines) 
    texts = []
    oneline=True
    for l in  lines:
        if not l.startswith('#'):
            if l.startswith('.blank'):
                for i in range(int(l.split(' ')[1])):
                    texts.append(['\n','\n'])
            elif  l.startswith('..'):
                texts.append([l[2:],''])
                oneline=True
            else:
                if oneline:
                    texts.append(['',l])
                    oneline=False
                else:
                    texts.append(['\n',l])
               
    left,right = [ "".join(l) for l in zip(*texts)]
    
    # MAKE TWO COLUMNS FOR THE CREDITS
    
    left,right =  [TextClip(txt,color=color,stroke_color=stroke_color,
                                stroke_width=stroke_width,font=font,
                                fontsize=fontsize,align=al)
               for txt,al in [(left,'East'),(right,'West')]]
               

    cc = CompositeVideoClip( [left, right.set_pos((left.w+gap,0))],
                             size = (left.w+right.w+gap,right.h),
                             transparent=True)
    
    # SCALE TO THE REQUIRED SIZE
    
    scaled = cc.fx(resize , width=width)
    
    # TRANSFORM THE WHOLE CREDIT CLIP INTO AN ImageCLip
    
    imclip = ImageClip(scaled.get_frame(0))
    amask = ImageClip(scaled.mask.get_frame(0),ismask=True)
    
    return imclip.set_mask(amask)

########NEW FILE########
__FILENAME__ = drawing
"""
This module deals with making images (np arrays). It provides drawing
methods that are difficult to do with the existing Python libraries.
"""

import numpy as np

def blit(im1, im2, pos=[0, 0], mask=None, ismask=False):
    """ Blit an image over another.
    
    Blits ``im1`` on ``im2`` as position ``pos=(x,y)``, using the
    ``mask`` if provided. If ``im1`` and ``im2`` are mask pictures
    (2D float arrays) then ``ismask`` must be ``True``.
    """

    # xp1,yp1,xp2,yp2 = blit area on im2
    # x1,y1,x2,y2 = area of im1 to blit on im2
    xp, yp = pos
    x1 = max(0, -xp)
    y1 = max(0, -yp)
    h1, w1 = im1.shape[:2]
    h2, w2 = im2.shape[:2]
    xp2 = min(w2, xp + w1)
    yp2 = min(h2, yp + h1)
    x2 = min(w1, w2 - xp)
    y2 = min(h1, h2 - yp)
    xp1 = max(0, xp)
    yp1 = max(0, yp)

    if (xp1 >= xp2) or (yp1 >= yp2):
        return im2

    blitted = im1[y1:y2, x1:x2]

    new_im2 = +im2

    if mask != None:
        mask = mask[y1:y2, x1:x2]
        if len(im1.shape) == 3:
            mask = np.dstack(3 * [mask])
        blit_region = new_im2[yp1:yp2, xp1:xp2]
        new_im2[yp1:yp2, xp1:xp2] = (
            1.0 * mask * blitted + (1.0 - mask) * blit_region)
    else:
        new_im2[yp1:yp2, xp1:xp2] = blitted

    return new_im2.astype('uint8') if (not ismask) else new_im2



def color_gradient(size,p1,p2=None,vector=None, r=None, col1=0,col2=1.0,
              shape='linear', offset = 0):
    """Draw a linear, bilinear, or radial gradient.
    
    The result is a picture of size ``size``, whose color varies
    gradually from color `col1` in position ``p1`` to color ``col2``
    in position ``p2``.
    
    If it is a RGB picture the result must be transformed into
    a 'uint8' array to be displayed normally:
     
     
    Parameters
    ------------      
    
    size
      Size (width, height) in pixels of the final picture/array.
    
    p1, p2
      Coordinates (x,y) in pixels of the limit point for ``col1``
      and ``col2``. The color 'before' ``p1`` is ``col1`` and it
      gradually changes in the direction of ``p2`` until it is ``col2``
      when it reaches ``p2``.
    
    vector
      A vector [x,y] in pixels that can be provided instead of ``p2``.
      ``p2`` is then defined as (p1 + vector).
    
    col1, col2
      Either floats between 0 and 1 (for gradients used in masks)
      or [R,G,B] arrays (for colored gradients).
               
    shape
      'linear', 'bilinear', or 'circular'.
      In a linear gradient the color varies in one direction,
      from point ``p1`` to point ``p2``.
      In a bilinear gradient it also varies symetrically form ``p1``
      in the other direction.
      In a circular gradient it goes from ``col1`` to ``col2`` in all
      directions.
    
    offset
      Real number between 0 and 1 indicating the fraction of the vector
      at which the gradient actually starts. For instance if ``offset``
      is 0.9 in a gradient going from p1 to p2, then the gradient will
      only occur near p2 (before that everything is of color ``col1``)
      If the offset is 0.9 in a radial gradient, the gradient will
      occur in the region located between 90% and 100% of the radius,
      this creates a blurry disc of radius d(p1,p2).  
    
    Returns
    --------
    
    image
      An Numpy array of dimensions (W,H,ncolors) of type float
      representing the image of the gradient.
      
    
    Examples
    ---------
    
    >>> grad = colorGradient(blabla).astype('unit8')
    
    """
    
    # np-arrayize and change x,y coordinates to y,x
    w,h = size
    
    col1, col2 = map(lambda x : np.array(x).astype(float), [col1, col2])
    
    if shape == 'bilinear':
        if vector is None:
            vector = np.array(p2) - np.array(p1)
        m1,m2 = [ colorGradient(size, p1, vector=v, col1 = 1.0, col2 = 0,
                           shape = 'linear', offset= offset)
                  for v in [vector,-vector]]
                  
        arr = np.maximum(m1,m2)
        if col1.size > 1:
            arr = np.dstack(3*[arr])
        return arr*col1 + (1-arr)*col2
        
    
    p1 = np.array(p1[::-1]).astype(float)
    
    if vector is None:
        if p2 != None:
            p2 = np.array(p2[::-1])
            vector = p2-p1
    else:
        vector = np.array(vector[::-1])
        p2 = p1 + vector
    
    if vector != None:    
        norm = np.linalg.norm(vector)
    
    M = np.dstack(np.meshgrid(range(w),range(h))[::-1]).astype(float)
    
    if shape == 'linear':
        
        n_vec = vector/norm**2 # norm 1/norm(vector)
        
        p1 = p1 + offset*vector
        arr = (M- p1).dot(n_vec)/(1-offset)
        arr = np.minimum(1,np.maximum(0,arr))
        if col1.size > 1:
            arr = np.dstack(3*[arr])
        return arr*col1 + (1-arr)*col2
    
    elif shape == 'radial':
        if r is None:
            r = norm
        if r==0:
            arr = np.ones((h,w))
        else:
            arr = (np.sqrt(((M- p1)**2).sum(axis=2)))-offset*r
            arr = arr / ((1-offset)*r)
            arr = np.minimum(1.0,np.maximum(0, arr) )
            
        if col1.size > 1:
            arr = np.dstack(3*[arr])
        return (1-arr)*col1 + arr*col2
        

def color_split(size,x=None,y=None,p1=None,p2=None,vector=None,
               col1=0,col2=1.0, grad_width=0):
    """Make an image splitted in 2 colored regions.
    
    Returns an array of size ``size`` divided in two regions called 1 and
    2 in wht follows, and which will have colors col& and col2
    respectively.
    
    Parameters
    -----------
    
    x: (int)
      If provided, the image is splitted horizontally in x, the left
      region being region 1.
        
    y: (int)
      If provided, the image is splitted vertically in y, the top region
      being region 1.
    
    p1,p2:
      Positions (x1,y1),(x2,y2) in pixels, where the numbers can be
      floats. Region 1 is defined as the whole region on the left when
      going from ``p1`` to ``p2``.
    
    p1, vector:
      ``p1`` is (x1,y1) and vector (v1,v2), where the numbers can be
      floats. Region 1 is then the region on the left when starting
      in position ``p1`` and going in the direction given by ``vector``.
       
    gradient_width
      If not zero, the split is not sharp, but gradual over a region of
      width ``gradient_width`` (in pixels). This is preferable in many
      situations (for instance for antialiasing). 
     
    
    Examples
    ---------
    
    >>> size = [200,200]
    >>> # an image with all pixels with x<50 =0, the others =1
    >>> colorSplit(size, x=50, col1=0, col2=1)
    >>> # an image with all pixels with y<50 red, the others green
    >>> colorSplit(size, x=50, col1=[255,0,0], col2=[0,255,0])
    >>> # An image splitted along an arbitrary line (see below) 
    >>> colorSplit(size, p1=[20,50], p2=[25,70] col1=0, col2=1)
        
    """
    
    if grad_width or ( (x is None) and (y is None)):
        if p2 != None:
            vector = (np.array(p2) - np.array(p1))
        x,y = vector
        vector = np.array([y,-x]).astype('float')
        norm = np.linalg.norm(vector)
        vector =  max(0.1,grad_width)*vector/norm
        return color_gradient(size,p1,vector=vector,
                         col1 = col1, col2 = col2, shape='linear')
    else:
        
        w,h = size
        shape = (h, w) if np.isscalar(col1) else (h, w, len(col1))
        arr = np.zeros(shape)
        if x:
            arr[:,:x] = col1
            arr[:,x:] = col2
        elif y:
            arr[:y] = col1
            arr[y:] = col2
            
        return arr
     
    # if we are here, it means we didn't exit with a proper 'return'
    print( "Arguments in color_split not understood !" )
    raise
    
def circle(screensize, center, radius, col1=1.0, col2=0, blur=1):
    """ Draw an image with a circle.
    
    Draws a circle of color ``col1``, on a background of color ``col2``,
    on a screen of size ``screensize`` at the position ``center=(x,y)``,
    with a radius ``radius`` but slightly blurred on the border by ``blur``
    pixels
    """
    return color_gradient(screensize,p1=center,r=radius, col1=col1,
              col2=col2, shape='radial', offset = 0 if (radius==0) else
                                              1.0*(radius-blur)/radius)

########NEW FILE########
__FILENAME__ = segmenting
import numpy as np
import scipy.ndimage as ndi
from moviepy.video.VideoClip import ImageClip


def findObjects(clip,rem_thr=500, preview=False):
    """ 
    Returns a list of ImageClips representing each a separate object on
    the screen.
        
    rem_thr : all objects found with size < rem_Thr will be
         considered false positives and will be removed
    
    """
    
    image = clip.get_frame(0)
    if clip.mask == None:
        clip = clip.add_mask()
        
    mask = clip.mask.get_frame(0)
    labelled, num_features = ndi.measurements.label(image[:,:,0])
    
    #find the objects
    slices = ndi.find_objects(labelled)
    # cool trick to remove letter holes (in o,e,a, etc.)
    slices = [e for e in slices if  mask[e[0],e[1]].mean() >0.2]
    # remove very small slices
    slices = [e for e in slices if  image[e[0],e[1]].size > rem_thr]
    # Sort the slices from left to right
    islices = sorted(enumerate(slices), key = lambda s : s[1][1].start)
    
    letters = []
    for i,(ind,(sy,sx)) in enumerate(islices):
        """ crop each letter separately """
        sy = slice(sy.start-1,sy.stop+1)
        sx = slice(sx.start-1,sx.stop+1)
        letter = image[sy,sx]
        labletter = labelled[sy,sx]
        maskletter = (labletter==(ind+1))*mask[sy,sx]
        letter = ImageClip(image[sy,sx])
        letter.mask = ImageClip( maskletter,ismask=True)
        letter.screenpos = np.array((sx.start,sy.start))
        letters.append(letter)
    
    if preview:
        import matplotlib.pyplot as plt
        print( "found %d objects"%(num_features) )
        fig,ax = plt.subplots(2)
        ax[0].axis('off')
        ax[0].imshow(labelled)
        ax[1].imshow([range(num_features)],interpolation='nearest')
        ax[1].set_yticks([])
        plt.show()
    
    return letters

########NEW FILE########
__FILENAME__ = tracking
"""
This module contains different fonctions for tracking objects in videos,
manually or automatically. The tracking functions return results under
the form:  ``( txy, (fx,fy) )`` where txy is of the form [(ti, xi, yi)...]
and (fx(t),fy(t)) give the position of the track for all times t (if the
time t is out of the time bounds of the tracking time interval
fx and fy return the position of the object at the start or at the end
of the tracking time interval).
"""

from scipy.interpolate import interp1d

from moviepy.video.io.preview import imdisplay

try:
    import cv2
except:
    # Note: this will be later fixed with scipy/skimage replacements
    # but for the moment OpenCV is mandatory, so...
    print("WARNING: OpenCV not found: automated tracking not possible")



# WE START WITH A TOOL FUNCTION

def to_fxfy(txy_list, **kwargs):
    """ Transforms a list [ (ti, (xi,yi)) ] into 2 functions (fx,fy)
        where fx : t -> x(t)  and  fy : t -> y(t).
        If the time t is out of the bounds of the tracking time interval
        fx and fy return the position of the object at the start or at
        the end of the tracking time interval.
        Keywords can be passed to decide the kind of interpolation,
        see the doc of ``scipy.interpolate.interp1d``."""
        
    tt, xx, yy = zip(*txy_list)
    interp_x = interp1d(tt, xx, **kwargs)
    interp_y = interp1d(tt, yy, **kwargs)
    fx = lambda t: xx[0] if (t <= tt[0]) else ( xx[-1] if t >= tt[-1]
                                          else ( interp_x(t) ) )
    fy = lambda t: yy[0] if (t <= tt[0]) else ( yy[-1] if t >= tt[-1]
                                          else ( interp_y(t) ) )
    return fx,fy


# MANUAL TRACKING

def manual_tracking(clip, t1=None, t2=None, fps=5, nobjects = 1):
    """
    Allows manual tracking of an object(s) in the video clip between
    times `t1` and `t2`. This displays the clip frame by frame
    and you must click on the object(s) in each frame. If ``t2=None``
    only the frame at ``t1`` is taken into account.
    
    Returns a list [(t1,x1,y1),(t2,x2,y2) etc... ] if there is one
    object per frame, else returns a list whose elements are of the 
    form (ti, [(xi1,yi1), (xi2,yi2), ...] )
    
    :param t1,t2: times during which to track (defaults are start and
        end of the clip)
    :param fps: Number of frames per second to freeze on.
    :param nobjects: Number of objects to click on each frame
    

    
    >>> print myClip.manTrack(10, 13,fps=7)
    >>>
    >>> # To print 5 points coordinates at t=5 : 
    >>> for i in range(5):
    >>>     print myClip.manTrack(5)
    
    Tip: To avoid redoing the tracking each time you run your script,
    better save the result the first time and then load it at each run. 
    
    >>> # First time:
    >>> import pickle
    >>> txy = myClip.manTrack(20, 10,fps=10)
    >>> with open("chaplin_txy.dat",'w+') as f:
    >>>     pickle.dump(txy,f)
    >>>
    >>> # Next times:
    >>> import pickle
    >>> with open("chaplin_txy.dat",'r') as f:
    >>>     txy = pickle.load(txy,f)
    
    """
    
    import pygame as pg
    
    screen = pg.display.set_mode(clip.size)
    step = 1.0 / fps
    if (t1 is None) and (t2 is None):
        t1,t2 = 0, clip.duration
    elif (t2 is None):
        t2 = t1 + step / 2
    t = t1
    txy_list = []
    
    def gatherClicks(t):
        
        imdisplay(clip.get_frame(t), screen)
        objects_to_click = nobjects
        clicks = []
        while objects_to_click:

            for event in pg.event.get():

                if event.type == pg.KEYDOWN:
                    if (event.key == pg.K_BACKSLASH):
                        return "return"
                        

                elif event.type == pg.MOUSEBUTTONDOWN:
                    x, y = pg.mouse.get_pos()
                    clicks.append((x, y))
                    objects_to_click -= 1
                    
        return clicks if (len(clicks)>1) else clicks[0]
        
    while t < t2:
        
        clicks  =gatherClicks(t)
        if clicks == 'return':
            txy_list.pop()
            t -= step
        else:
            txy_list.append((t,clicks))
            t += step

    return txy_list, to_fxfy(txy_list)






# AUTOMATED TRACKING OF A PATTERN

def findAround(pic,pat,xy=None,r=None):
    """
    find image pattern ``pat`` in ``pic[x +/- r, y +/- r]``.
    if xy is none, consider the whole picture.
    """
    
    if xy and r:
        h,w = pat.shape[:2]
        x,y = xy
        pic = pic[y-r : y+h+r , x-r : x+w+r]
        
    matches = cv2.matchTemplate(pat,pic,cv2.TM_CCOEFF_NORMED)
    yf,xf = np.unravel_index(matches.argmax(),matches.shape)
    return (x-r+xf,y-r+yf) if (xy and r) else (xf,yf)
        
        
def autoTrack(clip, pattern, tt=None, fps=None, radius=20, xy0=None):
    """
    Tracks a given pattern (small image array) in a video clip.
    Returns [(x1,y1),(x2,y2)...] where xi,yi are
    the coordinates of the pattern in the clip on frame i.
    To select the frames you can either specify a list of times with ``tt``
    or select a frame rate with ``fps``.
    This algorithm assumes that the pattern's aspect does not vary much
    and that the distance between two occurences of the pattern in
    two consecutive frames is smaller than ``radius`` (if you set ``radius``
    to -1 the pattern will be searched in the whole screen at each frame).
    You can also provide the original position of the pattern with xy0.
    """
    if not xy0:
        xy0 = findAround(clip.get_frame(tt[0]),pattern)
    
    if tt is None:
        tt = np.arange(0, clip.duration, 1.0/fps)
        
    xys = [xy0]
    for t in tt[1:]:
        xys.append( findAround(clip.get_frame(t),pattern,
                               xy=xys[-1],r=radius))
    
    xx,yy = zip(*xys)
    txy_list = zip(tt,xx,yy)
    return txy_list, to_fxfy(txy_list)

########NEW FILE########
__FILENAME__ = VideoClip
"""
This module implements VideoClip (base class for video clips) and its
main subclasses:
- Animated clips:     VideofileClip, DirectoryClip
- Static image clips: ImageClip, ColorClip, TextClip,
"""

import os
import subprocess
import multiprocessing
import tempfile
from copy import copy
from tqdm import tqdm


import numpy as np

from moviepy.decorators import  (apply_to_mask,
                                 requires_duration,
                                 outplace,
                                 add_mask_if_none)
from moviepy.tools import subprocess_call, sys_write_flush

import moviepy.audio.io as aio
from .io.ffmpeg_writer import ffmpeg_write_image, ffmpeg_write_video
from .io.ffmpeg_reader import ffmpeg_read_image
from .io.ffmpeg_tools import ffmpeg_merge_video_audio

from .tools.drawing import blit
from ..Clip import Clip
from ..conf import FFMPEG_BINARY, IMAGEMAGICK_BINARY


class VideoClip(Clip):
    """Base class for video clips.

    See ``VideofileClip``, ``ImageClip`` etc. for more user-friendly
    classes.


    Parameters
    -----------

    ismask
      `True` if the clip is going to be used as a mask.


    Attributes
    ----------

    size
      The size of the clip, (width,heigth), in pixels.

    w, h
      The width and height of the clip, in pixels.

    ismask
      Boolean set to `True` if the clip is a mask.

    get_frame
      A function ``t-> frame at time t`` where ``frame`` is a
      w*h*3 RGB array.

    mask (default None)
      VideoClip mask attached to this clip. If mask is ``None``,
                The video clip is fully opaque.

    audio (default None)
      An AudioClip instance containing the audio of the video clip.

    pos
      A function ``t->(x,y)`` where ``x,y`` is the position
      of the clip when it is composed with other clips.
      See ``VideoClip.set_pos`` for more details

    relative_pos
      See variable ``pos``.

    """

    def __init__(self, ismask=False, get_frame=None):
        Clip.__init__(self)
        self.mask = None
        self.audio = None
        self.pos = lambda t: (0, 0)
        self.relative_pos = False
        if get_frame:
            self.get_frame = get_frame
            self.size =get_frame(0).shape[:2][::-1]
        self.ismask = ismask

    @property
    def w(self):
        return self.size[0]



    @property
    def h(self):
        return self.size[1]



    # ===============================================================
    # EXPORT OPERATIONS



    def save_frame(self, filename, t=0, savemask=False):
        """ Save a clip's frame to an image file.

        Saves the frame of clip corresponding to time ``t`` in
        'filename'. If ``savemask`` is ``True`` the mask is saved in
        the alpha layer of the picture.

        """
        im = self.get_frame(t)
        if savemask and self.mask is not None:
            mask = 255 * self.mask.get_frame(t)
            im = np.dstack([im, mask]).astype('uint8')
        ffmpeg_write_image(filename, im)



    def to_videofile(self, filename, fps=24, codec='libx264',
                 bitrate=None, audio=True, audio_fps=44100,
                 audio_nbytes = 4, audio_codec= 'libvorbis',
                 audio_bitrate = None, audio_bufsize = 2000,
                 temp_audiofile=None,
                 rewrite_audio = True, remove_temp = True,
                 write_logfile=False,
                 para = False, verbose = True):
        """Write the clip to a videofile.

        Parameters
        -----------

        filename
          Name of the video file. The extension must correspond to the
          codec used (see below), ar simply be '.avi'.

        fps
          Number of frames per second in the resulting video file.

        codec
          Codec to use for image encoding. Can be any codec supported
          by ffmpeg.

          ``'rawvideo'``, ``'png'`` will produce a raw video,
          of perfect quality, but possibly very huge size. 'png' is
          is lossless and produces smaller files than 'rawvideo'.

          ``'mpeg4'`` produces nice quality, very well compressed
          videos.

          ``'libx264'`` (default) is a little better than 'mpeg4',
          a little heavier.

        audio
          Either ``True``, ``False``, or a file name.
          If ``True`` and the clip has an audio clip attached, this
          audio clip will be incorporated as a soundtrack in the movie.
          If ``audio`` is the name of an audio file, this audio file
          will be incorporated as a soundtrack in the movie.

        audiofps
          frame rate to use when writing the sound.

        temp_audiofile
          the name of the temporary audiofile to be generated and
          incorporated in the the movie, if any.

        """

        name, ext = os.path.splitext(os.path.basename(filename))

        if audio_codec == 'raw16':
            audio_codec = 'pcm_s16le'
        elif audio_codec == 'raw32':
            audio_codec = 'pcm_s32le'

        def verbose_print(s):
            if verbose: sys_write_flush(s)

        if isinstance(audio, str):
            # audio is some audiofile it is maybe not a wav file. It is
            # NOT temporary file, it will NOT be removed at the end.
            temp_audiofile = audio
            make_audio = False
            merge_audio = True

        elif self.audio is None:
            # audio not provided as a file and no clip.audio
            make_audio = merge_audio =  False

        elif audio:
            # The audio will be the clip's audio
            if temp_audiofile is None:

                # make a name for the temporary audio file

                D_ext = {'libmp3lame': 'mp3',
                       'libvorbis':'ogg',
                       'libfdk_aac':'m4a',
                       'aac':'m4a',
                       'pcm_s16le':'wav',
                       'pcm_s32le': 'wav'}

                if audio_codec in D_ext.values():
                    audio_ext = audio_codec
                else:
                    if audio_codec in D_ext.keys():
                        audio_ext = D_ext[audio_codec]
                    else:
                        raise ValueError('audio_codec for file'
                                          '%d unkown !'%filename)

                temp_audiofile = (name+Clip._TEMP_FILES_PREFIX +
                            "to_videofile_SOUND.%s"%audio_ext)

            make_audio = ( (not os.path.exists(temp_audiofile))
                            or rewrite_audio)
            merge_audio = True

        else:

            make_audio = False
            merge_audio = False

        if merge_audio:

            # make a name for the temporary video file
            videofile = (name + Clip._TEMP_FILES_PREFIX +
                         "to_videofile%s"%ext)

        else:

            videofile = filename

        # enough cpu for multiprocessing ?
        enough_cpu = (multiprocessing.cpu_count() > 2)

        verbose_print("\nMoviePy: building video file %s\n"%filename
                      +40*"-"+"\n")

        if para and make_audio and  enough_cpu:

            # Parallelize
            verbose_print("Writing audio/video in parrallel.\n")
            audioproc = multiprocessing.Process(
                    target=self.audio.to_audiofile,
                    args=(temp_audiofile,audio_fps,audio_nbytes,
                          audio_bufsize,audio_codec,
                          audio_bitrate,
                          verbose))

            audioproc.start()
            
            ffmpeg_write_video(self, 
                               videofile, fps, codec,
                               bitrate=bitrate,
                               write_logfile=write_logfile,
                               verbose=verbose)
            audioproc.join()
            if audioproc.exitcode:
                print ("WARNING: something went wrong with the audio"+
                       " writing, Exit code %d"%audioproc.exitcode)
        else:

            # Don't parallelize
            if make_audio:
                self.audio.to_audiofile(temp_audiofile,audio_fps,
                                        audio_nbytes, audio_bufsize,
                                        audio_codec, audio_bitrate,
                                        verbose)

            ffmpeg_write_video(self,
                               videofile, fps, codec,
                               bitrate=bitrate,
                               write_logfile=write_logfile,
                               verbose=verbose)

        # Merge with audio if any and trash temporary files.
        if merge_audio:

            verbose_print("\n\nNow merging video and audio:\n")
            ffmpeg_merge_video_audio(videofile,temp_audiofile,
                                  filename, ffmpeg_output=True)

            if remove_temp:
                os.remove(videofile)
                if not isinstance(audio,str):
                    os.remove(temp_audiofile)
            verbose_print("\nYour video is ready ! Fingers crossed"
                          " for the Oscars !\n")


    def to_images_sequence(self, nameformat, fps=None, verbose=True):
        """ Writes the videoclip to a sequence of image files.


        Parameters
        -----------

        nameformat
          A filename specifying the numerotation format and extension
          of the pictures. For instance "frame%03d.png" for filenames
          indexed with 3 digits and PNG format. Also possible:
          "some_folder/frame%04d.jpeg", etc.

        fps
          Number of frames per second to consider when writing the
          clip. If not specified, the clip's ``fps`` attribute will
          be used if it has one.

        verbose
          Verbose output ?


        Returns
        --------

        names_list
          A list of all the files generated.

        Notes
        ------

        The resulting image sequence can be read using e.g. the class
        ``DirectoryClip``.

        """

        if verbose:
          print( "MoviePy: Writing frames %s."%(nameformat))

        if fps is None:
            fps = self.fps

        tt = np.arange(0, self.duration, 1.0/fps)

        filenames = []
        total = int(self.duration/fps)+1
        for i, t in tqdm(enumerate(tt), total=total):
            name = nameformat%(i+1)
            filenames.append(name)
            self.save_frame(name, t, savemask=True)

        if verbose:
          print( "MoviePy: Done writing frames %s."%(nameformat))

        return filenames



    def to_gif(self, filename, fps=None, program= 'ImageMagick',
            opt="OptimizeTransparency", fuzz=1, verbose=True,
            loop=0, dispose=False):
        """ Write the VideoClip to a GIF file.

        Converts a VideoClip into an animated GIF using ImageMagick
        or ffmpeg.


        Parameters
        -----------

        filename
          Name of the resulting gif file.

        fps
          Number of frames per second (see note below). If it
            isn't provided, then the function will look for the clip's
            ``fps`` attribute (VideoFileClip, for instance, have one).

        program
          Software to use for the conversion, either 'ImageMagick' or
          'ffmpeg'.

        opt
          (ImageMagick only) optimalization to apply, either
          'optimizeplus' or 'OptimizeTransparency'.

        fuzz
          (ImageMagick only) Compresses the GIF by considering that
          the colors that are less than fuzz% different are in fact
          the same.


        Notes
        -----

        The gif will be playing the clip in real time (you can
        only change the frame rate). If you want the gif to be played
        slower than the clip you will use ::

            >>> # slow down clip 50% and make it a gif
            >>> myClip.speedx(0.5).to_gif('myClip.gif')

        """

        def verbose_print(s):
            if verbose: sys_write_flush(s)

        if fps is None:
            fps = self.fps

        fileName, fileExtension = os.path.splitext(filename)
        tt = np.arange(0,self.duration, 1.0/fps)
        tempfiles = []

        verbose_print("\nMoviePy: building GIF file %s\n"%filename
                      +40*"-"+"\n")

        verbose_print("Generating GIF frames.\n")

        total = int(self.duration/fps)+1
        for i, t in tqdm(enumerate(tt), total=total):

            name = "%s_GIFTEMP%04d.png"%(fileName, i+1)
            tempfiles.append(name)
            self.save_frame(name, t, savemask=True)

        verbose_print("Done generating GIF frames.\n")

        delay = int(100.0/fps)

        if program == "ImageMagick":

            cmd = [IMAGEMAGICK_BINARY,
                  '-delay' , '%d'%delay,
                  "-dispose" ,"%d"%(2 if dispose else 1),
                  "-loop" , "%d"%loop,
                  "%s_GIFTEMP*.png"%fileName,
                  "-coalesce",
                  "-fuzz", "%02d"%fuzz + "%",
                  "-layers", "%s"%opt,
                  "%s"%filename]

        elif program == "ffmpeg":

            cmd = [FFMPEG_BINARY, '-y',
                   '-f', 'image2',
                   '-i', fileName+'_GIFTEMP%04d.png',
                   '-r',str(fps),
                   filename]


        subprocess_call( cmd, verbose = verbose )

        for f in tempfiles:
            os.remove(f)



    #-----------------------------------------------------------------
    # F I L T E R I N G



    def subfx(self, fx, ta=0, tb=None, **kwargs):
        """ Apply a transformation to a part of the clip.

        Returns a new clip in which the function ``fun`` (clip->clip)
        has been applied to the subclip between times `ta` and `tb`
        (in seconds).

        Examples
        ---------

        >>> # The scene between times t=3s and t=6s in ``clip`` will be
        >>> # be played twice slower in ``newclip``
        >>> newclip = clip.subapply(lambda c:c.speedx(0.5) , 3,6)

        """
        left = None if (ta == 0) else self.subclip(0, tb=ta)
        center = self.subclip(ta, tb).fx(**kwargs)
        right = None if (tb is None) else self.subclip(ta=tb)

        clips = [c for c in [left, center, right] if c != None]
        cc = VideoClip.concat(clips)

        if self.start != None:
            cc = cc.set_start(self.start)

        return cc


    # IMAGE FILTERS


    def fl_image(self, image_func, apply_to=[]):
        """
        Modifies the images of a clip by replacing the frame
        `get_frame(t)` by another frame,  `image_func(get_frame(t))`
        """
        return self.fl(lambda gf, t: image_func(gf(t)), apply_to)

    #--------------------------------------------------------------
    # C O M P O S I T I N G

    
    def blit_on(self, picture, t):
        """
        Returns the result of the blit of the clip's frame at time `t`
        on the given `picture`, the position of the clip being given
        by the clip's ``pos`` attribute. Meant for compositing.
        """

        hf, wf = sizef = picture.shape[:2]

        if self.ismask and picture.max() != 0:
                return np.maximum(picture,
                                  self.blit_on(np.zeros(sizef), t))

        ct = t - self.start  # clip time

        # GET IMAGE AND MASK IF ANY

        img = self.get_frame(ct)
        mask = (None if (self.mask is None) else
                self.mask.get_frame(ct))
        hi, wi = img.shape[:2]

        # SET POSITION

        pos = self.pos(ct)


        # preprocess short writings of the position
        if isinstance(pos,str):
            pos = { 'center': ['center','center'],
                    'left': ['left','center'],
                    'right': ['right','center'],
                    'top':['center','top'],
                    'bottom':['center','bottom']}[pos]
        else:
            pos = list(pos)

        # is the position relative (given in % of the clip's size) ?
        if self.relative_pos:
            for i, dim in enumerate(wf, hf):
                if not isinstance(pos[i], str):
                    pos[i] = dim * pos[i]

        if isinstance(pos[0], str):
            D = {'left': 0, 'center': (wf - wi) / 2, 'right': wf - wi}
            pos[0] = D[pos[0]]

        if isinstance(pos[1], str):

            D = {'top': 0, 'center': (hf - hi) / 2, 'bottom': hf - hi}
            pos[1] = D[pos[1]]

        pos = map(int, pos)

        return blit(img, picture, pos, mask=mask, ismask=self.ismask)

    def add_mask(self, constant_size=True):
        """ Add a mask VideoClip to the VideoClip.

        Returns a copy of the clip with a completely opaque mask
        (made of ones). This makes computations slower compared to
        having a None mask but can be useful in many cases. Choose

        Set ``constant_size`` to  `False` for clips with moving
        image size.
        """
        if constant_size:
            mask = ColorClip(self.size, 1.0, ismask=True)
            return self.set_mask( mask.set_duration(self.duration))
        else:
            get_frame = lambda t: np.ones(self.get_frame(t).shape)
            mask = VideoClip(ismask=True, get_frame = get_frame)
            return self.set_mask(mask.set_duration(self.duration))



    def on_color(self, size=None, color=(0, 0, 0), pos=None,
                 col_opacity=None):
        """ Place the clip on a colored background.

        Returns a clip made of the current clip overlaid on a color
        clip of a possibly bigger size. Can serve to flatten transparent
        clips.

        Parameters
        -----------

        size
          Size (width, height) in pixels of the final clip.
          By default it will be the size of the current clip.

        bg_color
          Background color of the final clip ([R,G,B]).

        pos
          Position of the clip in the final clip.

        col_opacity
          Parameter in 0..1 indicating the opacity of the colored
          background.

        """
        from .compositing.CompositeVideoClip import CompositeVideoClip
        if size is None:
            size = self.size
        if pos is None:
            pos = 'center'
        colorclip = ColorClip(size, color)
        if col_opacity is not None:
            colorclip = colorclip.set_opacity(col_opacity)

        if self.duration is not None:
            colorclip = colorclip.set_duration(self.duration)

        result = CompositeVideoClip([colorclip, self.set_pos(pos)],
                                  transparent=(col_opacity != None))

        return result


    @outplace
    def set_get_frame(self, gf):
        """ Change the clip's ``get_frame``.

        Returns a copy of the VideoClip instance, with the get_frame
        attribute set to `gf`.
        """
        self.get_frame = gf
        self.size = gf(0).shape[:2][::-1]


    @outplace
    def set_audio(self, audioclip):
        """ Attach an AudioClip to the VideoClip.

        Returns a copy of the VideoClip instance, with the `audio`
        attribute set to ``audio``, hich must be an AudioClip instance.
        """
        self.audio = audioclip


    @outplace
    def set_mask(self, mask):
        """ Set the clip's mask.

        Returns a copy of the VideoClip with the mask attribute set to
        ``mask``, which must be a greyscale (values in 0-1) VideoClip"""
        assert ( (mask is None) or mask.ismask )
        self.mask = mask



    @add_mask_if_none
    @outplace
    def set_opacity(self, op):
        """ Set the opacity/transparency level of the clip.

        Returns a semi-transparent copy of the clip where the mask is
        multiplied by ``op`` (any float, normally between 0 and 1).
        """

        self.mask = self.mask.fl_image(lambda pic: op * pic)



    @apply_to_mask
    @outplace
    def set_pos(self, pos, relative=False):
        """ Set the clip's position in compositions.

        Sets the position that the clip will have when included
        in compositions. The argument ``pos`` can be either a couple
        ``(x,y)`` or a function ``t-> (x,y)``. `x` and `y` mark the
        location of the top left corner of the clip, and can be
        of several types.

        Examples
        ----------

        >>> clip.set_pos((45,150)) # x=45, y=150
        >>>
        >>> # clip horizontally centered, at the top of the picture
        >>> clip.set_pos(("center","top"))
        >>>
        >>> # clip is at 40% of the width, 70% of the height:
        >>> clip.set_pos((0.4,0.7), relative=True)
        >>>
        >>> # clip's position is horizontally centered, and moving up !
        >>> clip.set_pos(lambda t: ('center', 50+t) )

        """

        self.relative_pos = relative
        if hasattr(pos, '__call__'):
            self.pos = pos
        else:
            self.pos = lambda t: pos



    #--------------------------------------------------------------
    # CONVERSIONS TO OTHER TYPES



    def to_ImageClip(self,t=0):
        """
        Returns an ImageClip made out of the clip's frame at time ``t``
        """
        return ImageClip(self.get_frame(t))



    def to_mask(self, canal=0):
        """
        Returns a mask a video clip made from the clip.
        """
        if self.ismask:
            return self
        else:
            newclip = self.fl_image(lambda pic:
                                        1.0 * pic[:, :, canal] / 255)
            newclip.ismask = True
            return newclip



    def to_RGB(self):
        """
        Returns a non-mask video clip made from the mask video clip.
        """
        if self.ismask:
            f = lambda pic: np.dstack(3 * [255 * pic]).astype('uint8')
            newclip = self.fl_image( f )
            newclip.ismask = False
            return newclip
        else:
            return self


    @requires_duration
    def iter_frames(self, fps=None):
        """ Iterates over all the frames of the clip.
        
        Returns each frame of the clip as a HxWxN np.array,
        where N=1 for mask clips and N=3 for RGB clips.
        
        This function is not really meant for video editing.
        It provides an easy way to do frame-by-frame treatment of
        a video, for fields like science, computer vision...
        
        The ``fps`` (frames per second) parameter is optional if the
        clip already has a ``fps`` attribute.
        
        Examples
        ---------
        
        >>> # prints the maximum of red that is contained
        >>> # on the first line of each frame of the clip.
        >>> from moviepy.editor import VideoFileClip
        >>> myclip = VideoFileClip('myvideo.mp4')
        >>> for frame in myclip.iter_frames():
        >>>     print ( frame[0,:,0].max() )
        
        """
        
        if fps is None:
            fps = self.fps
            
        for t in np.arange(0, self.duration, 1.0/fps):
            yield self.get_frame(t)

    #----------------------------------------------------------------
    # Audio


    @outplace
    def without_audio(self):
        """ Remove the clip's audio.

        Return a copy of the clip with audio set to None.

        """
        self.audio = None


    @outplace
    def afx(self, fun, *a, **k):
        """ Transform the clip's audio.

        Return a new clip whose audio has been transformed by ``fun``.

        """
        self.audio = self.audio.fx(fun, *a, **k)



"""---------------------------------------------------------------------

    ImageClip (base class for all 'static clips') and its subclasses
    ColorClip and TextClip.
    I would have liked to put these in a separate file but Python is bad
    at cyclic imports.

---------------------------------------------------------------------"""



class ImageClip(VideoClip):

    """ Class for non-moving VideoClips.

    A video clip originating from a picture. This clip will simply
    display the given picture at all times.

    Examples
    ---------

    >>> clip = ImageClip("myHouse.jpeg")
    >>> clip = ImageClip( someArray ) # a Numpy array represent

    Parameters
    -----------

    img
      Any picture file (png, tiff, jpeg, etc.) or any array representing
      an RGB image (for instance a frame from a VideoClip).

    ismask
      Set this parameter to `True` if the clip is a mask.

    transparent
      Set this parameter to `True` (default) if you want the alpha layer
      of the picture (if it exists) to be used as a mask.

    Attributes
    -----------

    img
      Array representing the image of the clip.

    """


    def __init__(self, img, ismask=False, transparent=True,
                 fromalpha=False):

        VideoClip.__init__(self, ismask=ismask)

        if isinstance(img, str):
            img = ffmpeg_read_image(img,with_mask=transparent)

        if len(img.shape) == 3: # img is (now) a RGB(a) numpy array

                if img.shape[2] == 4:
                    if fromalpha:
                        img = 1.0 * img[:, :, 3] / 255
                    elif ismask:
                        img = 1.0 * img[:, :, 0] / 255
                    elif transparent:
                        self.mask = ImageClip(
                            1.0 * img[:, :, 3] / 255, ismask=True)
                        img = img[:, :, :3]
                elif ismask:
                        img = 1.0 * img[:, :, 0] / 255

        # if the image was just a 2D mask, it should arrive here
        # unchanged
        self.get_frame = lambda t: img
        self.size = img.shape[:2][::-1]
        self.img = img




    def fl(self, fl,  apply_to=[], keep_duration=True):
        """ General transformation filter.

        Equivalent to VideoClip.fl . The result is no more an
        ImageClip, it has the class VideoClip (since it may be animated)
        """

        # When we use fl on an image clip it may become animated.
        #Therefore the result is not an ImageClip, just a VideoClip.
        newclip = VideoClip.fl(self,fl, apply_to=apply_to,
                               keep_duration=keep_duration)
        newclip.__class__ = VideoClip
        return newclip



    @outplace
    def fl_image(self, image_func, apply_to= []):
        """ Image-transformation filter.

        Does the same as VideoClip.fl_image, but for ImageClip the
        tranformed clip is computed once and for all at the beginning,
        and not for each 'frame'.
        """

        arr = image_func(self.get_frame(0))
        self.size = arr.shape[:2][::-1]
        self.get_frame = lambda t: arr
        self.img = arr

        for attr in apply_to:
            if hasattr(self, attr):
                a = getattr(self, attr)
                if a != None:
                    new_a =  a.fl_image(image_func)
                    setattr(newclip, attr, new_a)



    @outplace
    def fl_time(self, time_func, apply_to =['mask', 'audio']):
        """ Time-transformation filter.

        Applies a transformation to the clip's timeline
        (see Clip.fl_time).

        This method does nothing for ImageClips (but it may affect their
        masks of their audios). The result is still an ImageClip.
        """

        for attr in apply_to:
            if hasattr(self, attr):
                a = getattr(self, attr)
                if a != None:
                    new_a = a.fl_time(time_func)
                    setattr(self, attr, new_a)



class ColorClip(ImageClip):
    """ An ImageClip showing just one color.

    Parameters
    -----------

    size
      Size (width, height) in pixels of the clip.

    color
      If argument ``ismask`` is False, ``color`` indicates
      the color in RGB of the clip (default is black). If `ismask``
      is True, ``color`` must be  a float between 0 and 1 (default is 1)

    ismask
      Set to true if the clip will be used as a mask.
    """


    def __init__(self,size, col=(0, 0, 0), ismask=False):
        w, h = size
        shape = (h, w) if np.isscalar(col) else (h, w, len(col))
        ImageClip.__init__(self, np.tile(col, w * h).reshape(shape),
                           ismask=ismask)



class TextClip(ImageClip):

    """ Class for autogenerated text clips.

    Creates an ImageClip originating from a script-generated text image.
    Requires ImageMagick.

    Parameters
    -----------

    txt
      either a string, or a filename. If txt is in a file and
      whose name is ``mytext.txt`` for instance, then txt must be
      equal to ``@mytext.txt`` .

    size
      Size of the picture in pixels. Can be auto-set if
      method='label', but mandatory if method='caption'.
      the height can be None, it will then be auto-determined.

    bg_color
      Color of the background. See ``TextClip.list('color')``
      for a list of acceptable names.

    color
      Color of the background. See ``TextClip.list('color')`` for a
      list of acceptable names.

    font
      Name of the font to use. See ``TextClip.list('font')`` for
      the list of fonts you can use on your computer.

    stroke_color
      Color of the stroke (=contour line) of the text. If ``None``,
      there will be no stroke.

    stroke_width
      Width of the stroke, in pixels. Can be a float, like 1.5.

    method
      Either 'label' (default, the picture will be autosized so as to fit
      exactly the size) or 'caption' (the text will be drawn in a picture
      with fixed size provided with the ``size`` argument). If `caption`,
      the text will be wrapped automagically (sometimes it is buggy, not
      my fault, complain to the ImageMagick crew) and can be aligned or
      centered (see parameter ``align``).

    kerning
      Changes the default spacing between letters. For
      nstance ``kerning=-1`` will make the letters 1 pixel nearer from
      ach other compared to the default spacing.

    align
      center | East | West | South | North . Will only work if ``method``
      is set to ``caption``

    transparent
      ``True`` (default) if you want to take into account the
      transparency in the image.

    """



    def __init__(self, txt, size=None, color='black',
             bg_color='transparent', fontsize=None, font='Courier',
             stroke_color=None, stroke_width=1, method='label',
             kerning=None, align='center', interline=None,
             tempfilename=None, temptxt=None,
             transparent=True, remove_temp=True,
             print_cmd=False):

        if not txt.startswith('@'):
            if temptxt is None:
                temptxt_fd, temptxt = tempfile.mkstemp(suffix='.txt')
                try: # only in Python3 will this work
                    os.write(temptxt_fd, bytes(txt,'UTF8'))
                except TypeError: # oops, fall back to Python2
                    os.write(temptxt_fd, txt)
                os.close(temptxt_fd)
            txt = '@'+temptxt
        else:
            txt = "'%s'"%txt

        if size != None:
            size = ('' if size[0] is None else str(size[0]),
                    '' if size[1] is None else str(size[1]))

        cmd = ( [IMAGEMAGICK_BINARY,
               "-background", bg_color,
               "-fill", color,
               "-font", font])

        if fontsize !=None:
            cmd += ["-pointsize", "%d"%fontsize]
        if kerning != None:
            cmd += ["-kerning", "%0.1f"%kerning]
        if stroke_color != None:
            cmd += ["-stroke", stroke_color, "-strokewidth",
                                             "%.01f"%stroke_width]
        if size != None:
            cmd += ["-size", "%sx%s"%(size[0], size[1])]
        if align != None:
            cmd += ["-gravity",align]
        if interline != None:
            cmd += ["-interline-spacing", "%d"%interline]

        if tempfilename is None:
            tempfile_fd, tempfilename = tempfile.mkstemp(suffix='.png')
            os.close(tempfile_fd)

        cmd += ["%s:%s" %(method, txt),
        "-type",  "truecolormatte", "PNG32:%s"%tempfilename]

        if print_cmd:
            print( " ".join(cmd) )

        subprocess_call(cmd, verbose=False )

        ImageClip.__init__(self, tempfilename, transparent=transparent)
        self.txt = txt
        self.color = color
        self.stroke_color = stroke_color

        if remove_temp:
            if os.path.exists(tempfilename):
                os.remove(tempfilename)
            if os.path.exists(temptxt):
                os.remove(temptxt)


    @staticmethod
    def list(arg):
        """
        Returns the list of all valid entries for the argument given
        (can be ``font``, ``color``, etc...) argument of ``TextClip``
        """
        process = subprocess.Popen([IMAGEMAGICK_BINARY, '-list', arg],
                                   stdout=subprocess.PIPE)
        result = process.communicate()[0]
        lines = result.splitlines()

        if arg == 'font':
            return [l[8:] for l in lines if l.startswith("  Font:")]
        elif arg == 'color':
            return [l.split(" ")[1] for l in lines[2:]]

########NEW FILE########
__FILENAME__ = tests
"""
Tests meant to be run with pytest
"""

import pytest

from moviepy.editor import *


@pytest.fixture
def example_video1():
	

########NEW FILE########
__FILENAME__ = test_install


from moviepy.editor import *

W,H = (150,180)
color_clips_props =  [{ 'color':[0,0,255],
                        'init_pos':[]
[0,0,255],[0,255,0],[255,0,0]
red_clip, green_clip, blue_clip = [ColorClip((W,H),color=c)
                                   for c in RED, GREEN, BLUE]

########NEW FILE########
