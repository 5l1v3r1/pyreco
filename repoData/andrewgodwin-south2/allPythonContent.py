__FILENAME__ = copy-code
#!/usr/bin/env python

"""
Code copier for South 2

As South 2 is a backport of the migration code from Django 1.7, we don't
want to have too much of a maintentance overhead when making changes and
bugfixes; thus, South 2 is considered a derived version of that code,
and some of it is copied directly over with minor transformations.

This file handles copying the code out of a Django development tree,
making any necessary transforms, and then writing it out to the South 2
development tree.

I know this seems a bit weird. Don't judge me. It's either this or manually
committing every fix twice.
"""

import os
import sys
import re

files = {
    "south/autodetector.py": "django/db/migrations/autodetector.py",
    "south/executor.py": "django/db/migrations/executor.py",
    "south/graph.py": "django/db/migrations/graph.py",
    "south/loader.py": "django/db/migrations/loader.py",
    "south/migration.py": "django/db/migrations/migration.py",
    "south/optimizer.py": "django/db/migrations/optimizer.py",
    "south/questioner.py": "django/db/migrations/questioner.py",
    "south/recorder.py": "django/db/migrations/recorder.py",
    "south/state.py": "django/db/migrations/state.py",
    "south/writer.py": "django/db/migrations/writer.py",
    "south/operations/__init__.py": "django/db/migrations/operations/__init__.py",
    "south/operations/base.py": "django/db/migrations/operations/base.py",
    "south/operations/models.py": "django/db/migrations/operations/models.py",
    "south/operations/fields.py": "django/db/migrations/operations/fields.py",
    "south/operations/special.py": "django/db/migrations/operations/special.py",
    "south/schema/__init__.py": "django/db/backends/schema.py",
    "south/schema/postgresql.py": "django/db/backends/postgresql_psycopg2/schema.py",
    "south/schema/mysql.py": "django/db/backends/mysql/schema.py",
    "south/schema/sqlite3.py": "django/db/backends/sqlite3/schema.py",
    "south/schema/oracle.py": "django/db/backends/oracle/schema.py",
    "south/management/commands/makemigrations.py": "django/core/management/commands/makemigrations.py",
    "south/management/commands/migrate.py": "django/core/management/commands/migrate.py",
    "south/management/commands/sqlmigrate.py": "django/core/management/commands/sqlmigrate.py",
    "south/management/commands/syncdb.py": "django/core/management/commands/syncdb.py",
    "tests/schema/__init__.py": "tests/schema/__init__.py",
    "tests/schema/models.py": "tests/schema/models.py",
    "tests/schema/tests.py": "tests/schema/tests.py",
    "tests/migrations/__init__.py": "tests/migrations/__init__.py",
    "tests/migrations/models.py": "tests/migrations/models.py",
    "tests/migrations/test_base.py": "tests/migrations/test_base.py",
    "tests/migrations/test_graph.py": "tests/migrations/test_graph.py",
}

transforms = {
    "__all__": {
        "^from django.utils.datastructures import OrderedSet": "from south.datastructures import OrderedSet",
        "^from django.db.backends.utils import": "from django.db.backends.util import",
        "^from django.core.apps import AppCache": "from south.app_cache import AppCache",
        "^from django.core.apps import app_cache": "from south.app_cache import app_cache",
        "^from django.core.apps.cache import AppCache": "from south.app_cache import AppCache",
        "^from django.db.backends.schema import": "from south.schema import",
        "from django.db.migrations import operations": "from south import operations",
        r"^from django.db.migrations.(\w+) import": r"from south.\1 import",
    }
}


def main(source, destination=None):
    """
    Copies and transforms code.
    """

    if destination is None:
        destination = os.path.dirname(__file__)

    for dfile, sfile in sorted(files.items()):
        # read source file
        with open(os.path.join(source, sfile), "r") as fh:
            contents = fh.read()
        # Run transforms
        file_transforms = dict(transforms.get("__all__", {}))
        file_transforms.update(transforms.get(dfile, {}))
        new_contents = ""
        for line in contents.split("\n"):
            for tfrom, tto in file_transforms.items():
                line = re.sub(tfrom, tto, line)
            new_contents += line + "\n"
        # Make sure there's only one newline at the end of the file
        while new_contents.endswith("\n\n"):
            new_contents = new_contents[:-1]
        # Write destination file w/header
        with open(os.path.join(destination, dfile), "w") as fh:
            fh.write("# Autogenerated from Django's %s - do not edit\n\n" % sfile)
            fh.write(new_contents)
        print "Wrote %s" % dfile


if __name__ == "__main__":
    # Check there's a source arg
    if len(sys.argv) != 2:
        print "Usage: copy-code.py /path/to/django-tree"
        sys.exit(1)
    # Check it's a django tree root
    source = sys.argv[1]
    if not os.path.isdir(source):
        print "Specified source directory is not a directory!"
        sys.exit(1)
    if not (
      os.path.isdir(os.path.join(source, "django")) and
      os.path.isdir(os.path.join(source, "tests"))):
        print "Specified source directory is not a Django checkout!"
        sys.exit(1)
    # Run copy
    main(source)

########NEW FILE########
__FILENAME__ = app_cache
from django.db.models.loading import AppCache as DjangoAppCache, cache as app_cache
from django.utils.datastructures import SortedDict


class AppCache(DjangoAppCache):
    """
    A modification of AppCache into a version that can be instantiated
    multiple times.
    """

    def __init__(self):
        self.__dict__ = dict(
            app_store=SortedDict(),
            app_labels={},
            app_models=SortedDict(),
            app_errors={},
            loaded=False,
            handled=set(),
            postponed=[],
            nesting_level=0,
            _get_models_cache={},
            available_apps=None,
        )
        self.loaded = True

########NEW FILE########
__FILENAME__ = autodetector
# Autogenerated from Django's django/db/migrations/autodetector.py - do not edit

import re
import datetime

from south import operations
from south.migration import Migration
from south.questioner import MigrationQuestioner


class MigrationAutodetector(object):
    """
    Takes a pair of ProjectStates, and compares them to see what the
    first would need doing to make it match the second (the second
    usually being the project's current state).

    Note that this naturally operates on entire projects at a time,
    as it's likely that changes interact (for example, you can't
    add a ForeignKey without having a migration to add the table it
    depends on first). A user interface may offer single-app usage
    if it wishes, with the caveat that it may not always be possible.
    """

    def __init__(self, from_state, to_state, questioner=None):
        self.from_state = from_state
        self.to_state = to_state
        self.questioner = questioner or MigrationQuestioner()

    def changes(self, graph, trim_to_apps=None):
        """
        Main entry point to produce a list of appliable changes.
        Takes a graph to base names on and an optional set of apps
        to try and restrict to (restriction is not guaranteed)
        """
        changes = self._detect_changes()
        changes = self._arrange_for_graph(changes, graph)
        if trim_to_apps:
            changes = self._trim_to_apps(changes, trim_to_apps)
        return changes

    def _detect_changes(self):
        """
        Returns a dict of migration plans which will achieve the
        change from from_state to to_state. The dict has app labels
        as keys and a list of migrations as values.

        The resulting migrations aren't specially named, but the names
        do matter for dependencies inside the set.
        """
        # We'll store migrations as lists by app names for now
        self.migrations = {}
        old_app_cache = self.from_state.render()
        new_app_cache = self.to_state.render()
        # Prepare lists of old/new model keys that we care about
        # (i.e. ignoring proxy ones)
        old_model_keys = [
            (al, mn)
            for al, mn in self.from_state.models.keys()
            if not old_app_cache.get_model(al, mn)._meta.proxy
        ]
        new_model_keys = [
            (al, mn)
            for al, mn in self.to_state.models.keys()
            if not new_app_cache.get_model(al, mn)._meta.proxy
        ]
        # Adding models. Phase 1 is adding models with no outward relationships.
        added_models = set(new_model_keys) - set(old_model_keys)
        pending_add = {}
        for app_label, model_name in added_models:
            model_state = self.to_state.models[app_label, model_name]
            # Are there any relationships out from this model? if so, punt it to the next phase.
            related_fields = []
            for field in new_app_cache.get_model(app_label, model_name)._meta.local_fields:
                if field.rel:
                    if field.rel.to:
                        related_fields.append((field.name, field.rel.to._meta.app_label.lower(), field.rel.to._meta.object_name.lower()))
                    if hasattr(field.rel, "through") and not field.rel.though._meta.auto_created:
                        related_fields.append((field.name, field.rel.through._meta.app_label.lower(), field.rel.through._meta.object_name.lower()))
            if related_fields:
                pending_add[app_label, model_name] = related_fields
            else:
                self.add_to_migration(
                    app_label,
                    operations.CreateModel(
                        name=model_state.name,
                        fields=model_state.fields,
                        options=model_state.options,
                        bases=model_state.bases,
                    )
                )
        # Phase 2 is progressively adding pending models, splitting up into two
        # migrations if required.
        pending_new_fks = []
        while pending_add:
            # Is there one we can add that has all dependencies satisfied?
            satisfied = [(m, rf) for m, rf in pending_add.items() if all((al, mn) not in pending_add for f, al, mn in rf)]
            if satisfied:
                (app_label, model_name), related_fields = sorted(satisfied)[0]
                model_state = self.to_state.models[app_label, model_name]
                self.add_to_migration(
                    app_label,
                    operations.CreateModel(
                        name=model_state.name,
                        fields=model_state.fields,
                        options=model_state.options,
                        bases=model_state.bases,
                    )
                )
                for field_name, other_app_label, other_model_name in related_fields:
                    if app_label != other_app_label:
                        self.add_dependency(app_label, other_app_label)
                del pending_add[app_label, model_name]
            # Ah well, we'll need to split one. Pick deterministically.
            else:
                (app_label, model_name), related_fields = sorted(pending_add.items())[0]
                model_state = self.to_state.models[app_label, model_name]
                # Work out the fields that need splitting out
                bad_fields = dict((f, (al, mn)) for f, al, mn in related_fields if (al, mn) in pending_add)
                # Create the model, without those
                self.add_to_migration(
                    app_label,
                    operations.CreateModel(
                        name=model_state.name,
                        fields=[(n, f) for n, f in model_state.fields if n not in bad_fields],
                        options=model_state.options,
                        bases=model_state.bases,
                    )
                )
                # Add the bad fields to be made in a phase 3
                for field_name, (other_app_label, other_model_name) in bad_fields.items():
                    pending_new_fks.append((app_label, model_name, field_name, other_app_label))
                del pending_add[app_label, model_name]
        # Phase 3 is adding the final set of FKs as separate new migrations
        for app_label, model_name, field_name, other_app_label in pending_new_fks:
            model_state = self.to_state.models[app_label, model_name]
            self.add_to_migration(
                app_label,
                operations.AddField(
                    model_name=model_name,
                    name=field_name,
                    field=model_state.get_field_by_name(field_name),
                ),
                new=True,
            )
            if app_label != other_app_label:
                self.add_dependency(app_label, other_app_label)
        # Removing models
        removed_models = set(old_model_keys) - set(new_model_keys)
        for app_label, model_name in removed_models:
            model_state = self.from_state.models[app_label, model_name]
            self.add_to_migration(
                app_label,
                operations.DeleteModel(
                    model_state.name,
                )
            )
        # Changes within models
        kept_models = set(old_model_keys).intersection(new_model_keys)
        old_fields = set()
        new_fields = set()
        for app_label, model_name in kept_models:
            old_model_state = self.from_state.models[app_label, model_name]
            new_model_state = self.to_state.models[app_label, model_name]
            # Collect field changes for later global dealing with (so AddFields
            # always come before AlterFields even on separate models)
            old_fields.update((app_label, model_name, x) for x, y in old_model_state.fields)
            new_fields.update((app_label, model_name, x) for x, y in new_model_state.fields)
            # Unique_together changes
            if old_model_state.options.get("unique_together", set()) != new_model_state.options.get("unique_together", set()):
                self.add_to_migration(
                    app_label,
                    operations.AlterUniqueTogether(
                        name=model_name,
                        unique_together=new_model_state.options.get("unique_together", set()),
                    )
                )
        # New fields
        for app_label, model_name, field_name in new_fields - old_fields:
            old_model_state = self.from_state.models[app_label, model_name]
            new_model_state = self.to_state.models[app_label, model_name]
            field = new_model_state.get_field_by_name(field_name)
            # Scan to see if this is actually a rename!
            field_dec = field.deconstruct()[1:]
            found_rename = False
            for rem_app_label, rem_model_name, rem_field_name in (old_fields - new_fields):
                if rem_app_label == app_label and rem_model_name == model_name:
                    if old_model_state.get_field_by_name(rem_field_name).deconstruct()[1:] == field_dec:
                        if self.questioner.ask_rename(model_name, rem_field_name, field_name, field):
                            self.add_to_migration(
                                app_label,
                                operations.RenameField(
                                    model_name=model_name,
                                    old_name=rem_field_name,
                                    new_name=field_name,
                                )
                            )
                            old_fields.remove((rem_app_label, rem_model_name, rem_field_name))
                            new_fields.remove((app_label, model_name, field_name))
                            found_rename = True
                            break
            if found_rename:
                continue
            # You can't just add NOT NULL fields with no default
            if not field.null and not field.has_default():
                field = field.clone()
                field.default = self.questioner.ask_not_null_addition(field_name, model_name)
                self.add_to_migration(
                    app_label,
                    operations.AddField(
                        model_name=model_name,
                        name=field_name,
                        field=field,
                        preserve_default=False,
                    )
                )
            else:
                self.add_to_migration(
                    app_label,
                    operations.AddField(
                        model_name=model_name,
                        name=field_name,
                        field=field,
                    )
                )
        # Old fields
        for app_label, model_name, field_name in old_fields - new_fields:
            old_model_state = self.from_state.models[app_label, model_name]
            new_model_state = self.to_state.models[app_label, model_name]
            self.add_to_migration(
                app_label,
                operations.RemoveField(
                    model_name=model_name,
                    name=field_name,
                )
            )
        # The same fields
        for app_label, model_name, field_name in old_fields.intersection(new_fields):
            # Did the field change?
            old_model_state = self.from_state.models[app_label, model_name]
            new_model_state = self.to_state.models[app_label, model_name]
            old_field_dec = old_model_state.get_field_by_name(field_name).deconstruct()
            new_field_dec = new_model_state.get_field_by_name(field_name).deconstruct()
            if old_field_dec != new_field_dec:
                self.add_to_migration(
                    app_label,
                    operations.AlterField(
                        model_name=model_name,
                        name=field_name,
                        field=new_model_state.get_field_by_name(field_name),
                    )
                )
        # Alright, now add internal dependencies
        for app_label, migrations in self.migrations.items():
            for m1, m2 in zip(migrations, migrations[1:]):
                m2.dependencies.append((app_label, m1.name))
        # Clean up dependencies
        for app_label, migrations in self.migrations.items():
            for migration in migrations:
                migration.dependencies = list(set(migration.dependencies))
        return self.migrations

    def add_to_migration(self, app_label, operation, new=False):
        migrations = self.migrations.setdefault(app_label, [])
        if not migrations or new:
            subclass = type("Migration", (Migration,), {"operations": [], "dependencies": []})
            instance = subclass("auto_%i" % (len(migrations) + 1), app_label)
            migrations.append(instance)
        migrations[-1].operations.append(operation)

    def add_dependency(self, app_label, other_app_label):
        """
        Adds a dependency to app_label's newest migration on
        other_app_label's latest migration.
        """
        if self.migrations.get(other_app_label, []):
            dependency = (other_app_label, self.migrations[other_app_label][-1].name)
        else:
            dependency = (other_app_label, "__first__")
        self.migrations[app_label][-1].dependencies.append(dependency)

    def _arrange_for_graph(self, changes, graph):
        """
        Takes in a result from changes() and a MigrationGraph,
        and fixes the names and dependencies of the changes so they
        extend the graph from the leaf nodes for each app.
        """
        leaves = graph.leaf_nodes()
        name_map = {}
        for app_label, migrations in list(changes.items()):
            if not migrations:
                continue
            # Find the app label's current leaf node
            app_leaf = None
            for leaf in leaves:
                if leaf[0] == app_label:
                    app_leaf = leaf
                    break
            # Do they want an initial migration for this app?
            if app_leaf is None and not self.questioner.ask_initial(app_label):
                # They don't.
                for migration in migrations:
                    name_map[(app_label, migration.name)] = (app_label, "__first__")
                del changes[app_label]
            # Work out the next number in the sequence
            if app_leaf is None:
                next_number = 1
            else:
                next_number = (self.parse_number(app_leaf[1]) or 0) + 1
            # Name each migration
            for i, migration in enumerate(migrations):
                if i == 0 and app_leaf:
                    migration.dependencies.append(app_leaf)
                if i == 0 and not app_leaf:
                    new_name = "0001_initial"
                else:
                    new_name = "%04i_%s" % (next_number, self.suggest_name(migration.operations))
                name_map[(app_label, migration.name)] = (app_label, new_name)
                migration.name = new_name
        # Now fix dependencies
        for app_label, migrations in changes.items():
            for migration in migrations:
                migration.dependencies = [name_map.get(d, d) for d in migration.dependencies]
        return changes

    def _trim_to_apps(self, changes, app_labels):
        """
        Takes changes from arrange_for_graph and set of app labels and
        returns a modified set of changes which trims out as many migrations
        that are not in app_labels as possible.
        Note that some other migrations may still be present, as they may be
        required dependencies.
        """
        # Gather other app dependencies in a first pass
        app_dependencies = {}
        for app_label, migrations in changes.items():
            for migration in migrations:
                for dep_app_label, name in migration.dependencies:
                    app_dependencies.setdefault(app_label, set()).add(dep_app_label)
        required_apps = set(app_labels)
        # Keep resolving till there's no change
        old_required_apps = None
        while old_required_apps != required_apps:
            old_required_apps = set(required_apps)
            for app_label in list(required_apps):
                required_apps.update(app_dependencies.get(app_label, set()))
        # Remove all migrations that aren't needed
        for app_label in list(changes.keys()):
            if app_label not in required_apps:
                del changes[app_label]
        return changes

    @classmethod
    def suggest_name(cls, ops):
        """
        Given a set of operations, suggests a name for the migration
        they might represent. Names are not guaranteed to be unique,
        but we put some effort in to the fallback name to avoid VCS conflicts
        if we can.
        """
        if len(ops) == 1:
            if isinstance(ops[0], operations.CreateModel):
                return ops[0].name.lower()
            elif isinstance(ops[0], operations.DeleteModel):
                return "delete_%s" % ops[0].name.lower()
            elif isinstance(ops[0], operations.AddField):
                return "%s_%s" % (ops[0].model_name.lower(), ops[0].name.lower())
            elif isinstance(ops[0], operations.RemoveField):
                return "remove_%s_%s" % (ops[0].model_name.lower(), ops[0].name.lower())
        elif all(isinstance(o, operations.CreateModel) for o in ops):
            return "_".join(sorted(o.name.lower() for o in ops))
        return "auto_%s" % datetime.datetime.now().strftime("%Y%m%d_%H%M")

    @classmethod
    def parse_number(cls, name):
        """
        Given a migration name, tries to extract a number from the
        beginning of it. If no number found, returns None.
        """
        if re.match(r"^\d+_", name):
            return int(name.split("_")[0])
        return None

########NEW FILE########
__FILENAME__ = datastructures
from django.utils.datastructures import SortedDict


class OrderedSet(object):
    """
    A set which keeps the ordering of the inserted items.
    Currently backs onto SortedDict.
    """

    def __init__(self, iterable=None):
        self.dict = SortedDict(((x, None) for x in iterable) if iterable else [])

    def add(self, item):
        self.dict[item] = None

    def remove(self, item):
        del self.dict[item]

    def discard(self, item):
        try:
            self.remove(item)
        except KeyError:
            pass

    def __iter__(self):
        return iter(self.dict.keys())

    def __contains__(self, item):
        return item in self.dict

    def __nonzero__(self):
        return bool(self.dict)

########NEW FILE########
__FILENAME__ = executor
# Autogenerated from Django's django/db/migrations/executor.py - do not edit

from django.db import migrations
from .loader import MigrationLoader
from .recorder import MigrationRecorder


class MigrationExecutor(object):
    """
    End-to-end migration execution - loads migrations, and runs them
    up or down to a specified set of targets.
    """

    def __init__(self, connection, progress_callback=None):
        self.connection = connection
        self.loader = MigrationLoader(self.connection)
        self.recorder = MigrationRecorder(self.connection)
        self.progress_callback = progress_callback

    def migration_plan(self, targets):
        """
        Given a set of targets, returns a list of (Migration instance, backwards?).
        """
        plan = []
        applied = set(self.loader.applied_migrations)
        for target in targets:
            # If the target is (appname, None), that means unmigrate everything
            if target[1] is None:
                for root in self.loader.graph.root_nodes():
                    if root[0] == target[0]:
                        for migration in self.loader.graph.backwards_plan(root):
                            if migration in applied:
                                plan.append((self.loader.graph.nodes[migration], True))
                                applied.remove(migration)
            # If the migration is already applied, do backwards mode,
            # otherwise do forwards mode.
            elif target in applied:
                backwards_plan = self.loader.graph.backwards_plan(target)[:-1]
                # We only do this if the migration is not the most recent one
                # in its app - that is, another migration with the same app
                # label is in the backwards plan
                if any(node[0] == target[0] for node in backwards_plan):
                    for migration in backwards_plan:
                        if migration in applied:
                            plan.append((self.loader.graph.nodes[migration], True))
                            applied.remove(migration)
            else:
                for migration in self.loader.graph.forwards_plan(target):
                    if migration not in applied:
                        plan.append((self.loader.graph.nodes[migration], False))
                        applied.add(migration)
        return plan

    def migrate(self, targets, plan=None, fake=False):
        """
        Migrates the database up to the given targets.
        """
        if plan is None:
            plan = self.migration_plan(targets)
        for migration, backwards in plan:
            if not backwards:
                self.apply_migration(migration, fake=fake)
            else:
                self.unapply_migration(migration, fake=fake)

    def collect_sql(self, plan):
        """
        Takes a migration plan and returns a list of collected SQL
        statements that represent the best-efforts version of that plan.
        """
        statements = []
        for migration, backwards in plan:
            with self.connection.schema_editor(collect_sql=True) as schema_editor:
                project_state = self.loader.graph.project_state((migration.app_label, migration.name), at_end=False)
                if not backwards:
                    migration.apply(project_state, schema_editor, collect_sql=True)
                else:
                    migration.unapply(project_state, schema_editor, collect_sql=True)
            statements.extend(schema_editor.collected_sql)
        return statements

    def apply_migration(self, migration, fake=False):
        """
        Runs a migration forwards.
        """
        if self.progress_callback:
            self.progress_callback("apply_start", migration, fake)
        if not fake:
            # Test to see if this is an already-applied initial migration
            if not migration.dependencies and self.detect_soft_applied(migration):
                fake = True
            else:
                # Alright, do it normally
                with self.connection.schema_editor() as schema_editor:
                    project_state = self.loader.graph.project_state((migration.app_label, migration.name), at_end=False)
                    migration.apply(project_state, schema_editor)
        # For replacement migrations, record individual statuses
        if migration.replaces:
            for app_label, name in migration.replaces:
                self.recorder.record_applied(app_label, name)
        else:
            self.recorder.record_applied(migration.app_label, migration.name)
        # Report progress
        if self.progress_callback:
            self.progress_callback("apply_success", migration, fake)

    def unapply_migration(self, migration, fake=False):
        """
        Runs a migration backwards.
        """
        if self.progress_callback:
            self.progress_callback("unapply_start", migration, fake)
        if not fake:
            with self.connection.schema_editor() as schema_editor:
                project_state = self.loader.graph.project_state((migration.app_label, migration.name), at_end=False)
                migration.unapply(project_state, schema_editor)
        # For replacement migrations, record individual statuses
        if migration.replaces:
            for app_label, name in migration.replaces:
                self.recorder.record_unapplied(app_label, name)
        else:
            self.recorder.record_unapplied(migration.app_label, migration.name)
        # Report progress
        if self.progress_callback:
            self.progress_callback("unapply_success", migration, fake)

    def detect_soft_applied(self, migration):
        """
        Tests whether a migration has been implicity applied - that the
        tables it would create exist. This is intended only for use
        on initial migrations (as it only looks for CreateModel).
        """
        project_state = self.loader.graph.project_state((migration.app_label, migration.name), at_end=True)
        app_cache = project_state.render()
        for operation in migration.operations:
            if isinstance(operation, migrations.CreateModel):
                model = app_cache.get_model(migration.app_label, operation.name)
                if model._meta.db_table not in self.connection.introspection.get_table_list(self.connection.cursor()):
                    return False
        return True

########NEW FILE########
__FILENAME__ = graph
# Autogenerated from Django's django/db/migrations/graph.py - do not edit

from south.datastructures import OrderedSet
from south.state import ProjectState


class MigrationGraph(object):
    """
    Represents the digraph of all migrations in a project.

    Each migration is a node, and each dependency is an edge. There are
    no implicit dependencies between numbered migrations - the numbering is
    merely a convention to aid file listing. Every new numbered migration
    has a declared dependency to the previous number, meaning that VCS
    branch merges can be detected and resolved.

    Migrations files can be marked as replacing another set of migrations -
    this is to support the "squash" feature. The graph handler isn't responsible
    for these; instead, the code to load them in here should examine the
    migration files and if the replaced migrations are all either unapplied
    or not present, it should ignore the replaced ones, load in just the
    replacing migration, and repoint any dependencies that pointed to the
    replaced migrations to point to the replacing one.

    A node should be a tuple: (app_path, migration_name). The tree special-cases
    things within an app - namely, root nodes and leaf nodes ignore dependencies
    to other apps.
    """

    def __init__(self):
        self.nodes = {}
        self.dependencies = {}
        self.dependents = {}

    def add_node(self, node, implementation):
        self.nodes[node] = implementation

    def add_dependency(self, child, parent):
        if child not in self.nodes:
            raise KeyError("Dependency references nonexistent child node %r" % (child,))
        if parent not in self.nodes:
            raise KeyError("Dependency references nonexistent parent node %r" % (parent,))
        self.dependencies.setdefault(child, set()).add(parent)
        self.dependents.setdefault(parent, set()).add(child)

    def forwards_plan(self, node):
        """
        Given a node, returns a list of which previous nodes (dependencies)
        must be applied, ending with the node itself.
        This is the list you would follow if applying the migrations to
        a database.
        """
        if node not in self.nodes:
            raise ValueError("Node %r not a valid node" % (node, ))
        return self.dfs(node, lambda x: self.dependencies.get(x, set()))

    def backwards_plan(self, node):
        """
        Given a node, returns a list of which dependent nodes (dependencies)
        must be unapplied, ending with the node itself.
        This is the list you would follow if removing the migrations from
        a database.
        """
        if node not in self.nodes:
            raise ValueError("Node %r not a valid node" % (node, ))
        return self.dfs(node, lambda x: self.dependents.get(x, set()))

    def root_nodes(self):
        """
        Returns all root nodes - that is, nodes with no dependencies inside
        their app. These are the starting point for an app.
        """
        roots = set()
        for node in self.nodes:
            if not any(key[0] == node[0] for key in self.dependencies.get(node, set())):
                roots.add(node)
        return roots

    def leaf_nodes(self, app=None):
        """
        Returns all leaf nodes - that is, nodes with no dependents in their app.
        These are the "most current" version of an app's schema.
        Having more than one per app is technically an error, but one that
        gets handled further up, in the interactive command - it's usually the
        result of a VCS merge and needs some user input.
        """
        leaves = set()
        for node in self.nodes:
            if not any(key[0] == node[0] for key in self.dependents.get(node, set())) and (not app or app == node[0]):
                leaves.add(node)
        return leaves

    def dfs(self, start, get_children):
        """
        Dynamic programming based depth first search, for finding dependencies.
        """
        cache = {}

        def _dfs(start, get_children, path):
            # If we already computed this, use that (dynamic programming)
            if (start, get_children) in cache:
                return cache[(start, get_children)]
            # If we've traversed here before, that's a circular dep
            if start in path:
                raise CircularDependencyError(path[path.index(start):] + [start])
            # Build our own results list, starting with us
            results = []
            results.append(start)
            # We need to add to results all the migrations this one depends on
            children = sorted(get_children(start))
            path.append(start)
            for n in children:
                results = _dfs(n, get_children, path) + results
            path.pop()
            # Use OrderedSet to ensure only one instance of each result
            results = list(OrderedSet(results))
            # Populate DP cache
            cache[(start, get_children)] = results
            # Done!
            return results
        return _dfs(start, get_children, [])

    def __str__(self):
        return "Graph: %s nodes, %s edges" % (len(self.nodes), sum(len(x) for x in self.dependencies.values()))

    def project_state(self, nodes=None, at_end=True):
        """
        Given a migration node or nodes, returns a complete ProjectState for it.
        If at_end is False, returns the state before the migration has run.
        If nodes is not provided, returns the overall most current project state.
        """
        if nodes is None:
            nodes = list(self.leaf_nodes())
        if len(nodes) == 0:
            return ProjectState()
        if not isinstance(nodes[0], tuple):
            nodes = [nodes]
        plan = []
        for node in nodes:
            for migration in self.forwards_plan(node):
                if migration not in plan:
                    if not at_end and migration in nodes:
                        continue
                    plan.append(migration)
        project_state = ProjectState()
        for node in plan:
            project_state = self.nodes[node].mutate_state(project_state)
        return project_state


class CircularDependencyError(Exception):
    """
    Raised when there's an impossible-to-resolve circular dependency.
    """
    pass

########NEW FILE########
__FILENAME__ = loader
# Autogenerated from Django's django/db/migrations/loader.py - do not edit

from importlib import import_module
import os
import sys

from south.app_cache import app_cache
from django.utils import six
from django.conf import settings
from .recorder import MigrationRecorder
from .graph import MigrationGraph


class MigrationLoader(object):
    """
    Loads migration files from disk, and their status from the database.

    Migration files are expected to live in the "migrations" directory of
    an app. Their names are entirely unimportant from a code perspective,
    but will probably follow the 1234_name.py convention.

    On initialisation, this class will scan those directories, and open and
    read the python files, looking for a class called Migration, which should
    inherit from django.db.migrations.Migration. See
    django.db.migrations.migration for what that looks like.

    Some migrations will be marked as "replacing" another set of migrations.
    These are loaded into a separate set of migrations away from the main ones.
    If all the migrations they replace are either unapplied or missing from
    disk, then they are injected into the main set, replacing the named migrations.
    Any dependency pointers to the replaced migrations are re-pointed to the
    new migration.

    This does mean that this class MUST also talk to the database as well as
    to disk, but this is probably fine. We're already not just operating
    in memory.
    """

    def __init__(self, connection, load=True):
        self.connection = connection
        self.disk_migrations = None
        self.applied_migrations = None
        if load:
            self.build_graph()

    @classmethod
    def migrations_module(cls, app_label):
        if app_label in settings.MIGRATION_MODULES:
            return settings.MIGRATION_MODULES[app_label]
        else:
            return '%s.migrations' % app_cache.get_app_config(app_label).name

    def load_disk(self):
        """
        Loads the migrations from all INSTALLED_APPS from disk.
        """
        self.disk_migrations = {}
        self.unmigrated_apps = set()
        self.migrated_apps = set()
        for app_config in app_cache.get_app_configs(only_with_models_module=True):
            # Get the migrations module directory
            module_name = self.migrations_module(app_config.label)
            was_loaded = module_name in sys.modules
            try:
                module = import_module(module_name)
            except ImportError as e:
                # I hate doing this, but I don't want to squash other import errors.
                # Might be better to try a directory check directly.
                if "No module named" in str(e) and "migrations" in str(e):
                    self.unmigrated_apps.add(app_config.label)
                    continue
                raise
            else:
                # PY3 will happily import empty dirs as namespaces.
                if not hasattr(module, '__file__'):
                    continue
                # Module is not a package (e.g. migrations.py).
                if not hasattr(module, '__path__'):
                    continue
                # Force a reload if it's already loaded (tests need this)
                if was_loaded:
                    six.moves.reload_module(module)
            self.migrated_apps.add(app_config.label)
            directory = os.path.dirname(module.__file__)
            # Scan for .py[c|o] files
            migration_names = set()
            for name in os.listdir(directory):
                if name.endswith(".py") or name.endswith(".pyc") or name.endswith(".pyo"):
                    import_name = name.rsplit(".", 1)[0]
                    if import_name[0] not in "_.~":
                        migration_names.add(import_name)
            # Load them
            south_style_migrations = False
            for migration_name in migration_names:
                try:
                    migration_module = import_module("%s.%s" % (module_name, migration_name))
                except ImportError as e:
                    # Ignore South import errors, as we're triggering them
                    if "south" in str(e).lower() or "no module named db" in str(e).lower():
                        south_style_migrations = True
                        break
                    raise
                if not hasattr(migration_module, "Migration"):
                    raise BadMigrationError("Migration %s in app %s has no Migration class" % (migration_name, app_config.label))
                # Ignore South-style migrations
                if hasattr(migration_module.Migration, "forwards"):
                    south_style_migrations = True
                    break
                self.disk_migrations[app_config.label, migration_name] = migration_module.Migration(migration_name, app_config.label)
            if south_style_migrations:
                self.unmigrated_apps.add(app_config.label)

    def get_migration(self, app_label, name_prefix):
        "Gets the migration exactly named, or raises KeyError"
        return self.graph.nodes[app_label, name_prefix]

    def get_migration_by_prefix(self, app_label, name_prefix):
        "Returns the migration(s) which match the given app label and name _prefix_"
        # Do the search
        results = []
        for l, n in self.disk_migrations:
            if l == app_label and n.startswith(name_prefix):
                results.append((l, n))
        if len(results) > 1:
            raise AmbiguityError("There is more than one migration for '%s' with the prefix '%s'" % (app_label, name_prefix))
        elif len(results) == 0:
            raise KeyError("There no migrations for '%s' with the prefix '%s'" % (app_label, name_prefix))
        else:
            return self.disk_migrations[results[0]]

    def build_graph(self):
        """
        Builds a migration dependency graph using both the disk and database.
        You'll need to rebuild the graph if you apply migrations. This isn't
        usually a problem as generally migration stuff runs in a one-shot process.
        """
        # Load disk data
        self.load_disk()
        # Load database data
        recorder = MigrationRecorder(self.connection)
        self.applied_migrations = recorder.applied_migrations()
        # Do a first pass to separate out replacing and non-replacing migrations
        normal = {}
        replacing = {}
        for key, migration in self.disk_migrations.items():
            if migration.replaces:
                replacing[key] = migration
            else:
                normal[key] = migration
        # Calculate reverse dependencies - i.e., for each migration, what depends on it?
        # This is just for dependency re-pointing when applying replacements,
        # so we ignore run_before here.
        reverse_dependencies = {}
        for key, migration in normal.items():
            for parent in migration.dependencies:
                reverse_dependencies.setdefault(parent, set()).add(key)
        # Carry out replacements if we can - that is, if all replaced migrations
        # are either unapplied or missing.
        for key, migration in replacing.items():
            # Ensure this replacement migration is not in applied_migrations
            self.applied_migrations.discard(key)
            # Do the check. We can replace if all our replace targets are
            # applied, or if all of them are unapplied.
            applied_statuses = [(target in self.applied_migrations) for target in migration.replaces]
            can_replace = all(applied_statuses) or (not any(applied_statuses))
            if not can_replace:
                continue
            # Alright, time to replace. Step through the replaced migrations
            # and remove, repointing dependencies if needs be.
            for replaced in migration.replaces:
                if replaced in normal:
                    # We don't care if the replaced migration doesn't exist;
                    # the usage pattern here is to delete things after a while.
                    del normal[replaced]
                for child_key in reverse_dependencies.get(replaced, set()):
                    if child_key in migration.replaces:
                        continue
                    normal[child_key].dependencies.remove(replaced)
                    normal[child_key].dependencies.append(key)
            normal[key] = migration
            # Mark the replacement as applied if all its replaced ones are
            if all(applied_statuses):
                self.applied_migrations.add(key)
        # Finally, make a graph and load everything into it
        self.graph = MigrationGraph()
        for key, migration in normal.items():
            self.graph.add_node(key, migration)
        for key, migration in normal.items():
            for parent in migration.dependencies:
                self.graph.add_dependency(key, parent)

    def detect_conflicts(self):
        """
        Looks through the loaded graph and detects any conflicts - apps
        with more than one leaf migration. Returns a dict of the app labels
        that conflict with the migration names that conflict.
        """
        seen_apps = {}
        conflicting_apps = set()
        for app_label, migration_name in self.graph.leaf_nodes():
            if app_label in seen_apps:
                conflicting_apps.add(app_label)
            seen_apps.setdefault(app_label, set()).add(migration_name)
        return dict((app_label, seen_apps[app_label]) for app_label in conflicting_apps)


class BadMigrationError(Exception):
    """
    Raised when there's a bad migration (unreadable/bad format/etc.)
    """
    pass


class AmbiguityError(Exception):
    """
    Raised when more than one migration matches a name prefix
    """
    pass

########NEW FILE########
__FILENAME__ = makemigrations
# Autogenerated from Django's django/core/management/commands/makemigrations.py - do not edit

import sys
import os
import operator
from optparse import make_option

from south.app_cache import app_cache
from django.core.management.base import BaseCommand, CommandError
from django.db import connections, DEFAULT_DB_ALIAS, migrations
from south.loader import MigrationLoader
from south.autodetector import MigrationAutodetector
from south.questioner import MigrationQuestioner, InteractiveMigrationQuestioner
from south.state import ProjectState
from south.writer import MigrationWriter
from django.utils.six.moves import reduce


class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('--dry-run', action='store_true', dest='dry_run', default=False,
            help="Just show what migrations would be made; don't actually write them."),
        make_option('--merge', action='store_true', dest='merge', default=False,
            help="Enable fixing of migration conflicts."),
    )

    help = "Creates new migration(s) for apps."
    usage_str = "Usage: ./manage.py makemigrations [--dry-run] [app [app ...]]"

    def handle(self, *app_labels, **options):

        self.verbosity = int(options.get('verbosity'))
        self.interactive = options.get('interactive')
        self.dry_run = options.get('dry_run', False)
        self.merge = options.get('merge', False)

        # Make sure the app they asked for exists
        app_labels = set(app_labels)
        bad_app_labels = set()
        for app_label in app_labels:
            try:
                app_cache.get_app_config(app_label)
            except LookupError:
                bad_app_labels.add(app_label)
        if bad_app_labels:
            for app_label in bad_app_labels:
                self.stderr.write("App '%s' could not be found. Is it in INSTALLED_APPS?" % app_label)
            sys.exit(2)

        # Load the current graph state. Takes a connection, but it's not used
        # (makemigrations doesn't look at the database state).
        loader = MigrationLoader(connections[DEFAULT_DB_ALIAS])

        # Before anything else, see if there's conflicting apps and drop out
        # hard if there are any and they don't want to merge
        conflicts = loader.detect_conflicts()
        if conflicts and not self.merge:
            name_str = "; ".join(
                "%s in %s" % (", ".join(names), app)
                for app, names in conflicts.items()
            )
            raise CommandError("Conflicting migrations detected (%s).\nTo fix them run 'python manage.py makemigrations --merge'" % name_str)

        # If they want to merge and there's nothing to merge, then politely exit
        if self.merge and not conflicts:
            self.stdout.write("No conflicts detected to merge.")
            return

        # If they want to merge and there is something to merge, then
        # divert into the merge code
        if self.merge and conflicts:
            return self.handle_merge(loader, conflicts)

        # Detect changes
        autodetector = MigrationAutodetector(
            loader.graph.project_state(),
            ProjectState.from_app_cache(app_cache),
            InteractiveMigrationQuestioner(specified_apps=app_labels),
        )
        changes = autodetector.changes(graph=loader.graph, trim_to_apps=app_labels or None)

        # No changes? Tell them.
        if not changes and self.verbosity >= 1:
            if len(app_labels) == 1:
                self.stdout.write("No changes detected in app '%s'" % app_labels.pop())
            elif len(app_labels) > 1:
                self.stdout.write("No changes detected in apps '%s'" % ("', '".join(app_labels)))
            else:
                self.stdout.write("No changes detected")
            return

        directory_created = {}
        for app_label, app_migrations in changes.items():
            if self.verbosity >= 1:
                self.stdout.write(self.style.MIGRATE_HEADING("Migrations for '%s':" % app_label) + "\n")
            for migration in app_migrations:
                # Describe the migration
                writer = MigrationWriter(migration)
                if self.verbosity >= 1:
                    self.stdout.write("  %s:\n" % (self.style.MIGRATE_LABEL(writer.filename),))
                    for operation in migration.operations:
                        self.stdout.write("    - %s\n" % operation.describe())
                # Write it
                if not self.dry_run:
                    migrations_directory = os.path.dirname(writer.path)
                    if not directory_created.get(app_label, False):
                        if not os.path.isdir(migrations_directory):
                            os.mkdir(migrations_directory)
                        init_path = os.path.join(migrations_directory, "__init__.py")
                        if not os.path.isfile(init_path):
                            open(init_path, "w").close()
                        # We just do this once per app
                        directory_created[app_label] = True
                    migration_string = writer.as_string()
                    with open(writer.path, "wb") as fh:
                        fh.write(migration_string)

    def handle_merge(self, loader, conflicts):
        """
        Handles merging together conflicted migrations interactively,
        if it's safe; otherwise, advises on how to fix it.
        """
        if self.interactive:
            questioner = InteractiveMigrationQuestioner()
        else:
            questioner = MigrationQuestioner()
        for app_label, migration_names in conflicts.items():
            # Grab out the migrations in question, and work out their
            # common ancestor.
            merge_migrations = []
            for migration_name in migration_names:
                migration = loader.get_migration(app_label, migration_name)
                migration.ancestry = loader.graph.forwards_plan((app_label, migration_name))
                merge_migrations.append(migration)
            common_ancestor = None
            for level in zip(*[m.ancestry for m in merge_migrations]):
                if reduce(operator.eq, level):
                    common_ancestor = level[0]
                else:
                    break
            if common_ancestor is None:
                raise ValueError("Could not find common ancestor of %s" % migration_names)
            # Now work out the operations along each divergent branch
            for migration in merge_migrations:
                migration.branch = migration.ancestry[
                    (migration.ancestry.index(common_ancestor) + 1):
                ]
                migration.merged_operations = []
                for node_app, node_name in migration.branch:
                    migration.merged_operations.extend(
                        loader.get_migration(node_app, node_name).operations
                    )
            # In future, this could use some of the Optimizer code
            # (can_optimize_through) to automatically see if they're
            # mergeable. For now, we always just prompt the user.
            if self.verbosity > 0:
                self.stdout.write(self.style.MIGRATE_HEADING("Merging %s" % app_label))
                for migration in merge_migrations:
                    self.stdout.write(self.style.MIGRATE_LABEL("  Branch %s" % migration.name))
                    for operation in migration.merged_operations:
                        self.stdout.write("    - %s\n" % operation.describe())
            if questioner.ask_merge(app_label):
                # If they still want to merge it, then write out an empty
                # file depending on the migrations needing merging.
                numbers = [
                    MigrationAutodetector.parse_number(migration.name)
                    for migration in merge_migrations
                ]
                try:
                    biggest_number = max([x for x in numbers if x is not None])
                except ValueError:
                    biggest_number = 1
                subclass = type("Migration", (migrations.Migration, ), {
                    "dependencies": [(app_label, migration.name) for migration in merge_migrations],
                })
                new_migration = subclass("%04i_merge" % (biggest_number + 1), app_label)
                writer = MigrationWriter(new_migration)
                with open(writer.path, "wb") as fh:
                    fh.write(writer.as_string())
                if self.verbosity > 0:
                    self.stdout.write("\nCreated new merge migration %s" % writer.path)

########NEW FILE########
__FILENAME__ = migrate
# Autogenerated from Django's django/core/management/commands/migrate.py - do not edit

# encoding: utf8
from __future__ import unicode_literals
from optparse import make_option
from collections import OrderedDict
from importlib import import_module
import itertools
import traceback

from django.conf import settings
from south.app_cache import app_cache
from django.core.management import call_command
from django.core.management.base import BaseCommand, CommandError
from django.core.management.color import no_style
from django.core.management.sql import custom_sql_for_model, emit_post_migrate_signal, emit_pre_migrate_signal
from django.db import connections, router, transaction, DEFAULT_DB_ALIAS
from south.executor import MigrationExecutor
from south.loader import MigrationLoader, AmbiguityError
from south.state import ProjectState
from south.autodetector import MigrationAutodetector
from django.utils.module_loading import module_has_submodule


class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option('--noinput', action='store_false', dest='interactive', default=True,
            help='Tells Django to NOT prompt the user for input of any kind.'),
        make_option('--no-initial-data', action='store_false', dest='load_initial_data', default=True,
            help='Tells Django not to load any initial data after database synchronization.'),
        make_option('--database', action='store', dest='database',
            default=DEFAULT_DB_ALIAS, help='Nominates a database to synchronize. '
                'Defaults to the "default" database.'),
        make_option('--fake', action='store_true', dest='fake', default=False,
            help='Mark migrations as run without actually running them'),
        make_option('--list', '-l', action='store_true', dest='list', default=False,
            help='Show a list of all known migrations and which are applied'),
    )

    help = "Updates database schema. Manages both apps with migrations and those without."

    def handle(self, *args, **options):

        self.verbosity = int(options.get('verbosity'))
        self.interactive = options.get('interactive')
        self.show_traceback = options.get('traceback')
        self.load_initial_data = options.get('load_initial_data')
        self.test_database = options.get('test_database', False)

        # Import the 'management' module within each installed app, to register
        # dispatcher events.
        for app_name in settings.INSTALLED_APPS:
            if module_has_submodule(import_module(app_name), "management"):
                import_module('.management', app_name)

        # Get the database we're operating from
        db = options.get('database')
        connection = connections[db]

        # If they asked for a migration listing, quit main execution flow and show it
        if options.get("list", False):
            return self.show_migration_list(connection, args)

        # Work out which apps have migrations and which do not
        executor = MigrationExecutor(connection, self.migration_progress_callback)

        # Before anything else, see if there's conflicting apps and drop out
        # hard if there are any
        conflicts = executor.loader.detect_conflicts()
        if conflicts:
            name_str = "; ".join(
                "%s in %s" % (", ".join(names), app)
                for app, names in conflicts.items()
            )
            raise CommandError("Conflicting migrations detected (%s).\nTo fix them run 'python manage.py makemigrations --merge'" % name_str)

        # If they supplied command line arguments, work out what they mean.
        run_syncdb = False
        target_app_labels_only = True
        if len(args) > 2:
            raise CommandError("Too many command-line arguments (expecting 'appname' or 'appname migrationname')")
        elif len(args) == 2:
            app_label, migration_name = args
            if app_label not in executor.loader.migrated_apps:
                raise CommandError("App '%s' does not have migrations (you cannot selectively sync unmigrated apps)" % app_label)
            if migration_name == "zero":
                targets = [(app_label, None)]
            else:
                try:
                    migration = executor.loader.get_migration_by_prefix(app_label, migration_name)
                except AmbiguityError:
                    raise CommandError("More than one migration matches '%s' in app '%s'. Please be more specific." % (app_label, migration_name))
                except KeyError:
                    raise CommandError("Cannot find a migration matching '%s' from app '%s'." % (app_label, migration_name))
                targets = [(app_label, migration.name)]
            target_app_labels_only = False
        elif len(args) == 1:
            app_label = args[0]
            if app_label not in executor.loader.migrated_apps:
                raise CommandError("App '%s' does not have migrations (you cannot selectively sync unmigrated apps)" % app_label)
            targets = [key for key in executor.loader.graph.leaf_nodes() if key[0] == app_label]
        else:
            targets = executor.loader.graph.leaf_nodes()
            run_syncdb = True

        plan = executor.migration_plan(targets)

        # Print some useful info
        if self.verbosity >= 1:
            self.stdout.write(self.style.MIGRATE_HEADING("Operations to perform:"))
            if run_syncdb:
                self.stdout.write(self.style.MIGRATE_LABEL("  Synchronize unmigrated apps: ") + (", ".join(executor.loader.unmigrated_apps) or "(none)"))
            if target_app_labels_only:
                self.stdout.write(self.style.MIGRATE_LABEL("  Apply all migrations: ") + (", ".join(set(a for a, n in targets)) or "(none)"))
            else:
                if targets[0][1] is None:
                    self.stdout.write(self.style.MIGRATE_LABEL("  Unapply all migrations: ") + "%s" % (targets[0][0], ))
                else:
                    self.stdout.write(self.style.MIGRATE_LABEL("  Target specific migration: ") + "%s, from %s" % (targets[0][1], targets[0][0]))

        # Run the syncdb phase.
        # If you ever manage to get rid of this, I owe you many, many drinks.
        # Note that pre_migrate is called from inside here, as it needs
        # the list of models about to be installed.
        if run_syncdb:
            if self.verbosity >= 1:
                self.stdout.write(self.style.MIGRATE_HEADING("Synchronizing apps without migrations:"))
            created_models = self.sync_apps(connection, executor.loader.unmigrated_apps)
        else:
            created_models = []

        # Migrate!
        if self.verbosity >= 1:
            self.stdout.write(self.style.MIGRATE_HEADING("Running migrations:"))
        if not plan:
            if self.verbosity >= 1:
                self.stdout.write("  No migrations needed.")
                # If there's changes that aren't in migrations yet, tell them how to fix it.
                autodetector = MigrationAutodetector(
                    executor.loader.graph.project_state(),
                    ProjectState.from_app_cache(app_cache),
                )
                changes = autodetector.changes(graph=executor.loader.graph)
                if changes:
                    self.stdout.write(self.style.NOTICE("  Your models have changes that are not yet reflected in a migration, and so won't be applied."))
                    self.stdout.write(self.style.NOTICE("  Run 'manage.py makemigrations' to make new migrations, and then re-run 'manage.py migrate' to apply them."))
        else:
            executor.migrate(targets, plan, fake=options.get("fake", False))

        # Send the post_migrate signal, so individual apps can do whatever they need
        # to do at this point.
        emit_post_migrate_signal(created_models, self.verbosity, self.interactive, connection.alias)

    def migration_progress_callback(self, action, migration, fake=False):
        if self.verbosity >= 1:
            if action == "apply_start":
                self.stdout.write("  Applying %s..." % migration, ending="")
                self.stdout.flush()
            elif action == "apply_success":
                if fake:
                    self.stdout.write(self.style.MIGRATE_SUCCESS(" FAKED"))
                else:
                    self.stdout.write(self.style.MIGRATE_SUCCESS(" OK"))
            elif action == "unapply_start":
                self.stdout.write("  Unapplying %s..." % migration, ending="")
                self.stdout.flush()
            elif action == "unapply_success":
                if fake:
                    self.stdout.write(self.style.MIGRATE_SUCCESS(" FAKED"))
                else:
                    self.stdout.write(self.style.MIGRATE_SUCCESS(" OK"))

    def sync_apps(self, connection, apps):
        "Runs the old syncdb-style operation on a list of apps."
        cursor = connection.cursor()

        # Get a list of already installed *models* so that references work right.
        tables = connection.introspection.table_names()
        seen_models = connection.introspection.installed_models(tables)
        created_models = set()
        pending_references = {}

        # Build the manifest of apps and models that are to be synchronized
        all_models = [
            (app_config.label,
                router.get_migratable_models(app_config.models_module, connection.alias, include_auto_created=True))
            for app_config in app_cache.get_app_configs(only_with_models_module=True)
            if app_config.label in apps
        ]

        def model_installed(model):
            opts = model._meta
            converter = connection.introspection.table_name_converter
            # Note that if a model is unmanaged we short-circuit and never try to install it
            return not ((converter(opts.db_table) in tables) or
                (opts.auto_created and converter(opts.auto_created._meta.db_table) in tables))

        manifest = OrderedDict(
            (app_name, list(filter(model_installed, model_list)))
            for app_name, model_list in all_models
        )

        create_models = set(itertools.chain(*manifest.values()))
        emit_pre_migrate_signal(create_models, self.verbosity, self.interactive, connection.alias)

        # Create the tables for each model
        if self.verbosity >= 1:
            self.stdout.write("  Creating tables...\n")
        with transaction.atomic(using=connection.alias, savepoint=False):
            for app_name, model_list in manifest.items():
                for model in model_list:
                    # Create the model's database table, if it doesn't already exist.
                    if self.verbosity >= 3:
                        self.stdout.write("    Processing %s.%s model\n" % (app_name, model._meta.object_name))
                    sql, references = connection.creation.sql_create_model(model, no_style(), seen_models)
                    seen_models.add(model)
                    created_models.add(model)
                    for refto, refs in references.items():
                        pending_references.setdefault(refto, []).extend(refs)
                        if refto in seen_models:
                            sql.extend(connection.creation.sql_for_pending_references(refto, no_style(), pending_references))
                    sql.extend(connection.creation.sql_for_pending_references(model, no_style(), pending_references))
                    if self.verbosity >= 1 and sql:
                        self.stdout.write("    Creating table %s\n" % model._meta.db_table)
                    for statement in sql:
                        cursor.execute(statement)
                    tables.append(connection.introspection.table_name_converter(model._meta.db_table))

        # We force a commit here, as that was the previous behaviour.
        # If you can prove we don't need this, remove it.
        transaction.set_dirty(using=connection.alias)

        # The connection may have been closed by a syncdb handler.
        cursor = connection.cursor()

        # Install custom SQL for the app (but only if this
        # is a model we've just created)
        if self.verbosity >= 1:
            self.stdout.write("  Installing custom SQL...\n")
        for app_name, model_list in manifest.items():
            for model in model_list:
                if model in created_models:
                    custom_sql = custom_sql_for_model(model, no_style(), connection)
                    if custom_sql:
                        if self.verbosity >= 2:
                            self.stdout.write("    Installing custom SQL for %s.%s model\n" % (app_name, model._meta.object_name))
                        try:
                            with transaction.commit_on_success_unless_managed(using=connection.alias):
                                for sql in custom_sql:
                                    cursor.execute(sql)
                        except Exception as e:
                            self.stderr.write("    Failed to install custom SQL for %s.%s model: %s\n" % (app_name, model._meta.object_name, e))
                            if self.show_traceback:
                                traceback.print_exc()
                    else:
                        if self.verbosity >= 3:
                            self.stdout.write("    No custom SQL for %s.%s model\n" % (app_name, model._meta.object_name))

        if self.verbosity >= 1:
            self.stdout.write("  Installing indexes...\n")

        # Install SQL indices for all newly created models
        for app_name, model_list in manifest.items():
            for model in model_list:
                if model in created_models:
                    index_sql = connection.creation.sql_indexes_for_model(model, no_style())
                    if index_sql:
                        if self.verbosity >= 2:
                            self.stdout.write("    Installing index for %s.%s model\n" % (app_name, model._meta.object_name))
                        try:
                            with transaction.commit_on_success_unless_managed(using=connection.alias):
                                for sql in index_sql:
                                    cursor.execute(sql)
                        except Exception as e:
                            self.stderr.write("    Failed to install index for %s.%s model: %s\n" % (app_name, model._meta.object_name, e))

        # Load initial_data fixtures (unless that has been disabled)
        if self.load_initial_data:
            call_command('loaddata', 'initial_data', verbosity=self.verbosity, database=connection.alias, skip_validation=True)

        return created_models

    def show_migration_list(self, connection, apps=None):
        """
        Shows a list of all migrations on the system, or only those of
        some named apps.
        """
        # Load migrations from disk/DB
        loader = MigrationLoader(connection)
        graph = loader.graph
        # If we were passed a list of apps, validate it
        if apps:
            invalid_apps = []
            for app in apps:
                if app not in loader.migrated_apps:
                    invalid_apps.append(app)
            if invalid_apps:
                raise CommandError("No migrations present for: %s" % (", ".join(invalid_apps)))
        # Otherwise, show all apps in alphabetic order
        else:
            apps = sorted(loader.migrated_apps)
        # For each app, print its migrations in order from oldest (roots) to
        # newest (leaves).
        for app in apps:
            self.stdout.write(app, self.style.MIGRATE_LABEL)
            shown = set()
            for node in graph.leaf_nodes(app):
                for plan_node in graph.forwards_plan(node):
                    if plan_node not in shown and plan_node[0] == app:
                        # Give it a nice title if it's a squashed one
                        title = plan_node[1]
                        if graph.nodes[plan_node].replaces:
                            title += " (%s squashed migrations)" % len(graph.nodes[plan_node].replaces)
                        # Mark it as applied/unapplied
                        if plan_node in loader.applied_migrations:
                            self.stdout.write(" [X] %s" % title)
                        else:
                            self.stdout.write(" [ ] %s" % title)
                        shown.add(plan_node)
            # If we didn't print anything, then a small message
            if not shown:
                self.stdout.write(" (no migrations)", self.style.MIGRATE_FAILURE)

########NEW FILE########
__FILENAME__ = sqlmigrate
# Autogenerated from Django's django/core/management/commands/sqlmigrate.py - do not edit

# encoding: utf8
from __future__ import unicode_literals
from optparse import make_option

from django.core.management.base import BaseCommand, CommandError
from django.db import connections, DEFAULT_DB_ALIAS
from south.executor import MigrationExecutor
from south.loader import AmbiguityError


class Command(BaseCommand):

    option_list = BaseCommand.option_list + (
        make_option('--database', action='store', dest='database',
            default=DEFAULT_DB_ALIAS, help='Nominates a database to create SQL for. '
                'Defaults to the "default" database.'),
        make_option('--backwards', action='store_true', dest='backwards',
            default=False, help='Creates SQL to unapply the migration, rather than to apply it'),
    )

    help = "Prints the SQL statements for the named migration."

    def handle(self, *args, **options):

        # Get the database we're operating from
        db = options.get('database')
        connection = connections[db]

        # Load up an executor to get all the migration data
        executor = MigrationExecutor(connection)

        # Resolve command-line arguments into a migration
        if len(args) != 2:
            raise CommandError("Wrong number of arguments (expecting 'sqlmigrate appname migrationname')")
        else:
            app_label, migration_name = args
            if app_label not in executor.loader.migrated_apps:
                raise CommandError("App '%s' does not have migrations" % app_label)
            try:
                migration = executor.loader.get_migration_by_prefix(app_label, migration_name)
            except AmbiguityError:
                raise CommandError("More than one migration matches '%s' in app '%s'. Please be more specific." % (app_label, migration_name))
            except KeyError:
                raise CommandError("Cannot find a migration matching '%s' from app '%s'. Is it in INSTALLED_APPS?" % (app_label, migration_name))
            targets = [(app_label, migration.name)]

        # Make a plan that represents just the requested migrations and show SQL
        # for it
        plan = [(executor.loader.graph.nodes[targets[0]], options.get("backwards", False))]
        sql_statements = executor.collect_sql(plan)
        for statement in sql_statements:
            self.stdout.write(statement)

########NEW FILE########
__FILENAME__ = syncdb
# Autogenerated from Django's django/core/management/commands/syncdb.py - do not edit

import warnings
from optparse import make_option
from django.db import DEFAULT_DB_ALIAS
from django.core.management import call_command
from django.core.management.base import NoArgsCommand


class Command(NoArgsCommand):
    option_list = NoArgsCommand.option_list + (
        make_option('--noinput', action='store_false', dest='interactive', default=True,
            help='Tells Django to NOT prompt the user for input of any kind.'),
        make_option('--no-initial-data', action='store_false', dest='load_initial_data', default=True,
            help='Tells Django not to load any initial data after database synchronization.'),
        make_option('--database', action='store', dest='database',
            default=DEFAULT_DB_ALIAS, help='Nominates a database to synchronize. '
                'Defaults to the "default" database.'),
    )
    help = "Deprecated - use 'migrate' instead."

    def handle_noargs(self, **options):
        warnings.warn("The syncdb command will be removed in Django 1.9", PendingDeprecationWarning)
        call_command("migrate", **options)

########NEW FILE########
__FILENAME__ = migration
# Autogenerated from Django's django/db/migrations/migration.py - do not edit

class Migration(object):
    """
    The base class for all migrations.

    Migration files will import this from django.db.migrations.Migration
    and subclass it as a class called Migration. It will have one or more
    of the following attributes:

     - operations: A list of Operation instances, probably from django.db.migrations.operations
     - dependencies: A list of tuples of (app_path, migration_name)
     - run_before: A list of tuples of (app_path, migration_name)
     - replaces: A list of migration_names

    Note that all migrations come out of migrations and into the Loader or
    Graph as instances, having been initialised with their app label and name.
    """

    # Operations to apply during this migration, in order.
    operations = []

    # Other migrations that should be run before this migration.
    # Should be a list of (app, migration_name).
    dependencies = []

    # Other migrations that should be run after this one (i.e. have
    # this migration added to their dependencies). Useful to make third-party
    # apps' migrations run after your AUTH_USER replacement, for example.
    run_before = []

    # Migration names in this app that this migration replaces. If this is
    # non-empty, this migration will only be applied if all these migrations
    # are not applied.
    replaces = []

    # Error class which is raised when a migration is irreversible
    class IrreversibleError(RuntimeError):
        pass

    def __init__(self, name, app_label):
        self.name = name
        self.app_label = app_label
        # Copy dependencies & other attrs as we might mutate them at runtime
        self.operations = list(self.__class__.operations)
        self.dependencies = list(self.__class__.dependencies)
        self.run_before = list(self.__class__.run_before)
        self.replaces = list(self.__class__.replaces)

    def __eq__(self, other):
        if not isinstance(other, Migration):
            return False
        return (self.name == other.name) and (self.app_label == other.app_label)

    def __ne__(self, other):
        return not (self == other)

    def __repr__(self):
        return "<Migration %s.%s>" % (self.app_label, self.name)

    def __str__(self):
        return "%s.%s" % (self.app_label, self.name)

    def __hash__(self):
        return hash("%s.%s" % (self.app_label, self.name))

    def mutate_state(self, project_state):
        """
        Takes a ProjectState and returns a new one with the migration's
        operations applied to it.
        """
        new_state = project_state.clone()
        for operation in self.operations:
            operation.state_forwards(self.app_label, new_state)
        return new_state

    def apply(self, project_state, schema_editor, collect_sql=False):
        """
        Takes a project_state representing all migrations prior to this one
        and a schema_editor for a live database and applies the migration
        in a forwards order.

        Returns the resulting project state for efficient re-use by following
        Migrations.
        """
        for operation in self.operations:
            # If this operation cannot be represented as SQL, place a comment
            # there instead
            if collect_sql and not operation.reduces_to_sql:
                schema_editor.collected_sql.append("--")
                schema_editor.collected_sql.append("-- MIGRATION NOW PERFORMS OPERATION THAT CANNOT BE WRITTEN AS SQL:")
                schema_editor.collected_sql.append("-- %s" % operation.describe())
                schema_editor.collected_sql.append("--")
                continue
            # Get the state after the operation has run
            new_state = project_state.clone()
            operation.state_forwards(self.app_label, new_state)
            # Run the operation
            operation.database_forwards(self.app_label, schema_editor, project_state, new_state)
            # Switch states
            project_state = new_state
        return project_state

    def unapply(self, project_state, schema_editor, collect_sql=False):
        """
        Takes a project_state representing all migrations prior to this one
        and a schema_editor for a live database and applies the migration
        in a reverse order.
        """
        # We need to pre-calculate the stack of project states
        to_run = []
        for operation in self.operations:
            # If this operation cannot be represented as SQL, place a comment
            # there instead
            if collect_sql and not operation.reduces_to_sql:
                schema_editor.collected_sql.append("--")
                schema_editor.collected_sql.append("-- MIGRATION NOW PERFORMS OPERATION THAT CANNOT BE WRITTEN AS SQL:")
                schema_editor.collected_sql.append("-- %s" % operation.describe())
                schema_editor.collected_sql.append("--")
                continue
            # If it's irreversible, error out
            if not operation.reversible:
                raise Migration.IrreversibleError("Operation %s in %s is not reversible" % (operation, self))
            new_state = project_state.clone()
            operation.state_forwards(self.app_label, new_state)
            to_run.append((operation, project_state, new_state))
            project_state = new_state
        # Now run them in reverse
        to_run.reverse()
        for operation, to_state, from_state in to_run:
            operation.database_backwards(self.app_label, schema_editor, from_state, to_state)

########NEW FILE########
__FILENAME__ = migrations
# Placeholder for django.db.migrations and imports people use from that

from .migration import Migration  # NOQA
from .operations import *  # NOQA

########NEW FILE########
__FILENAME__ = models
# Empty models file, as 1.6 and below needs this for installable apps.

########NEW FILE########
__FILENAME__ = base
# Autogenerated from Django's django/db/migrations/operations/base.py - do not edit

class Operation(object):
    """
    Base class for migration operations.

    It's responsible for both mutating the in-memory model state
    (see db/migrations/state.py) to represent what it performs, as well
    as actually performing it against a live database.

    Note that some operations won't modify memory state at all (e.g. data
    copying operations), and some will need their modifications to be
    optionally specified by the user (e.g. custom Python code snippets)

    Due to the way this class deals with deconstruction, it should be
    considered immutable.
    """

    # If this migration can be run in reverse.
    # Some operations are impossible to reverse, like deleting data.
    reversible = True

    # Can this migration be represented as SQL? (things like RunPython cannot)
    reduces_to_sql = True

    def __new__(cls, *args, **kwargs):
        # We capture the arguments to make returning them trivial
        self = object.__new__(cls)
        self._constructor_args = (args, kwargs)
        return self

    def deconstruct(self):
        """
        Returns a 3-tuple of class import path (or just name if it lives
        under django.db.migrations), positional arguments, and keyword
        arguments.
        """
        return (
            self.__class__.__name__,
            self._constructor_args[0],
            self._constructor_args[1],
        )

    def state_forwards(self, app_label, state):
        """
        Takes the state from the previous migration, and mutates it
        so that it matches what this migration would perform.
        """
        raise NotImplementedError('subclasses of Operation must provide a state_forwards() method')

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        """
        Performs the mutation on the database schema in the normal
        (forwards) direction.
        """
        raise NotImplementedError('subclasses of Operation must provide a database_forwards() method')

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        """
        Performs the mutation on the database schema in the reverse
        direction - e.g. if this were CreateModel, it would in fact
        drop the model's table.
        """
        raise NotImplementedError('subclasses of Operation must provide a database_backwards() method')

    def describe(self):
        """
        Outputs a brief summary of what the action does.
        """
        return "%s: %s" % (self.__class__.__name__, self._constructor_args)

    def references_model(self, name, app_label=None):
        """
        Returns True if there is a chance this operation references the given
        model name (as a string), with an optional app label for accuracy.

        Used for optimization. If in doubt, return True;
        returning a false positive will merely make the optimizer a little
        less efficient, while returning a false negative may result in an
        unusable optimized migration.
        """
        return True

    def references_field(self, model_name, name, app_label=None):
        """
        Returns True if there is a chance this operation references the given
        field name, with an optional app label for accuracy.

        Used for optimization. If in doubt, return True.
        """
        return self.references_model(model_name, app_label)

    def __repr__(self):
        return "<%s %s%s>" % (
            self.__class__.__name__,
            ", ".join(map(repr, self._constructor_args[0])),
            ",".join(" %s=%r" % x for x in self._constructor_args[1].items()),
        )

    def __eq__(self, other):
        return (self.__class__ == other.__class__) and (self.deconstruct() == other.deconstruct())

    def __ne__(self, other):
        return not (self == other)

########NEW FILE########
__FILENAME__ = fields
# Autogenerated from Django's django/db/migrations/operations/fields.py - do not edit

from django.db import router
from django.db.models.fields import NOT_PROVIDED
from .base import Operation


class AddField(Operation):
    """
    Adds a field to a model.
    """

    def __init__(self, model_name, name, field, preserve_default=True):
        self.model_name = model_name
        self.name = name
        self.field = field
        self.preserve_default = preserve_default

    def state_forwards(self, app_label, state):
        # If preserve default is off, don't use the default for future state
        if not self.preserve_default:
            field = self.field.clone()
            field.default = NOT_PROVIDED
        else:
            field = self.field
        state.models[app_label, self.model_name.lower()].fields.append((self.name, field))

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        to_model = to_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, to_model):
            schema_editor.add_field(from_model, to_model._meta.get_field_by_name(self.name)[0])

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, from_model):
            schema_editor.remove_field(from_model, from_model._meta.get_field_by_name(self.name)[0])

    def describe(self):
        return "Add field %s to %s" % (self.name, self.model_name)

    def __eq__(self, other):
        return (
            (self.__class__ == other.__class__) and
            (self.name == other.name) and
            (self.model_name.lower() == other.model_name.lower()) and
            (self.field.deconstruct()[1:] == other.field.deconstruct()[1:])
        )

    def references_model(self, name, app_label=None):
        return name.lower() == self.model_name.lower()

    def references_field(self, model_name, name, app_label=None):
        return self.references_model(model_name) and name.lower() == self.name.lower()


class RemoveField(Operation):
    """
    Removes a field from a model.
    """

    def __init__(self, model_name, name):
        self.model_name = model_name
        self.name = name

    def state_forwards(self, app_label, state):
        new_fields = []
        for name, instance in state.models[app_label, self.model_name.lower()].fields:
            if name != self.name:
                new_fields.append((name, instance))
        state.models[app_label, self.model_name.lower()].fields = new_fields

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, from_model):
            schema_editor.remove_field(from_model, from_model._meta.get_field_by_name(self.name)[0])

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        to_model = to_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, to_model):
            schema_editor.add_field(from_model, to_model._meta.get_field_by_name(self.name)[0])

    def describe(self):
        return "Remove field %s from %s" % (self.name, self.model_name)

    def references_model(self, name, app_label=None):
        return name.lower() == self.model_name.lower()

    def references_field(self, model_name, name, app_label=None):
        return self.references_model(model_name) and name.lower() == self.name.lower()


class AlterField(Operation):
    """
    Alters a field's database column (e.g. null, max_length) to the provided new field
    """

    def __init__(self, model_name, name, field):
        self.model_name = model_name
        self.name = name
        self.field = field

    def state_forwards(self, app_label, state):
        state.models[app_label, self.model_name.lower()].fields = [
            (n, self.field if n == self.name else f) for n, f in state.models[app_label, self.model_name.lower()].fields
        ]

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        to_model = to_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, to_model):
            schema_editor.alter_field(
                from_model,
                from_model._meta.get_field_by_name(self.name)[0],
                to_model._meta.get_field_by_name(self.name)[0],
            )

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        self.database_forwards(app_label, schema_editor, from_state, to_state)

    def describe(self):
        return "Alter field %s on %s" % (self.name, self.model_name)

    def __eq__(self, other):
        return (
            (self.__class__ == other.__class__) and
            (self.name == other.name) and
            (self.model_name.lower() == other.model_name.lower()) and
            (self.field.deconstruct()[1:] == other.field.deconstruct()[1:])
        )

    def references_model(self, name, app_label=None):
        return name.lower() == self.model_name.lower()

    def references_field(self, model_name, name, app_label=None):
        return self.references_model(model_name) and name.lower() == self.name.lower()


class RenameField(Operation):
    """
    Renames a field on the model. Might affect db_column too.
    """

    def __init__(self, model_name, old_name, new_name):
        self.model_name = model_name
        self.old_name = old_name
        self.new_name = new_name

    def state_forwards(self, app_label, state):
        state.models[app_label, self.model_name.lower()].fields = [
            (self.new_name if n == self.old_name else n, f) for n, f in state.models[app_label, self.model_name.lower()].fields
        ]

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        to_model = to_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, to_model):
            schema_editor.alter_field(
                from_model,
                from_model._meta.get_field_by_name(self.old_name)[0],
                to_model._meta.get_field_by_name(self.new_name)[0],
            )

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        from_model = from_state.render().get_model(app_label, self.model_name)
        to_model = to_state.render().get_model(app_label, self.model_name)
        if router.allow_migrate(schema_editor.connection.alias, to_model):
            schema_editor.alter_field(
                from_model,
                from_model._meta.get_field_by_name(self.new_name)[0],
                to_model._meta.get_field_by_name(self.old_name)[0],
            )

    def describe(self):
        return "Rename field %s on %s to %s" % (self.old_name, self.model_name, self.new_name)

    def references_model(self, name, app_label=None):
        return name.lower() == self.model_name.lower()

    def references_field(self, model_name, name, app_label=None):
        return self.references_model(model_name) and (
            name.lower() == self.old_name.lower() or
            name.lower() == self.new_name.lower()
        )

########NEW FILE########
__FILENAME__ = models
# Autogenerated from Django's django/db/migrations/operations/models.py - do not edit

from .base import Operation
from django.utils import six
from django.db import models, router
from django.db.models.options import normalize_unique_together
from ..state import ModelState


class CreateModel(Operation):
    """
    Create a model's table.
    """

    def __init__(self, name, fields, options=None, bases=None):
        self.name = name
        self.fields = fields
        self.options = options or {}
        self.bases = bases or (models.Model,)

    def state_forwards(self, app_label, state):
        state.models[app_label, self.name.lower()] = ModelState(app_label, self.name, self.fields, self.options, self.bases)

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        app_cache = to_state.render()
        model = app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, model):
            schema_editor.create_model(model)

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        app_cache = from_state.render()
        model = app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, model):
            schema_editor.delete_model(model)

    def describe(self):
        return "Create model %s" % (self.name, )

    def references_model(self, name, app_label=None):
        strings_to_check = [self.name]
        # Check we didn't inherit from the model
        for base in self.bases:
            if isinstance(base, six.string_types):
                strings_to_check.append(base.split(".")[-1])
        # Check we have no FKs/M2Ms with it
        for fname, field in self.fields:
            if field.rel:
                if isinstance(field.rel.to, six.string_types):
                    strings_to_check.append(field.rel.to.split(".")[-1])
        # Now go over all the strings and compare them
        for string in strings_to_check:
            if string.lower() == name.lower():
                return True
        return False

    def __eq__(self, other):
        return (
            (self.__class__ == other.__class__) and
            (self.name == other.name) and
            (self.options == other.options) and
            (self.bases == other.bases) and
            ([(k, f.deconstruct()[1:]) for k, f in self.fields] == [(k, f.deconstruct()[1:]) for k, f in other.fields])
        )


class DeleteModel(Operation):
    """
    Drops a model's table.
    """

    def __init__(self, name):
        self.name = name

    def state_forwards(self, app_label, state):
        del state.models[app_label, self.name.lower()]

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        app_cache = from_state.render()
        model = app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, model):
            schema_editor.delete_model(model)

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        app_cache = to_state.render()
        model = app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, model):
            schema_editor.create_model(model)

    def references_model(self, name, app_label=None):
        return name.lower() == self.name.lower()

    def describe(self):
        return "Delete model %s" % (self.name, )


class RenameModel(Operation):
    """
    Renames a model.
    """

    def __init__(self, old_name, new_name):
        self.old_name = old_name
        self.new_name = new_name

    def state_forwards(self, app_label, state):
        state.models[app_label, self.new_name.lower()] = state.models[app_label, self.old_name.lower()]
        state.models[app_label, self.new_name.lower()].name = self.new_name
        del state.models[app_label, self.old_name.lower()]

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        old_app_cache = from_state.render()
        new_app_cache = to_state.render()
        old_model = old_app_cache.get_model(app_label, self.old_name)
        new_model = new_app_cache.get_model(app_label, self.new_name)
        if router.allow_migrate(schema_editor.connection.alias, new_model):
            schema_editor.alter_db_table(
                new_model,
                old_model._meta.db_table,
                new_model._meta.db_table,
            )

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        old_app_cache = from_state.render()
        new_app_cache = to_state.render()
        old_model = old_app_cache.get_model(app_label, self.new_name)
        new_model = new_app_cache.get_model(app_label, self.old_name)
        if router.allow_migrate(schema_editor.connection.alias, new_model):
            schema_editor.alter_db_table(
                new_model,
                old_model._meta.db_table,
                new_model._meta.db_table,
            )

    def references_model(self, name, app_label=None):
        return (
            name.lower() == self.old_name.lower() or
            name.lower() == self.new_name.lower()
        )

    def describe(self):
        return "Rename model %s to %s" % (self.old_name, self.new_name)


class AlterModelTable(Operation):
    """
    Renames a model's table
    """

    def __init__(self, name, table):
        self.name = name
        self.table = table

    def state_forwards(self, app_label, state):
        state.models[app_label, self.name.lower()].options["db_table"] = self.table

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        old_app_cache = from_state.render()
        new_app_cache = to_state.render()
        old_model = old_app_cache.get_model(app_label, self.name)
        new_model = new_app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, new_model):
            schema_editor.alter_db_table(
                new_model,
                old_model._meta.db_table,
                new_model._meta.db_table,
            )

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        return self.database_forwards(app_label, schema_editor, from_state, to_state)

    def references_model(self, name, app_label=None):
        return name.lower() == self.name.lower()

    def describe(self):
        return "Rename table for %s to %s" % (self.name, self.table)


class AlterUniqueTogether(Operation):
    """
    Changes the value of index_together to the target one.
    Input value of unique_together must be a set of tuples.
    """

    def __init__(self, name, unique_together):
        self.name = name
        unique_together = normalize_unique_together(unique_together)
        self.unique_together = set(tuple(cons) for cons in unique_together)

    def state_forwards(self, app_label, state):
        model_state = state.models[app_label, self.name.lower()]
        model_state.options["unique_together"] = self.unique_together

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        old_app_cache = from_state.render()
        new_app_cache = to_state.render()
        old_model = old_app_cache.get_model(app_label, self.name)
        new_model = new_app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, new_model):
            schema_editor.alter_unique_together(
                new_model,
                getattr(old_model._meta, "unique_together", set()),
                getattr(new_model._meta, "unique_together", set()),
            )

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        return self.database_forwards(app_label, schema_editor, from_state, to_state)

    def references_model(self, name, app_label=None):
        return name.lower() == self.name.lower()

    def describe(self):
        return "Alter unique_together for %s (%s constraints)" % (self.name, len(self.unique_together))


class AlterIndexTogether(Operation):
    """
    Changes the value of index_together to the target one.
    Input value of index_together must be a set of tuples.
    """

    def __init__(self, name, index_together):
        self.name = name
        self.index_together = set(tuple(cons) for cons in index_together)

    def state_forwards(self, app_label, state):
        model_state = state.models[app_label, self.name.lower()]
        model_state.options["index_together"] = self.index_together

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        old_app_cache = from_state.render()
        new_app_cache = to_state.render()
        old_model = old_app_cache.get_model(app_label, self.name)
        new_model = new_app_cache.get_model(app_label, self.name)
        if router.allow_migrate(schema_editor.connection.alias, new_model):
            schema_editor.alter_index_together(
                new_model,
                getattr(old_model._meta, "index_together", set()),
                getattr(new_model._meta, "index_together", set()),
            )

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        return self.database_forwards(app_label, schema_editor, from_state, to_state)

    def references_model(self, name, app_label=None):
        return name.lower() == self.name.lower()

    def describe(self):
        return "Alter index_together for %s (%s constraints)" % (self.name, len(self.index_together))

########NEW FILE########
__FILENAME__ = special
# Autogenerated from Django's django/db/migrations/operations/special.py - do not edit

import re
import textwrap
from .base import Operation
from django.utils import six


class SeparateDatabaseAndState(Operation):
    """
    Takes two lists of operations - ones that will be used for the database,
    and ones that will be used for the state change. This allows operations
    that don't support state change to have it applied, or have operations
    that affect the state or not the database, or so on.
    """

    def __init__(self, database_operations=None, state_operations=None):
        self.database_operations = database_operations or []
        self.state_operations = state_operations or []

    def state_forwards(self, app_label, state):
        for state_operation in self.state_operations:
            state_operation.state_forwards(app_label, state)

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        # We calculate state separately in here since our state functions aren't useful
        for database_operation in self.database_operations:
            to_state = from_state.clone()
            database_operation.state_forwards(app_label, to_state)
            database_operation.database_forwards(self, app_label, schema_editor, from_state, to_state)
            from_state = to_state

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        # We calculate state separately in here since our state functions aren't useful
        base_state = to_state
        for pos, database_operation in enumerate(reversed(self.database_operations)):
            to_state = base_state.clone()
            for dbop in self.database_operations[:-(pos + 1)]:
                dbop.state_forwards(app_label, to_state)
            from_state = base_state.clone()
            database_operation.state_forwards(app_label, from_state)
            database_operation.database_backwards(self, app_label, schema_editor, from_state, to_state)

    def describe(self):
        return "Custom state/database change combination"


class RunSQL(Operation):
    """
    Runs some raw SQL - a single statement by default, but it will attempt
    to parse and split it into multiple statements if multiple=True.

    A reverse SQL statement may be provided.

    Also accepts a list of operations that represent the state change effected
    by this SQL change, in case it's custom column/table creation/deletion.
    """

    def __init__(self, sql, reverse_sql=None, state_operations=None, multiple=False):
        self.sql = sql
        self.reverse_sql = reverse_sql
        self.state_operations = state_operations or []
        self.multiple = multiple

    @property
    def reversible(self):
        return self.reverse_sql is not None

    def state_forwards(self, app_label, state):
        for state_operation in self.state_operations:
            state_operation.state_forwards(app_label, state)

    def _split_sql(self, sql):
        regex = r"(?mx) ([^';]* (?:'[^']*'[^';]*)*)"
        comment_regex = r"(?mx) (?:^\s*$)|(?:--.*$)"
        # First, strip comments
        sql = "\n".join([x.strip().replace("%", "%%") for x in re.split(comment_regex, sql) if x.strip()])
        # Now get each statement
        for st in re.split(regex, sql)[1:][::2]:
            yield st

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        if self.multiple:
            statements = self._split_sql(self.sql)
        else:
            statements = [self.sql]
        for statement in statements:
            schema_editor.execute(statement)

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        if self.reverse_sql is None:
            raise NotImplementedError("You cannot reverse this operation")
        if self.multiple:
            statements = self._split_sql(self.reverse_sql)
        else:
            statements = [self.reverse_sql]
        for statement in statements:
            schema_editor.execute(statement)

    def describe(self):
        return "Raw SQL operation"


class RunPython(Operation):
    """
    Runs Python code in a context suitable for doing versioned ORM operations.
    """

    reduces_to_sql = False
    reversible = False

    def __init__(self, code, reverse_code=None):
        # Forwards code
        if isinstance(code, six.string_types):
            # Trim any leading whitespace that is at the start of all code lines
            # so users can nicely indent code in migration files
            code = textwrap.dedent(code)
            # Run the code through a parser first to make sure it's at least
            # syntactically correct
            self.code = compile(code, "<string>", "exec")
        else:
            self.code = code
        # Reverse code
        if reverse_code is None:
            self.reverse_code = None
        elif isinstance(reverse_code, six.string_types):
            reverse_code = textwrap.dedent(reverse_code)
            self.reverse_code = compile(reverse_code, "<string>", "exec")
        else:
            self.reverse_code = reverse_code

    def state_forwards(self, app_label, state):
        # RunPython objects have no state effect. To add some, combine this
        # with SeparateDatabaseAndState.
        pass

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        # We now execute the Python code in a context that contains a 'models'
        # object, representing the versioned models as an AppCache.
        # We could try to override the global cache, but then people will still
        # use direct imports, so we go with a documentation approach instead.
        if callable(self.code):
            self.code(models=from_state.render(), schema_editor=schema_editor)
        else:
            context = {
                "models": from_state.render(),
                "schema_editor": schema_editor,
            }
            eval(self.code, context)

    def database_backwards(self, app_label, schema_editor, from_state, to_state):
        if self.reverse_code is None:
            raise NotImplementedError("You cannot reverse this operation")
        elif callable(self.reverse_code):
            self.reverse_code(models=from_state.render(), schema_editor=schema_editor)
        else:
            context = {
                "models": from_state.render(),
                "schema_editor": schema_editor,
            }
            eval(self.reverse_code, context)

    def describe(self):
        return "Raw Python operation"

########NEW FILE########
__FILENAME__ = optimizer
# Autogenerated from Django's django/db/migrations/optimizer.py - do not edit

from django.db import migrations


class MigrationOptimizer(object):
    """
    Powers the optimization process, where you provide a list of Operations
    and you are returned a list of equal or shorter length - operations
    are merged into one if possible.

    For example, a CreateModel and an AddField can be optimised into a
    new CreateModel, and CreateModel and DeleteModel can be optimised into
    nothing.
    """

    def optimize(self, operations, app_label=None):
        """
        Main optimization entry point. Pass in a list of Operation instances,
        get out a new list of Operation instances.

        Unfortunately, due to the scope of the optimisation (two combinable
        operations might be separated by several hundred others), this can't be
        done as a peephole optimisation with checks/output implemented on
        the Operations themselves; instead, the optimizer looks at each
        individual operation and scans forwards in the list to see if there
        are any matches, stopping at boundaries - operations which can't
        be optimized over (RunSQL, operations on the same field/model, etc.)

        The inner loop is run until the starting list is the same as the result
        list, and then the result is returned. This means that operation
        optimization must be stable and always return an equal or shorter list.

        The app_label argument is optional, but if you pass it you'll get more
        efficient optimization.
        """
        # Internal tracking variable for test assertions about # of loops
        self._iterations = 0
        while True:
            result = self.optimize_inner(operations, app_label)
            self._iterations += 1
            if result == operations:
                return result
            operations = result

    def optimize_inner(self, operations, app_label=None):
        """
        Inner optimization loop.
        """
        new_operations = []
        for i, operation in enumerate(operations):
            # Compare it to each operation after it
            for j, other in enumerate(operations[i + 1:]):
                result = self.reduce(operation, other)
                if result is not None:
                    # Optimize! Add result, then remaining others, then return
                    new_operations.extend(result)
                    new_operations.extend(operations[i + 1:i + 1 + j])
                    new_operations.extend(operations[i + j + 2:])
                    return new_operations
                if not self.can_optimize_through(operation, other, app_label):
                    new_operations.append(operation)
                    break
            else:
                new_operations.append(operation)
        return new_operations

    #### REDUCTION ####

    def reduce(self, operation, other):
        """
        Either returns a list of zero, one or two operations,
        or None, meaning this pair cannot be optimized.
        """
        submethods = [
            (
                migrations.CreateModel,
                migrations.DeleteModel,
                self.reduce_model_create_delete,
            ),
            (
                migrations.AlterModelTable,
                migrations.DeleteModel,
                self.reduce_model_alter_delete,
            ),
            (
                migrations.AlterUniqueTogether,
                migrations.DeleteModel,
                self.reduce_model_alter_delete,
            ),
            (
                migrations.AlterIndexTogether,
                migrations.DeleteModel,
                self.reduce_model_alter_delete,
            ),
            (
                migrations.CreateModel,
                migrations.RenameModel,
                self.reduce_model_create_rename,
            ),
            (
                migrations.RenameModel,
                migrations.RenameModel,
                self.reduce_model_rename_self,
            ),
            (
                migrations.CreateModel,
                migrations.AddField,
                self.reduce_create_model_add_field,
            ),
            (
                migrations.CreateModel,
                migrations.AlterField,
                self.reduce_create_model_alter_field,
            ),
            (
                migrations.CreateModel,
                migrations.RemoveField,
                self.reduce_create_model_remove_field,
            ),
            (
                migrations.AddField,
                migrations.AlterField,
                self.reduce_add_field_alter_field,
            ),
            (
                migrations.AddField,
                migrations.RemoveField,
                self.reduce_add_field_delete_field,
            ),
            (
                migrations.AlterField,
                migrations.RemoveField,
                self.reduce_alter_field_delete_field,
            ),
            (
                migrations.AddField,
                migrations.RenameField,
                self.reduce_add_field_rename_field,
            ),
            (
                migrations.AlterField,
                migrations.RenameField,
                self.reduce_alter_field_rename_field,
            ),
            (
                migrations.CreateModel,
                migrations.RenameField,
                self.reduce_create_model_rename_field,
            ),
            (
                migrations.RenameField,
                migrations.RenameField,
                self.reduce_rename_field_self,
            ),
        ]
        for ia, ib, om in submethods:
            if isinstance(operation, ia) and isinstance(other, ib):
                return om(operation, other)
        return None

    def reduce_model_create_delete(self, operation, other):
        """
        Folds a CreateModel and a DeleteModel into nothing.
        """
        if operation.name.lower() == other.name.lower():
            return []

    def reduce_model_alter_delete(self, operation, other):
        """
        Folds an AlterModelSomething and a DeleteModel into just delete.
        """
        if operation.name.lower() == other.name.lower():
            return [other]

    def reduce_model_create_rename(self, operation, other):
        """
        Folds a model rename into its create
        """
        if operation.name.lower() == other.old_name.lower():
            return [
                migrations.CreateModel(
                    other.new_name,
                    fields=operation.fields,
                    options=operation.options,
                    bases=operation.bases,
                )
            ]

    def reduce_model_rename_self(self, operation, other):
        """
        Folds a model rename into another one
        """
        if operation.new_name.lower() == other.old_name.lower():
            return [
                migrations.RenameModel(
                    operation.old_name,
                    other.new_name,
                )
            ]

    def reduce_create_model_add_field(self, operation, other):
        if operation.name.lower() == other.model_name.lower():
            return [
                migrations.CreateModel(
                    operation.name,
                    fields=operation.fields + [(other.name, other.field)],
                    options=operation.options,
                    bases=operation.bases,
                )
            ]

    def reduce_create_model_alter_field(self, operation, other):
        if operation.name.lower() == other.model_name.lower():
            return [
                migrations.CreateModel(
                    operation.name,
                    fields=[
                        (n, other.field if n == other.name else v)
                        for n, v in operation.fields
                    ],
                    options=operation.options,
                    bases=operation.bases,
                )
            ]

    def reduce_create_model_rename_field(self, operation, other):
        if operation.name.lower() == other.model_name.lower():
            return [
                migrations.CreateModel(
                    operation.name,
                    fields=[
                        (other.new_name if n == other.old_name else n, v)
                        for n, v in operation.fields
                    ],
                    options=operation.options,
                    bases=operation.bases,
                )
            ]

    def reduce_create_model_remove_field(self, operation, other):
        if operation.name.lower() == other.model_name.lower():
            return [
                migrations.CreateModel(
                    operation.name,
                    fields=[
                        (n, v)
                        for n, v in operation.fields
                        if n.lower() != other.name.lower()
                    ],
                    options=operation.options,
                    bases=operation.bases,
                )
            ]

    def reduce_add_field_alter_field(self, operation, other):
        if operation.model_name.lower() == other.model_name.lower() and operation.name.lower() == other.name.lower():
            return [
                migrations.AddField(
                    model_name=operation.model_name,
                    name=operation.name,
                    field=other.field,
                )
            ]

    def reduce_add_field_delete_field(self, operation, other):
        if operation.model_name.lower() == other.model_name.lower() and operation.name.lower() == other.name.lower():
            return []

    def reduce_alter_field_delete_field(self, operation, other):
        if operation.model_name.lower() == other.model_name.lower() and operation.name.lower() == other.name.lower():
            return [other]

    def reduce_add_field_rename_field(self, operation, other):
        if operation.model_name.lower() == other.model_name.lower() and operation.name.lower() == other.old_name.lower():
            return [
                migrations.AddField(
                    model_name=operation.model_name,
                    name=other.new_name,
                    field=operation.field,
                )
            ]

    def reduce_alter_field_rename_field(self, operation, other):
        if operation.model_name.lower() == other.model_name.lower() and operation.name.lower() == other.old_name.lower():
            return [
                other,
                migrations.AlterField(
                    model_name=operation.model_name,
                    name=other.new_name,
                    field=operation.field,
                ),
            ]

    def reduce_rename_field_self(self, operation, other):
        if operation.model_name.lower() == other.model_name.lower() and operation.new_name.lower() == other.old_name.lower():
            return [
                migrations.RenameField(
                    operation.model_name,
                    operation.old_name,
                    other.new_name,
                ),
            ]

    #### THROUGH CHECKS ####

    def can_optimize_through(self, operation, other, app_label=None):
        """
        Returns True if it's possible to optimize 'operation' with something
        the other side of 'other'. This is possible if, for example, they
        affect different models.
        """
        MODEL_LEVEL_OPERATIONS = (
            migrations.CreateModel,
            migrations.AlterModelTable,
            migrations.AlterUniqueTogether,
            migrations.AlterIndexTogether,
        )
        FIELD_LEVEL_OPERATIONS = (
            migrations.AddField,
            migrations.AlterField,
        )
        # If it's a model level operation, let it through if there's
        # nothing that looks like a reference to us in 'other'.
        if isinstance(operation, MODEL_LEVEL_OPERATIONS):
            if not other.references_model(operation.name, app_label):
                return True
        # If it's field level, only let it through things that don't reference
        # the field (which includes not referencing the model)
        if isinstance(operation, FIELD_LEVEL_OPERATIONS):
            if not other.references_field(operation.model_name, operation.name, app_label):
                return True
        return False

########NEW FILE########
__FILENAME__ = app_cache_methods
from south.patches import add_to_class


@add_to_class("django.db.models.loading.AppCache")
def get_app_configs(self, only_with_models_module=False):
    """
    Emulates the 1.7 app configs just enough so you can iterate over
    them and get app info.
    """
    configs = []
    for app in self.get_apps():
        configs.append(self.get_app_config(app.__name__.split('.')[-2]))
    return configs


@add_to_class("django.db.models.loading.AppCache")
def get_app_config(self, app_label, only_installed=True, only_with_models_module=False):
    """
    Emulates the 1.7 app configs just enough so you can get info
    from them.
    """
    app = self.get_app(app_label)
    config_class = type("AppConfig", (object, ), {})
    config = config_class()
    config.name = app.__name__.rsplit(".", 1)[0]
    config.label = app.__name__.split('.')[-2]
    config.models_module = app
    return config

########NEW FILE########
__FILENAME__ = atomic
from functools import wraps
from south.patches import add_to_module
from django.db import DEFAULT_DB_ALIAS, connections
from django.utils.decorators import available_attrs


@add_to_module("django.db.transaction")
class Atomic(object):
    """
    This class is a mere shadow of the real Atomic class that attempts
    to map the behaviour to old transactions enough that migrations can run.
    """

    def __init__(self, using, savepoint):
        self.using = using
        self.savepoint = savepoint

    def __enter__(self):
        connection = connections[self.using]
        connection.enter_transaction_management()

    def __exit__(self, exc_type, exc_value, traceback):
        connection = connections[self.using]
        if exc_type is None:
            connection.commit()
        else:
            connection.rollback()
        connection.leave_transaction_management()

    def __call__(self, func):
        @wraps(func, assigned=available_attrs(func))
        def inner(*args, **kwargs):
            with self:
                return func(*args, **kwargs)
        return inner


@add_to_module("django.db.transaction")
def atomic(using=None, savepoint=True):
    # Bare decorator: @atomic -- although the first argument is called
    # `using`, it's actually the function being decorated.
    if callable(using):
        return Atomic(DEFAULT_DB_ALIAS, savepoint)(using)
    # Decorator: @atomic(...) or context manager: with atomic(...): ...
    else:
        return Atomic(using, savepoint)

########NEW FILE########
__FILENAME__ = database_features
from django.core.exceptions import ImproperlyConfigured

from django.db.backends import BaseDatabaseFeatures
BaseDatabaseFeatures.can_rollback_ddl = False
BaseDatabaseFeatures.supports_combined_alters = False
BaseDatabaseFeatures.max_index_name_length = 63
BaseDatabaseFeatures.supports_foreign_keys = True
BaseDatabaseFeatures.supports_check_constraints = True
BaseDatabaseFeatures.requires_literal_defaults = False
BaseDatabaseFeatures.connection_persists_old_columns = False


try:
    from django.db.backends.postgresql_psycopg2.base import DatabaseFeatures
    DatabaseFeatures.can_rollback_ddl = True
    DatabaseFeatures.supports_combined_alters = True
except ImproperlyConfigured:
    pass


try:
    from django.db.backends.mysql.base import DatabaseFeatures
    DatabaseFeatures.supports_check_constraints = False
except ImproperlyConfigured:
    pass


try:
    from django.db.backends.sqlite3.base import DatabaseFeatures
    DatabaseFeatures.supports_foreign_keys = False
    DatabaseFeatures.supports_check_constraints = False
except ImproperlyConfigured:
    pass


try:
    from django.db.backends.oracle.base import DatabaseFeatures
    DatabaseFeatures.max_index_name_length = 30
    DatabaseFeatures.requires_literal_defaults = True
    DatabaseFeatures.connection_persists_old_columns = True
except ImproperlyConfigured:
    pass

########NEW FILE########
__FILENAME__ = django_1_4
import sys

from django.core.exceptions import ImproperlyConfigured
from django.utils import six
from django.utils.importlib import import_module


from south.patches import add_to_module

@add_to_module("django.utils.module_loading")
def import_by_path(dotted_path, error_prefix=''):
    """
    Import a dotted module path and return the attribute/class designated by the
    last name in the path. Raise ImproperlyConfigured if something goes wrong.
    """
    try:
        module_path, class_name = dotted_path.rsplit('.', 1)
    except ValueError:
        raise ImproperlyConfigured("%s%s doesn't look like a module path" % (
            error_prefix, dotted_path))
    try:
        module = import_module(module_path)
    except ImportError as e:
        msg = '%sError importing module %s: "%s"' % (
            error_prefix, module_path, e)
        six.reraise(ImproperlyConfigured, ImproperlyConfigured(msg),
                    sys.exc_info()[2])
    try:
        attr = getattr(module, class_name)
    except AttributeError:
        raise ImproperlyConfigured('%sModule "%s" does not define a "%s" attribute/class' % (
            error_prefix, module_path, class_name))
    return attr

########NEW FILE########
__FILENAME__ = fields
from django.db.models.fields import NOT_PROVIDED, Field, AutoField, BooleanField, DateField, DecimalField, EmailField, FilePathField, IPAddressField, GenericIPAddressField, NullBooleanField, SlugField, TimeField, URLField
from django.db.models.fields.related import CASCADE, ForeignKey, OneToOneField, ManyToManyField
from django.utils import six
from django.conf import settings
from south.patches import add_to_class


@add_to_class("django.db.models.fields.Field")
def db_parameters(self, connection):
    db_type = self.db_type(connection)
    if " CHECK " in db_type:
        bits = db_type.split(" CHECK ", 1)
        return {
            "type": bits[0],
            "check": bits[1],
        }
    else:
        return {
            "type": db_type,
            "check": None,
        }


Field.old_init = Field.__init__

@add_to_class("django.db.models.fields.Field")
def __init__(self, *args, **kwargs):
    self._validators = kwargs.get("validators", [])
    self._error_messages = kwargs.get("error_messages", None)
    self._verbose_name = kwargs.get("verbose_name", None if len(args) == 0 else args[0])
    self.old_init(*args, **kwargs)


@add_to_class("django.db.models.fields.Field")
def deconstruct(self):
    # Original code below
    keywords = {}
    possibles = {
        "verbose_name": None,
        "primary_key": False,
        "max_length": None,
        "unique": False,
        "blank": False,
        "null": False,
        "db_index": False,
        "default": NOT_PROVIDED,
        "editable": True,
        "serialize": True,
        "unique_for_date": None,
        "unique_for_month": None,
        "unique_for_year": None,
        "choices": [],
        "help_text": '',
        "db_column": None,
        "db_tablespace": settings.DEFAULT_INDEX_TABLESPACE,
        "auto_created": False,
        "validators": [],
        "error_messages": None,
    }
    attr_overrides = {
        "unique": "_unique",
        "choices": "_choices",
        "error_messages": "_error_messages",
        "validators": "_validators",
        "verbose_name": "_verbose_name",
    }
    equals_comparison = set(["choices", "validators", "db_tablespace"])
    for name, default in possibles.items():
        value = getattr(self, attr_overrides.get(name, name))
        if name in equals_comparison:
            if value != default:
                keywords[name] = value
        else:
            if value is not default:
                keywords[name] = value
    # Work out path - we shorten it for known Django core fields
    path = "%s.%s" % (self.__class__.__module__, self.__class__.__name__)
    if path.startswith("django.db.models.fields.related"):
        path = path.replace("django.db.models.fields.related", "django.db.models")
    if path.startswith("django.db.models.fields.files"):
        path = path.replace("django.db.models.fields.files", "django.db.models")
    if path.startswith("django.db.models.fields.proxy"):
        path = path.replace("django.db.models.fields.proxy", "django.db.models")
    if path.startswith("django.db.models.fields"):
        path = path.replace("django.db.models.fields", "django.db.models")
    # Return basic info - other fields should override this.
    return (
        self.name,
        path,
        [],
        keywords,
    )


@add_to_class("django.db.models.fields.AutoField")
def deconstruct(self):
    name, path, args, kwargs = super(AutoField, self).deconstruct()
    del kwargs['blank']
    kwargs['primary_key'] = True
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.BooleanField")
def deconstruct(self):
    name, path, args, kwargs = super(BooleanField, self).deconstruct()
    del kwargs['blank']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.DateField")
def deconstruct(self):
    name, path, args, kwargs = super(DateField, self).deconstruct()
    if self.auto_now:
        kwargs['auto_now'] = True
        del kwargs['editable']
        del kwargs['blank']
    if self.auto_now_add:
        kwargs['auto_now_add'] = True
        del kwargs['editable']
        del kwargs['blank']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.DecimalField")
def deconstruct(self):
    name, path, args, kwargs = super(DecimalField, self).deconstruct()
    if self.max_digits:
        kwargs['max_digits'] = self.max_digits
    if self.decimal_places:
        kwargs['decimal_places'] = self.decimal_places
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.EmailField")
def deconstruct(self):
    name, path, args, kwargs = super(EmailField, self).deconstruct()
    # We do not exclude max_length if it matches default as we want to change
    # the default in future.
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.FilePathField")
def deconstruct(self):
    name, path, args, kwargs = super(FilePathField, self).deconstruct()
    if self.path != '':
        kwargs['path'] = self.path
    if self.match is not None:
        kwargs['match'] = self.match
    if self.recursive is not False:
        kwargs['recursive'] = self.recursive
    if self.allow_files is not True:
        kwargs['allow_files'] = self.allow_files
    if self.allow_folders is not False:
        kwargs['allow_folders'] = self.allow_folders
    if kwargs.get("max_length", None) == 100:
        del kwargs["max_length"]
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.IPAddressField")
def deconstruct(self):
    name, path, args, kwargs = super(IPAddressField, self).deconstruct()
    del kwargs['max_length']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.GenericIPAddressField")
def deconstruct(self):
    name, path, args, kwargs = super(GenericIPAddressField, self).deconstruct()
    if self.unpack_ipv4 is not False:
        kwargs['unpack_ipv4'] = self.unpack_ipv4
    if self.protocol != "both":
        kwargs['protocol'] = self.protocol
    if kwargs.get("max_length", None) == 39:
        del kwargs['max_length']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.NullBooleanField")
def deconstruct(self):
    name, path, args, kwargs = super(NullBooleanField, self).deconstruct()
    del kwargs['null']
    del kwargs['blank']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.SlugField")
def deconstruct(self):
    name, path, args, kwargs = super(SlugField, self).deconstruct()
    if kwargs.get("max_length", None) == 50:
        del kwargs['max_length']
    if self.db_index is False:
        kwargs['db_index'] = False
    else:
        del kwargs['db_index']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.TimeField")
def deconstruct(self):
    name, path, args, kwargs = super(TimeField, self).deconstruct()
    if self.auto_now is not False:
        kwargs["auto_now"] = self.auto_now
    if self.auto_now_add is not False:
        kwargs["auto_now_add"] = self.auto_now_add
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.URLField")
def deconstruct(self):
    name, path, args, kwargs = super(URLField, self).deconstruct()
    if kwargs.get("max_length", None) == 200:
        del kwargs['max_length']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.related.ForeignKey")
def deconstruct(self):
    name, path, args, kwargs = super(ForeignKey, self).deconstruct()
    if isinstance(self.rel.to, six.string_types):
        kwargs['to'] = self.rel.to
    else:
        kwargs['to'] = "%s.%s" % (self.rel.to._meta.app_label, self.rel.to._meta.object_name)
    # Handle the simpler arguments
    if self.db_index:
        del kwargs['db_index']
    else:
        kwargs['db_index'] = False
    if getattr(self, "db_constraint", True) is not True:
        kwargs['db_constraint'] = self.db_constraint
    if self.rel.on_delete is not CASCADE:
        kwargs['on_delete'] = self.rel.on_delete
    # Rel needs more work.
    if self.rel.field_name:
        kwargs['to_field'] = self.rel.field_name
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.related.OneToOneField")
def deconstruct(self):
    name, path, args, kwargs = super(OneToOneField, self).deconstruct()
    if "unique" in kwargs:
        del kwargs['unique']
    return name, path, args, kwargs


@add_to_class("django.db.models.fields.related.ManyToManyField")
def deconstruct(self):
    name, path, args, kwargs = super(ManyToManyField, self).deconstruct()
    if isinstance(self.rel.to, six.string_types):
        kwargs['to'] = self.rel.to
    else:
        kwargs['to'] = "%s.%s" % (self.rel.to._meta.app_label, self.rel.to._meta.object_name)
    # Handle the simpler arguments
    if getattr(self.rel, "db_constraint", True) is not True:
        kwargs['db_constraint'] = self.rel.db_constraint
    if "help_text" in kwargs:
        del kwargs['help_text']
    # Rel needs more work.
    if isinstance(self.rel.to, six.string_types):
        kwargs['to'] = self.rel.to
    else:
        kwargs['to'] = "%s.%s" % (self.rel.to._meta.app_label, self.rel.to._meta.object_name)
    return name, path, args, kwargs

########NEW FILE########
__FILENAME__ = global_settings
from django.conf import global_settings, settings


global_settings.MIGRATION_MODULES = {}
settings.MIGRATION_MODULES = {}

########NEW FILE########
__FILENAME__ = model_options
from django.db.models import options
from south.patches import add_to_module, add_to_class


options.DEFAULT_NAMES = options.DEFAULT_NAMES + ("app_cache", )


@add_to_module("django.db.models.options")
def normalize_unique_together(unique_together):
    """
    unique_together can be either a tuple of tuples, or a single
    tuple of two strings. Normalize it to a tuple of tuples, so that
    calling code can uniformly expect that.
    """
    if not unique_together:
        return ()
    first_element = next(iter(unique_together))
    if not isinstance(first_element, (tuple, list)):
        unique_together = (unique_together,)
    # Normalize everything to tuples
    return tuple(tuple(ut) for ut in unique_together)


options.Options.old_init = options.Options.__init__
@add_to_class("django.db.models.options.Options")
def __init__(self, *args, **kwargs):
    from south.app_cache import app_cache
    self.app_cache = app_cache
    self.old_init(*args, **kwargs)


options.Options.old_contribute_to_class = options.Options.contribute_to_class
@add_to_class("django.db.models.options.Options")
def contribute_to_class(self, cls, name):
    self.original_attrs = {}
    if self.meta:
        meta_attrs = self.meta.__dict__.copy()
        for attr_name in options.DEFAULT_NAMES:
            if attr_name in meta_attrs:
                self.original_attrs[attr_name] = getattr(self, attr_name)
            elif hasattr(self.meta, attr_name):
                self.original_attrs[attr_name] = getattr(self, attr_name)
    return self.old_contribute_to_class(cls, name)

########NEW FILE########
__FILENAME__ = routers
from south.patches import add_to_class


@add_to_class("django.db.utils.ConnectionRouter")
def allow_migrate(self, db, model):
    for router in self.routers:
        try:
            try:
                method = router.allow_migrate
            except AttributeError:
                method = router.allow_syncdb
        except AttributeError:
            # If the router doesn't have a method, skip to the next one.
            pass
        else:
            allow = method(db, model)
            if allow is not None:
                return allow
    return True


@add_to_class("django.db.utils.ConnectionRouter")
def get_migratable_models(self, app, db, include_auto_created=False):
    from south.app_cache import app_cache
    return [
        model
        for model in app_cache.get_models(app, include_auto_created=include_auto_created)
        if self.allow_migrate(db, model)
    ]

########NEW FILE########
__FILENAME__ = schema_editor
from south.patches import add_to_class
from django.core.exceptions import ImproperlyConfigured


try:
    @add_to_class("django.db.backends.postgresql_psycopg2.base.DatabaseWrapper")
    def schema_editor(self, *args, **kwargs):
        from south.schema.postgresql import DatabaseSchemaEditor
        return DatabaseSchemaEditor(self, *args, **kwargs)
except ImproperlyConfigured:
    pass


try:
    @add_to_class("django.db.backends.mysql.base.DatabaseWrapper")
    def schema_editor(self, *args, **kwargs):
        from south.schema.mysql import DatabaseSchemaEditor
        return DatabaseSchemaEditor(self, *args, **kwargs)
except ImproperlyConfigured:
    pass


try:
    @add_to_class("django.db.backends.sqlite3.base.DatabaseWrapper")
    def schema_editor(self, *args, **kwargs):
        from south.schema.sqlite3 import DatabaseSchemaEditor
        return DatabaseSchemaEditor(self, *args, **kwargs)
except ImproperlyConfigured:
    pass


try:
    @add_to_class("django.db.backends.oracle.base.DatabaseWrapper")
    def schema_editor(self, *args, **kwargs):
        from south.schema.oracle import DatabaseSchemaEditor
        return DatabaseSchemaEditor(self, *args, **kwargs)
except ImproperlyConfigured:
    pass

########NEW FILE########
__FILENAME__ = signals
from south.patches import add_to_module
from django.dispatch import Signal
from django.db.models import signals


add_to_module(
    "django.db.models.signals",
    "pre_migrate",
    Signal(providing_args=["app", "create_models", "verbosity", "interactive", "db"]),
)

add_to_module(
    "django.db.models.signals",
    "post_migrate",
    Signal(providing_args=["class", "app", "created_models", "verbosity", "interactive", "db"])
)


@add_to_module("django.core.management.sql")
def emit_pre_migrate_signal(create_models, verbosity, interactive, db):
    # Emit the pre_migrate signal for every application.
    from south.app_cache import app_cache
    for app in app_cache.get_apps():
        app_name = app.__name__.split('.')[-2]
        if verbosity >= 2:
            print("Running pre-migrate handlers for application %s" % app_name)
        signals.pre_migrate.send(
            sender=app,
            app=app,
            create_models=create_models,
            verbosity=verbosity,
            interactive=interactive,
            db=db,
        )


@add_to_module("django.core.management.sql")
def emit_post_migrate_signal(created_models, verbosity, interactive, db):
    # Emit the post_migrate signal for every application.
    from south.app_cache import app_cache
    for app in app_cache.get_apps():
        app_name = app.__name__.split('.')[-2]
        if verbosity >= 2:
            print("Running post-migrate handlers for application %s" % app_name)
        signals.post_migrate.send(
            sender=app,
            app=app,
            created_models=created_models,
            verbosity=verbosity,
            interactive=interactive,
            db=db,
        )

########NEW FILE########
__FILENAME__ = termcolors
from django.utils import termcolors

termcolors.PALETTES = {
    termcolors.NOCOLOR_PALETTE: {
        'ERROR': {},
        'NOTICE': {},
        'SQL_FIELD': {},
        'SQL_COLTYPE': {},
        'SQL_KEYWORD': {},
        'SQL_TABLE': {},
        'HTTP_INFO': {},
        'HTTP_SUCCESS': {},
        'HTTP_REDIRECT': {},
        'HTTP_NOT_MODIFIED': {},
        'HTTP_BAD_REQUEST': {},
        'HTTP_NOT_FOUND': {},
        'HTTP_SERVER_ERROR': {},
        'MIGRATE_HEADING': {},
        'MIGRATE_LABEL': {},
        'MIGRATE_SUCCESS': {},
        'MIGRATE_FAILURE': {},
    },
    termcolors.DARK_PALETTE: {
        'ERROR': {'fg': 'red', 'opts': ('bold',)},
        'NOTICE': {'fg': 'red'},
        'SQL_FIELD': {'fg': 'green', 'opts': ('bold',)},
        'SQL_COLTYPE': {'fg': 'green'},
        'SQL_KEYWORD': {'fg': 'yellow'},
        'SQL_TABLE': {'opts': ('bold',)},
        'HTTP_INFO': {'opts': ('bold',)},
        'HTTP_SUCCESS': {},
        'HTTP_REDIRECT': {'fg': 'green'},
        'HTTP_NOT_MODIFIED': {'fg': 'cyan'},
        'HTTP_BAD_REQUEST': {'fg': 'red', 'opts': ('bold',)},
        'HTTP_NOT_FOUND': {'fg': 'yellow'},
        'HTTP_SERVER_ERROR': {'fg': 'magenta', 'opts': ('bold',)},
        'MIGRATE_HEADING': {'fg': 'cyan', 'opts': ('bold',)},
        'MIGRATE_LABEL': {'opts': ('bold',)},
        'MIGRATE_SUCCESS': {'fg': 'green', 'opts': ('bold',)},
        'MIGRATE_FAILURE': {'fg': 'red', 'opts': ('bold',)},
    },
    termcolors.LIGHT_PALETTE: {
        'ERROR': {'fg': 'red', 'opts': ('bold',)},
        'NOTICE': {'fg': 'red'},
        'SQL_FIELD': {'fg': 'green', 'opts': ('bold',)},
        'SQL_COLTYPE': {'fg': 'green'},
        'SQL_KEYWORD': {'fg': 'blue'},
        'SQL_TABLE': {'opts': ('bold',)},
        'HTTP_INFO': {'opts': ('bold',)},
        'HTTP_SUCCESS': {},
        'HTTP_REDIRECT': {'fg': 'green', 'opts': ('bold',)},
        'HTTP_NOT_MODIFIED': {'fg': 'green'},
        'HTTP_BAD_REQUEST': {'fg': 'red', 'opts': ('bold',)},
        'HTTP_NOT_FOUND': {'fg': 'red'},
        'HTTP_SERVER_ERROR': {'fg': 'magenta', 'opts': ('bold',)},
        'MIGRATE_HEADING': {'fg': 'cyan', 'opts': ('bold',)},
        'MIGRATE_LABEL': {'opts': ('bold',)},
        'MIGRATE_SUCCESS': {'fg': 'green', 'opts': ('bold',)},
        'MIGRATE_FAILURE': {'fg': 'red', 'opts': ('bold',)},
    }
}

########NEW FILE########
__FILENAME__ = questioner
# Autogenerated from Django's django/db/migrations/questioner.py - do not edit

import importlib
import os
import sys

from south.app_cache import app_cache
from django.utils import datetime_safe
from django.utils.six.moves import input


class MigrationQuestioner(object):
    """
    Gives the autodetector responses to questions it might have.
    This base class has a built-in noninteractive mode, but the
    interactive subclass is what the command-line arguments will use.
    """

    def __init__(self, defaults=None, specified_apps=None):
        self.defaults = defaults or {}
        self.specified_apps = specified_apps or set()

    def ask_initial(self, app_label):
        "Should we create an initial migration for the app?"
        # If it was specified on the command line, definitely true
        if app_label in self.specified_apps:
            return True
        # Otherwise, we look to see if it has a migrations module
        # without any Python files in it, apart from __init__.py.
        # Apps from the new app template will have these; the python
        # file check will ensure we skip South ones.
        try:
            app_config = app_cache.get_app_config(app_label)
        except LookupError:         # It's a fake app.
            return self.defaults.get("ask_initial", False)
        migrations_import_path = "%s.migrations" % app_config.name
        try:
            migrations_module = importlib.import_module(migrations_import_path)
        except ImportError:
            return self.defaults.get("ask_initial", False)
        else:
            filenames = os.listdir(os.path.dirname(migrations_module.__file__))
            return not any(x.endswith(".py") for x in filenames if x != "__init__.py")

    def ask_not_null_addition(self, field_name, model_name):
        "Adding a NOT NULL field to a model"
        # None means quit
        return None

    def ask_rename(self, model_name, old_name, new_name, field_instance):
        "Was this field really renamed?"
        return self.defaults.get("ask_rename", False)

    def ask_merge(self, app_label):
        "Do you really want to merge these migrations?"
        return self.defaults.get("ask_merge", False)


class InteractiveMigrationQuestioner(MigrationQuestioner):

    def _boolean_input(self, question, default=None):
        result = input("%s " % question)
        if not result and default is not None:
            return default
        while len(result) < 1 or result[0].lower() not in "yn":
            result = input("Please answer yes or no: ")
        return result[0].lower() == "y"

    def _choice_input(self, question, choices):
        print(question)
        for i, choice in enumerate(choices):
            print(" %s) %s" % (i + 1, choice))
        result = input("Select an option: ")
        while True:
            try:
                value = int(result)
                if 0 < value <= len(choices):
                    return value
            except ValueError:
                pass
            result = input("Please select a valid option: ")

    def ask_not_null_addition(self, field_name, model_name):
        "Adding a NOT NULL field to a model"
        choice = self._choice_input(
            "You are trying to add a non-nullable field '%s' to %s without a default;\n" % (field_name, model_name) +
            "we can't do that (the database needs something to populate existing rows).\n" +
            "Please select a fix:",
            [
                "Provide a one-off default now (will be set on all existing rows)",
                "Quit, and let me add a default in models.py",
            ]
        )
        if choice == 2:
            sys.exit(3)
        else:
            print("Please enter the default value now, as valid Python")
            print("The datetime module is available, so you can do e.g. datetime.date.today()")
            while True:
                code = input(">>> ")
                if not code:
                    print("Please enter some code, or 'exit' (with no quotes) to exit.")
                elif code == "exit":
                    sys.exit(1)
                else:
                    try:
                        return eval(code, {}, {"datetime": datetime_safe})
                    except (SyntaxError, NameError) as e:
                        print("Invalid input: %s" % e)

    def ask_rename(self, model_name, old_name, new_name, field_instance):
        "Was this field really renamed?"
        return self._boolean_input("Did you rename %s.%s to %s.%s (a %s)? [y/N]" % (model_name, old_name, model_name, new_name, field_instance.__class__.__name__), False)

    def ask_merge(self, app_label):
        return self._boolean_input(
            "\nMerging will only work if the operations printed above do not conflict\n" +
            "with each other (working on different fields or models)\n" +
            "Do you want to merge these migration branches? [y/N]",
            False,
        )

########NEW FILE########
__FILENAME__ = recorder
# Autogenerated from Django's django/db/migrations/recorder.py - do not edit

from south.app_cache import AppCache
from django.db import models
from django.utils.timezone import now


class MigrationRecorder(object):
    """
    Deals with storing migration records in the database.

    Because this table is actually itself used for dealing with model
    creation, it's the one thing we can't do normally via syncdb or migrations.
    We manually handle table creation/schema updating (using schema backend)
    and then have a floating model to do queries with.

    If a migration is unapplied its row is removed from the table. Having
    a row in the table always means a migration is applied.
    """

    class Migration(models.Model):
        app = models.CharField(max_length=255)
        name = models.CharField(max_length=255)
        applied = models.DateTimeField(default=now)

        class Meta:
            app_cache = AppCache()
            app_label = "migrations"
            db_table = "django_migrations"

    def __init__(self, connection):
        self.connection = connection

    def ensure_schema(self):
        """
        Ensures the table exists and has the correct schema.
        """
        # If the table's there, that's fine - we've never changed its schema
        # in the codebase.
        if self.Migration._meta.db_table in self.connection.introspection.get_table_list(self.connection.cursor()):
            return
        # Make the table
        with self.connection.schema_editor() as editor:
            editor.create_model(self.Migration)

    def applied_migrations(self):
        """
        Returns a set of (app, name) of applied migrations.
        """
        self.ensure_schema()
        return set(tuple(x) for x in self.Migration.objects.values_list("app", "name"))

    def record_applied(self, app, name):
        """
        Records that a migration was applied.
        """
        self.ensure_schema()
        self.Migration.objects.create(app=app, name=name)

    def record_unapplied(self, app, name):
        """
        Records that a migration was unapplied.
        """
        self.ensure_schema()
        self.Migration.objects.filter(app=app, name=name).delete()

    @classmethod
    def flush(cls):
        """
        Deletes all migration records. Useful if you're testing migrations.
        """
        cls.Migration.objects.all().delete()

########NEW FILE########
__FILENAME__ = mysql
# Autogenerated from Django's django/db/backends/mysql/schema.py - do not edit

from south.schema import BaseDatabaseSchemaEditor


class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):

    sql_rename_table = "RENAME TABLE %(old_table)s TO %(new_table)s"

    sql_alter_column_null = "MODIFY %(column)s %(type)s NULL"
    sql_alter_column_not_null = "MODIFY %(column)s %(type)s NOT NULL"
    sql_alter_column_type = "MODIFY %(column)s %(type)s"
    sql_rename_column = "ALTER TABLE %(table)s CHANGE %(old_column)s %(new_column)s %(type)s"

    sql_delete_unique = "ALTER TABLE %(table)s DROP INDEX %(name)s"

    sql_create_fk = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) REFERENCES %(to_table)s (%(to_column)s)"
    sql_delete_fk = "ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s"

    sql_delete_index = "DROP INDEX %(name)s ON %(table)s"

    sql_delete_pk = "ALTER TABLE %(table)s DROP PRIMARY KEY"

    alter_string_set_null = 'MODIFY %(column)s %(type)s NULL;'
    alter_string_drop_null = 'MODIFY %(column)s %(type)s NOT NULL;'

    sql_create_pk = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
    sql_delete_pk = "ALTER TABLE %(table)s DROP PRIMARY KEY"

########NEW FILE########
__FILENAME__ = oracle
# Autogenerated from Django's django/db/backends/oracle/schema.py - do not edit

import copy

from south.schema import BaseDatabaseSchemaEditor
from django.db.utils import DatabaseError


class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):

    sql_create_column = "ALTER TABLE %(table)s ADD %(column)s %(definition)s"
    sql_alter_column_type = "MODIFY %(column)s %(type)s"
    sql_alter_column_null = "MODIFY %(column)s NULL"
    sql_alter_column_not_null = "MODIFY %(column)s NOT NULL"
    sql_alter_column_default = "MODIFY %(column)s DEFAULT %(default)s"
    sql_alter_column_no_default = "MODIFY %(column)s DEFAULT NULL"
    sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
    sql_delete_table = "DROP TABLE %(table)s CASCADE CONSTRAINTS"

    def delete_model(self, model):
        # Run superclass action
        super(DatabaseSchemaEditor, self).delete_model(model)
        # Clean up any autoincrement trigger
        self.execute("""
            DECLARE
                i INTEGER;
            BEGIN
                SELECT COUNT(*) INTO i FROM USER_CATALOG
                    WHERE TABLE_NAME = '%(sq_name)s' AND TABLE_TYPE = 'SEQUENCE';
                IF i = 1 THEN
                    EXECUTE IMMEDIATE 'DROP SEQUENCE "%(sq_name)s"';
                END IF;
            END;
        /""" % {'sq_name': self.connection.ops._get_sequence_name(model._meta.db_table)})

    def alter_field(self, model, old_field, new_field, strict=False):
        try:
            # Run superclass action
            super(DatabaseSchemaEditor, self).alter_field(model, old_field, new_field, strict)
        except DatabaseError as e:
            description = str(e)
            # If we're changing to/from LOB fields, we need to do a
            # SQLite-ish workaround
            if 'ORA-22858' in description or 'ORA-22859' in description:
                self._alter_field_lob_workaround(model, old_field, new_field)
            else:
                raise

    def _alter_field_lob_workaround(self, model, old_field, new_field):
        """
        Oracle refuses to change a column type from/to LOB to/from a regular
        column. In Django, this shows up when the field is changed from/to
        a TextField.
        What we need to do instead is:
        - Add the desired field with a temporary name
        - Update the table to transfer values from old to new
        - Drop old column
        - Rename the new column
        """
        # Make a new field that's like the new one but with a temporary
        # column name.
        new_temp_field = copy.deepcopy(new_field)
        new_temp_field.column = self._generate_temp_name(new_field.column)
        # Add it
        self.add_field(model, new_temp_field)
        # Transfer values across
        self.execute("UPDATE %s set %s=%s" % (
            self.quote_name(model._meta.db_table),
            self.quote_name(new_temp_field.column),
            self.quote_name(old_field.column),
        ))
        # Drop the old field
        self.remove_field(model, old_field)
        # Rename the new field
        self.alter_field(model, new_temp_field, new_field)
        # Close the connection to force cx_Oracle to get column types right
        # on a new cursor
        self.connection.close()

    def normalize_name(self, name):
        """
        Get the properly shortened and uppercased identifier as returned by quote_name(), but without the actual quotes.
        """
        nn = self.quote_name(name)
        if nn[0] == '"' and nn[-1] == '"':
            nn = nn[1:-1]
        return nn

    def _generate_temp_name(self, for_name):
        """
        Generates temporary names for workarounds that need temp columns
        """
        suffix = hex(hash(for_name)).upper()[1:]
        return self.normalize_name(for_name + "_" + suffix)

    def prepare_default(self, value):
        return self.connection.ops.quote_parameter(value)

########NEW FILE########
__FILENAME__ = postgresql
# Autogenerated from Django's django/db/backends/postgresql_psycopg2/schema.py - do not edit

from south.schema import BaseDatabaseSchemaEditor


class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):

    sql_create_sequence = "CREATE SEQUENCE %(sequence)s"
    sql_delete_sequence = "DROP SEQUENCE IF EXISTS %(sequence)s CASCADE"
    sql_set_sequence_max = "SELECT setval('%(sequence)s', MAX(%(column)s)) FROM %(table)s"

    def _alter_column_type_sql(self, table, column, type):
        """
        Makes ALTER TYPE with SERIAL make sense.
        """
        if type.lower() == "serial":
            sequence_name = "%s_%s_seq" % (table, column)
            return (
                (
                    self.sql_alter_column_type % {
                        "column": self.quote_name(column),
                        "type": "integer",
                    },
                    [],
                ),
                [
                    (
                        self.sql_delete_sequence % {
                            "sequence": sequence_name,
                        },
                        [],
                    ),
                    (
                        self.sql_create_sequence % {
                            "sequence": sequence_name,
                        },
                        [],
                    ),
                    (
                        self.sql_alter_column % {
                            "table": table,
                            "changes": self.sql_alter_column_default % {
                                "column": column,
                                "default": "nextval('%s')" % sequence_name,
                            }
                        },
                        [],
                    ),
                    (
                        self.sql_set_sequence_max % {
                            "table": table,
                            "column": column,
                            "sequence": sequence_name,
                        },
                        [],
                    ),
                ],
            )
        else:
            return super(DatabaseSchemaEditor, self)._alter_column_type_sql(table, column, type)

########NEW FILE########
__FILENAME__ = sqlite3
# Autogenerated from Django's django/db/backends/sqlite3/schema.py - do not edit

from south.app_cache import AppCache
from south.schema import BaseDatabaseSchemaEditor
from django.db.models.fields.related import ManyToManyField


class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):

    sql_delete_table = "DROP TABLE %(table)s"

    def _remake_table(self, model, create_fields=[], delete_fields=[], alter_fields=[], rename_fields=[], override_uniques=None):
        """
        Shortcut to transform a model from old_model into new_model
        """
        # Work out the new fields dict / mapping
        body = dict((f.name, f) for f in model._meta.local_fields)
        mapping = dict((f.column, f.column) for f in model._meta.local_fields)
        # If any of the new or altered fields is introducing a new PK,
        # remove the old one
        restore_pk_field = None
        if any(f.primary_key for f in create_fields) or any(n.primary_key for o, n in alter_fields):
            for name, field in list(body.items()):
                if field.primary_key:
                    field.primary_key = False
                    restore_pk_field = field
                    if field.auto_created:
                        del body[name]
                        del mapping[field.column]
        # Add in any created fields
        for field in create_fields:
            body[field.name] = field
        # Add in any altered fields
        for (old_field, new_field) in alter_fields:
            del body[old_field.name]
            del mapping[old_field.column]
            body[new_field.name] = new_field
            mapping[new_field.column] = old_field.column
        # Remove any deleted fields
        for field in delete_fields:
            del body[field.name]
            del mapping[field.column]
        # Work inside a new AppCache
        app_cache = AppCache()
        # Construct a new model for the new state
        meta_contents = {
            'app_label': model._meta.app_label,
            'db_table': model._meta.db_table + "__new",
            'unique_together': model._meta.unique_together if override_uniques is None else override_uniques,
            'app_cache': app_cache,
        }
        meta = type("Meta", tuple(), meta_contents)
        body['Meta'] = meta
        body['__module__'] = model.__module__
        temp_model = type(model._meta.object_name, model.__bases__, body)
        # Create a new table with that format
        self.create_model(temp_model)
        # Copy data from the old table
        field_maps = list(mapping.items())
        self.execute("INSERT INTO %s (%s) SELECT %s FROM %s" % (
            self.quote_name(temp_model._meta.db_table),
            ', '.join(x for x, y in field_maps),
            ', '.join(y for x, y in field_maps),
            self.quote_name(model._meta.db_table),
        ))
        # Delete the old table
        self.delete_model(model)
        # Rename the new to the old
        self.alter_db_table(model, temp_model._meta.db_table, model._meta.db_table)
        # Run deferred SQL on correct table
        for sql in self.deferred_sql:
            self.execute(sql.replace(temp_model._meta.db_table, model._meta.db_table))
        self.deferred_sql = []
        # Fix any PK-removed field
        if restore_pk_field:
            restore_pk_field.primary_key = True

    def add_field(self, model, field):
        """
        Creates a field on a model.
        Usually involves adding a column, but may involve adding a
        table instead (for M2M fields)
        """
        # Special-case implicit M2M tables
        if isinstance(field, ManyToManyField) and field.rel.through._meta.auto_created:
            return self.create_model(field.rel.through)
        # Detect bad field combinations
        if (not field.null and
           (not field.has_default() or field.get_default() is None) and
           not field.empty_strings_allowed):
            raise ValueError("You cannot add a null=False column without a default value on SQLite.")
        self._remake_table(model, create_fields=[field])

    def remove_field(self, model, field):
        """
        Removes a field from a model. Usually involves deleting a column,
        but for M2Ms may involve deleting a table.
        """
        # Special-case implicit M2M tables
        if isinstance(field, ManyToManyField) and field.rel.through._meta.auto_created:
            return self.delete_model(field.rel.through)
        # For everything else, remake.
        self._remake_table(model, delete_fields=[field])

    def alter_field(self, model, old_field, new_field, strict=False):
        """
        Allows a field's type, uniqueness, nullability, default, column,
        constraints etc. to be modified.
        Requires a copy of the old field as well so we can only perform
        changes that are required.
        If strict is true, raises errors if the old column does not match old_field precisely.
        """
        old_db_params = old_field.db_parameters(connection=self.connection)
        old_type = old_db_params['type']
        new_db_params = new_field.db_parameters(connection=self.connection)
        new_type = new_db_params['type']
        if old_type is None and new_type is None and (old_field.rel.through and new_field.rel.through and old_field.rel.through._meta.auto_created and new_field.rel.through._meta.auto_created):
            return self._alter_many_to_many(model, old_field, new_field, strict)
        elif old_type is None or new_type is None:
            raise ValueError("Cannot alter field %s into %s - they are not compatible types (probably means only one is an M2M with implicit through model)" % (
                old_field,
                new_field,
            ))
        # Alter by remaking table
        self._remake_table(model, alter_fields=[(old_field, new_field)])

    def alter_unique_together(self, model, old_unique_together, new_unique_together):
        """
        Deals with a model changing its unique_together.
        Note: The input unique_togethers must be doubly-nested, not the single-
        nested ["foo", "bar"] format.
        """
        self._remake_table(model, override_uniques=new_unique_together)

    def _alter_many_to_many(self, model, old_field, new_field, strict):
        """
        Alters M2Ms to repoint their to= endpoints.
        """
        # Make a new through table
        self.create_model(new_field.rel.through)
        # Copy the data across
        self.execute("INSERT INTO %s (%s) SELECT %s FROM %s" % (
            self.quote_name(new_field.rel.through._meta.db_table),
            ', '.join([
                "id",
                new_field.m2m_column_name(),
                new_field.m2m_reverse_name(),
            ]),
            ', '.join([
                "id",
                old_field.m2m_column_name(),
                old_field.m2m_reverse_name(),
            ]),
            self.quote_name(old_field.rel.through._meta.db_table),
        ))
        # Delete the old through table
        self.delete_model(old_field.rel.through)

########NEW FILE########
__FILENAME__ = state
# Autogenerated from Django's django/db/migrations/state.py - do not edit

from south.app_cache import AppCache
from django.db import models
from django.db.models.options import DEFAULT_NAMES, normalize_unique_together
from django.utils import six
from django.utils.module_loading import import_by_path


class InvalidBasesError(ValueError):
    pass


class ProjectState(object):
    """
    Represents the entire project's overall state.
    This is the item that is passed around - we do it here rather than at the
    app level so that cross-app FKs/etc. resolve properly.
    """

    def __init__(self, models=None):
        self.models = models or {}
        self.app_cache = None

    def add_model_state(self, model_state):
        self.models[(model_state.app_label, model_state.name.lower())] = model_state

    def clone(self):
        "Returns an exact copy of this ProjectState"
        return ProjectState(
            models=dict((k, v.clone()) for k, v in self.models.items())
        )

    def render(self):
        "Turns the project state into actual models in a new AppCache"
        if self.app_cache is None:
            self.app_cache = AppCache()
            # We keep trying to render the models in a loop, ignoring invalid
            # base errors, until the size of the unrendered models doesn't
            # decrease by at least one, meaning there's a base dependency loop/
            # missing base.
            unrendered_models = list(self.models.values())
            while unrendered_models:
                new_unrendered_models = []
                for model in unrendered_models:
                    try:
                        model.render(self.app_cache)
                    except InvalidBasesError:
                        new_unrendered_models.append(model)
                if len(new_unrendered_models) == len(unrendered_models):
                    raise InvalidBasesError("Cannot resolve bases for %r" % new_unrendered_models)
                unrendered_models = new_unrendered_models
        return self.app_cache

    @classmethod
    def from_app_cache(cls, app_cache):
        "Takes in an AppCache and returns a ProjectState matching it"
        app_models = {}
        for model in app_cache.get_models():
            model_state = ModelState.from_model(model)
            app_models[(model_state.app_label, model_state.name.lower())] = model_state
        return cls(app_models)

    def __eq__(self, other):
        if set(self.models.keys()) != set(other.models.keys()):
            return False
        return all(model == other.models[key] for key, model in self.models.items())

    def __ne__(self, other):
        return not (self == other)


class ModelState(object):
    """
    Represents a Django Model. We don't use the actual Model class
    as it's not designed to have its options changed - instead, we
    mutate this one and then render it into a Model as required.

    Note that while you are allowed to mutate .fields, you are not allowed
    to mutate the Field instances inside there themselves - you must instead
    assign new ones, as these are not detached during a clone.
    """

    def __init__(self, app_label, name, fields, options=None, bases=None):
        self.app_label = app_label
        self.name = name
        self.fields = fields
        self.options = options or {}
        self.bases = bases or (models.Model, )
        # Sanity-check that fields is NOT a dict. It must be ordered.
        if isinstance(self.fields, dict):
            raise ValueError("ModelState.fields cannot be a dict - it must be a list of 2-tuples.")

    @classmethod
    def from_model(cls, model):
        """
        Feed me a model, get a ModelState representing it out.
        """
        # Deconstruct the fields
        fields = []
        for field in model._meta.local_fields:
            name, path, args, kwargs = field.deconstruct()
            field_class = import_by_path(path)
            try:
                fields.append((name, field_class(*args, **kwargs)))
            except TypeError as e:
                raise TypeError("Couldn't reconstruct field %s on %s.%s: %s" % (
                    name,
                    model._meta.app_label,
                    model._meta.object_name,
                    e,
                ))
        for field in model._meta.local_many_to_many:
            name, path, args, kwargs = field.deconstruct()
            field_class = import_by_path(path)
            try:
                fields.append((name, field_class(*args, **kwargs)))
            except TypeError as e:
                raise TypeError("Couldn't reconstruct m2m field %s on %s: %s" % (
                    name,
                    model._meta.object_name,
                    e,
                ))
        # Extract the options
        options = {}
        for name in DEFAULT_NAMES:
            # Ignore some special options
            if name in ["app_cache", "app_label"]:
                continue
            elif name in model._meta.original_attrs:
                if name == "unique_together":
                    ut = model._meta.original_attrs["unique_together"]
                    options[name] = set(normalize_unique_together(ut))
                else:
                    options[name] = model._meta.original_attrs[name]
        # Make our record
        bases = tuple(
            ("%s.%s" % (base._meta.app_label, base._meta.object_name.lower()) if hasattr(base, "_meta") else base)
            for base in model.__bases__
            if (not hasattr(base, "_meta") or not base._meta.abstract)
        )
        if not bases:
            bases = (models.Model, )
        return cls(
            model._meta.app_label,
            model._meta.object_name,
            fields,
            options,
            bases,
        )

    def clone(self):
        "Returns an exact copy of this ModelState"
        # We deep-clone the fields using deconstruction
        fields = []
        for name, field in self.fields:
            _, path, args, kwargs = field.deconstruct()
            field_class = import_by_path(path)
            fields.append((name, field_class(*args, **kwargs)))
        # Now make a copy
        return self.__class__(
            app_label=self.app_label,
            name=self.name,
            fields=fields,
            options=dict(self.options),
            bases=self.bases,
        )

    def render(self, app_cache):
        "Creates a Model object from our current state into the given app_cache"
        # First, make a Meta object
        meta_contents = {'app_label': self.app_label, "app_cache": app_cache}
        meta_contents.update(self.options)
        if "unique_together" in meta_contents:
            meta_contents["unique_together"] = list(meta_contents["unique_together"])
        meta = type("Meta", tuple(), meta_contents)
        # Then, work out our bases
        bases = tuple(
            (app_cache.get_model(*base.split(".", 1)) if isinstance(base, six.string_types) else base)
            for base in self.bases
        )
        if None in bases:
            raise InvalidBasesError("Cannot resolve one or more bases from %r" % (self.bases,))
        # Turn fields into a dict for the body, add other bits
        body = dict(self.fields)
        body['Meta'] = meta
        body['__module__'] = "__fake__"
        # Then, make a Model object
        return type(
            self.name,
            bases,
            body,
        )

    def get_field_by_name(self, name):
        for fname, field in self.fields:
            if fname == name:
                return field
        raise ValueError("No field called %s on model %s" % (name, self.name))

    def __eq__(self, other):
        return (
            (self.app_label == other.app_label) and
            (self.name == other.name) and
            (len(self.fields) == len(other.fields)) and
            all((k1 == k2 and (f1.deconstruct()[1:] == f2.deconstruct()[1:])) for (k1, f1), (k2, f2) in zip(self.fields, other.fields)) and
            (self.options == other.options) and
            (self.bases == other.bases)
        )

    def __ne__(self, other):
        return not (self == other)

########NEW FILE########
__FILENAME__ = writer
# Autogenerated from Django's django/db/migrations/writer.py - do not edit

from __future__ import unicode_literals

import datetime
from importlib import import_module
import os
import types

from south.app_cache import app_cache
from django.db import models
from django.utils.encoding import force_text
from django.utils.functional import Promise
from django.utils import six
from .loader import MigrationLoader


class MigrationWriter(object):
    """
    Takes a Migration instance and is able to produce the contents
    of the migration file from it.
    """

    def __init__(self, migration):
        self.migration = migration

    def as_string(self):
        """
        Returns a string of the file contents.
        """
        items = {
            "dependencies": repr(self.migration.dependencies),
            "replaces_str": "",
        }
        imports = set()
        # Deconstruct operations
        operation_strings = []
        for operation in self.migration.operations:
            name, args, kwargs = operation.deconstruct()
            arg_strings = []
            for arg in args:
                arg_string, arg_imports = self.serialize(arg)
                arg_strings.append(arg_string)
                imports.update(arg_imports)
            for kw, arg in kwargs.items():
                arg_string, arg_imports = self.serialize(arg)
                imports.update(arg_imports)
                arg_strings.append("%s = %s" % (kw, arg_string))
            operation_strings.append("migrations.%s(%s\n        )" % (name, "".join("\n            %s," % arg for arg in arg_strings)))
        items["operations"] = "[%s\n    ]" % "".join("\n        %s," % s for s in operation_strings)
        # Format imports nicely
        imports.discard("from django.db import models")
        if not imports:
            items["imports"] = ""
        else:
            items["imports"] = "\n".join(imports) + "\n"
        # If there's a replaces, make a string for it
        if self.migration.replaces:
            items['replaces_str'] = "\n    replaces = %s\n" % repr(self.migration.replaces)
        return (MIGRATION_TEMPLATE % items).encode("utf8")

    @property
    def filename(self):
        return "%s.py" % self.migration.name

    @property
    def path(self):
        migrations_package_name = MigrationLoader.migrations_module(self.migration.app_label)
        # See if we can import the migrations module directly
        try:
            migrations_module = import_module(migrations_package_name)
            basedir = os.path.dirname(migrations_module.__file__)
        except ImportError:
            app_config = app_cache.get_app_config(self.migration.app_label)
            migrations_package_basename = migrations_package_name.split(".")[-1]

            # Alright, see if it's a direct submodule of the app
            if '%s.%s' % (app_config.name, migrations_package_basename) == migrations_package_name:
                basedir = os.path.join(app_config.path, migrations_package_basename)
            else:
                raise ImportError("Cannot open migrations module %s for app %s" % (migrations_package_name, self.migration.app_label))
        return os.path.join(basedir, self.filename)

    @classmethod
    def serialize_deconstructed(cls, path, args, kwargs):
        module, name = path.rsplit(".", 1)
        if module == "django.db.models":
            imports = set(["from django.db import models"])
            name = "models.%s" % name
        else:
            imports = set(["import %s" % module])
            name = path
        arg_strings = []
        for arg in args:
            arg_string, arg_imports = cls.serialize(arg)
            arg_strings.append(arg_string)
            imports.update(arg_imports)
        for kw, arg in kwargs.items():
            arg_string, arg_imports = cls.serialize(arg)
            imports.update(arg_imports)
            arg_strings.append("%s=%s" % (kw, arg_string))
        return "%s(%s)" % (name, ", ".join(arg_strings)), imports

    @classmethod
    def serialize(cls, value):
        """
        Serializes the value to a string that's parsable by Python, along
        with any needed imports to make that string work.
        More advanced than repr() as it can encode things
        like datetime.datetime.now.
        """
        # Sequences
        if isinstance(value, (list, set, tuple)):
            imports = set()
            strings = []
            for item in value:
                item_string, item_imports = cls.serialize(item)
                imports.update(item_imports)
                strings.append(item_string)
            if isinstance(value, set):
                format = "set([%s])"
            elif isinstance(value, tuple):
                format = "(%s,)"
            else:
                format = "[%s]"
            return format % (", ".join(strings)), imports
        # Dictionaries
        elif isinstance(value, dict):
            imports = set()
            strings = []
            for k, v in value.items():
                k_string, k_imports = cls.serialize(k)
                v_string, v_imports = cls.serialize(v)
                imports.update(k_imports)
                imports.update(v_imports)
                strings.append((k_string, v_string))
            return "{%s}" % (", ".join("%s: %s" % (k, v) for k, v in strings)), imports
        # Datetimes
        elif isinstance(value, (datetime.datetime, datetime.date)):
            return repr(value), set(["import datetime"])
        # Simple types
        elif isinstance(value, six.integer_types + (float, six.binary_type, six.text_type, bool, type(None))):
            return repr(value), set()
        # Promise
        elif isinstance(value, Promise):
            return repr(force_text(value)), set()
        # Django fields
        elif isinstance(value, models.Field):
            attr_name, path, args, kwargs = value.deconstruct()
            return cls.serialize_deconstructed(path, args, kwargs)
        # Anything that knows how to deconstruct itself.
        elif hasattr(value, 'deconstruct'):
            return cls.serialize_deconstructed(*value.deconstruct())
        # Functions
        elif isinstance(value, (types.FunctionType, types.BuiltinFunctionType)):
            # @classmethod?
            if getattr(value, "__self__", None) and isinstance(value.__self__, type):
                klass = value.__self__
                module = klass.__module__
                return "%s.%s.%s" % (module, klass.__name__, value.__name__), set(["import %s" % module])
            elif value.__name__ == '<lambda>':
                raise ValueError("Cannot serialize function: lambda")
            elif value.__module__ is None:
                raise ValueError("Cannot serialize function %r: No module" % value)
            else:
                module = value.__module__
                return "%s.%s" % (module, value.__name__), set(["import %s" % module])
        # Classes
        elif isinstance(value, type):
            special_cases = [
                (models.Model, "models.Model", []),
            ]
            for case, string, imports in special_cases:
                if case is value:
                    return string, set(imports)
            if hasattr(value, "__module__"):
                module = value.__module__
                return "%s.%s" % (module, value.__name__), set(["import %s" % module])
        # Uh oh.
        else:
            raise ValueError("Cannot serialize: %r" % value)


MIGRATION_TEMPLATE = """# encoding: utf8
from django.db import models, migrations
%(imports)s

class Migration(migrations.Migration):
    %(replaces_str)s
    dependencies = %(dependencies)s

    operations = %(operations)s
"""

########NEW FILE########
__FILENAME__ = models
# Autogenerated from Django's tests/migrations/models.py - do not edit

# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from south.app_cache import AppCache
from django.db import models
from django.utils.encoding import python_2_unicode_compatible


@python_2_unicode_compatible
class UnicodeModel(models.Model):
    title = models.CharField('ÚÑÍ¢ÓÐÉ', max_length=20, default='“Ðjáñgó”')

    class Meta:
        # Disable auto loading of this model as we load it on our own
        app_cache = AppCache()
        verbose_name = 'úñí©óðé µóðéø'
        verbose_name_plural = 'úñí©óðé µóðéøß'

    def __str__(self):
        return self.title


class Unserializable(object):
    """
    An object that migration doesn't know how to serialize.
    """
    pass


class UnserializableModel(models.Model):
    title = models.CharField(max_length=20, default=Unserializable())

    class Meta:
        # Disable auto loading of this model as we load it on our own
        app_cache = AppCache()

########NEW FILE########
__FILENAME__ = test_base
# Autogenerated from Django's tests/migrations/test_base.py - do not edit

from django.test import TransactionTestCase
from django.db import connection


class MigrationTestBase(TransactionTestCase):
    """
    Contains an extended set of asserts for testing migrations and schema operations.
    """

    available_apps = ["migrations"]

    def assertTableExists(self, table):
        self.assertIn(table, connection.introspection.get_table_list(connection.cursor()))

    def assertTableNotExists(self, table):
        self.assertNotIn(table, connection.introspection.get_table_list(connection.cursor()))

    def assertColumnExists(self, table, column):
        self.assertIn(column, [c.name for c in connection.introspection.get_table_description(connection.cursor(), table)])

    def assertColumnNotExists(self, table, column):
        self.assertNotIn(column, [c.name for c in connection.introspection.get_table_description(connection.cursor(), table)])

    def assertColumnNull(self, table, column):
        self.assertEqual([c.null_ok for c in connection.introspection.get_table_description(connection.cursor(), table) if c.name == column][0], True)

    def assertColumnNotNull(self, table, column):
        self.assertEqual([c.null_ok for c in connection.introspection.get_table_description(connection.cursor(), table) if c.name == column][0], False)

    def assertIndexExists(self, table, columns, value=True):
        self.assertEqual(
            value,
            any(
                c["index"]
                for c in connection.introspection.get_constraints(connection.cursor(), table).values()
                if c['columns'] == list(columns)
            ),
        )

    def assertIndexNotExists(self, table, columns):
        return self.assertIndexExists(table, columns, False)

########NEW FILE########
__FILENAME__ = test_graph
# Autogenerated from Django's tests/migrations/test_graph.py - do not edit

from django.test import TestCase
from south.graph import MigrationGraph, CircularDependencyError


class GraphTests(TestCase):
    """
    Tests the digraph structure.
    """

    def test_simple_graph(self):
        """
        Tests a basic dependency graph:

        app_a:  0001 <-- 0002 <--- 0003 <-- 0004
                                 /
        app_b:  0001 <-- 0002 <-/
        """
        # Build graph
        graph = MigrationGraph()
        graph.add_node(("app_a", "0001"), None)
        graph.add_node(("app_a", "0002"), None)
        graph.add_node(("app_a", "0003"), None)
        graph.add_node(("app_a", "0004"), None)
        graph.add_node(("app_b", "0001"), None)
        graph.add_node(("app_b", "0002"), None)
        graph.add_dependency(("app_a", "0004"), ("app_a", "0003"))
        graph.add_dependency(("app_a", "0003"), ("app_a", "0002"))
        graph.add_dependency(("app_a", "0002"), ("app_a", "0001"))
        graph.add_dependency(("app_a", "0003"), ("app_b", "0002"))
        graph.add_dependency(("app_b", "0002"), ("app_b", "0001"))
        # Test root migration case
        self.assertEqual(
            graph.forwards_plan(("app_a", "0001")),
            [('app_a', '0001')],
        )
        # Test branch B only
        self.assertEqual(
            graph.forwards_plan(("app_b", "0002")),
            [("app_b", "0001"), ("app_b", "0002")],
        )
        # Test whole graph
        self.assertEqual(
            graph.forwards_plan(("app_a", "0004")),
            [('app_b', '0001'), ('app_b', '0002'), ('app_a', '0001'), ('app_a', '0002'), ('app_a', '0003'), ('app_a', '0004')],
        )
        # Test reverse to b:0002
        self.assertEqual(
            graph.backwards_plan(("app_b", "0002")),
            [('app_a', '0004'), ('app_a', '0003'), ('app_b', '0002')],
        )
        # Test roots and leaves
        self.assertEqual(
            graph.root_nodes(),
            set([('app_a', '0001'), ('app_b', '0001')]),
        )
        self.assertEqual(
            graph.leaf_nodes(),
            set([('app_a', '0004'), ('app_b', '0002')]),
        )

    def test_complex_graph(self):
        """
        Tests a complex dependency graph:

        app_a:  0001 <-- 0002 <--- 0003 <-- 0004
                      \        \ /         /
        app_b:  0001 <-\ 0002 <-X         /
                      \          \       /
        app_c:         \ 0001 <-- 0002 <-
        """
        # Build graph
        graph = MigrationGraph()
        graph.add_node(("app_a", "0001"), None)
        graph.add_node(("app_a", "0002"), None)
        graph.add_node(("app_a", "0003"), None)
        graph.add_node(("app_a", "0004"), None)
        graph.add_node(("app_b", "0001"), None)
        graph.add_node(("app_b", "0002"), None)
        graph.add_node(("app_c", "0001"), None)
        graph.add_node(("app_c", "0002"), None)
        graph.add_dependency(("app_a", "0004"), ("app_a", "0003"))
        graph.add_dependency(("app_a", "0003"), ("app_a", "0002"))
        graph.add_dependency(("app_a", "0002"), ("app_a", "0001"))
        graph.add_dependency(("app_a", "0003"), ("app_b", "0002"))
        graph.add_dependency(("app_b", "0002"), ("app_b", "0001"))
        graph.add_dependency(("app_a", "0004"), ("app_c", "0002"))
        graph.add_dependency(("app_c", "0002"), ("app_c", "0001"))
        graph.add_dependency(("app_c", "0001"), ("app_b", "0001"))
        graph.add_dependency(("app_c", "0002"), ("app_a", "0002"))
        # Test branch C only
        self.assertEqual(
            graph.forwards_plan(("app_c", "0002")),
            [('app_b', '0001'), ('app_c', '0001'), ('app_a', '0001'), ('app_a', '0002'), ('app_c', '0002')],
        )
        # Test whole graph
        self.assertEqual(
            graph.forwards_plan(("app_a", "0004")),
            [('app_b', '0001'), ('app_c', '0001'), ('app_a', '0001'), ('app_a', '0002'), ('app_c', '0002'), ('app_b', '0002'), ('app_a', '0003'), ('app_a', '0004')],
        )
        # Test reverse to b:0001
        self.assertEqual(
            graph.backwards_plan(("app_b", "0001")),
            [('app_a', '0004'), ('app_c', '0002'), ('app_c', '0001'), ('app_a', '0003'), ('app_b', '0002'), ('app_b', '0001')],
        )
        # Test roots and leaves
        self.assertEqual(
            graph.root_nodes(),
            set([('app_a', '0001'), ('app_b', '0001'), ('app_c', '0001')]),
        )
        self.assertEqual(
            graph.leaf_nodes(),
            set([('app_a', '0004'), ('app_b', '0002'), ('app_c', '0002')]),
        )

    def test_circular_graph(self):
        """
        Tests a circular dependency graph.
        """
        # Build graph
        graph = MigrationGraph()
        graph.add_node(("app_a", "0001"), None)
        graph.add_node(("app_a", "0002"), None)
        graph.add_node(("app_a", "0003"), None)
        graph.add_node(("app_b", "0001"), None)
        graph.add_node(("app_b", "0002"), None)
        graph.add_dependency(("app_a", "0003"), ("app_a", "0002"))
        graph.add_dependency(("app_a", "0002"), ("app_a", "0001"))
        graph.add_dependency(("app_a", "0001"), ("app_b", "0002"))
        graph.add_dependency(("app_b", "0002"), ("app_b", "0001"))
        graph.add_dependency(("app_b", "0001"), ("app_a", "0003"))
        # Test whole graph
        self.assertRaises(
            CircularDependencyError,
            graph.forwards_plan, ("app_a", "0003"),
        )

########NEW FILE########
__FILENAME__ = runtests

########NEW FILE########
__FILENAME__ = models
# Autogenerated from Django's tests/schema/models.py - do not edit

from south.app_cache import AppCache
from django.db import models

# Because we want to test creation and deletion of these as separate things,
# these models are all inserted into a separate AppCache so the main test
# runner doesn't migrate them.

new_app_cache = AppCache()


class Author(models.Model):
    name = models.CharField(max_length=255)
    height = models.PositiveIntegerField(null=True, blank=True)

    class Meta:
        app_cache = new_app_cache


class AuthorWithM2M(models.Model):
    name = models.CharField(max_length=255)

    class Meta:
        app_cache = new_app_cache


class Book(models.Model):
    author = models.ForeignKey(Author)
    title = models.CharField(max_length=100, db_index=True)
    pub_date = models.DateTimeField()
    # tags = models.ManyToManyField("Tag", related_name="books")

    class Meta:
        app_cache = new_app_cache


class BookWithM2M(models.Model):
    author = models.ForeignKey(Author)
    title = models.CharField(max_length=100, db_index=True)
    pub_date = models.DateTimeField()
    tags = models.ManyToManyField("TagM2MTest", related_name="books")

    class Meta:
        app_cache = new_app_cache


class BookWithSlug(models.Model):
    author = models.ForeignKey(Author)
    title = models.CharField(max_length=100, db_index=True)
    pub_date = models.DateTimeField()
    slug = models.CharField(max_length=20, unique=True)

    class Meta:
        app_cache = new_app_cache
        db_table = "schema_book"


class Tag(models.Model):
    title = models.CharField(max_length=255)
    slug = models.SlugField(unique=True)

    class Meta:
        app_cache = new_app_cache


class TagM2MTest(models.Model):
    title = models.CharField(max_length=255)
    slug = models.SlugField(unique=True)

    class Meta:
        app_cache = new_app_cache


class TagIndexed(models.Model):
    title = models.CharField(max_length=255)
    slug = models.SlugField(unique=True)

    class Meta:
        app_cache = new_app_cache
        index_together = [["slug", "title"]]


class TagUniqueRename(models.Model):
    title = models.CharField(max_length=255)
    slug2 = models.SlugField(unique=True)

    class Meta:
        app_cache = new_app_cache
        db_table = "schema_tag"


class UniqueTest(models.Model):
    year = models.IntegerField()
    slug = models.SlugField(unique=False)

    class Meta:
        app_cache = new_app_cache
        unique_together = ["year", "slug"]


class BookWithLongName(models.Model):
    author_foreign_key_with_really_long_field_name = models.ForeignKey(Author)

    class Meta:
        app_cache = new_app_cache

########NEW FILE########
__FILENAME__ = tests
# Autogenerated from Django's tests/schema/tests.py - do not edit

from __future__ import absolute_import
import datetime
import unittest

from django.test import TransactionTestCase
from django.db import connection, DatabaseError, IntegrityError
from django.db.models.fields import IntegerField, TextField, CharField, SlugField
from django.db.models.fields.related import ManyToManyField, ForeignKey
from django.db.transaction import atomic
from .models import (Author, AuthorWithM2M, Book, BookWithLongName,
    BookWithSlug, BookWithM2M, Tag, TagIndexed, TagM2MTest, TagUniqueRename,
    UniqueTest)


class SchemaTests(TransactionTestCase):
    """
    Tests that the schema-alteration code works correctly.

    Be aware that these tests are more liable than most to false results,
    as sometimes the code to check if a test has worked is almost as complex
    as the code it is testing.
    """

    available_apps = []

    models = [
        Author, AuthorWithM2M, Book, BookWithLongName, BookWithSlug,
        BookWithM2M, Tag, TagIndexed, TagM2MTest, TagUniqueRename, UniqueTest,
    ]

    # Utility functions

    def tearDown(self):
        # Delete any tables made for our models
        self.delete_tables()

    def delete_tables(self):
        "Deletes all model tables for our models for a clean test environment"
        cursor = connection.cursor()
        connection.disable_constraint_checking()
        table_names = connection.introspection.table_names(cursor)
        for model in self.models:
            # Remove any M2M tables first
            for field in model._meta.local_many_to_many:
                with atomic():
                    tbl = field.rel.through._meta.db_table
                    if tbl in table_names:
                        cursor.execute(connection.schema_editor().sql_delete_table % {
                            "table": connection.ops.quote_name(tbl),
                        })
                        table_names.remove(tbl)
            # Then remove the main tables
            with atomic():
                tbl = model._meta.db_table
                if tbl in table_names:
                    cursor.execute(connection.schema_editor().sql_delete_table % {
                        "table": connection.ops.quote_name(tbl),
                    })
                    table_names.remove(tbl)
        connection.enable_constraint_checking()

    def column_classes(self, model):
        cursor = connection.cursor()
        columns = dict(
            (d[0], (connection.introspection.get_field_type(d[1], d), d))
            for d in connection.introspection.get_table_description(
                cursor,
                model._meta.db_table,
            )
        )
        # SQLite has a different format for field_type
        for name, (type, desc) in columns.items():
            if isinstance(type, tuple):
                columns[name] = (type[0], desc)
        # SQLite also doesn't error properly
        if not columns:
            raise DatabaseError("Table does not exist (empty pragma)")
        return columns

    # Tests

    def test_creation_deletion(self):
        """
        Tries creating a model's table, and then deleting it.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Check that it's there
        list(Author.objects.all())
        # Clean up that table
        with connection.schema_editor() as editor:
            editor.delete_model(Author)
        # Check that it's gone
        self.assertRaises(
            DatabaseError,
            lambda: list(Author.objects.all()),
        )

    @unittest.skipUnless(connection.features.supports_foreign_keys, "No FK support")
    def test_fk(self):
        "Tests that creating tables out of FK order, then repointing, works"
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Book)
            editor.create_model(Author)
            editor.create_model(Tag)
        # Check that initial tables are there
        list(Author.objects.all())
        list(Book.objects.all())
        # Make sure the FK constraint is present
        with self.assertRaises(IntegrityError):
            Book.objects.create(
                author_id=1,
                title="Much Ado About Foreign Keys",
                pub_date=datetime.datetime.now(),
            )
        # Repoint the FK constraint
        new_field = ForeignKey(Tag)
        new_field.set_attributes_from_name("author")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Book,
                Book._meta.get_field_by_name("author")[0],
                new_field,
                strict=True,
            )
        # Make sure the new FK constraint is present
        constraints = connection.introspection.get_constraints(connection.cursor(), Book._meta.db_table)
        for name, details in constraints.items():
            if details['columns'] == ["author_id"] and details['foreign_key']:
                self.assertEqual(details['foreign_key'], ('schema_tag', 'id'))
                break
        else:
            self.fail("No FK constraint for author_id found")

    def test_add_field(self):
        """
        Tests adding fields to models
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure there's no age field
        columns = self.column_classes(Author)
        self.assertNotIn("age", columns)
        # Alter the name field to a TextField
        new_field = IntegerField(null=True)
        new_field.set_attributes_from_name("age")
        with connection.schema_editor() as editor:
            editor.add_field(
                Author,
                new_field,
            )
        # Ensure the field is right afterwards
        columns = self.column_classes(Author)
        self.assertEqual(columns['age'][0], "IntegerField")
        self.assertEqual(columns['age'][1][6], True)

    def test_alter(self):
        """
        Tests simple altering of fields
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the field is right to begin with
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "CharField")
        self.assertEqual(bool(columns['name'][1][6]), bool(connection.features.interprets_empty_strings_as_nulls))
        # Alter the name field to a TextField
        new_field = TextField(null=True)
        new_field.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Author,
                Author._meta.get_field_by_name("name")[0],
                new_field,
                strict=True,
            )
        # Ensure the field is right afterwards
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "TextField")
        self.assertEqual(columns['name'][1][6], True)
        # Change nullability again
        new_field2 = TextField(null=False)
        new_field2.set_attributes_from_name("name")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Author,
                new_field,
                new_field2,
                strict=True,
            )
        # Ensure the field is right afterwards
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "TextField")
        self.assertEqual(bool(columns['name'][1][6]), False)

    def test_rename(self):
        """
        Tests simple altering of fields
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the field is right to begin with
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "CharField")
        self.assertNotIn("display_name", columns)
        # Alter the name field's name
        new_field = CharField(max_length=254)
        new_field.set_attributes_from_name("display_name")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Author,
                Author._meta.get_field_by_name("name")[0],
                new_field,
                strict=True,
            )
        # Ensure the field is right afterwards
        columns = self.column_classes(Author)
        self.assertEqual(columns['display_name'][0], "CharField")
        self.assertNotIn("name", columns)

    def test_m2m_create(self):
        """
        Tests M2M fields on models during creation
        """
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(TagM2MTest)
            editor.create_model(BookWithM2M)
        # Ensure there is now an m2m table there
        columns = self.column_classes(BookWithM2M._meta.get_field_by_name("tags")[0].rel.through)
        self.assertEqual(columns['tagm2mtest_id'][0], "IntegerField")

    def test_m2m(self):
        """
        Tests adding/removing M2M fields on models
        """
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(AuthorWithM2M)
            editor.create_model(TagM2MTest)
        # Create an M2M field
        new_field = ManyToManyField("schema.TagM2MTest", related_name="authors")
        new_field.contribute_to_class(AuthorWithM2M, "tags")
        try:
            # Ensure there's no m2m table there
            self.assertRaises(DatabaseError, self.column_classes, new_field.rel.through)
            # Add the field
            with connection.schema_editor() as editor:
                editor.add_field(
                    Author,
                    new_field,
                )
            # Ensure there is now an m2m table there
            columns = self.column_classes(new_field.rel.through)
            self.assertEqual(columns['tagm2mtest_id'][0], "IntegerField")
            # Remove the M2M table again
            with connection.schema_editor() as editor:
                editor.remove_field(
                    Author,
                    new_field,
                )
            # Ensure there's no m2m table there
            self.assertRaises(DatabaseError, self.column_classes, new_field.rel.through)
        finally:
            # Cleanup model states
            AuthorWithM2M._meta.local_many_to_many.remove(new_field)

    def test_m2m_repoint(self):
        """
        Tests repointing M2M fields
        """
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithM2M)
            editor.create_model(TagM2MTest)
            editor.create_model(UniqueTest)
        # Ensure the M2M exists and points to TagM2MTest
        constraints = connection.introspection.get_constraints(connection.cursor(), BookWithM2M._meta.get_field_by_name("tags")[0].rel.through._meta.db_table)
        if connection.features.supports_foreign_keys:
            for name, details in constraints.items():
                if details['columns'] == ["tagm2mtest_id"] and details['foreign_key']:
                    self.assertEqual(details['foreign_key'], ('schema_tagm2mtest', 'id'))
                    break
            else:
                self.fail("No FK constraint for tagm2mtest_id found")
        # Repoint the M2M
        new_field = ManyToManyField(UniqueTest)
        new_field.contribute_to_class(BookWithM2M, "uniques")
        try:
            with connection.schema_editor() as editor:
                editor.alter_field(
                    Author,
                    BookWithM2M._meta.get_field_by_name("tags")[0],
                    new_field,
                )
            # Ensure old M2M is gone
            self.assertRaises(DatabaseError, self.column_classes, BookWithM2M._meta.get_field_by_name("tags")[0].rel.through)
            # Ensure the new M2M exists and points to UniqueTest
            constraints = connection.introspection.get_constraints(connection.cursor(), new_field.rel.through._meta.db_table)
            if connection.features.supports_foreign_keys:
                for name, details in constraints.items():
                    if details['columns'] == ["uniquetest_id"] and details['foreign_key']:
                        self.assertEqual(details['foreign_key'], ('schema_uniquetest', 'id'))
                        break
                else:
                    self.fail("No FK constraint for uniquetest_id found")
        finally:
            # Cleanup through table separately
            with connection.schema_editor() as editor:
                editor.remove_field(BookWithM2M, BookWithM2M._meta.get_field_by_name("uniques")[0])
            # Cleanup model states
            BookWithM2M._meta.local_many_to_many.remove(new_field)
            del BookWithM2M._meta._m2m_cache

    @unittest.skipUnless(connection.features.supports_check_constraints, "No check constraints")
    def test_check_constraints(self):
        """
        Tests creating/deleting CHECK constraints
        """
        # Create the tables
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the constraint exists
        constraints = connection.introspection.get_constraints(connection.cursor(), Author._meta.db_table)
        for name, details in constraints.items():
            if details['columns'] == ["height"] and details['check']:
                break
        else:
            self.fail("No check constraint for height found")
        # Alter the column to remove it
        new_field = IntegerField(null=True, blank=True)
        new_field.set_attributes_from_name("height")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Author,
                Author._meta.get_field_by_name("height")[0],
                new_field,
                strict=True,
            )
        constraints = connection.introspection.get_constraints(connection.cursor(), Author._meta.db_table)
        for name, details in constraints.items():
            if details['columns'] == ["height"] and details['check']:
                self.fail("Check constraint for height found")
        # Alter the column to re-add it
        with connection.schema_editor() as editor:
            editor.alter_field(
                Author,
                new_field,
                Author._meta.get_field_by_name("height")[0],
                strict=True,
            )
        constraints = connection.introspection.get_constraints(connection.cursor(), Author._meta.db_table)
        for name, details in constraints.items():
            if details['columns'] == ["height"] and details['check']:
                break
        else:
            self.fail("No check constraint for height found")

    def test_unique(self):
        """
        Tests removing and adding unique constraints to a single column.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        # Ensure the field is unique to begin with
        Tag.objects.create(title="foo", slug="foo")
        self.assertRaises(IntegrityError, Tag.objects.create, title="bar", slug="foo")
        Tag.objects.all().delete()
        # Alter the slug field to be non-unique
        new_field = SlugField(unique=False)
        new_field.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Tag,
                Tag._meta.get_field_by_name("slug")[0],
                new_field,
                strict=True,
            )
        # Ensure the field is no longer unique
        Tag.objects.create(title="foo", slug="foo")
        Tag.objects.create(title="bar", slug="foo")
        Tag.objects.all().delete()
        # Alter the slug field to be unique
        new_new_field = SlugField(unique=True)
        new_new_field.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Tag,
                new_field,
                new_new_field,
                strict=True,
            )
        # Ensure the field is unique again
        Tag.objects.create(title="foo", slug="foo")
        self.assertRaises(IntegrityError, Tag.objects.create, title="bar", slug="foo")
        Tag.objects.all().delete()
        # Rename the field
        new_field = SlugField(unique=False)
        new_field.set_attributes_from_name("slug2")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Tag,
                Tag._meta.get_field_by_name("slug")[0],
                TagUniqueRename._meta.get_field_by_name("slug2")[0],
                strict=True,
            )
        # Ensure the field is still unique
        TagUniqueRename.objects.create(title="foo", slug2="foo")
        self.assertRaises(IntegrityError, TagUniqueRename.objects.create, title="bar", slug2="foo")
        Tag.objects.all().delete()

    def test_unique_together(self):
        """
        Tests removing and adding unique_together constraints on a model.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(UniqueTest)
        # Ensure the fields are unique to begin with
        UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.create(year=2011, slug="foo")
        UniqueTest.objects.create(year=2011, slug="bar")
        self.assertRaises(IntegrityError, UniqueTest.objects.create, year=2012, slug="foo")
        UniqueTest.objects.all().delete()
        # Alter the model to it's non-unique-together companion
        with connection.schema_editor() as editor:
            editor.alter_unique_together(
                UniqueTest,
                UniqueTest._meta.unique_together,
                [],
            )
        # Ensure the fields are no longer unique
        UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.create(year=2012, slug="foo")
        UniqueTest.objects.all().delete()
        # Alter it back
        new_new_field = SlugField(unique=True)
        new_new_field.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_unique_together(
                UniqueTest,
                [],
                UniqueTest._meta.unique_together,
            )
        # Ensure the fields are unique again
        UniqueTest.objects.create(year=2012, slug="foo")
        self.assertRaises(IntegrityError, UniqueTest.objects.create, year=2012, slug="foo")
        UniqueTest.objects.all().delete()

    def test_index_together(self):
        """
        Tests removing and adding index_together constraints on a model.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        # Ensure there's no index on the year/slug columns first
        self.assertEqual(
            False,
            any(
                c["index"]
                for c in connection.introspection.get_constraints(connection.cursor(), "schema_tag").values()
                if c['columns'] == ["slug", "title"]
            ),
        )
        # Alter the model to add an index
        with connection.schema_editor() as editor:
            editor.alter_index_together(
                Tag,
                [],
                [("slug", "title")],
            )
        # Ensure there is now an index
        self.assertEqual(
            True,
            any(
                c["index"]
                for c in connection.introspection.get_constraints(connection.cursor(), "schema_tag").values()
                if c['columns'] == ["slug", "title"]
            ),
        )
        # Alter it back
        new_new_field = SlugField(unique=True)
        new_new_field.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_index_together(
                Tag,
                [("slug", "title")],
                [],
            )
        # Ensure there's no index
        self.assertEqual(
            False,
            any(
                c["index"]
                for c in connection.introspection.get_constraints(connection.cursor(), "schema_tag").values()
                if c['columns'] == ["slug", "title"]
            ),
        )

    def test_create_index_together(self):
        """
        Tests creating models with index_together already defined
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(TagIndexed)
        # Ensure there is an index
        self.assertEqual(
            True,
            any(
                c["index"]
                for c in connection.introspection.get_constraints(connection.cursor(), "schema_tagindexed").values()
                if c['columns'] == ["slug", "title"]
            ),
        )

    def test_db_table(self):
        """
        Tests renaming of the table
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
        # Ensure the table is there to begin with
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "CharField")
        # Alter the table
        with connection.schema_editor() as editor:
            editor.alter_db_table(
                Author,
                "schema_author",
                "schema_otherauthor",
            )
        # Ensure the table is there afterwards
        Author._meta.db_table = "schema_otherauthor"
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "CharField")
        # Alter the table again
        with connection.schema_editor() as editor:
            editor.alter_db_table(
                Author,
                "schema_otherauthor",
                "schema_author",
            )
        # Ensure the table is still there
        Author._meta.db_table = "schema_author"
        columns = self.column_classes(Author)
        self.assertEqual(columns['name'][0], "CharField")

    def test_indexes(self):
        """
        Tests creation/altering of indexes
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(Book)
        # Ensure the table is there and has the right index
        self.assertIn(
            "title",
            connection.introspection.get_indexes(connection.cursor(), Book._meta.db_table),
        )
        # Alter to remove the index
        new_field = CharField(max_length=100, db_index=False)
        new_field.set_attributes_from_name("title")
        with connection.schema_editor() as editor:
            editor.alter_field(
                Book,
                Book._meta.get_field_by_name("title")[0],
                new_field,
                strict=True,
            )
        # Ensure the table is there and has no index
        self.assertNotIn(
            "title",
            connection.introspection.get_indexes(connection.cursor(), Book._meta.db_table),
        )
        # Alter to re-add the index
        with connection.schema_editor() as editor:
            editor.alter_field(
                Book,
                new_field,
                Book._meta.get_field_by_name("title")[0],
                strict=True,
            )
        # Ensure the table is there and has the index again
        self.assertIn(
            "title",
            connection.introspection.get_indexes(connection.cursor(), Book._meta.db_table),
        )
        # Add a unique column, verify that creates an implicit index
        with connection.schema_editor() as editor:
            editor.add_field(
                Book,
                BookWithSlug._meta.get_field_by_name("slug")[0],
            )
        self.assertIn(
            "slug",
            connection.introspection.get_indexes(connection.cursor(), Book._meta.db_table),
        )
        # Remove the unique, check the index goes with it
        new_field2 = CharField(max_length=20, unique=False)
        new_field2.set_attributes_from_name("slug")
        with connection.schema_editor() as editor:
            editor.alter_field(
                BookWithSlug,
                BookWithSlug._meta.get_field_by_name("slug")[0],
                new_field2,
                strict=True,
            )
        self.assertNotIn(
            "slug",
            connection.introspection.get_indexes(connection.cursor(), Book._meta.db_table),
        )

    def test_primary_key(self):
        """
        Tests altering of the primary key
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Tag)
        # Ensure the table is there and has the right PK
        self.assertTrue(
            connection.introspection.get_indexes(connection.cursor(), Tag._meta.db_table)['id']['primary_key'],
        )
        # Alter to change the PK
        new_field = SlugField(primary_key=True)
        new_field.set_attributes_from_name("slug")
        new_field.model = Tag
        with connection.schema_editor() as editor:
            editor.remove_field(Tag, Tag._meta.get_field_by_name("id")[0])
            editor.alter_field(
                Tag,
                Tag._meta.get_field_by_name("slug")[0],
                new_field,
            )
        # Ensure the PK changed
        self.assertNotIn(
            'id',
            connection.introspection.get_indexes(connection.cursor(), Tag._meta.db_table),
        )
        self.assertTrue(
            connection.introspection.get_indexes(connection.cursor(), Tag._meta.db_table)['slug']['primary_key'],
        )

    def test_context_manager_exit(self):
        """
        Ensures transaction is correctly closed when an error occurs
        inside a SchemaEditor context.
        """
        class SomeError(Exception):
            pass
        try:
            with connection.schema_editor():
                raise SomeError
        except SomeError:
            self.assertFalse(connection.in_atomic_block)

    def test_foreign_key_index_long_names_regression(self):
        """
        Regression test for #21497. Only affects databases that supports
        foreign keys.
        """
        # Create the table
        with connection.schema_editor() as editor:
            editor.create_model(Author)
            editor.create_model(BookWithLongName)
        # Find the properly shortened column name
        column_name = connection.ops.quote_name("author_foreign_key_with_really_long_field_name_id")
        column_name = column_name[1:-1].lower()  # unquote, and, for Oracle, un-upcase
        # Ensure the table is there and has an index on the column
        self.assertIn(
            column_name,
            connection.introspection.get_indexes(connection.cursor(), BookWithLongName._meta.db_table),
        )

########NEW FILE########
