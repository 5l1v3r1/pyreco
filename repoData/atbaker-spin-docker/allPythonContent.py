__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# spin-docker documentation build configuration file, created by
# sphinx-quickstart on Mon Feb 24 02:54:32 2014.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = []

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'spin-docker'
copyright = u'2014, Andrew T. Baker'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.1.0'
# The full version, including alpha/beta/rc tags.
release = '0.1.0'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'spin-dockerdoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  ('index', 'spin-docker.tex', u'spin-docker Documentation',
   u'Andrew T. Baker', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'spin-docker', u'spin-docker Documentation',
     [u'Andrew T. Baker'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'spin-docker', u'spin-docker Documentation',
   u'Andrew T. Baker', 'spin-docker', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False

########NEW FILE########
__FILENAME__ = runserver
from spindocker import app

import os

if os.environ['ENVIRONMENT'] == 'production':
    app.run()
else:
    app.run(debug=True, host='0.0.0.0', port=80)

########NEW FILE########
__FILENAME__ = tasks
from celery import Celery
from docker import APIError
from spindocker.utils import r, client, RUNNING, STOPPED

import os

celery = Celery('spin_docker',
                broker='amqp://',)

# Timeout intervals
DISABLE_TIMEOUTS = os.environ.get('DISABLE_TIMEOUTS')
INITIAL_TIMEOUT_INTERVAL = int(os.environ['INITIAL_TIMEOUT_INTERVAL'])
TIMEOUT_INTERVAL = int(os.environ['TIMEOUT_INTERVAL'])


def get_container_ports(port_info):
    spin_docker_ports = {'ssh_port': '', 'app_port': ''}

    for port, value in port_info.iteritems():
        if value is not None:
            key = 'ssh_port' if port == '22/tcp' else 'app_port'
            spin_docker_ports[key] = value[0]['HostPort']

    return spin_docker_ports

def delete_container_ip(container_id):
    """Deletes a container's IP mapping in redis."""
    container_ip = client.inspect_container(
        container_id)['NetworkSettings']['IPAddress']
    r.delete('ips:%s' % container_ip)

def audit_containers():
    """Reviews all known containers and updates their information in redis."""
    for ip_address in r.keys('ips:*'):
        r.delete(ip_address)

    containers = [r.hgetall(container) for container in r.keys('containers:*')]

    for container in containers:
        container_id = container['container_id']
        try:
            docker_info = client.inspect_container(container_id)
        except APIError:
            r.delete('containers:%s' % container_id)
            break

        if docker_info['State']['Running']:
            ports = get_container_ports(docker_info['NetworkSettings']['Ports'])
            r.hmset('containers:%s' % container_id, {
                    'status': RUNNING, 'active': 0,
                    'ssh_port': ports['ssh_port'],
                    'app_port': ports['app_port']})
            r.set('ips:%s' %
                  docker_info['NetworkSettings']['IPAddress'], container_id)
        else:
            r.hmset('containers:%s' % container_id, {
                    'status': STOPPED, 'active': 0, 'ssh_port': '', 'app_port': ''})

def start_container(container_id):
    """Starts a container. Never actually invoked asynchronously."""
    client.start(container_id, publish_all_ports=True)

    container_details = client.inspect_container(container_id)

    # Gather info about the new container
    container = {'container_id': container_id,
                 'name': container_details['Name'],
                 'image': container_details['Config']['Image'],
                 'status': RUNNING,
                 'active': 0}

    # Get new container's ports
    ports = get_container_ports(container_details['NetworkSettings']['Ports'])
    container.update(ports)

    r.hmset('containers:%s' % container_id, container)

    container_ip = container_details['NetworkSettings']['IPAddress']
    r.set('ips:%s' % container_ip, container_id)

    if not DISABLE_TIMEOUTS:
        check_container_activity.apply_async(
            args=(container_id,), countdown=INITIAL_TIMEOUT_INTERVAL)

    return container


@celery.task(bind=True, max_retries=3, default_retry_delay=30)
def stop_container(self, container_id):
    """Stops a container asynchronously."""
    delete_container_ip(container_id)

    try:
        client.stop(container_id)
    except APIError as exception:
        raise self.retry(exc=exception)

    r.hmset('containers:%s' % container_id, {
            'status': STOPPED, 'active': 0, 'ssh_port': '', 'app_port': ''})


@celery.task(bind=True, max_retries=3, default_retry_delay=30)
def remove_container(self, container_id):
    """Deletes a container asynchronously."""
    delete_container_ip(container_id)

    try:
        client.stop(container_id)
        client.remove_container(container_id)
    except APIError as exception:
        raise self.retry(exc=exception)

    r.delete('containers:%s' % container_id)


@celery.task
def check_container_activity(container_id, final=False):
    """Checks a container's activity.

    Containers configured for spin-docker activity monitoring regularly POST to
    the /check-in URL indicating whether they are active or not.

    If spin-docker is configured to check container activity, this celery task
    is scheduled when the container is started to check on the container after
    the INITIAL_TIMEOUT_INTERVAL setting. For each check after that, it uses the
    TIMEOUT_INTERVAL setting.

    The first time this task finds no container activity, it schedules itself
    for one last check after another TIMEOUT_INTERVAL. If there is still no
    activity, it stops the container.
    """
    container = r.hgetall('containers:%s' % container_id)
    if container and container['status'] == RUNNING:
        inactive = container['active'] == '0'

        if inactive:
            if final:
                stop_container.delay(container_id)
                return 'stopping container'
            else:
                check_container_activity.apply_async(
                    args=(container_id,), kwargs={'final': True, }, countdown=TIMEOUT_INTERVAL)
                return 'container inactive'
        else:
            check_container_activity.apply_async(
                args=(container_id,), countdown=TIMEOUT_INTERVAL)
            return 'container active'

########NEW FILE########
__FILENAME__ = utils
from docker import Client

import redis

r = redis.StrictRedis(host='localhost', port=6379)
client = Client()

# Status constants
RUNNING = 'running'
STOPPED = 'stopped'
STOPPING = 'stopping'

########NEW FILE########
__FILENAME__ = views
from itertools import chain
import os

from docker import APIError
from flask import request
from flask.ext.httpauth import HTTPBasicAuth
from flask.ext.restful import reqparse, abort, Resource, fields, marshal, types
from spindocker.tasks import audit_containers, start_container, stop_container, remove_container
from spindocker.utils import r, client, RUNNING, STOPPED, STOPPING

from spindocker import app, api

auth = HTTPBasicAuth()

users = {
    "admin": os.environ['SPIN_DOCKER_PASSWORD'],
}

@app.before_first_request
def startup_audit():
    audit_containers()

@auth.get_password
def get_pw(username):
    """Returns the password specified in 'SPIN_DOCKER_PASSWORD'."""
    return users.get(username)

container_fields = {
    'container_id': fields.String,
    'name': fields.String,
    'image': fields.String,
    'ssh_port': fields.String,
    'app_port': fields.String,
    'status': fields.String,
    'active': fields.String,
    'uri': fields.Url('container'),
}


def abort_if_container_doesnt_exist(container_id):
    """Checks that a container is found before proceeding with a request."""
    if not r.exists('containers:%s' % container_id):
        abort(404, message="Container %s doesn't exist" % container_id)


class ImageList(Resource):
    decorators = [auth.login_required, ]

    def __init__(self):
        self.reqparse = reqparse.RequestParser()
        super(ImageList, self).__init__()

    def get(self):
        """Gets a list of all tagged images for the /images endpoint."""
        repo_tag_iter = (image['RepoTags'] for image in client.images())
        return [repotag for repotag in chain.from_iterable(repo_tag_iter) \
            if repotag != u'<none>:<none>']


class ContainerList(Resource):
    decorators = [auth.login_required, ]

    def __init__(self):
        self.reqparse = reqparse.RequestParser()
        super(ContainerList, self).__init__()

    def get(self):
        """Returns all containers for the /containers endpoint."""
        self.reqparse.add_argument('audit', type=types.boolean, default=False,)
        args = self.reqparse.parse_args()

        if args['audit']:
            audit_containers()

        containers = [r.hgetall(container) for container in r.keys('containers:*')]
        return [marshal(c, container_fields) for c in containers]

    def post(self):
        """Creates a new container based on a POST to /containers."""
        self.reqparse.add_argument(
            'image', type=str, required=True, help='Image cannot be blank')
        args = self.reqparse.parse_args()

        # Check that image exists
        try:
            image = client.inspect_image(args['image'])
        except APIError:
            abort(500, message="Image %s not found on this server" %
                  args['image'])

        if not image['container_config']['ExposedPorts']:
            abort(500, message="This image does not expose any ports. \
                Use the EXPOSE command in your dockerfile to specify some.")

        # Create and start the container
        try:
            result = client.create_container(image=args['image'],
                                             detach=True,
                                             )
            container_id = result['Id']
            container = start_container(container_id)
        except APIError as exception:
            abort(500, message=exception.explanation)

        return marshal(container, container_fields), 201


class Container(Resource):
    decorators = [auth.login_required, ]

    def __init__(self):
        self.reqparse = reqparse.RequestParser()
        self.reqparse.add_argument('status', type=str)
        super(Container, self).__init__()

    def get(self, container_id):
        """Returns information about a single container."""
        abort_if_container_doesnt_exist(container_id)
        container = r.hgetall('containers:%s' % container_id)
        return marshal(container, container_fields)

    def patch(self, container_id):
        """Updates information on a single container. Currently just status."""
        args = self.reqparse.parse_args()

        if 'status' in args:
            if args['status'] == STOPPED:
                stop_container.delay(container_id)
                r.hset('containers:%s' % container_id, 'status', STOPPING)
            elif args['status'] == RUNNING:
                try:
                    start_container(container_id)
                except APIError as exception:
                    abort(500, message=exception.explanation)

        container = r.hgetall('containers:%s' % container_id)
        return marshal(container, container_fields)

    def delete(self, container_id):
        """Stops and deletes a single container."""
        abort_if_container_doesnt_exist(container_id)
        remove_container.delay(container_id)
        return '', 204

# Setup the Api resource routing here
api.add_resource(ImageList, '/v1/images', endpoint='images')
api.add_resource(ContainerList, '/v1/containers', endpoint='containers')
api.add_resource(
    Container, '/v1/containers/<string:container_id>', endpoint='container')


@app.route('/v1/check-in', methods=['POST'])
def check_in():
    """Processes activity reports from the containers."""
    active = request.form['active']
    container_ip = request.remote_addr
    container_id = r.get('ips:%s' % container_ip)
    if container_id is not None:
        r.hset('containers:%s' %
               container_id, 'active', active)
    return ''

########NEW FILE########
__FILENAME__ = tests
import base64
import os
import unittest
import time

import redis
from docker import Client
from flask import json
from mock import Mock

# Disable timeouts for testing
CURRENT_DISABLE_TIMEOUTS = os.environ.get('DISABLE_TIMEOUTS')
os.environ['DISABLE_TIMEOUTS'] = 'True'

existing_containers = []

r = redis.StrictRedis(host='localhost', port=6379)
client = Client()

from spindocker import app
from spindocker.tasks import celery, check_container_activity

celery.conf.CELERY_ALWAYS_EAGER = True

class SpinDockerTestCase(unittest.TestCase):

    @classmethod
    def setUpClass(self):
        for c in client.containers(all=True, quiet=True):
            existing_containers.append(c['Id'])
        r.flushall()

    @classmethod
    def tearDownClass(self):
        for c in client.containers(all=True, quiet=True):
            if c['Id'] not in existing_containers:
                client.kill(c['Id'])
                client.remove_container(c['Id'])

        if not CURRENT_DISABLE_TIMEOUTS:
            del os.environ['DISABLE_TIMEOUTS']

    def setUp(self):
        # Set HTTP basic authentication headers
        self.auth = {'Authorization': 'Basic ' + \
            base64.b64encode('admin' + ":" + os.environ['SPIN_DOCKER_PASSWORD'])}   
        self.app = app.test_client()

    def tearDown(self):
        r.flushall()

    def _get_containers(self):
        resp = self.app.get('/v1/containers', headers=self.auth)
        data = json.loads(resp.data)
        return data

    def _create_container(self, image='atbaker/sd-postgres'):
        resp = self.app.post('/v1/containers', 
            headers=self.auth,
            data={'image': image})
        data = json.loads(resp.data)
        return data

    def test_bad_authentication(self):
        resp = self.app.get('/v1/containers', 
            headers={'Authorization': 'Basic ' + \
            base64.b64encode('wrong' + ":" + 'user')})

        self.assertEqual(resp.status_code, 401)

    def test_no_authentication(self):
        resp = self.app.get('/v1/containers')

        self.assertEqual(resp.status_code, 401)

    def test_get_images(self):
        resp = self.app.get('/v1/images',
            headers=self.auth)     
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 200)
        self.assertIn('atbaker/sd-postgres:latest', data)

    def test_container_list_empty(self):
        data = self._get_containers()
        self.assertEqual(data, [])

    def test_container_list_one_container(self):
        container = self._create_container()

        data = self._get_containers()

        self.assertEqual(len(data), 1)
        self.assertEqual(data[0], container)

    def test_container_list_multiple_containers(self):
        container_one = self._create_container()
        container_two = self._create_container()

        data = self._get_containers()

        self.assertEqual(len(data), 2)
        self.assertIn(container_one, data)
        self.assertIn(container_two, data)

    def test_create_container_bad_image_name(self):
        resp = self.app.post('/v1/containers',
            headers=self.auth, 
            data={'image': 'badimage'})
        data = json.loads(resp.data)

        self.assertEqual(500, resp.status_code)
        self.assertEqual('Image badimage not found on this server', data['message'])

    def test_container_get(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.get('/v1/containers/%s' % container_id,
            headers=self.auth)
        data = json.loads(resp.data)

        self.assertEqual(container, data)
        self.assertIn('container_id', data.keys())
        self.assertIn('image', data.keys())
        self.assertIn('uri', data.keys())        
        self.assertIn('app_port', data.keys())
        self.assertIn('ssh_port', data.keys())
        self.assertIn('active', data.keys())

    def test_container_get_bad_container_id(self):
        self._create_container()
        bad_container_id = '1337'

        resp = self.app.get('/v1/containers/%s' % bad_container_id,
            headers=self.auth)
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 404)
        self.assertEqual(data['message'], "Container %s doesn't exist" % bad_container_id)

    def test_container_delete(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.delete('/v1/containers/%s' % container_id,
            headers=self.auth)

        self.assertEqual(resp.status_code, 204)
        self.assertEqual(self._get_containers(), [])

    def test_container_stop(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.patch('/v1/containers/%s' % container_id, 
            headers=self.auth,
            data=dict(status='stopped'))
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 200)
        self.assertEqual(data['status'], 'stopping')

    def test_container_start(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.patch('/v1/containers/%s' % container_id, 
            headers=self.auth,
            data=dict(status='stopped'))
        resp = self.app.patch('/v1/containers/%s' % container_id,
            headers=self.auth,
            data=dict(status='running'))
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 200)
        self.assertEqual(data['status'], 'running')

    def test_container_start_already_running(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.patch('/v1/containers/%s' % container_id,
            headers=self.auth,
            data=dict(status='running'))
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 500)
        self.assertIn("Cannot start container %s" % container_id, data['message'])

    def test_container_audit_remove_container(self):
        container = self._create_container()
        container_id = container['container_id']

        client.kill(container_id)
        client.remove_container(container_id)

        resp = self.app.get('/v1/containers?audit=true',
            headers=self.auth)
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 200)
        self.assertEqual(data, [])

    def test_container_audit_stopped_container(self):
        container = self._create_container()
        container_id = container['container_id']

        client.stop(container_id)

        resp = self.app.get('/v1/containers?audit=true',
            headers=self.auth)
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 200)
        self.assertEqual(data[0]['status'], 'stopped')
        self.assertEqual(data[0]['ssh_port'], '')
        self.assertEqual(data[0]['app_port'], '')
        self.assertEqual(data[0]['active'], '0')

    def test_container_audit_started_container(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.patch('/v1/containers/%s' % container_id,
            headers=self.auth,
            data=dict(status='stopped'))
        self.assertEqual(resp.status_code, 200)

        client.start(container_id)

        resp = self.app.get('/v1/containers?audit=true',
            headers=self.auth)
        data = json.loads(resp.data)

        self.assertEqual(resp.status_code, 200)
        self.assertEqual(data[0]['status'], 'running')

    def test_check_activity_no_container(self):
        result = check_container_activity('bad_container_id')

        self.assertIsNone(result)

    def test_check_activity_not_running(self):
        container = self._create_container()
        container_id = container['container_id']

        resp = self.app.patch('/v1/containers/%s' % container_id,
            headers=self.auth,
            data=dict(status='stopped'))

        result = check_container_activity(container_id)

        self.assertIsNone(result)

    def test_check_activity_active_connections(self):
        container = self._create_container()
        container_id = container['container_id']
        r.hset('containers:%s' % container_id, 'active', '1')

        # Mock apply_async so we don't get stuck in infinite loop
        check_container_activity.apply_async = Mock()

        result = check_container_activity(container_id)

        self.assertEqual(result, 'container active')
        self.assertTrue(check_container_activity.apply_async.called)

    def test_check_activity_no_connections(self):
        container = self._create_container()
        container_id = container['container_id']

        result = check_container_activity(container_id)

        self.assertEqual(result, 'container inactive')

    def test_check_activity_no_connections_final(self):
        container = self._create_container()
        container_id = container['container_id']

        result = check_container_activity(container_id, final=True)

        self.assertEqual(result, 'stopping container')

    def test_check_in(self):
        container = self._create_container()
        container_id = container['container_id']

        self.app.post('/v1/check-in',
            headers=self.auth,
            data={'active': 1},
            environ_base={'REMOTE_ADDR': client.inspect_container(container_id)['NetworkSettings']['IPAddress'],})

        container_active = r.hget('containers:%s' % container_id, 'active')

        self.assertEqual(container_active, '1')

    def test_check_in_nonexistent_container(self):
        resp = self.app.post('/v1/check-in',
            headers=self.auth,
            data={'active': 1},
            environ_base={'REMOTE_ADDR': '127.0.0.99',})

        self.assertEqual(resp.status_code, 200)
        self.assertEqual(resp.data, '')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
