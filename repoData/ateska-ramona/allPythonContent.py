__FILENAME__ = demo
#!/usr/bin/env python
#
# Released under the BSD license. See LICENSE.txt file for details.
#
import os
import ramona

class MyDemoConsoleApp(ramona.console_app):

	@ramona.tool
	def tool_demo(self):
		"""Printing message about demo of custom ramona.tool"""
		print "This is implementation of custom tool (see ./demo.sh --help)"
		# Example how to access configuration from tool:
		print "Value of env:RAMONADEMO = {0}".format(self.config.get("env", "RAMONADEMO"))
		env = ramona.config.get_env()
		print "All environment variables", env
		print
		env_alternative1 = ramona.config.get_env("alternative1")
		print "All alternative1 environment variables", env_alternative1



	@ramona.tool
	class tool_class_demo(object):
		"""Demo of custom ramona.tool (class)"""

		def init_parser(self, cnsapp, parser):
			parser.description = 'You can use methods from argparse module of Python to customize tool (sub)parser.'
			parser.add_argument('integers', metavar='N', type=int, nargs='+', 
				help='an integer for the accumulator'
			)
			parser.add_argument('--sum', dest='accumulate', action='store_const',
				const=sum, default=max,
				help='sum the integers (default: find the max)'
			)

		def main(self, cnsapp, args):
			print args.accumulate(args.integers)


	@ramona.proxy_tool
	def proxy_tool_demo(self, argv):
		"""Proxying execution of /bin/ls"""
		os.execv('/bin/ls', argv)


if __name__ == '__main__':
	app = MyDemoConsoleApp(configuration='./demo.conf')
	app.run()

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Ramona documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 15 19:55:30 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = []

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Ramona'
copyright = u'2012-2013, Ales Teska'

# The short X.Y version.
version = '1.1'

# The full version, including alpha/beta/rc tags.
release = '1.1b1'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the _static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Ramonadoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Ramona.tex', u'Ramona Documentation',
   u'Ales Teska', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'ramona', u'Ramona Documentation',
     [u'Ales Teska'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Ramona', u'Ramona Documentation',
   u'Ales Teska', 'Ramona', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = cnscom
import os, struct, time, json, select, logging
###

L = logging.getLogger("cnscom")
Lmy = logging.getLogger("my")

###

callid_ping = 70
callid_start = 71
callid_stop = 72
callid_restart = 73
callid_status = 74
callid_tail = 75
callid_tailf_stop = 76 # Terminate previously initialized tailf mode
callid_init = 77
callid_who = 78
callid_notify = 79

#

call_magic = '>'
resp_magic = '<'

call_struct_fmt = '!cBH'
resp_struct_fmt = '!ccH'

resp_return = 'R'
resp_exception = 'E'
resp_yield_message = 'M' # Used to propagate message from server to console
resp_tailf_data = 'T' # Used to send data in tail -f mode

###

class program_state_enum(object):
	'''Enum'''
	DISABLED = -1
	STOPPED = 0
	STARTING = 10
	RUNNING = 20
	STOPPING = 30
	FATAL = 200
	CFGERROR=201

	labels = {
		DISABLED: 'DISABLED',
		STOPPED: 'STOPPED',
		STARTING: 'STARTING',
		RUNNING: 'RUNNING',
		STOPPING: 'STOPPING',
		FATAL: 'FATAL',
		CFGERROR: 'CFGERROR',
	}


###


def svrcall(cnssocket, callid, params=""):
	'''
	Client side of console communication IPC call (kind of RPC / Remote procedure call).

	@param cnssocket: Socket to server (created by socket_uri factory)
	@param callid: one of callid_* identification
	@param params: string representing parameters that will be passed to server call
	@return: String returned by server or raises exception if server call failed
	'''

	paramlen = len(params)
	if paramlen >= 0x7fff:
		raise RuntimeError("Transmitted parameters are too long.")

	cnssocket.send(struct.pack(call_struct_fmt, call_magic, callid, paramlen)+params)

	while 1:
		retype, params = svrresp(cnssocket, hang_message="callid : {0}".format(callid))

		if retype == resp_return:
			# Remote server call returned normally
			return params
		
		elif retype == resp_exception:
			# Remove server call returned exception
			raise RuntimeError(params)
		
		elif retype == resp_yield_message:
			# Remote server call returned yielded message -> we will continue receiving
			obj = json.loads(params)
			obj = logging.makeLogRecord(obj)
			if Lmy.getEffectiveLevel() <= obj.levelno: # Print only if log level allows that
				Lmy.handle(obj)
			continue

		else:
			raise RuntimeError("Unknown/invalid server response: {0}".format(retype))

###

def svrresp(cnssocket, hang_detector=True, hang_message='details not provided'):
	'''Receive and parse one server response - used inherently by svrcall.

	@param cnssocket: Socket to server (created by socket_uri factory)
	@param hang_detector: If set to True, logs warning when server is not responding in 2 seconds	
	@param hang_message: Details about server call to be included in eventual hang message
	@return: tuple(retype, params) - retype is cnscom.resp_* integer and params are data attached to given response
	'''

	x = time.time()
	resp = ""
	while len(resp) < 4:
		rlist, _, _ = select.select([cnssocket],[],[], 5)
		if len(rlist) == 0:
			if hang_detector and time.time() - x > 5:
				x = time.time()
				L.warning("Possible server hang detected: {0} (continue waiting)".format(hang_message))
			continue
		ndata = cnssocket.recv(4 - len(resp))
		if len(ndata) == 0:
			raise EOFError("It looks like server closed connection")

		resp += ndata

	magic, retype, paramlen = struct.unpack(resp_struct_fmt, resp)
	assert magic == resp_magic

	# Read rest of the response (size given by paramlen)
	params = ""
	while paramlen > 0:
		ndata = cnssocket.recv(paramlen)
		params += ndata
		paramlen -= len(ndata)

	return retype, params

###

def parse_json_kwargs(params):
	'''Used when params are transfered as JSON - it also handles situation when 'params' is empty string '''
	if params == '': return dict()
	return json.loads(params)

###

class svrcall_error(RuntimeError):
	'''
	Exception used to report error to the console without leaving trace in server error log.
	'''
	pass

########NEW FILE########
__FILENAME__ = config
from __future__ import print_function
import os, sys, logging, re, platform, ConfigParser
###

L = logging.getLogger("config")

###

# Defaults are stated in documentation, if you change them here, update documentation too!
config_defaults = {
	'general' : {
		'appname' : 'ramona-driven-app',
		'logdir' : '<env>',
		'include' : '<siteconf>',
		'logmaxsize': '{0}'.format(512*1024*1024), # 512Mb
		'logbackups': '3',
		'logcompress': '1'
	},
	'ramona:server' : {
		'consoleuri': 'unix://.ramona.sock',
		'consoleuri@windows': 'tcp://localhost:7788',
		'pidfile': '',
		'log': '<logdir>',
		'loglevel': 'INFO',
	},
	'ramona:console' : {
		'serveruri': 'unix://.ramona.sock',
		'serveruri@windows': 'tcp://localhost:7788',
		'history': '',
	},
	'ramona:notify' : {
		'delivery': '',
		'sender': '<user>',
		'dailyat': '09:00',
		'notify_fatal': 'now',
		'logscan_stdout': '',
		'logscan_stderr': '',
		'logscan': '',
		'stashdir': '<none>',
	},
	'ramona:httpfend': {
		'listenaddr': "tcp://localhost:5588",
	}
	
}

###

config = ConfigParser.SafeConfigParser()
config.optionxform = str # Disable default 'lowecasing' behavior of ConfigParser
config_files = []
config_includes = []

config_platform_selector = platform.system().lower()

###

def read_config(configs=None, use_env=True):
	global config
	assert len(config.sections()) == 0

	# Prepare platform selector regex
	psrg = re.compile('^(.*)@(.*)$')

	# Load config_defaults
	psdefaults = []
	for section, items in config_defaults.iteritems():
		if not config.has_section(section):
			config.add_section(section)

		for key, val in items.iteritems():
			r = psrg.match(key)
			if r is None:
				config.set(section, key, val)
			else:
				if r.group(2) != config_platform_selector: continue
				psdefaults.append((section, r.group(1), val))

	# Handle platform selectors in config_defaults
	for section, key, val in psdefaults:
		config.set(section, key, val)


	# Load configuration files
	global config_files

	if configs is not None: configs = configs[:]
	else: configs = []
	if use_env:
		# Configs from environment variables
		config_envs = os.environ.get('RAMONA_CONFIG')
		if config_envs is not None:
			for config_file in config_envs.split(os.pathsep):
				configs.append(config_file)

	for cfile in configs:
		rfile = os.path.abspath(os.path.expanduser(cfile))
		if os.path.isfile(rfile):
			config_files.append(rfile)
		config.read([rfile])


	# Handle includes ...
	appname = config.get('general','appname')
	for _ in range(100):
		includes = config.get('general','include')
		if includes == '': break
		config.set('general','include','')
		includes = includes.split(';')
		for i in xrange(len(includes)-1,-1,-1):
			include = includes[i] = includes[i].strip()
			if include == '<siteconf>':
				# These are platform specific
				siteconfs = [
					'./site.conf',
					'./{}-site.conf'.format(appname),
					'/etc/{0}.conf'.format(appname),
					'~/.{0}.conf'.format(appname),
				]
				includes[i:i+1] = siteconfs
			elif include[:1] == '<':
				print('WARNING: Unknown include fragment: {0}'.format(include), file=sys.stderr)
				continue

		for include in includes:
			rinclude = os.path.abspath(os.path.expanduser(include))
			if os.path.isfile(rinclude):
				config_includes.append(rinclude)
				config.read([rinclude])

	else:
		raise RuntimeError("FATAL: It looks like we have loop in configuration includes!")

	# Threat platform selector alternatives
	if config_platform_selector is not None and config_platform_selector != '':
		for section in config.sections():
			for name, value in config.items(section):
				r = psrg.match(name)
				if r is None: continue
				if (r.group(2) != config_platform_selector): continue
				config.set(section, r.group(1), value)

	# Special treatment of some values
	if config.get('general', 'logdir') == '<env>':
		logdir = os.environ.get('LOGDIR')
		if logdir is None: logdir = os.curdir
		logdir = os.path.expanduser(logdir)
		config.set('general','logdir',logdir)
	elif config.get('general', 'logdir').strip()[:1] == '<':
		raise RuntimeError("FATAL: Unknown magic value in [general] logdir: '{}'".format(config.get('general', 'logdir')))
	
	for (sec, valname) in (("ramona:server", "consoleuri"), ("ramona:notify", "delivery")):
		if ";" in config.get(sec, valname):
			print(
				"WARNING: ';' character was found in URI: {}. Please note that ';' has been replaced '?' in Ramona 1.0. This can lead to Ramona apparent freeze during start.".format(
					config.get(sec, valname)
				),
				file=sys.stderr
			)

	stashdir = config.get('ramona:notify', 'stashdir')
	if stashdir != '<none>':
		if not os.path.isdir(stashdir):
			os.makedirs(stashdir)

###

def get_boolean(value):
	'''
	Translates string/<any-type> value into boolean value. It is kind of similar to ConfigParser.getboolean but this one is used also in different places of code
	'''
	if value is True: return True
	if value is False: return False

	value = str(value)

	if value.upper() in ('TRUE','ON','YES','1'):
		return True
	elif value.upper() in ('FALSE','OFF','NO','0'):
		return False
	else:
		raise ValueError("Invalid boolean string '{0}'' (use one of true, on, yes, false, off or no).".format(value))

###

def get_numeric_loglevel(loglevelstring):
	'''
	Translates log level given in string into numeric value.
	'''
	numeric_level = getattr(logging, loglevelstring.upper(), None)
	if not isinstance(numeric_level, int): raise ValueError('Invalid log level: {0}'.format(loglevelstring))
	return numeric_level

###

def get_logconfig():
	'''
	return (logbackups, logmaxsize, logcompress) tupple
	'''
	if config.get('general','logmaxsize') == '<inf>':
		logbackups = 0
		logmaxsize = 0
		logcompress = False

	else:
		try:
			# TODO: Parse human-friendly logmaxsize ... e.g. 10Mb
			logmaxsize = config.getint('general','logmaxsize')
			x = config.get('general','logbackups')
			if x == '<inf>':
				logbackups = 0
			else:
				logbackups = int(x)
			logcompress = config.getboolean('general', 'logcompress')
		except Exception, e:
			logbackups = 0
			logmaxsize = 0
			logcompress = False
			L.warning("Invalid configuration of log rotation: {0} - log rotation disabled".format(e))

	return logbackups, logmaxsize, logcompress


def get_env(alt_env=None):
	"""
	Get environment variables dictionary from config.
	If not argument provided, it is taken from [env] section of the configuration merged with os.environ
	If alt_env argument is provided, it is taken from [env:<alt_env>] section merged with os.environ

	Return is compatible with os.exec family of functions.
	"""
	if alt_env is not None:
		section = "env:{0}".format(alt_env)
	else:
		section = "env"
	env = os.environ.copy()

	if config.has_section(section):
		for name, value in config.items(section):
			if value != '':
				env[name] = value
			else:
				env.pop(name, 0)
	return env


########NEW FILE########
__FILENAME__ = console
import os, cmd, logging, sys, functools
from ...config import config
from ... import cnscom

###

name = 'console'
cmdhelp = 'Enter interactive console mode'

###

L = logging.getLogger("console")

###

def init_parser(parser):
	return

###

try:
	import readline
except ImportError:
	readline = None

if readline is not None:
	# See http://stackoverflow.com/questions/7116038/python-tab-completion-mac-osx-10-7-lion
	if 'libedit' in readline.__doc__:
		readline.parse_and_bind("bind ^I rl_complete")
	else:
		readline.parse_and_bind("tab: complete")

###

class _console_cmd(cmd.Cmd):

	def __init__(self, cnsapp):
		self.prompt = '> '
		self.cnsapp = cnsapp
		

		from ..parser import consoleparser
		self.parser = consoleparser(self.cnsapp)

		# Build dummy method for each command in the parser
		for cmdname, cmditem in self.parser.subcommands.iteritems():
			def do_cmd_template(self, _cmdline):
				try:
					self.parser.execute(self.cnsapp)
				except Exception, e:
					L.error("{0}".format(e))

			setattr(self.__class__, "do_{0}".format(cmdname), do_cmd_template)
			
			if hasattr(cmditem, "complete"):
				setattr(self.__class__, "complete_{0}".format(cmdname), cmditem.complete)

		# Add also proxy_tools
		self.proxy_tool_set = set()
		for mn in dir(cnsapp):
			fn = getattr(cnsapp, mn)
			if not hasattr(fn, '__proxy_tool'): continue

			self.proxy_tool_set.add(mn)
			setattr(self.__class__, "do_{0}".format(mn), functools.partial(launch_proxy_tool, fn, mn))


		cmd.Cmd.__init__(self)


	def precmd(self, line):
		if line == '': return ''
		if line == "EOF":
			print
			sys.exit(0)

		# Check if this is proxy tool - if yes, then bypass parser
		try:
			farg, _ = line.split(' ',1)
		except ValueError:
			farg = line
		farg = farg.strip()
		if farg in self.proxy_tool_set:
			return line

		try:
			self.parser.parse(line.split())
		except SyntaxError: # To capture cases like 'xxx' (avoid exiting)
			self.parser.parse(['help'])
			return 'help'
		except SystemExit: # To capture cases like 'tail -xxx' (avoid exiting)
			self.parser.parse(['help'])
			return 'help'
		return line


	def emptyline(self):
		# Send 'ping' to server
		try:
			self.cnsapp.cnssvrcall(cnscom.callid_ping, '', auto_connect=True)
		except Exception, e:
			L.error("{0}".format(e))
	
#

def main(cnsapp, args):
	from ... import version as ramona_version
	L.info("Ramona (version {0}) console for {1}".format(ramona_version, config.get('general','appname')))

	histfile = config.get('ramona:console', 'history')
	if histfile != '':
		histfile = os.path.expanduser(histfile)
		try:
			if readline is not None: readline.read_history_file(histfile)
		except IOError:
			pass

	c = _console_cmd(cnsapp)
	try:
		c.cmdloop()
	
	except Exception, e:
		L.exception("Exception during cmd loop:")

	except KeyboardInterrupt:
		print ""
	
	finally:
		if readline is not None and histfile != '':
			try:
				readline.write_history_file(histfile)
			except Exception, e:
				L.warning("Cannot write console history file '{1}': {0}".format(e, histfile))

#

def launch_proxy_tool(fn, cmd, cmdline):
	'''
	To launch proxy tool, we need to fork and then call proxy_tool method in child.
	Parent is waiting for child exit ...
	'''
	cmdline = cmdline.split(' ')
	cmdline.insert(0, cmd)

	pid = os.fork()
	if pid == 0:
		# Child
		try:
			fn(cmdline)
		except Exception, e:
			print "Execution of tool failed: ", e
		os._exit(0)
	else:
		# Parent
		ret = os.waitpid(pid, 0) # Wait for child process to finish


########NEW FILE########
__FILENAME__ = exit
import sys
###

name = 'exit'
cmdhelp = 'Exit console'

###

def init_parser(parser):
	return

###

def main(cnsapp, args):
	sys.exit(0) # Ignore return code from application

########NEW FILE########
__FILENAME__ = help

name = 'help'
cmdhelp = 'Display help'

###

def init_parser(parser):
	return

def main(cnsapp, args):
	'''Stub that actually does nothing'''
	pass
########NEW FILE########
__FILENAME__ = notify
import json, logging
from ... import cnscom

###

name = 'notify'
cmdhelp = 'Insert notification'

###

L = logging.getLogger('notify')

###

def init_parser(parser):
	parser.add_argument('-t','--target', action='store', choices=['now','daily'], default='now', help='Specify target of notification. Default is "now".')
	parser.add_argument('-s','--subject', action='store', help="Specify subject of notification.")
	parser.add_argument('text', help='Body of notification.')

def main(cnsapp, args):
	params = {
		'target': args.target,
		'subject': args.subject,
		'text': args.text
	}
	ret = cnsapp.cnssvrcall(
		cnscom.callid_notify,
		json.dumps(params),
		auto_connect=True
	)

########NEW FILE########
__FILENAME__ = restart
import json
from ... import cnscom
from ._completions import complete_ident

###

name = 'restart'
cmdhelp = 'Restart program(s)'

###

def init_parser(parser):
	parser.add_argument('-n','--no-server-start', action='store_true', help='Avoid eventual automatic Ramona server start')
	parser.add_argument('-i','--immediate-return', action='store_true', help="Don't wait for restart of programs and exit ASAP")
	parser.add_argument('-f','--force-start', action='store_true', help='Force restart of programs even in FATAL state')
	parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command. If none is given, all programs are considered in scope.')

###

def complete(console, text, line, begidx, endidx):
	textst = text.strip()
	ret = []
	ret.extend(complete_ident(console, textst))
	return ret

###

def main(cnsapp, args):
	params={
		'force':args.force_start,
		'immediate': args.immediate_return,
	}
	if len(args.program) > 0: params['pfilter'] = args.program

	cnsapp.cnssvrcall(
		cnscom.callid_restart,
		json.dumps(params),
		auto_connect=args.no_server_start,
		auto_server_start=not args.no_server_start
	)

########NEW FILE########
__FILENAME__ = server
from .. import exception

###

name = 'server'
cmdhelp = 'Start the Ramona server in the foreground'

###

def init_parser(parser):
	parser.add_argument('-S','--server-only', action='store_true', help='Start only server, programs are not launched')
	parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command. If none is given, all programs are considered in scope.')

###

def main(cnsapp, args):
	if args.server_only:
		if len(args.program) > 0:
			raise exception.parameters_error('Cannot specify programs and -S option at once.')

	from ...utils import launch_server
	launch_server(args.server_only, args.program)

########NEW FILE########
__FILENAME__ = start
import json
from ... import cnscom
from .. import exception
from ._completions import complete_ident
###

name = 'start'
cmdhelp = 'Start program(s)'

###

def init_parser(parser):
	parser.add_argument('-n','--no-server-start', action='store_true', help='Avoid eventual automatic start of Ramona server')
	parser.add_argument('-i','--immediate-return', action='store_true', help="Don't wait for start of programs and exit ASAP")
	parser.add_argument('-f','--force-start', action='store_true', help='Force start of programs even if they are in FATAL state')
	parser.add_argument('-S','--server-only', action='store_true', help='Start only server, programs are not started')
	parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command. If none is given, all programs are considered in scope.')

###

def complete(console, text, line, begidx, endidx):
	textst = text.strip()
	ret = []
	ret.extend(complete_ident(console, textst))
	return ret

###

def main(cnsapp, args):

	if args.server_only:
		if len(args.program) > 0:
			raise exception.parameters_error('Cannot specify programs and -S option at once.')
		cnsapp.auto_server_start()
		return

	params={
		'force': args.force_start,
		'immediate': args.immediate_return,
	}
	if len(args.program) > 0: params['pfilter'] = args.program

	cnsapp.cnssvrcall(
		cnscom.callid_start,
		json.dumps(params),
		auto_connect=args.no_server_start,
		auto_server_start=not args.no_server_start
	)

########NEW FILE########
__FILENAME__ = status
import json, time, itertools, collections, logging
from ... import cnscom
from ._completions import complete_ident

###

name = 'status'
cmdhelp = 'Show status of program(s)'

###

L = logging.getLogger('status')

###

def init_parser(parser):
	parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command. If none is given, all programs are considered in scope')

###

def complete(console, text, line, begidx, endidx):
	textst = text.strip()
	ret = []
	ret.extend(complete_ident(console, textst))
	return ret

###

def main(cnsapp, args):
	params={}
	if len(args.program) > 0: params['pfilter'] = args.program
	ret = cnsapp.cnssvrcall(
		cnscom.callid_status, 
		json.dumps(params),
		auto_connect=True
	)

	status = json.loads(ret)
	
	for sp in status:

		details = collections.OrderedDict()

		exit_status = sp.pop('exit_status', None)
		if exit_status is not None: details["exit_status"] = exit_status

		pid = sp.pop('pid', None)
		if pid is not None: details["pid"] = pid

		details['launches'] = sp.pop('launch_cnt','')

		t = sp.pop('start_time', None)
		if t is not None: details["start_time"] = time.strftime("%d-%m-%Y %H:%M:%S",time.localtime(t))

		t = sp.pop('exit_time', None)
		if t is not None: details["exit_time"] = time.strftime("%d-%m-%Y %H:%M:%S",time.localtime(t))

		# Format uptime
		t = sp.pop('uptime', None)
		if t is not None:
			# TODO: Print pretty (e.g. uptime:2d 2h)
			details['uptime'] = "{0:.2f}s".format(t)

		state = sp.pop('state')
		stlbl = cnscom.program_state_enum.labels.get(state, "({0})".format(state))

		line = "{0:<16} {1:<10}".format(
			sp.pop('ident', '???'), 
			stlbl,
			)

		line += ', '.join(['{0}:{1}'.format(k,v) for k,v in itertools.chain(details.iteritems(), sp.iteritems())])
			

		print line

########NEW FILE########
__FILENAME__ = stop
import json
from ... import cnscom
from .. import exception
from ._completions import complete_ident

###

name = 'stop'
cmdhelp = 'Stop program(s)'

###

def init_parser(parser):
	parser.add_argument('-i','--immediate-return', action='store_true', help='Dont wait for termination of programs and exit ASAP')
	parser.add_argument('-c','--core-dump', action='store_true', help='Stop program(s) to produce core dump (has to be also enabled in program configuration).')
	parser.add_argument('-E','--stop-and-exit', action='store_true', help='Stop all programs and exit Ramona server. Command-line default for:\n%(prog)s')
	parser.add_argument('-S','--stop-and-stay', action='store_true', help='Stop all programs but keep Ramona server running')
	parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command. If none is given, all programs are considered in scope')

###

def complete(console, text, line, begidx, endidx):
	textst = text.strip()
	ret = []
	ret.extend(complete_ident(console, textst))
	return ret

###

def main(cnsapp, args):
	if args.stop_and_exit and len(args.program) > 0:
		raise exception.parameters_error('Cannot specify programs and -E option at once.')

	if args.stop_and_exit and args.stop_and_stay:
		raise exception.parameters_error('Cannot specify -T and -E option at once.')

	if len(args.program) == 0 and not args.stop_and_stay:
		args.stop_and_exit = True

	params={
		'immediate': args.immediate_return,
		'coredump': args.core_dump,
	}
	if args.stop_and_exit: params['mode'] = 'exit'
	elif args.stop_and_stay: params['mode'] = 'stay'
	if len(args.program) > 0: params['pfilter'] = args.program

	cnsapp.cnssvrcall(
		cnscom.callid_stop,
		json.dumps(params),
		auto_connect=True
	)

	if args.stop_and_exit:
		cnsapp.wait_for_svrexit()

########NEW FILE########
__FILENAME__ = tail
import sys, json, logging
from ... import cnscom
from .. import exception
from ._completions import complete_ident
###

name = 'tail'
cmdhelp = 'Display the last part of a log'

###

L = logging.getLogger('tail')

###

def init_parser(parser):
	parser.add_argument('-l','--log-stream', choices=['stdout','stderr'], default='stderr', help='Specify which standard stream to use (default is stderr)')
	parser.add_argument('-f', '--follow', action='store_true', help='Causes tail command to not stop when end of stream is reached, but rather to wait for additional data to be appended to the input')
	parser.add_argument('-n', '--lines', metavar='N', type=int, default=40, help='Output the last N lines, instead of the last 40')
	parser.add_argument('program', help='Specify the program in scope of the command')

###

def complete(console, text, line, begidx, endidx):
	textst = text.strip()
	ret = []
	ret.extend(complete_ident(console, textst))
	return ret

###


def main(cnsapp, args):

	params = {
		'program': args.program,
		'stream': args.log_stream,
		'lines': args.lines,
		'tailf': args.follow,
	}
	ret = cnsapp.cnssvrcall(
		cnscom.callid_tail,
		json.dumps(params),
		auto_connect=True
	)

	sys.stdout.write(ret)

	if not args.follow:
		return

	# Handle tail -f mode
	try:
		while 1:
			retype, params = cnscom.svrresp(cnsapp.ctlconsock, hang_detector=False)
			if retype == cnscom.resp_tailf_data:
				sys.stdout.write(params)
			else:
				raise RuntimeError("Unknown/invalid server response: {0}".format(retype))

	except KeyboardInterrupt:
		print

	except Exception, e:
		L.error("Tail failed: {0}".format(e))

	params = {
		'program': args.program,
		'stream': args.log_stream,
	}
	ret = cnsapp.cnssvrcall(
		cnscom.callid_tailf_stop,
		json.dumps(params)
	)

########NEW FILE########
__FILENAME__ = who
import json, logging, time
from ... import cnscom

###

name = 'who'
cmdhelp = 'Show users currently connected the server'

###

L = logging.getLogger('who')

###

def init_parser(parser):
	return

def main(cnsapp, args):
	print "Connected clients:"
	ret = cnsapp.cnssvrcall(
		cnscom.callid_who, 
		auto_connect=True
	)
	whoparsed = json.loads(ret)
	for whoitem in whoparsed:
		print "{}{} @ {}".format(
			'*' if whoitem['me'] else ' ',
			nice_addr(whoitem['descr'], whoitem['address']),
			time.strftime("%d-%m-%Y %H:%M:%S", time.localtime(whoitem['connected_at']))
		)

def nice_addr(descr, address):
	sock_family, sock_type, sock_proto, sock_ssl = descr

	if sock_proto == 'IPPROTO_TCP' and sock_family == 'AF_INET6':
		return " TCP [{}]:{}{}".format(address[0], address[1], ' SSL' if sock_ssl else '')
	elif sock_proto == 'IPPROTO_TCP' and sock_family == 'AF_INET':
		return " TCP {}:{}{}".format(address[0], address[1], ' SSL' if sock_ssl else '')
	elif sock_family == 'AF_UNIX':
		return "UNIX {}{}".format(address, ' SSL' if sock_ssl else '')
	else:
		return "{} {}".format(descr, address)

########NEW FILE########
__FILENAME__ = wininstall
import logging
import pywintypes # from Python Win32
from ..winsvc import w32_install_svc

###

name = 'wininstall'
cmdhelp = 'Install the Ramona server as a Windows Service (Windows only)'

###


L = logging.getLogger('wininstall')

###

def init_parser(parser):
	parser.add_argument('-d', '--dont-start', action='store_true', help="Don't start service after installation")
	
	parser.add_argument('-S','--server-only', action='store_true', help='When service is acticated start only the Ramona server, not programs')
	parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command. If none is given, all programs are considered in scope')

	#TODO: Auto-start of service (after reboot) enable (default) / disable

###

def main(cnsapp, args):
	try:
		cls = w32_install_svc(
			start=not args.dont_start,
			server_only=args.server_only,
			programs=args.program if len(args.program) > 0 else None
		)
	except pywintypes.error, e:
		L.error("Error when installing Windows service: {0} ({1})".format(e.strerror, e.winerror))
		return 3 # Exit code

	if args.dont_start:
		L.info("Windows service '{0}' has been installed successfully.".format(cls._svc_name_))
	else:
		L.info("Windows service '{0}' has been installed and started successfully.".format(cls._svc_name_))

########NEW FILE########
__FILENAME__ = winuninstall
import logging
import pywintypes # from Python Win32
from ..winsvc import w32_uninstall_svc

###

name = 'winuninstall'
cmdhelp = 'Uninstall the Ramona Windows Service (Windows only)'

###


L = logging.getLogger('winuninstall')

###

def init_parser(parser):
	pass

###

def main(cnsapp, args):
	try:
		cls = w32_uninstall_svc()
	except pywintypes.error, e:
		L.error("Error when uninstalling Windows service: {0} ({1})".format(e.strerror, e.winerror))
		return 3 # Exit code

	L.info("Windows service '{0}' has been uninstalled.".format(cls._svc_name_))

########NEW FILE########
__FILENAME__ = _completions
import json
from ... import cnscom

def complete_ident(console, textst):
	ret = []
	statuses = console.cnsapp.cnssvrcall(cnscom.callid_status, json.dumps({}), auto_connect=True)
	for st in json.loads(statuses):
		if st['ident'].startswith(textst) or textst == "":
			ret.append(st['ident'])
	return ret

########NEW FILE########
__FILENAME__ = cnsapp
import sys, os, socket, errno, logging, time, json, inspect
from ..config import config, read_config, config_files
from ..utils import launch_server_daemonized
from .. import cnscom, socketuri
from .parser import argparser
from . import exception

###

L = logging.getLogger("cnsapp")

###

class console_app(object):
	'''
Console application (base for custom implementations)
@ivar config: Configuration dictionary linked from ramona.config (shortcut for ramona tool procedures)
	'''

	def __init__(self, configuration):
		'''
		@param configuration: string or list of configuration files that will be used by Ramona. This is application level configuration.
		'''
		# Change directory to location of user console script
		os.chdir(os.path.dirname(sys.argv[0]))

		# Check if this is request for proxy tool - and avoid parsing
		if len(sys.argv) > 1:
			for mn in dir(self):
				fn = getattr(self, mn)
				if not hasattr(fn, '__proxy_tool'): continue
				if mn == sys.argv[1]:
					ret = fn(sys.argv[1:])
					sys.exit(ret)

		# Parse command line arguments
		self.argparser = argparser(self)

		if (len(sys.argv) < 2):
			# Default command
			argv = ['console']
		else:
			argv = None

		self.argparser.parse(argv)

		# Read config
		if self.argparser.args.config is None:
			if isinstance(configuration, basestring):
				configuration = [configuration]
			else:
				pass
		else:
			configuration = self.argparser.args.config
		for config_file in configuration:
			config_file = config_file.strip()
			if not os.path.isfile(config_file):
				print("Cannot find configuration file {0}".format(config_file))
				sys.exit(exception.configuration_error.exitcode)
		
		try:
			read_config(configuration, use_env=False)
		except Exception, e:
			print("{0}".format(e))
			sys.exit(exception.configuration_error.exitcode)

		self.config = config

		# Configure logging
		llvl = logging.INFO
		if self.argparser.args.silent: llvl = logging.ERROR
		if self.argparser.args.debug: llvl = logging.DEBUG
		logging.basicConfig(
			level=llvl,
			stream=sys.stderr,
			format="%(asctime)s %(levelname)s: %(message)s",
		)
		if self.argparser.args.debug:
			L.debug("Debug output is enabled.")

		L.debug("Configuration read from: {0}".format(', '.join(config_files)))

		logdir = self.config.get('general', 'logdir')
		if not os.path.isdir(logdir):
			L.warning("Log directory '{}' not found.".format(logdir))


		# Prepare server connection factory
		self.cnsconuri = socketuri.socket_uri(config.get('ramona:console','serveruri'))
		self.ctlconsock = None


	def run(self):
		try:
			ec = self.argparser.execute(self)
		except exception.ramona_runtime_errorbase, e:
			L.error("{0}".format(e))
			ec = e.exitcode
		except KeyboardInterrupt, e:
			ec = 0
		except AssertionError, e:
			L.exception("Assertion failed:")
			ec = 101 # Assertion failed exit code
		except Exception, e:
			errstr = "{0}".format(e)
			if len(errstr) == 0: errstr=e.__repr__()
			L.error(errstr)
			ec = 100 # Generic error exit code
		sys.exit(ec if ec is not None else 0)


	def connect(self):
		if self.ctlconsock is None: 
			try:
				self.ctlconsock = self.cnsconuri.create_socket_connect()
			except socket.error, e:
				if e.errno == errno.ECONNREFUSED: return None
				if e.errno == errno.ENOENT and self.cnsconuri.protocol == 'unix': return None
				raise
			
			server_init_params_ret = cnscom.svrcall(self.ctlconsock, cnscom.callid_init, '')
			server_init_params = json.loads(server_init_params_ret)
			server_version = server_init_params.get("version", None)
			if server_version is not None:
				from .. import version as ramona_version
				client_version = ramona_version
				if server_version != client_version:
					L.warn("Version mismatch. The server version '{0}' is different from the console version '{1}'. The console may malfunction.".format(server_version, client_version))
			
		return self.ctlconsock


	def cnssvrcall(self, callid, params="", auto_connect=False, auto_server_start=False):
		'''
		Console-server call (wrapper to cnscom.svrcall)

		@param auto_connect: Automatically establish server connection if not present
		@param auto_server_start: Automatically start server if not running and establish connection
		'''
		assert not (auto_connect & auto_server_start), "Only one of auto_connect and auto_server_start can be true"
		if auto_connect:
			if self.ctlconsock is None:
				s = self.connect()
				if s is None:
					raise exception.server_not_responding_error("Server is not responding - maybe it isn't running.")

		elif auto_server_start:
			# Fist check if ramona server is running and if not, launch that
			s = self.auto_server_start()

		else:
			assert self.ctlconsock is not None

		try:
			return cnscom.svrcall(self.ctlconsock, callid, params)
		except socket.error:
			pass

		if auto_connect or auto_server_start:
			L.debug("Reconnecting to server ...")

			self.ctlconsock = None
			s = self.connect()
			if s is None:
				raise exception.server_not_responding_error("Server is not responding - maybe it isn't running.")

			return cnscom.svrcall(self.ctlconsock, callid, params)


	def wait_for_svrexit(self):
		if self.ctlconsock is None: return
		while True:
			x = self.ctlconsock.recv(4096)
			if len(x) == 0: break
		self.ctlconsock
		self.ctlconsock = None


	def auto_server_start(self):
		s = self.connect()
		if s is None:
			L.debug("It looks like Ramona server is not running - launching server")
			launch_server_daemonized()

			for _ in range(100): # Check server availability for next 10 seconds 
				# TODO: Also improve 'crash-start' detection (to reduce lag when server fails to start)
				time.sleep(0.1)
				s = self.connect()
				if s is not None: break

		if s is None:
			raise exception.server_start_error("Ramona server process start failed")

		return s

###

def tool(fn):
	'''
	Tool decorator foc console_app

	Marks function object by '.__tool' attribute
	'''

	if inspect.isfunction(fn):
		fn.__tool = fn.func_name

	elif inspect.isclass(fn):
		fn.__tool = fn.__name__

	else:
		raise RuntimeError("Unknown type decorated as Ramona tool: {0}".format(fn))

	return fn

#

def proxy_tool(fn):
	'''
	Proxy tool (with straight argument passing) decorator foc console_app

	Marks function object by '.__proxy_tool' attribute
	'''
	fn.__proxy_tool = fn.func_name
	return fn

########NEW FILE########
__FILENAME__ = exception
class ramona_runtime_errorbase(RuntimeError):
	exitcode = 100

class server_not_responding_error(ramona_runtime_errorbase):
	exitcode = 2

class server_start_error(ramona_runtime_errorbase):
	exitcode = 3

class configuration_error(ramona_runtime_errorbase):
	exitcode = 98

class parameters_error(ramona_runtime_errorbase):
	exitcode = 99

########NEW FILE########
__FILENAME__ = parser
import sys, os, argparse, inspect

###

class _parser_base(argparse.ArgumentParser):

	argparser_kwargs = None # To be overridden in final parser implementation class
	subparser_kwargs = None # To be overridden in final parser implementation class

	def __init__(self, cnsapp):

		# Build parser
		argparse.ArgumentParser.__init__(self, **self.argparser_kwargs)

		self.subparsers = self.add_subparsers(
			dest='subcommand',
			title='subcommands',
			parser_class=argparse.ArgumentParser,
		)
		
		# Adding sub-commands ...
		self.subcommands = {}
		for cmd in self.build_cmdlist():
			subparser = self.subparsers.add_parser(cmd.name, help=cmd.cmdhelp, **self.subparser_kwargs)
			subparser.description = cmd.cmdhelp
			cmd.init_parser(subparser)
			self.subcommands[cmd.name] = cmd

		#Iterate via application object to find 'tool/__tool' and 'proxy_tool/__proxy_tool' (decorated method)
		for mn in dir(cnsapp):
			fn = getattr(cnsapp, mn)
			if hasattr(fn, '__tool'):
				subparser = self.subparsers.add_parser(mn, help=fn.__doc__)
				if inspect.ismethod(fn):
					self.subcommands[mn] = fn.im_func # Unbound method
				elif inspect.isclass(fn):
					# Initialize tool given by a class
					toolobj = fn()
					if hasattr(toolobj,'init_parser'):
						toolobj.init_parser(cnsapp, subparser)
					self.subcommands[mn] = toolobj

				else:
					raise RuntimeError("Unknown type of Ramona tool object: {0}".format(fn))

			elif hasattr(fn, '__proxy_tool'):
				self.subparsers.add_parser(mn, help=fn.__doc__)
				# Not subcommand as proxy tools are handled prior argument parsing


	def build_cmdlist(self):
		from .cmd import start
		yield start

		from .cmd import stop
		yield stop

		from .cmd import restart
		yield restart

		from .cmd import status
		yield status

		from .cmd import help
		yield help

		from .cmd import tail
		yield tail

		from .cmd import who
		yield who

		from .cmd import notify
		yield notify

		if sys.platform == 'win32':
			from .cmd import wininstall
			yield wininstall

			from .cmd import winuninstall
			yield winuninstall


	def parse(self, argv):
		self.args = None # This is to allow re-entrant parsing
		self.args = self.parse_args(argv)
		

	def execute(self, cnsapp):
		if self.args.subcommand == 'help':
			# Help is given by special treatment as this is actually function of parser itself
			self.print_help()
			return

		cmdobj = self.subcommands[self.args.subcommand]

		if hasattr(cmdobj,'__call__'):
			return cmdobj(cnsapp)
		else:
			return cmdobj.main(cnsapp, self.args)

#

class argparser(_parser_base):

	argparser_kwargs = {}
	subparser_kwargs = {}

	def __init__(self, cnsapp):

		# Prepare description (with Ramona version)
		from .. import version as ramona_version
		self.argparser_kwargs['description'] = 'Powered by Ramona (version {0}).'.format(ramona_version)

		_parser_base.__init__(self, cnsapp)

		# Add config file option
		self.add_argument('-c', '--config', metavar="CONFIGFILE", action='append', help='Specify configuration file(s) to read (this option can be given more times). This will override build-in application level configuration.')

		# Add debug log level option
		self.add_argument('-d', '--debug', action='store_true', help='Enable debug (verbose) output.')

		# Add silent log level option
		self.add_argument('-s', '--silent', action='store_true', help='Enable silent mode of operation (only errors are printed).')


	def build_cmdlist(self):
		for cmd in _parser_base.build_cmdlist(self): yield cmd

		from .cmd import console
		yield console

		from .cmd import server
		yield server

#

class consoleparser(_parser_base):

	argparser_kwargs = {'add_help': False, 'usage': argparse.SUPPRESS}
	subparser_kwargs = {'usage': argparse.SUPPRESS}

	def build_cmdlist(self):
		for cmd in _parser_base.build_cmdlist(self): yield cmd

		from .cmd import exit
		yield exit


	def error(self, message):
		print "Error:", message
		raise SyntaxError()


########NEW FILE########
__FILENAME__ = winsvc
#See http://code.activestate.com/recipes/551780/ for details 

# To debug use:
# > c:\Python27\Lib\site-packages\win32\pythonservice.exe -debug ramona-test ramonahttpfend

import os, sys, time
from os.path import splitext, abspath, join, dirname
from sys import modules

import win32serviceutil
import win32service
import win32api

from ..config import config, config_files

###

class w32_ramona_service(win32serviceutil.ServiceFramework):


	_svc_name_ = None
	_svc_display_name_ = 'Ramona Demo Service'

	@classmethod
	def configure(cls):
		assert cls._svc_name_ is None
		cls._svc_name_ = config.get('general','appname')
		# TODO: Allow user to provide display name via config
		cls._svc_display_name_ = config.get('general','appname')


	def __init__(self, *args):
		assert self._svc_name_ is None
		servicename = args[0][0]

		self.log("Ramona service '{0}' is starting".format(servicename))

		# Read working directory from registry and change to it
		directory = win32serviceutil.GetServiceCustomOption(servicename, 'directory')
		os.chdir(directory)

		# Set Ramona config environment variable to ensure proper configuration files load
		os.environ['RAMONA_CONFIG'] =  win32serviceutil.GetServiceCustomOption(servicename, 'config')

		from ..server.svrapp import server_app
		self.svrapp = server_app()
		self.configure()

		win32serviceutil.ServiceFramework.__init__(self, *args)


	def log(self, msg):
		import servicemanager
		servicemanager.LogInfoMsg(str(msg))


	def SvcDoRun(self):
		self.ReportServiceStatus(win32service.SERVICE_START_PENDING)

		try:
			self.ReportServiceStatus(win32service.SERVICE_RUNNING)
			self.log('Ramona service {0} is running'.format(self._svc_name_))
			self.svrapp.run()
			self.log('Quak')

		except SystemExit, e:
			self.log('SystemExit: {0}'.format(e))

		except Exception, e:
			self.log('Exception: {0}'.format(e))

		self.svrapp = None
		#self.ReportServiceStatus(win32service.SERVICE_STOPPED)


	def SvcStop(self):
		self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)

		if self.svrapp is not None:
			self.svrapp.exitwatcher.send()
			while self.svrapp is not None:
				time.sleep(1)

		self.log('Ramona service {0} is stopped'.format(self._svc_name_))
		#self.ReportServiceStatus(win32service.SERVICE_STOPPED)

###

def w32_install_svc(start=False, server_only=True, programs=None):
	'''Install Windows Ramona Service'''

	import logging
	L = logging.getLogger('winsvc')

	directory = abspath(dirname(sys.argv[0])) # Find where console python prog is launched from ...

	cls = w32_ramona_service
	if cls._svc_name_ is None: cls.configure()

	try:
		module_path=modules[cls.__module__].__file__
	except AttributeError:
		# maybe py2exe went by
		from sys import executable
		module_path=executable
	module_file = splitext(abspath(join(module_path,'..','..', '..')))[0]
	cls._svc_reg_class_ = '{0}\\ramona.console.winsvc.{1}'.format(module_file, cls.__name__)

	win32api.SetConsoleCtrlHandler(lambda x: True, True) #  Service will stop on logout if False

	# Prepare command line
	cmdline = []
	if server_only: cmdline.append('-S')
	elif programs is not None: cmdline.extend(programs)

	# Install service
	win32serviceutil.InstallService(
		cls._svc_reg_class_,
		cls._svc_name_,
		cls._svc_display_name_,
		startType = win32service.SERVICE_AUTO_START,
		exeArgs = ' '.join(cmdline),
	)

	# Set directory from which Ramona server should be launched ...
	win32serviceutil.SetServiceCustomOption(cls._svc_name_, 'directory', directory)
	win32serviceutil.SetServiceCustomOption(cls._svc_name_, 'config', ';'.join(config_files))

	L.debug("Service {0} installed".format(cls._svc_name_))

	if start:
		x = win32serviceutil.StartService(cls._svc_name_)
		L.debug("Service {0} is starting ...".format(cls._svc_name_))
		#TODO: Wait for service start to check start status ...
		L.debug("Service {0} started".format(cls._svc_name_))

	return cls


def w32_uninstall_svc():
	'''Uninstall (remove) Windows Ramona Service'''

	import logging
	L = logging.getLogger('winsvc')

	cls = w32_ramona_service
	if cls._svc_name_ is None: cls.configure()

	scvType, svcState, svcControls, err, svcErr, svcCP, svcWH = win32serviceutil.QueryServiceStatus(cls._svc_name_)

	if svcState == win32service.SERVICE_RUNNING:
		L.debug("Service {0} is stopping ...".format(cls._svc_name_))
		win32serviceutil.StopService(cls._svc_name_)
		L.debug("Service {0} is stopped.".format(cls._svc_name_))

	win32serviceutil.RemoveService(cls._svc_name_)

	return cls

########NEW FILE########
__FILENAME__ = app
import sys, os, socket, ConfigParser, errno, logging, signal, threading, itertools, collections
import pyev
from ..config import config, read_config, get_numeric_loglevel, config_defaults
from .. import socketuri
from ._request_handler import ramona_http_req_handler

###

L = logging.getLogger("httpfendapp")

###

class httpfend_app(object):

	STOPSIGNALS = [signal.SIGINT, signal.SIGTERM]
	NONBLOCKING = frozenset([errno.EAGAIN, errno.EWOULDBLOCK])
	# Maximum number of worker threads serving the client requests
	MAX_WORKER_THREADS = 10
	
	def __init__(self):
		# Read config
		read_config()
		
		# Configure logging
		try:
			loglvl = get_numeric_loglevel(config.get(os.environ['RAMONA_SECTION'], 'loglevel'))
		except:
			loglvl = logging.INFO
		logging.basicConfig(
			level=loglvl,
			stream=sys.stderr,
			format="%(asctime)s %(levelname)s: %(message)s",
		)

		try:
			self.listenaddr = config.get(os.environ['RAMONA_SECTION'], 'listen')
		except (ConfigParser.NoSectionError, ConfigParser.NoOptionError):
			self.listenaddr = config_defaults['ramona:httpfend']['listenaddr']
		
		self.username = None
		self.password = None 
		try:
			self.username = config.get(os.environ['RAMONA_SECTION'], 'username')
			self.password = config.get(os.environ['RAMONA_SECTION'], 'password')
		except:
			pass
		
		if self.username is not None and self.password is None:
			L.fatal("Configuration error: 'username' option is set, but 'password' option is not set. Please set 'password'")
			sys.exit(1)
		
		self.logmsgcnt = itertools.count()
		self.logmsgs = dict()
			
		self.workers = collections.deque()
		self.dyingws = collections.deque() # Dying workers

		self.svrsockets = []
		
		for addr in self.listenaddr.split(','):
			socket_factory = socketuri.socket_uri(addr)
			try:
				socks = socket_factory.create_socket_listen()
			except socket.error, e:
				L.fatal("It looks like that server is already running: {0}".format(e))
				sys.exit(1)
			self.svrsockets.extend(socks)

		if len(self.svrsockets) == 0:
			L.fatal("There is no http server listen address configured - considering this as fatal error")
			sys.exit(1)

		self.loop = pyev.default_loop()
		self.watchers = [
			pyev.Signal(sig, self.loop, self.__terminal_signal_cb) for sig in self.STOPSIGNALS
		]
		self.dyingwas = pyev.Async(self.loop, self.__wdied_cb) # Dying workers async. signaling
		self.watchers.append(self.dyingwas)
		
		for sock in self.svrsockets:
			sock.setblocking(0)
			self.watchers.append(pyev.Io(sock._sock, pyev.EV_READ, self.loop, self.__on_accept, data=sock._sock.fileno()))

		
	def run(self):
		for sock in self.svrsockets:
			sock.listen(socket.SOMAXCONN)
			L.debug("Ramona HTTP frontend is listening at {0}".format(sock.getsockname()))
		for watcher in self.watchers:
			watcher.start()

		L.info('Ramona HTTP frontend started and is available at {0}'.format(self.listenaddr))

		# Launch loop
		try:
			self.loop.start()
		finally:
			# Stop accepting new work
			for sock in self.svrsockets: sock.close()

			# Join threads  ...
			for i in range(len(self.workers)-1,-1,-1):
				w = self.workers[i]
				w.join(2)
				if not w.is_alive(): del self.workers[i]

			if len(self.workers) > 0:
				L.warning("Not all workers threads exited nicely - expect hang during exit")


	def __on_accept(self, watcher, events):
		# First find relevant socket
		sock = None
		for s in self.svrsockets:
			if s.fileno() == watcher.data:
				sock = s
				break
		if sock is None:
			L.warning("Received accept request on unknown socket {0}".format(watcher.fd))
			return
		# Accept all connection that are pending in listen backlog
		while True:
			try:
				clisock, address = sock.accept()
				
			except socket.error as err:
				if err.args[0] in self.NONBLOCKING:
					break
				else:
					raise
			else:
				clisock.setblocking(1)
				num_workers = len(self.workers)
				if num_workers >= self.MAX_WORKER_THREADS:
					L.error("There are already {0} worker threads, which is >= MAX_WORKER_THREADS = {1}. Not creating a new thread for client {2}".format(
						num_workers, self.MAX_WORKER_THREADS, address))
					continue
				
				worker = _request_worker(clisock, address, self)
				L.debug("Request from client {0} is processed by thread {1}".format(address, worker.name))
				worker.start()
				self.workers.append(worker)
	

	def __terminal_signal_cb(self, watcher, events):
		watcher.loop.stop()


	def __wdied_cb(self, _watcher, _events):
		'''Iterate thru list of workers and remove dead threads'''
		while len(self.dyingws) > 0:
			w = self.dyingws.pop()
			L.debug("Joining thread {0}".format(w.name))
			w.join()
			self.workers.remove(w)

#

class _request_worker(threading.Thread):
	
	def __init__(self, sock, address, server):
		threading.Thread.__init__(self)
		self.name = "HttpfendRequestWorker-{0}".format(self.name)
		self.sock = sock
		self.address = address
		self.server = server
	
	def run(self):
		try:
			ramona_http_req_handler(self.sock, self.address, self.server)
			self.sock.close()
		except:
			L.exception("Uncaught exception during worker thread execution:")
		finally:
			self.server.dyingws.append(self)
			self.server.dyingwas.send()


########NEW FILE########
__FILENAME__ = _request_handler
import os, socket, errno, httplib, BaseHTTPServer, mimetypes, json, logging, time
import cgi, pprint, urllib, urlparse, base64, hashlib, pkgutil, zipimport
from .. import cnscom, socketuri, version as ramona_version
from ..config import config
from ._tailf import tail_f_handler

###

L = logging.getLogger("httpfendapp")

###

STRFTIME_FMT = "%d-%b-%Y %H:%M:%S"

###

# Initialize mimetypes
if not mimetypes.inited:
	mimetypes.init()

###

class ramona_http_req_handler(BaseHTTPServer.BaseHTTPRequestHandler):
	
	ActionToCallid = {"start": cnscom.callid_start, "stop": cnscom.callid_stop, "restart": cnscom.callid_restart}
	
	def __init__(self, request, client_address, server):
		self.server = server
		self.cnsconn = None
		try:
			BaseHTTPServer.BaseHTTPRequestHandler.__init__(self, request, client_address, server)
		except:
			L.exception("Exception while requesthandler execution")
	
	def do_GET(self):
		# Static has to be handled before authentication, as the static content is available
		# even without authentication, because the static resources are used on the 401 page as well
		if self.path.startswith("/static/"):
			return self._handle_static()
		
		if not self._check_authentication(): return
		
		if self.path.startswith("/ajax/"):
			return self._handle_ajax()
				
		elif self.path.startswith("/log/"):
			return self._handle_log()
		elif self.path.startswith("/loginner/"):
			
			return self._handle_log_inner()

		else:
			return self._handler_other()
	
	def send_header(self, keyword, value):
		# TODO: Take this from configuration
		prod = True
		if prod and keyword.lower() == "server": return
		
		BaseHTTPServer.BaseHTTPRequestHandler.send_header(self, keyword, value)
	
	def _check_authentication(self):
		"""
		Check if the authentication is enabled and if yes, check if the user is authenticated
		   to access the httpfend or not.
		   If authentication is turned on, but the user fails to authenticate, the authentication headers
		   are sent to client (which triggers username and password prompt in the browser)
		   @return: True if the authentication is turned off or the user is successfully authenticated
		            False otherwise
		"""
		authheader = self.headers.getheader("Authorization", None)
		if self.server.username is not None and authheader is None:
			self.serve_auth_headers()
			return False
		
		elif self.server.username is not None and authheader is not None:
			method, authdata = authheader.split(" ") 
			if method != "Basic":
				self.send_error(httplib.NOT_IMPLEMENTED, "The authentication method '{0}' is not supported. Only Basic authnetication method is supported.".format(method))
				return False
			username, _, password = base64.b64decode(authdata).partition(":")
			if self.server.password.startswith("{SHA}"):
				password = "{SHA}" + hashlib.sha1(password).hexdigest()
			
			if username != self.server.username or password != self.server.password:
				self.serve_auth_headers()
				return False
			
		return True 
		
	
	def _handle_static(self):
		if not _static_file_exists(self.path):
			self.send_error(httplib.NOT_FOUND)
			return
		try:
			f = _get_static_file(self.path)
		except IOError:
			self.send_error(httplib.NOT_FOUND)
			return
		try:
			self.send_response(httplib.OK)
			self.send_header("Content-Type", mimetypes.guess_type(self.path)[0])
			self.end_headers()
			self.wfile.write(f.read())
			return
		finally:
			f.close()
		
	
	def _handle_ajax(self):
		parsed = urlparse.urlparse(self.path)
		action = parsed.path[6:]
		if action == "statusTable":
			self.send_response(httplib.OK)
			self.send_header("Content-Type", "text/html; charset=utf-8")
			self.end_headers()
			self.wfile.write(self.buildStatusTable(json.loads(self.getStatuses())))
	
	
	def _handle_log(self):
		parsed = urlparse.urlparse(self.path)
		logname = parsed.path[5:]
		
		self.send_response(httplib.OK)
		self.send_header("Content-Type", "text/html; charset=utf-8")
		self.end_headers()
		f = _get_static_file("log_frame.tmpl.html")
		try:
			self.wfile.write(f.read().format(
				appname=config.get('general','appname'),
				version=ramona_version,
				logpath="/loginner/{0}".format(logname)
			))
		finally:
			f.close()
	
	def _handle_log_inner(self):
		parsed = urlparse.urlparse(self.path)
		logname = parsed.path[10:]
		parts = logname.split("/")
		if len(parts) < 2:
			self.send_error(httplib.NOT_FOUND, "Invalid URL.")
			return
		stream = parts[0]
		if stream not in ("stdout", "stderr"):
			self.send_error(httplib.NOT_FOUND, "'{0}' is not a valid type of stream. Only 'stdout' and 'stderr' are supported.".format(stream))
			return
		program = urllib.unquote_plus(parts[1].rpartition(".")[0])
		cnsconn = self.socket_connect()
		tailf = True
		params = {
				"program": program,
				"stream": stream,
				"tailf": tailf 
		}
		headers_sent = False
		try:
			ret = cnscom.svrcall(cnsconn, cnscom.callid_tail, json.dumps(params))
			self.send_response(httplib.OK)
			self.send_header("Content-Type", "text/plain; charset=utf-8")
			self.end_headers()
			headers_sent = True
			
			self.wfile.write(ret)
			cnsconn.setblocking(0)
			
			tailfhandler = tail_f_handler(self, cnsconn)
			tailfhandler.run()
			
			# after the tailf handling exists, sent the tailf_stop command to ramona server
			cnsconn.setblocking(1)
			params = {
				'program': program,
				'stream': stream,
			}
			cnscom.svrcall(
				cnsconn,
				cnscom.callid_tailf_stop,
				json.dumps(params)
			)
			
		except Exception, e:
			if not headers_sent:
				self.send_error(httplib.INTERNAL_SERVER_ERROR, str(e))
			else:
				self.wfile.write("Error while getting the log contents: {0}".format(e))
	
	def _handler_other(self):
		parsed = urlparse.urlparse(self.path)
		if parsed.path != "/":
			self.send_error(httplib.NOT_FOUND)
			return
		
		qs = urlparse.parse_qs(parsed.query)
		action = None
		actionList = qs.get('action')
		if actionList is not None and len(actionList) > 0:
			action = actionList[0]
		if action in ("start", "stop", "restart"):
			conn = self.socket_connect()
			params = {
				'immediate': True,
			}
			qsIdent = qs.get('ident')
			if qsIdent is not None and len(qsIdent) > 0:
				params['pfilter'] = [qsIdent[0]]
			else:
				params['pfilter'] = list(self.getAllPrograms(True))
			
			qsForce = qs.get('force')
			if qsForce is not None and len(qsForce) > 0:
				if qsForce[0] == "1":
					params['force'] = True
			
			try:
				cnscom.svrcall(conn, self.ActionToCallid[action], json.dumps(params))
				msgid = self.addLogMessage("success", "Command '{0}' successfully triggered.".format(action))
			except Exception, e:
				msgid = self.addLogMessage("error", "Failed to trigger the command: {0}".format(e))
			
			self.send_response(httplib.SEE_OTHER)
			self.send_header("Location", self.getAbsPath(msgid=msgid))
			self.end_headers()
			return
		
		self.send_response(httplib.OK)
		self.send_header("Content-Type", "text/html; charset=utf-8")
		self.end_headers()
		
		logmsg = ""
		for msgid in qs.get('msgid', []):
			m = self.server.logmsgs.pop(int(msgid), None)
			if m is not None:
				logmsg += '''<div class="alert alert-{0}">{1}</div>'''.format(*m)

		f = _get_static_file("index.tmpl.html")
		try:
			sttable = self.buildStatusTable(json.loads(self.getStatuses()))
			self.wfile.write(f.read().format(
				statuses=sttable,
				logmsg=logmsg,
				appname=config.get('general','appname'),
				version=ramona_version,
			))
		finally:
			f.close()
	
	
	def log_message(self, fmt, *args):
		L.debug("{0} -- [{1}]: {2}".format(self.address_string(), self.log_date_time_string(), fmt % args))
			
	
	def buildStatusTable(self, statuses):
		ret = '<table id="statusTable" class="table table-hover table-bordered"><thead>'
		ret += '<tr><th>Process ident.</th><th>Status</th><th><abbr title="O = stdout, E = stderr">Log</abbr></th><th>PID</th><th><abbr title="Launch counter">L.cnt.</abbr></th><th>Start time</th><th>Exit time</th><th>Exit code</th><th></th></tr>'
		ret += "</thead>"
		ret += "<tbody>"
		for sp in statuses:
			ret += "<tr>"
			ident = sp.pop('ident', '???')
			ret += '<th>{0}</th>'.format(cgi.escape(ident))
			labelCls = "label-inverse"
			progState = sp.pop("state")
			
			if progState == cnscom.program_state_enum.RUNNING:
				labelCls = "label-success"
			elif progState == cnscom.program_state_enum.STOPPED:
				labelCls = ""
			elif progState in (cnscom.program_state_enum.STOPPING, cnscom.program_state_enum.STARTING):
				labelCls = "label-info"
			elif progState == cnscom.program_state_enum.STOPPED:
				labelCls = ""
			elif progState in (cnscom.program_state_enum.FATAL, cnscom.program_state_enum.CFGERROR):
				labelCls = "label-important"
			
			stlbl = cnscom.program_state_enum.labels.get(progState, "({0})".format(progState))
			ret += '<td><span class="label {0}">{1}</span></td>'.format(labelCls, cgi.escape(stlbl))
			if progState != cnscom.program_state_enum.CFGERROR:
				ret += '<td><a href="/log/stdout/{0}.log" target="_blank">O</a> <a href="/log/stderr/{0}.log" target="_blank">E</a></td>'.format(urllib.quote_plus(ident))
			else:
				ret += '<td></td>'
			pid = sp.pop('pid', "")
			ret += '<td>{0}</td>'.format(pid)
			ret += '<td>{0}</td>'.format(sp.pop('launch_cnt', ""))

			u = sp.pop('uptime', None)
			if u is not None:
				t = sp.pop('start_time', '?')
				ret += '<td title="Started at {1}">{0}</td>'.format(natural_relative_time(u), time.strftime(STRFTIME_FMT,time.localtime(t)))
			else:
				t = sp.pop('start_time', None)
				tform = ""
				if t is not None: tform = time.strftime(STRFTIME_FMT,time.localtime(t))
				ret += '<td>{0}</td>'.format(tform)

			t = sp.pop('exit_time', None)
			tform = ""
			if t is not None: tform = time.strftime(STRFTIME_FMT,time.localtime(t))
			ret += '<td>{0}</td>'.format(tform)
			ret += '<td>{0}</td>'.format(sp.pop('exit_status',''))
			
			actions = []
			if pid != os.getpid():
				# TODO: Should there be some filtering for STOPPING ???
				if progState not in (cnscom.program_state_enum.FATAL, cnscom.program_state_enum.RUNNING, cnscom.program_state_enum.STARTING, cnscom.program_state_enum.DISABLED):
					actions.append('<a class="btn btn-small btn-success" href="/?{0}">Start</a>'.format(cgi.escape(urllib.urlencode([("action", "start"), ("ident", ident)]))))
				
				if progState == cnscom.program_state_enum.RUNNING:
					actions.append('<a class="btn btn-small btn-danger" href="/?{0}">Stop</a>'.format(cgi.escape(urllib.urlencode([("action", "stop"), ("ident", ident)]))))
					actions.append('<a class="btn btn-small btn-warning" href="/?{0}">Restart</a>'.format(cgi.escape(urllib.urlencode([("action", "restart"), ("ident", ident)]))))
			
				if progState == cnscom.program_state_enum.FATAL:
					actions.append('<a class="btn btn-small btn-inverse" href="/?{0}">Start (force)</a>'.format(cgi.escape(urllib.urlencode([("action", "start"), ("ident", ident), ("force", "1")]))))

			ret += '<td>{0}</td>'.format(" ".join(actions))
			ret += "</tr>"
			
			if len(sp) > 0:
				ret += '<tr class="info"><td colspan="2"></td><td colspan="7"><pre class="pre-scrollable">'
				ret += cgi.escape(pprint.pformat(sp, width=3))
				ret += '</pre></td></tr>'
		
		ret += "</tbody></table>"
		return ret
	
	
	def addLogMessage(self, level, msg):
		msgid = self.server.logmsgcnt.next()
		self.server.logmsgs[msgid] = (level, msg)
		return msgid
	
	def getAbsPath(self, path="/", **kwargs):
		queryList = []
		for k,v in kwargs.iteritems():
			queryList.append((k, v))
		
		return urlparse.urlunparse(("http", self.headers['Host'], "/", None, urllib.urlencode(queryList), None))
	
	def getStatuses(self):
		conn = self.socket_connect()
		return cnscom.svrcall(conn, cnscom.callid_status, json.dumps({}))
	
	def getAllPrograms(self, withoutSelf=False):
		"""
		@param withoutSelf: If true, the process with the same pid will be ignored
		@return iterator: Ident of all registered programs
		"""
		for st in json.loads(self.getStatuses()):
			ident = st.get("ident")
			pid = st.get("pid")
			if ident is None:
				continue
			if (not withoutSelf) or (pid != os.getpid()):
				yield ident
		
	
	def socket_connect(self):
		if self.cnsconn is not None:
			return self.cnsconn
		try:
			# Prepare server connection factory
			cnsconuri = socketuri.socket_uri(config.get('ramona:console','serveruri'))
			self.cnsconn = cnsconuri.create_socket_connect()
			return self.cnsconn
		except socket.error, e:
			if e.errno == errno.ECONNREFUSED: return None
			if e.errno == errno.ENOENT and self.cnsconuri.protocol == 'unix': return None
			raise
	
	def serve_auth_headers(self):
		self.send_response(httplib.UNAUTHORIZED)
		self.send_header('WWW-Authenticate', 'Basic realm="Ramona HTTP frontend - {0}"'.format(config.get('general','appname')))
		self.send_header('Content-type', 'text/html')
		self.end_headers()
		f = _get_static_file("401.tmpl.html")
		try:
			self.wfile.write(f.read().format(
					appname=config.get('general','appname'),
					configsection=os.environ['RAMONA_SECTION'])
			)
		finally:
			f.close()

# 
# Support functions
# 

def _is_egg():
	ret = isinstance(pkgutil.get_loader(__name__), zipimport.zipimporter)
	return ret


_scriptdir = os.path.dirname(__file__)
def _static_file_exists(path):
	if _is_egg():
		from pkg_resources import resource_exists
		if path.startswith("/"): path = path[1:]
		return resource_exists("ramona.httpfend", path)
	else:
		parts = path.split("/")
		fname = os.path.join(_scriptdir, *[x for x in parts if len(x) > 0])
		return os.path.isfile(fname)
	return True


def _get_static_file(path):
	if _is_egg():
		from pkg_resources import resource_stream
		if path.startswith("/"): path = path[1:]
		return resource_stream("ramona.httpfend", path)

	else:
		parts = path.split("/")
		return open(os.path.join(_scriptdir, *[x for x in parts if len(x) > 0]), "rb")

		

def natural_relative_time(diff_sec):
	#TODO: Improve this significantly - maybe even add unit test
	#if diff.days > 7 or diff.days < 0: return d.strftime('%d %b %y')
#	elif diff.days == 1:
#	    return '1 day ago'
#	elif diff.days > 1:
#	    return '{} days ago'.format(diff.days)
	if diff_sec <= 1:
		return 'just now'
	elif diff_sec < 60:
		return '{:0.1f} sec(s) ago'.format(diff_sec)
	elif diff_sec < 120:
		return '1 min ago'
	elif diff_sec < 3600:
		return '{:0.0f} min(s) ago'.format(diff_sec/60)
	elif diff_sec < 7200:
		return '1 hour ago'
	else:
		return '{:0.0f} hours ago'.format(diff_sec/3600)

########NEW FILE########
__FILENAME__ = _tailf
import logging
import pyev
from .. import cnscom

###

L = logging.getLogger("httpfendapp")

###

class tail_f_handler(object):
	
	def __init__(self, req_handler, cnsconn):
		self.loop = pyev.Loop()
		self.watchers = []
		self.req_handler = req_handler
		self.cnsconn = cnsconn
		self.watchers.append(self.loop.io(req_handler.rfile._sock, pyev.EV_READ, self.__on_rfile_io))
		self.watchers.append(self.loop.io(cnsconn._sock, pyev.EV_READ, self.__on_cns_io))
		
	def run(self):
		for watcher in self.watchers:
			watcher.start()
		self.loop.start()
			
	def __on_cns_io(self, watcher, events):
		retype, params = cnscom.svrresp(self.cnsconn, hang_detector=False)
		if retype == cnscom.resp_tailf_data:
			self.req_handler.wfile.write(params)
		else:
			raise RuntimeError("Unknown/invalid server response: {0}".format(retype))
	
	def __on_rfile_io(self, watcher, events):
		buf = self.req_handler.rfile.read(1)
		if len(buf) == 0:
			L.debug("Closing the tailf loop for client {0}".format(self.req_handler.client_address))
			self.loop.stop()
			return
		else:
			L.warning("Unexpected data received from the client: {}".format(buf))

########NEW FILE########
__FILENAME__ = __main__
from .app import httpfend_app


if __name__ == '__main__':
	app = httpfend_app()
	app.run()
	
########NEW FILE########
__FILENAME__ = kmpsearch
class kmp_search(object):
	'''Implementation of Knuth-Morris-Pratt string matching algorithm
	See http://en.wikipedia.org/wiki/Knuth-Morris-Pratt_algorithm for more details.

	Basically this is useful for searching pattern (string) in the non-persistent stream of data.
	'''

	def __init__(self, pattern):
		# allow indexing into pattern and protect against change during yield
		self.pattern = list(pattern)
		self.patternlen = len(self.pattern)

		# build table of shift amounts
		self.shifts = [1] * (self.patternlen + 1)
		shift = 1
		for pos in range(self.patternlen):
			while shift <= pos and self.pattern[pos] != self.pattern[pos-shift]:
				shift += self.shifts[pos-shift]
		self.shifts[pos+1] = shift

		self.startpos = 0
		self.matchsel = 0


	def search(self, text):
		for c in text:
			while self.matchsel == self.patternlen or self.matchsel >= 0 and self.pattern[self.matchsel] != c:
				self.startpos += self.shifts[self.matchsel]
				self.matchsel -= self.shifts[self.matchsel]
			self.matchsel += 1
			if self.matchsel == self.patternlen:
				return self.startpos
		return -1


########NEW FILE########
__FILENAME__ = sendmail
import urlparse, smtplib, logging, getpass, socket, os, string
from email.mime.text import MIMEText
from .config import config
###

L = logging.getLogger('sendmail')

###

# Configure urlparse
if 'smtp' not in urlparse.uses_query: urlparse.uses_query.append('smtp')

###

class send_mail(object):

	def __init__(self, deliveryuri, sender=None):
		delurl = urlparse.urlparse(deliveryuri)
		if delurl.scheme == 'smtp' :
			if delurl.hostname is None:
				raise RuntimeError("Delivery URL '{0}' has no hostname".format(deliveryuri))
			else:
				self.hostname = delurl.hostname
				self.port = delurl.port if delurl.port is not None else 25
				self.username = delurl.username
				self.password = delurl.password
				self.params = dict(urlparse.parse_qsl(delurl.query))

				if sender is None:
					self.sender = config.get('ramona:notify','sender')
				else:
					self.sender = sender

				if self.sender == '<user>':
					self.sender = self.get_default_fromaddr()
				elif self.sender[:1] == '<':
					raise RuntimeError('Invalid sender option: {0}'.format(self.sender))

		else:
			raise RuntimeError("Unknown delivery method in {0}".format(deliveryuri))

		self.receiver = map(string.strip, config.get('ramona:notify', 'receiver').split(','))


	def send(self, recipients, subject, mail_body, sender=None):

		if sender is None: sender = self.sender

		msg = MIMEText(mail_body, 'plain', 'utf-8')
		msg['Subject'] = subject
		msg['From'] = sender
		msg['To'] = ', '.join(recipients)

		s = smtplib.SMTP(self.hostname, self.port)
		if self.params.get('tls', '1') == '1': s.starttls()
		if self.username is not None and self.password is not None:
			s.login(self.username, self.password)

		s.sendmail(sender, recipients, msg.as_string())
		s.quit()


	@staticmethod
	def get_default_fromaddr():
		hostname = socket.getfqdn()
		if hostname == 'localhost': hostname = socket.gethostname()
		return "{0}@{1}".format(getpass.getuser(), hostname)

########NEW FILE########
__FILENAME__ = call_status
import json, time
###

def main(svrapp, pfilter=None):
	l = svrapp.filter_roaster_iter(pfilter)
	ret = []
	for p in l:
		i = {
			'ident': p.ident,
			'state': p.state,
			'launch_cnt': p.launch_cnt,
		}
		if p.subproc is not None: i['pid'] = p.subproc.pid
		if p.exit_status is not None: i['exit_status'] = p.exit_status
		if p.exit_time is not None: i['exit_time'] = p.exit_time
		if p.start_time is not None:
			i['start_time'] = p.start_time
			if p.exit_time is None:  i["uptime"] = time.time() - p.start_time
		if p.autorestart_cnt > 0: i['autorestart_cnt'] = p.autorestart_cnt
		ret.append(i)

	return json.dumps(ret)

########NEW FILE########
__FILENAME__ = cnscon
import sys, socket, errno, struct, weakref, json, select, logging, time
import pyev
from .. import cnscom
###

L = logging.getLogger("cnscon")

###

if sys.platform != 'win32':
	BUFSIZE = select.PIPE_BUF
else:
	BUFSIZE = 512

###

class console_connection(object):
	'''Server side of console communication IPC'''

	NONBLOCKING = frozenset([errno.EAGAIN, errno.EWOULDBLOCK])

	def __init__(self, sock, address, serverapp):
		self.serverapp = serverapp
	
		self.sock = sock
		self.sock.setblocking(0)
		# Tuple of (socket family, socket type, socket protocol, ssl) 
		self.descr = (
			_socket_families_map.get(self.sock.family, self.sock.family),
			_socket_type_map.get(self.sock.type, self.sock.type),
			_socket_proto_map.get(self.sock.proto, self.sock.proto),
			None #TODO: SSL goes here ...
		)
		self.address = address
		
		self.connected_at = time.time()
		
		self.read_buf = ""
		self.write_buf = None
		
		self.yield_enabled = False
		self.return_expected = False # This is synchronization element used in asserts preventing IPC goes out of sync
		self.tailf_enabled = False

		self.watcher = pyev.Io(self.sock._sock, pyev.EV_READ, serverapp.loop, self.io_cb)
		self.watcher.start()

		L.debug("Console connection open ({0})".format(self.address))


	def __del__(self):
		self.close()


	def reset(self, events):
		self.watcher.stop()
		self.watcher.set(self.sock._sock, events)
		self.watcher.start()


	def io_cb(self, watcher, revents):
		try:
			if (revents & pyev.EV_READ) == pyev.EV_READ:
				self.handle_read()

			if self.sock is None: return # Socket has been just closed

			if (revents & pyev.EV_WRITE) == pyev.EV_WRITE:
				self.handle_write()
		except:
			L.exception("Exception during IO on console connection:")


	def handle_read(self):
		try:
			buf = self.sock.recv(1024)
		except socket.error as err:
			if err.args[0] not in self.NONBLOCKING:
				L.error("Error when reading from console connection socket: {0}".format(err)) 
				self.handle_error()
			return
		
		if len(buf) > 0:
			self.read_buf += buf
			
			while len(self.read_buf) >= 4:
				magic, callid, paramlen = struct.unpack(cnscom.call_struct_fmt, self.read_buf[:4])
				if magic != cnscom.call_magic:
					L.warning("Invalid data stream on control port")
					self.handle_error()
					return

				if (paramlen + 4) <= len(self.read_buf):
					params = self.read_buf[4:4+paramlen]
					self.read_buf = self.read_buf[4+paramlen:]
					
					self.return_expected = True
					try:
						ret = self.serverapp.dispatch_svrcall(self, callid, params)
					except Exception, e:
						if not isinstance(e, cnscom.svrcall_error):
							L.exception("Exception during dispatching console call")
						self.send_exception(e, callid)
					else:
						if ret == deffered_return: return
						self.send_return(ret, callid)

		else:
			L.debug("Connection closed by peer")
			self.handle_error()


	def handle_write(self):
		try:
			sent = self.sock.send(self.write_buf[:BUFSIZE])
		except socket.error as err:
			if err.args[0] not in self.NONBLOCKING:
				#TODO: Log "error writing to {0}".format(self.sock)
				self.handle_error()
				return
		else :
			self.write_buf = self.write_buf[sent:]
			if len(self.write_buf) == 0:
				self.reset(pyev.EV_READ)
				self.write_buf = None


	def write(self, data):
		if self.sock is None:
			L.warning("Socket is closed - write operation is ignored")
			return

		#TODO: Close socket if write buffer is tooo long

		if self.write_buf is None:
			self.write_buf = data
			self.reset(pyev.EV_READ | pyev.EV_WRITE)
		else:
			self.write_buf += data


	def close(self):
		if self.watcher is not None:
			self.watcher.stop()
			self.watcher = None
		if self.sock is not None:
			self.sock.close()
			self.sock = None


	def handle_error(self):
		L.debug("Console connection closed.")
		self.close()


	def send_return(self, ret, callid='-'):
		'''
		Internal function that manages communication of response (type return) to the console (client).
		'''
		assert self.return_expected

		self.yield_enabled = False
		ret = str(ret)
		lenret = len(ret)
		if lenret >= 0x7fff:
			self.handle_error()
			raise RuntimeError("Transmitted return value is too long (callid={0})".format(callid))
		
		self.write(struct.pack(cnscom.resp_struct_fmt, cnscom.resp_magic, cnscom.resp_return, lenret) + ret)
		self.return_expected = False


	def send_exception(self, e, callid='-'):
		'''
		Internal function that manages communication of response (type exception) to the console (client).
		'''
		assert self.return_expected, "Raised exception when return is not expected"

		self.yield_enabled = False
		ret = str(e)
		lenret = len(ret)
		if lenret >= 0x7fff:
			self.handle_error()
			raise RuntimeError("Transmitted exception is too long (callid={0})".format(callid))
		self.write(struct.pack(cnscom.resp_struct_fmt, cnscom.resp_magic, cnscom.resp_exception, lenret) + ret)
		self.return_expected = False


	def yield_message(self, message):
		if not self.yield_enabled: return
		assert self.return_expected

		messagelen = len(message)
		if messagelen >= 0x7fff:
			raise RuntimeError("Transmitted yield message is too long.")

		self.write(struct.pack(cnscom.resp_struct_fmt, cnscom.resp_magic, cnscom.resp_yield_message, messagelen) + message)


	def send_tailf(self, data):
		if not self.tailf_enabled: return

		datalen = len(data)
		if datalen >= 0x7fff:
			raise RuntimeError("Transmitted tailf data are too long.")

		self.write(struct.pack(cnscom.resp_struct_fmt, cnscom.resp_magic, cnscom.resp_tailf_data, datalen) + data)

###

class message_yield_loghandler(logging.Handler):
	'''
	Message yield(ing) log handler provides functionality to propagate log messages to connected consoles.
	It automatically emits all log records that are submitted into relevant logger (e.g. Lmy = logging.getLogger("my") ) and forwards them
	as resp_yield_message to connected consoles (yield has to be enabled on particular connection see yield_enabled).
	'''


	def __init__(self, serverapp):
		logging.Handler.__init__(self)
		self.serverapp = weakref.ref(serverapp)


	def emit(self, record):
		serverapp = self.serverapp()
		if serverapp is None: return

		msg = json.dumps({
			'msg': record.msg,
			'args': record.args,
			'funcName': record.funcName,
			'lineno': record.lineno,
			'levelno': record.levelno,
			'levelname': record.levelname,
			'name': record.name,
			'pathname': record.pathname,
		})

		for conn in serverapp.conns:
			conn.yield_message(msg)

###

class deffered_return(object): pass # This is just a symbol definition

#

_socket_families_map = {
	socket.AF_UNIX: 'AF_UNIX',
	socket.AF_INET: 'AF_INET',
	socket.AF_INET6: 'AF_INET6',
}

_socket_type_map = {
	socket.SOCK_STREAM: 'SOCK_STREAM',
	socket.SOCK_DGRAM: 'SOCK_DGRAM',
}

_socket_proto_map = {
	socket.IPPROTO_TCP: 'IPPROTO_TCP',
}

########NEW FILE########
__FILENAME__ = idlework
import logging, functools
import pyev
###

L = logging.getLogger("idlework")

###

def _execute(w):
	# Launch worker safely
	try:
		w()
	# except SystemExit, e:
	# 	L.debug("Idle worker requested system exit")
	# 	self.Terminate(e.code)
	except:
		L.exception("Exception during idle worker")


###

class idlework_appmixin(object):


	def __init__(self):
		self.idle_queue = []
		self.idle_watcher = pyev.Idle(self.loop, self.__idle_cb)


	def stop_idlework(self):
		self.idle_watcher.stop()
		self.idle_watcher = None

		while len(self.idle_queue) > 0:
			w = self.idle_queue.pop(0)
			_execute(w)


	def __del__(self):
		try:
			self.idle_watcher.stop()
		except AttributeError:
			pass


	def __idle_cb(self, watcher, revents):
		w = self.idle_queue.pop(0)

		if len(self.idle_queue) == 0:
			self.idle_watcher.stop()

		_execute(w)


	def add_idlework(self, worker, *args, **kwargs):
		'''
		Add worker (callable) to idle work queue.
		@param worker: Callable that will be invoked when applicaiton loops idles
		@param *args: Optional positional arguments that will be supplied to worker callable
		@param **kwargs: Optional keywork arguments that will be supplied to worker callable
		'''
		if len(args) > 0 or len(kwargs) > 0:
			worker = functools.partial(worker, *args, **kwargs)
		
		self.idle_queue.append(worker)
		self.idle_watcher.start()

########NEW FILE########
__FILENAME__ = logmed
import collections, os, weakref, logging
from ..config import get_logconfig
from ..kmpsearch import kmp_search
from ..utils import rotate_logfiles
from .singleton import get_svrapp

###

L = logging.getLogger('logmed')
Lmy = logging.getLogger("my") # Message yielding logger

###


class log_mediator(object):
	'''
	This object serves as mediator between program and its log files.

	It provides following functionality:
		- log rotation
		- tail buffer
		- seek for patterns in log stream and eventually trigger error mail
	'''

	maxlinelen = 0x7f00 # Connected to maximum IPC (console-server) data buffer
	linehistory = 100 # Number of tail history (in lines)

	def __init__(self, prog_ident, stream_name, fname):
		'''
		@param prog_ident: identification of the program (x from [program:x])
		@param stream_name: stdout or stderr
		@param fname: name of connected log file, can be None if no log is connected
		'''
		self.prog_ident = prog_ident
		self.stream_name = stream_name
		self.fname = os.path.normpath(fname) if fname is not None else None
		self.outf = None
		self.scanners = []

		self.tailbuf = collections.deque() # Lines
		self.tailbufnl = True
		self.tailfset = weakref.WeakSet()


		# Read last content of the file into tail buffer
		if self.fname is not None and os.path.isfile(self.fname):
			with open(self.fname, "r") as logf:
				logf.seek(0, os.SEEK_END)
				fsize = logf.tell()
				fsize -= self.linehistory * 512
				if fsize <0: fsize = 0
				logf.seek(fsize, os.SEEK_SET)
				
				for line in logf:
					self.__add_to_tailbuf(line)


		# Configure log rotation
		self.logbackups, self.logmaxsize, self.logcompress = get_logconfig()


	def open(self):
		if self.outf is None and self.fname is not None:
			try:
				self.outf = open(self.fname,'a')
			except Exception, e:
				L.warning("Cannot open log file '{0}' for {1}: {2}".format(self.fname, self.stream_name, e))
				Lmy.warning("Cannot open log file '{0}' for {1}: {2}".format(self.fname, self.stream_name, e))
				self.outf = None
				return False

		return True


	def close(self):
		if self.outf is not None:
			self.outf.close()
			self.outf = None


	def write(self, data):
		if self.outf is not None:
			self.outf.write(data)
			self.outf.flush() #TODO: Maybe something more clever here can be better (check logging.StreamHandler)
			if (self.logmaxsize > 0) and (self.outf.tell() >= self.logmaxsize):
				self.rotate()

		self.__add_to_tailbuf(data)

		# Search for patterns
		svrapp = get_svrapp()
		if len(self.scanners) > 0 and svrapp is not None:

			stext = data.lower()
			for s in self.scanners:

				startpos = s.startpos
				r = s.search(stext)
				if r < 0: continue

				# Calculate position in the stream
				startpos = r - startpos
				if startpos < 0: startpos = 0

				# Identify starting position 
				errstart = startpos
				for _ in range(3): # Number of lines before pattern hit
					errstart = stext.rfind('\n', 0, errstart)
					if errstart < 0:
						errstart = 0
						break

				# Identify end position 
				errend = startpos
				for _ in range(3):
					errend = stext.find('\n', errend+1)
					if errend < 0:
						errend = -1
						break
				
				pattern = ''.join(s.pattern)
				ntftext  = 'Program: {0}\n'.format(s.prog_ident)
				ntftext += 'Pattern: {0}\n'.format(pattern)
				ntftext += '\n'+'-'*50+'\n'
				ntftext += data[errstart:errend].strip('\n')
				ntftext += '\n'+'-'*50+'\n'

				svrapp.notificator.publish(s.target, ntftext, "{} / {}".format(s.prog_ident, pattern))


	def rotate(self):
		'Perform rotation of connected file - if any'
		if self.fname is None: return
		if self.outf is None: return

		L.debug("Rotating '{0}' file".format(self.fname))

		self.outf.close()
		try:
			rotate_logfiles(get_svrapp(), self.fname, self.logbackups, self.logcompress)
		finally:
			self.outf = open(self.fname,'a')		


	def __tailbuf_append(self, data, nlt):
		if self.tailbufnl:
			if len(data) <= self.maxlinelen:
				self.tailbuf.append(data)
			else:
				self.tailbuf.extend(_chunker(data, self.maxlinelen))

		else:
			data = self.tailbuf.pop() + data
			if len(data) <= self.maxlinelen:
				self.tailbuf.append(data)
			else:
				self.tailbuf.extend(_chunker(data, self.maxlinelen))

		self.tailbufnl = nlt

		# Remove old tail lines
		while len(self.tailbuf) > self.linehistory:
			self.tailbuf.popleft()


	def __add_to_tailbuf(self, data):
		# Add data to tail buffer
		lendata = len(data)
		if lendata == 0: return

		datapos = 0
		while datapos < lendata:
			seppos = data.find('\n', datapos)
			if seppos == -1:
				# Last chunk & no \n at the end
				if datapos == 0:
					self.__tailbuf_append(data, False)
				else:
					self.__tailbuf_append(data[datapos:], False)
				break
			elif seppos == lendata-1:
				# Last chunk terminated with \n
				if datapos == 0:
					self.__tailbuf_append(data, True)
				else:
					self.__tailbuf_append(data[datapos:], True)
				break
			else:
				self.__tailbuf_append(data[datapos:seppos+1], True)
				datapos = seppos + 1

		# Send tail to tailf clients
		for cnscon in self.tailfset:
			cnscon.send_tailf(data)


	def tail(self, cnscon, lines, tailf):
		d = collections.deque()
		dlen = 0
		for line in reversed(self.tailbuf):
			dlen += len(line)
			if dlen >= 0x7fff: break #Protect maximum IPC data len
			d.appendleft(line)
			lines -= 1
			if lines <=0: break

		if tailf:
			cnscon.tailf_enabled = True
			self.tailfset.add(cnscon)

		return "".join(d)


	def tailf_stop(self, cnscon):
		self.tailfset.remove(cnscon)
		cnscon.tailf_enabled = False


	def add_scanner(self, pattern, target):
		self.scanners.append(
			_log_scanner(self.prog_ident, self.stream_name, pattern, target)
		)

#

class _log_scanner(kmp_search):

	def __init__(self, prog_ident, stream_name, pattern, target):
		kmp_search.__init__(self, pattern)
		assert target.startswith(('now','daily'))
		self.target = target
		self.prog_ident = prog_ident
		self.stream_name = stream_name

#

def _chunker(data, maxsize):
	for i in xrange(0, len(data), maxsize):
		yield data[i:i+maxsize]


########NEW FILE########
__FILENAME__ = notify
import os, datetime, socket, logging, time, pickle
import pyev
from ..config import config
from ..sendmail import send_mail

#

L = logging.getLogger('notify')

#

class stash(object):
	# Example structure of self.data dict is:
	# {
	#   "foo@bar.com": [] # List of lines to be included in the mail
	#   "bar@foo.com": ['notify1', 'notify2']
	# }


	def __init__(self, name):
		self.data = dict()
		self.name = name
		stashdir = config.get('ramona:notify', 'stashdir')
		if stashdir == '<none>':
			self.fname = None
		else:
			self.fname = os.path.join(stashdir, name)
			if os.path.isfile(self.fname):
				try:
					with open(self.fname, "rb") as f:
						self.data = pickle.load(f)
				except:
					L.warning("Ignored issue when loading stash file '{}'".format(self.fname))

		self.store_needed = False
		


	def add(self, recipients, ntfbody):
		 #TODO: Consider adding also ntfsubj (subject)
		for recipient in recipients:
			if not self.data.has_key(recipient):
				self.data[recipient] = list()
			self.data[recipient].append(ntfbody)

		self.store_needed = True


	def yield_text(self):
		for recipient, ntftexts in self.data.iteritems():
			textssend = []
			while True:
				try:
					textssend.append(ntftexts.pop())
				except IndexError:
					break

			yield recipient, textssend
		self.store_needed = True


	def store(self):
		if not self.store_needed: return
		self.store_needed = False
		if self.fname is None: return

		with open(self.fname, "wb") as f:
			pickle.dump(self.data, f)

		L.debug("Stash '{}' persisted!".format(self.name))

#

class notificator(object):

	def __init__(self, svrapp):
		delivery = config.get('ramona:notify','delivery').strip()
		if delivery == '':
			self.delivery = None
		else:
			try:
				self.delivery = send_mail(delivery)
			except RuntimeError, e:
				L.error("{0}".format(e))
				self.delivery = None
		
		self.stashes = {
			'daily': stash('daily'),
		}
		if self.delivery is not None:
			svrapp.watchers.append(pyev.Periodic(self.__get_daily_time_offset(), 24*3600, svrapp.loop, self.send_daily))

		#TODO: <sendmail> - see http://stackoverflow.com/questions/73781/sending-mail-via-sendmail-from-python
		#TODO: cmd:custom.sh


	def on_tick(self, now):
		for stash in self.stashes.itervalues():
			stash.store()


	def __get_daily_time_offset(self):
		sendtimestr = config.get("ramona:notify", "dailyat")
		
		# TODO: Enhance to better handle situation for the day when the timezone changes (switch from/to daylight saving time)
		sendtime = datetime.datetime.strptime(sendtimestr, "%H:%M").time()
		is_dst = time.daylight and time.localtime().tm_isdst > 0
		utc_offset = time.altzone if is_dst else time.timezone
		
		sendtimeseconds = sendtime.hour * 3600 + sendtime.minute * 60 + utc_offset
		
		if sendtimeseconds < 0:
			sendtimeseconds += 24*3600
		if sendtimeseconds >= 24*3600:
			sendtimeseconds -= 24*3600
		
		return sendtimeseconds
	
	
	def send_daily(self, watcher, revents):
		if watcher is not None:
			watcher.offset = self.__get_daily_time_offset()
			watcher.reset()

		appname = config.get('general','appname')
		hostname = socket.gethostname()
		subj = '{0} / {1} - daily'.format(appname, hostname)
		sep = '\n'+'-'*50+'\n'

		for recipient, textssend in self.stashes['daily'].yield_text():
			# Use pop to get the items from the stash to ensure that items that are put on the stash
			# during sending are not sent twice (in the current email and in the next email)
			if len(textssend) == 0: continue
			self._send_mail(subj, sep.join(textssend)+'\n', [recipient])


	def publish(self, target, ntfbody, ntfsubj):
		if ntfsubj is None: ntfsubj = 'notification'

		targettime, _, recipientconf = target.partition(":")
		recipientconf = recipientconf.strip()
		if recipientconf != "":
			recipients = [recipientconf]
		else:
			if self.delivery is None:
				L.warning("No default delivery set for notifications.")
				return
			recipients = self.delivery.receiver

		if targettime == "now":
			self._send_mail(
				ntfsubj, 
				ntfbody,
				recipients
			)

		elif targettime == "daily":
			self.stashes['daily'].add(recipients, ntfbody)
			
		else:
			L.warn("Target {} not implemented!".format(targettime))
			


	def _send_mail(self, subject, text, recipients):
		'''
		@param subject: Subject of the email message
		@param text: Text to be sent (it is prefixed with greeting and signature by this method)
		@param recipients: List of message recipients
		'''

		L.info("Sending '{}' mail to {}".format(subject, ', '.join(recipients)))

		fqdn = socket.getfqdn()
		appname = config.get('general','appname')
		hostname = socket.gethostname()

		subject = '{0} / {1} / {2} (by Ramona)'.format(appname, hostname, subject)

		sysident = 'Application: {0}\n'.format(appname)
		if hostname != fqdn and fqdn != 'localhost':
			sysident += 'Hostname: {0} / {1}'.format(hostname, fqdn)
		else:
			sysident += 'Hostname: {0}'.format(hostname)

		try:
			text = ''.join([
				'Hello,\n\nRamona produced following notification:\n\n', text,
				'\n\nSystem info:\n', sysident, #Two enters in the begging are intentional; arg 'text' should not have one at its end
				'\n\nBest regards,\nYour Ramona\n\nhttp://ateska.github.com/ramona\n'
			])
			
			self.delivery.send(recipients, subject, text)

		except:
			L.exception('Exception during sending mail - ignoring')

########NEW FILE########
__FILENAME__ = proaster
import logging, time
from ..config import config
from ..cnscom import svrcall_error, program_state_enum
from .program import program
from .seqctrl import sequence_controller

###

L = logging.getLogger('proaster')
Lmy = logging.getLogger('my')

###

class program_roaster(object):
	'''
Program roaster is object that control all configured programs, their start/stop operations etc.
	'''

	def __init__(self):
		self.start_seq = None
		self.stop_seq = None
		self.restart_seq = None

		self.roaster = []
		for config_section in config.sections():
			if config_section.find('program:') != 0: continue
			sp = program(self, config_section)
			self.roaster.append(sp)


	def get_program(self, ident):
		for p in self.roaster:
			if p.ident == ident: return p
		raise KeyError("Unknown program '{0}' requested".format(ident))


	def filter_roaster_iter(self, pfilter=None):
		if pfilter is None:
			for p in self.roaster: yield p
			return

		filter_set = frozenset(pfilter)
		roaster_dict = dict((p.ident, p) for p in self.roaster)

		# Pass only known program names
		not_found = filter_set.difference(roaster_dict)
		if len(not_found) > 0:
			for pn in not_found:
				Lmy.error('Unknown/invalid program name: {0}'.format(pn))

		for ident, p in roaster_dict.iteritems():
			if ident in filter_set: yield p


	def start_program(self, cnscon=None, pfilter=None, force=False):
		'''Start processes that are STOPPED and (forced) FATAL'''
		if self.start_seq is not None or self.stop_seq is not None or self.restart_seq is not None:
			raise svrcall_error("There is already start/stop sequence running - please wait and try again later.")

		l = self.filter_roaster_iter(pfilter)

		L.debug("Initializing start sequence")
		self.start_seq = sequence_controller(cnscon)

		# If 'force' is used, include as programs in FATAL state
		if force: states = (program_state_enum.STOPPED,program_state_enum.FATAL)
		else: states = (program_state_enum.STOPPED,)

		for p in l:
			if p.state in states:
				self.start_seq.add(p)		
			else:
				Lmy.warning("Program {0} is in {1} state - not starting.".format(p.ident, program_state_enum.labels.get(p.state,'<?>')))

		self.__startstop_pad_next(True)


	def stop_program(self, cnscon=None, pfilter=None, force=False, coredump=False):
		'''
		Stop processes that are RUNNING and STARTING
		@param force: If True then it interrupts any concurrently running start/stop sequence.
		'''
		if force:
			self.start_seq = None
			self.restart_seq = None
			self.stop_seq = None

		else:
			if self.start_seq is not None or self.stop_seq is not None or self.restart_seq is not None:
				raise svrcall_error("There is already start/stop sequence running - please wait and try again later.")

		l = self.filter_roaster_iter(pfilter)

		L.debug("Initializing stop sequence")
		self.stop_seq = sequence_controller(cnscon)

		for p in l:
			if p.state not in (program_state_enum.RUNNING, program_state_enum.STARTING): continue
			if coredump: p.charge_coredump()
			self.stop_seq.add(p)

		self.__startstop_pad_next(False)


	def restart_program(self, cnscon, pfilter=None, force=False):
		'''Restart processes that are RUNNING, STARTING, STOPPED and (forced) FATAL'''
		if self.start_seq is not None or self.stop_seq is not None or self.restart_seq is not None:
			raise svrcall_error("There is already start/stop sequence running - please wait and try again later.")

		L.debug("Initializing restart sequence")
		
		l = self.filter_roaster_iter(pfilter)

		self.stop_seq = sequence_controller() # Don't need to have cnscon connected with stop_seq (there is no return)
		self.restart_seq = sequence_controller(cnscon)

		# If 'force' is used, include as programs in FATAL state
		if force: start_states = (program_state_enum.STOPPED,program_state_enum.FATAL)
		else: start_states = (program_state_enum.STOPPED,)

		for p in l:
			if p.state in (program_state_enum.RUNNING, program_state_enum.STARTING):
				self.stop_seq.add(p)
				self.restart_seq.add(p)
			elif p.state in start_states:
				self.restart_seq.add(p)
			else:
				Lmy.warning("Program {0} is in {1} state - not restarting.".format(p.ident, program_state_enum.labels.get(p.state,'<?>')))

		self.__startstop_pad_next(False)



	def __startstop_pad_next(self, start=True):
		pg = self.start_seq.next() if start else self.stop_seq.next()
		if pg is None:
			if start:
				cnscon = self.start_seq.cnscon
				if cnscon is not None:
					self.start_seq.cnscon = None
					cnscon.send_return(True)
				self.start_seq = None
				L.debug("Start sequence completed.")
			else:
				cnscon = self.stop_seq.cnscon

				if self.restart_seq is None or self.termstatus is not None:
					if cnscon is not None:
						self.stop_seq.cnscon = None
						cnscon.send_return(True)
					L.debug("Stop sequence completed.")
					self.stop_seq = None
					return

				else:
					Lmy.info("Restart finished stop phase and entering start phase")
					L.debug("Restart sequence enters starting phase")
					self.stop_seq = None
					self.start_seq = self.restart_seq
					self.restart_seq = None
					self.__startstop_pad_next(True)
					return

		else:
			# Start/stop all programs in the active set
			map(program.start if start else program.stop, pg)


	def on_terminate_program(self, pid, status):
		for p in self.roaster:
			if p.subproc is None: continue
			if pid != p.subproc.pid: continue
			return p.on_terminate(status)
		else:
			L.warning("Unknown program died (pid={0}, status={1})".format(pid, status))


	def on_tick(self, now):
		'''Periodic check of program states'''
		for p in self.roaster:
			p.on_tick(now)

		if self.start_seq is not None:
			r = self.start_seq.check(program_state_enum.STARTING, program_state_enum.RUNNING)
			if r is None:
				L.warning("Start sequence aborted due to program error")
				self.start_seq = None
				assert self.restart_seq is None
			elif r:
				self.__startstop_pad_next(True)

		if self.stop_seq is not None:
			r = self.stop_seq.check(program_state_enum.STOPPING, program_state_enum.STOPPED)
			if r is None:
				if self.restart_seq is None:
					L.warning("Stop sequence aborted due to program error")
					self.stop_seq = None
					assert self.start_seq is None
					assert self.restart_seq is None
				else:
					L.warning("Restart sequence aborted due to program error")
					self.restart_seq = None
					self.stop_seq = None
					assert self.start_seq is None

			elif r:
				self.__startstop_pad_next(False)

########NEW FILE########
__FILENAME__ = program
import sys, os, time, logging, shlex, signal, subprocess, errno
import pyev
from ..config import config, get_boolean, get_env
from ..utils import parse_signals, expandvars, enable_nonblocking, disable_nonblocking, get_python_exec, get_signal_name
from ..cnscom import program_state_enum, svrcall_error
from .logmed import log_mediator
from .singleton import get_svrapp


if sys.platform == 'win32':
	import msvcrt
	import win32file, win32pipe, pywintypes, winerror # from Python Win32
#

try:
	import resource
except ImportError:
	resource = None

#

L = logging.getLogger("program")
Lmy = logging.getLogger("my") # Message yielding logger

#

class program(object):

	DEFAULTS = {
		'command': None,
		'directory': None,
		'umask': None,
		'starttimeout': 0.5,
		'stoptimeout': 3,
		'killby': 'TERM,INT,TERM,INT,TERM,INT,KILL',
		'stdin': '<null>', # TODO: This can be very probably removed as there is no reasonable use
		'stdout': '<stderr>',
		'stderr': '<logdir>',
		'priority': 100,
		'disabled': False,
		'coredump': False,
		'autorestart': False,
		'processgroup': True,
		'logscan_stdout': '',
		'logscan_stderr': '',
		'notify_fatal': '<global>',
	}

	def __init__(self, svrapp, config_section):
		_, self.ident = config_section.split(':', 2)
		self.state = program_state_enum.STOPPED
		self.subproc = None

		self.launch_cnt = 0
		self.autorestart_cnt = 0
		self.start_time = None
		self.stop_time = None
		self.exit_time = None
		self.exit_status = None
		self.coredump_enabled = None # If true, kill by SIGQUIT -> dump core

		if sys.platform != 'win32':
			# On Windows we are using periodic pipe check in win32_read_stdfd
			self.watchers = [
				pyev.Io(0, 0, svrapp.loop, self.__read_stdfd, 0),
				pyev.Io(0, 0, svrapp.loop, self.__read_stdfd, 1),
			]

		# Build configuration
		self.config = self.DEFAULTS.copy()
		self.config.update(config.items(config_section))

		# Prepare program command line
		cmd = self.config.get('command')
		if cmd is None:
			L.error("Missing command option in {0} -> CFGERROR".format(config_section))
			self.state = program_state_enum.CFGERROR
			return

		if cmd == '<httpfend>':
			cmd = get_python_exec(cmdline=["-u","-m","ramona.httpfend"])
		elif cmd[:1] == '<':
			L.error("Unknown command option '{1}' in {0} -> CFGERROR".format(config_section, cmd))
			self.state = program_state_enum.CFGERROR
			return

		cmd = cmd.replace('\\', '\\\\')
		self.cmdline = shlex.split(cmd)

		# Prepare stop signals
		if sys.platform != 'win32':
			self.stopsignals = parse_signals(self.config['killby'])
			if len(self.stopsignals) == 0: self.stopsignals = [signal.SIGTERM]
			self.act_stopsignals = None

		if self.config['stdin'] != '<null>':
			L.error("Unknown stdin option '{0}' in {1} -> CFGERROR".format(self.config['stdin'], config_section))
			self.state = program_state_enum.CFGERROR
			return

		try:
			self.priority = int(self.config.get('priority'))
		except:
			L.error("Invalid priority option '{0}' in {1} -> CFGERROR".format(self.config['priority'], config_section))
			self.state = program_state_enum.CFGERROR
			return		
		
		try:
			dis = get_boolean(self.config.get('disabled'))
		except ValueError:
			L.error("Unknown 'disabled' option '{0}' in {1} -> CFGERROR".format(dis, config_section))
			self.state = program_state_enum.CFGERROR
			return
		if dis:
			self.state = program_state_enum.DISABLED

		self.ulimits = {}
		#TODO: Enable other ulimits..
		try:
			coredump = get_boolean(self.config.get('coredump',False))
		except ValueError:
			L.error("Unknown 'coredump' option '{0}' in {1} -> CFGERROR".format(self.config.get('coredump','?'), config_section))
			self.state = program_state_enum.CFGERROR
			return

		if coredump and resource is not None:
			self.ulimits[resource.RLIMIT_CORE] = (-1,-1)

		try:
			self.autorestart = get_boolean(self.config.get('autorestart',False))
		except ValueError:
			L.error("Unknown 'autorestart' option '{0}' in {1} -> CFGERROR".format(self.config.get('autorestart','?'), config_section))
			self.state = program_state_enum.CFGERROR
			return

		try:
			get_boolean(self.config.get('processgroup',True))
		except ValueError:
			L.error("Unknown 'processgroup' option '{0}' in {1} -> CFGERROR".format(self.config.get('processgroup','?'), config_section))
			self.state = program_state_enum.CFGERROR
			return

		umask = self.config.get('umask')
		if umask is not None:
			try:
				umask = int(umask, 8)
			except:
				L.error("Invalid umask option ({1}) in {0} -> CFGERROR".format(config_section, umask))
				self.state = program_state_enum.CFGERROR
				return
			self.config['umask'] = umask


		# Prepare log files
		stdout_cnf = self.config['stdout']
		stderr_cnf = self.config['stderr']

		if (stdout_cnf == '<stderr>') and (stderr_cnf == '<stdout>'):
			L.error("Invalid stdout and stderr combination in {0} -> CFGERROR".format(config_section))
			self.state = program_state_enum.CFGERROR
			return			

		# Stdout settings
		if stdout_cnf == '<logdir>':
			if stderr_cnf  in ('<stdout>','<null>') :
				fname = os.path.join(config.get('general','logdir'), self.ident + '.log')
			else:
				fname = os.path.join(config.get('general','logdir'), self.ident + '-out.log')
			self.log_out = log_mediator(self.ident, 'stdout', fname)
		elif stdout_cnf == '<stderr>':
			pass
		elif stdout_cnf == '<null>':
			self.log_out = log_mediator(self.ident, 'stdout', None)
		elif stdout_cnf[:1] == '<':
			L.error("Unknown stdout option in {0} -> CFGERROR".format(config_section))
			self.state = program_state_enum.CFGERROR
			return			
		else:
			self.log_out = log_mediator(self.ident, 'stdout', stdout_cnf)

		# Stderr settings
		if stderr_cnf == '<logdir>':
			if stdout_cnf in ('<stderr>','<null>') :
				fname = os.path.join(config.get('general','logdir'), self.ident + '.log')
			else:
				fname = os.path.join(config.get('general','logdir'), self.ident + '-err.log')
			self.log_err = log_mediator(self.ident, 'stderr', fname)
		elif stderr_cnf == '<stdout>':
			self.log_err = self.log_out
		elif stderr_cnf == '<null>':
			self.log_err = log_mediator(self.ident, 'stderr', None)
		elif stderr_cnf[:1] == '<':
			L.error("Unknown stderr option in {0} -> CFGERROR".format(config_section))
			self.state = program_state_enum.CFGERROR
			return
		else:
			self.log_err = log_mediator(self.ident, 'stderr', stderr_cnf)

		if stdout_cnf == '<stderr>':
			self.log_out = self.log_err

		# Log scans
		for stream, logmed in [('stdout', self.log_out),('stderr', self.log_err)]:

			logscanval = self.config.get('logscan_{0}'.format(stream)).strip()
			if len(logscanval) == 0:
				logscanval = config.get('ramona:notify','logscan_{}'.format(stream))
				if len(logscanval) == 0:
					logscanval = config.get('ramona:notify','logscan'.format(stream))

			for logscanseg in logscanval.split(','):
				logscanseg = logscanseg.strip()
				if logscanseg == '': continue

				try:
					pattern, target = logscanseg.split('>',1)
				except ValueError:
					L.error("Unknown 'logscan_{2}' option '{0}' in {1} -> CFGERROR".format(logscanseg, config_section, stream))
					self.state = program_state_enum.CFGERROR
					return

				if not validate_notify_target(target):
					L.error("Unknown 'logscan_{2}' option '{0}' in {1} -> CFGERROR".format(target, config_section, stream))
					self.state = program_state_enum.CFGERROR
					return

				logmed.add_scanner(pattern, target)

		# Environment variables
		try:
			alt_env = config.get(config_section, None)
		except:
			alt_env = None

		self.env = get_env(alt_env)
		self.env['RAMONA_SECTION'] = config_section

		# Notification on state change to FATAL
		self.notify_fatal_target = self.config.get('notify_fatal', '<global>')
		if self.notify_fatal_target == '<global>':
			self.notify_fatal_target = config.get('ramona:notify','notify_fatal', 'now')

		if self.notify_fatal_target == '<none>':
			self.notify_fatal_target = None

		if (self.notify_fatal_target is not None) and not validate_notify_target(self.notify_fatal_target):
			L.warning("Invalid notify_fatal target: '{}'".format(self.notify_fatal_target))
			self.notify_fatal_target = None


	def __repr__(self):
		ret = "<{0} {1} state={2}".format(self.__class__.__name__, self.ident, program_state_enum.labels.get(self.state, '?'))
		if self.subproc is not None:
			ret +=  ' pid={}'.format(self.subproc.pid)
		if self.exit_status is not None:
			ret +=  ' exit_status={}'.format(self.exit_status)
		return ret+'>'


	def start(self, reset_autorestart_cnt=True):
		'''Transition to state STARTING'''
		assert self.subproc is None
		assert self.state in (program_state_enum.STOPPED, program_state_enum.FATAL)

		L.debug("{0} ({1}) -> STARTING".format(self, self.cmdline))

		# Prepare working directory
		directory = self.config.get('directory')
		if directory is not None:
			directory = expandvars(directory, self.env)

		# Launch subprocess
		cmdline = [expandvars(arg, self.env) for arg in self.cmdline]
		try:
			self.subproc = subprocess.Popen(
				cmdline,
				stdin=None,
				stdout=subprocess.PIPE,
				stderr=subprocess.PIPE,
				preexec_fn=self.__preexec_fn if sys.platform != 'win32' else None,
				close_fds=True if sys.platform != 'win32' else None,
				shell=False, #TOOD: This can/should be configurable in [program:x] section
				cwd=directory,
				env=self.env
			)
		except Exception, e:
			self.state = program_state_enum.FATAL
			Lmy.error("{0} failed to start (now in FATAL state): {1}".format(self.ident, e))
			L.error("{0} failed to start: {1} -> FATAL".format(self, e))
			return

		if sys.platform != 'win32':
			enable_nonblocking(self.subproc.stdout)
			self.watchers[0].set(self.subproc.stdout, pyev.EV_READ)
			self.watchers[0].start()

			enable_nonblocking(self.subproc.stderr)
			self.watchers[1].set(self.subproc.stderr, pyev.EV_READ)
			self.watchers[1].start()

		# Open log files
		#TODO: Following functions can fail - maybe termination of start sequence is proper reaction
		self.log_out.open()
		if self.log_out != self.log_err: self.log_err.open()

		self.log_err.write("\n-=[ {} STARTING by Ramona on {} ]=-\n".format(self.ident, time.strftime("%Y-%m-%d %H:%M:%S")))
		self.state = program_state_enum.STARTING
		self.start_time = time.time()
		self.stop_time = None
		self.exit_time = None
		self.exit_status = None
		self.coredump_enabled = None
		self.launch_cnt += 1
		if reset_autorestart_cnt: self.autorestart_cnt = 0


	def __preexec_fn(self):
		# Launch in dedicated process group (optionally)
		if get_boolean(self.config.get('processgroup',True)):
			os.setsid()

		# Set umask
		umask = self.config.get('umask')
		if umask is not None:
			try:
				os.umask(umask)
			except Exception, e:
				os.write(2, "FATAL: Set umask {0} failed: {1}\n".format(umask, e))
				raise

		# Set ulimits
		if resource is not None:
			for k,v in self.ulimits.iteritems():
				try:
					resource.setrlimit(k,v)
				except Exception, e:
					os.write(2, "WARNING: Setting ulimit '{1}' failed: {0}\n".format(e, k))

		#TODO: Load shell profile if configured (can be used e.g. for virtual-env bootstrap)


	def stop(self):
		'''Transition to state STOPPING'''
		if self.state == program_state_enum.FATAL: return # This can happen and it is probably OK

		assert self.subproc is not None
		assert self.state in (program_state_enum.RUNNING, program_state_enum.STARTING)

		L.debug("{0} -> STOPPING".format(self))
		if sys.platform == 'win32':
			self.subproc.terminate()
		else:
			self.act_stopsignals = self.stopsignals[:]
			signal = self.get_next_stopsignal()
			try:
				if get_boolean(self.config.get('processgroup',True)):
					os.kill(-self.subproc.pid, signal) # Killing whole process group
				else:
					os.kill(self.subproc.pid, signal)
			except:
				pass
			

		self.state = program_state_enum.STOPPING
		self.stop_time = time.time()


	def on_terminate(self, status):
		self.exit_time = time.time()

		# Evaluate exit status
		if sys.platform == 'win32':
			self.exit_status = status
		elif os.WIFSIGNALED(status):
			self.exit_status = get_signal_name(os.WTERMSIG(status))
		elif os.WIFEXITED(status):
			self.exit_status = os.WEXITSTATUS(status)
		else:
			self.exit_status = "?"

		# Close process stdout and stderr pipes (including vacuum of actual content)
		if sys.platform != 'win32':
			self.watchers[0].stop()
			self.watchers[0].set(0, 0)
			disable_nonblocking(self.subproc.stdout)
			while True:
				signal.setitimer(signal.ITIMER_REAL, 0.5) # Set timeout for following operation
				try:
					data = os.read(self.subproc.stdout.fileno(), 4096)
				except OSError, e:
					if e.errno == errno.EINTR:
						L.warning("We have stall recovery situation on stdout socket of {0}".format(self))
						# This stall situation can happen when program shares stdout with its child
						# e.g. command=bash -c "echo ahoj1; tail -f /dev/null"
						break
					raise
				if len(data) == 0: break
				self.log_out.write(data)

			self.watchers[1].stop()
			self.watchers[1].set(0, 0)
			disable_nonblocking(self.subproc.stderr)
			while True:
				signal.setitimer(signal.ITIMER_REAL, 0.2) # Set timeout for following operation
				try:
					data = os.read(self.subproc.stderr.fileno(), 4096)
				except OSError, e:
					if e.errno == errno.EINTR:
						L.warning("We have stall recovery situation on stderr socket of {0}".format(self))
						# See comment above
						break
					raise
				if len(data) == 0: break
				self.log_err.write(data)

		elif sys.platform == 'win32':
			self.win32_read_stdfd()

		# Explicitly destroy subprocess object
		if self.subproc is not None: pidtext = ', pid: {}'.format(self.subproc.pid)
		else: pidtext = ''
		self.subproc = None

		# Close log files
		self.log_err.write("\n-=[ {} EXITED on {} with status {}{} ]=-\n".format(self.ident, time.strftime("%Y-%m-%d %H:%M:%S"), self.exit_status, pidtext))
		self.log_out.close()
		self.log_err.close()

		# Handle state change properly
		if self.state == program_state_enum.STARTING:
			Lmy.error("{0} exited too quickly (exit_status:{1}{2}, now in FATAL state)".format(self.ident, self.exit_status, pidtext))
			L.error("{0} exited too quickly -> FATAL".format(self))
			self.state = program_state_enum.FATAL
			self.notify_fatal_state(program_state_enum.STARTING)

		elif self.state == program_state_enum.STOPPING:
			Lmy.info("{0} is now STOPPED (exit_status:{1}{2})".format(self.ident, self.exit_status, pidtext))
			L.debug("{0} -> STOPPED".format(self))
			self.state = program_state_enum.STOPPED

		else:
			orig_state = self.state
			if self.autorestart:
				Lmy.error("{0} exited unexpectedly and going to be restarted (exit_status:{1}{2})".format(self.ident, self.exit_status, pidtext))
				L.error("{0} exited unexpectedly -> FATAL -> autorestart".format(self))
				self.state = program_state_enum.FATAL
				self.autorestart_cnt += 1
				self.notify_fatal_state(orig_state, autorestart=True)
				self.start(reset_autorestart_cnt=False)
			else:
				Lmy.error("{0} exited unexpectedly (exit_status:{1}{2}, now in FATAL state)".format(self.ident, self.exit_status, pidtext))
				L.error("{0} exited unexpectedly -> FATAL".format(self))
				self.state = program_state_enum.FATAL
				self.notify_fatal_state(orig_state)


	def on_tick(self, now):
		# Switch starting programs into running state
		if self.state == program_state_enum.STARTING:
			if now - self.start_time >= self.config['starttimeout']:
				Lmy.info("{0} is now RUNNING".format(self.ident))
				L.debug("{0} -> RUNNING".format(self))
				self.state = program_state_enum.RUNNING

		elif self.state == program_state_enum.STOPPING:
			if now - self.stop_time >= self.config['stoptimeout']:
				L.warning("{0} is still terminating - sending another signal".format(self))
				signal = self.get_next_stopsignal()
				try:
					if get_boolean(self.config.get('processgroup',True)):
						os.kill(-self.subproc.pid, signal) # Killing whole process group
					else:
						os.kill(self.subproc.pid, signal)
				except:
					pass


	def get_next_stopsignal(self):
		if self.coredump_enabled:
			self.coredump_enabled = None
			L.debug("Core dump enabled for {0} - using SIGQUIT".format(self))
			return signal.SIGQUIT
		if len(self.act_stopsignals) == 0: return signal.SIGKILL
		return self.act_stopsignals.pop(0)


	def __read_stdfd(self, watcher, revents):
		try:
			while 1:
				try:
					data = os.read(watcher.fd, 4096)
				except OSError, e:
					if e.errno == errno.EAGAIN: return # No more data to read (would block)
					raise

				if len(data) == 0: # File descriptor is closed
					watcher.stop()
					return 
				
				if watcher.data == 0: self.log_out.write(data)
				elif watcher.data == 1: self.log_err.write(data)
		except:
			L.exception("Error during __read_stdfd:")
			

	def win32_read_stdfd(self):
		'''Alternative implementation of stdout/stderr non-blocking read for Windows
		For details see:

		http://code.activestate.com/recipes/440554/
		http://msdn.microsoft.com/en-us/library/windows/desktop/aa365779(v=vs.85).aspx
		'''
		assert self.subproc is not None

		if self.subproc.stdout is not None:
			while 1:
				x = msvcrt.get_osfhandle(self.subproc.stdout.fileno())
				try:
					(read, nAvail, nMessage) = win32pipe.PeekNamedPipe(x, 0)
				except pywintypes.error, e:
					if e.winerror == winerror.ERROR_BROKEN_PIPE: break
					raise
				if nAvail > 4096: nAvail = 4096
				if nAvail == 0: break
				
				(errCode, data) = win32file.ReadFile(x, nAvail, None)
				self.log_out.write(data)


		if self.subproc.stderr is not None:
			while 1:
				x = msvcrt.get_osfhandle(self.subproc.stderr.fileno())
				try:
					(read, nAvail, nMessage) = win32pipe.PeekNamedPipe(x, 0)
				except pywintypes.error, e:
					if e.winerror == winerror.ERROR_BROKEN_PIPE: break
					raise
				if nAvail > 4096: nAvail = 4096
				if nAvail == 0: break

				(errCode, data) = win32file.ReadFile(x, nAvail, None)
				self.log_err.write(data)


	def tail(self, cnscon, stream, lines=80, tailf=False):
		if self.state == program_state_enum.CFGERROR:
			raise svrcall_error("Program {0} is not correctly configured".format(self.ident))
		if stream == 'stdout':
			return self.log_out.tail(cnscon, lines, tailf)
		elif stream == 'stderr':
			return self.log_err.tail(cnscon, lines, tailf)
		else:
			raise ValueError("Unknown stream '{0}'".format(stream))


	def tailf_stop(self, cnscon, stream):
		if stream == 'stdout':
			return self.log_out.tailf_stop(cnscon)
		elif stream == 'stderr':
			return self.log_err.tailf_stop(cnscon)
		else:
			raise ValueError("Unknown stream '{0}'".format(stream))


	def charge_coredump(self):
		if resource is None:
			L.warning("This platform doesn't support core dumps.")
			return

		l = self.ulimits.get(resource.RLIMIT_CORE, (0,0))
		if l == (0,0):
			Lmy.warning("Program {0} is not configured to dump code".format(self.ident))
			return
		self.coredump_enabled = True


	def notify_fatal_state(self, orig_state, autorestart=False):
		if self.notify_fatal_target is None: return

		svrapp = get_svrapp()
		if svrapp is None: return

		ntftext  = 'Program: {}\n'.format(self.ident)
		ntftext += 'Changed status: {} -> {}\n'.format(
			program_state_enum.labels.get(orig_state, '?'),
			program_state_enum.labels.get(self.state, '?')
		)
		if self.subproc is not None:
			ntftext += 'Pid: {}\n'.format(self.subproc.pid)
		if self.exit_status is not None:
			ntftext += 'Exit status: {}\n'.format(self.exit_status)
		if self.state == program_state_enum.FATAL:
			if autorestart:
				ntftext += 'Auto-restart: YES (count={})\n'.format(self.autorestart_cnt)
			else:
				ntftext += 'Auto-restart: NO (count={})\n'.format(self.autorestart_cnt)

		ntftext += '\nStandard output:\n'+'-'*50+'\n'
		log = []
		for i, line in enumerate(reversed(self.log_out.tailbuf)):
			if i > 20: break
			log.insert(0, line)
		ntftext += ''.join(log)
		ntftext += '\n'+'-'*50+'\n'

		if  self.log_err != self.log_out:
			ntftext += '\nStandard error:\n'+'-'*50+'\n'
			log = []
			for i, line in enumerate(reversed(self.log_err.tailbuf)):
				if i > 20: break
				log.insert(0, line)
			ntftext += ''.join(log)
			ntftext += '\n'+'-'*50+'\n'

		svrapp.notificator.publish(self.notify_fatal_target, ntftext, "{} / {}".format(self.ident, program_state_enum.labels.get(self.state, '?')))


def validate_notify_target(target):
	x = target.split(':',1)
	if len(x) == 1:
		if target not in ('now', 'daily'): return False
	elif len(x) == 2:
		target, email = x
		if target not in ('now', 'daily'): return False
	else:
		return False

	return True


########NEW FILE########
__FILENAME__ = seqctrl

class sequence_controller(object):
	'''
Start/Stop program sequence controller.
It is implementation of "SELECT * FROM programs GROUP BY priority" with a little bit of logic on top of that
	'''

	def __init__(self, cnscon = None):
		'''
		@param cnscon: Eventual console connection.
		'''
		super(sequence_controller, self).__init__()
		self.sequence = {}
		self.active = None
		self.cnscon = cnscon


	def __del__(self):
		if self.cnscon is not None:
			self.cnscon.send_exception(RuntimeError('Start/stop sequence terminated prematurely'))
			self.cnscon = None


	def add(self, program):
		sq = self.sequence.get(program.priority)
		if sq is None:
			self.sequence[program.priority] = sq = list()

		sq.append(program)


	def next(self):
		assert self.active is None
		try:
			maxk=max(self.sequence.iterkeys())
		except ValueError:
			# We are at the end of the launch sequence
			return None
		self.active = self.sequence.pop(maxk)
		return self.active[:] # Return copy (it is safer)


	def check(self, src_state, trg_state):
		'''
		@param state: target state for active set
		@return: 
			True if active set is 'ready to advance' (all in given 'state') to next program set
			False if not
			None if active set launch failed (and launchpad sequence is wasted)
		'''
		if self.active is None: return True

		res = True
		for a in self.active:
			if a.state == src_state: res = False
			elif a.state == trg_state: pass
			else: return None

		if res:self.active = None
		return res

########NEW FILE########
__FILENAME__ = singleton
import weakref

#

class server_app_singleton(object):
	'''
	Providing server application singleton construct and 
	more importantly also server_app_singleton.instance weak reference (that points to top level application object)
	'''

	instance = None

	def __init__(self):
		assert server_app_singleton.instance is None
		server_app_singleton.instance = weakref.ref(self)

	def __del__(self):
		server_app_singleton.instance = None


def get_svrapp():
	if server_app_singleton.instance is None: return None
	return server_app_singleton.instance()

########NEW FILE########
__FILENAME__ = svrapp
import sys, os, socket, signal, errno, weakref, logging, argparse, itertools, time, json
import pyev
from .. import cnscom, socketuri, version as ramona_version
from ..config import config, read_config, config_files, config_includes, get_numeric_loglevel, get_logconfig
from ..cnscom import program_state_enum, svrcall_error
from ..utils import rotate_logfiles
from .cnscon import console_connection, message_yield_loghandler, deffered_return
from .proaster import program_roaster
from .idlework import idlework_appmixin
from .singleton import server_app_singleton
from .notify import notificator

from . import call_status

###

L = logging.getLogger("server")

###

class server_app(program_roaster, idlework_appmixin, server_app_singleton):

	STOPSIGNALS = [signal.SIGINT, signal.SIGTERM]
	NONBLOCKING = frozenset([errno.EAGAIN, errno.EWOULDBLOCK])

	def __init__(self):
		server_app_singleton.__init__(self)

		# Create own process group
		if os.name == 'posix':
			try:
				os.setpgrp()
			except:
				#When launched from upstart, following command will fail
				pass

		# Parse command line arguments
		parser = argparse.ArgumentParser()
		parser.add_argument('-S','--server-only', action='store_true', help='Start only server, programs are not launched')
		parser.add_argument('program', nargs='*', help='Optionally specify program(s) in scope of the command (if nothing is specified, all enabled programs will be launched)')

		# This is to support debuging of pythonservice.exe on Windows
		if sys.platform == 'win32':
			parser.add_argument('-debug', action='store', help=argparse.SUPPRESS)

		self.args = parser.parse_args()

		# Read configuration
		read_config()

		# Configure logging
		loglvl = get_numeric_loglevel(config.get('ramona:server','loglevel'))
		logging.basicConfig(
			level=loglvl,
			stream=sys.stderr,
			format="%(asctime)s %(levelname)s: %(message)s",
			)
		L.info("Ramona server started")
		L.debug("Configuration loaded from: {0}".format(', '.join(itertools.chain(config_files,config_includes))))

		# Prepare message yield logger
		my_logger = logging.getLogger('my')
		my_logger.setLevel(logging.DEBUG) 
		my_logger.addHandler(message_yield_loghandler(self))
		my_logger.propagate = False

		# Open console communication sockets (listen mode)
		self.cnssockets = []
		consoleuri = config.get("ramona:server", "consoleuri")
		for cnsuri in consoleuri.split(','):
			socket_factory = socketuri.socket_uri(cnsuri)
			
			# Special casing for UNIX domain socket 
			# There can be abandoned/stalled file entry - we need to find out if this is the case ...
			# (see http://stackoverflow.com/questions/7405932/how-to-know-whether-any-process-is-bound-to-a-unix-domain-socket)
			if socket_factory.protocol == 'unix':
				# Try to connect ...
				if os.path.exists(socket_factory.uri.path):
					try:
						s = socket_factory.create_socket_connect()
					except socket.error, e:
						if e.errno == errno.ECONNREFUSED:
							L.debug("Removing stalled UNIX socket '{0}'".format(socket_factory.uri.path))
							os.unlink(socket_factory.uri.path)
					else:
						s.close()
						L.fatal("It looks like that server is already running, there is active UNIX socket '{0}'".format(socket_factory.uri.path))
						sys.exit(1)

			try:
				socks = socket_factory.create_socket_listen()
			except socket.error, e:
				L.fatal("It looks like that server is already running: {0}".format(e))
				sys.exit(1)
			self.cnssockets.extend(socks)
		if len(self.cnssockets) == 0:
			L.fatal("There is no console socket configured - considering this as fatal error")
			sys.exit(1)

		self.loop = pyev.default_loop()
		self.watchers = [pyev.Signal(sig, self.loop, self.__terminal_signal_cb) for sig in self.STOPSIGNALS]
		self.watchers.append(pyev.Signal(signal.SIGHUP, self.loop, self.__restart_signal_cb))
		self.watchers.append(pyev.Periodic(0, 1.0, self.loop, self.__tick_cb))

		if sys.platform == 'win32':
			# There is no pyev.Child watcher on Windows; periodic check is used instead
			self.watchers.append(pyev.Periodic(0, 0.5, self.loop, self.__check_childs_cb))
		else:
			self.watchers.append(pyev.Child(0, False, self.loop, self.__child_signal_cb))


		for sock in self.cnssockets:
			sock.setblocking(0)
			# Watcher data are used (instead logical watcher.fd due to Win32 mismatch)
			self.watchers.append(pyev.Io(sock._sock, pyev.EV_READ, self.loop, self.__accept_cb, data=sock._sock.fileno()))

		self.conns = weakref.WeakSet()
		self.termstatus =  None
		self.termstatus_change = None

		# Prepare also exit watcher - can be used to 'simulate' terminal signal (useful on Win32)
		self.exitwatcher = pyev.Async(self.loop, self.__terminal_signal_cb)
		self.exitwatcher.start()

		program_roaster.__init__(self)
		idlework_appmixin.__init__(self)

		# Build notificator component
		self.notificator = notificator(self)

		# Reopen stdout and stderr - if pointing to log file, this includes also log rotate check
		self.__rotate_stdout_stderr()


	def run(self):
		for sock in self.cnssockets:
			sock.listen(socket.SOMAXCONN)
		for watcher in self.watchers:
			watcher.start()

		# Create pid file
		pidfile = config.get('ramona:server','pidfile')
		if pidfile !='':
			pidfile = os.path.expandvars(pidfile)
			try:
				open(pidfile,'w').write("{0}\n".format(os.getpid()))
			except Exception, e:
				L.critical("Cannot create pidfile: {0}".format(e)) 
				del self.cnssockets # Make sure that socket is explicitly closed (and eventual UNIX socket file deleted)
				sys.exit(1)

		# Launch start sequence
		if not self.args.server_only:
			self.start_program(pfilter=self.args.program if len(self.args.program) > 0 else None)

		# Start heartbeat loop
		try:
			self.loop.start()
		finally:
			# Close connections
			for conn in self.conns:
				conn.close()

			# Finalize idle work queue
			self.stop_idlework()

			# Go thru final tick at notificator (this will ensure final persistance of a stash)
			self.notificator.on_tick(time.time())

			# Finally remove pid file
			if pidfile !='':
				try:
					os.unlink(pidfile)
				except Exception, e:
					L.error("Cannot remove pidfile: {0}".format(e))
					while len(self.cnssockets) > 0:
						sock = self.cnssockets.pop()
						sock.close()
						del sock # Make sure that socket is explicitly closed (and eventual UNIX socket file deleted)
					sys.exit(1)

		sys.exit(0)


	def __accept_cb(self, watcher, revents):
		'''Accept incomming console connection'''
		try:
			# Fist find relevant socket
			sock = None
			for s in self.cnssockets:
				if s.fileno() == watcher.data:
					sock = s
					break

			if sock is None:
				L.warning("Received accept request on unknown socket {0}".format(watcher.fd))
				return

			# Accept all connection that are pending in listen backlog
			while True:
				try:
					clisock, address = sock.accept()
				except socket.error as err:
					if err.args[0] in self.NONBLOCKING:
						break
					else:
						raise
				else:
					if self.termstatus is not None: clisock.close() # Do not accept new connection when exiting
					if sys.platform != 'win32' and clisock.family==socket.AF_UNIX and address=='': address = clisock.getsockname()
					conn = console_connection(clisock, address, self)
					self.conns.add(conn)

		except:
			L.exception("Exception during server socket accept:")


	def __terminal_signal_cb(self, watcher, _revents):
		if hasattr(watcher, 'signum'):
			if watcher.signum == signal.SIGINT:
				# Print ENTER when Ctrl-C is pressed
				print

		if self.termstatus is None:
			if hasattr(watcher, 'signum'):
				L.info("Exit request received (by signal {0})".format(watcher.signum))
			else:
				L.info("Exit request received")
			self.__init_soft_exit()
			return

		else:
			self.__init_real_exit()
			return


	def __check_childs_cb(self, watcher, _revents):
		'''This is alternative way of detecting subprocess exit - used on Windows'''
		extra_tick = False
		for p in self.roaster:
			if p.subproc is None: continue
			ret = p.subproc.poll()
			if ret != None:
				self.on_terminate_program(p.subproc.pid, ret)
				extra_tick = True

			if p.subproc is not None:
				p.win32_read_stdfd()	


		if extra_tick:
			self.add_idlework(self.on_tick)



	def __child_signal_cb(self, watcher, _revents):
		try:
			self.on_terminate_program(watcher.rpid, watcher.rstatus)
			self.add_idlework(self.on_tick) # Schedule extra periodic check 
		except:
			L.exception("Exception during SIGCHLD callback")


	def __tick_cb(self, watcher, revents):
		try:
			self.on_tick()
		except:
			L.exception("Exception during periodic internal check")


	def stop_loop(self):
		'''
		Stop internal loop and exit.
		'''
		self.loop.stop(pyev.EVBREAK_ALL)
		for sock in self.cnssockets:
			sock.close()
		while self.watchers:
			self.watchers.pop().stop()


	def dispatch_svrcall(self, cnscon, callid, params):
		if self.termstatus is not None:
			raise cnscom.svrcall_error('Ramona server is exiting - no further commands will be accepted')
			
		if callid == cnscom.callid_init:
			return json.dumps({"version": ramona_version})
			
		elif callid == cnscom.callid_start:
			kwargs = cnscom.parse_json_kwargs(params)
			immediate = kwargs.pop('immediate', False)
			if immediate:
				return self.start_program(cnscon=None, **kwargs)
			else:
				cnscon.yield_enabled=True
				self.start_program(cnscon=cnscon, **kwargs)
				return deffered_return


		elif callid == cnscom.callid_stop:
			kwargs = cnscom.parse_json_kwargs(params)
			immediate = kwargs.pop('immediate', False)
			mode = kwargs.pop('mode',None)

			if mode is None or mode == 'stay':
				self.add_idlework(self.on_tick) # Schedule extra periodic check (to provide swift server background response to to user action)
				if immediate:
					return self.stop_program(cnscon=None, **kwargs)
				else:
					cnscon.yield_enabled=True
					self.stop_program(cnscon=cnscon, **kwargs)
					return deffered_return

			elif mode == 'exit':
				if immediate:
					return self.__init_soft_exit(cnscon=None, **kwargs)
				else:
					cnscon.yield_enabled=True
					self.__init_soft_exit(cnscon=cnscon, **kwargs)
					return deffered_return

			else:
				L.warning("Unknown exit mode issued: {0}".format(mode))

		elif callid == cnscom.callid_restart:
			self.add_idlework(self.on_tick) # Schedule extra periodic check (to provide swift server background response to to user action)
			kwargs = cnscom.parse_json_kwargs(params)
			immediate = kwargs.pop('immediate', False)
			if immediate:
				return self.restart_program(cnscon=None, **kwargs)
			else:
				cnscon.yield_enabled=True
				self.restart_program(cnscon=cnscon, **kwargs)
				return deffered_return

		elif callid == cnscom.callid_status:
			return call_status.main(self, **cnscom.parse_json_kwargs(params))

		elif callid == cnscom.callid_ping:
			return params

		elif callid == cnscom.callid_tail:
			kwargs = cnscom.parse_json_kwargs(params)
			program = kwargs.pop('program')
			try:
				program = self.get_program(program)
			except KeyError, e:
				raise svrcall_error("{0}".format(e.message))
			
			return program.tail(cnscon, **kwargs)

		elif callid == cnscom.callid_tailf_stop:
			kwargs = cnscom.parse_json_kwargs(params)
			program = kwargs.pop('program')
			try:
				program = self.get_program(program)
			except KeyError, e:
				raise svrcall_error("{0}".format(e.message))
			
			return program.tailf_stop(cnscon, **kwargs)

		elif callid == cnscom.callid_who:
			ret = []
			for c in self.conns:
				ret.append({
					"me": cnscon == c,
					"descr": c.descr,
					"address": c.address,
					"connected_at": c.connected_at
				})
			return json.dumps(ret)


		elif callid == cnscom.callid_notify:
			kwargs = cnscom.parse_json_kwargs(params)
			t = kwargs['text']
			if len(t) > 0:
				self.notificator.publish(kwargs['target'], t, kwargs['subject'])
			else:
				self.notificator.send_daily(None, None)
			return "OK"

		else:
			L.error("Received unknown callid: {0}".format(callid))


	def on_tick(self):
		now = time.time()
		program_roaster.on_tick(self, now)

		# If termination status take too long - do hard kill
		if self.termstatus_change is not None:
			if (now - self.termstatus_change) > 5:
				if self.termstatus != 3:
					self.__init_real_exit()
				else:
					L.fatal("It looks like server shutdown is taking way too much time - taking nasty exit")
					os._exit(10) 

		if (self.termstatus == 1) and (self.stop_seq is None):
			# Special care for server terminating condition 
			not_running_states=frozenset([program_state_enum.STOPPED, program_state_enum.FATAL, program_state_enum.CFGERROR, program_state_enum.DISABLED])
			ready_to_stop = True
			for p in self.roaster: # Seek for running programs
				if p.state not in not_running_states:
					ready_to_stop = False
					break

			if ready_to_stop: # Happy-flow (stop sequence finished and there is no program running - we can stop looping and exit)
				for p in self.roaster:
					if p.state in (program_state_enum.FATAL, program_state_enum.CFGERROR):
						L.warning("Process in error condition during exit: {0}".format(p))

				self.__init_soft2_exit(self)
			else:
				L.warning("Restarting stop sequence due to exit request.")
				self.stop_program(force=True)

		if (self.termstatus == 2):
			self.__close_idle_conns()
			if len(self.conns) == 0:
				self.__init_real_exit()

		#Ensure stash persistence
		self.notificator.on_tick(now)

		#Evaluate if Ramona log needs to be rotated
		self.__rotate_stdout_stderr()


	def __init_soft_exit(self, cnscon=None, **kwargs):
		if self.termstatus > 1: return

		self.termstatus =  1
		self.termstatus_change = time.time()
		self.stop_program(cnscon=cnscon, force=True, **kwargs)
		self.add_idlework(self.on_tick) # Schedule extra periodic check 


	def __init_soft2_exit(self, cnscon=None):
		'''Term status 2: Clean idling console connections and wait for others console connections to close'''
		if self.termstatus > 2: return
		if self.termstatus == 1: self.__close_idle_conns()
		self.termstatus = 2
		self.termstatus_change = time.time()


	def __init_real_exit(self):
		self.termstatus = 3
		self.termstatus_change = time.time()
		self.stop_loop()


	def __close_idle_conns(self):
		for conn in list(self.conns):
			if conn.write_buf is None \
			   and len(conn.read_buf) == 0 \
			   and conn.yield_enabled is False \
			   and conn.return_expected is False:
				conn.close()


	def __rotate_stdout_stderr(self):
		'''
		Conditionally check if we need to rotate log file of Ramona server
		'''

		logfile = os.environ.get('RAMONA_LOGFILE')
		if logfile is None: return # There is no file to rotate ...

		logfstat = os.fstat(sys.stderr.fileno())
		logbackups, logmaxsize, logcompress = get_logconfig()

		if logfstat.st_size < logmaxsize:
			# Not rotating ...
			return

		try:
			rotate_logfiles(self, logfile, logbackups, logcompress)
		finally:
			# Reopen log file and attach that to stdout and stderr
			w = os.open(logfile, os.O_WRONLY | os.O_APPEND |os.O_CREAT)
			os.dup2(w, 1)
			os.dup2(w, 2)
			os.close(w)


	def __restart_signal_cb(self, watcher, _revents):
		return self.restart_program(cnscon=None, force=True)

########NEW FILE########
__FILENAME__ = __main__
'''
This code is stub/kickstarted for ramona server application 
'''

# This code can be used to enable remote debugging in PyDev
#Add pydevd to the PYTHONPATH (may be skipped if that path is already added in the PyDev configurations)
#import sys;sys.path.append(r'/opt/eclipse4.2/plugins/org.python.pydev_2.6.0.2012062818/pysrc')
#import sys;sys.path.append(r'/Applications/eclipse/plugins/org.python.pydev.debug_2.5.0.2012040618/pysrc') # Alex Macbook
#import pydevd
#pydevd.settrace()

###

if __name__ == "__main__":
	from .svrapp import server_app
	svrapp = server_app()
	svrapp.run()

########NEW FILE########
__FILENAME__ = __utest__
import unittest
from .seqctrl import sequence_controller
from ..cnscom import program_state_enum
from .logmed import log_mediator
###
'''
To launch unit test:
python -m unittest -v ramona.server.__utest__
'''
###

class TestSequenceController(unittest.TestCase):


	class _dummy_program(object):

		def __init__(self, ident, prio):
			self.ident = ident
			self.priority = prio
			self.state = program_state_enum.STOPPED


	def test_HappyFlow(self):
		sc = sequence_controller()

		# Build launchpad sequence
		sc.add(self._dummy_program('a',9))
		sc.add(self._dummy_program('b',8))
		sc.add(self._dummy_program('c',9))
		sc.add(self._dummy_program('d',8))
		sc.add(self._dummy_program('e',9))
		sc.add(self._dummy_program('f',6))

		# Get first set
		actps = sc.next()
		pset = set(p.ident for p in actps)
		self.assertSetEqual(pset,{'a','c','e'})

		# Cannot continue to next one till got response
		self.assertRaises(AssertionError, sc.next)

		# Simulate start of active set and check that
		for p in actps: p.state = program_state_enum.STARTING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertFalse(r)
		self.assertRaises(AssertionError, sc.next)

		# Simulate sequential start of programs
		actps[0].state = program_state_enum.RUNNING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertFalse(r)
		self.assertRaises(AssertionError, sc.next)

		actps[1].state = program_state_enum.RUNNING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertFalse(r)
		self.assertRaises(AssertionError, sc.next)

		actps[2].state = program_state_enum.RUNNING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertTrue(r)

		# Now advancing to the next set
		actps = sc.next()
		pset = set(p.ident for p in actps)
		self.assertSetEqual(pset,{'b','d'})

		# Simulate sequential start of programs
		actps[0].state = program_state_enum.RUNNING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertFalse(r)
		self.assertRaises(AssertionError, sc.next)

		actps[1].state = program_state_enum.RUNNING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertTrue(r)

		# Third step
		actps = sc.next()
		pset = set(p.ident for p in actps)
		self.assertSetEqual(pset,{'f'})

		actps[0].state = program_state_enum.RUNNING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertTrue(r)

		actps = sc.next()
		self.assertIsNone(actps)


	def test_LaunchFailure(self):
		sc = sequence_controller()

		# Build launchpad sequence
		sc.add(self._dummy_program('a',9))
		sc.add(self._dummy_program('b',8))
		sc.add(self._dummy_program('c',9))

		# Get first set
		actps = sc.next()
		pset = set(p.ident for p in actps)
		self.assertSetEqual(pset,{'a','c'})

		# Simulate start of active set and check that
		for p in actps: p.state = program_state_enum.STARTING
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)
		self.assertFalse(r)
		self.assertRaises(AssertionError, sc.next)

		# Simulate sequential start of programs
		actps[0].state = program_state_enum.FATAL
		r = sc.check(program_state_enum.STARTING, program_state_enum.RUNNING)

		self.assertIsNone(r)

#

class TestLogMediator(unittest.TestCase):


	def test_LogMediatorBasic(self):
		'Constructing log mediator'

		lm = log_mediator('foo_prog', 'stdout', None)
		lm.open()
		lm.write('Line1\n')
		lm.write('Line2\n')
		lm.write('Line3\n')
		lm.close()


	def test_LogMediatorLineTail(self):
		'Log mediator line separator'

		lm = log_mediator('foo_prog', 'stdout', None)
		lm.open()

		lm.write('Line')
		self.assertItemsEqual(lm.tailbuf, ['Line'])
		lm.write(' One')
		self.assertItemsEqual(lm.tailbuf, ['Line One'])
		lm.write('\n')
		self.assertItemsEqual(lm.tailbuf, ['Line One\n'])

		lm.write('Line 2\n')
		self.assertItemsEqual(lm.tailbuf, [
			'Line One\n',
			'Line 2\n',
		])

		lm.write('3Line')
		self.assertEqual(lm.tailbuf[-1], '3Line')
		lm.write(' 3')
		self.assertEqual(lm.tailbuf[-1], '3Line 3')
		lm.write('\n')
		self.assertItemsEqual(lm.tailbuf, [
			'Line One\n',
			'Line 2\n',
			'3Line 3\n',
		])

		lm.write('Line 4\nLine 5\nLine 6\n')
		self.assertItemsEqual(lm.tailbuf, [
			'Line One\n',
			'Line 2\n',
			'3Line 3\n',
			'Line 4\n',
			'Line 5\n',
			'Line 6\n',
		])

		lm.write('Line 7\nLine 8\nLine 9')

		self.assertItemsEqual(lm.tailbuf, [
			'Line One\n',
			'Line 2\n',
			'3Line 3\n',
			'Line 4\n',
			'Line 5\n',
			'Line 6\n',
			'Line 7\n',
			'Line 8\n',
			'Line 9',
		])

		lm.close()


	def test_LogMediatorLongLineTail(self):
		'Log mediator line separator (long lines)'

		lm = log_mediator('foo_prog', 'stdout', None)
		lm.open()

		lm.write('Line 1\n')
		self.assertItemsEqual(lm.tailbuf, ['Line 1\n'])

		lm.write('X'*60000)
		self.assertEqual(len(lm.tailbuf), 3)
		self.assertEqual(lm.tailbuf[1], 'X' * 32512)
		self.assertEqual(lm.tailbuf[2], 'X' * 27488)

		lm.write('X'*60000)
		self.assertEqual(len(lm.tailbuf), 5)
		self.assertEqual(lm.tailbuf[1], 'X' * 32512)
		self.assertEqual(lm.tailbuf[2], 'X' * 32512)
		self.assertEqual(lm.tailbuf[3], 'X' * 32512)
		self.assertEqual(lm.tailbuf[4], 'X' * 22464)

		lm.write('X\n')
		self.assertEqual(len(lm.tailbuf), 5)
		self.assertEqual(lm.tailbuf[4], 'X' * 22465 + '\n')

		lm.close()

########NEW FILE########
__FILENAME__ = socketuri
import os, sys, socket, urlparse

###

class socket_uri(object):
	'''
	Socket factory that is configured using socket URI.
	This is actually quite generic implementation - not specific to console-server IPC communication.
	'''

	# Configure urlparse
	if 'unix' not in urlparse.uses_query: urlparse.uses_query.append('unix')
	if 'tcp' not in urlparse.uses_query: urlparse.uses_query.append('tcp')

	def __init__(self, uri):
		self.uri = urlparse.urlparse(uri.strip())
		self.uriquery = dict(urlparse.parse_qsl(self.uri.query))

		self.protocol = self.uri.scheme.lower()
		if self.protocol == 'tcp':
			try:
				_port = int(self.uri.port)
			except ValueError:
				raise RuntimeError("Invalid port number in socket URI {0}".format(uri))

			if self.uri.path != '': raise RuntimeError("Path has to be empty in socket URI {0}".format(uri))

		elif self.protocol == 'unix':
			if sys.platform == 'win32':
				os.error("UNIX sockets are not supported on this plaform")
				raise RuntimeError("UNIX sockets are not supported on this plaform ({0})".format(uri))
			if self.uri.netloc != '':
				# Special case of situation when netloc is not empty (path is relative)
				self.uri = self.uri._replace(netloc='', path=self.uri.netloc + self.uri.path)

		else:
			raise RuntimeError("Unknown/unsupported protocol '{0}' in socket URI {1}".format(self.protocol, uri))


	def create_socket_listen(self):
		'''Return list of socket created in listen mode.
		The trick here is that for single host/port combinations, multiple listen socket can be created (e.g. IPv4 vs IPv6)
		'''
		retsocks = []

		if self.protocol == 'tcp':
			for family, socktype, proto, canonname, sockaddr in socket.getaddrinfo(self.uri.hostname, self.uri.port, 0, socket.SOCK_STREAM):
				s = socket.socket(family, socktype, proto)
				s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
				s.bind(sockaddr)
				retsocks.append(s)

		elif self.protocol == 'unix':
			mode = self.uriquery.get('mode',None)
			if mode is None: mode = 0o600
			else: mode = int(mode,8)
			oldmask = os.umask(mode ^ 0o777)
			s = _deleteing_unix_socket()
			s.bind(self.uri.path)
			os.umask(oldmask)

			retsocks.append(s)

		else:
			raise RuntimeError("Unknown/unsupported protocol '{0}'".format(self.protocol))

		return retsocks


	def create_socket_connect(self):
		if self.protocol == 'tcp':
			last_error = None
			for family, socktype, proto, canonname, sockaddr in socket.getaddrinfo(self.uri.hostname, self.uri.port, 0, socket.SOCK_STREAM):
				try:
					s = socket.socket(family, socktype, proto)
					s.connect(sockaddr)
					return s
				except Exception, e:
					last_error = e
					continue

			# Raise last error from eventual sequence ...
			if last_error is not None: raise last_error
			raise RuntimeError("Unexpected error condition during server connect.")

		elif self.protocol == 'unix':
			s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
			s.connect(self.uri.path)
			return s

		else:
			raise RuntimeError("Unknown/unsuported protocol '{0}'".format(self.protocol))

###

class _deleteing_unix_socket(socket.socket):
	'''
This class is used as wrapper to socket object that represent listening UNIX socket.
It added ability to delete socket file when destroyed.

It is basically used only on server side of UNIX socket.
	'''

	def __init__(self):
		socket.socket.__init__(self, socket.AF_UNIX, socket.SOCK_STREAM)
		self.__sockfile = None


	def __del__(self):
		self.__delsockfile()


	def close(self):
		socket.socket.close(self)
		self.__delsockfile()


	def bind(self, fname):
		socket.socket.bind(self, fname)
		self.__sockfile = fname


	def __delsockfile(self):
		if self.__sockfile is not None:
			fname = self.__sockfile
			self.__sockfile = None
			os.unlink(fname)
			assert not os.path.isfile(fname)


########NEW FILE########
__FILENAME__ = utils
import os, sys, re, signal, logging, itertools, glob, gzip
try:
	import resource
except ImportError:
	resource = None

###

L = logging.getLogger("utils")

###

def launch_server(server_only=True, programs=None, logfname=None):
	'''
This function launches Ramona server - in 'os.exec' manner which means that this function will not return
and instead of that, current process will be replaced by launched server. 

All file descriptors above 2 are closed.
	'''
	if server_only: assert (programs is None or len(programs) == 0)

	# Prepare environment variable RAMONA_CONFIG and RAMONA_CONFIG_FULL
	from .config import config_files, config_includes
	os.environ['RAMONA_CONFIG'] = os.pathsep.join(config_files)
	os.environ['RAMONA_CONFIG_WINC'] = os.pathsep.join(itertools.chain(config_files, config_includes))
	if logfname is not None: os.environ['RAMONA_LOGFILE'] = logfname

	# Prepare command line
	cmdline = ["-m", "ramona.server"]
	if server_only: cmdline.append('-S')
	elif programs is not None: cmdline.extend(programs)

	# Launch
	if sys.platform == 'win32':
		# Windows specific code, os.exec* process replacement is not possible, so we try to mimic that
		import subprocess
		ret = subprocess.call(get_python_exec(cmdline))
		sys.exit(ret)

	else:
		close_fds()
		pythonexec = get_python_exec()
		os.execl(pythonexec, os.path.basename(pythonexec), *cmdline)

#

def launch_server_daemonized():
	"""
This function launches Ramona server as a UNIX daemon.
It detaches the process context from parent (caller) and session.
This functions does return, launch_server() function doesn't due to exec() function in it.
	"""
	from .config import config

	logfname = config.get('ramona:server','log')
	if logfname.find('<logdir>') == 0:
		lastfname = logfname[8:].strip().lstrip('/')
		if len(lastfname) == 0: lastfname = 'ramona.log'
		logfname = os.path.join(config.get('general','logdir'), lastfname)
	elif logfname[:1] == '<':
		L.error("Unknown log option in [server] section - server not started")
		return

	try:
		logf = open(logfname, 'a')
	except IOError, e:
		L.fatal("Cannot open logfile {0} for writing: {1}. Check the configuration in [server] section. Exiting.".format(logfname, e))
		return

	with logf:
		pid = os.fork()
		if pid > 0:
			return pid

		os.setsid()

		pid = os.fork()
		if pid > 0:
			os._exit(0)

		stdin = os.open(os.devnull, os.O_RDONLY)
		os.dup2(stdin, 0)

		os.dup2(logf.fileno(), 1) # Prepare stdout
		os.dup2(logf.fileno(), 2) # Prepare stderr

	launch_server(logfname=logfname)

###

def parse_signals(signals):
	ret = []
	signame2signum = dict((name, num) for name, num in signal.__dict__.iteritems() if name.startswith('SIG') and not name.startswith('SIG_'))
	for signame in signals.split(','):
		signame = signame.strip().upper()
		if not signame.startswith('SIG'): signame = 'SIG'+signame
		signum = signame2signum.get(signame)
		if signum is None: raise RuntimeError("Unknown signal '{0}'".format(signame))
		ret.append(signum)
	return ret


def get_signal_name(signum):
	sigdict = dict((num, name) for name, num in signal.__dict__.iteritems() if name.startswith('SIG') and not name.startswith('SIG_'))
	ret = sigdict.get(signum)
	if ret is None: ret = "SIG({})".format(str(signum))
	return ret

###

def close_fds():
	'''
	Close all open file descriptors above standard ones. 
	This prevents the child from keeping open any file descriptors inherited from the parent.

	This function is executed only if platform supports that - otherwise it does nothing.
	'''
	if resource is None: return
	
	maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
	if (maxfd == resource.RLIM_INFINITY):
		maxfd = 1024

	os.closerange(3, maxfd)

###

if os.name == 'posix':
	import fcntl

	def enable_nonblocking(fd):
		fl = fcntl.fcntl(fd, fcntl.F_GETFL)
		fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)

	def disable_nonblocking(fd):
		fl = fcntl.fcntl(fd, fcntl.F_GETFL)
		fcntl.fcntl(fd, fcntl.F_SETFL, fl ^ os.O_NONBLOCK)

elif sys.platform == 'win32':

	def enable_nonblocking(fd):
		raise NotImplementedError("utils.enable_nonblocking() not implementerd on Windows")

	def disable_nonblocking(fd):
		raise NotImplementedError("utils.disable_nonblocking() not implementerd on Windows")

###

_varprog = re.compile(r'\$(\w+|\{[^}]*\})')

def expandvars(path, env):
	"""Expand shell variables of form $var and ${var}.  Unknown variables are left unchanged.
	This is actually borrowed from os.path.expandvars (posixpath variant).
	"""

	if '$' not in path: return path
	i = 0

	while True:
        	m = _varprog.search(path, i)
        	if not m: break
        	i, j = m.span(0)
        	name = m.group(1)
		if name.startswith('{') and name.endswith('}'): name = name[1:-1]
		name=name.upper() # Use upper-case form for environment variables (e.g. Windows ${comspec})
		if name in env:
			tail = path[j:]
			path = path[:i] + env[name]
			i = len(path)
			path += tail
		else:
			i = j

	return path

###

def get_python_exec(cmdline=None):
	"""
	Return path for Python executable - similar to sys.executable but also handles corner cases on Win32

	@param cmdline: Optional command line arguments that will be added to python executable, can be None, string or list
	"""

	if sys.executable.lower().endswith('pythonservice.exe'):
		pythonexec = os.path.join(sys.exec_prefix, 'python.exe')
	else:
		pythonexec = sys.executable

	if cmdline is None: return pythonexec
	elif isinstance(cmdline, basestring): return pythonexec + ' ' + cmdline
	else: return " ".join([pythonexec] + cmdline)

###

def compress_logfile(fname):
	with open(fname, 'rb') as f_in, gzip.open('{0}.gz'.format(fname), 'wb') as f_out:
		f_out.writelines(f_in)
	os.unlink(fname)

#

_rotlognamerg = re.compile('\.([0-9]+)(\.gz)?$')

def rotate_logfiles(app, logfilename, logbackups, logcompress):
	fnames = set()
	suffixes = dict()
	for fname in glob.iglob(logfilename+'.*'):
		if not os.path.isfile(fname): continue
		x = _rotlognamerg.search(fname)
		if x is None: continue
		idx = int(x.group(1))
		suffix = x.group(2)
		if suffix is not None: 
			suffixes[idx] = suffix
		fnames.add(idx)

	for k in sorted(fnames, reverse=True):
		suffix = suffixes.get(k, "")
		if (logbackups > 0) and (k >= logbackups):
			os.unlink("{0}.{1}{2}".format(logfilename, k, suffix))
			continue
		if ((k-1) not in fnames) and (k > 1): continue # Move only files where there is one 'bellow'
		os.rename("{0}.{1}{2}".format(logfilename, k, suffix), "{0}.{1}{2}".format(logfilename, k+1, suffix))
		if logcompress and suffix != ".gz" and k+1 >= 2:
		 	app.add_idlework(compress_logfile, "{0}.{1}".format(logfilename, k+1))

	os.rename("{0}".format(logfilename), "{0}.1".format(logfilename))

########NEW FILE########
__FILENAME__ = __utest__
import unittest
import logging
from . import config
from . import sendmail
from . import utils
###
'''
To launch unit test:
python -m unittest -v ramona.__utest__
'''
###

class TestConfig(unittest.TestCase):


	def test_get_numeric_loglevel(self):
		'''Translating log level to numbers'''
		lvl = config.get_numeric_loglevel('Debug')
		self.assertEqual(lvl, logging.DEBUG)

		lvl = config.get_numeric_loglevel('ERROR')
		self.assertEqual(lvl, logging.ERROR)

		self.assertRaises(ValueError, config.get_numeric_loglevel, '')

#

class TestSendMail(unittest.TestCase):

	def test_get_default_fromaddr(self):
		sendmail.send_mail.get_default_fromaddr()


	def test_sendmail_uri_01(self):
		u = sendmail.send_mail('smtp://mail.example.com')
		self.assertEqual(u.hostname, 'mail.example.com')
		self.assertEqual(u.port, 25)
		self.assertIsNone(u.username)
		self.assertIsNone(u.password)
		self.assertDictEqual(u.params, {})


	def test_sendmail_uri_02(self):
		self.assertRaises(RuntimeError, sendmail.send_mail, 'xsmtp://smtp.t-email.cz')


	def test_sendmail_uri_03(self):
		self.assertRaises(RuntimeError, sendmail.send_mail, 'xsmtp:///dd')


	def test_sendmail_uri_04(self):
		'''Simulating Google SMTP parametrization'''
		u = sendmail.send_mail('smtp://user:password@smtp.gmail.com:587?tls=1')
		self.assertEqual(u.hostname, 'smtp.gmail.com')
		self.assertEqual(u.port, 587)
		self.assertEqual(u.username, 'user')
		self.assertEqual(u.password, 'password')
		self.assertDictEqual(u.params, {'tls':'1'})

#

class TestExpandVars(unittest.TestCase):

	def test_expandvars_01(self):
		env = {'FOO':'bar'}
		
		p = utils.expandvars('/testing/$FOO/there', env)
		self.assertEqual(p, '/testing/bar/there')

		p = utils.expandvars('$FOO/there', env)
		self.assertEqual(p, 'bar/there')

		p = utils.expandvars('/testing/$FOO', env)
		self.assertEqual(p, '/testing/bar')


	def test_expandvars_02(self):
		env = {'FOO':'bar'}
		
		p = utils.expandvars('$XXX/testing/$FOO/there', env)
		self.assertEqual(p, '$XXX/testing/bar/there')

		p = utils.expandvars('$FOO/there$XXX', env)
		self.assertEqual(p, 'bar/there$XXX')

		p = utils.expandvars('/testing/$XX$FOO', env)
		self.assertEqual(p, '/testing/$XXbar')


	def test_expandvars_02(self):
		env = {'FOO':'bar'}
		
		p = utils.expandvars('$XXX/testing/${FOO}/there', env)
		self.assertEqual(p, '$XXX/testing/bar/there')

		p = utils.expandvars('${FOO}/there$XXX', env)
		self.assertEqual(p, 'bar/there$XXX')

		p = utils.expandvars('/testing/$XX${FOO}', env)
		self.assertEqual(p, '/testing/$XXbar')

########NEW FILE########
__FILENAME__ = ramona-dev
#!/usr/bin/env python
#
# Released under the BSD license. See LICENSE.txt file for details.
#
import os
import sys
import fnmatch
import shutil
import ramona

class RamonaDevConsoleApp(ramona.console_app):

	@ramona.tool
	def clean(self):
		"""Clean project directory from intermediate files (*.pyc)"""
		for root, dirnames, filenames in os.walk('.'):
			for filename in fnmatch.filter(filenames, '*.pyc'):
				filename = os.path.join(root, filename)
				if not os.path.isfile(filename): continue
				os.unlink(filename)

		try:
			shutil.rmtree('dist')
		except:
			pass

		try:
			shutil.rmtree('build')
		except:
			pass

		for f in ['MANIFEST', 'demo_history', 'ramonadev_history']:
			try:
				os.unlink(f)
			except:
				pass


	@ramona.tool
	def unittests(self):
		"""Seek for all unit tests and execute them"""
		import unittest
		tl = unittest.TestLoader()
		ts = tl.discover('.', '__utest__.py')

		tr = unittest.runner.TextTestRunner(verbosity=2)
		res = tr.run(ts)

		return 0 if res.wasSuccessful() else 1

	@ramona.tool
	def sdist(self):
		"""Prepare the distribution package"""
		os.execl(sys.executable, sys.executable, 'setup.py', 'sdist', '--formats=gztar,zip', '--owner=root', '--group=root')

	@ramona.tool
	def upload_test(self):
		"""Upload (register) a new version to TestPyPi"""
		os.system("LC_ALL=en_US.UTF-8 {0} setup.py \
			sdist --formats=gztar,zip --owner=root --group=root \
			register -r http://testpypi.python.org/pypi \
			upload -r http://testpypi.python.org/pypi \
			".format(sys.executable)
		)

	@ramona.tool
	def upload(self):
		"""Upload (register) a new version to PyPi"""
		os.system("LC_ALL=en_US.UTF-8 {0} setup.py \
			sdist --formats=gztar,zip --owner=root --group=root \
			register -r http://pypi.python.org/pypi \
			upload -r http://pypi.python.org/pypi \
			".format(sys.executable)
		)

	@ramona.tool
	def version(self):
		"""Returns the Ramona version number"""
		print ramona.version

	@ramona.tool
	def manual(self):
		"""Build a HTML version of the manual"""
		if os.path.isdir('docs/manual/_build'):
			shutil.rmtree('docs/manual/_build')
		os.system('LC_ALL=en_US.UTF-8 make -C docs/manual html')

	@ramona.tool
	def gource(self):
		"""Creates visualizations about the Ramona development"""
		import subprocess, re

		cmd= r"""git log --pretty=format:user:%aN%n%ct --reverse --raw --encoding=UTF-8 --no-renames"""
		gitlog = subprocess.check_output(cmd, shell=True)

		gitlog = re.sub(r'\nuser:Ales Teska\n','\nuser:ateska\n',gitlog)
		gitlog = re.sub(r'\nuser:Jan Stastny\n','\nuser:jstastny\n',gitlog)

		cmd  = r"""gource -1280x720 --stop-at-end --highlight-users --seconds-per-day .5 --title "Ramona" --log-format git -o - -"""
		cmd += " | "
		cmd += r"ffmpeg -y -r 60 -f image2pipe -vcodec ppm -i - -vcodec libx264 -preset ultrafast -pix_fmt yuv420p -crf 16 -threads 0 -bf 0 gource.mp4"

		x = subprocess.Popen(cmd, stdin=subprocess.PIPE, shell=True)
		x.communicate(gitlog)

if __name__ == '__main__':
	app = RamonaDevConsoleApp(configuration='./ramona.conf')
	app.run()

########NEW FILE########
__FILENAME__ = test
#!/usr/bin/env python
#
# Released under the BSD license. See LICENSE.txt file for details.
#
import ramona

class TestConsoleApp(ramona.console_app):
	"""
	This application serves mostly for testing and as example.
	The programs run by this application usually fails to test
	different corner cases.
	"""
	
	pass
	
if __name__ == '__main__':
	app = TestConsoleApp(configuration='./test.conf')
	app.run()

########NEW FILE########
