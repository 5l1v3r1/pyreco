What's eating the battery life of my laptop? Why isn't it many more
hours? Which software component causes the most power to be burned?
These are important questions without a good answer... until now.

The Linux 2.6.21 kernel introduces the so called tickless-idle
feature. This feature allows the processor to be really idle for long
periods of time, rather than having to wake up every millisecond for
the timer tick. Current processors save a lot of power if they are
idle for long periods, which translates into a longer battery life for
your laptop, or a lower energy bill for your datacenter. However, a
Linux system consists of more software than just the kernel, and there
are many tunables involved. It's not easy to see what is going on, and
as a result the behavior is sometimes far from optimal, and a lot of
power is wasted.

Intel is proud to announce the PowerTOP tool
(http://www.linuxpowertop.org), a program that collects the various
pieces of information from your system and presents an overview of how
well your laptop is doing in terms of power savings. In addition,
PowerTOP will provide an indication of which tunables and software
components are the biggest offenders in slurping up your battery time.
PowerTOP will update it's display frequently so that you can directly
see the impact of any changes you are making.

A typical Linux distribution has many components that wake the
processor up frequently for no good reason. In our testing with
PowerTOP, we have seen many cases where with some simple fixes, the
battery life of typical laptops was increased by one hour or more!

We are providing fixes for several of the issues we identified, and we
encourage the Linux community to help us in this quest to get the
maximum battery life out of your (hopefully Intel based) laptops. Try
the PowerTOP tool, join the mailing list or the IRC channel and
provide feedback, problem reports or fixes!

Website:      http://www.linuxpowertop.org
IRC:          irc.oftc.net    #powertop channel
Mailing list: http://www.bughost.org/mailman/listinfo/power
Tags: intel, linux



If you have bugreports or patches, I prefer that you use the mailing list
but you can email me directly at arjan@linux.intel.com.

README
======

This directory is the holding area for storing libraries which are common
to both client and server. Libraries which are client-specific should live
in client/bin and libraries which are server-specific should live in
server.

This directory is a sub-directory of client because AutoTest doesn't install 
anything but the client directory.

Libraries in this directory should only rely on other libraries in this
directory. In other words, they should not reach out in client/bin or server.

EXAMPLES
========
This directory contains some sample configuration files for conmux.

socket.cf -- where the console is exposed directly on a tcp port on
  the local network.

command.cf -- where the console is obtained through a driver.

Details on the command line options for each driver are in the
comments at the top of the driver.

CONMUX -- Console Multiplexor
=============================
CONMUX is a console abstractor.  Presenting any console with a
consistent location, naming and semantic.  Access to the console,
and hardreset of the machine is the same regardless of the underlying
access methodology.


License
-------
See the COPYING file for details.


Installation
------------
See the INSTALL file for details.


Configuration
-------------
A console multiplexor is defined using a per instance configuration file.
The standard startup scripts expect this to be in the ROOT/etc and have
a .cf suffix.

Below is an example configuration defining the console for a NUMA-Q:

  $ cat kite.cf
  # START:autoboot
  listener kite
  socket console 'kite console' console.server.here.com:6000
    command 'hardreset' 'initated a hard reset' \
      'conmux-attach -o status localhost/kite reboot-numaq vcs \
       vcsconsole.server.here.com kite 12346 administrator passwd'
  $ 

These are connected to using the console command, using the symbolic console
name:

  $ console kite


Automatic Startup
-----------------
See the start script for automated startup of console daemons.
This script is designed to be used at system boot time out of
/etc/init.d.


Documentation and Examples
--------------------------
More detailed information on the workings of conmux can be found in
'conmux.html'.  Example configuration files can be found in the
'examples' directory.


Legal
-----
(C) Copyright IBM Corp. 2004, 2005, 2006
Author: Andy Whitcroft <andyw@uk.ibm.com>

The Console Multiplexor is released under the GNU Public License V2

About this:
-----------

This module contains extensions to `atest` that proved to be useful
when doing virtualization testing of multiple KVM versions, on multiple
operating system versions (Fedora, RHEL5, RHEL6).

It uses a simple templating mechanism, to inject extra configuration into
the server control file, that will then end up on the cartesian config
file parsing. These options can be set directly with the command line
options `--extra-cartesian-config` or indirectly with other command line
options such as `--koji-tag` and `--koji-pkg`.

Some options, such as the koji ones, will trigger local validation, that
is, errors such as specifying invalid packages will be caught right away,
and the job won't be submitted. This is to prevent a typo from triggering
a job that will fail and waste developer time.

We also included a version of our internal test config, cleaned out
to include only the publicly available upstream components.
You may copy it to qemu/cfg/site-config.cfg, on your virt-tests copy.

Instalation:
------------

1) copy (or link) the site_job.py file to <autotest_root>/cli/,
usually /usr/local/autotest/cli.

2) validate it is working by running:

  # <autotest_root>/cli/atest job create --help

The output should include the added options:

...
  -T, --template        Control file is actually a template
  -x EXTRA_CARTESIAN_CONFIG, --extra-cartesian-config=EXTRA_CARTESIAN_CONFIG
                        Add extra configuration to the cartesian config file
  --timestamp           Add a timestamp to the name of the job
  --koji-arch=KOJI_ARCH
                        Default architecture for packages that will be fetched
                        from koji build. This will be combined with
                        "noarch".This option is used to help to validate
                        packages from the job submitting machine.
  --koji-tag=KOJI_TAG   Sets a default koji tag for koji packages specified
                        with --koji-pkg
  --koji-pkg=KOJI_PKG   Packages to add to host installation based on koji
                        build. This options may be specified multiple times.


Usage Examples:
---------------

These examples actually depend on local cartersian configuration, that is,
they might not work out of the box in your autotest installation. Please
use them only as a reference and adapt the examples to your scenario:

1) To run a test of the upstream qemu git repo:

  # <autotest_root>/cli/atest job create -s -m "yourmail@yourdomain.org" \
    -f "<autotest_root>/contrib/virt/control.template" -T --timestamp \
    -x 'only qemu-git..sanity' "Upstream qemu.git sanity"

2) To run a test with specific packages built on koji:

  # <autotest_root>/cli/atest job create -s -m "yourmail@yourdomain.org" \
    -f "<autotest_root>/contrib/virt/control.template" -T --timestamp \
    --koji-tag=f15 --koji-pkg=':qemu-kvm:qemu-kvm,qemu-img,qemu-kvm-tools' \
    --koji-pkg='seabios' --koji-pkg='vgabios' --koji-pkg=':gpxe:gpxe-roms-qemu' \
    --koji-pkg=':spice-server:spice-server' \
    -x 'only f15-koji..sanity' "Fedora 15 Koji Sanity"


Contributed by (who to bug):
----------------------------
Cleber Rosa (crosa@redhat.com)
Lucas Meneghel Rodrigues (lmr@redhat.com)

<b>Ran the control file: </b>
<pre>
{{ obj.job.control_file }}
</pre>
<b>Created on:</b> {{ obj.job.created_on }}<br />
<b>Owner: </b>{{ obj.job.owner }}<br />
<b>Labels: </b>
	{% for label in obj.host.labels.all %}
		{{ label.name }}{% if not forloop.last %}, {% endif %} 
	{% endfor %}
<br />

To compile GWT clients use autotest/utils/compile_gwt_clients.py

This is a directory for the logs of autotest-scheduler and any other daemons we run.

This folder should contain the packages used by the packaging system 
(autotest client, deps, tests and profilers). 

# For installation and configuration instruction on Fedora-based systems,
# consult https://fedoraproject.org/wiki/Install_and_configure_autotest

# For creating your own package, follow these instructions:

1) Decide what autotest version/branch/commit you want to package. The following assumes you want to package the next tree, at commit 0c2ab5b5306f6ccf5b47ff8b989faa2ad412c3d6. This also assumes you building packages for the fedora-19-x86_64 target.

2) Modify the specfile and update the commit accordingly.

3) Write down the "shortcommit" also, it's just the first 7 characters of the commit hash.

4) Get a tarball out of the autotest tree. This is usually a matter of running something like:

  $ git archive next --prefix autotest-0.15.1.next.git0c2ab5b/ -o /tmp/autotest-src/autotest-0.15.1.next.git0c2ab5b.tar.gz

Please pay attention to the prefix appended to the archive and the output in a separate, empty directory.

5) Create a SRPM out of the SPEC file and tarball by running something like:

  $ mock --buildsrpm --spec autotest-framework.spec --sources=/tmp/autotest-src

6) Now save your SRPM to another location, or else, it'll be overwritten by the next mock run:

  $ cp /var/lib/mock/fedora-19-x86_64/result/autotest-framework-0.15.1.next.git0c2ab5b-1.fc19.src.rpm /tmp/

7) Now build the "binary" RPMS out of the SRPM:

  $ mock --rebuild /tmp/autotest-framework-0.15.1.next.git0c2ab5b-1.fc19.src.rpm

8) Enjoy! The RPMS should be located at: /var/lib/mock/fedora-19-x86_64/result

========================================================
Autotest: Fully automated tests under the linux platform
========================================================

Autotest is a framework for fully automated testing. It is designed primarily to
test the Linux kernel, though it is useful for many other functions such as
qualifying new hardware. It's an open-source project under the GPL and is used
and developed by a number of organizations, including Google, IBM, Red Hat, and
many others.

Autotest is composed of a number of modules that will help you to do stand alone
tests or setup a fully automated test grid, depending on what you are up to.
A non extensive list of modules is:

* Autotest client: The engine that executes the tests (dir client). Each
  autotest test is a a directory inside (client/tests) and it is represented
  by a python class that implements a minimum number of methods. The client
  is what you need if you are a single developer trying out autotest and executing
  some tests. Autotest client executes ''client side control files'', which are
  regular python programs, and leverage the API of the client.

* Autotest server: A program that copies the client to remote machines and
  controls their execution. Autotest server executes ''server side control files'',
  which are also regular python programs, but leverage a higher level API, since
  the autotest server can control test execution in multiple machines. If you
  want to perform tests slightly more complex involving more than one machine you
  might want the autotest server

* Autotest database: For test grids, we need a way to store test results, and
  that is the purpose of the database component. This DB is used by the autotest
  scheduler and the frontends to store and visualize test results.

* Autotest scheduler: For test grids, we need an utility that can schedule and
  trigger job execution in test machines, the autotest scheduler is that utility.

* Autotest web frontend: For test grids, A web app, whose backend is written in
  django (http://www.djangoproject.com/) and UI written in gwt
  (http://code.google.com/webtoolkit/), lets users to trigger jobs and visualize
  test results

* Autotest command line interface: Alternatively, users also can use the
  autotest CLI, written in python


Getting started with autotest client
------------------------------------

For the impatient:

https://github.com/autotest/autotest/wiki/ClientQuickStart


Main project page
-----------------

http://autotest.github.com/


Main project documentation source
----------------------------------

You can find plenty of information on the autotest wiki

http://github.com/autotest/autotest/wiki


Mailing list and IRC info
-------------------------

https://github.com/autotest/autotest/wiki/ContactInfo


Grabbing the latest source
--------------------------

https://github.com/autotest/autotest


Hacking and submitting patches
------------------------------

https://github.com/autotest/autotest/wiki/SubmissionChecklist


Downloading stable versions
---------------------------

https://github.com/autotest/autotest/downloads



All results will appear in this directory under the subdir

queuename-jobname

So if you ran job "fancypants" on machine "cruncher", you'd get

cruncher-fancypants/


A simple module to expose the standard sem_* functions in Linux needed for
using named semaphores. To compile, run:

python setup.py build

This will produce a namedsem.so file; put this file somewhere on your python
import path and you should be able to import it as a module called namedsem.

Before actually using this in python code, it really should be wrapped in
something like the threading.Semaphore class. The module simply exposes the raw
C functions with very little error checking.

