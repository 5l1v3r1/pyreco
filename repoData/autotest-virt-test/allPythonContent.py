__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Virt Test documentation build configuration file, created by
# sphinx-quickstart on Mon Apr 14 20:17:08 2014.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os


class DocBuildError(Exception):
    pass

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
root_path = os.path.abspath(os.path.join("..", ".."))
sys.path.insert(0, root_path)
import commands
_sphinx_apidoc = commands.getoutput('which sphinx-apidoc').strip()
_output_dir = os.path.join(root_path, 'documentation', 'source', 'api')
_api_dir = os.path.join(root_path, 'virttest')
_status, _output = commands.getstatusoutput("%s -o %s %s" % (_sphinx_apidoc, _output_dir, _api_dir))
if _status:
    raise DocBuildError("API rst auto generation failed: %s" % _output)

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Virt Test'
copyright = u'2009-2014, Virt Test Team'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.

from virttest.version import get_version

# The short X.Y version.
version = get_version()
# The full version, including alpha/beta/rc tags.
release = get_version()

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# on_rtd is whether we are on readthedocs.org, this line of code grabbed from docs.readthedocs.org
on_rtd = os.environ.get('READTHEDOCS', None) == 'True'

if not on_rtd:  # only import and set the theme if we're building docs locally
    try:
        import sphinx_rtd_theme
        html_theme = 'sphinx_rtd_theme'
        html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]
    except ImportError:
        html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'VirtTestdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #'papersize': 'letterpaper',

    # The font size ('10pt', '11pt' or '12pt').
    #'pointsize': '10pt',

    # Additional stuff for the LaTeX preamble.
    #'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
    ('index', 'VirtTest.tex', u'Virt Test Documentation',
     u'Virt Test Team', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'virttest', u'Virt Test Documentation',
     [u'Virt Test Team'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
    ('index', 'VirtTest', u'Virt Test Documentation',
     u'Virt Test Team', 'VirtTest', 'One line description of project.',
     'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {'http://docs.python.org/': None}

########NEW FILE########
__FILENAME__ = bad_test
"""
Simple bad test.

:difficulty: simple
:copyright: 2014 Red Hat Inc.
"""
from autotest.client import utils


def run(test, params, env):
    """
    Executes missing_command which, in case it's not present, should raise
    exception providing information about this failure.

    :param test: QEMU test object
    :param params: Dictionary with the test parameters
    :param env: Dictionary with test environment.
    """
    utils.run("missing_command")

########NEW FILE########
__FILENAME__ = guest_hostname
"""
Simple hostname test (on guest)

:difficulty: simple
:copyright: 2014 Red Hat Inc.
"""
import logging


def run(test, params, env):
    """
    Logs guest's hostname.
    1) get VM
    2) login to VM
    3) execute command
    4) log the output

    :param test: QEMU test object
    :param params: Dictionary with the test parameters
    :param env: Dictionary with test environment.
    """
    # 1) get VM with name defined by params "main_vm"
    vm = env.get_vm(params["main_vm"])
    # vm = env.get_all_vms()[0]    # Get list of defined vms

    # 2) login to VM
    session = vm.wait_for_login()

    # 3) execute hostname
    output = session.cmd_output("hostname")

    # 4) log the output
    logging.info("The output of 'hostname' command from guest is '%s'", output)

########NEW FILE########
__FILENAME__ = hostname
"""
Simple hostname test (on host).

Before this test please set your hostname to something meaningful.

:difficulty: simple
:copyright: 2014 Red Hat Inc.
"""
import logging
from autotest.client import utils


def run(test, params, env):
    """
    Logs the host name and exits

    :param test: QEMU test object
    :param params: Dictionary with the test parameters
    :param env: Dictionary with test environment.
    """
    result = utils.run("hostname")
    logging.info("Output of 'hostname' cmd is '%s'", result.stdout)

########NEW FILE########
__FILENAME__ = ls_disk
"""
Shows all existing disk partitions.

This test requires test-provider to be qemu.

Try this test without config, than put ls_disk.cfg into $tests/cfg/ directory
and see the difference.
Additionally you might put ls_disk_v2.cfg into $tests/cfg/ directory and
execute ls_disk_v2 test (which also uses this script!) and watch for even
bigger differences.

:difficulty: advanced
:copyright: 2014 Red Hat Inc.
"""
import logging


def run(test, params, env):
    """
    Logs guest's disk partitions

    :param test: QEMU test object
    :param params: Dictionary with the test parameters
    :param env: Dictionary with test environment.
    """
    vm = env.get_vm(params["main_vm"])
    session = vm.wait_for_login()
    output = session.cmd_output("ls /dev/[hsv]d* -1")
    logging.info("Guest disks are:\n%s", output)

    # Let's get some monitor data
    monitor = vm.monitor
    # Following two provides different output for HMP and QMP monitors
    # output = monitor.cmd("info block", debug=False)
    # output = monitor.info("block", debug=False)
    # Following command unifies the response no matter which monitor is used
    output = monitor.info_block(debug=False)
    logging.info("info block:\n%s", output)

########NEW FILE########
__FILENAME__ = service
"""
Simple service handling test

Please put the configuration file service.cfg into $tests/cfg/ directory.

:difficulty: advanced
:copyright: 2014 Red Hat Inc.
"""
import logging
import time

from autotest.client import utils
from autotest.client.shared import error
from autotest.client.shared.service import SpecificServiceManager
from virttest import remote


# error.context_aware decorator initializes context, which provides additional
# information on exceptions.
@error.context_aware
def run(test, params, env):
    """
    Logs guest's hostname.
    1) Decide whether use host/guest
    2) Check current service status
    3) Start (Stop) $service
    4) Check status of $service
    5) Stop (Start) $service
    6) Check service status

    :param test: QEMU test object
    :param params: Dictionary with the test parameters
    :param env: Dictionary with test environment.
    """
    if params.get('test_on_guest') == "yes":
        # error.context() is common method to log test steps used to verify
        # what exactly was tested.
        error.context("Using guest.", logging.info)
        vm = env.get_vm(params["main_vm"])
        session = vm.wait_for_login()
        # RemoteRunner is object, which simulates the utils.run() behavior
        # on remote consoles
        runner = remote.RemoteRunner(session=session).run
    else:
        error.context("Using host", logging.info)
        runner = utils.run

    error.context("Initialize service manager", logging.info)
    service = SpecificServiceManager(params["test_service"], runner)

    error.context("Testing service %s" % params["test_service"], logging.info)
    original_status = service.status()
    logging.info("Original status=%s", original_status)

    if original_status is True:
        service.stop()
        time.sleep(5)
        if service.status() is not False:
            logging.error("Fail to stop service")
            service.start()
            raise error.TestFail("Fail to stop service")
        service.start()
    else:
        service.start()
        time.sleep(5)
        if service.status() is not True:
            logging.error("Fail to start service")
            service.stop()
            raise error.TestFail("Fail to start service")
        service.start()
    time.sleep(5)
    if not service.status() is original_status:
        raise error.TestFail("Fail to restore original status of the %s "
                             "service" % params["test_service"])

########NEW FILE########
__FILENAME__ = template
# :difficulty: simple
# Put this file into $test_provider/tests directory and use
# ./run -t $type --tests="template" to execute it.
import logging


def run(test, params, env):
    """
    Docstring describing template.

    Detailed description of the test:

    1) Get a living VM
    2) Establish a remote session to it
    3) Run the shell command "uptime" on the session.

    :param test: Test object.
    :param params: Dictionary with test parameters.
    :param env: Test environment object.
    """
    vm = env.get_vm(params["main_vm"])
    vm.verify_alive()
    timeout = float(params.get("login_timeout", 240))
    session = vm.wait_for_login(timeout=timeout)
    uptime = session.cmd("uptime")
    logging.info("Guest uptime result is: %s", uptime)

########NEW FILE########
__FILENAME__ = boottool
#!/usr/bin/env python

'''
A boottool clone, but written in python and relying mostly on grubby[1].

[1] - http://git.fedorahosted.org/git/?p=grubby.git
'''

import os
import re
import sys
import optparse
import logging
import subprocess
import urllib
import tarfile
import tempfile
import shutil
import struct

#
# Get rid of DeprecationWarning messages on newer Python version while still
# making it run on properly on Python 2.4
#
try:
    import hashlib as md5
except ImportError:
    import md5


__all__ = ['Grubby', 'OptionParser', 'EfiVar', 'EfiToolSys',
           'EliloConf', 'find_executable', 'parse_entry']


#
# Information on default requirements and installation for grubby
#
GRUBBY_REQ_VERSION = (8, 15)
GRUBBY_TARBALL_URI = ('http://pkgs.fedoraproject.org/repo/pkgs/grubby/'
                      'grubby-8.15.tar.bz2/c53d3f4cb5d22b25d27e3ee4c7ed5b80/'
                      'grubby-8.15.tar.bz2')
GRUBBY_TARBALL_MD5 = 'c53d3f4cb5d22b25d27e3ee4c7ed5b80'
GRUBBY_DEFAULT_SYSTEM_PATH = '/sbin/grubby'
GRUBBY_DEFAULT_USER_PATH = '/tmp/grubby'

#
# All options that are first class actions
# One of them should be given on the command line
#
ACTIONS = ['bootloader-probe',
           'arch-probe',
           'add-kernel',
           'boot-once',
           'install',
           'remove-kernel',
           'info',
           'set-default',
           'default',
           'update-kernel',
           # Commands not available in the old boottool
           'grubby-version',
           'grubby-version-check',
           'grubby-install']

#
# When the command line is parsed, 'opts' gets attributes that are named
# after the command line options, but with slight changes
#
ACTIONS_OPT_METHOD_NAME = [act.replace('-', '_') for act in ACTIONS]


#
# Actions (as a opt/method name) that require a --title parameter
#
ACTIONS_REQUIRE_TITLE = ['boot_once', ]


#
# Include the logger (logging channel) name on the default logging config
#
LOGGING_FORMAT = "%(levelname)s: %(name)s: %(message)s"

#
# Default log object
#
log = logging.getLogger('boottool')


def find_header(hdr):
    """
    Find a given header in the system.
    """
    for dir in ['/usr/include', '/usr/local/include']:
        file = os.path.join(dir, hdr)
        if os.path.exists(file):
            return file
    raise ValueError('Missing header: %s' % hdr)


class EfiVar(object):

    '''
    Helper class to manipulate EFI firmware variables

    This class has no notion of the EFI firmware variables interface, that is,
    where it should read from or write to in order to create or delete EFI
    variables.

    On systems with kernel >= 2.6, that interface is a directory structure
    under /sys/firmware/efi/vars.

    On systems with kernel <= 2.4, that interface is going to be a directory
    structure under /proc/efi/vars. But be advised: this has not been tested
    yet on kernels <= 2.4.
    '''

    GUID_FMT = '16B'
    GUID_CONTENT = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

    ATTR_NON_VOLATILE = 0x0000000000000001
    ATTR_BOOTSERVICE_ACCESS = 0x0000000000000002
    ATTR_RUNTIME_ACCESS = 0x0000000000000004

    DEFAULT_ATTRIBUTES = (ATTR_NON_VOLATILE |
                          ATTR_BOOTSERVICE_ACCESS |
                          ATTR_RUNTIME_ACCESS)

    FMT = ('512H' +
           GUID_FMT +
           '1L' +
           '512H' +
           '1L' +
           '1I')

    def __init__(self, name, data, guid=None, attributes=None):
        '''
        Instantiates a new EfiVar

        :type name: string
        :param name: the name of the variable that will be created
        :type data: string
        :param data: user data that will populate the variable
        :type guid: tuple
        :param guid: content for the guid value that composes the full variable
                     name
        :param attributes: integer
        :param attributes: bitwise AND of the EFI attributes this variable will
                           have set
        '''
        self.data = data
        self.name = name

        if guid is None:
            guid = self.GUID_CONTENT
        self.guid = guid

        if attributes is None:
            attributes = self.DEFAULT_ATTRIBUTES
        self.attributes = attributes

    def get_name(self):
        '''
        Returns the variable name in a list ready for struct.pack()
        '''
        l = []
        for i in range(512):
            l.append(0)

        for i in range(len(self.name)):
            l[i] = ord(self.name[i])
        return l

    def get_data(self):
        '''
        Returns the variable data in a list ready for struct.pack()
        '''
        l = []
        for i in range(512):
            l.append(0)

        for i in range(len(self.data)):
            l[i] = ord(self.data[i])
        return l

    def get_packed(self):
        '''
        Returns the EFI variable raw data packed by struct.pack()

        This data should be written to the appropriate interface to create
        an EFI variable
        '''
        params = self.get_name()
        params += self.guid
        params.append((len(self.data) * 2) + 2)
        params += self.get_data()
        params.append(0)
        params.append(self.attributes)

        return struct.pack(self.FMT, *params)


class EfiToolSys(object):

    '''
    Interfaces with /sys/firmware/efi/vars provided by the kernel

    This interface is present on kernels >= 2.6 with CONFIG_EFI and
    CONFIG_EFI_VARS options set.
    '''

    BASE_PATH = '/sys/firmware/efi/vars'
    NEW_VAR = os.path.join(BASE_PATH, 'new_var')
    DEL_VAR = os.path.join(BASE_PATH, 'del_var')

    def __init__(self):
        if not os.path.exists(self.BASE_PATH):
            sys.exit(-1)
        self.log = logging.getLogger(self.__class__.__name__)

    def create_variable(self, name, data, guid=None, attributes=None):
        '''
        Creates a new EFI variable

        :type name: string
        :param name: the name of the variable that will be created
        :type data: string
        :param data: user data that will populate the variable
        :type guid: tuple
        :param guid: content for the guid value that composes the full variable
                     name
        :param attributes: integer
        :param attributes: bitwise AND of the EFI attributes this variable will
                           have set
        '''
        if not self.check_basic_structure():
            return False

        var = EfiVar(name, data, guid, attributes)
        f = open(self.NEW_VAR, 'w')
        f.write(var.get_packed())
        return True

    def delete_variable(self, name, data, guid=None, attributes=None):
        '''
        Delets an existing EFI variable

        :type name: string
        :param name: the name of the variable that will be deleted
        :type data: string
        :param data: user data that will populate the variable
        :type guid: tuple
        :param guid: content for the guid value that composes the full variable
                     name
        :param attributes: integer
        :param attributes: bitwise AND of the EFI attributes this variable will
                           have set
        '''
        if not self.check_basic_structure():
            return False

        var = EfiVar(name, data, guid, attributes)
        f = open(self.DEL_VAR, 'w')
        f.write(var.get_packed())
        return True

    def check_basic_structure(self):
        '''
        Checks the basic directory structure for the /sys/.../vars interface
        '''
        status = True
        if not os.path.isdir(self.BASE_PATH):
            self.log.error('Could not find the base directory interface for '
                           'EFI variables: "%s"', self.BASE_PATH)
            status = False

        if not os.path.exists(self.NEW_VAR):
            self.log.error('Could not find the file interface for creating new'
                           ' EFI variables: "%s"', self.NEW_VAR)
            status = False

        if not os.path.exists(self.DEL_VAR):
            self.log.error('Could not find the file interface for deleting '
                           'EFI variables: "%s"', self.DEL_VAR)
            status = False

        return status


class EliloConf(object):

    '''
    A simple parser for elilo configuration file

    Has simple features to add and remove global options only, as this is all
    we need. grubby takes care of manipulating the boot entries themselves.
    '''

    def __init__(self, path='/etc/elilo.conf'):
        '''
        Instantiates a new EliloConf

        :type path: string
        :param path: path to elilo.conf
        '''
        self.path = path
        self.global_options_to_add = {}
        self.global_options_to_remove = {}

        self._follow_symlink()

    def _follow_symlink(self):
        '''
        Dereference the path if it's a symlink and make it absolute

        elilo.conf usually is a symlink to the EFI boot partition, so we
        better follow it to the proper location.
        '''
        if os.path.islink(self.path):
            self.path_link = self.path
            self.path = os.path.realpath(self.path_link)

        self.path = os.path.abspath(self.path)

    def add_global_option(self, key, val=None):
        '''
        Adds a global option to the updated elilo configuration file

        :type key: string
        :param key: option name
        :type val: string or None
        :param key: option value or None for options with no values
        :return: None
        '''
        self.global_options_to_add[key] = val

    def remove_global_option(self, key, val=None):
        '''
        Removes a global option to the updated elilo configuration file

        :type key: string
        :param key: option name
        :type val: string or None
        :param key: option value or None for options with no values
        :return: None
        '''
        self.global_options_to_remove[key] = val

    def line_to_keyval(self, line):
        '''
        Transforms a text line from the configuration file into a tuple

        :type line: string
        :param line: line of text from the configuration file
        :return: a tuple with key and value
        '''
        parts = line.split('=', 1)
        key = parts[0].rstrip()
        if len(parts) == 1:
            val = None
        elif len(parts) == 2:
            val = parts[1].strip()
        return (key, val)

    def keyval_to_line(self, keyval):
        '''
        Transforms a tuple into a text line suitable for the config file

        :type keyval: tuple
        :param keyval: a tuple containing key and value
        :return: a text line suitable for the config file
        '''
        key, val = keyval
        if val is None:
            return '%s\n' % key
        else:
            return '%s=%s\n' % (key, val)

    def matches_global_option_to_remove(self, line):
        '''
        Utility method to check if option is to be removed

        :type line: string
        :param line: line of text from the configuration file
        :return: True or False
        '''
        key, val = self.line_to_keyval(line)
        if key in self.global_options_to_remove:
            return True
        else:
            return False

    def matches_global_option_to_add(self, line):
        '''
        Utility method to check if option is to be added

        :type line: string
        :param line: line of text from the configuration file
        :return: True or False
        '''
        key, val = self.line_to_keyval(line)
        if key in self.global_options_to_add:
            return True
        else:
            return False

    def get_updated_content(self):
        '''
        Returns the config file content with options to add and remove applied
        '''
        output = ''

        for key, val in self.global_options_to_add.items():
            output += self.keyval_to_line((key, val))

        eliloconf = open(self.path, 'r')
        for line in eliloconf.readlines():
            if self.matches_global_option_to_remove(line):
                continue
            if self.matches_global_option_to_add(line):
                continue
            else:
                output += line

        eliloconf.close()
        return output

    def update(self):
        '''
        Writes the updated content to the configuration file
        '''
        content = self.get_updated_content()
        eliloconf_write = open(self.path, 'w')
        eliloconf_write.write(content)
        eliloconf_write.close()


def find_executable(executable, favorite_path=None):
    '''
    Returns whether the system has a given executable

    :type executable: string
    :param executable: the name of a file that can be read and executed
    '''
    if os.path.isabs(executable):
        paths = [os.path.dirname(executable)]
        executable = os.path.basename(executable)
    else:
        paths = os.environ['PATH'].split(':')
        if favorite_path is not None and favorite_path not in paths:
            paths.insert(0, favorite_path)

    for d in paths:
        f = os.path.join(d, executable)
        if os.path.exists(f) and os.access(f, os.R_OK | os.X_OK):
            return f
    return None


def parse_entry(entry_str, separator='='):
    """
    Parse entry as returned by boottool.

    :param entry_str: one entry information as returned by boottool
    :return: dictionary of key -> value where key is the string before
            the first ":" in an entry line and value is the string after
            it
    """
    entry = {}
    for line in entry_str.splitlines():
        if len(line) == 0:
            continue

        try:
            name, value = line.split(separator, 1)
        except ValueError:
            continue

        name = name.strip()
        value = value.strip()

        if name == 'index':
            # index values are integrals
            value = int(value)
        entry[name] = value

    return entry


def detect_distro_type():
    '''
    Simple distro detection based on release/version files
    '''
    if os.path.exists('/etc/redhat-release'):
        return 'redhat'
    elif os.path.exists('/etc/debian_version'):
        return 'debian'
    elif os.path.exists('/etc/issue'):
        if re.match(r'.*SUSE.*', open('/etc/issue').read()):
            return 'suse'
    else:
        return None


class DebianBuildDeps(object):

    '''
    Checks and install grubby build dependencies on Debian (like) systems

    Tested on:
       * Debian Squeeze (6.0)
       * Ubuntu 12.04 LTS
    '''

    PKGS = ['gcc', 'make', 'libpopt-dev', 'libblkid-dev']

    def check(self):
        '''
        Checks if necessary packages are already installed
        '''
        result = True
        for p in self.PKGS:
            args = ['dpkg-query', '--show', '--showformat=${Status}', p]
            output = subprocess.Popen(args, shell=False,
                                      stdin=subprocess.PIPE,
                                      stdout=subprocess.PIPE,
                                      stderr=subprocess.PIPE,
                                      close_fds=True).stdout.read()
            if not output == 'install ok installed':
                result = False
        return result

    def install(self):
        '''
        Attempt to install the build dependencies via a package manager
        '''
        if self.check():
            return True
        else:
            try:
                args = ['apt-get', 'update', '-qq']
                subprocess.call(args,
                                stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE)

                args = ['apt-get', 'install', '-qq'] + self.PKGS
                subprocess.call(args,
                                stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE)
            except OSError:
                pass
        return self.check()


class RPMBuildDeps(object):

    '''
    Base class for RPM based systems
    '''

    def check(self):
        '''
        Checks if necessary packages are already installed
        '''
        result = True
        for p in self.PKGS:
            args = ['rpm', '-q', '--qf=%{NAME}', p]
            output = subprocess.Popen(args, shell=False,
                                      stdin=subprocess.PIPE,
                                      stdout=subprocess.PIPE,
                                      stderr=subprocess.PIPE,
                                      close_fds=True).stdout.read()
            if not output.startswith(p):
                result = False

        return result


class SuseBuildDeps(RPMBuildDeps):

    '''
    Checks and install grubby build dependencies on SuSE (like) systems

    Tested on:
       * OpenSuSE 12.2
    '''

    PKGS = ['gcc', 'make', 'popt-devel', 'libblkid-devel']

    def install(self):
        '''
        Attempt to install the build dependencies via a package manager
        '''
        if self.check():
            return True
        else:
            try:
                args = ['zypper', '-n', '--no-cd', 'install'] + self.PKGS
                result = subprocess.call(args,
                                         stdout=subprocess.PIPE,
                                         stderr=subprocess.PIPE)
            except OSError:
                pass
        return self.check()


class RedHatBuildDeps(RPMBuildDeps):

    '''
    Checks and install grubby build dependencies on RedHat (like) systems

    Tested on:
       * Fedora 17
       * RHEL 5
       * RHEL 6
    '''

    PKGS = ['gcc', 'make']
    REDHAT_RELEASE_RE = re.compile('.*\srelease\s(\d)\.(\d)\s.*')

    def __init__(self):
        '''
        Initializes a new dep installer, taking into account RHEL version
        '''
        match = self.REDHAT_RELEASE_RE.match(
            open('/etc/redhat-release').read())
        if match:
            major, minor = match.groups()
            if int(major) <= 5:
                self.PKGS += ['popt', 'e2fsprogs-devel']
            else:
                self.PKGS += ['popt-devel', 'libblkid-devel']

    def install(self):
        '''
        Attempt to install the build dependencies via a package manager
        '''
        if self.check():
            return True
        else:
            try:
                args = ['yum', 'install', '-q', '-y'] + self.PKGS

                # This is an extra safety step, to install the needed header
                # in case the blkid headers package could not be detected
                args += ['/usr/include/popt.h',
                         '/usr/include/blkid/blkid.h']

                result = subprocess.call(args,
                                         stdout=subprocess.PIPE,
                                         stderr=subprocess.PIPE)
            except OSError:
                pass
        return self.check()


DISTRO_DEPS_MAPPING = {
    'debian': DebianBuildDeps,
    'redhat': RedHatBuildDeps,
    'suse': SuseBuildDeps
}


def install_grubby_if_necessary(path=None):
    '''
    Installs grubby if it's necessary on this system

    Or if the required version is not sufficient for the needs of boottool
    '''
    installed_grubby = False

    if path is None:
        if find_executable(GRUBBY_DEFAULT_USER_PATH):
            executable = GRUBBY_DEFAULT_USER_PATH
        else:
            executable = find_executable(GRUBBY_DEFAULT_SYSTEM_PATH)
    else:
        executable = find_executable(path)

    if executable is None:
        log.info('Installing grubby because it was not found on this system')
        grubby = Grubby()
        path = grubby.grubby_install()
        installed_grubby = True
    else:
        grubby = Grubby(executable)
        current_version = grubby.get_grubby_version()
        if current_version is None:
            log.error('Could not find version for grubby executable "%s"',
                      executable)
            path = grubby.grubby_install()
            installed_grubby = True

        elif current_version < GRUBBY_REQ_VERSION:
            log.info('Installing grubby because currently installed '
                     'version (%s.%s) is not recent enough',
                     current_version[0], current_version[1])
            path = grubby.grubby_install()
            installed_grubby = True

    if installed_grubby:
        grubby = Grubby(path)
        installed_version = grubby.get_grubby_version_raw()
        log.debug('Installed: %s', installed_version)


class GrubbyInstallException(Exception):

    '''
    Exception that signals failure when doing grubby installation
    '''
    pass


class Grubby(object):

    '''
    Grubby wrapper

    This class calls the grubby binary for most commands, but also
    adds some functionality that is not really suited to be included
    in int, such as boot-once.
    '''

    SUPPORTED_BOOTLOADERS = ('lilo', 'grub2', 'grub', 'extlinux', 'yaboot',
                             'elilo')

    def __init__(self, path=None, opts=None):
        self._set_path(path)
        self.bootloader = None
        self.opts = opts
        self.log = logging.getLogger(self.__class__.__name__)

        if os.environ.has_key('BOOTTOOL_DEBUG_RUN'):
            self.debug_run = True
        else:
            self.debug_run = False

        self._check_grubby_version()
        self._set_bootloader()

    def _set_path(self, path=None):
        """
        Set grubby path.

        If path is not provided, check first if there's a built grubby,
        then look for the system grubby.

        :param path: Alternate grubby path.
        """
        if path is None:
            if os.path.exists(GRUBBY_DEFAULT_USER_PATH):
                self.path = GRUBBY_DEFAULT_USER_PATH
            else:
                self.path = GRUBBY_DEFAULT_SYSTEM_PATH
        else:
            self.path = path

    #
    # The following block contain utility functions that are used to build
    # most of these class methods, such as methods for running commands
    # and preparing grubby command line switches.
    #

    def _check_grubby_version(self):
        '''
        Checks the version of grubby in use and warns if it's not good enough
        '''
        current_version = self.get_grubby_version()
        if current_version is None:
            self.log.warn('Could not detect current grubby version. It may '
                          'be that you are running an unsupported version '
                          'of grubby')
        elif current_version < GRUBBY_REQ_VERSION:
            self.log.warn('version %s.%s being used is not guaranteed to '
                          'work properly. Mininum required version is %s.%s.',
                          current_version[0], current_version[1],
                          GRUBBY_REQ_VERSION[0], GRUBBY_REQ_VERSION[1])

    def _run_get_output(self, arguments):
        '''
        Utility function that runs a command and returns command output
        '''
        if self.debug_run:
            self.log.debug('running: "%s"', ' '.join(arguments))

        result = None
        try:
            result = subprocess.Popen(arguments, shell=False,
                                      stdin=subprocess.PIPE,
                                      stdout=subprocess.PIPE,
                                      close_fds=True).stdout.read()
        except:
            pass

        if result is not None:
            result = result.strip()
            if self.debug_run:
                logging.debug('previous command output: "%s"', result)
        else:
            self.log.error('_run_get_output error while running: "%s"',
                           ' '.join(arguments))
        return result

    def _run_get_output_err(self, arguments):
        '''
        Utility function that runs a command and returns command output
        '''
        if self.debug_run:
            self.log.debug('running: "%s"', ' '.join(arguments))

        result = None
        try:
            result = subprocess.Popen(arguments, shell=False,
                                      stdin=subprocess.PIPE,
                                      stdout=subprocess.PIPE,
                                      stderr=subprocess.PIPE,
                                      close_fds=True).stdout.read()
        except:
            pass

        if result is not None:
            result = result.strip()
            if self.debug_run:
                logging.debug('previous command output/error: "%s"', result)
        else:
            self.log.error('_run_get_output_err error while running: "%s"',
                           ' '.join(arguments))
        return result

    def _run_get_return(self, arguments):
        '''
        Utility function that runs a command and returns status code
        '''
        if self.debug_run:
            self.log.debug('running: "%s"', ' '.join(arguments))

        result = None
        try:
            result = subprocess.call(arguments)
            if self.debug_run:
                logging.debug('previous command result: %s', result)
        except OSError:
            result = -1
            self.log.error('caught OSError, returning %s', result)

        return result

    def _set_bootloader(self, bootloader=None):
        '''
        Attempts to detect what bootloader is installed on the system

        The result of this method is used in all other calls to grubby,
        so that it acts accordingly to the bootloader detected.
        '''
        if bootloader is None:
            result = self.get_bootloader()
            if result is not None:
                self.bootloader = result
        else:
            if bootloader in self.SUPPORTED_BOOTLOADERS:
                self.bootloader = bootloader
            else:
                raise ValueError('Bootloader "%s" is not supported' %
                                 bootloader)

    def _run_grubby_prepare_args(self, arguments, include_bootloader=True):
        '''
        Prepares the argument list when running a grubby command
        '''
        args = []

        if self.path is None:
            self._set_path()

        args.append(self.path)

        if self.path is not None and not os.path.exists(self.path):
            self.log.error('grubby executable does not exist: "%s"', self.path)
            if not os.access(self.path, os.R_OK | os.X_OK):
                self.log.error('insufficient permissions (read and execute) '
                               'for grubby executable: "%s"', self.path)

        # If a bootloader has been detected, that is, a mode has been set,
        # it's passed as the first command line argument to grubby
        if include_bootloader and self.bootloader is not None:
            args.append('--%s' % self.bootloader)

        # Override configuration file
        if self.opts is not None and self.opts.config_file:
            args.append('--config-file=%s' % self.opts.config_file)

        args += arguments
        return args

    def _run_grubby_get_output(self, arguments, include_bootloader=True):
        '''
        Utility function that runs grubby with arguments and returns output
        '''
        args = self._run_grubby_prepare_args(arguments, include_bootloader)
        return self._run_get_output(args)

    def _run_grubby_get_return(self, arguments, include_bootloader=True):
        '''
        Utility function that runs grubby with and returns status code
        '''
        args = self._run_grubby_prepare_args(arguments, include_bootloader)
        return self._run_get_return(args)

    def _extract_tarball(self, tarball, directory):
        '''
        Extract tarball into the an directory

        This code assume the first (or only) entry is the main directory

        :type tarball: string
        :param tarball: tarball file path
        :type directory: string
        :param directory: directory path
        :return: path of toplevel directory as extracted from tarball
        '''
        f = tarfile.open(tarball)
        members = f.getmembers()
        topdir = members[0]
        assert topdir.isdir()
        # we can not use extractall() because it is not available on python 2.4
        for m in members:
            f.extract(m, directory)
        return os.path.join(directory, topdir.name)

    def _get_entry_indexes(self, info):
        '''
        Returns the indexes found in a get_info() output

        :type info: list of lines
        :param info: result of utility method get_info()
        :return: maximum index number
        '''
        indexes = []
        for line in self.get_info_lines():
            try:
                key, value = line.split("=")
                if key == 'index':
                    indexes.append(int(value))
            except ValueError:
                pass
        return indexes

    def _index_for_title(self, title):
        '''
        Returns the index of an entry based on the title of the entry

        :type title: string
        :param title: the title of the entry
        :return: the index of the given entry or None
        '''
        if self._is_number(title):
            return title

        info = self.get_info_lines()

        for i in self._get_entry_indexes(info):
            info = self.get_info(i)
            if info is None:
                continue
            lines = info.splitlines()
            looking_for = ('title=%s' % title,
                           'label=%s' % title)
            for line in lines:
                if line in looking_for:
                    return i
        return None

    def _info_filter(self, info, key, value=None):
        '''
        Filters info, looking for keys, optionally set with a given value

        :type info: list of lines
        :param info: result of utility method get_info()
        :type key: string
        :param key: filter based on this key
        :type value: string
        :param value: filter based on this value
        :return: value or None
        '''
        for line in info:
            if value is not None:
                looking_for = '%s=%s' % (key, value)
                if line == looking_for:
                    return line.split("=")[1]
            else:
                if line.startswith("%s=" % key):
                    return line.split("=")[1]
        return None

    def _kernel_for_title(self, title):
        '''
        Returns the kernel path for an entry based on its title

        :type title: string
        :param title: the title of the entry
        :return: the kernel path of None
        '''
        index = self._index_for_title(title)
        if index is not None:
            info = self.get_info_lines(index)
            kernel = self._info_filter(info, 'kernel')
            return kernel
        else:
            return None

    def _is_number(self, data):
        '''
        Returns true if supplied data is an int or string with digits
        '''
        if isinstance(data, int):
            return True
        elif isinstance(data, str) and data.isdigit():
            return True
        return False

    def _get_entry_selection(self, data):
        '''
        Returns a valid grubby parameter for commands such as --update-kernel
        '''
        if self._is_number(data):
            return data
        elif isinstance(data, str) and data.startswith('/'):
            # assume it's the kernel filename
            return data
        elif isinstance(data, str):
            return self._kernel_for_title(data)
        else:
            raise ValueError("Bad value for 'kernel' parameter. Expecting "
                             "either and int (index) or string (kernel or "
                             "title)")

    def _remove_duplicate_cmdline_args(self, cmdline):
        """
        Remove the duplicate entries in cmdline making sure that the first
        duplicate occurrences are the ones removed and the last one remains
        (this is in order to not change the semantics of the "console"
        parameter where the last occurrence has special meaning)

        :param cmdline: a space separate list of kernel boot parameters
            (ex. 'console=ttyS0,57600n8 nmi_watchdog=1')
        :return: a space separated list of kernel boot parameters without
            duplicates
        """
        copied = set()
        new_args = []

        for arg in reversed(cmdline.split()):
            if arg not in copied:
                new_args.insert(0, arg)
                copied.add(arg)
        return ' '.join(new_args)

    #
    # The following methods implement a form of "API" that action methods
    # can rely on. Another goal is to maintain compatibility with the current
    # client side API in autotest (client/shared/boottool.py)
    #
    def get_bootloader(self):
        '''
        Get the bootloader name that is detected on this machine

        This module performs the same action as client side boottool.py
        get_type() method, but with a better name IMHO.

        :return: name of detected bootloader
        '''
        args = [self.path, '--bootloader-probe']
        output = self._run_get_output_err(args)
        if output is None:
            return None
        if output.startswith('grubby: bad argument'):
            return None
        elif output not in self.SUPPORTED_BOOTLOADERS:
            return None
        return output

    # Alias for client side boottool.py API
    get_type = get_bootloader

    # Alias for boottool app
    bootloader_probe = get_bootloader

    def get_architecture(self):
        '''
        Get the system architecture

        This is much simpler version then the original boottool version, that
        does not attempt to filter the result of the command / system call
        that returns the archicture.

        :return: string with system archicteture, such as x86_64, ppc64, etc
        '''
        return os.uname()[4]

    # Alias for boottool app
    arch_probe = get_architecture

    def get_titles(self):
        '''
        Get the title of all boot entries.

        :return: list with titles of boot entries
        '''
        titles = []
        for line in self.get_info_lines():
            try:
                key, value = line.split("=")
                if key in ['title', 'label']:
                    titles.append(value)
            except ValueError:
                pass
        return titles

    def get_default_index(self):
        '''
        Get the default entry index.

        This module performs the same action as client side boottool.py
        get_default() method, but with a better name IMHO.

        :return: an integer with the the default entry.
        '''
        default_index = self._run_grubby_get_output(['--default-index'])
        if default_index is not None and default_index:
            default_index = int(default_index)
        return default_index

    # Alias for client side boottool.py API
    get_default = get_default_index

    # Alias for boottool app
    default = get_default_index

    def set_default_by_index(self, index):
        """
        Sets the given entry number to be the default on every next boot

        To set a default only for the next boot, use boot_once() instead.

        This module performs the same action as client side boottool.py
        set_default() method, but with a better name IMHO.

        Note: both --set-default=<kernel> and --set-default-index=<index>
        on grubby returns no error when it doesn't find the kernel or
        index. So this method will, until grubby gets fixed, always return
        success.

        :param index: entry index number to set as the default.
        """
        return self._run_grubby_get_return(['--set-default-index=%s' % index])

    # Alias for client side boottool.py API
    set_default = set_default_by_index

    def get_default_title(self):
        '''
        Get the default entry title.

        Conforms to the client side boottool.py API, but rely directly on
        grubby functionality.

        :return: a string of the default entry title.
        '''
        return self._run_grubby_get_output(['--default-title'])

    def get_entry(self, search_info):
        """
        Get a single bootloader entry information.

        NOTE: if entry is "fallback" and bootloader is grub
        use index instead of kernel title ("fallback") as fallback is
        a special option in grub

        :param search_info: can be 'default', position number or title
        :return: a dictionary of key->value where key is the type of entry
                information (ex. 'title', 'args', 'kernel', etc) and value
                is the value for that piece of information.
        """
        info = self.get_info(search_info)
        return parse_entry(info)

    def get_entries(self):
        """
        Get all entries information.

        :return: a dictionary of index -> entry where entry is a dictionary
                of entry information as described for get_entry().
        """
        raw = self.get_info()

        entries = {}
        for entry_str in re.split("index", raw):
            if len(entry_str.strip()) == 0:
                continue
            if entry_str.startswith('boot='):
                continue
            if 'non linux entry' in entry_str:
                continue
            entry = parse_entry("index" + entry_str)
            try:
                entries[entry["index"]] = entry
            except KeyError:
                continue

        return entries

    def get_info(self, entry='ALL'):
        '''
        Returns information on a given entry, or all of them if not specified

        The information is returned as a set of lines, that match the output
        of 'grubby --info=<entry>'

        :type entry: string
        :param entry: entry description, usually an index starting from 0
        :return: set of lines
        '''
        command = '--info=%s' % entry
        info = self._run_grubby_get_output([command])
        if info:
            return info

    def get_title_for_kernel(self, path):
        """
        Returns a title for a particular kernel.

        :param path: path of the kernel image configured in the boot config
        :return: if the given kernel path is found it will return a string
                with the title for the found entry, otherwise returns None
        """
        entries = self.get_entries()
        for entry in entries.itervalues():
            if entry.get('kernel') == path:
                return entry['title']
        return None

    def add_args(self, kernel, args):
        """
        Add cmdline arguments for the specified kernel.

        :param kernel: can be a position number (index) or title
        :param args: argument to be added to the current list of args
        """
        entry_selection = self._get_entry_selection(kernel)
        command_arguments = ['--update-kernel=%s' % entry_selection,
                             '--args=%s' % args]
        self._run_grubby_get_return(command_arguments)

    def remove_args(self, kernel, args):
        """
        Removes specified cmdline arguments.

        :param kernel: can be a position number (index) or title
        :param args: argument to be removed of the current list of args
        """
        entry_selection = self._get_entry_selection(kernel)
        command_arguments = ['--update-kernel=%s' % entry_selection,
                             '--remove-args=%s' % args]
        self._run_grubby_get_return(command_arguments)

    def add_kernel(self, path, title='autoserv', root=None, args=None,
                   initrd=None, default=False, position='end'):
        """
        Add a kernel entry to the bootloader (or replace if one exists
        already with the same title).

        :param path: string path to the kernel image file
        :param title: title of this entry in the bootloader config
        :param root: string of the root device
        :param args: string with cmdline args
        :param initrd: string path to the initrd file
        :param default: set to True to make this entry the default one
                (default False)
        :param position: where to insert the new entry in the bootloader
                config file (default 'end', other valid input 'start', or
                # of the title)
        :param xen_hypervisor: xen hypervisor image file (valid only when
                xen mode is enabled)
        """
        if title in self.get_titles():
            self.remove_kernel(title)

        parameters = ['--add-kernel=%s' % path, '--title=%s' % title]

        # FIXME: grubby takes no --root parameter
        # if root:
        #     parameters.append('--root=%s' % root)

        if args:
            parameters.append('--args=%s' %
                              self._remove_duplicate_cmdline_args(args))

        if initrd:
            parameters.append('--initrd=%s' % initrd)

        if default:
            parameters.append('--make-default')

        # There's currently an issue with grubby '--add-to-bottom' feature.
        # Because it uses the tail instead of the head of the list to add
        # a new entry, when copying a default entry as a template
        # (--copy-default), it usually copies the "recover" entries that
        # usually go along a regular boot entry, specially on grub2.
        #
        # So, for now, until I fix grubby, we'll *not* respect the position
        # (--position=end) command line option.
        #
        # if opts.position == 'end':
        #     parameters.append('--add-to-bottom')

        parameters.append("--copy-default")
        return self._run_grubby_get_return(parameters)

    def remove_kernel(self, kernel):
        """
        Removes a specific entry from the bootloader configuration.

        :param kernel: entry position or entry title.

        FIXME: param kernel should also take 'start' or 'end'.
        """
        entry_selection = self._get_entry_selection(kernel)
        if entry_selection is None:
            self.log.debug('remove_kernel for title "%s" did not find an '
                           'entry. This is most probably NOT an error', kernel)
            return 0

        command_arguments = ['--remove-kernel=%s' % entry_selection]
        return self._run_grubby_get_return(command_arguments)

    #
    # The following methods are not present in the original client side
    # boottool.py
    #
    def get_info_lines(self, entry='ALL'):
        '''
        Returns information on a given entry, or all of them if not specified

        The information is returned as a set of lines, that match the output
        of 'grubby --info=<entry>'

        :type entry: string
        :param entry: entry description, usually an index starting from 0
        :return: set of lines
        '''
        info = self.get_info(entry)
        if info:
            return info.splitlines()

    def get_grubby_version_raw(self):
        '''
        Get the version of grubby that is installed on this machine as is

        :return: string with raw output from grubby --version
        '''
        return self._run_grubby_get_output(['--version'], False)

    def get_grubby_version(self):
        '''
        Get the version of grubby that is installed on this machine

        :return: tuple with (major, minor) grubby version
        '''
        output = self.get_grubby_version_raw()
        if output is None:
            self.log.warn('Could not run grubby to fetch its version')
            return None

        match = re.match('(grubby version)?(\s)?(\d+)\.(\d+)(.*)', output)
        if match:
            groups = match.groups()
            return (int(groups[2]), int(groups[3]))
        else:
            return None

    def grubby_install_patch_makefile(self):
        '''
        Patch makefile, making CFLAGS more forgivable to older toolchains
        '''
        cflags_line = 'CFLAGS += $(RPM_OPT_FLAGS) -std=gnu99 -ggdb\n'
        libs_line = 'grubby_LIBS = -lblkid -lpopt -luuid\n'
        shutil.move('Makefile', 'Makefile.boottool.bak')
        o = open('Makefile', 'w')
        for l in open('Makefile.boottool.bak').readlines():
            if l.startswith('CFLAGS += '):
                o.write(cflags_line)
            elif l.startswith('grubby_LIBS = -lblkid -lpopt'):
                o.write(libs_line)
            else:
                o.write(l)
        o.close()

    def grubby_install_backup(self, path):
        '''
        Backs up the current grubby binary to make room the one we'll build

        :type path: string
        :param path: path to the binary that should be backed up
        '''
        backup_path = '%s.boottool.bkp' % path
        if (os.path.exists(path)
                and not os.path.exists(backup_path)):
            try:
                shutil.move(path, backup_path)
            except:
                self.log.warn('Failed to backup the current grubby binary')

    def grubby_install_fetch_tarball(self, topdir):
        '''
        Fetches and verifies the grubby source tarball
        '''
        tarball_name = os.path.basename(GRUBBY_TARBALL_URI)

        # first look in the current directory
        try:
            tarball = tarball_name
            f = open(tarball)
        except:
            try:
                # then the autotest source directory
                from autotest.client.shared.settings import settings
                top_path = settings.get_value('COMMON', 'autotest_top_path')
                tarball = os.path.join(top_path, tarball_name)
                f = open(tarball)
            except:
                # then try to grab it from github
                try:
                    tarball = os.path.join(topdir, tarball_name)
                    urllib.urlretrieve(GRUBBY_TARBALL_URI, tarball)
                    f = open(tarball)
                except:
                    return None

        tarball_md5 = md5.md5(f.read()).hexdigest()
        if tarball_md5 != GRUBBY_TARBALL_MD5:
            return None

        return tarball

    def grubby_build(self, topdir, tarball):
        '''
        Attempts to build grubby from the source tarball
        '''
        def log_lines(lines):
            for line in lines:
                self.log.debug(line.strip())

        try:
            find_header('popt.h')
        except ValueError:
            self.log.debug('No popt.h header present, skipping build')
            return False

        tarball_name = os.path.basename(tarball)

        srcdir = os.path.join(topdir, 'src')
        srcdir = self._extract_tarball(tarball, srcdir)
        os.chdir(srcdir)
        self.grubby_install_patch_makefile()
        result = subprocess.Popen(['make'],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE)
        if result.wait() != 0:
            self.log.debug('Failed to build grubby during "make" step')
            log_lines(result.stderr.read().splitlines())
            return False

        install_root = os.path.join(topdir, 'install_root')
        os.environ['DESTDIR'] = install_root
        result = subprocess.Popen(['make', 'install'],
                                  stdout=subprocess.PIPE,
                                  stderr=subprocess.PIPE)
        if result.wait() != 0:
            self.log.debug('Failed to build grubby during "make install" step')
            log_lines(result.stderr.read().splitlines())
            return False
        return True

    def grubby_install(self, path=None):
        '''
        Attempts to install a recent enough version of grubby

        So far tested on:
           * Fedora 16 x86_64
           * Debian 6 x86_64
           * SuSE 12.1 x86_64
           * RHEL 4 on ia64 (with updated python 2.4)
           * RHEL 5 on ia64
           * RHEL 6 on ppc64
        '''
        if path is None:
            if os.geteuid() == 0:
                path = GRUBBY_DEFAULT_SYSTEM_PATH
            else:
                path = GRUBBY_DEFAULT_USER_PATH

        topdir = tempfile.mkdtemp()

        deps_klass = DISTRO_DEPS_MAPPING.get(detect_distro_type(), None)
        if deps_klass is not None:
            deps = deps_klass()
            if not deps.check():
                self.log.warn('Installing distro build deps for grubby. This '
                              'may take a while, depending on bandwidth and '
                              'actual number of packages to install')
                if not deps.install():
                    self.log.error('Failed to install distro build deps for '
                                   'grubby')

        tarball = self.grubby_install_fetch_tarball(topdir)
        if tarball is None:
            raise GrubbyInstallException('Failed to fetch grubby tarball')

        srcdir = os.path.join(topdir, 'src')
        install_root = os.path.join(topdir, 'install_root')
        os.mkdir(install_root)

        if not self.grubby_build(topdir, tarball):
            raise GrubbyInstallException('Failed to build grubby')

        self.grubby_install_backup(path)

        grubby_bin = os.path.join(install_root, 'sbin', 'grubby')
        inst_dir = os.path.dirname(path)
        if not os.access(inst_dir, os.W_OK):
            raise GrubbyInstallException('No permission to copy grubby '
                                         'binary to directory "%s"' % inst_dir)
        try:
            shutil.copy(grubby_bin, path)
        except:
            raise GrubbyInstallException('Failed to copy grubby binary to '
                                         'directory "%s"' % inst_dir)

        return path

    def boot_once(self, title=None):
        '''
        Configures the bootloader to boot an entry only once

        This is not implemented by grubby, but directly implemented here, via
        the 'boot_once_<bootloader>' method.
        '''
        self.log.debug('Title chosen to boot once: %s', title)

        available_titles = self.get_titles()
        if title not in available_titles:
            self.log.error('Entry with title "%s" was not found', title)
            return -1

        default_title = self.get_default_title()
        self.log.debug('Title actually set as default: %s', default_title)

        if default_title == title:
            self.log.info('Doing nothing: entry to boot once is the same as '
                          'default entry')
            return
        else:
            self.log.debug('Setting boot once for entry: %s', title)

        bootloader = self.get_bootloader()
        if bootloader in ('grub', 'grub2', 'elilo'):
            entry_index = self._index_for_title(title)
            if entry_index is None:
                self.log.error('Could not find index for entry with title '
                               '"%s"', title)
                return -1

        if bootloader == 'grub':
            return self.boot_once_grub(entry_index)
        elif bootloader == 'grub2':
            return self.boot_once_grub2(entry_index)
        elif bootloader == 'yaboot':
            return self.boot_once_yaboot(title)
        elif bootloader == 'elilo':
            return self.boot_once_elilo(entry_index)
        else:
            self.log.error("Detected bootloader does not implement boot once")
            return -1

    def boot_once_grub(self, entry_index):
        '''
        Implements the boot once feature for the grub bootloader
        '''
        # grubonce is a hack present in distros like OpenSUSE
        grubonce_cmd = find_executable('grubonce')
        if grubonce_cmd is None:
            # XXX: check the type of default set (numeric or "saved")
            grub_instructions = ['savedefault --default=%s --once' %
                                 entry_index, 'quit']
            grub_instructions_text = '\n'.join(grub_instructions)
            grub_binary = find_executable('grub')
            if grub_binary is None:
                self.log.error("Could not find the 'grub' binary, aborting")
                return -1

            p = subprocess.Popen([grub_binary, '--batch'],
                                 stdin=subprocess.PIPE,
                                 stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE)
            out, err = p.communicate(grub_instructions_text)

            complete_out = ''
            if out is not None:
                complete_out = out
            if err is not None:
                complete_out += "\n%s" % err

            grub_batch_err = []
            if complete_out:
                for l in complete_out.splitlines():
                    if re.search('error', l, re.IGNORECASE):
                        grub_batch_err.append(l)
                if grub_batch_err:
                    self.log.error("Error while running grub to set boot "
                                   "once: %s", "\n".join(grub_batch_err))
                    return -1

            self.log.debug('No error detected while running grub to set boot '
                           'once')
            return 0
        else:
            rc = self._run_get_return([grubonce_cmd, str(entry_index)])
            if rc:
                self.log.error('Error running %s', grubonce_cmd)
            else:
                self.log.debug('No error detected while running %s',
                               grubonce_cmd)
            return rc

    def boot_once_grub2(self, entry_index):
        '''
        Implements the boot once feature for the grub2 bootloader

        Caveat: this assumes the default set is of type "saved", and not a
        numeric value.
        '''
        default_index_re = re.compile('\s*set\s+default\s*=\s*\"+(\d+)\"+')

        grub_reboot_names = ['grub-reboot', 'grub2-reboot']
        grub_reboot_exec = None
        for grub_reboot in grub_reboot_names:
            grub_reboot_exec = find_executable(grub_reboot)
            if grub_reboot_exec is not None:
                break

        if grub_reboot_exec is None:
            self.log.error('Could not find executable among searched names: '
                           '%s', ' ,'.join(grub_reboot_names))
            return -1

        grub_set_default_names = ['grub-set-default', 'grub2-set-default']
        grub_set_default_exec = None
        for grub_set_default in grub_set_default_names:
            grub_set_default_exec = find_executable(grub_set_default)
            if grub_set_default_exec is not None:
                break

        if grub_set_default_exec is None:
            self.log.error('Could not find executable among searched names: '
                           '%s', ' ,'.join(grub_set_default_names))
            return -1

        # Make sure the "set default" entry in the configuration file is set
        # to "${saved_entry}. Assuming the config file is at
        # /boot/grub/grub.cfg
        deb_grub_cfg_path = '/boot/grub/grub.cfg'
        deb_grub_cfg_bkp_path = '%s.boottool.bak' % deb_grub_cfg_path

        default_index = None
        if os.path.exists(deb_grub_cfg_path):
            shutil.move(deb_grub_cfg_path, deb_grub_cfg_bkp_path)
            o = open(deb_grub_cfg_path, 'w')
            for l in open(deb_grub_cfg_bkp_path).readlines():
                m = default_index_re.match(l)
                if m is not None:
                    default_index = int(m.groups()[0])
                    o.write('set default="${saved_entry}"\n')
                else:
                    o.write(l)
            o.close()

        # Make the current default entry the "previous saved entry"
        if default_index is None:
            default_index = self.get_default_index()
        else:
            # grubby adds entries to top. this assumes a new entry to boot once
            # has already been added to the top, so fallback to the second
            # entry (index 1) if the boot once entry fails to boot
            if entry_index == 0:
                default_index = 1
            else:
                default_index = 0

        # A negative index is never acceptable
        if default_index >= 0:
            prev_saved_return = self._run_get_return([grub_set_default_exec,
                                                      '%s' % default_index])
            if prev_saved_return != 0:
                self.log.error(
                    'Could not make entry %s the previous saved entry',
                    default_index)
                return prev_saved_return

        # Finally set the boot once entry
        return self._run_get_return([grub_reboot_exec,
                                     '%s' % entry_index])

    def boot_once_yaboot(self, entry_title):
        '''
        Implements the boot once feature for the yaboot bootloader
        '''
        nvsetenv_cmd = find_executable('nvsetenv')
        if nvsetenv_cmd is None:
            self.log.error("Could not find nvsetenv in PATH")
            return -1
        return self._run_get_return([nvsetenv_cmd,
                                     'boot-once',
                                     entry_title])

    def boot_once_elilo(self, entry_index):
        '''
        Implements boot once for machines with kernel >= 2.6

        This manipulates EFI variables via the interface available at
        /sys/firmware/efi/vars
        '''
        info = self.get_entry(entry_index)
        kernel = os.path.basename(info['kernel'])

        # remove quotes
        args = info['args']
        if args[0] == '"':
            args = args[1:]
        if args[-1] == '"':
            args = args[:-1]

        params = "root=%s %s" % (info['root'], args)
        data = "%s %s" % (kernel, params)

        efi = EfiToolSys()
        if not (efi.create_variable('EliloAlt', data)):
            return -1

        eliloconf = EliloConf()
        eliloconf.add_global_option('checkalt')
        eliloconf.add_global_option('initrd', os.path.basename(info['initrd']))
        eliloconf.remove_global_option('prompt')
        eliloconf.update()
        return 0


class OptionParser(optparse.OptionParser):

    '''
    Command line option parser

    Aims to maintain compatibility at the command line level with boottool
    '''

    option_parser_usage = '''%prog [options]'''

    def __init__(self, **kwargs):
        optparse.OptionParser.__init__(self,
                                       usage=self.option_parser_usage,
                                       **kwargs)

        misc = self.add_option_group('MISCELLANEOUS OPTIONS')
        misc.add_option('--config-file',
                        help='Specifies the path and name of the bootloader '
                        'config file, overriding autodetection of this file')

        misc.add_option('--force', action='store_true',
                        help='If specified, any conflicting kernels will be '
                        'removed')

        misc.add_option('--bootloader',
                        help='Manually specify the bootloader to use.  By '
                        'default, boottool will automatically try to detect '
                        'the bootloader being used')

        misc.add_option('--root',
                        help='The device where the root partition is located')

        misc.add_option('--debug', default=0,
                        help='Prints debug messages. This expects a numerical '
                        'argument corresponding to the debug message '
                        'verbosity')

        probe = self.add_option_group('SYSTEM PROBING')
        probe.add_option('--bootloader-probe', action='store_true',
                         help='Prints the bootloader in use on the system '
                         'and exits')

        probe.add_option('--arch-probe', action='store_true',
                         help='Prints the arch of the system and exits')

        actions = self.add_option_group('ACTIONS ON BOOT ENTRIES')
        actions.add_option('--add-kernel',
                           help='Adds a new kernel with the given path')

        actions.add_option('--remove-kernel',
                           help='Removes the bootloader entry with the given '
                           'position or title. Also accepts \'start\' or '
                           '\'end\'')

        actions.add_option('--update-kernel',
                           help='Updates an existing kernel with the given '
                           'position number or title. Useful options when '
                           'modifying a kernel include --args and '
                           '--remove-args')

        actions.add_option('--info',
                           help='Display information about the bootloader entry '
                           'at the given position number. Also accepts \'all\' '
                           'or \'default\'')

        actions.add_option('--default', action='store_true',
                           help='Prints the current default kernel for the '
                           'bootloader')

        actions.add_option('--set-default',
                           help='Updates the bootloader to set the default '
                           'boot entry to given given position or title')

        actions.add_option('--install', action='store_true',
                           help='Causes bootloader to update and re-install '
                           'the bootloader file')

        actions.add_option('--boot-once', action='store_true',
                           help='Causes the bootloader to boot the kernel '
                           'specified by --title just one time, then fall back'
                           ' to the default entry. This option does not work '
                           'identically on all architectures')

        act_args = self.add_option_group('ACTION PARAMETERS')
        act_args.add_option('--title',
                            help='The title or label to use for the '
                            'bootloader entry. Required when adding a new '
                            'entry.')

        act_args.add_option('--position',
                            help='Insert bootloader entry at the given '
                            'position number, counting from 0. Also accepts '
                            '\'start\' or \'end\'. Optional when adding a new '
                            'entry.')

        act_args.add_option('--make-default', action='store_true',
                            help='Specifies that the bootloader entry being '
                            'added should be the new default')

        kernel = self.add_option_group('LINUX KERNEL PARAMETERS',
                                       'Options specific to manage boot '
                                       'entries with Linux')
        kernel.add_option('--args',
                          help='Add arguments to be passed to the kernel at '
                          'boot. Use when adding a new entry or when '
                          'modifying an existing entry.')

        kernel.add_option('--remove-args',
                          help='Arguments to be removed from an existing entry'
                          '. Use when modifying an existing entry with '
                          '--update-kernel action.')

        kernel.add_option('--initrd',
                          help='The initrd image path to use in the bootloader '
                          'entry')

        kernel.add_option('--module',
                          help='This option adds modules to the new kernel. It'
                          ' only works with Grub Bootloader. For more module '
                          'options just add another --module parameter')

        grubby = self.add_option_group('GRUBBY',
                                       'Manage grubby, the tool that drives '
                                       'most of boottool functionality')
        grubby.add_option('--grubby-version', action='store_true',
                          help='Prints the version of grubby installed on '
                          'this machine')

        grubby.add_option('--grubby-version-check',
                          help='Checks if the installed version of grubby is '
                          'recent enough')

        grubby.add_option('--grubby-install', action='store_true',
                          help='Attempts to install a recent enought version '
                          'of grubby')

        grubby.add_option('--grubby-path',
                          help='Use a different grubby binary, located at the '
                          'given path')

    def opts_has_action(self, opts):
        '''
        Checks if (parsed) opts has a first class action
        '''
        global ACTIONS_OPT_METHOD_NAME
        has_action = False
        for action in ACTIONS_OPT_METHOD_NAME:
            value = getattr(opts, action)
            if value is not None:
                has_action = True
        return has_action

    def opts_get_action(self, opts):
        '''
        Gets the selected action from the parsed opts
        '''
        global ACTIONS_OPT_METHOD_NAME
        for action in ACTIONS_OPT_METHOD_NAME:
            value = getattr(opts, action)
            if value is not None:
                return action
        return None

    def check_values(self, opts, args):
        '''
        Validate the option the user has supplied
        '''
        # check if an action has been selected
        if not self.opts_has_action(opts):
            self.print_help()
            raise SystemExit

        # check if action needs a --title option
        action = self.opts_get_action(opts)
        if action in ACTIONS_REQUIRE_TITLE:
            if opts.title is None:
                print 'Action %s requires a --title parameter' % action
                raise SystemExit

        return (opts, args)


class BoottoolApp(object):

    '''
    The boottool application itself
    '''

    def __init__(self):
        self.opts = None
        self.args = None
        self.option_parser = OptionParser()
        self.grubby = None
        self.log = logging.getLogger(self.__class__.__name__)

    def _parse_command_line(self):
        '''
        Parsers the command line arguments
        '''
        (self.opts,
         self.args) = self.option_parser.parse_args()

    def _configure_logging(self):
        '''
        Configures logging based on --debug= command line switch

        We do not have as many levels as the original boottool(.pl) had, but
        we accept the same range of parameters and adjust it to our levels.
        '''
        log_map = {0: logging.WARNING,
                   1: logging.INFO,
                   2: logging.DEBUG}
        try:
            level = int(self.opts.debug)
        except ValueError:
            level = 0

        max_level = max(log_map.keys())
        if level > max_level:
            level = max_level

        if os.environ.has_key('BOOTTOOL_DEBUG_RUN'):
            logging_level = logging.DEBUG
        else:
            logging_level = log_map.get(level)

        logging.basicConfig(level=logging_level,
                            format=LOGGING_FORMAT)

    def run(self):
        self._parse_command_line()
        self._configure_logging()

        # if we made this far, the command line checking succeeded
        if self.opts.grubby_path:
            self.grubby = Grubby(self.opts.grubby_path, self.opts)
        else:
            install_grubby_if_necessary()
            self.grubby = Grubby(opts=self.opts)

        if self.opts.bootloader:
            self.log.debug('Forcing bootloader "%s"', self.opts.bootloader)
            try:
                self.grubby._set_bootloader(self.opts.bootloader)
            except ValueError, msg:
                self.log.error(msg)
                sys.exit(-1)

        #
        # The following implements a simple action -> method dispatcher
        # First, we look for a method named action_ + action_name on the
        # app instance itself. If not found, we try to find a method with
        # the same name as the action in the grubby instance.
        #
        action_name = self.option_parser.opts_get_action(self.opts)
        try:
            action_method = getattr(self, "action_%s" % action_name)
        except AttributeError:
            action_method = getattr(self.grubby, action_name)

        if action_method:
            result = action_method()
            if result is None:
                result = 0
            elif isinstance(result, str):
                print result
                result = 0
            sys.exit(result)

    #
    # The following block implements actions. Actions are methods that will be
    # called because of user supplied parameters on the command line. Most
    # actions, such as the ones that query information, are built around the
    # "API" methods defined in the previous block
    #
    def action_grubby_version(self):
        '''
        Prints the of grubby that is installed on this machine
        '''
        version = self.grubby.get_grubby_version()
        if version is not None:
            print "%s.%s" % version
            return

        version = self.grubby.get_grubby_version_raw()
        if version is not None:
            print version

    def action_grubby_version_check(self):
        '''
        Prints the of grubby that is installed on this machine
        '''
        current_version = self.grubby.get_grubby_version()
        if current_version is None:
            self.log.warn('Could not get version numbers from grubby')
            return -1

        required_version = self.opts.grubby_version_check.split('.', 1)
        required_version_major = required_version[0]
        if len(required_version) == 1:
            req_version = (int(required_version_major), 0)
        else:
            req_version = (int(required_version_major),
                           int(required_version[1]))

        if current_version >= req_version:
            return 0
        else:
            return -1

    def action_grubby_install(self):
        '''
        Attempts to install a recent enough version of grubby
        '''
        return self.grubby.grubby_install()

    def action_info(self):
        '''
        Prints boot entry information

        boottool is frequently called with 'all' lowercase, but
        grubby expects it to be uppercase
        '''
        if not self.opts.info:
            self.log.error('Parameter to info is required')
            return -1

        info_index = self.opts.info
        if not ((info_index.lower() == 'all') or
                (self.opts.info.isdigit())):
            self.log.error('Parameter to info should be either "all", "ALL" '
                           'or an integer index')
            return -1

        if info_index == 'all':
            info_index = 'ALL'

        if info_index == 'ALL':
            entries = self.grubby.get_entries()
        else:
            entries = {info_index: self.grubby.get_entry(info_index)}

        for index, entry in entries.items():
            print
            for key, val in entry.items():
                # remove quotes
                if isinstance(val, str):
                    if val.startswith('"') and val.endswith('"'):
                        val = val[1:-1]

                print '%-8s: %s' % (key, val)

    def action_add_kernel(self):
        '''
        Adds a new boot entry based on the values of other command line options

        :type opts: object
        :param opts: parsed command line options
        :return:
        '''
        if not self.opts.add_kernel:
            self.log.error("Kernel to add is required")
            return -1

        if not self.opts.title:
            self.log.error("Kernel title is required")
            return -1

        if not self.opts.initrd:
            self.log.error("initrd is required")
            return -1

        return self.grubby.add_kernel(self.opts.add_kernel,
                                      self.opts.title,
                                      args=self.opts.args,
                                      initrd=self.opts.initrd)

    def action_update_kernel(self):
        '''
        Updates a kernel entry
        '''
        if not self.opts.update_kernel:
            self.log.error("Kernel title to update is required")
            return -1

        args = []

        kernel = self.grubby._get_entry_selection(self.opts.update_kernel)
        if kernel is not None:
            args.append("--update-kernel=%s" % kernel)

        if self.opts.args:
            args.append("--args=%s" % self.opts.args)

        if self.opts.remove_args:
            args.append("--remove-args=%s" % self.opts.remove_args)

        return self.grubby._run_grubby_get_return(args)

    def action_remove_kernel(self):
        '''
        Removes a boot entry by the specified title

        boottool expects: title
        grubby expects: kernel path or special syntax (eg, TITLE=)
        '''
        if not self.opts.remove_kernel:
            self.log.error("Kernel title to remove is required")
            return -1

        return self.grubby.remove_kernel(self.opts.remove_kernel)

    def action_boot_once(self):
        """
        Sets a specific entry for the next boot only

        The subsequent boots will use the default kernel
        """
        if not self.opts.boot_once:
            self.log.error("Kernel to boot once is required")

        return self.grubby.boot_once(self.opts.title)

    def action_default(self):
        """
        Get the default entry index
        """
        print self.grubby.get_default_index()

    def action_set_default(self):
        """
        Sets the given entry number to be the default on every next boot
        """
        if not self.opts.set_default:
            self.log.error("Entry index is required")

        return self.grubby.set_default_by_index(self.opts.set_default)


if __name__ == '__main__':
    app = BoottoolApp()
    app.run()
else:
    logging.basicConfig(level=logging.INFO,
                        format=LOGGING_FORMAT)

########NEW FILE########
__FILENAME__ = kernelinstall
import os
import logging
import sys
from autotest.client import test
from autotest.client import utils
from autotest.client.shared import git, error, software_manager


class kernelinstall(test.test):
    version = 1
    sm = software_manager.SoftwareManager()

    def _kernel_install_rpm(self, rpm_file, kernel_deps_rpms=None,
                            need_reboot=True):
        """
        Install kernel rpm package.
        The rpm packages should be a url or put in this test's
        directory (client/test/kernelinstall)
        """
        if kernel_deps_rpms:
            logging.info("Installing kernel dependencies.")
            if isinstance(kernel_deps_rpms, list):
                kernel_deps_rpms = " ".join(kernel_deps_rpms)
            self.sm.install(kernel_deps_rpms)

        dst = os.path.join("/tmp", os.path.basename(rpm_file))
        knl = utils.get_file(rpm_file, dst)
        kernel = self.job.kernel(knl)
        logging.info("Installing kernel %s", rpm_file)
        kernel.install(install_vmlinux=False)

        if need_reboot:
            kernel.boot()
        else:
            kernel.add_to_bootloader()

    def _kernel_install_koji(self, kernel_koji_spec, kernel_deps_koji_spec,
                             need_reboot=True):
        # Using hardcoded package names (the names are not expected to change)
        # we avoid lookup errors due to SSL problems, so let's go with that.
        for koji_package in ['koji', 'brewkoji']:
            if not self.sm.check_installed(koji_package):
                logging.debug("%s missing - trying to install", koji_package)
                self.sm.install(koji_package)

        sys.path.append(self.bindir)
        try:
            from staging import utils_koji
        except ImportError:
            from autotest.client.shared import utils_koji
        # First, download packages via koji/brew
        c = utils_koji.KojiClient()

        deps_rpms = []
        k_dep = utils_koji.KojiPkgSpec(text=kernel_deps_koji_spec)
        logging.info('Fetching kernel dependencies: %s', kernel_deps_koji_spec)
        c.get_pkgs(k_dep, self.bindir)
        rpm_file_name_list = c.get_pkg_rpm_file_names(k_dep)
        if len(rpm_file_name_list) == 0:
            raise error.TestError("No packages on brew/koji match spec %s" %
                                  kernel_deps_koji_spec)
        dep_rpm_basename = rpm_file_name_list[0]
        deps_rpms.append(os.path.join(self.bindir, dep_rpm_basename))

        k = utils_koji.KojiPkgSpec(text=kernel_koji_spec)
        logging.info('Fetching kernel: %s', kernel_koji_spec)
        c.get_pkgs(k, self.bindir)
        rpm_file_name_list = c.get_pkg_rpm_file_names(k)
        if len(rpm_file_name_list) == 0:
            raise error.TestError("No packages on brew/koji match spec %s" %
                                  kernel_koji_spec)

        kernel_rpm_basename = rpm_file_name_list[0]
        kernel_rpm_path = os.path.join(self.bindir, kernel_rpm_basename)

        # Then install kernel rpm packages.
        self._kernel_install_rpm(kernel_rpm_path, deps_rpms, need_reboot)

    def _kernel_install_src(self, base_tree, config=None, config_list=None,
                            patch_list=None, need_reboot=True):
        if not utils.is_url(base_tree):
            base_tree = os.path.join(self.bindir, base_tree)
        if not utils.is_url(config):
            config = os.path.join(self.bindir, config)
        kernel = self.job.kernel(base_tree, self.outputdir)
        if patch_list:
            patches = []
            for p in patch_list.split():
                # Make sure all the patches are in local.
                if not utils.is_url(p):
                    continue
                dst = os.path.join(self.bindir, os.path.basename(p))
                local_patch = utils.get_file(p, dst)
                patches.append(local_patch)
            kernel.patch(*patches)
        if not os.path.isfile(config):
            config = None
        if not config and not config_list:
            kernel.config()
        else:
            kernel.config(config, config_list)
        kernel.build()
        kernel.install()

        if need_reboot:
            kernel.boot()
        else:
            kernel.add_to_bootloader()

    def _kernel_install_git(self, repo, config, repo_base=None,
                            branch="master", commit=None, config_list=None,
                            patch_list=None, need_reboot=True):
        repodir = os.path.join("/tmp", 'kernel_src')
        repodir = git.get_repo(uri=repo, branch=branch,
                               destination_dir=repodir,
                               commit=commit, base_uri=repo_base)
        self._kernel_install_src(repodir, config, config_list, patch_list,
                                 need_reboot)

    def execute(self, install_type="koji", params=None):
        need_reboot = params.get("need_reboot") == "yes"

        logging.info("Chose to install kernel through '%s', proceeding",
                     install_type)

        if install_type == "rpm":
            rpm_url = params.get("kernel_rpm_path")
            kernel_deps_rpms = params.get("kernel_deps_rpms", None)

            self._kernel_install_rpm(rpm_url, kernel_deps_rpms, need_reboot)
        elif install_type in ["koji", "brew"]:

            kernel_koji_spec = params.get("kernel_koji_spec")
            kernel_deps_koji_spec = params.get("kernel_deps_koji_spec")

            self._kernel_install_koji(kernel_koji_spec, kernel_deps_koji_spec,
                                      need_reboot)

        elif install_type == "git":
            repo = params.get('kernel_git_repo')
            repo_base = params.get('kernel_git_repo_base', None)
            branch = params.get('kernel_git_branch', "master")
            commit = params.get('kernel_git_commit', None)
            patch_list = params.get("kernel_patch_list", None)
            config = params.get('kernel_config')
            config_list = params.get("kernel_config_list", None)

            self._kernel_install_git(repo, config, repo_base, branch, commit,
                                     config_list, patch_list, need_reboot)
        elif install_type == "tar":
            src_pkg = params.get("kernel_src_pkg")
            config = params.get('kernel_config')
            patch_list = params.get("kernel_patch_list", None)

            self._kernel_install_src(src_pkg, config, None, patch_list,
                                     need_reboot)
        else:
            logging.error("Could not find '%s' method, "
                          "keep the current kernel.", install_type)

########NEW FILE########
__FILENAME__ = cb
import pygtk
pygtk.require('2.0')
import gtk
import sys
import os
from optparse import OptionParser


def return_nonrandom_str(length):
    """
    A method to return a nonrandom_string of the length determined by the input

    :param length, length of the string to be returned
    """
    input_string = "anonrandomstring_"
    finalstring = ""
    str_len = len(input_string)

    for i in xrange(int(length)):
        finalstring += input_string[i % str_len]

    return finalstring


def main(argv):
    '''
    usage to set image file in clipboard:     python clipboard.py --set <path>
    usage to get image file in clipboard:     python clipboard.py
    '''

    # Command line parser alternative
    parser = OptionParser()
    parser.add_option("-c", "--clear", dest="clear",
                      action="store_true", help="clear the clipboard")
    parser.add_option("-s", "--set", dest="setcb",
                      default='', help="Sets the local clip board")
    parser.add_option("-p", "--print", dest="setcb",
                      default='', help="Prints the text that was set")
    parser.add_option("-i", "--set_image", dest="setcbimage",
                      default='', help="Sets an image to local clip board")
    parser.add_option("-m", help="Saves an image to the /tmp directory",
                      dest="setfilename")
    parser.add_option("-r", "--file_copy", dest="setcb_file",
                      default='', help="Creates a file, Reads the text from " +
                      "a file and puts it onto the clipboard")
    parser.add_option("-f", "--file_paste", dest="pastecb_filename",
                      default='', help="Given a filename, the clipboard " +
                      "contents will be pasted")
    parser.add_option("-n", "--create_file", dest="setcb_lrgstr_file",
                      default='', help="Given a integer value a file will " +
                      "be created and put on the clipboard")

    # Read the command line parameters now
    (options, _) = parser.parse_args()

    # Get the clipboard
    clipboard = gtk.clipboard_get()

    if options.setcb:

        ssetcb = options.setcb
        # Set the clipboard text data
        clipboard.set_text(ssetcb)

        # Make our data available to other applicatons
        clipboard.store()
        print 'The text has been placed into the clipboard.'
    elif options.setfilename:
        # Read the clipboard image data.

        # Is there an image
        print "Is there an image: " + str(clipboard.wait_is_image_available())

        image = clipboard.wait_for_image()
        if image is None:
            print 'No image stored'
        else:
            location_to_save = options.setfilename
            image.save(location_to_save, 'png')
            print 'Cb Image stored and saved to: ' + options.setfilename
    elif options.setcbimage:
        ssetcb = options.setcbimage
        print ssetcb

        # Set the clipboard text data
        assert os.path.exists(ssetcb), "file does not exist"
        image = gtk.image_new_from_file(ssetcb).get_pixbuf()
        clipboard.set_image(image)

        # Make our data available to other applications
        clipboard.store()
        print 'The image has been placed into the clipboard.'
    elif options.clear:
        # Get and clear the clipboard
        clipboard.set_text("")
        clipboard.store()
        print 'The clipboard has been cleared.'
    elif options.setcb_file:
        # Read a file and put the contents into the clipboard
        file_contents = open(options.setcb_file, 'r')
        clipboard.set_text(file_contents.read())
        file_contents.close()
        clipboard.store()
    elif options.pastecb_filename:
        # Get the text from the clipboard and write to a file
        print 'Getting the text from the clipboard'
        clipboard_text = clipboard.wait_for_text()
        print ('Starting to write the clipboard text to the file' +
               options.pastecb_filename)
        file_contents = open(options.pastecb_filename, 'w')
        file_contents.write(clipboard_text)
        print 'Writing of the clipboard text is complete'
        file_contents.close()
    elif options.setcb_lrgstr_file:
        # Create a non-random string of the size specified and write it to
        # a file and put it on the clipboard.
        finalstring = return_nonrandom_str(int(options.setcb_lrgstr_file))
        file_contents = open("/tmp/StringLengthTest.txt", 'w')
        file_contents.write(finalstring)
        file_contents.close()
        file_contents = open("/tmp/StringLengthTest.txt", 'r')
        clipboard.set_text(file_contents.read())
        file_contents.close()
        print ("Non random string put into file: /tmp/StringLengthTest. " +
               " The string has also been placed in the clipboard. " +
               "String of size " + options.setcb_lrgstr_file)
        clipboard.store()
    else:
        # Read the clipboard text data.
        text = clipboard.wait_for_text()
        print 'clipboard=' + str(text)

if __name__ == "__main__":
    main(sys.argv[1:])
    sys.exit(0)

########NEW FILE########
__FILENAME__ = check_cpu_flag
#!/usr/bin/python
import os
import sys


class check_error(Exception):
    pass


def check_cpu_flag():
    cpuinfo = file('/proc/cpuinfo').read()
    flags = os.environ['KVM_TEST_required_cpu_flags']
    for i in flags.split():
        if i not in cpuinfo:
            err_msg = "Host CPU doestn't have flag(%s)" % i
            print err_msg
            raise check_error(err_msg)

if __name__ == "__main__":
    check_cpu_flag()

########NEW FILE########
__FILENAME__ = cmd_runner
"""
This script is used to execute a program and collect the monitor
information in background, redirect the outputs to log files.
"""

import threading
import shelve
import commands
import re
import os
import sys
import random
import string


class Runner(object):

    def __init__(self):
        """
        Set the global parameter for thread clean up
        """
        self.kill_thread_flag = False

    def monitor_thread(self, m_cmd, p_file, r_path):
        """
        Record the parent process id and start the monitor process
        in background
        """
        fd = shelve.open(p_file)
        fd["pid"] = os.getpid()
        fd.close()
        commands.getoutput("%s &> %s_monitor" % (m_cmd, r_path))

    def thread_kill(self, cmd, p_file):
        """
        Kill the process according to its parent pid and command
        """
        fd = shelve.open(p_file)
        _, o = commands.getstatusoutput("pstree -p %s" % fd["pid"])
        try:
            tmp = cmd.split()[0]
            pid = re.findall("%s.(\d+)" % tmp, o)[0]
        except IndexError:
            return (0, "")
        s, o = commands.getstatusoutput("kill -9 %s" % pid)
        fd.close()
        return (s, o)

    def test_thread(self, m_cmd, t_cmd, p_file):
        """
        Test thread
        """
        self.kill_thread_flag = True
        s, o = commands.getstatusoutput(t_cmd)
        if s != 0:
            print "Test failed or timeout: %s" % o
        if self.kill_thread_flag:
            s, o = self.thread_kill(m_cmd, p_file)
            if s != 0:
                print "Monitor process is still alive, %s" % o
            else:
                self.kill_thread_flag = False

    def run(self, m_cmd, t_cmd, r_path, timeout):
        """
        Main thread for testing, will do clean up afterwards
        """
        pid_file = "/tmp/pid_file_%s" % "".join(random.sample(string.letters,
                                                              4))
        monitor = threading.Thread(target=self.monitor_thread, args=(m_cmd,
                                                                     pid_file, r_path))
        test_runner = threading.Thread(target=self.test_thread, args=(m_cmd,
                                                                      t_cmd, pid_file))

        monitor.start()
        test_runner.start()
        monitor.join(timeout)
        if self.kill_thread_flag:
            self.thread_kill(m_cmd, pid_file)
            self.thread_kill(t_cmd, pid_file)
            self.kill_thread_flag = False


if __name__ == '__main__':
    if len(sys.argv) < 4:
        this = os.path.basename(sys.argv[0])
        print "Usage: %s <monitor_cmd> <test_cmd> <test_path> <timeout>" % this
        sys.exit(1)

    monitor_cmd = sys.argv[1]
    test_cmd = sys.argv[2]
    test_path = sys.argv[3]
    test_cmd = test_cmd % test_path
    timeout = int(sys.argv[4])
    r = Runner()
    r.run(monitor_cmd, test_cmd, test_path, timeout)

########NEW FILE########
__FILENAME__ = key_event_form
import gtk
import logging


class TestForm(gtk.Window):

    def __init__(self):
        super(TestForm, self).__init__()

        self.set_title("Key test")
        self.set_size_request(200, 200)
        self.set_position(gtk.WIN_POS_CENTER)

        fixed = gtk.Fixed()

        entry = gtk.Entry()
        fixed.put(entry, 10, 10)

        entry.connect("key_press_event", self.on_key_press_event)

        self.connect("destroy", gtk.main_quit)
        self.add(fixed)
        self.show_all()

        # Clean the text file:
        input_file = open("/tmp/autotest-rv_input", "w")
        input_file.close()

    def on_key_press_event(self, widget, event):
        # Store caught keycodes into text file
        input_file = open("/tmp/autotest-rv_input", "a")
        input_file.write("{0} ".format(event.keyval))
        input_file.close()

if __name__ == "__main__":
    TestForm()
    gtk.main()

########NEW FILE########
__FILENAME__ = ksm_overcommit_guest
#!/usr/bin/python
# -*- coding: utf-8 -*-
"""
Auxiliary script used to allocate memory on guests.

:copyright: 2008-2009 Red Hat Inc.
:author: Jiri Zupka (jzupka@redhat.com)
"""


import os
import array
import sys
import random
import copy
import tempfile
import datetime
import math

PAGE_SIZE = 4096  # machine page size

TMPFS_OVERHEAD = 0.0022  # overhead on 1MB of write data


class MemFill(object):

    """
    Fills guest memory according to certain patterns.
    """

    def __init__(self, mem, static_value, random_key):
        """
        Constructor of MemFill class.

        :param mem: Amount of test memory in MB.
        :param random_key: Seed of random series used for fill up memory.
        :param static_value: Value used to fill all memory.
        """
        if (static_value < 0 or static_value > 255):
            print ("FAIL: Initialization static value"
                   "can be only in range (0..255)")
            return

        self.tmpdp = tempfile.mkdtemp()
        tmpfs_size = mem + math.ceil(mem * TMPFS_OVERHEAD)
        ret_code = os.system("mount -o size=%dM tmpfs %s -t tmpfs" %
                             (tmpfs_size, self.tmpdp))
        if ret_code != 0:
            if os.getuid() != 0:
                print ("FAIL: Unable to mount tmpfs "
                       "(likely cause: you are not root)")
            else:
                print "FAIL: Unable to mount tmpfs"
        else:
            self.f = tempfile.TemporaryFile(prefix='mem', dir=self.tmpdp)
            self.allocate_by = 'L'
            self.npages = ((mem * 1024 * 1024) / PAGE_SIZE)
            self.random_key = random_key
            self.static_value = static_value
            print "PASS: Initialization (tmpfs size: %dM)" % tmpfs_size

    def __del__(self):
        if os.path.ismount(self.tmpdp):
            self.f.close()
            os.system("umount %s" % (self.tmpdp))

    def compare_page(self, original, inmem):
        """
        Compare pages of memory and print the differences found.

        :param original: Data that was expected to be in memory.
        :param inmem: Data in memory.
        """
        for ip in range(PAGE_SIZE / original.itemsize):
            if (not original[ip] == inmem[ip]):  # find which item is wrong
                originalp = array.array("B")
                inmemp = array.array("B")
                originalp.fromstring(original[ip:ip + 1].tostring())
                inmemp.fromstring(inmem[ip:ip + 1].tostring())
                for ib in range(len(originalp)):  # find wrong byte in item
                    if not (originalp[ib] == inmemp[ib]):
                        position = (self.f.tell() - PAGE_SIZE + ip *
                                    original.itemsize + ib)
                        print ("Mem error on position %d wanted 0x%Lx and is "
                               "0x%Lx" % (position, originalp[ib], inmemp[ib]))

    def value_page(self, value):
        """
        Create page filled by value.

        :param value: String we want to fill the page with.
        :return: return array of bytes size PAGE_SIZE.
        """
        a = array.array("B")
        for _ in range((PAGE_SIZE / a.itemsize)):
            try:
                a.append(value)
            except Exception:
                print "FAIL: Value can be only in range (0..255)"
        return a

    def random_page(self, seed):
        """
        Create page filled by static random series.

        :param seed: Seed of random series.
        :return: Static random array series.
        """
        random.seed(seed)
        a = array.array(self.allocate_by)
        for _ in range(PAGE_SIZE / a.itemsize):
            a.append(random.randrange(0, sys.maxint))
        return a

    def value_fill(self, value=None):
        """
        Fill memory page by page, with value generated with value_page.

        :param value: Parameter to be passed to value_page. None to just use
                what's on the attribute static_value.
        """
        self.f.seek(0)
        if value is None:
            value = self.static_value
        page = self.value_page(value)
        for _ in range(self.npages):
            page.tofile(self.f)
        print "PASS: Mem value fill"

    def value_check(self, value=None):
        """
        Check memory to see if data is correct.

        :param value: Parameter to be passed to value_page. None to just use
                what's on the attribute static_value.
        :return: if data in memory is correct return PASS
                else print some wrong data and return FAIL
        """
        self.f.seek(0)
        e = 2
        failure = False
        if value is None:
            value = self.static_value
        page = self.value_page(value)
        for _ in range(self.npages):
            pf = array.array("B")
            pf.fromfile(self.f, PAGE_SIZE / pf.itemsize)
            if not (page == pf):
                failure = True
                self.compare_page(page, pf)
                e = e - 1
                if e == 0:
                    break
        if failure:
            print "FAIL: value verification"
        else:
            print "PASS: value verification"

    def static_random_fill(self, n_bytes_on_end=PAGE_SIZE):
        """
        Fill memory by page with static random series with added special value
        on random place in pages.

        :param n_bytes_on_end: how many bytes on the end of page can be changed.
        :return: PASS.
        """
        self.f.seek(0)
        page = self.random_page(self.random_key)
        random.seed(self.random_key)
        p = copy.copy(page)

        t_start = datetime.datetime.now()
        for pages in range(self.npages):
            rand = random.randint(((PAGE_SIZE / page.itemsize) - 1) -
                                  (n_bytes_on_end / page.itemsize),
                                  (PAGE_SIZE / page.itemsize) - 1)
            p[rand] = pages
            p.tofile(self.f)
            p[rand] = page[rand]

        t_end = datetime.datetime.now()
        delta = t_end - t_start
        milisec = delta.microseconds / 1e3 + delta.seconds * 1e3
        print "PASS: filling duration = %Ld ms" % milisec

    def static_random_verify(self, n_bytes_on_end=PAGE_SIZE):
        """
        Check memory to see if it contains correct contents.

        :return: if data in memory is correct return PASS
                else print some wrong data and return FAIL.
        """
        self.f.seek(0)
        e = 2
        page = self.random_page(self.random_key)
        random.seed(self.random_key)
        p = copy.copy(page)
        failure = False
        for pages in range(self.npages):
            rand = random.randint(((PAGE_SIZE / page.itemsize) - 1) -
                                  (n_bytes_on_end / page.itemsize),
                                  (PAGE_SIZE / page.itemsize) - 1)
            p[rand] = pages
            pf = array.array(self.allocate_by)
            pf.fromfile(self.f, PAGE_SIZE / pf.itemsize)
            if not (p == pf):
                failure = True
                self.compare_page(p, pf)
                e = e - 1
                if e == 0:
                    break
            p[rand] = page[rand]
        if failure:
            print "FAIL: Random series verification"
        else:
            print "PASS: Random series verification"


def die():
    """
    Quit allocator.
    """
    sys.exit(0)


def main():
    """
    Main (infinite) loop of allocator.
    """
    print "PASS: Start"
    end = False
    while not end:
        sr = raw_input()
        exec sr


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = multicast_guest
#!/usr/bin/python
import socket
import struct
import os
import signal
import sys
# -*- coding: utf-8 -*-

"""
Script used to join machine into multicast groups.

:author Amos Kong <akong@redhat.com>
"""

if __name__ == "__main__":
    if len(sys.argv) < 4:
        print """%s [mgroup_count] [prefix] [suffix]
        mgroup_count: count of multicast addresses
        prefix: multicast address prefix
        suffix: multicast address suffix""" % sys.argv[0]
        sys.exit()

    mgroup_count = int(sys.argv[1])
    prefix = sys.argv[2]
    suffix = int(sys.argv[3])

    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    for i in range(mgroup_count):
        mcast = prefix + "." + str(suffix + i)
        try:
            mreq = struct.pack("4sl", socket.inet_aton(mcast),
                               socket.INADDR_ANY)
            s.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
        except Exception:
            s.close()
            print "Could not join multicast: %s" % mcast
            raise

    print "join_mcast_pid:%s" % os.getpid()
    os.kill(os.getpid(), signal.SIGSTOP)
    s.close()

########NEW FILE########
__FILENAME__ = netperf_agent
#!/usr/bin/python
"""
:author Amos Kong <akong@redhat.com>

"""
import os
import sys
import time

if len(sys.argv) < 4:
    print """ netperf agent usage:
    %s [session_number] [netperf_path] [netperf_parameters_str]

    $session_number: number of client sessions
    $netperf_path: client path
    $netperf_parameter_str: netperf parameters string""" % sys.argv[0]
    sys.exit()

n = int(sys.argv[1])
path = sys.argv[2]
params = " ".join(sys.argv[3:])

for i in range(n - 1):
    os.system("%s %s &" % (path, params))
os.system("%s %s" % (path, params))

########NEW FILE########
__FILENAME__ = set_win_promisc
import socket
import time
HOST = socket.gethostbyname(socket.gethostname())
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
s.bind((HOST, 0))

s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
time.sleep(2)
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
time.sleep(2)

########NEW FILE########
__FILENAME__ = virtio_console_guest
#!/usr/bin/python
# -*- coding: utf-8 -*-
"""
Auxiliary script used to send data between ports on guests.

:copyright: 2010 Red Hat, Inc.
:author: Jiri Zupka (jzupka@redhat.com)
:author: Lukas Doktor (ldoktor@redhat.com)
"""
import threading
from threading import Thread
import os
import select
import re
import random
import sys
import array
import stat
import traceback
import signal
import time

if os.name == "posix":  # Linux
    os_linux = True
    import fcntl
else:   # Windows
    os_linux = False
    try:
        import win32file
    except ImportError, failure_detail:
        print "Import failed. Do you have ctypes and pywin32 installed?"
        raise failure_detail

DEBUGPATH = "/sys/kernel/debug"
SYSFSPATH = "/sys/class/virtio-ports/"
DEVPATH = "/dev/virtio-ports/"

exiting = False
virt = None


class VirtioGuest:

    """
    Test tools of virtio_ports.
    """
    LOOP_NONE = 0
    LOOP_POLL = 1
    LOOP_SELECT = 2
    LOOP_RECONNECT_NONE = 3

    def __init__(self):
        self.files = {}
        self.exit_thread = threading.Event()
        self.threads = []
        self.ports = {}
        self.poll_fds = {}
        self.catch_signal = None
        self.use_config = threading.Event()

    def init(self, in_files):
        """
        Init and check port properties.
        """
        raise NotImplementedError

    def _open(self, in_files):
        """
        Open devices and return array of descriptors

        :param in_files: Files array
        :return: Array of descriptor
        """
        raise NotImplementedError

    def check_zero_sym(self):
        """
        Check if port the first port symlinks were created.
        """
        raise NotImplementedError

    def poll(self, port, expected, timeout=500):
        """
        Checks the port POLL status and verify with expected results.

        :param port: Port name.
        :param expected: Expected POLL status (mask)
        """
        raise NotImplementedError

    def lseek(self, port, pos, how):
        """
        Use lseek on the device. The device is unseekable so PASS is returned
        when lseek command fails and vice versa.

        :param port: Name of the port
        :param pos: Offset
        :param how: Relative offset os.SEEK_{SET,CUR,END}
        """
        raise NotImplementedError

    def blocking(self, port, mode=False):
        """
        Set port function mode blocking/nonblocking

        :param port: port to set mode
        :param mode: False to set nonblock mode, True for block mode
        """
        raise NotImplementedError

    def async(self, port, mode=True, exp_val=0):
        """
        Set port function mode async/sync.

        :param port: port which should be pooled.
        :param mode: False to set sync mode, True for sync mode.
        :param exp_val: Value which should be pooled.
        """
        raise NotImplementedError

    def close(self, port_file):
        """
        Close open port.

        :param port_file: File to close.
        """
        raise NotImplementedError

    def open(self, in_file):
        """
        Direct open devices.

        :param in_file: Array of files.
        :return: Array of descriptors.
        """
        raise NotImplementedError

    def loopback(self, in_files, out_files, cachesize=1024,
                 mode=0):
        """
        Start a switch thread.

        (There is a problem with multiple opens of a single file).

        :param in_files: Array of input files.
        :param out_files: Array of output files.
        :param cachesize: Cachesize.
        :param mode: Mode of switch.
        """
        in_f = self._open(in_files)
        out_f = self._open(out_files)

        s = self.Switch(in_f, out_f, self.exit_thread, cachesize, mode)
        s.start()
        self.threads.append(s)
        print "PASS: Start switch"

    def exit_threads(self):
        """
        Function end all running data switch.
        """
        raise NotImplementedError

    def send_loop_init(self, port, length):
        """
        Prepares the sender thread. Requires clean thread structure.

        :param port: On which port to sent data
        :param length: length of data
        """
        raise NotImplementedError

    def send_loop(self):
        """
        Start sender data transfer. Requires senderprepare run first.
        """
        raise NotImplementedError

    def send(self, port, length=1, mode=True, is_static=False):
        """
        Send a data of arbitrary length

        :param port: Port to write data
        :param length: Length of data
        :param mode: True = loop mode, False = one shoot mode
        :param is_static: False = generates $length long block (mode=0)
                          True = generates 4096 long block (faster, mode=1)
        """
        raise NotImplementedError

    def recv(self, port, length=1, bfr=1024, mode=True):
        """
        Receive a data of arbitrary length.

        :param port: Port to write data
        :param length: Length of data
        :param mode: True = loop mode, False = one shoot mode
        """
        raise NotImplementedError

    def clean_port(self, port, bfr=1024):
        raise NotImplementedError


class VirtioGuestPosix(VirtioGuest):

    """
    Test tools of virtio_ports.
    """

    def _readfile(self, name):
        """
        Read file and return content as string

        :param name: Name of file
        :return: Content of file as string
        """
        out = ""
        try:
            f = open(name, "r")
            out = f.read()
            f.close()
        except Exception:
            print "FAIL: Cannot open file %s" % (name)

        return out

    def _get_port_status(self, in_files=None):
        """
        Get info about ports from kernel debugfs.

        :param in_files: Array of input files.
        :return: Ports dictionary of port properties
        """
        ports = {}
        not_present_msg = "FAIL: There's no virtio-ports dir in debugfs"
        if not os.path.ismount(DEBUGPATH):
            os.system('mount -t debugfs none %s' % (DEBUGPATH))
        try:
            if not os.path.isdir('%s/virtio-ports' % (DEBUGPATH)):
                print not_present_msg
        except Exception:
            print not_present_msg
        else:
            viop_names = os.listdir('%s/virtio-ports' % (DEBUGPATH))
            if in_files is not None:
                dev_names = os.listdir('/dev')
                rep = re.compile(r"vport[0-9]p[0-9]+")
                dev_names = filter(
                    lambda x: rep.match(x) is not None, dev_names)
                if len(dev_names) != len(in_files):
                    print ("FAIL: Not all ports were successfully initialized "
                           "in /dev, only %d from %d." % (len(dev_names),
                                                          len(in_files)))
                    return

                if len(viop_names) != len(in_files):
                    print ("FAIL: Not all ports were successfully initialized "
                           "in debugfs, only %d from %d." % (len(viop_names),
                                                             len(in_files)))
                    return

            for name in viop_names:
                open_db_file = "%s/virtio-ports/%s" % (DEBUGPATH, name)
                f = open(open_db_file, 'r')
                port = {}
                line_list = []
                for line in iter(f):
                    line_list.append(line)
                try:
                    for line in line_list:
                        m = re.match("(\S+): (\S+)", line)
                        port[m.group(1)] = m.group(2)

                    if port['is_console'] == "yes":
                        port["path"] = "/dev/hvc%s" % (port["console_vtermno"])
                        # Console works like a serialport
                    else:
                        port["path"] = "/dev/%s" % name

                    if not os.path.exists(port['path']):
                        print "FAIL: %s not exist" % port['path']

                    sysfspath = SYSFSPATH + name
                    if not os.path.isdir(sysfspath):
                        print "FAIL: %s not exist" % (sysfspath)

                    info_name = sysfspath + "/name"
                    port_name = self._readfile(info_name).strip()
                    if port_name != port["name"]:
                        print ("FAIL: Port info does not match "
                               "\n%s - %s\n%s - %s" %
                               (info_name, port_name,
                                "%s/virtio-ports/%s" % (DEBUGPATH, name),
                                port["name"]))
                    dev_ppath = DEVPATH + port_name
                    if not os.path.exists(dev_ppath):
                        print "FAIL: Symlink %s does not exist." % dev_ppath
                    if not os.path.realpath(dev_ppath) != "/dev/name":
                        print "FAIL: Symlink %s is not correct." % dev_ppath
                except AttributeError:
                    print ("Bad data on file %s:\n%s. " %
                           (open_db_file, "".join(file).strip()))
                    print "FAIL: Bad data on file %s." % open_db_file
                    return

                ports[port['name']] = port
                f.close()

        return ports

    def check_zero_sym(self):
        """
        Check if port /dev/vport0p0 was created.
        """
        symlink = "/dev/vport0p0"
        if os.path.exists(symlink):
            print "PASS: Symlink %s exists." % symlink
        else:
            print "FAIL: Symlink %s does not exist." % symlink

    def init(self, in_files):
        """
        Init and check port properties.
        """
        self.ports = self._get_port_status(in_files)

        if self.ports is None:
            return
        for item in in_files:
            if (item[1] != self.ports[item[0]]["is_console"]):
                print self.ports
                print "FAIL: Host console is not like console on guest side\n"
                return

        print "PASS: Init and check virtioconsole files in system."

    class Switch(Thread):

        """
        Thread that sends data between ports.
        """

        def __init__(self, in_files, out_files, event,
                     cachesize=1024, method=0):
            """
            :param in_files: Array of input files.
            :param out_files: Array of output files.
            :param method: Method of read/write access.
            :param cachesize: Block to receive and send.
            """
            Thread.__init__(self, name="Switch")
            self.in_files = in_files[0]
            self.in_names = in_files[1]
            self.out_files = out_files[0]
            self.out_names = out_files[1]
            self.exit_thread = event
            self.method = method

            self.cachesize = cachesize

        def _none_mode(self):
            """
            Read and write to device in blocking mode
            """
            data = ""
            while not self.exit_thread.isSet():
                data = ""
                for desc in self.in_files:
                    data += os.read(desc, self.cachesize)
                if data != "":
                    for desc in self.out_files:
                        os.write(desc, data)

        def _poll_mode(self):
            """
            Read and write to device in polling mode.
            """

            pi = select.poll()
            po = select.poll()

            for fd in self.in_files:
                pi.register(fd, select.POLLIN)

            for fd in self.out_files:
                po.register(fd, select.POLLOUT)

            while not self.exit_thread.isSet():
                data = ""
                t_out = self.out_files

                readyf = pi.poll(1.0)
                for i in readyf:
                    data += os.read(i[0], self.cachesize)

                if data != "":
                    while ((len(t_out) != len(readyf)) and not
                           self.exit_thread.isSet()):
                        readyf = po.poll(1.0)
                    for desc in t_out:
                        os.write(desc, data)

        def _select_mode(self):
            """
            Read and write to device in selecting mode.
            """
            while not self.exit_thread.isSet():
                ret = select.select(self.in_files, [], [], 1.0)
                data = ""
                if ret[0] != []:
                    for desc in ret[0]:
                        data += os.read(desc, self.cachesize)
                if data != "":
                    ret = select.select([], self.out_files, [], 1.0)
                    while ((len(self.out_files) != len(ret[1])) and not
                           self.exit_thread.isSet()):
                        ret = select.select([], self.out_files, [], 1.0)
                    for desc in ret[1]:
                        os.write(desc, data)

        def _reconnect_none_mode(self):
            """
            Read and write to device in blocking mode, close and reopen device
            when it get OSError.
            This is workaround for hotplugging of virtio port.
            """
            # TODO: Remove port unplugging after failure from guest_worker
            #       when bz796048 is resolved.
            data = ""
            while not self.exit_thread.isSet():
                data = ""
                for i in xrange(len(self.in_files)):
                    if self.exit_thread.isSet():
                        break
                    desc = self.in_files[i]
                    try:
                        data += os.read(desc, self.cachesize)
                    except OSError, inst:
                        if inst.errno == 9:
                            # Wait 0.1 before spoiling output with additional
                            # log information.
                            # time.sleep(0.5)
                            sys.stdout.write("FD closed, readerr %s\n" % inst)
                            while self.in_names[i] not in virt.files:
                                pass
                            self.in_files[i] = virt.files[self.in_names[i]]
                        else:
                            sys.stdout.write("Missing device, readerr %s\n"
                                             % inst)
                            _desc = desc
                            for item in virt.files.iteritems():
                                if item[1] == desc:
                                    path = item[0]
                                    break
                            for item in virt.ports.iteritems():
                                if item[1]['path'] == path:
                                    name = item[0]
                                    break
                            virt.close(name)
                            while not self.exit_thread.isSet():
                                try:
                                    desc = virt._open([name])[0]
                                    sys.stdout.write("PASS: Opened %s\n"
                                                     % name)
                                    break
                                except OSError:
                                    pass
                            self.in_files[self.in_files.index(_desc)] = desc
                if data != "":
                    for i in xrange(len(self.out_files)):
                        if self.exit_thread.isSet():
                            break
                        desc = self.out_files[i]
                        written = False
                        while not written:
                            try:
                                if self.exit_thread.isSet():
                                    break
                                os.write(desc, data)
                                written = True
                            except OSError, inst:
                                if inst.errno == 9:
                                    # Wait 0.1 before spoiling output with
                                    # additional log information.
                                    # time.sleep(0.5)
                                    sys.stdout.write("FD closed, writeerr %s\n"
                                                     % inst)
                                    while self.out_names[i] not in virt.files:
                                        pass
                                    self.out_files[i] = virt.files[
                                        self.out_names[i]]
                                else:
                                    sys.stdout.write("Missing device, writeerr"
                                                     " %s\n" % inst)
                                    _desc = desc
                                    for item in virt.files.iteritems():
                                        if item[1] == desc:
                                            path = item[0]
                                            break
                                    for item in virt.ports.iteritems():
                                        if item[1]['path'] == path:
                                            name = item[0]
                                            break
                                    virt.close(name)
                                    while not self.exit_thread.isSet():
                                        try:
                                            desc = virt._open([name])[0]
                                            sys.stdout.write("PASS: Opened "
                                                             "%s\n" % name)
                                            break
                                        except OSError:
                                            pass
                                    _desc = self.out_files.index(_desc)
                                    self.out_files[_desc] = desc

        def run(self):
            if (self.method == VirtioGuest.LOOP_POLL):
                self._poll_mode()
            elif (self.method == VirtioGuest.LOOP_SELECT):
                self._select_mode()
            elif (self.method == VirtioGuest.LOOP_RECONNECT_NONE):
                self._reconnect_none_mode()
            elif (self.method == VirtioGuest.LOOP_NONE):
                self._none_mode()
            else:
                print "WARNIGN: Unknown mode %s, using LOOP_NONE" % self.method
                self._reconnect_none_mode()

    class Sender(Thread):

        """
        Creates a thread which sends random blocks of data to dst port.
        """

        def __init__(self, port, event, length):
            """
            :param port: Destination port
            :param length: Length of the random data block
            """
            Thread.__init__(self, name="Sender")
            self.port = port
            self.exit_thread = event
            self.data = array.array('L')
            for _ in range(max(length / self.data.itemsize, 1)):
                self.data.append(random.randrange(sys.maxint))

        def run(self):
            while not self.exit_thread.isSet():
                os.write(self.port, self.data)

    def _open(self, in_files):
        """
        Open devices and return array of descriptors

        :param in_files: Files array
        :return: Array of descriptor
        """
        f = []

        for item in in_files:
            path = self.ports[item]["path"]
            if (path in self.files):
                f.append(self.files[path])
            else:
                try:
                    self.files[path] = os.open(path, os.O_RDWR)
                    if (self.ports[item]["is_console"] == "yes"):
                        print os.system("stty -F %s raw -echo" % (path))
                        print os.system("stty -F %s -a" % (path))
                    f.append(self.files[path])
                except Exception, inst:
                    print "FAIL: Failed to open file %s" % (path)
                    raise inst
        return f

    @staticmethod
    def pollmask_to_str(mask):
        """
        Conver pool mast to string

        :param mask: poll return mask
        """
        out = ""
        if (mask & select.POLLIN):
            out += "IN "
        if (mask & select.POLLPRI):
            out += "PRI IN "
        if (mask & select.POLLOUT):
            out += "OUT "
        if (mask & select.POLLERR):
            out += "ERR "
        if (mask & select.POLLHUP):
            out += "HUP "
        if (mask & select.POLLMSG):
            out += "MSG "
        return out

    def poll(self, port, expected, timeout=500):
        """
        Pool event from device and print event like text.

        :param file: Device.
        """
        in_f = self._open([port])

        p = select.poll()
        p.register(in_f[0])

        mask = p.poll(timeout)

        maskstr = self.pollmask_to_str(mask[0][1])
        if (mask[0][1] & expected) == expected:
            print "PASS: Events: " + maskstr
        else:
            emaskstr = self.pollmask_to_str(expected)
            print "FAIL: Events: " + maskstr + "  Expected: " + emaskstr

    def lseek(self, port, pos, how):
        """
        Use lseek on the device. The device is unseekable so PASS is returned
        when lseek command fails and vice versa.

        :param port: Name of the port
        :param pos: Offset
        :param how: Relative offset os.SEEK_{SET,CUR,END}
        """
        fd = self._open([port])[0]

        try:
            os.lseek(fd, pos, how)
        except Exception, inst:
            if inst.errno == 29:
                print "PASS: the lseek failed as expected"
            else:
                print inst
                print "FAIL: unknown error"
        else:
            print "FAIL: the lseek unexpectedly passed"

    def blocking(self, port, mode=False):
        """
        Set port function mode blocking/nonblocking

        :param port: port to set mode
        :param mode: False to set nonblock mode, True for block mode
        """
        fd = self._open([port])[0]

        try:
            fl = fcntl.fcntl(fd, fcntl.F_GETFL)
            if not mode:
                fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
            else:
                fcntl.fcntl(fd, fcntl.F_SETFL, fl & ~os.O_NONBLOCK)

        except Exception, inst:
            print "FAIL: Setting (non)blocking mode: " + str(inst)
            return

        if mode:
            print "PASS: set to blocking mode"
        else:
            print "PASS: set to nonblocking mode"

    def __call__(self, sig, frame):
        """
        Call function. Used for signal handle.
        """
        if (sig == signal.SIGIO):
            self.sigio_handler(sig, frame)

    def sigio_handler(self, sig, frame):
        """
        Handler for sigio operation.

        :param sig: signal which call handler.
        :param frame: frame of caller
        """
        if self.poll_fds:
            p = select.poll()
            map(p.register, self.poll_fds.keys())

            masks = p.poll(1)
            print masks
            for mask in masks:
                self.poll_fds[mask[0]][1] |= mask[1]

    def get_sigio_poll_return(self, port):
        """
        Return PASS, FAIL and poll walue in string format.

        :param port: Port to check poll information.
        """
        fd = self._open([port])[0]

        maskstr = self.pollmask_to_str(self.poll_fds[fd][1])
        if (self.poll_fds[fd][0] ^ self.poll_fds[fd][1]):
            emaskstr = self.pollmask_to_str(self.poll_fds[fd][0])
            print "FAIL: Events: " + maskstr + "  Expected: " + emaskstr
        else:
            print "PASS: Events: " + maskstr
        self.poll_fds[fd][1] = 0

    def set_pool_want_return(self, port, poll_value):
        """
        Set value to static variable.

        :param port: Port which should be set excepted mask
        :param poll_value: Value to check sigio signal.
        """
        fd = self._open([port])[0]
        self.poll_fds[fd] = [poll_value, 0]
        print "PASS: Events: " + self.pollmask_to_str(poll_value)

    def catching_signal(self):
        """
        return: True if should set catch signal, False if ignore signal and
                none when configuration is not changed.
        """
        ret = self.catch_signal
        self.catch_signal = None
        return ret

    def async(self, port, mode=True, exp_val=0):
        """
        Set port function mode async/sync.

        :param port: port which should be pooled.
        :param mode: False to set sync mode, True for sync mode.
        :param exp_val: Value which should be pooled.
        """
        fd = self._open([port])[0]

        try:
            fcntl.fcntl(fd, fcntl.F_SETOWN, os.getpid())
            fl = fcntl.fcntl(fd, fcntl.F_GETFL)

            self.use_config.clear()
            if mode:
                self.catch_signal = True
                os.kill(os.getpid(), signal.SIGUSR1)
                self.use_config.wait()
                fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_ASYNC)
                self.poll_fds[fd] = [exp_val, 0]
            else:
                del self.poll_fds[fd]
                fcntl.fcntl(fd, fcntl.F_SETFL, fl & ~os.O_ASYNC)
                self.catch_signal = False
                os.kill(os.getpid(), signal.SIGUSR1)
                self.use_config.wait()

        except Exception, inst:
            print "FAIL: Setting (a)sync mode: " + str(inst)
            return

        if mode:
            print "PASS: Set to async mode"
        else:
            print "PASS: Set to sync mode"

    def close(self, filepath):
        """
        Close open port.

        :param filepath: File to close.
        """
        descriptor = None
        path = self.ports[filepath]["path"]
        if path is not None:
            if path in self.files.keys():
                descriptor = self.files[path]
                del self.files[path]
            if descriptor is not None:
                try:
                    os.close(descriptor)
                except Exception, inst:
                    print "FAIL: Closing the file: " + str(inst)
                    return
        print "PASS: Close"

    def open(self, in_file, attempts=1):
        """
        Direct open devices.

        :param in_file: Array of files.
        :return: Array of descriptors.
        """
        opened = False
        for i in xrange(attempts):
            try:
                name = self.ports[in_file]["path"]
                self.files[name] = os.open(name, os.O_RDWR)
                if (self.ports[in_file]["is_console"] == "yes"):
                    print os.system("stty -F %s raw -echo" % (name))
                opened = True
                break
            except Exception, exc:
                print str(exc)
                time.sleep(0.1)
        if opened:
            print "PASS: All files opened correctly. (%d)" % i
        else:
            print "FAIL: Failed open file %s" % name

    def loopback(self, in_files, out_files, cachesize=1024,
                 mode=0):
        """
        Start a switch thread.

        (There is a problem with multiple opens of a single file).

        :param in_files: Array of input files.
        :param out_files: Array of output files.
        :param cachesize: Cachesize.
        :param mode: Mode of switch.
        """
        self.ports = self._get_port_status()

        in_f = self._open(in_files)
        out_f = self._open(out_files)
        in_files = [self.ports[item]["path"] for item in in_files]
        out_files = [self.ports[item]["path"] for item in out_files]

        s = self.Switch([in_f, in_files], [out_f, out_files], self.exit_thread,
                        cachesize, mode)
        s.start()
        self.threads.append(s)
        sys.stdout.write("PASS: Start switch\n")

    def exit_threads(self):
        """
        Function end all running data switch.
        """
        self.exit_thread.set()
        for th in self.threads:
            print "join %s" % th.getName()
            th.join()
        self.exit_thread.clear()

        del self.threads[:]
        for desc in self.files.itervalues():
            os.close(desc)
        self.files.clear()
        print "PASS: All threads finished"

    def die(self):
        """
        Quit consoleswitch.
        """
        self.exit_threads()
        sys.exit(0)

    def send_loop_init(self, port, length):
        """
        Prepares the sender thread. Requires clean thread structure.
        """
        self.ports = self._get_port_status()
        in_f = self._open([port])

        self.threads.append(self.Sender(in_f[0], self.exit_thread, length))
        print "PASS: Sender prepare"

    def send_loop(self):
        """
        Start sender data transfer. Requires senderprepare run first.
        """
        self.threads[0].start()
        print "PASS: Sender start"

    def send(self, port, length=1, mode=True, is_static=False):
        """
        Send a data of some length

        :param port: Port to write data
        :param length: Length of data
        :param mode: True = loop mode, False = one shoot mode
        :param is_static: False = generates $length long block (mode=0)
                          True = generates 4096 long block (faster, mode=1)
        """
        in_f = self._open([port])

        data = ""
        writes = 0

        if not is_static:
            while len(data) < length:
                data += "%c" % random.randrange(255)
            try:
                writes = os.write(in_f[0], data)
            except Exception, inst:
                print inst
        else:
            while len(data) < 4096:
                data += "%c" % random.randrange(255)
        if mode:
            while (writes < length):
                try:
                    writes += os.write(in_f[0], data)
                except Exception, inst:
                    print inst
        if writes >= length:
            print "PASS: Send data length %d" % writes
        else:
            print ("FAIL: Partial send: desired %d, transferred %d" %
                   (length, writes))

    def recv(self, port, length=1, bfr=1024, mode=True):
        """
        Receive a data of arbitrary length.

        :param port: Port to write data
        :param length: Length of data
        :param mode: True = loop mode, False = one shoot mode
        """
        in_f = self._open([port])

        recvs = ""
        try:
            recvs = os.read(in_f[0], bfr)
        except Exception, inst:
            print inst
        if mode:
            while (len(recvs) < length):
                try:
                    recvs += os.read(in_f[0], bfr)
                except Exception, inst:
                    print inst
        if len(recvs) >= length:
            print "PASS: Recv data length %d" % len(recvs)
        else:
            print ("FAIL: Partial recv: desired %d, transferred %d" %
                   (length, len(recvs)))

    def clean_port(self, port, bfr=1024):
        in_f = self._open([port])
        ret = select.select([in_f[0]], [], [], 1.0)
        buf = ""
        if ret[0]:
            buf = os.read(in_f[0], bfr)
        print ("PASS: Rest in socket: ") + str(buf[:10])


class VirtioGuestNt(VirtioGuest):

    """
    Test tools of virtio_ports.
    """
    LOOP_NONE = 0
    LOOP_POLL = 0   # TODO: Use SELECT instead of NONE (poll not supp. by win)
    LOOP_SELECT = 0     # TODO: Support for Select

    def _get_port_status(self, in_files=[]):
        """
        Get info about ports.

        :param in_files: Array of input files.
        :return: Ports dictionary of port properties
        """
        ports = {}
        for in_file in in_files:
            port = {}
            port['path'] = "\\\\.\\%s" % in_file[0]
            port['name'] = in_file[0]
            port['is_console'] = in_file[1]
            ports[in_file[0]] = port

        return ports

    def init(self, in_files):
        """
        Init and check port properties.
        """
        # This only sets the ports names and paths
        # TODO: symlinks are sometimes missing, use /dev/vport%dp%d"
        self.ports = self._get_port_status(in_files)

        # Check if all ports really exists
        remove = []
        for item in self.ports.iteritems():
            port = item[1]
            try:
                hFile = win32file.CreateFile(port['path'], 0, 0, None,
                                             win32file.OPEN_EXISTING,
                                             win32file.FILE_ATTRIBUTE_NORMAL,
                                             None)
                win32file.CloseHandle(hFile)
            except win32file.error:
                remove.append(port['name'])
                print "Fail to open port %s" % port['name']
        for name in remove:
            del(self.ports[name])

        # Check if in_files count and system port count matches
        # TODO: Not all devices are listed
        # TODO: Find the way to list all devices
        if remove:
            print "FAIL: Not all ports are present, check the log."
            return
        """
        reg = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE, "System")
        reg = _winreg.OpenKey(reg, "CurrentControlSet")
        reg = _winreg.OpenKey(reg, "Services")
        reg = _winreg.OpenKey(reg, "VirtioSerial")
        reg = _winreg.OpenKey(reg, "Enum")
        virtio_port_count = _winreg.QueryValueEx(reg, "Count")[0]
        if virtio_port_count != len(self.ports):
            print ("FAIL: Number of ports (%d) doesn't match the number"
                   " of ports in registry (%d)"
                   % (len(self.ports), virtio_port_count))
            return
        """

        print "PASS: Init and check virtioconsole files in system."

    def close(self, filepath):
        """
        Close open port.

        :param filepath: File to close.
        """
        hFile = None
        path = self.ports[filepath]["path"]
        if path is not None:
            if path in self.files.keys():
                hFile = self.files[path]
                del self.files[path]
            if hFile is not None:
                try:
                    win32file.CloseHandle(hFile)
                except win32file.error, inst:
                    print "FAIL: Closing the file: " + str(inst)
                    return
        print "PASS: Close"

    def _open(self, in_files):
        """
        Open devices and return array of descriptors

        :param in_files: List of port names
        :return: Array of descriptor
        """
        f = []

        for name in in_files:
            path = self.ports[name]["path"]
            if path in self.files:
                f.append(self.files[path])
            else:
                ret = self.open(name)
                if ret:
                    raise ret
                f.append(self.files[path])
        return f

    def open(self, name):
        """
        Direct open devices.

        :param name: Port name.
        :return: 0 on success
        """
        path = self.ports[name]['path']
        try:
            self.files[path] = win32file.CreateFile(path,
                                                    win32file.GENERIC_WRITE |
                                                    win32file.GENERIC_READ,
                                                    0,
                                                    None,
                                                    win32file.OPEN_EXISTING,
                                                    win32file.FILE_ATTRIBUTE_NORMAL,
                                                    None)
        except win32file.error, exc_detail:
            print "%s\nFAIL: Failed open file %s" % (str(exc_detail), name)
            return exc_detail
        print "PASS: All files opened correctly."

    def exit_threads(self):
        """
        Function end all running data switch.
        """
        self.exit_thread.set()
        for th in self.threads:
            print "join"
            th.join()
        self.exit_thread.clear()

        del self.threads[:]
        for desc in self.files.itervalues():
            win32file.CloseHandle(desc)
        self.files.clear()
        print "PASS: All threads finished"

    class Switch(Thread):

        """
        Thread that sends data between ports.
        """

        def __init__(self, in_files, out_files, event,
                     cachesize=1024, method=0):
            """
            :param in_files: Array of input files.
            :param out_files: Array of output files.
            :param method: Method of read/write access.
            :param cachesize: Block to receive and send.
            """
            Thread.__init__(self, name="Switch")

            self.in_files = in_files
            self.out_files = out_files
            self.exit_thread = event
            self.method = method
            self.cachesize = cachesize

        def _none_mode(self):
            """
            Read and write to device in blocking mode
            """
            data = ""
            while not self.exit_thread.isSet():
                data = ""
                for desc in self.in_files:
                    ret, _data = win32file.ReadFile(desc, self.cachesize)
                    if ret:
                        msg = ("Error occurred while receiving data, "
                               "err=%s, read=%s" % (ret, _data))
                        print "FAIL: " + msg
                        raise IOError(msg)
                    data += _data
                if data != "":
                    for desc in self.out_files:
                        ret, _data = win32file.WriteFile(desc, data)
                        if ret:
                            msg = ("Error occurred while sending data, "
                                   "err=%s, sentlen=%s" % (ret, _data))
                            print "FAIL: " + msg
                            raise IOError(msg)

        def run(self):
            self._none_mode()

    class Sender(Thread):

        """
        Creates a thread which sends random blocks of data to dst port.
        """

        def __init__(self, port, event, length):
            """
            :param port: Destination port
            :param length: Length of the random data block
            """
            Thread.__init__(self, name="Sender")
            self.port = port
            self.exit_thread = event
            self.data = array.array('L')
            for _ in range(max(length / self.data.itemsize, 1)):
                self.data.append(random.randrange(sys.maxint))

        def run(self):
            while not self.exit_thread.isSet():
                if win32file.WriteFile(self.port, self.data)[0]:
                    msg = "Error occurred while sending data."
                    print "FAIL: " + msg
                    raise IOError(msg)

    def send_loop_init(self, port, length):
        """
        Prepares the sender thread. Requires clean thread structure.
        """
        in_f = self._open([port])

        self.threads.append(self.Sender(in_f[0], self.exit_thread, length))
        print "PASS: Sender prepare"

    def send_loop(self):
        """
        Start sender data transfer. Requires senderprepare run first.
        """
        self.threads[0].start()
        print "PASS: Sender start"

    def send(self, port, length=1, mode=True, is_static=False):
        """
        Send a data of arbitrary length

        :param port: Port to write data
        :param length: Length of data
        :param mode: True = loop mode, False = one shoot mode
        :param is_static: False = generates $length long block (mode=0)
                          True = generates 4096 long block (faster, mode=1)
        """
        port = self._open([port])[0]

        data = ""
        writes = 0

        if not is_static:
            try:
                while len(data) < length:
                    data += "%c" % random.randrange(255)
                _ret, _len = win32file.WriteFile(port, data)
                if _ret:
                    msg = ("Error occurred while sending data, "
                           "err=%s, sentlen=%s" % (_ret, _len))
                    raise IOError(msg)
                writes = _len
            except Exception, inst:
                print inst
        else:
            while len(data) < 4096:
                data += "%c" % random.randrange(255)
        if mode:
            try:
                while (writes < length):
                    _ret, _len = win32file.WriteFile(port, data)
                    if _ret:
                        msg = ("Error occurred while sending data, err=%s"
                               ", sentlen=%s, allsentlen=%s" % (_ret, _len,
                                                                writes))
                        raise IOError(msg)
                    writes += _len
            except Exception, inst:
                print inst
        if writes >= length:
            print "PASS: Send data length %d" % writes
        else:
            print ("FAIL: Partial send: desired %d, transferred %d" %
                   (length, writes))

    def recv(self, port, length=1, buflen=1024, mode=True):
        """
        Receive a data of arbitrary length.

        :param port: Port to write data
        :param length: Length of data
        :param mode: True = loop mode, False = one shoot mode
        """
        port = self._open([port])[0]

        recvs = ""
        try:
            _ret, _data = win32file.ReadFile(port, buflen)
            if _ret:
                msg = ("Error occurred while receiving data, "
                       "err=%s, read=%s" % (_ret, _data))
                raise IOError(msg)
            recvs = _data
        except Exception, inst:
            print inst
        if mode:
            while (len(recvs) < length):
                try:
                    _ret, _data = win32file.ReadFile(port, buflen)
                    if _ret:
                        msg = ("Error occurred while receiving data, "
                               "err=%s, read=%s, allread=%s" % (_ret, _data,
                                                                len(recvs)))
                        raise IOError(msg)
                except Exception, inst:
                    print inst
        if len(recvs) >= length:
            print "PASS: Recv data length %d" % len(recvs)
        else:
            print ("FAIL: Partial recv: desired %d, transferred %d" %
                   (length, len(recvs)))


def is_alive():
    """
    Check is only main thread is alive and if guest react.
    """
    if ((os_linux and (threading.activeCount() == 2)) or
            ((not os_linux) and (threading.activeCount() == 1))):
        print ("PASS: Guest is ok no thread alive")
    else:
        threads = ""
        for thread in threading.enumerate():
            threads += thread.name + ", "
        print ("FAIL: On guest run thread. Active thread:" + threads)


def guest_exit():
    """
    quit/finish/exit this script
    """
    global exiting
    exiting = True


def compile_script():
    """
    Compile virtio_console_guest.py to speed up.
    """
    import py_compile
    py_compile.compile(__file__, "%so" % __file__)
    print "PASS: compile"
    sys.exit(0)


def worker(virt):
    """
    Worker thread (infinite) loop of virtio_guest.
    """
    global exiting
    print "PASS: Daemon start."
    p = select.poll()
    p.register(sys.stdin.fileno())
    while not exiting:
        d = p.poll()
        if (d[0][1] == select.POLLIN):
            out = raw_input()
            try:
                exec out
            except Exception:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                print "On Guest exception from: \n" + "".join(
                    traceback.format_exception(exc_type,
                                               exc_value,
                                               exc_traceback))
                print "FAIL: Guest command exception."
        elif (d[0][1] & select.POLLHUP):
            time.sleep(0.5)


def sigusr_handler(sig, frame):
    pass


class Daemon:

    """
    Daemonize guest
    """

    def __init__(self, stdin, stdout, stderr):
        """
        Init daemon.

        :param stdin: path to stdin file.
        :param stdout: path to stdout file.
        :param stderr: path to stderr file.
        """
        self.stdin = stdin
        self.stdout = stdout
        self.stderr = stderr

    @staticmethod
    def is_file_open(path):
        """
        Determine process which open file.

        :param path: Path to file.
        :return: [[pid,mode], ... ].
        """
        opens = []
        pids = os.listdir('/proc')
        for pid in sorted(pids):
            try:
                int(pid)
            except ValueError:
                continue
            fd_dir = os.path.join('/proc', pid, 'fd')
            try:
                for filepath in os.listdir(fd_dir):
                    try:
                        p = os.path.join(fd_dir, filepath)
                        link = os.readlink(os.path.join(fd_dir, filepath))
                        if link == path:
                            mode = os.lstat(p).st_mode
                            opens.append([pid, mode])
                    except OSError:
                        continue
            except OSError, e:
                if e.errno == 2:
                    continue
                raise
        return opens

    def daemonize(self):
        """
        Run guest as a daemon.
        """
        try:
            pid = os.fork()
            if pid > 0:
                return False
        except OSError, e:
            sys.stderr.write("Daemonize failed: %s\n" % (e))
            sys.exit(1)

        os.chdir("/")
        os.setsid()
        os.umask(0)

        try:
            pid = os.fork()
            if pid > 0:
                sys.exit(0)
        except OSError, e:
            sys.stderr.write("Daemonize failed: %s\n" % (e))
            sys.exit(1)

        sys.stdout.flush()
        sys.stderr.flush()
        si = file(self.stdin, 'r')
        so = file(self.stdout, 'w')
        se = file(self.stderr, 'w')

        os.dup2(si.fileno(), sys.stdin.fileno())
        os.dup2(so.fileno(), sys.stdout.fileno())
        os.dup2(se.fileno(), sys.stderr.fileno())

        sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)
        sys.stderr = os.fdopen(sys.stderr.fileno(), 'w', 0)
        return True

    def start(self):
        """
        Start the daemon

        :return: PID of daemon.
        """
        # Check for a pidfile to see if the daemon already runs
        openers = self.is_file_open(self.stdout)
        rundaemon = False
        if len(openers) > 0:
            for i in openers:
                if i[1] & stat.S_IWUSR:
                    rundaemon = True
                    openers.remove(i)
            if len(openers) > 0:
                for i in openers:
                    os.kill(int(i[0]), 9)
        time.sleep(0.3)

        # Start the daemon
        if not rundaemon:
            if self.daemonize():
                self.run()

    def run(self):
        """
        Run guest main thread
        """
        global virt
        global exiting
        virt = VirtioGuestPosix()
        slave = Thread(target=worker, args=(virt,))
        slave.start()
        signal.signal(signal.SIGUSR1, sigusr_handler)
        signal.signal(signal.SIGALRM, sigusr_handler)
        while not exiting:
            signal.alarm(1)
            signal.pause()
            catch = virt.catching_signal()
            if catch:
                signal.signal(signal.SIGIO, virt)
            elif catch is False:
                signal.signal(signal.SIGIO, signal.SIG_DFL)
            if catch is not None:
                virt.use_config.set()
        print "PASS: guest_exit"
        sys.exit(0)


def main():
    """
    Main function for OS Linux with infinite loop to catch signal from system.
    """
    stdin = "/tmp/guest_daemon_pi"
    stdout = "/tmp/guest_daemon_po"
    stderr = "/tmp/guest_daemon_pe"

    for f in [stdin, stdout, stderr]:
        try:
            os.mkfifo(f)
        except OSError, e:
            if e.errno == 17:
                pass

    daemon = Daemon(stdin,
                    stdout,
                    stderr)
    daemon.start()

    d_stdin = os.open(stdin, os.O_WRONLY)
    d_stdout = os.open(stdout, os.O_RDONLY)
    d_stderr = os.open(stderr, os.O_RDONLY)

    s_stdin = sys.stdin.fileno()
    s_stdout = sys.stdout.fileno()
    s_stderr = sys.stderr.fileno()

    pid = filter(lambda x: x[0] != str(os.getpid()),
                 daemon.is_file_open(stdout))[0][0]

    print "PASS: Start"

    while 1:
        ret = select.select([d_stderr,
                             d_stdout,
                             s_stdin],
                            [], [], 1.0)
        if s_stdin in ret[0]:
            os.write(d_stdin, os.read(s_stdin, 1))
        if d_stdout in ret[0]:
            os.write(s_stdout, os.read(d_stdout, 1024))
        if d_stderr in ret[0]:
            os.write(s_stderr, os.read(d_stderr, 1024))
        if not os.path.exists("/proc/" + pid):
            sys.exit(0)

    os.close(d_stdin)
    os.close(d_stdout)
    os.close(d_stderr)


def main_nt():
    """
    Main function for Windows NT with infinite loop.
    """
    global virt
    global exiting
    virt = VirtioGuestNt()
    print "PASS: Start"
    sys.stdout.flush()
    while not exiting:
        try:
            exec raw_input()
        except Exception:
            exc_type, exc_value, exc_traceback = sys.exc_info()
            print "On Guest exception from: \n" + "".join(
                traceback.format_exception(exc_type,
                                           exc_value,
                                           exc_traceback))
            print "FAIL: Guest command exception."
        sys.stdout.flush()
    print "PASS: guest_exit"
    sys.exit(0)


if __name__ == "__main__":
    if (len(sys.argv) > 1) and (sys.argv[1] == "-c"):
        compile_script()

    if os_linux:    # Linux
        main()
    else:   # Windows
        main_nt()

########NEW FILE########
__FILENAME__ = build_docs
#!/usr/bin/python
"""
Build documentation and report wether we had warning/error messages.

This is geared towards documentation build regression testing.
"""
import os
import sys
import common

from autotest.client import utils


def build_docs():
    """
    Build virt-test HTML docs, reporting failures.
    """
    ignore_list = ['No python imaging library installed',
                   'Virsh executable not set or found on path',
                   "failed to import module u'virttest.passfd'",
                   "failed to import module u'virttest.step_editor'"]
    failure_lines = []
    root_dir = common.virt_test_dir
    doc_dir = os.path.join(root_dir, 'documentation')
    output = utils.system_output('make -C %s html 2>&1' % doc_dir)
    output_lines = output.splitlines()
    for line in output_lines:
        ignore_msg = False
        for ignore in ignore_list:
            if ignore in line:
                print 'Expected warning ignored: %s' % line
                ignore_msg = True
        if ignore_msg:
            continue
        if 'ERROR' in line:
            failure_lines.append(line)
        if 'WARNING' in line:
            failure_lines.append(line)
    if failure_lines:
        print ('%s ERRORs/WARNINGs detected while building the html docs:' %
               len(failure_lines))
        for (index, failure_line) in enumerate(failure_lines):
            print "%s) %s" % (index + 1, failure_line)
        print 'Please check the output and fix your docstrings/.rst docs'
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == '__main__':
    build_docs()

########NEW FILE########
__FILENAME__ = cd_hash
#!/usr/bin/python
"""
Program that calculates several hashes for a given CD image.

:copyright: Red Hat 2008-2009
"""

import os
import sys
import optparse
import logging

import common
from autotest.client.shared import logging_manager
from autotest.client import utils
from virttest import utils_misc


if __name__ == "__main__":
    parser = optparse.OptionParser("usage: %prog [options] [filenames]")
    options, args = parser.parse_args()

    logging_manager.configure_logging(utils_misc.VirtLoggingConfig())

    if args:
        filenames = args
    else:
        parser.print_help()
        sys.exit(1)

    for filename in filenames:
        filename = os.path.abspath(filename)

        file_exists = os.path.isfile(filename)
        can_read_file = os.access(filename, os.R_OK)
        if not file_exists:
            logging.critical("File %s does not exist!", filename)
            continue
        if not can_read_file:
            logging.critical("File %s does not have read permissions!",
                             filename)
            continue

        logging.info("Hash values for file %s", os.path.basename(filename))
        logging.info("md5    (1m): %s", utils.hash_file(filename, 1024 * 1024,
                                                        method="md5"))
        logging.info("sha1   (1m): %s", utils.hash_file(filename, 1024 * 1024,
                                                        method="sha1"))
        logging.info(
            "md5  (full): %s", utils.hash_file(filename, method="md5"))
        logging.info("sha1 (full): %s", utils.hash_file(filename,
                                                        method="sha1"))
        logging.info("")

########NEW FILE########
__FILENAME__ = common
import os
import sys


def load_setup_modules(client_dir):
    try:
        sys.path.insert(0, client_dir)
        import setup_modules
    finally:
        sys.path.pop(0)
    return setup_modules

dirname = os.path.dirname(sys.modules[__name__].__file__)
virt_test_dir = os.path.abspath(os.path.join(dirname, ".."))
sys.path.insert(0, virt_test_dir)

try:
    import autotest.client.setup_modules as setup_modules
    client_dir = os.path.dirname(setup_modules.__file__)
    sm = setup_modules
except ImportError:
    try:
        client_dir = os.path.abspath(os.path.join(dirname, "..", "..", ".."))
        sm = load_setup_modules(client_dir)
    except:
        try:
            client_dir = os.path.join(os.environ['AUTOTEST_PATH'], 'client')
        except KeyError:
            print("Environment variable $AUTOTEST_PATH not set. "
                  "please set it to a path containing an autotest checkout")
            print("Or install the autotest-framework package for your distro")
            sys.exit(1)
        if not os.path.isdir(client_dir):
            print('Autotest client library directory was not found at: "%s"' %
                  client_dir)
            print('Please check if the environment variable "$AUTOTEST_PATH" '
                  'points to a valid location')
            sys.exit(1)
        sm = load_setup_modules(client_dir)
sm.setup(base_path=client_dir, root_module_name="autotest.client")

########NEW FILE########
__FILENAME__ = download_manager
#!/usr/bin/python
"""
Download helper for blobs needed for virt testing.

Downloads blobs defined in assets. Assets are .ini files that contain the
    following config keys:

    title: Title string to display in the download progress bar.
    url = URL of the resource
    sha1_url = URL with SHA1 information for the resource, in the form
        sha1sum file_basename
    destination = Location of your file relative to the data directory
        (TEST_SUITE_ROOT/shared/data)
    destination_uncompressed (optional) = Location of the uncompressed file
        relative to the data directory (TEST_SUITE_ROOT/shared/data)
    uncompress_cmd (optionl) = Command that needs to be executed with the
        compressed file as a parameter

:copyright: Red Hat 2012
"""
import glob
import os
import sys
import logging
import time
import common
from autotest.client.shared import logging_manager
from virttest import asset, utils_misc


def download_assets():
    all_assets = asset.get_all_assets()
    if all_assets:
        logging.info("Available download assets:")
        logging.info("")
        for asset_info in all_assets:
            asset_keys = asset_info.keys()
            logging.info("%d - %s" % (all_assets.index(asset_info) + 1,
                                      asset_info['title']))
            asset_keys.pop(asset_keys.index('title'))
            asset_keys.sort()
            for k in asset_keys:
                logging.info("    %s = %s" % (k, asset_info[k]))
            logging.info("")
    indexes = raw_input("%s INFO | Type the index for the assets you want to "
                        "download (comma separated, Ctrl+C to abort): " %
                        time.strftime("%H:%M:%S", time.localtime()))

    index_list = []

    for idx in indexes.split(","):
        try:
            index = int(idx) - 1
            index_list.append(index)
            all_assets[index]
        except (ValueError, IndexError):
            logging.error("Invalid index(es), aborting...")
            sys.exit(1)

    for idx in index_list:
        asset_info = all_assets[idx]
        asset.download_file(asset_info, interactive=True)

if __name__ == "__main__":
    logging_manager.configure_logging(utils_misc.VirtLoggingConfig())
    try:
        download_assets()
    except KeyboardInterrupt:
        print
        logging.info("Aborting...")
        sys.exit(0)

########NEW FILE########
__FILENAME__ = cache_populate
#!/usr/bin/env python

import sys
import os
import getpass
import datetime
from github import Github
from github_issues import GithubIssues

gh = Github(login_or_token=raw_input("Enter github username: "),
            password=getpass.getpass('Enter github password: '),
            user_agent='PyGithub/Python')

print "Enter location (<user>/<repo>)",
repo_full_name = 'autotest/virt-test'
repo_full_name = raw_input("or blank for '%s': "
                           % repo_full_name).strip() or repo_full_name

print

issues = GithubIssues(gh, repo_full_name)

for issue in issues:
    sys.stdout.write(str(issue['number']) + '\n')
    sys.stdout.flush()

# make sure cache is cleaned and saved up
del issues

print

########NEW FILE########
__FILENAME__ = example
#!/usr/bin/env python

import sys
import os
import getpass
import datetime

# PyGithub >= 1.13 is required https://pypi.python.org/pypi/PyGithub
from github import Github
from github_issues import GithubIssuesBase, GithubIssues

# You could use OAuth here too for unattended access
# see http://developer.github.com/v3/oauth/#create-a-new-authorization
print "Enter github username:"
username = sys.stdin.readline().strip()
print
password = getpass.getpass('Enter github password: ')

gh = Github(login_or_token=username,
            password=password, user_agent='PyGithub/Python')
# needed to fetch fresh rate_limiting data
repo = gh.get_repo('autotest/virt-test')

# Requests for logged in users are limited to 5000 per hour
# or about 1 request every 0.7 seconds
start = gh.rate_limiting
# Open up cache and repository
issues = GithubIssues(gh, 'autotest/virt-test')
print "Issue #125: ",
# Any issue can be referenced by number
print issues[125]
end = gh.rate_limiting
print "Requests used: ", start[0] - end[0]
print "Cache hits: %s misses: %s" % (issues.cache_hits, issues.cache_misses)

# Pull requests are treated as issues
issues = GithubIssues(gh, 'autotest/virt-test')
start = end
print "Pull #526: ",
print issues[526]
end = gh.rate_limiting
print "Requests used: ", start[0] - end[0]
print "Cache hits: %s misses: %s" % (issues.cache_hits, issues.cache_misses)

# Listing issues requires finding the last issue
# this takes a while when the cache is empty
issues = GithubIssues(gh, 'autotest/virt-test')
start = end
print "Total number of issues (this could take a while):"
# This len() is used to force the slower binary-search
print GithubIssuesBase.__len__(issues)
end = gh.rate_limiting
print "Requests used: ", start[0] - end[0]
print "Cache hits: %s misses: %s" % (issues.cache_hits, issues.cache_misses)

# Searches are supported and return lists of issue-numbers
issues = GithubIssues(gh, 'autotest/virt-test')
start = end
print "Open issues last few days without any label (could take 2-10 minutes):"
two_days = datetime.timedelta(days=2)
last_week = datetime.datetime.now() - two_days
# Search criteria is put into a dictionary
#            state - str - 'open', 'closed'
#            assignee - list of str (login), "none" or "*"
#            mentioned - str (login)
#            labels - list of str (label name)
#            sort - str - 'created', 'updated', 'comments'
#            direction - str - 'asc', 'desc'
#            since - datetime.datetime
criteria = {'state': 'open', 'since': last_week}
# Search results are cached for 10-minutes, otherwise searches can be slow
for number in issues.search(criteria):
    issue = issues[number]
    # some items must be searched/compared manually
    if len(issue['labels']) < 1:
        print ('https://github.com/autotest/virt-test/issues/%s\t"%s"'
               % (issue['number'], issue['summary']))
print
print "Requests used: ", start[0] - end[0]
print "Cache hits: %s misses: %s" % (issues.cache_hits, issues.cache_misses)

# Now that cache is populated, this will be very fast
issues = GithubIssues(gh, 'autotest/virt-test')
start = end
print "Total number of issues (this should be a lot faster):"
# This length uses a cached issue count plus a 'since' criteria search
print len(issues)
end = gh.rate_limiting
print "Final Requests used: ", start[0] - end[0]
print "Cache hits: %s misses: %s" % (issues.cache_hits, issues.cache_misses)
del issues

########NEW FILE########
__FILENAME__ = github_issues
"""
Classes to cache and read specific items from github issues in a uniform way
"""

from functools import partial as Partial
import datetime
import time
import shelve
# Requires PyGithub version >= 1.13 for access to raw_data attribute
import github


# Needed to not confuse cached 'None' objects
class Nothing(object):
    raw_data = None


# Needed to signal list cache, not github object
class SearchResults(object):

    def __init__(self, *stuff):
        self.raw_data = stuff


class GithubCache(object):

    """
    Auto-refreshing github.GithubObject.GithubObject from dict
    """

    cache_hits = 0
    cache_misses = 0

    cache_lifetimes = {
        'default': datetime.timedelta(hours=2),
        github.GitCommit.GitCommit: datetime.timedelta(days=30),
        github.NamedUser.NamedUser: datetime.timedelta(days=30),
        github.Commit.Commit: datetime.timedelta(days=30),
        github.Issue.Issue: datetime.timedelta(minutes=30),
        github.PullRequest.PullRequest: datetime.timedelta(hours=1),
        # Special case for github.Issue.Issue
        'closed': datetime.timedelta(days=30),
        SearchResults: datetime.timedelta(minutes=10),
        github.NamedUser.NamedUser: datetime.timedelta(hours=2),
        github.GitAuthor.GitAuthor: datetime.timedelta(days=9999),
        'total_issues': datetime.timedelta(days=9999)
    }

    def __init__(self, github_obj, cache_get_partial, cache_set_partial,
                 cache_del_partial, pre_fetch_partial, fetch_partial):
        self.github = github_obj
        self.cache_get = cache_get_partial  # Returns native dict
        self.cache_set = cache_set_partial  # called with value=dict
        self.cache_del = cache_del_partial
        self.pre_fetch = pre_fetch_partial  # called with nothing
        self.fetch = fetch_partial  # Returns github.GithubObject.GithubObject

    def __call__(self):
        """
        Retrieve instance from fresh or cached data
        """
        # microseconds aren't useful when fetch takes ~1 second
        now = datetime.datetime.utcnow()
        now = datetime.datetime(year=now.year, month=now.month,
                                day=now.day, hour=now.hour,
                                minute=now.minute, second=0, microsecond=0)
        try:
            data = self.cached_data()
            if data['expires'] < now:
                raise KeyError  # refresh cache
            self.cache_hits += 1
        except KeyError:
            data = self.fetched_data(now)
            self.cache_set(value=data)
            self.cache_misses += 1
        # Any exceptions thrown during conversion should purge cache entry
        try:
            # Format data for consumption
            if data['klass'] == github.PaginatedList.PaginatedList:
                inside_klass = data['inside_klass']
                result = []
                for item in data['raw_data']:
                    result.append(
                        self.github.create_from_raw_data(inside_klass,
                                                         item))
                return result
            elif data['klass'] == Nothing:
                return None  # it's a None object
            elif data['klass'] == SearchResults:
                return data['raw_data']  # just the contents
            else:
                return self.github.create_from_raw_data(data['klass'],
                                                        data['raw_data'])
        except:
            try:
                self.cache_del()
            except KeyError:
                pass  # doesn't exist in cache, ignore
            raise  # original exception

    @staticmethod
    def format_data(klass, expires, raw_data, inside_klass=None):
        """
        Enforce uniform data format for fetched data
        """
        if inside_klass is None:
            return {'klass': klass,
                    'fetched': datetime.datetime.utcnow(),
                    'expires': expires,
                    'raw_data': raw_data}
        else:
            return {'klass': klass,
                    'inside_klass': inside_klass,
                    'fetched': datetime.datetime.utcnow(),
                    'expires': expires,
                    'raw_data': raw_data}

    def fetched_data(self, now):
        """
        Return dictionary containing freshly fetched values
        """
        try:
            if callable(self.pre_fetch):
                self.pre_fetch()
            fetched_obj = self.fetch()
        except github.GithubException, detail:
            if detail.status == 404:
                raise KeyError('Github item not-found error while calling %s '
                               'with args=%s and dargs=%s' % (self.fetch.func,
                                                              self.fetch.args,
                                                              self.fetch.keywords))
            else:
                raise
        if fetched_obj is None:
            fetched_obj = Nothing()
        klass = fetched_obj.__class__
        # github.PaginatedList.PaginatedList need special handling
        if isinstance(fetched_obj, github.PaginatedList.PaginatedList):
            raw_data = [item.raw_data for item in fetched_obj]
            inside_klass = fetched_obj[0].__class__
            expires = now + self.cache_lifetimes.get(inside_klass,
                                                     self.cache_lifetimes['default'])
            return self.__class__.format_data(klass,
                                              now + self.cache_lifetimes.get(
                                                  inside_klass,
                                                  self.cache_lifetimes[
                                                      'default']),
                                              raw_data, inside_klass)
        else:
            expires = now + self.cache_lifetimes.get(klass,
                                                     # else default
                                                     self.cache_lifetimes['default'])
            # closed issues/pull requests don't change much
            if hasattr(fetched_obj, 'closed_at'):
                if fetched_obj.closed_at is not None:
                    expires = now + self.cache_lifetimes['closed']
            return self.__class__.format_data(klass, expires,
                                              fetched_obj.raw_data)

    def cached_data(self):
        """
        Return dictionary containing cached values or raise KeyError
        """
        try:
            return self.cache_get()  # maybe raise KeyError or TypeError
        except KeyError:
            raise
        except:
            # Try to delete the entry
            self.cache_del()
            raise


class GithubIssuesBase(list):

    """
    Base class for cached list of github issues
    """

    # Force static pickle protocol version
    protocol = 2

    # Class to use for cache management
    cache_class = GithubCache

    def __init__(self, github_obj, repo_full_name, cache_filename):
        """
        Initialize cache and reference github repository issues
        """

        self.github = github_obj
        self.repo_full_name = repo_full_name
        self.shelf = shelve.open(filename=cache_filename,
                                 protocol=self.protocol,
                                 writeback=True)

        # Avoid exceeding rate-limit per hour
        requests = self.github.rate_limiting[1]  # requests per hour
        period = 60.0 * 60.0  # one hour in seconds
        sleeptime = period / requests
        self.pre_fetch_partial = Partial(time.sleep, sleeptime)
        # self.pre_fetch_partial = None # cheat-mode enable (no delays)

        repo_cache_key = 'repo_%s' % self.repo_full_name
        # get_repo called same way throughout instance life
        cache_get_partial = Partial(self.shelf.__getitem__, repo_cache_key)
        cache_set_partial = Partial(self.shelf.__setitem__, repo_cache_key)
        cache_del_partial = Partial(self.shelf.__delitem__, repo_cache_key)
        fetch_partial = Partial(self.github.get_repo,
                                self.repo_full_name)
        # Callable instance retrieves cached or fetched value for key
        self.get_repo = self.cache_class(self.github,
                                         cache_get_partial,
                                         cache_set_partial,
                                         cache_del_partial,
                                         self.pre_fetch_partial,
                                         fetch_partial)
        super(GithubIssuesBase, self).__init__()

    def __del__(self):
        """
        Make sure cache is saved
        """
        try:
            self.shelf.close()
        except AttributeError:
            pass  # Open must have failed

    def __len__(self):
        """
        Binary search through issue numbers until largest identified
        """
        increment = 1000
        last_issue = 1
        if not self.__contains__(last_issue):
            return 0  # no issues
        while increment > 0:
            while self.__contains__(last_issue):
                last_issue += increment
            # Fall back to prior one
            last_issue -= increment
            # Chop increment in half
            increment /= 2
        return last_issue

    def __contains__(self, key):
        try:
            # Must call this classes method specifically
            GithubIssuesBase.__getitem__(self, key)
        except KeyError:
            return False
        return True

    def __iter__(self):
        for key in self.keys():
            yield self[key]

    def __setitem__(self, key, value):
        raise KeyError("Read only mapping while trying to set %s to %s"
                       % (str(key), str(value)))

    def __delitem__(self, key):
        raise KeyError(
            "Read only mapping while trying to delete %s" % str(key))

    def __getitem__(self, key):
        """
        Return a standardized dict of github issue unless NoEnumerate=True
        """
        repo = self.get_repo()
        # Enforce uniform key string
        cache_key = self.get_issue_cache_key(key)
        fetch_partial = Partial(repo.get_issue, int(key))
        item = self.get_gh_obj(cache_key, fetch_partial)
        # No exception raised, update cache on disk
        self.shelf.sync()
        return item

    def get_issue_cache_key(self, number):
        return 'repo_%s_issue_%s' % (self.repo_full_name, str(int(number)))

    def has_key(self, key):
        return self.__contains__(key)

    def items(self):
        # Iterator comprehension
        return (self[key] for key in self.keys())

    def keys(self):
        # Iterators are simply better
        return xrange(1, self.__len__() + 1)

    def values(self):
        # Iterator comprehension
        return (value for (key, value) in self.items())


class GithubIssues(GithubIssuesBase, object):

    """
    Read-only List-like interface to cached github issues in standardized format
    """

    # Marshal callables for key to github.Issue.Issue value
    marshal_map = {
        'number': lambda gh_obj: getattr(gh_obj, 'number'),
        'summary': lambda gh_obj: getattr(gh_obj, 'title'),
        'description': lambda gh_obj: getattr(gh_obj, 'body'),
        'modified': lambda gh_obj: getattr(gh_obj, 'updated_at'),
        'commits': NotImplementedError,  # setup in __init__
        'opened': lambda gh_obj: getattr(gh_obj, 'created_at'),
        'closed': lambda gh_obj: getattr(gh_obj, 'closed_at'),
        'assigned': lambda gh_obj: getattr(gh_obj, 'assignee'),
        'author': lambda gh_obj: getattr(gh_obj, 'user').login,
        'commit_authors': NotImplementedError,  # setup in __init__
        'comments': lambda gh_obj: getattr(gh_obj, 'comments'),
        'comment_authors': NotImplementedError,  # setup in __init__
        'labels': lambda gh_obj: [label.name for label in gh_obj.labels],
        'url': lambda gh_obj: getattr(gh_obj, 'html_url'),
        'github_issue': lambda gh_obj: gh_obj
    }

    # Storage for property values
    _cache_hits = 0   # Tracks temporary cache instances
    _cache_misses = 0  # Tracks temporary cache instances

    def __init__(self, github_obj, repo_full_name):
        """
        Initialize cache and reference github repository issues
        """
        cache_filename = self.__class__.__name__ + '.cache'
        super(GithubIssues, self).__init__(github_obj,
                                           repo_full_name,
                                           cache_filename)
        # These marshal functions require state
        self.marshal_map['commits'] = self.gh_pr_commits
        self.marshal_map['commit_authors'] = self.gh_pr_commit_authors
        self.marshal_map['comment_authors'] = self.gh_issue_comment_authors

    def __del__(self):
        self.vacuum()
        super(GithubIssues, self).__del__()

    def vacuum(self):
        """Vacuum up all expired entries"""
        # Can't modify list while iterating
        keys_to_del = []
        now = datetime.datetime.utcnow()
        for key, value in self.shelf.items():
            # no need to be precise
            if value['expires'] <= now:
                keys_to_del.append(key)
        for key in keys_to_del:
            del self.shelf[key]

    @property
    def cache_hits(self):
        return self.get_repo.cache_hits + self._cache_hits

    @property
    def cache_misses(self):
        return self.get_repo.cache_misses + self._cache_misses

    def __getitem__(self, key):
        """
        Return a standardized dict of github issue
        """
        item = self.marshal_gh_obj(super(GithubIssues, self).__getitem__(key))
        self.shelf.sync()
        return item

    def __len__(self):
        """
        Return cached number of issues
        """
        cache_key = 'repo_%s_total_issues' % self.repo_full_name
        # seconds aren't useful when fetch takes > 1 minute
        now = datetime.datetime.utcnow()
        now = datetime.datetime(year=now.year, month=now.month,
                                day=now.day, hour=now.hour,
                                minute=now.minute, second=0, microsecond=0)
        # Easier to do custom caching behavior here than fuss with GithubCache
        try:
            cache_data = self.shelf.__getitem__(cache_key)
            if cache_data['expires'] < now:
                raise KeyError
            # Bypass search_result caching used in self.search()
            searchresult = self.make_search_results(
                {'since': cache_data['since']})
            # about to change the number
            cache_data['since'] = now
            # total equal to old count plus new count since then
            cache_data['raw_data'] += len(searchresult.raw_data)
        except KeyError:
            cache_data = {}
            # doesn't expire ever
            cache_data['expires'] = now + GithubCache.cache_lifetimes[
                'total_issues']
            cache_data['since'] = now
            # This will take a while if issue cache is stale
            cache_data['raw_data'] = super(GithubIssues, self).__len__()
        self.shelf.__setitem__(cache_key, cache_data)
        return cache_data['raw_data']

    def get_gh_obj(self, cache_key, fetch_partial):
        """
        Helper to get object possibly from cache and update counters
        """
        cache_get_partial = Partial(self.shelf.__getitem__,
                                    cache_key)
        cache_set_partial = Partial(self.shelf.__setitem__,
                                    cache_key)
        cache_del_partial = Partial(self.shelf.__delitem__,
                                    cache_key)
        # Callable instance could change every time
        get_obj = GithubCache(self.github,
                              cache_get_partial,
                              cache_set_partial,
                              cache_del_partial,
                              self.pre_fetch_partial,
                              fetch_partial)
        result = get_obj()
        self._cache_hits += get_obj.cache_hits
        self._cache_misses += get_obj.cache_misses
        return result  # DOES NOT SYNC DATA!

    def search(self, criteria):
        """
        Return a list of issue-numbers that match a search criteria.

        :param criteria: Dictionary of search terms
            state - str - 'open', 'closed'
            assignee - list of str (login), "none" or "*"
            mentioned - str (login)
            labels - list of str (label name)
            sort - str - 'created', 'updated', 'comments'
            direction - str - 'asc', 'desc'
            since - datetime.datetime
        """
        valid_criteria = {}
        # use search dictionary to form hash for cached results
        search_cache_key = 'issue_search'
        # Validate & transform criteria
        if criteria.has_key('state'):
            state = str(criteria['state'])
            if state not in ('open', 'closed'):
                raise ValueError("'state' criteria must be 'open' or 'closed'")
            valid_criteria['state'] = state
            search_cache_key = '%s_%s' % (search_cache_key, state)

        if criteria.has_key('assignee'):
            assignee = str(criteria['assignee'])
            search_cache_key = '%s_%s' % (search_cache_key, assignee)
            if assignee in ('none', '*'):
                valid_criteria['assignee'] = assignee
            else:
                # returns github.NamedUser.NamedUser
                valid_criteria['assignee'] = self.get_gh_user(assignee)

        if criteria.has_key('mentioned'):
            mentioned = str(criteria['assignee'])
            search_cache_key = '%s_%s' % (search_cache_key, mentioned)
            if mentioned in ('none', '*'):
                valid_criteria['mentioned'] = mentioned
            else:
                # returns github.NamedUser.NamedUser
                valid_criteria['mentioned'] = self.get_gh_user(mentioned)

        if criteria.has_key('labels'):
            labels = criteria['labels']
            if not isinstance(labels, list):
                raise ValueError("'lables' criteria must be a list")
            valid_criteria['labels'] = []
            for name in labels:
                search_cache_key = '%s_%s' % (search_cache_key, labels)
                valid_criteria['labels'].append(self.get_gh_label(str(name)))

        if criteria.has_key('sort'):
            sort = str(criteria['sort'])
            if sort not in ('created', 'updated', 'comments'):
                raise ValueError("'sort' criteria must be 'created', 'updated'"
                                 ", 'comments'")
            valid_criteria['sort'] = sort
            search_cache_key = '%s_%s' % (search_cache_key, sort)

        if criteria.has_key('direction'):
            direction = str(criteria['direction'])
            if direction not in ('asc', 'desc'):
                raise ValueError("'direction' criteria must be 'asc', 'desc'")
            valid_criteria['direction'] = direction
            search_cache_key = '%s_%s' % (search_cache_key, direction)

        if criteria.has_key('since'):
            since = criteria['since']
            if not isinstance(since, datetime.datetime):
                raise ValueError("'since' criteria must be a "
                                 "datetime.datetime")
            # second and milisecond not useful to search or cache
            since = datetime.datetime(year=since.year,
                                      month=since.month,
                                      day=since.day,
                                      hour=since.hour,
                                      minute=since.minute,
                                      second=0,
                                      microsecond=0)
            search_cache_key = '%s_%s' % (search_cache_key, since.isoformat())
            valid_criteria['since'] = since

        # Do not perform search operation unless no cached results
        # or cached results have expired
        fetch_partial = Partial(self.make_search_results, valid_criteria)
        # This could take an arbitrarily LONG time
        return self.get_gh_obj(search_cache_key, fetch_partial)

    def make_search_results(self, valid_criteria):
        """
        Return a SearchResults instance from issue numbers found by search
        """
        repo = self.get_repo()
        result = repo.get_issues(**valid_criteria)
        return SearchResults(*[issue.number for issue in result])

    def clean_cache_entry(self, key):
        """
        Remove an entry from cache, ignoring any KeyErrors
        """
        try:
            del self.shelf[key]
        except KeyError:
            pass

    def get_gh_user(self, login):
        cache_key = 'github_user_%s' % login
        fetch_partial = Partial(self.github.get_user, login)
        try:
            return self.get_gh_obj(cache_key, fetch_partial)
        except KeyError:
            raise ValueError('login %s is not a valid github user' % login)

    def get_gh_label(self, name):
        repo = self.get_repo()
        cache_key = str('repo_%s_label_%s' % (self.repo_full_name, name))
        fetch_partial = Partial(repo.get_label, name)
        try:
            return self.get_gh_obj(cache_key, fetch_partial)
        except KeyError:
            raise ValueError('label %s is not valid for repo %s' % (name,
                                                                    self.repo_full_name))

    def marshal_gh_obj(self, gh_issue):
        """
        Translate a github issue object into dictionary w/ fixed keys
        """
        mkeys = self.marshal_map.keys()
        return dict([(key, self.marshal_map[key](gh_issue)) for key in mkeys])

    @staticmethod
    def gh_issue_is_pull(gh_issue):
        """
        Return True/False if gh_issue is a pull request or not
        """
        pullreq = gh_issue.pull_request
        if pullreq is not None:
            if (pullreq.diff_url is None and
                pullreq.html_url is None and
                    pullreq.patch_url is None):
                return False
        else:
            return False
        # pullreq not None but pullreq attributes are not None
        return True

    # marshal_map method
    def gh_issue_comment_authors(self, gh_issue):
        """
        Retrieve a list of comment author e-mail addresses
        """
        if gh_issue.comments > 0:
            num = gh_issue.number
            cache_key = ('repo_%s_issue_%s_comments'
                         % (self.repo_full_name, num))
            fetch_partial = Partial(gh_issue.get_comments)
            authors = set()
            for comment in self.get_gh_obj(cache_key, fetch_partial):
                # Referencing user attribute requires a request, so cache it
                user_cache_key = cache_key + '_%s_user' % comment.id
                user_fetch_partial = Partial(getattr, comment, 'user')
                try:
                    user = self.get_gh_obj(user_cache_key, user_fetch_partial)
                except:
                    # Also clean up comments cache
                    self.clean_cache_entry(cache_key)
                    raise  # original exception
                authors.add(user.email)
            return authors
        else:
            return None

    # marshal_map method
    def gh_pr_commit_authors(self, gh_issue):
        """
        Return list of commit author e-mail addresses for a pull-request
        """

        if GithubIssues.gh_issue_is_pull(gh_issue):
            num = gh_issue.number
            repo = self.get_repo()
            cache_key = 'repo_%s_pull_%s' % (self.repo_full_name, str(num))
            fetch_partial = Partial(repo.get_pull, num)
            pull = self.get_gh_obj(cache_key, fetch_partial)
            if pull.commits is None or pull.commits < 1:
                return None  # No commits == no commit authors

            cache_key = 'repo_%s_pull_%s_commits' % (self.repo_full_name,
                                                     str(num))
            fetch_partial = Partial(pull.get_commits)
            authors = set()
            for commit in self.get_gh_obj(cache_key, fetch_partial):
                # Referencing commit author requires a request, cache it.
                author_cache_key = cache_key + '_%s_author' % str(commit.sha)
                author_fetch_partial = Partial(getattr, commit, 'author')
                try:
                    author_obj = self.get_gh_obj(author_cache_key,
                                                 author_fetch_partial)
                except:
                    # clean up commit list cache entry also
                    self.clean_cache_entry(cache_key)
                    raise  # original exception
                # Retrieve e-mail from git commit object
                if author_obj is None:
                    # Referencing git commit requires a request, cache it
                    gitcommit_cache_key = (cache_key + '_%s_gitcommit'
                                                       % str(commit.sha))
                    gitcommit_fetch_partial = Partial(getattr, commit,
                                                      'commit')  # git commit
                    try:
                        gitcommit = self.get_gh_obj(gitcommit_cache_key,
                                                    gitcommit_fetch_partial)
                    except:
                        # Need to clean commit and gitcommit entries
                        self.clean_cache_entry(cache_key)
                        self.clean_cache_entry(gitcommit_cache_key)
                        raise
                    authors.add(gitcommit.author.email)
                else:  # Author is a github user
                    authors.add(author_obj.login)
            return authors
        return None  # not a pull request

    # marshal_map method
    def gh_pr_commits(self, gh_issue):
        """
        Retrieves the number of commits on a pull-request, None if not a pull.
        """
        if GithubIssues.gh_issue_is_pull(gh_issue):
            num = gh_issue.number
            repo = self.get_repo()
            cache_key = 'repo_%s_pull_%s' % (self.repo_full_name, str(num))
            fetch_partial = Partial(repo.get_pull, num)
            pull = self.get_gh_obj(cache_key, fetch_partial)
            return pull.commits
        return None  # not a pull request


class MutateError(KeyError):

    def __init__(self, key, number):
        super(MutateError, self).__init__("Unable to modify %s on issue %d"
                                          % (str(key), number))


class MutableIssue(dict):

    """Allow modification of some issue values"""

    def __init__(self, github_issues, issue_number):
        if not isinstance(github_issues, GithubIssues):
            raise ValueError("github_issues %s is not a GithubIssues, it's a %s"
                             % (str(github_issues), str(type(github_issues))))
        # make sure issue_number is valid and cached
        junk = github_issues[issue_number]
        del junk
        # Private for private _github_issue property access
        self._github_issues = github_issues
        self._issue_number = issue_number
        super(MutableIssue, self).__init__()

    @property
    def _github_issue(self):
        return self._github_issues[self._issue_number]

    @property
    def _issue_cache_key(self):
        return self.get_issue_cache_key(self._issue_number)

    def _setdelitem(self, opr, key, value):
        if key not in self._github_issues.marshal_map.keys():
            raise MutateError(key, self._issue_number)
        methodname = '%s_%s' % (opr, key)
        if callable(getattr(self, methodname)):
            method = getattr(self, methodname)
            if opr == 'set':
                method(value)
            else:
                method()
        else:
            raise MutateError(key, self._issue_number)

    def __getitem__(self, key):
        # Guarantees fresh/cached data for every call
        return self._github_issue[key]

    def __setitem__(self, key, value):
        self._setdelitem('set', key, value)

    def __delitem__(self, key):
        self._setdelitem('del', key, None)

    def set_labels(self, value):
        """
        Merge list of new lables into existing label set
        """
        new_labels = set(value)
        old_labels = set(self._github_issue['labels'])
        change_list = list(new_labels | old_labels)
        get_gh_label = self._github_issues.get_gh_label  # save typing
        # Raise exception if any label name is bad
        gh_labels = [get_gh_label(label) for label in change_list]
        # Access PyGithub object to change labels
        self._github_issue['github_issue'].set_labels(*gh_labels)
        # Force retrieval of changed item
        self._github_issues.clean_cache_entry(self._issue_cache_key())

    def del_labels(self):
        """
        Remove all lbels from an issue
        """
        self._github_issue['github_issue'].delete_labels()
        # Force retrieval of changed item
        self._github_issues.clean_cache_entry(self._issue_cache_key())

    # TODO: Write get_*(), set_*(), del_*() for other dictionary keys

########NEW FILE########
__FILENAME__ = label_issues
#!/usr/bin/env python

import sys
import os
import getpass
import datetime
from github import Github
from github_issues import GithubIssues, MutableIssue


def set_labels(mutable_issue):
    print "Enter replacement github labels, blank to end:"
    labels = []
    while True:
        label = raw_input("labels[%d]: " % (len(labels) + 1))
        label = label.strip()
        if label:
            try:
                # http://jacquev6.github.io
                # /PyGithub/github_objects/Label.html#github.Label.Label
                labels.append(issues.get_gh_label(label).name)
            except ValueError, detail:
                print str(detail)
        else:
            break
    print
    if len(labels) > 0:
        mutable_issue['labels'] = labels

gh = Github(login_or_token=raw_input("Enter github username: "),
            password=getpass.getpass('Enter github password: '),
            user_agent='PyGithub/Python')

print "Enter location (<user>/<repo>)",
repo_full_name = 'autotest/virt-test'
repo_full_name = raw_input("or blank for '%s': "
                           % repo_full_name).strip() or repo_full_name
print

issues = GithubIssues(gh, repo_full_name)

# Can't directly search for no labels
criteria = {'state': 'open',
            'sort': 'updated', 'direction': 'asc'}  # updated-asc == oldest first

heading = ("Open, unlabeled issues from %s, oldest-first" % repo_full_name)
print heading
print "-" * len(heading)
print

repo = gh.get_repo(repo_full_name)
labels = ", ".join([label.name for label in repo.get_labels()])

for number in issues.search(criteria):
    if len(issues[number]['labels']) > 0:
        continue
    print '#%d:' % number,
    print issues[number]['summary'] + ':'
    print issues[number]['description']
    print "Available Labels:", labels
    set_labels(MutableIssue(issues, number))

# make sure cache is cleaned and saved up
del issues

print

########NEW FILE########
__FILENAME__ = pulls_applied
#!/usr/bin/env python

import sys
import os
import getpass
import datetime
from github import Github
from github_issues import GithubIssues

gh = Github(login_or_token=raw_input("Enter github username: "),
            password=getpass.getpass('Enter github password: '),
            user_agent='PyGithub/Python')

print "Enter location (<user>/<repo>)",
repo_full_name = 'autotest/virt-test'
repo_full_name = raw_input("or blank for '%s': "
                           % repo_full_name).strip() or repo_full_name

print

issues = GithubIssues(gh, repo_full_name)
print

print "Pull requests applied since:"

while True:
    date_string = "20" + raw_input("Enter date (YY-MM-DD): ") + " 00:00:00.0"
    date_string = date_string.strip()
    fmt = '%Y-%m-%d %H:%M:%S.%f'
    try:
        since = datetime.datetime.strptime(date_string, fmt)
        break
    except ValueError:
        print "When?"
print

print "Enter github labels, blank to end:"
labels = []
while True:
    label = raw_input("labels[%d]" % (len(labels) + 1))
    label = label.strip()
    if label:
        try:
            # http://jacquev6.github.io
            # /PyGithub/github_objects/Label.html#github.Label.Label
            labels.append(issues.get_gh_label(label).name)
        except ValueError, detail:
            print str(detail)
    else:
        break
print

# Search criteria is put into a dictionary
#            state - str - 'open', 'closed'
#            assignee - list of str (login), "none" or "*"
#            mentioned - str (login)
#            labels - list of str (label name)
#            sort - str - 'created', 'updated', 'comments'
#            direction - str - 'asc', 'desc'
#            since - datetime.datetime
criteria = {'state': 'closed', 'labels': labels,
            'sort': 'updated', 'since': since}

heading = ("Applied %s pull-requests from %s since %s  by author"
           % (",".join(labels), repo_full_name, since.isoformat()))
print heading
print "-" * len(heading)
print

author_issues = {}
for number in issues.search(criteria):
    issue = issues[number]
    # Issues don't have commits
    if issue['commits'] is not None:
        author_issues[issue['author']] = issue

authors = author_issues.keys()
authors.sort()
for author in authors:
    issue = author_issues[author]
    print "Pull #%d: '%s'" % (issue['number'], issue['summary'])
    print "    %d commit(s) by %s" % (issue['commits'],
                                      ",".join(issue['commit_authors']))
    print

# make sure cache is cleaned and saved up
del issues

print

########NEW FILE########
__FILENAME__ = stale_pulls
#!/usr/bin/env python

import sys
import os
import getpass
import datetime
from github import Github
from github_issues import GithubIssues

gh = Github(login_or_token=raw_input("Enter github username: "),
            password=getpass.getpass('Enter github password: '),
            user_agent='PyGithub/Python')

print "Enter location (<user>/<repo>)",
repo_full_name = 'autotest/virt-test'
repo_full_name = raw_input("or blank for '%s': "
                           % repo_full_name).strip() or repo_full_name

print

issues = GithubIssues(gh, repo_full_name)

print "Enter github labels, blank to end:"
labels = []
while True:
    label = raw_input("labels[%d]: " % (len(labels) + 1))
    label = label.strip()
    if label:
        try:
            # http://jacquev6.github.io
            # /PyGithub/github_objects/Label.html#github.Label.Label
            labels.append(issues.get_gh_label(label).name)
        except ValueError, detail:
            print str(detail)
    else:
        break
print

criteria = {'state': 'open', 'labels': labels,
            'sort': 'updated', 'direction': 'asc'}

heading = ("Oldest updates for Open %s pull requests from %s, past 1 day old:"
           % (",".join(labels), repo_full_name))
print heading
print "-" * len(heading)
print

for number in issues.search(criteria):
    if issues[number]['commits'] and issues[number]['commits'] > 0:
        age = datetime.datetime.now() - issues[number]['modified']
        hours = age.seconds / (60 * 60)
        days = age.days
        url = issues[number]['url']
        summary = issues[number]['summary']
        if days > 0:
            print "%s -  %d days %d hours old - %s" % (
                  url, days, hours, summary[0:30])
        else:
            # Results sorted by decreasing update age
            # don't care about issues updated today
            break

# make sure cache is cleaned and saved up
del issues

print

########NEW FILE########
__FILENAME__ = unassigned_issues
#!/usr/bin/env python

import sys
import os
import getpass
import datetime
from github import Github
from github_issues import GithubIssues

gh = Github(login_or_token=raw_input("Enter github username: "),
            password=getpass.getpass('Enter github password: '),
            user_agent='PyGithub/Python')

print "Enter location (<user>/<repo>)",
repo_full_name = 'autotest/virt-test'
repo_full_name = raw_input("or blank for '%s': "
                           % repo_full_name).strip() or repo_full_name

print

issues = GithubIssues(gh, repo_full_name)

print "Enter github labels, blank to end:"
labels = []
while True:
    label = raw_input("labels[%d]" % (len(labels) + 1))
    label = label.strip()
    if label:
        try:
            # http://jacquev6.github.io
            # /PyGithub/github_objects/Label.html#github.Label.Label
            labels.append(issues.get_gh_label(label).name)
        except ValueError, detail:
            print str(detail)
    else:
        break
print

criteria = {'state': 'open', 'assignee': 'none', 'labels': labels,
            'sort': 'updated', 'direction': 'asc'}  # asc-updated == oldest first

heading = ("Unassigned %s issues from %s, oldest-first"
           % (",".join(labels), repo_full_name))
print heading
print "-" * len(heading)
print

for number in issues.search(criteria):
    print issues[number]['url'], issues[number]['summary'][:30]

# make sure cache is cleaned and saved up
del issues

print

########NEW FILE########
__FILENAME__ = koji_pkgspec
#!/usr/bin/env python

'''
This is a tool for that makes it easy to understand what a given KojiPkgSpec
syntax will expand to.

The main use case is making sure the packages specified in a KojiInstaller
will match the packages you intended to install.
'''

import sys
import optparse
import common
from virttest import cartesian_config

try:
    from virttest.staging import utils_koji
except ImportError:
    from autotest.client.shared import utils_koji


class OptionParser(optparse.OptionParser):

    '''
    KojiPkgSpec App option parser
    '''

    def __init__(self):
        optparse.OptionParser.__init__(self,
                                       usage=('Usage: %prog [options] '
                                              '[koji-pkg-spec]'))

        general = optparse.OptionGroup(self, 'GENERAL OPTIONS')
        general.add_option('-a', '--arch', dest='arch', default='x86_64',
                           help=('architecture of packages to list, together '
                                 'with "noarch". defaults to "x86_64"'))
        general.add_option('-t', '--tag', dest='tag', help='default koji tag')
        self.add_option_group(general)

        cartesian_config = optparse.OptionGroup(self, 'CARTESIAN CONFIG')
        cartesian_config.add_option('-c', '--config', dest='config',
                                    help=('use a cartesian configuration file '
                                          'for fetching package values'))

        self.add_option_group(cartesian_config)


class App:

    '''
    KojiPkgSpec app
    '''

    def __init__(self):
        self.opt_parser = OptionParser()

    def usage(self):
        self.opt_parser.print_help()
        sys.exit(1)

    def parse_cmdline(self):
        self.options, self.args = self.opt_parser.parse_args()

        # Check for a control file if not in prebuild mode.
        if (len(self.args) < 1) and not self.options.config:
            print "Missing Package Specification!"
            self.usage()

    def get_koji_qemu_kvm_tag_pkgs(self, config_file):
        tag = None
        pkgs = None
        parser = cartesian_config.Parser(config_file)
        for d in parser.get_dicts():
            if tag is not None and pkgs is not None:
                break

            if d.has_key('koji_qemu_kvm_tag'):
                if tag is None:
                    tag = d.get('koji_qemu_kvm_tag')
            if d.has_key('koji_qemu_kvm_pkgs'):
                if pkgs is None:
                    pkgs = d.get('koji_qemu_kvm_pkgs')
        return (tag, pkgs)

    def check_koji_pkg_spec(self, koji_pkg_spec):
        if not koji_pkg_spec.is_valid():
            print 'ERROR:', koji_pkg_spec.describe_invalid()
            sys.exit(-1)

    def print_koji_pkg_spec_info(self, koji_pkg_spec):
        info = self.koji_client.get_pkg_info(koji_pkg_spec)
        if not info:
            print 'ERROR: could not find info about "%s"' % koji_pkg_spec.to_text()
            return

        name = info.get('name', 'unknown')
        pkgs = self.koji_client.get_pkg_rpm_file_names(koji_pkg_spec,
                                                       arch=self.options.arch)
        print 'Package name: %s' % name
        print 'Package files:'
        for p in pkgs:
            print '\t* %s' % p
        print

    def main(self):
        self.parse_cmdline()
        self.koji_client = utils_koji.KojiClient()
        pkgs = []

        if self.options.tag:
            utils_koji.set_default_koji_tag(self.options.tag)

        if self.options.config:
            tag, pkgs = self.get_koji_qemu_kvm_tag_pkgs(self.options.config)
            if tag is not None:
                utils_koji.set_default_koji_tag(tag)
            if pkgs is not None:
                pkgs = pkgs.split()
        else:
            pkgs = self.args

        if pkgs:
            for p in pkgs:
                koji_pkg_spec = utils_koji.KojiPkgSpec(p)
                self.check_koji_pkg_spec(koji_pkg_spec)
                self.print_koji_pkg_spec_info(koji_pkg_spec)


if __name__ == '__main__':
    app = App()
    app.main()

########NEW FILE########
__FILENAME__ = package_jeos
#!/usr/bin/python

import os
import sys
import logging
import shutil

import common
from autotest.client import utils
from autotest.client.shared import logging_manager
from virttest import utils_misc


def package_jeos(img):
    """
    Package JeOS and make it ready for upload.

    Steps:
    1) Move /path/to/jeos.qcow2 to /path/to/jeos.qcow2.backup
    2) Sparsify the image, creating a new, trimmed down /path/to/jeos.qcow2
    3) Compress the sparsified image with 7za

    :param img: Path to a qcow2 image
    """
    basedir = os.path.dirname(img)
    backup = img + '.backup'
    qemu_img = utils_misc.find_command('qemu-img')
    shutil.move(img, backup)
    logging.info("Backup %s saved", backup)

    utils.system("%s convert -f qcow2 -O qcow2 %s %s" % (qemu_img, backup, img))
    logging.info("Sparse file %s created successfully", img)

    archiver = utils_misc.find_command('7za')
    compressed_img = img + ".7z"
    utils.system("%s a %s %s" % (archiver, compressed_img, img))
    logging.info("JeOS compressed file %s created successfuly",
                 compressed_img)


if __name__ == "__main__":
    logging_manager.configure_logging(utils_misc.VirtLoggingConfig(),
                                      verbose=True)

    if len(sys.argv) <= 1:
        logging.info("Usage: %s [path to freshly installed JeOS qcow2 image]",
                     sys.argv[0])
        sys.exit(1)

    path = sys.argv[1]
    image = os.path.abspath(path)
    package_jeos(image)

########NEW FILE########
__FILENAME__ = parallel
import os
import sys


class ParallelError(Exception):

    def __init__(self, out, errors):
        self.out = out
        self.errors = errors
        Exception.__init__(self, out)


class ParallelExecute(object):

    def __init__(self, functions, max_simultaneous_procs=20):
        """
        This takes in a dictionary of functions which map to a set of
        functions that they depend on.

        functions: This is either a list of or dictionary of functions to
                   be run.  If it's a dictionary, the value should be a set
                   of other functions this function is dependent on.  If its
                   a list (or tuple or anything iterable that returns a
                   single element each iteration), then it's assumed that
                   there are no dependencies.

        max_simultaneous_procs: Throttle the number of processes we have
                                running at once.
        """
        if not isinstance(functions, dict):
            function_list = functions
            functions = {}
            for fn in function_list:
                functions[fn] = set()

        dependents = {}
        for fn, deps in functions.iteritems():
            dependents[fn] = []
        for fn, deps in functions.iteritems():
            for dep in deps:
                dependents[dep].append(fn)

        self.max_procs = max_simultaneous_procs
        self.functions = functions
        self.dependents = dependents
        self.pid_map = {}
        self.ready_to_run = []

    def _run(self, function):
        self.functions.pop(function)
        pid = os.fork()
        if pid:
            self.pid_map[pid] = function
        else:
            function()
            sys.exit(0)

    def run_until_completion(self):
        for fn, deps in self.functions.iteritems():
            if len(deps) == 0:
                self.ready_to_run.append(fn)

        errors = []
        while len(self.pid_map) > 0 or len(self.ready_to_run) > 0:
            max_allowed = self.max_procs - len(self.pid_map)
            max_able = len(self.ready_to_run)
            for _ in xrange(min(max_allowed, max_able)):
                self._run(self.ready_to_run.pop())

            # Handle one proc that's finished.
            pid, status = os.wait()
            fn = self.pid_map.pop(pid)
            if status != 0:
                errors.append("%s failed" % fn.__name__)
                continue

            for dependent in self.dependents[fn]:
                self.functions[dependent].remove(fn)
                if len(self.functions[dependent]) == 0:
                    self.ready_to_run.append(dependent)

        if len(self.functions) > 0 and len(errors) == 0:
            errors.append("Deadlock detected")

        if len(errors) > 0:
            msg = "Errors occurred during execution:"
            msg = '\n'.join([msg] + errors)
            raise ParallelError(msg, errors)


def redirect_io(log_file='/dev/null'):
    # Always redirect stdin.
    in_fd = os.open('/dev/null', os.O_RDONLY)
    try:
        os.dup2(in_fd, 0)
    finally:
        os.close(in_fd)

    out_fd = os.open(log_file, os.O_WRONLY | os.O_CREAT)
    try:
        os.dup2(out_fd, 2)
        os.dup2(out_fd, 1)
    finally:
        os.close(out_fd)

    sys.stdin = os.fdopen(0, 'r')
    sys.stdout = os.fdopen(1, 'w')
    sys.stderr = os.fdopen(2, 'w')

########NEW FILE########
__FILENAME__ = regression
#!/usr/bin/python
"""
Program that parses standard format results,
compute and check regression bug.

:copyright: Red Hat 2011-2012
:author: Amos Kong <akong@redhat.com>
"""
import os
import sys
import re
import commands
import warnings
import ConfigParser
import MySQLdb


def exec_sql(cmd, conf="../../global_config.ini"):
    config = ConfigParser.ConfigParser()
    config.read(conf)
    user = config.get("AUTOTEST_WEB", "user")
    passwd = config.get("AUTOTEST_WEB", "password")
    db = config.get("AUTOTEST_WEB", "database")
    db_type = config.get("AUTOTEST_WEB", "db_type")
    if db_type != 'mysql':
        print "regression.py: only support mysql database!"
        sys.exit(1)

    conn = MySQLdb.connect(host="localhost", user=user,
                           passwd=passwd, db=db)
    cursor = conn.cursor()
    cursor.execute(cmd)
    rows = cursor.fetchall()
    lines = []
    for row in rows:
        line = []
        for c in row:
            line.append(str(c))
        lines.append(" ".join(line))

    cursor.close()
    conn.close()
    return lines


def get_test_keyval(jobid, keyname, default=''):
    idx = exec_sql("select job_idx from tko_jobs where afe_job_id=%s"
                   % jobid)[-1]
    test_idx = exec_sql('select test_idx from tko_tests where job_idx=%s'
                        % idx)[3]
    try:
        return exec_sql('select value from tko_test_attributes'
                        ' where test_idx=%s and attribute="%s"'
                        % (test_idx, keyname))[-1]
    except:
        return default


class Sample(object):

    """ Collect test results in same environment to a sample """

    def __init__(self, sample_type, arg):
        def generate_raw_table(test_dict):
            ret_dict = []
            tmp = []
            sample_type = category = None
            for i in test_dict:
                line = i.split('|')[1:]
                if not sample_type:
                    sample_type = line[0:2]
                if sample_type != line[0:2]:
                    ret_dict.append('|'.join(sample_type + tmp))
                    sample_type = line[0:2]
                    tmp = []
                if "e+" in line[-1]:
                    tmp.append("%f" % float(line[-1]))
                elif 'e-' in line[-1]:
                    tmp.append("%f" % float(line[-1]))
                elif not (re.findall("[a-zA-Z]", line[-1]) or is_int(line[-1])):
                    tmp.append("%f" % float(line[-1]))
                else:
                    tmp.append(line[-1])

                if category != i.split('|')[0]:
                    category = i.split('|')[0]
                    ret_dict.append("Category:" + category.strip())
                    ret_dict.append(self.categories)
            ret_dict.append('|'.join(sample_type + tmp))
            return ret_dict

        if sample_type == 'filepath':
            files = arg.split()
            self.files_dict = []
            for i in range(len(files)):
                fd = open(files[i], "r")
                f = []
                for l in fd.readlines():
                    l = l.strip()
                    if re.findall("^### ", l):
                        if "kvm-userspace-ver" in l:
                            self.kvmver = l.split(':')[-1]
                        elif "kvm_version" in l:
                            self.hostkernel = l.split(':')[-1]
                        elif "guest-kernel-ver" in l:
                            self.guestkernel = l.split(':')[-1]
                        elif "session-length" in l:
                            self.len = l.split(':')[-1]
                    else:
                        f.append(l.strip())
                self.files_dict.append(f)
                fd.close()

            sysinfodir = os.path.join(os.path.dirname(files[0]), "../../sysinfo/")
            sysinfodir = os.path.realpath(sysinfodir)
            cpuinfo = commands.getoutput("cat %s/cpuinfo" % sysinfodir)
            lscpu = commands.getoutput("cat %s/lscpu" % sysinfodir)
            meminfo = commands.getoutput("cat %s/meminfo" % sysinfodir)
            lspci = commands.getoutput("cat %s/lspci_-vvnn" % sysinfodir)
            partitions = commands.getoutput("cat %s/partitions" % sysinfodir)
            fdisk = commands.getoutput("cat %s/fdisk_-l" % sysinfodir)

            status_path = os.path.join(os.path.dirname(files[0]), "../status")
            status_file = open(status_path, 'r')
            content = status_file.readlines()
            self.testdata = re.findall("localtime=(.*)\t", content[-1])[-1]

            cpunum = len(re.findall("processor\s+: \d", cpuinfo))
            cpumodel = re.findall("Model name:\s+(.*)", lscpu)
            socketnum = int(re.findall("Socket\(s\):\s+(\d+)", lscpu)[0])
            corenum = int(re.findall("Core\(s\) per socket:\s+(\d+)", lscpu)[0]) * socketnum
            threadnum = int(re.findall("Thread\(s\) per core:\s+(\d+)", lscpu)[0]) * corenum
            numanodenum = int(re.findall("NUMA node\(s\):\s+(\d+)", lscpu)[0])
            memnum = float(re.findall("MemTotal:\s+(\d+)", meminfo)[0]) / 1024 / 1024
            nicnum = len(re.findall("\d+:\d+\.0 Ethernet", lspci))
            disknum = re.findall("sd\w+\S", partitions)
            fdiskinfo = re.findall("Disk\s+(/dev/sd.*\s+GiB),", fdisk)
        elif sample_type == 'database':
            jobid = arg
            self.kvmver = get_test_keyval(jobid, "kvm-userspace-ver")
            self.hostkernel = get_test_keyval(jobid, "kvm_version")
            self.guestkernel = get_test_keyval(jobid, "guest-kernel-ver")
            self.len = get_test_keyval(jobid, "session-length")
            self.categories = get_test_keyval(jobid, "category")

            idx = exec_sql("select job_idx from tko_jobs where afe_job_id=%s"
                           % jobid)[-1]
            data = exec_sql("select test_idx,iteration_key,iteration_value"
                            " from tko_perf_view where job_idx=%s" % idx)
            testidx = None
            job_dict = []
            test_dict = []
            for l in data:
                s = l.split()
                if not testidx:
                    testidx = s[0]
                if testidx != s[0]:
                    job_dict.append(generate_raw_table(test_dict))
                    test_dict = []
                    testidx = s[0]
                test_dict.append(' | '.join(s[1].split('--')[0:] + s[-1:]))

            job_dict.append(generate_raw_table(test_dict))
            self.files_dict = job_dict

        self.version = " userspace: %s\n host kernel: %s\n guest kernel: %s" % (
            self.kvmver, self.hostkernel, self.guestkernel)
        nrepeat = len(self.files_dict)
        if nrepeat < 2:
            print "`nrepeat' should be larger than 1!"
            sys.exit(1)

        self.desc = """<hr>Machine Info:
o CPUs(%s * %s), Cores(%s), Threads(%s), Sockets(%s),
o NumaNodes(%s), Memory(%.1fG), NICs(%s)
o Disks(%s | %s)

Please check sysinfo directory in autotest result to get more details.
(eg: http://autotest-server.com/results/5057-autotest/host1/sysinfo/)
<hr>""" % (cpunum, cpumodel, corenum, threadnum, socketnum, numanodenum, memnum, nicnum, fdiskinfo, disknum)

        self.desc += """ - Every Avg line represents the average value based on *%d* repetitions of the same test,
   and the following SD line represents the Standard Deviation between the *%d* repetitions.
 - The Standard deviation is displayed as a percentage of the average.
 - The significance of the differences between the two averages is calculated using unpaired T-test that
   takes into account the SD of the averages.
 - The paired t-test is computed for the averages of same category.

""" % (nrepeat, nrepeat)

    def getAvg(self, avg_update=None):
        return self._process_files(self.files_dict, self._get_list_avg,
                                   avg_update=avg_update)

    def getAvgPercent(self, avgs_dict):
        return self._process_files(avgs_dict, self._get_augment_rate)

    def getSD(self):
        return self._process_files(self.files_dict, self._get_list_sd)

    def getSDRate(self, sds_dict):
        return self._process_files(sds_dict, self._get_rate)

    def getTtestPvalue(self, fs_dict1, fs_dict2, paired=None, ratio=None):
        """
        scipy lib is used to compute p-value of Ttest
        scipy: http://www.scipy.org/
        t-test: http://en.wikipedia.org/wiki/Student's_t-test
        """
        try:
            from scipy import stats
            import numpy as np
        except ImportError:
            print "No python scipy/numpy library installed!"
            return None

        ret = []
        s1 = self._process_files(fs_dict1, self._get_list_self, merge=False)
        s2 = self._process_files(fs_dict2, self._get_list_self, merge=False)
        # s*[line][col] contians items (line*col) of all sample files

        for line in range(len(s1)):
            tmp = []
            if type(s1[line]) != list:
                tmp = s1[line]
            else:
                if len(s1[line][0]) < 2:
                    continue
                for col in range(len(s1[line])):
                    avg1 = self._get_list_avg(s1[line][col])
                    avg2 = self._get_list_avg(s2[line][col])
                    sample1 = np.array(s1[line][col])
                    sample2 = np.array(s2[line][col])
                    warnings.simplefilter("ignore", RuntimeWarning)
                    if (paired):
                        if (ratio):
                            (_, p) = stats.ttest_rel(np.log(sample1), np.log(sample2))
                        else:
                            (_, p) = stats.ttest_rel(sample1, sample2)
                    else:
                        (_, p) = stats.ttest_ind(sample1, sample2)
                    flag = "+"
                    if float(avg1) > float(avg2):
                        flag = "-"
                    tmp.append(flag + "%f" % (1 - p))
                tmp = "|".join(tmp)
            ret.append(tmp)
        return ret

    def _get_rate(self, data):
        """ num2 / num1 * 100 """
        result = "0.0"
        if len(data) == 2 and float(data[0]) != 0:
            result = float(data[1]) / float(data[0]) * 100
            if result > 100:
                result = "%.2f%%" % result
            else:
                result = "%.4f%%" % result
        return result

    def _get_augment_rate(self, data):
        """ (num2 - num1) / num1 * 100 """
        result = "+0.0"
        if len(data) == 2 and float(data[0]) != 0:
            result = (float(data[1]) - float(data[0])) / float(data[0]) * 100
            if result > 100:
                result = "%+.2f%%" % result
            else:
                result = "%+.4f%%" % result
        return result

    def _get_list_sd(self, data):
        """
        sumX = x1 + x2 + ... + xn
        avgX = sumX / n
        sumSquareX = x1^2 + ... + xn^2
        SD = sqrt([sumSquareX - (n * (avgX ^ 2))] / (n - 1))
        """
        o_sum = sqsum = 0.0
        n = len(data)
        for i in data:
            o_sum += float(i)
            sqsum += float(i) ** 2
        avg = o_sum / n
        if avg == 0 or n == 1 or sqsum - (n * avg ** 2) <= 0:
            return "0.0"
        return "%f" % (((sqsum - (n * avg ** 2)) / (n - 1)) ** 0.5)

    def _get_list_avg(self, data):
        """ Compute the average of list entries """
        o_sum = 0.0
        for i in data:
            o_sum += float(i)
        return "%f" % (o_sum / len(data))

    def _get_list_self(self, data):
        """ Use this to convert sample dicts """
        return data

    def _process_lines(self, files_dict, row, func, avg_update, merge):
        """ Use unified function to process same lines of different samples """
        lines = []
        ret = []

        for i in range(len(files_dict)):
            lines.append(files_dict[i][row].split("|"))

        for col in range(len(lines[0])):
            data_list = []
            for i in range(len(lines)):
                tmp = lines[i][col].strip()
                if is_int(tmp):
                    data_list.append(int(tmp))
                else:
                    data_list.append(float(tmp))
            ret.append(func(data_list))

        if avg_update:
            for i in avg_update.split('|'):
                l = i.split(',')
                ret[int(l[0])] = "%f" % (float(ret[int(l[1])]) /
                                         float(ret[int(l[2])]))
        if merge:
            return "|".join(ret)
        return ret

    def _process_files(self, files_dict, func, avg_update=None, merge=True):
        """
        Process dicts of sample files with assigned function,
        func has one list augment.
        """
        ret_lines = []
        for i in range(len(files_dict[0])):
            if re.findall("[a-zA-Z]", files_dict[0][i]):
                ret_lines.append(files_dict[0][i].strip())
            else:
                line = self._process_lines(files_dict, i, func, avg_update,
                                           merge)
                ret_lines.append(line)
        return ret_lines


def display(lists, rates, allpvalues, f, ignore_col, o_sum="Augment Rate",
            prefix0=None, prefix1=None, prefix2=None, prefix3=None):
    """
    Display lists data to standard format

    param lists: row data lists
    param rates: augment rates lists
    param f: result output filepath
    param ignore_col: do not display some columns
    param o_sum: compare result summary
    param prefix0: output prefix in head lines
    param prefix1: output prefix in Avg/SD lines
    param prefix2: output prefix in Diff Avg/P-value lines
    param prefix3: output prefix in total Sign line
    """
    def str_ignore(out, split=False):
        out = out.split("|")
        for i in range(ignore_col):
            out[i] = " "
        if split:
            return "|".join(out[ignore_col:])
        return "|".join(out)

    def tee_line(content, filepath, n=None):
        fd = open(filepath, "a")
        print content
        out = ""
        out += "<TR ALIGN=CENTER>"
        content = content.split("|")
        for i in range(len(content)):
            if not is_int(content[i]) and is_float(content[i]):
                if "+" in content[i] or "-" in content[i]:
                    if float(content[i]) > 100:
                        content[i] = "%+.2f" % float(content[i])
                    else:
                        content[i] = "%+.4f" % float(content[i])
                elif float(content[i]) > 100:
                    content[i] = "%.2f" % float(content[i])
                else:
                    content[i] = "%.4f" % float(content[i])
            if n and i >= 2 and i < ignore_col + 2:
                out += "<TD ROWSPAN=%d WIDTH=1%% >%.0f</TD>" % (n, float(content[i]))
            else:
                out += "<TD WIDTH=1%% >%s</TD>" % content[i]
        out += "</TR>"
        fd.write(out + "\n")
        fd.close()

    for l in range(len(lists[0])):
        if not re.findall("[a-zA-Z]", lists[0][l]):
            break
    tee("<TABLE BORDER=1 CELLSPACING=1 CELLPADDING=1 width=10%><TBODY>",
        f)
    tee("<h3>== %s " % o_sum + "==</h3>", f)
    category = 0
    for i in range(len(lists[0])):
        for n in range(len(lists)):
            is_diff = False
            for j in range(len(lists)):
                if lists[0][i] != lists[j][i]:
                    is_diff = True
                if len(lists) == 1 and not re.findall("[a-zA-Z]", lists[j][i]):
                    is_diff = True

            pfix = prefix1[0]
            if len(prefix1) != 1:
                pfix = prefix1[n]
            if is_diff:
                if n == 0:
                    tee_line(pfix + lists[n][i], f, n=len(lists) + len(rates))
                else:
                    tee_line(pfix + str_ignore(lists[n][i], True), f)
            if not is_diff and n == 0:
                if '|' in lists[n][i]:
                    tee_line(prefix0 + lists[n][i], f)
                elif "Category:" in lists[n][i]:
                    if category != 0 and prefix3:
                        if len(allpvalues[category - 1]) > 0:
                            tee_line(prefix3 + str_ignore(
                                     allpvalues[category - 1][0]), f)
                        tee("</TBODY></TABLE>", f)
                        tee("<br>", f)
                        tee("<TABLE BORDER=1 CELLSPACING=1 CELLPADDING=1 "
                            "width=10%><TBODY>", f)
                    category += 1
                    tee("<TH colspan=3 >%s</TH>" % lists[n][i], f)
                else:
                    tee("<TH colspan=3 >%s</TH>" % lists[n][i], f)
        for n in range(len(rates)):
            if lists[0][i] != rates[n][i] and (not re.findall("[a-zA-Z]",
                                                              rates[n][i]) or "nan" in rates[n][i]):
                tee_line(prefix2[n] + str_ignore(rates[n][i], True), f)
    if prefix3 and len(allpvalues[-1]) > 0:
        tee_line(prefix3 + str_ignore(allpvalues[category - 1][0]), f)
    tee("</TBODY></TABLE>", f)


def analyze(test, sample_type, arg1, arg2, configfile):
    """ Compute averages/p-vales of two samples, print results nicely """
    config = ConfigParser.ConfigParser()
    config.read(configfile)
    ignore_col = int(config.get(test, "ignore_col"))
    avg_update = config.get(test, "avg_update")
    desc = config.get(test, "desc")

    def get_list(directory):
        result_file_pattern = config.get(test, "result_file_pattern")
        cmd = 'find %s|grep "%s.*/%s"' % (directory, test, result_file_pattern)
        print cmd
        return commands.getoutput(cmd)

    if sample_type == 'filepath':
        arg1 = get_list(arg1)
        arg2 = get_list(arg2)

    commands.getoutput("rm -f %s.*html" % test)
    s1 = Sample(sample_type, arg1)
    avg1 = s1.getAvg(avg_update=avg_update)
    sd1 = s1.getSD()

    s2 = Sample(sample_type, arg2)
    avg2 = s2.getAvg(avg_update=avg_update)
    sd2 = s2.getSD()

    sd1 = s1.getSDRate([avg1, sd1])
    sd2 = s1.getSDRate([avg2, sd2])
    avgs_rate = s1.getAvgPercent([avg1, avg2])

    navg1 = []
    navg2 = []
    allpvalues = []
    tmp1 = []
    tmp2 = []
    for i in range(len(avg1)):
        if not re.findall("[a-zA-Z]", avg1[i]):
            tmp1.append([avg1[i]])
            tmp2.append([avg2[i]])
        elif 'Category' in avg1[i] and i != 0:
            navg1.append(tmp1)
            navg2.append(tmp2)
            tmp1 = []
            tmp2 = []
    navg1.append(tmp1)
    navg2.append(tmp2)

    for i in range(len(navg1)):
        allpvalues.append(s1.getTtestPvalue(navg1[i], navg2[i], True, True))

    pvalues = s1.getTtestPvalue(s1.files_dict, s2.files_dict, False)
    rlist = [avgs_rate]
    if pvalues:
        # p-value list isn't null
        rlist.append(pvalues)

    desc = desc % s1.len

    tee("<pre>####1. Description of setup#1\n" + s1.version + "\n test data:  "
        + s1.testdata + "</pre>", test + ".html")
    tee("<pre>####2. Description of setup#2\n" + s2.version + "\n test data:  "
        + s2.testdata + "</pre>", test + ".html")
    tee("<pre>" + '\n'.join(desc.split('\\n')) + "</pre>", test + ".html")
    tee("<pre>" + s1.desc + "</pre>", test + ".html")

    display([avg1, sd1, avg2, sd2], rlist, allpvalues, test + ".html",
            ignore_col, o_sum="Regression Testing: %s" % test, prefix0="#|Tile|",
            prefix1=["1|Avg|", " |%SD|", "2|Avg|", " |%SD|"],
            prefix2=["-|%Diff between Avg|", "-|Significance|"],
            prefix3="-|Total Significance|")

    display(s1.files_dict, [avg1], [], test + ".avg.html", ignore_col,
            o_sum="Raw data of sample 1", prefix0="#|Tile|",
            prefix1=[" |    |"],
            prefix2=["-|Avg |"], prefix3="")

    display(s2.files_dict, [avg2], [], test + ".avg.html", ignore_col,
            o_sum="Raw data of sample 2", prefix0="#|Tile|",
            prefix1=[" |    |"],
            prefix2=["-|Avg |"], prefix3="")


def is_int(n):
    try:
        int(n)
        return True
    except ValueError:
        return False


def is_float(n):
    try:
        float(n)
        return True
    except ValueError:
        return False


def tee(content, filepath):
    """ Write content to standard output and filepath """
    fd = open(filepath, "a")
    fd.write(content + "\n")
    fd.close()
    print content


if __name__ == "__main__":
    if len(sys.argv) != 5:
        this = os.path.basename(sys.argv[0])
        print 'Usage: %s <testname> filepath <dir1> <dir2>' % this
        print '    or %s <testname> db <jobid1> <jobid2>' % this
        sys.exit(1)
    analyze(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], 'perf.conf')

########NEW FILE########
__FILENAME__ = run_unittests
#!/usr/bin/python -u

import os
import sys
import unittest
import optparse
import fcntl
import common
from autotest.client.shared.test_utils import unittest as custom_unittest
import parallel


class StreamProxy(object):

    """
    Mechanism to suppress stdout output, while keeping the original stdout.
    """

    def __init__(self, filename='/dev/null', stream=sys.stdout):
        """
        Keep 2 streams to write to, and eventually switch.
        """
        self.terminal = stream
        self.log = open(filename, "a")
        self.stream = self.log

    def write(self, message):
        """
        Write to the current stream.
        """
        self.stream.write(message)

    def flush(self):
        """
        Flush the current stream.
        """
        self.stream.flush()

    def switch(self):
        """
        Switch between the 2 currently available streams.
        """
        if self.stream == self.log:
            self.stream = self.terminal
        else:
            self.stream = self.log


def print_stdout(sr, end=True):
    try:
        sys.stdout.switch()
    except AttributeError:
        pass
    if end:
        print(sr)
    else:
        print(sr),
    try:
        sys.stdout.switch()
    except AttributeError:
        pass


class Bcolors(object):

    """
    Very simple class with color support.
    """

    def __init__(self):
        self.HEADER = '\033[94m'
        self.PASS = '\033[92m'
        self.SKIP = '\033[93m'
        self.FAIL = '\033[91m'
        self.ENDC = '\033[0m'
        allowed_terms = ['linux', 'xterm', 'xterm-256color', 'vt100']
        term = os.environ.get("TERM")
        if (not os.isatty(1)) or (term not in allowed_terms):
            self.disable()

    def disable(self):
        self.HEADER = ''
        self.PASS = ''
        self.SKIP = ''
        self.FAIL = ''
        self.ENDC = ''

# Instantiate bcolors to be used in the functions below.
bcolors = Bcolors()


def print_header(sr):
    """
    Print a string to stdout with HEADER (blue) color.
    """
    print_stdout(bcolors.HEADER + sr + bcolors.ENDC)


def print_skip():
    """
    Print SKIP to stdout with SKIP (yellow) color.
    """
    print_stdout(bcolors.SKIP + "SKIP" + bcolors.ENDC)


def print_pass(end=True):
    """
    Print PASS to stdout with PASS (green) color.
    """
    print_stdout(bcolors.PASS + "PASS" + bcolors.ENDC, end=end)


def print_fail(end=True):
    """
    Print FAIL to stdout with FAIL (red) color.
    """
    print_stdout(bcolors.FAIL + "FAIL" + bcolors.ENDC, end=end)


def silence_stderr():
    out_fd = os.open('/dev/null', os.O_WRONLY | os.O_CREAT)
    try:
        os.dup2(out_fd, 2)
    finally:
        os.close(out_fd)
    sys.stderr = os.fdopen(2, 'w')


parser = optparse.OptionParser()
parser.add_option("-r", action="store", type="string", dest="start",
                  default='',
                  help="root directory to start running unittests")
parser.add_option("--full", action="store_true", dest="full", default=False,
                  help="whether to run the shortened version of the test")
parser.add_option("--debug", action="store_true", dest="debug", default=False,
                  help="run in debug mode")
parser.add_option("--skip-tests", dest="skip_tests", default=[],
                  help="A space separated list of tests to skip")

parser.set_defaults(module_list=None)

ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))


class TestFailure(Exception):
    pass


def run_test(mod_names, options):
    """
    :param mod_names: A list of individual parts of the module name to import
            and run as a test suite.
    :param options: optparse options.
    """
    if not options.debug:
        sys.stdout = StreamProxy(stream=sys.stdout)
        silence_stderr()
    else:
        sys.stdout = StreamProxy(stream=sys.stdout)

    test_name = '.'.join(mod_names)
    fail = False

    try:
        from_module = __import__(mod_names[0], globals(), locals(), [mod_names[-1]])
        mod = getattr(from_module, mod_names[-1])

        for ut_module in [unittest, custom_unittest]:
            test = ut_module.defaultTestLoader.loadTestsFromModule(mod)
            suite = ut_module.TestSuite(test)
            runner = ut_module.TextTestRunner(verbosity=2)
            result = runner.run(suite)
            if result.errors or result.failures:
                fail = True
    except:
        fail = True

    lockfile = open('/var/tmp/unittest.lock', 'w')
    fcntl.flock(lockfile, fcntl.LOCK_EX)
    print_stdout(test_name + ":", end=False)
    if fail:
        print_fail()
    else:
        print_pass()
    fcntl.flock(lockfile, fcntl.LOCK_UN)
    lockfile.close()

    if fail:
        raise TestFailure("Test %s failed" % test_name)


def scan_for_modules(start, options):
    modules = []

    skip_tests = []
    if options.skip_tests:
        skip_tests = options.skip_tests.split()

    for dirpath, subdirs, filenames in os.walk(start):
        # Only look in and below subdirectories that are python modules.
        if '__init__.py' not in filenames:
            if options.full:
                for filename in filenames:
                    if filename.endswith('.pyc'):
                        os.unlink(os.path.join(dirpath, filename))
            # Skip all subdirectories below this one, it is not a module.
            del subdirs[:]
            if options.debug:
                print 'Skipping', dirpath
            continue  # Skip this directory.

        # Look for unittest files.
        for fname in filenames:
            if fname.endswith('_unittest.py'):
                if fname in skip_tests:
                    continue
                path_no_py = os.path.join(dirpath, fname).rstrip('.py')
                assert path_no_py.startswith(ROOT)
                names = path_no_py[len(ROOT) + 1:].split('/')
                modules.append(names)
                if options.debug:
                    print 'testing', path_no_py
    return modules


def find_and_run_tests(start, options):
    """
    Find and run Python unittest suites below the given directory.  Only look
    in subdirectories of start that are actual importable Python modules.

    :param start: The absolute directory to look for tests under.
    :param options: optparse options.
    """
    if options.module_list:
        modules = []
        for m in options.module_list:
            modules.append(m.split('.'))
    else:
        modules = scan_for_modules(start, options)

    modules_count = len(modules)
    if not modules_count:
        print_header('No test module was found!')
        return (modules_count, [])
    print_header('Number of test modules found: %d' % modules_count)

    functions = {}

    for module_names in modules:
        # Create a function that'll test a particular module.  module=module
        # is a hack to force python to evaluate the params now.  We then
        # rename the function to make error reporting nicer.
        run_module = lambda module = module_names: run_test(module, options)
        name = '.'.join(module_names)
        run_module.__name__ = name
        functions[run_module] = set()

    try:
        dargs = {}
        if options.debug:
            dargs['max_simultaneous_procs'] = 1
        pe = parallel.ParallelExecute(functions, **dargs)
        pe.run_until_completion()
    except parallel.ParallelError, err:
        return (modules_count, err.errors)
    return (modules_count, [])


def main():
    options, args = parser.parse_args()
    if args:
        options.module_list = args

    # Strip the arguments off the command line, so that the unit tests do not
    # see them.
    del sys.argv[1:]

    absolute_start = os.path.join(ROOT, options.start)
    mod_cnt, errors = find_and_run_tests(absolute_start, options)
    if errors:
        print "%d tests passed" % (mod_cnt - len(errors))
        print "%d tests resulted in an error/failure:" % len(errors)
        for error in errors:
            print "\t%s" % error
        print "Rerun", sys.argv[0], "--debug to see the failure details."
        sys.exit(1)
    elif not mod_cnt:
        print "No modules were tested"
        sys.exit(0)
    else:
        print "%d tests passed" % (mod_cnt - len(errors))
        print "All passed!"
        sys.exit(0)


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = run_unittests_nose
#!/usr/bin/env python
# -*- coding: utf-8 -*-

__author__ = 'Lucas Meneghel Rodrigues <lmr@redhat.com>'

from nose.selector import Selector

from nose.plugins import Plugin
from nose.plugins.attrib import AttributeSelector
from nose.plugins.xunit import Xunit
from nose.plugins.cover import Coverage

import logging
import os
import nose
import sys


logger = logging.getLogger(__name__)


class VirtTestSelector(Selector):

    def wantDirectory(self, dirname):
        return True

    def wantModule(self, module):
        if module.__name__ == 'virttest.utils_test':
            return False
        return True

    def wantFile(self, filename):
        if not filename.endswith('_unittest.py'):
            return False

        skip_tests = []
        if self.config.options.skip_tests:
            skip_tests = self.config.options.skip_tests.split()

        if os.path.basename(filename)[:-3] in skip_tests:
            logger.debug('Skipping test: %s' % filename)
            return False

        if self.config.options.debug:
            logger.debug('Adding %s as a valid test' % filename)

        return True


class VirtTestRunner(Plugin):

    enabled = True
    name = 'virt_test_runner'

    def configure(self, options, config):
        self.result_stream = sys.stdout

        config.logStream = self.result_stream
        self.testrunner = nose.core.TextTestRunner(stream=self.result_stream,
                                                   descriptions=True,
                                                   verbosity=2,
                                                   config=config)

    def options(self, parser, env):
        parser.add_option("--virttest-skip-tests",
                          dest="skip_tests",
                          default=[],
                          help='A space separated list of tests to skip')

    def prepareTestLoader(self, loader):
        loader.selector = VirtTestSelector(loader.config)


def run_test():
    nose.main(addplugins=[VirtTestRunner(),
                          AttributeSelector(),
                          Xunit(),
                          Coverage()])


def main():
    run_test()


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = tapfd_helper
#!/usr/bin/python

import sys
import os
import re
import logging
import common
from autotest.client.shared import logging_manager
from virttest import utils_net, utils_misc


def destroy_tap(tapfd_list):
    for tapfd in tapfd_list:
        try:
            os.close(tapfd)
        # File descriptor is already closed
        except OSError:
            pass


if __name__ == "__main__":
    logging_manager.configure_logging(utils_misc.VirtLoggingConfig(),
                                      verbose=True)
    if len(sys.argv) <= 2:
        logging.info("Usage: %s bridge_name qemu_command_line", sys.argv[0])
        sys.exit(255)

    brname = sys.argv[1]
    cmd_line = ' '.join(sys.argv[2:])

    if re.findall("-netdev\s", cmd_line):
        # so we get the new qemu cli with netdev parameter.
        tap_list_re = r"tap,id=(.*?),"
        tap_replace_re = r"(tap,id=%s.*?,fd=)\d+"
    else:
        # the old cli contain "-net" parameter.
        tap_list_re = r"tap,vlan=(\d+),"
        tap_replace_re = r"(tap,vlan=%s,fd=)\d+"

    tap_list = re.findall(tap_list_re, cmd_line)
    if not tap_list:
        print "Could not find tap device."
        sys.exit(1)

    tapfd_list = []

    for tap in tap_list:
        try:
            ifname = "tap-%s" % tap
            tapfd = utils_net.open_tap("/dev/net/tun", ifname)
            utils_net.add_to_bridge(ifname, brname)
            utils_net.bring_up_ifname(ifname)
            pattern = tap_replace_re % tap
            cmd_line = re.sub(pattern, "\g<1>%s " % tapfd, cmd_line)
            tapfd_list.append(tapfd)
        except Exception, e:
            destroy_tap(tapfd_list)
            print "Error: %s" % e
            sys.exit(2)

    try:
        # Run qemu command.
        logging.info("TAP fd open to %s: %s", brname, tapfd_list)
        os.system(cmd_line)
    finally:
        destroy_tap(tapfd_list)

########NEW FILE########
__FILENAME__ = virt_disk
#!/usr/bin/env python

'''
This is a tool for that makes it easy to create virtual disks, optionally
with content ready for unattended installations.

The main use case for this tool is debugging guest installations with an
disks just like they're created by the virt unattended test installation.
'''

import sys
import optparse
import common
from virttest import utils_disk


class OptionParser(optparse.OptionParser):

    '''
    App option parser
    '''

    def __init__(self):
        optparse.OptionParser.__init__(self,
                                       usage=('Usage: %prog [options] '
                                              '<image_file_name> '
                                              '[file 1][file 2]..[file N]'))

        media = optparse.OptionGroup(self, 'MEDIA SELECTION')
        media.set_description('Choose only one of the media formats supported')
        media.add_option('-c', '--cdrom', dest='cdrom', default=False,
                         action='store_true',
                         help=('create a basic cdrom image'))
        media.add_option('-f', '--floppy', dest='floppy', default=False,
                         action='store_true',
                         help=('create a basic floppy image'))
        media.add_option('--floppy-size', dest='vfd_size',
                         action='store_true', default="1440k",
                         help=('Floppy size (1440k or 2880k). '
                               'defaults to %default'))
        self.add_option_group(media)

        path = optparse.OptionGroup(self, 'PATH SELECTION')
        path.add_option('-q', '--qemu-img', dest='qemu_img',
                        default='/usr/bin/qemu-img',
                        help=('qemu-img binary path. defaults to '
                              '%default'))
        path.add_option('-t', '--temp', dest='temp', default='/tmp',
                        help='Path to hold temporary files. defaults to %default')
        self.add_option_group(path)


class App:

    '''
    Virt Disk Creation App
    '''

    def __init__(self):
        self.opt_parser = OptionParser()

    def usage(self):
        self.opt_parser.print_help()
        sys.exit(1)

    def parse_cmdline(self):
        self.options, self.args = self.opt_parser.parse_args()
        if not (self.options.cdrom or self.options.floppy):
            self.usage()
        if (self.options.cdrom and self.options.floppy):
            self.usage()

        if not len(self.args) >= 1:
            self.usage()
        else:
            self.image = self.args[0]
            self.files = self.args[1:]

    def main(self):
        self.parse_cmdline()
        if self.options.floppy:
            self.disk = utils_disk.FloppyDisk(self.image,
                                              self.options.qemu_img,
                                              self.options.temp,
                                              self.options.vfd_size)
        elif self.options.cdrom:
            self.disk = utils_disk.CdromDisk(self.image,
                                             self.options.temp)

        for f in self.files:
            self.disk.copy_to(f)
        self.disk.close()


if __name__ == '__main__':
    app = App()
    app.main()

########NEW FILE########
__FILENAME__ = virt
import os
import sys
import logging
import imp
import Queue
from autotest.client import test
from autotest.client.shared import error
from virttest import utils_misc, utils_params, utils_env, env_process
from virttest import data_dir, bootstrap, funcatexit, version, asset


class virt(test.test):

    """
    Shared test class infrastructure for tests such as the KVM test.

    It comprises a subtest load system, use of parameters, and an env
    file, all code that can be reused among those virt tests.
    """
    version = 1
    env_version = utils_env.get_env_version()

    def initialize(self, params):
        # Change the value of the preserve_srcdir attribute according to
        # the value present on the configuration file (defaults to yes)
        if params.get("preserve_srcdir", "yes") == "yes":
            self.preserve_srcdir = True
        virtdir = os.path.dirname(sys.modules[__name__].__file__)
        self.virtdir = os.path.join(virtdir, "shared")
        # Place where virt software will be built/linked
        self.builddir = os.path.join(virtdir, 'backends', params.get("vm_type"))
        self.background_errors = Queue.Queue()

    def verify_background_errors(self):
        """
        Verify if there are any errors that happened on background threads.

        :raise Exception: Any exception stored on the background_errors queue.
        """
        try:
            exc = self.background_errors.get(block=False)
        except Queue.Empty:
            pass
        else:
            raise exc[1], None, exc[2]

    def run_once(self, params):
        # Convert params to a Params object
        params = utils_params.Params(params)

        # If a dependency test prior to this test has failed, let's fail
        # it right away as TestNA.
        if params.get("dependency_failed") == 'yes':
            raise error.TestNAError("Test dependency failed")

        # Report virt test version
        logging.info(version.get_pretty_version_info())
        # Report the parameters we've received and write them as keyvals
        logging.debug("Test parameters:")
        keys = params.keys()
        keys.sort()
        for key in keys:
            logging.debug("    %s = %s", key, params[key])
            self.write_test_keyval({key: params[key]})

        # Set the log file dir for the logging mechanism used by kvm_subprocess
        # (this must be done before unpickling env)
        utils_misc.set_log_file_dir(self.debugdir)

        # Open the environment file
        custom_env_path = params.get("custom_env_path", "")
        if custom_env_path:
            env_path = custom_env_path
        else:
            env_path = params.get("vm_type")
        env_filename = os.path.join(self.bindir, "backends", env_path,
                                    params.get("env", "env"))
        env = utils_env.Env(env_filename, self.env_version)
        other_subtests_dirs = params.get("other_tests_dirs", "")

        test_passed = False
        t_type = None

        try:
            try:
                try:
                    subtest_dirs = []
                    bin_dir = self.bindir

                    for d in other_subtests_dirs.split():
                        # Replace split char.
                        d = os.path.join(*d.split("/"))
                        subtestdir = os.path.join(bin_dir, d, "tests")
                        if not os.path.isdir(subtestdir):
                            raise error.TestError("Directory %s not"
                                                  " exist." % (subtestdir))
                        subtest_dirs += data_dir.SubdirList(subtestdir,
                                                            bootstrap.test_filter)

                    # Verify if we have the correspondent source file for it
                    for generic_subdir in asset.get_test_provider_subdirs('generic'):
                        subtest_dirs += data_dir.SubdirList(generic_subdir,
                                                            bootstrap.test_filter)

                    for specific_subdir in asset.get_test_provider_subdirs(params.get("vm_type")):
                        subtest_dirs += data_dir.SubdirList(specific_subdir,
                                                            bootstrap.test_filter)

                    subtest_dir = None

                    # Get the test routine corresponding to the specified
                    # test type
                    logging.debug("Searching for test modules that match "
                                  "'type = %s' and 'provider = %s' "
                                  "on this cartesian dict",
                                  params.get("type"), params.get("provider", None))

                    t_types = params.get("type").split()
                    provider = params.get("provider", None)
                    if provider is not None:
                        subtest_dirs = [d for d in subtest_dirs if provider in d]
                    # Make sure we can load provider_lib in tests
                    for s in subtest_dirs:
                        if os.path.dirname(s) not in sys.path:
                            sys.path.insert(0, os.path.dirname(s))

                    test_modules = {}
                    for t_type in t_types:
                        for d in subtest_dirs:
                            module_path = os.path.join(d, "%s.py" % t_type)
                            if os.path.isfile(module_path):
                                subtest_dir = d
                                break
                        if subtest_dir is None:
                            msg = ("Could not find test file %s.py on tests"
                                   "dirs %s" % (t_type, subtest_dirs))
                            raise error.TestError(msg)
                        # Load the test module
                        f, p, d = imp.find_module(t_type, [subtest_dir])
                        test_modules[t_type] = imp.load_module(t_type, f, p, d)
                        f.close()

                    # Preprocess
                    try:
                        params = env_process.preprocess(self, params, env)
                    finally:
                        env.save()

                    # Run the test function
                    for t_type, test_module in test_modules.items():
                        run_func = utils_misc.get_test_entrypoint_func(
                            t_type, test_module)
                        try:
                            run_func(self, params, env)
                            self.verify_background_errors()
                        finally:
                            env.save()
                    test_passed = True
                    error_message = funcatexit.run_exitfuncs(env, t_type)
                    if error_message:
                        raise error.TestWarn("funcatexit failed with: %s"
                                             % error_message)

                except Exception, e:
                    if t_type is not None:
                        error_message = funcatexit.run_exitfuncs(env, t_type)
                        if error_message:
                            logging.error(error_message)
                    logging.error("Test failed: %s: %s",
                                  e.__class__.__name__, e)
                    try:
                        env_process.postprocess_on_error(
                            self, params, env)
                    finally:
                        env.save()
                    raise

            finally:
                # Postprocess
                try:
                    try:
                        env_process.postprocess(self, params, env)
                    except Exception, e:
                        if test_passed:
                            raise
                        logging.error("Exception raised during "
                                      "postprocessing: %s", e)
                finally:
                    env.save()

        except Exception, e:
            if params.get("abort_on_error") != "yes":
                raise
            # Abort on error
            logging.info("Aborting job (%s)", e)
            if params.get("vm_type") == "qemu":
                for vm in env.get_all_vms():
                    if vm.is_dead():
                        continue
                    logging.info("VM '%s' is alive.", vm.name)
                    for m in vm.monitors:
                        logging.info(
                            "'%s' has a %s monitor unix socket at: %s",
                            vm.name, m.protocol, m.filename)
                    logging.info(
                        "The command line used to start '%s' was:\n%s",
                        vm.name, vm.make_qemu_command())
                raise error.JobError("Abort requested (%s)" % e)

########NEW FILE########
__FILENAME__ = aexpect
#!/usr/bin/python
"""
A class and functions used for running and controlling child processes.

:copyright: 2008-2009 Red Hat Inc.
"""

import os
import sys
import pty
import select
import termios
import fcntl
import tempfile
import logging
import shutil

BASE_DIR = os.path.join('/tmp', 'aexpect')


def clean_tmp_files():
    """
    Remove all aexpect temporary files.
    """
    if os.path.isdir(BASE_DIR):
        shutil.rmtree(BASE_DIR, ignore_errors=True)

# The following helper functions are shared by the server and the client.


def _lock(filename):
    if not os.path.exists(filename):
        open(filename, "w").close()
    fd = os.open(filename, os.O_RDWR)
    fcntl.lockf(fd, fcntl.LOCK_EX)
    return fd


def _unlock(fd):
    fcntl.lockf(fd, fcntl.LOCK_UN)
    os.close(fd)


def _locked(filename):
    try:
        fd = os.open(filename, os.O_RDWR)
    except Exception:
        return False
    try:
        fcntl.lockf(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
    except Exception:
        os.close(fd)
        return True
    fcntl.lockf(fd, fcntl.LOCK_UN)
    os.close(fd)
    return False


def _wait(filename):
    fd = _lock(filename)
    _unlock(fd)


def _makeraw(shell_fd):
    attr = termios.tcgetattr(shell_fd)
    attr[0] &= ~(termios.IGNBRK | termios.BRKINT | termios.PARMRK |
                 termios.ISTRIP | termios.INLCR | termios.IGNCR |
                 termios.ICRNL | termios.IXON)
    attr[1] &= ~termios.OPOST
    attr[2] &= ~(termios.CSIZE | termios.PARENB)
    attr[2] |= termios.CS8
    attr[3] &= ~(termios.ECHO | termios.ECHONL | termios.ICANON |
                 termios.ISIG | termios.IEXTEN)
    termios.tcsetattr(shell_fd, termios.TCSANOW, attr)


def _makestandard(shell_fd, echo):
    attr = termios.tcgetattr(shell_fd)
    attr[0] &= ~termios.INLCR
    attr[0] &= ~termios.ICRNL
    attr[0] &= ~termios.IGNCR
    attr[1] &= ~termios.OPOST
    if echo:
        attr[3] |= termios.ECHO
    else:
        attr[3] &= ~termios.ECHO
    termios.tcsetattr(shell_fd, termios.TCSANOW, attr)


def _get_filenames(base_dir, a_id):
    return [os.path.join(base_dir, a_id, s) for s in
            "shell-pid", "status", "output", "inpipe", "ctrlpipe",
            "lock-server-running", "lock-client-starting",
            "server-log"]


def _get_reader_filename(base_dir, a_id, reader):
    return os.path.join(base_dir, a_id, "outpipe-%s" % reader)


# The following is the server part of the module.

if __name__ == "__main__":
    a_id = sys.stdin.readline().strip()
    echo = sys.stdin.readline().strip() == "True"
    readers = sys.stdin.readline().strip().split(",")
    command = sys.stdin.readline().strip() + " && echo %s > /dev/null" % a_id

    # Define filenames to be used for communication
    (shell_pid_filename,
     status_filename,
     output_filename,
     inpipe_filename,
     ctrlpipe_filename,
     lock_server_running_filename,
     lock_client_starting_filename,
     log_filename) = _get_filenames(BASE_DIR, a_id)

    logging_format = '%(asctime)s %(levelname)-5.5s| %(message)s'
    date_format = '%m/%d %H:%M:%S'
    logging.basicConfig(filename=log_filename, level=logging.DEBUG,
                        format=logging_format, datefmt=date_format)
    server_log = logging.getLogger()

    server_log.info('Server %s starting with parameters:' % str(a_id))
    server_log.info('echo: %s' % str(echo))
    server_log.info('readers: %s' % str(readers))
    server_log.info('command: %s' % str(command))

    # Populate the reader filenames list
    reader_filenames = [_get_reader_filename(BASE_DIR, a_id, reader)
                        for reader in readers]

    # Set $TERM = dumb
    os.putenv("TERM", "dumb")

    server_log.info('Forking child process for command')
    (shell_pid, shell_fd) = pty.fork()
    if shell_pid == 0:
        # Child process: run the command in a subshell
        if len(command) > 255:
            new_stack = None
            if len(command) > 2000000:
                # Stack size would probably not suffice (and no open files)
                # (1 + len(command) * 4 / 8290304) * 8196
                # 2MB => 8196kb, 4MB => 16392, ...
                new_stack = (1 + len(command) / 2072576) * 8196
                command = "ulimit -s %s\nulimit -n 819200\n%s" % (new_stack,
                                                                  command)
            tmp_dir = os.path.join(BASE_DIR, a_id)
            tmp_file = tempfile.mktemp(suffix='.sh',
                                       prefix='aexpect-', dir=tmp_dir)
            fd_cmd = open(tmp_file, "w")
            fd_cmd.write(command)
            fd_cmd.close()
            os.execv("/bin/bash", ["/bin/bash", "-c", "source %s" % tmp_file])
            os.remove(tmp_file)
        else:
            os.execv("/bin/bash", ["/bin/bash", "-c", command])
    else:
        # Parent process
        server_log.info('Acquiring server lock on %s' % lock_server_running_filename)
        lock_server_running = _lock(lock_server_running_filename)

        # Set terminal echo on/off and disable pre- and post-processing
        _makestandard(shell_fd, echo)

        server_log.info('Opening output file %s' % output_filename)
        output_file = open(output_filename, "w")
        server_log.info('Opening input pipe %s' % inpipe_filename)
        os.mkfifo(inpipe_filename)
        inpipe_fd = os.open(inpipe_filename, os.O_RDWR)
        server_log.info('Opening control pipe %s' % ctrlpipe_filename)
        os.mkfifo(ctrlpipe_filename)
        ctrlpipe_fd = os.open(ctrlpipe_filename, os.O_RDWR)
        # Open output pipes (readers)
        reader_fds = []
        for filename in reader_filenames:
            server_log.info('Opening output pipe %s' % filename)
            os.mkfifo(filename)
            reader_fds.append(os.open(filename, os.O_RDWR))
        server_log.info('Reader fd list: %s' % reader_fds)

        # Write shell PID to file
        server_log.info('Writing shell PID file %s' % shell_pid_filename)
        fileobj = open(shell_pid_filename, "w")
        fileobj.write(str(shell_pid))
        fileobj.close()

        # Print something to stdout so the client can start working
        print "Server %s ready" % a_id
        sys.stdout.flush()

        # Initialize buffers
        buffers = ["" for reader in readers]

        # Read from child and write to files/pipes
        server_log.info('Entering main read loop')
        while True:
            check_termination = False
            # Make a list of reader pipes whose buffers are not empty
            fds = [fd for (i, fd) in enumerate(reader_fds) if buffers[i]]
            # Wait until there's something to do
            r, w, x = select.select([shell_fd, inpipe_fd, ctrlpipe_fd],
                                    fds, [], 0.5)
            # If a reader pipe is ready for writing --
            for (i, fd) in enumerate(reader_fds):
                if fd in w:
                    bytes_written = os.write(fd, buffers[i])
                    buffers[i] = buffers[i][bytes_written:]
            if ctrlpipe_fd in r:
                cmd_len = int(os.read(ctrlpipe_fd, 10))
                data = os.read(ctrlpipe_fd, cmd_len)
                if data == "raw":
                    _makeraw(shell_fd)
                elif data == "standard":
                    _makestandard(shell_fd, echo)
            # If there's data to read from the child process --
            if shell_fd in r:
                try:
                    data = os.read(shell_fd, 16384)
                except OSError:
                    data = ""
                if not data:
                    check_termination = True
                # Remove carriage returns from the data -- they often cause
                # trouble and are normally not needed
                data = data.replace("\r", "")
                output_file.write(data)
                output_file.flush()
                for i in range(len(readers)):
                    buffers[i] += data
            # If os.read() raised an exception or there was nothing to read --
            if check_termination or shell_fd not in r:
                pid, status = os.waitpid(shell_pid, os.WNOHANG)
                if pid:
                    status = os.WEXITSTATUS(status)
                    break
            # If there's data to read from the client --
            if inpipe_fd in r:
                data = os.read(inpipe_fd, 1024)
                os.write(shell_fd, data)

        server_log.info('Out of the main read loop. Writing status to %s' % status_filename)
        fileobj = open(status_filename, "w")
        fileobj.write(str(status))
        fileobj.close()

        # Wait for the client to finish initializing
        _wait(lock_client_starting_filename)

        # Close all files and pipes
        output_file.close()
        os.close(inpipe_fd)
        server_log.info('Closed input pipe')
        for fd in reader_fds:
            os.close(fd)
            server_log.info('Closed reader fd %s' % fd)

        _unlock(lock_server_running)
        server_log.info('Exiting normally')
        sys.exit(0)


# The following is the client part of the module.

import subprocess
import time
import signal
import re
import threading
import logging
import utils_misc


class ExpectError(Exception):

    def __init__(self, patterns, output):
        Exception.__init__(self, patterns, output)
        self.patterns = patterns
        self.output = output

    def _pattern_str(self):
        if len(self.patterns) == 1:
            return "pattern %r" % self.patterns[0]
        else:
            return "patterns %r" % self.patterns

    def __str__(self):
        return ("Unknown error occurred while looking for %s    (output: %r)" %
                (self._pattern_str(), self.output))


class ExpectTimeoutError(ExpectError):

    def __str__(self):
        return ("Timeout expired while looking for %s    (output: %r)" %
                (self._pattern_str(), self.output))


class ExpectProcessTerminatedError(ExpectError):

    def __init__(self, patterns, status, output):
        ExpectError.__init__(self, patterns, output)
        self.status = status

    def __str__(self):
        return ("Process terminated while looking for %s    "
                "(status: %s,    output: %r)" % (self._pattern_str(),
                                                 self.status, self.output))


class ShellError(Exception):

    def __init__(self, cmd, output):
        Exception.__init__(self, cmd, output)
        self.cmd = cmd
        self.output = output

    def __str__(self):
        return ("Could not execute shell command %r    (output: %r)" %
                (self.cmd, self.output))


class ShellTimeoutError(ShellError):

    def __str__(self):
        return ("Timeout expired while waiting for shell command to "
                "complete: %r    (output: %r)" % (self.cmd, self.output))


class ShellProcessTerminatedError(ShellError):
    # Raised when the shell process itself (e.g. ssh, netcat, telnet)
    # terminates unexpectedly

    def __init__(self, cmd, status, output):
        ShellError.__init__(self, cmd, output)
        self.status = status

    def __str__(self):
        return ("Shell process terminated while waiting for command to "
                "complete: %r    (status: %s,    output: %r)" %
                (self.cmd, self.status, self.output))


class ShellCmdError(ShellError):
    # Raised when a command executed in a shell terminates with a nonzero
    # exit code (status)

    def __init__(self, cmd, status, output):
        ShellError.__init__(self, cmd, output)
        self.status = status

    def __str__(self):
        return ("Shell command failed: %r    (status: %s,    output: %r)" %
                (self.cmd, self.status, self.output))


class ShellStatusError(ShellError):
    # Raised when the command's exit status cannot be obtained

    def __str__(self):
        return ("Could not get exit status of command: %r    (output: %r)" %
                (self.cmd, self.output))


def run_tail(command, termination_func=None, output_func=None, output_prefix="",
             timeout=1.0, auto_close=True):
    """
    Run a subprocess in the background and collect its output and exit status.

    Run command as a subprocess.  Call output_func with each line of output
    from the subprocess (prefixed by output_prefix).  Call termination_func
    when the subprocess terminates.  Return when timeout expires or when the
    subprocess exits -- whichever occurs first.

    :param command: The shell command to execute
    :param termination_func: A function to call when the process terminates
            (should take an integer exit status parameter)
    :param output_func: A function to call with each line of output from
            the subprocess (should take a string parameter)
    :param output_prefix: A string to pre-pend to each line of the output,
            before passing it to stdout_func
    :param timeout: Time duration (in seconds) to wait for the subprocess to
            terminate before returning
    :param auto_close: If True, close() the instance automatically when its
                reference count drops to zero (default False).

    :return: A Expect object.
    """
    process = Tail(command=command,
                   termination_func=termination_func,
                   output_func=output_func,
                   output_prefix=output_prefix,
                   auto_close=auto_close)

    end_time = time.time() + timeout
    while time.time() < end_time and process.is_alive():
        time.sleep(0.1)

    return process


def run_bg(command, termination_func=None, output_func=None, output_prefix="",
           timeout=1.0, auto_close=True):
    """
    Run a subprocess in the background and collect its output and exit status.

    Run command as a subprocess.  Call output_func with each line of output
    from the subprocess (prefixed by output_prefix).  Call termination_func
    when the subprocess terminates.  Return when timeout expires or when the
    subprocess exits -- whichever occurs first.

    :param command: The shell command to execute
    :param termination_func: A function to call when the process terminates
            (should take an integer exit status parameter)
    :param output_func: A function to call with each line of output from
            the subprocess (should take a string parameter)
    :param output_prefix: A string to pre-pend to each line of the output,
            before passing it to stdout_func
    :param timeout: Time duration (in seconds) to wait for the subprocess to
            terminate before returning
    :param auto_close: If True, close() the instance automatically when its
                reference count drops to zero (default False).

    :return: A Expect object.
    """
    process = Expect(command=command,
                     termination_func=termination_func,
                     output_func=output_func,
                     output_prefix=output_prefix,
                     auto_close=auto_close)

    end_time = time.time() + timeout
    while time.time() < end_time and process.is_alive():
        time.sleep(0.1)

    return process


def run_fg(command, output_func=None, output_prefix="", timeout=1.0):
    """
    Run a subprocess in the foreground and collect its output and exit status.

    Run command as a subprocess.  Call output_func with each line of output
    from the subprocess (prefixed by prefix).  Return when timeout expires or
    when the subprocess exits -- whichever occurs first.  If timeout expires
    and the subprocess is still running, kill it before returning.

    :param command: The shell command to execute
    :param output_func: A function to call with each line of output from
            the subprocess (should take a string parameter)
    :param output_prefix: A string to pre-pend to each line of the output,
            before passing it to stdout_func
    :param timeout: Time duration (in seconds) to wait for the subprocess to
            terminate before killing it and returning

    :return: A 2-tuple containing the exit status of the process and its
            STDOUT/STDERR output.  If timeout expires before the process
            terminates, the returned status is None.
    """
    process = run_bg(command, None, output_func, output_prefix, timeout)
    output = process.get_output()
    if process.is_alive():
        status = None
    else:
        status = process.get_status()
    process.close()
    return (status, output)


class Spawn(object):

    """
    This class is used for spawning and controlling a child process.

    A new instance of this class can either run a new server (a small Python
    program that reads output from the child process and reports it to the
    client and to a text file) or attach to an already running server.
    When a server is started it runs the child process.
    The server writes output from the child's STDOUT and STDERR to a text file.
    The text file can be accessed at any time using get_output().
    In addition, the server opens as many pipes as requested by the client and
    writes the output to them.
    The pipes are requested and accessed by classes derived from Spawn.
    These pipes are referred to as "readers".
    The server also receives input from the client and sends it to the child
    process.
    An instance of this class can be pickled.  Every derived class is
    responsible for restoring its own state by properly defining
    __getinitargs__().

    The first named pipe is used by _tail(), a function that runs in the
    background and reports new output from the child as it is produced.
    The second named pipe is used by a set of functions that read and parse
    output as requested by the user in an interactive manner, similar to
    pexpect.
    When unpickled it automatically
    resumes _tail() if needed.
    """

    def __init__(self, command=None, a_id=None, auto_close=False, echo=False,
                 linesep="\n"):
        """
        Initialize the class and run command as a child process.

        :param command: Command to run, or None if accessing an already running
                server.
        :param a_id: ID of an already running server, if accessing a running
                server, or None if starting a new one.
        :param auto_close: If True, close() the instance automatically when its
                reference count drops to zero (default False).
        :param echo: Boolean indicating whether echo should be initially
                enabled for the pseudo terminal running the subprocess.  This
                parameter has an effect only when starting a new server.
        :param linesep: Line separator to be appended to strings sent to the
                child process by sendline().
        """
        self.a_id = a_id or utils_misc.generate_random_string(8)
        self.log_file = None

        base_dir = os.path.join(BASE_DIR, self.a_id)

        # Define filenames for communication with server
        try:
            os.makedirs(base_dir)
        except Exception:
            pass
        (self.shell_pid_filename,
         self.status_filename,
         self.output_filename,
         self.inpipe_filename,
         self.ctrlpipe_filename,
         self.lock_server_running_filename,
         self.lock_client_starting_filename,
         self.server_log_filename) = _get_filenames(BASE_DIR,
                                                    self.a_id)

        self.command = command

        # Remember some attributes
        self.auto_close = auto_close
        self.echo = echo
        self.linesep = linesep

        # Make sure the 'readers' and 'close_hooks' attributes exist
        if not hasattr(self, "readers"):
            self.readers = []
        if not hasattr(self, "close_hooks"):
            self.close_hooks = []

        # Define the reader filenames
        self.reader_filenames = dict(
            (reader, _get_reader_filename(BASE_DIR, self.a_id, reader))
            for reader in self.readers)

        # Let the server know a client intends to open some pipes;
        # if the executed command terminates quickly, the server will wait for
        # the client to release the lock before exiting
        lock_client_starting = _lock(self.lock_client_starting_filename)

        # Start the server (which runs the command)
        if command:
            sub = subprocess.Popen("%s %s" % (sys.executable, __file__),
                                   shell=True,
                                   stdin=subprocess.PIPE,
                                   stdout=subprocess.PIPE,
                                   stderr=subprocess.STDOUT)
            # Send parameters to the server
            sub.stdin.write("%s\n" % self.a_id)
            sub.stdin.write("%s\n" % echo)
            sub.stdin.write("%s\n" % ",".join(self.readers))
            sub.stdin.write("%s\n" % command)
            # Wait for the server to complete its initialization
            while "Server %s ready" % self.a_id not in sub.stdout.readline():
                pass

        # Open the reading pipes
        self.reader_fds = {}
        try:
            assert(_locked(self.lock_server_running_filename))
            for reader, filename in self.reader_filenames.items():
                self.reader_fds[reader] = os.open(filename, os.O_RDONLY)
        except Exception:
            pass

        # Allow the server to continue
        _unlock(lock_client_starting)

    # The following two functions are defined to make sure the state is set
    # exclusively by the constructor call as specified in __getinitargs__().
    def __reduce__(self):
        return self.__class__, (self.__getinitargs__())

    def __getstate__(self):
        pass

    def __setstate__(self, state):
        pass

    def __getinitargs__(self):
        # Save some information when pickling -- will be passed to the
        # constructor upon unpickling
        return (None, self.a_id, self.auto_close, self.echo, self.linesep)

    def __del__(self):
        self._close_reader_fds()
        if self.auto_close:
            self.close()

    def _add_reader(self, reader):
        """
        Add a reader whose file descriptor can be obtained with _get_fd().
        Should be called before __init__().  Intended for use by derived
        classes.

        :param reader: The name of the reader.
        """
        if not hasattr(self, "readers"):
            self.readers = []
        self.readers.append(reader)

    def _add_close_hook(self, hook):
        """
        Add a close hook function to be called when close() is called.
        The function will be called after the process terminates but before
        final cleanup.  Intended for use by derived classes.

        :param hook: The hook function.
        """
        if not hasattr(self, "close_hooks"):
            self.close_hooks = []
        self.close_hooks.append(hook)

    def _get_fd(self, reader):
        """
        Return an open file descriptor corresponding to the specified reader
        pipe.  If no such reader exists, or the pipe could not be opened,
        return None.  Intended for use by derived classes.

        :param reader: The name of the reader.
        """
        return self.reader_fds.get(reader)

    def _close_reader_fds(self):
        """
        Close all reader file descriptors.
        """
        for fd in self.reader_fds.values():
            try:
                os.close(fd)
            except OSError:
                pass

    def get_id(self):
        """
        Return the instance's a_id attribute, which may be used to access the
        process in the future.
        """
        return self.a_id

    def get_pid(self):
        """
        Return the PID of the process.

        Note: this may be the PID of the shell process running the user given
        command.
        """
        try:
            fileobj = open(self.shell_pid_filename, "r")
            pid = int(fileobj.read())
            fileobj.close()
            return pid
        except Exception:
            return None

    def get_status(self):
        """
        Wait for the process to exit and return its exit status, or None
        if the exit status is not available.
        """
        _wait(self.lock_server_running_filename)
        try:
            fileobj = open(self.status_filename, "r")
            status = int(fileobj.read())
            fileobj.close()
            return status
        except Exception:
            return None

    def get_output(self):
        """
        Return the STDOUT and STDERR output of the process so far.
        """
        try:
            fileobj = open(self.output_filename, "r")
            output = fileobj.read()
            fileobj.close()
            return output
        except Exception:
            return ""

    def get_stripped_output(self):
        """
        Return the STDOUT and STDERR output without the console codes escape
        and sequences of the process so far.
        """
        return utils_misc.strip_console_codes(self.get_output())

    def is_alive(self):
        """
        Return True if the process is running.
        """
        return _locked(self.lock_server_running_filename)

    def is_defunct(self):
        """
        Return True if the process is defunct (zombie).
        """
        return utils_misc.process_or_children_is_defunct(self.get_pid())

    def kill(self, sig=signal.SIGKILL):
        """
        Kill the child process if alive
        """
        # Kill it if it's alive
        if self.is_alive():
            utils_misc.kill_process_tree(self.get_pid(), sig)

    def close(self, sig=signal.SIGKILL):
        """
        Kill the child process if it's alive and remove temporary files.

        :param sig: The signal to send the process when attempting to kill it.
        """
        self.kill(sig=sig)
        # Wait for the server to exit
        _wait(self.lock_server_running_filename)
        # Call all cleanup routines
        for hook in self.close_hooks:
            hook(self)
        # Close reader file descriptors
        self._close_reader_fds()
        self.reader_fds = {}
        # Remove all used files
        for filename in (_get_filenames(BASE_DIR, self.a_id)):
            try:
                os.unlink(filename)
            except OSError:
                pass

    def set_linesep(self, linesep):
        """
        Sets the line separator string (usually "\\n").

        :param linesep: Line separator string.
        """
        self.linesep = linesep

    def send(self, cont=""):
        """
        Send a string to the child process.

        :param cont: String to send to the child process.
        """
        try:
            fd = os.open(self.inpipe_filename, os.O_RDWR)
            os.write(fd, cont)
            os.close(fd)
        except Exception:
            pass

    def sendline(self, cont=""):
        """
        Send a string followed by a line separator to the child process.

        :param cont: String to send to the child process.
        """
        self.send(cont + self.linesep)

    def send_ctrl(self, control_str=""):
        """
        Send a control string to the aexpect process.

        :param control_str: Control string to send to the child process
                            container.
        """
        try:
            fd = os.open(self.ctrlpipe_filename, os.O_RDWR)
            os.write(fd, "%10d%s" % (len(control_str), control_str))
            os.close(fd)
        except Exception:
            pass


_thread_kill_requested = False


def kill_tail_threads():
    """
    Kill all Tail threads.

    After calling this function no new threads should be started.
    """
    global _thread_kill_requested
    _thread_kill_requested = True

    for t in threading.enumerate():
        if hasattr(t, "name") and t.name.startswith("tail_thread"):
            t.join(10)
    _thread_kill_requested = False


class Tail(Spawn):

    """
    This class runs a child process in the background and sends its output in
    real time, line-by-line, to a callback function.

    See Spawn's docstring.

    This class uses a single pipe reader to read data in real time from the
    child process and report it to a given callback function.
    When the child process exits, its exit status is reported to an additional
    callback function.

    When this class is unpickled, it automatically resumes reporting output.
    """

    def __init__(self, command=None, a_id=None, auto_close=False, echo=False,
                 linesep="\n", termination_func=None, termination_params=(),
                 output_func=None, output_params=(), output_prefix="",
                 thread_name=None):
        """
        Initialize the class and run command as a child process.

        :param command: Command to run, or None if accessing an already running
                server.
        :param a_id: ID of an already running server, if accessing a running
                server, or None if starting a new one.
        :param auto_close: If True, close() the instance automatically when its
                reference count drops to zero (default False).
        :param echo: Boolean indicating whether echo should be initially
                enabled for the pseudo terminal running the subprocess.  This
                parameter has an effect only when starting a new server.
        :param linesep: Line separator to be appended to strings sent to the
                child process by sendline().
        :param termination_func: Function to call when the process exits.  The
                function must accept a single exit status parameter.
        :param termination_params: Parameters to send to termination_func
                before the exit status.
        :param output_func: Function to call whenever a line of output is
                available from the STDOUT or STDERR streams of the process.
                The function must accept a single string parameter.  The string
                does not include the final newline.
        :param output_params: Parameters to send to output_func before the
                output line.
        :param output_prefix: String to prepend to lines sent to output_func.
        :param thread_name: Name of thread to better identify hanging threads.
        """
        # Add a reader and a close hook
        self._add_reader("tail")
        self._add_close_hook(Tail._join_thread)
        self._add_close_hook(Tail._close_log_file)

        # Init the superclass
        Spawn.__init__(self, command, a_id, auto_close, echo, linesep)
        if thread_name is None:
            self.thread_name = ("tail_thread_%s_%s") % (self.a_id,
                                                        str(command)[:10])
        else:
            self.thread_name = thread_name

        # Remember some attributes
        self.termination_func = termination_func
        self.termination_params = termination_params
        self.output_func = output_func
        self.output_params = output_params
        self.output_prefix = output_prefix

        # Start the thread in the background
        self.tail_thread = None
        if termination_func or output_func:
            self._start_thread()

    def __reduce__(self):
        return self.__class__, (self.__getinitargs__())

    def __getinitargs__(self):
        return Spawn.__getinitargs__(self) + (self.termination_func,
                                              self.termination_params,
                                              self.output_func,
                                              self.output_params,
                                              self.output_prefix,
                                              self.thread_name)

    def set_termination_func(self, termination_func):
        """
        Set the termination_func attribute. See __init__() for details.

        :param termination_func: Function to call when the process terminates.
                Must take a single parameter -- the exit status.
        """
        self.termination_func = termination_func
        if termination_func and not self.tail_thread:
            self._start_thread()

    def set_termination_params(self, termination_params):
        """
        Set the termination_params attribute. See __init__() for details.

        :param termination_params: Parameters to send to termination_func
                before the exit status.
        """
        self.termination_params = termination_params

    def set_output_func(self, output_func):
        """
        Set the output_func attribute. See __init__() for details.

        :param output_func: Function to call for each line of STDOUT/STDERR
                output from the process.  Must take a single string parameter.
        """
        self.output_func = output_func
        if output_func and not self.tail_thread:
            self._start_thread()

    def set_output_params(self, output_params):
        """
        Set the output_params attribute. See __init__() for details.

        :param output_params: Parameters to send to output_func before the
                output line.
        """
        self.output_params = output_params

    def set_output_prefix(self, output_prefix):
        """
        Set the output_prefix attribute. See __init__() for details.

        :param output_prefix: String to pre-pend to each line sent to
                output_func (see set_output_callback()).
        """
        self.output_prefix = output_prefix

    def set_log_file(self, filename):
        """
        Set a log file name for this tail instance.

        :param filename: Base name of the log.
        """
        self.log_file = filename

    def _close_log_file(self):
        if self.log_file is not None:
            utils_misc.close_log_file(self.log_file)

    def _tail(self):
        def print_line(text):
            # Pre-pend prefix and remove trailing whitespace
            text = self.output_prefix + text.rstrip()
            # Pass text to output_func
            try:
                params = self.output_params + (text,)
                self.output_func(*params)
            except TypeError:
                pass

        try:
            fd = self._get_fd("tail")
            bfr = ""
            while True:
                global _thread_kill_requested
                if _thread_kill_requested:
                    try:
                        os.close(fd)
                    except:
                        pass
                    return
                try:
                    # See if there's any data to read from the pipe
                    r, w, x = select.select([fd], [], [], 0.05)
                except Exception:
                    break
                if fd in r:
                    # Some data is available; read it
                    new_data = os.read(fd, 1024)
                    if not new_data:
                        break
                    bfr += new_data
                    # Send the output to output_func line by line
                    # (except for the last line)
                    if self.output_func:
                        lines = bfr.split("\n")
                        for line in lines[:-1]:
                            print_line(line)
                    # Leave only the last line
                    last_newline_index = bfr.rfind("\n")
                    bfr = bfr[last_newline_index + 1:]
                else:
                    # No output is available right now; flush the bfr
                    if bfr:
                        print_line(bfr)
                        bfr = ""
            # The process terminated; print any remaining output
            if bfr:
                print_line(bfr)
            # Get the exit status, print it and send it to termination_func
            status = self.get_status()
            if status is None:
                return
            print_line("(Process terminated with status %s)" % status)
            try:
                params = self.termination_params + (status,)
                self.termination_func(*params)
            except TypeError:
                pass
        finally:
            self.tail_thread = None

    def _start_thread(self):
        self.tail_thread = threading.Thread(target=self._tail,
                                            name=self.thread_name)
        self.tail_thread.start()

    def _join_thread(self):
        # Wait for the tail thread to exit
        # (it's done this way because self.tail_thread may become None at any
        # time)
        t = self.tail_thread
        if t:
            t.join()


class Expect(Tail):

    """
    This class runs a child process in the background and provides expect-like
    services.

    It also provides all of Tail's functionality.
    """

    def __init__(self, command=None, a_id=None, auto_close=True, echo=False,
                 linesep="\n", termination_func=None, termination_params=(),
                 output_func=None, output_params=(), output_prefix="",
                 thread_name=None):
        """
        Initialize the class and run command as a child process.

        :param command: Command to run, or None if accessing an already running
                server.
        :param a_id: ID of an already running server, if accessing a running
                server, or None if starting a new one.
        :param auto_close: If True, close() the instance automatically when its
                reference count drops to zero (default False).
        :param echo: Boolean indicating whether echo should be initially
                enabled for the pseudo terminal running the subprocess.  This
                parameter has an effect only when starting a new server.
        :param linesep: Line separator to be appended to strings sent to the
                child process by sendline().
        :param termination_func: Function to call when the process exits.  The
                function must accept a single exit status parameter.
        :param termination_params: Parameters to send to termination_func
                before the exit status.
        :param output_func: Function to call whenever a line of output is
                available from the STDOUT or STDERR streams of the process.
                The function must accept a single string parameter.  The string
                does not include the final newline.
        :param output_params: Parameters to send to output_func before the
                output line.
        :param output_prefix: String to prepend to lines sent to output_func.
        """
        # Add a reader
        self._add_reader("expect")

        # Init the superclass
        Tail.__init__(self, command, a_id, auto_close, echo, linesep,
                      termination_func, termination_params,
                      output_func, output_params, output_prefix, thread_name)

    def __reduce__(self):
        return self.__class__, (self.__getinitargs__())

    def __getinitargs__(self):
        return Tail.__getinitargs__(self)

    def read_nonblocking(self, internal_timeout=None, timeout=None):
        """
        Read from child until there is nothing to read for timeout seconds.

        :param internal_timeout: Time (seconds) to wait before we give up
                                 reading from the child process, or None to
                                 use the default value.
        :param timeout: Timeout for reading child process output.
        """
        if internal_timeout is None:
            internal_timeout = 0.1
        end_time = None
        if timeout:
            end_time = time.time() + timeout
        fd = self._get_fd("expect")
        data = ""
        while True:
            try:
                r, w, x = select.select([fd], [], [], internal_timeout)
            except Exception:
                return data
            if fd in r:
                new_data = os.read(fd, 1024)
                if not new_data:
                    return data
                data += new_data
            else:
                return data
            if end_time and time.time() > end_time:
                return data

    def match_patterns(self, cont, patterns):
        """
        Match cont against a list of patterns.

        Return the index of the first pattern that matches a substring of cont.
        None and empty strings in patterns are ignored.
        If no match is found, return None.

        :param cont: input string
        :param patterns: List of strings (regular expression patterns).
        """
        for i in range(len(patterns)):
            if not patterns[i]:
                continue
            if re.search(patterns[i], cont):
                return i

    def match_patterns_multiline(self, cont, patterns):
        """
        Match list of lines against a list of patterns.

        Return the index of the first pattern that matches a substring of cont.
        None and empty strings in patterns are ignored.
        If no match is found, return None.

        :param cont: List of strings (input strings)
        :param patterns: List of strings (regular expression patterns). The
                         pattern priority is from the last to first.
        """
        for i in range(-len(patterns), 0):
            if not patterns[i]:
                continue
            for line in cont:
                if re.search(patterns[i], line):
                    return i

    def read_until_output_matches(self, patterns, filter_func=lambda x: x,
                                  timeout=60, internal_timeout=None,
                                  print_func=None, match_func=None):
        """
        Read from child using read_nonblocking until a pattern matches.

        Read using read_nonblocking until a match is found using match_patterns,
        or until timeout expires. Before attempting to search for a match, the
        data is filtered using the filter_func function provided.

        :param patterns: List of strings (regular expression patterns)
        :param filter_func: Function to apply to the data read from the child before
                attempting to match it against the patterns (should take and
                return a string)
        :param timeout: The duration (in seconds) to wait until a match is
                found
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :param match_func: Function to compare the output and patterns.
        :return: Tuple containing the match index and the data read so far
        :raise ExpectTimeoutError: Raised if timeout expires
        :raise ExpectProcessTerminatedError: Raised if the child process
                terminates while waiting for output
        :raise ExpectError: Raised if an unknown error occurs
        """
        if not match_func:
            match_func = self.match_patterns
        fd = self._get_fd("expect")
        o = ""
        end_time = time.time() + timeout
        while True:
            try:
                r, w, x = select.select([fd], [], [],
                                        max(0, end_time - time.time()))
            except (select.error, TypeError):
                break
            if not r:
                raise ExpectTimeoutError(patterns, o)
            # Read data from child
            data = self.read_nonblocking(internal_timeout,
                                         end_time - time.time())
            if not data:
                break
            # Print it if necessary
            if print_func:
                for line in data.splitlines():
                    print_func(line)
            # Look for patterns
            o += data
            match = match_func(filter_func(o), patterns)
            if match is not None:
                return match, o

        # Check if the child has terminated
        if utils_misc.wait_for(lambda: not self.is_alive(), 5, 0, 0.1):
            raise ExpectProcessTerminatedError(patterns, self.get_status(), o)
        else:
            # This shouldn't happen
            raise ExpectError(patterns, o)

    def read_until_last_word_matches(self, patterns, timeout=60,
                                     internal_timeout=None, print_func=None):
        """
        Read using read_nonblocking until the last word of the output matches
        one of the patterns (using match_patterns), or until timeout expires.

        :param patterns: A list of strings (regular expression patterns)
        :param timeout: The duration (in seconds) to wait until a match is
                found
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :return: A tuple containing the match index and the data read so far
        :raise ExpectTimeoutError: Raised if timeout expires
        :raise ExpectProcessTerminatedError: Raised if the child process
                terminates while waiting for output
        :raise ExpectError: Raised if an unknown error occurs
        """
        def get_last_word(cont):
            if cont:
                return cont.split()[-1]
            else:
                return ""

        return self.read_until_output_matches(patterns, get_last_word,
                                              timeout, internal_timeout,
                                              print_func)

    def read_until_last_line_matches(self, patterns, timeout=60,
                                     internal_timeout=None, print_func=None):
        """
        Read using read_nonblocking until the last non-empty line matches a pattern.

        Read using read_nonblocking until the last non-empty line of the output
        matches one of the patterns (using match_patterns), or until timeout
        expires. Return a tuple containing the match index (or None if no match
        was found) and the data read so far.

        :param patterns: A list of strings (regular expression patterns)
        :param timeout: The duration (in seconds) to wait until a match is
                found
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :return: A tuple containing the match index and the data read so far
        :raise ExpectTimeoutError: Raised if timeout expires
        :raise ExpectProcessTerminatedError: Raised if the child process
                terminates while waiting for output
        :raise ExpectError: Raised if an unknown error occurs
        """
        def get_last_nonempty_line(cont):
            nonempty_lines = [l for l in cont.splitlines() if l.strip()]
            if nonempty_lines:
                return nonempty_lines[-1]
            else:
                return ""

        return self.read_until_output_matches(patterns, get_last_nonempty_line,
                                              timeout, internal_timeout,
                                              print_func)

    def read_until_any_line_matches(self, patterns, timeout=60,
                                    internal_timeout=None, print_func=None):
        """
        Read using read_nonblocking until any line matches a pattern.

        Read using read_nonblocking until any line of the output matches
        one of the patterns (using match_patterns_multiline), or until timeout
        expires. Return a tuple containing the match index (or None if no match
        was found) and the data read so far.

        :param patterns: A list of strings (regular expression patterns)
                         Consider using '^' in the beginning.
        :param timeout: The duration (in seconds) to wait until a match is
                found
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :return: A tuple containing the match index and the data read so far
        :raise ExpectTimeoutError: Raised if timeout expires
        :raise ExpectProcessTerminatedError: Raised if the child process
                terminates while waiting for output
        :raise ExpectError: Raised if an unknown error occurs
        """
        return self.read_until_output_matches(patterns,
                                              lambda x: x.splitlines(
                                              ), timeout,
                                              internal_timeout, print_func,
                                              self.match_patterns_multiline)


class ShellSession(Expect):

    """
    This class runs a child process in the background.  It it suited for
    processes that provide an interactive shell, such as SSH and Telnet.

    It provides all services of Expect and Tail.  In addition, it
    provides command running services, and a utility function to test the
    process for responsiveness.
    """

    def __init__(self, command=None, a_id=None, auto_close=True, echo=False,
                 linesep="\n", termination_func=None, termination_params=(),
                 output_func=None, output_params=(), output_prefix="",
                 thread_name=None, prompt=r"[\#\$]\s*$",
                 status_test_command="echo $?"):
        """
        Initialize the class and run command as a child process.

        :param command: Command to run, or None if accessing an already running
                server.
        :param a_id: ID of an already running server, if accessing a running
                server, or None if starting a new one.
        :param auto_close: If True, close() the instance automatically when its
                reference count drops to zero (default True).
        :param echo: Boolean indicating whether echo should be initially
                enabled for the pseudo terminal running the subprocess.  This
                parameter has an effect only when starting a new server.
        :param linesep: Line separator to be appended to strings sent to the
                child process by sendline().
        :param termination_func: Function to call when the process exits.  The
                function must accept a single exit status parameter.
        :param termination_params: Parameters to send to termination_func
                before the exit status.
        :param output_func: Function to call whenever a line of output is
                available from the STDOUT or STDERR streams of the process.
                The function must accept a single string parameter.  The string
                does not include the final newline.
        :param output_params: Parameters to send to output_func before the
                output line.
        :param output_prefix: String to prepend to lines sent to output_func.
        :param prompt: Regular expression describing the shell's prompt line.
        :param status_test_command: Command to be used for getting the last
                exit status of commands run inside the shell (used by
                cmd_status_output() and friends).
        """
        # Init the superclass
        Expect.__init__(self, command, a_id, auto_close, echo, linesep,
                        termination_func, termination_params,
                        output_func, output_params, output_prefix, thread_name)

        # Remember some attributes
        self.prompt = prompt
        self.status_test_command = status_test_command

    def __reduce__(self):
        return self.__class__, (self.__getinitargs__())

    def __getinitargs__(self):
        return Expect.__getinitargs__(self) + (self.prompt,
                                               self.status_test_command)

    @classmethod
    def remove_command_echo(cls, cont, cmd):
        if cont and cont.splitlines()[0] == cmd:
            cont = "".join(cont.splitlines(True)[1:])
        return cont

    @classmethod
    def remove_last_nonempty_line(cls, cont):
        return "".join(cont.rstrip().splitlines(True)[:-1])

    def set_prompt(self, prompt):
        """
        Set the prompt attribute for later use by read_up_to_prompt.

        :param String that describes the prompt contents.
        """
        self.prompt = prompt

    def set_status_test_command(self, status_test_command):
        """
        Set the command to be sent in order to get the last exit status.

        :param status_test_command: Command that will be sent to get the last
                exit status.
        """
        self.status_test_command = status_test_command

    def is_responsive(self, timeout=5.0):
        """
        Return True if the process responds to STDIN/terminal input.

        Send a newline to the child process (e.g. SSH or Telnet) and read some
        output using read_nonblocking().
        If all is OK, some output should be available (e.g. the shell prompt).
        In that case return True.  Otherwise return False.

        :param timeout: Time duration to wait before the process is considered
                unresponsive.
        """
        # Read all output that's waiting to be read, to make sure the output
        # we read next is in response to the newline sent
        self.read_nonblocking(internal_timeout=0, timeout=timeout)
        # Send a newline
        self.sendline()
        # Wait up to timeout seconds for some output from the child
        end_time = time.time() + timeout
        while time.time() < end_time:
            time.sleep(0.5)
            if self.read_nonblocking(0, end_time - time.time()).strip():
                return True
        # No output -- report unresponsive
        return False

    def read_up_to_prompt(self, timeout=60, internal_timeout=None,
                          print_func=None):
        """
        Read using read_nonblocking until the last non-empty line matches the prompt.

        Read using read_nonblocking until the last non-empty line of the output
        matches the prompt regular expression set by set_prompt, or until
        timeout expires.

        :param timeout: The duration (in seconds) to wait until a match is
                found
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being
                read (should take a string parameter)

        :return: The data read so far
        :raise ExpectTimeoutError: Raised if timeout expires
        :raise ExpectProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ExpectError: Raised if an unknown error occurs
        """
        return self.read_until_last_line_matches([self.prompt], timeout,
                                                 internal_timeout,
                                                 print_func)[1]

    def cmd_output(self, cmd, timeout=60, internal_timeout=None,
                   print_func=None):
        """
        Send a command and return its output.

        :param cmd: Command to send (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)

        :return: The output of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellError: Raised if an unknown error occurs
        """
        logging.debug("Sending command: %s" % cmd)
        self.read_nonblocking(0, timeout)
        self.sendline(cmd)
        try:
            o = self.read_up_to_prompt(timeout, internal_timeout, print_func)
        except ExpectError, e:
            o = self.remove_command_echo(e.output, cmd)
            if isinstance(e, ExpectTimeoutError):
                raise ShellTimeoutError(cmd, o)
            elif isinstance(e, ExpectProcessTerminatedError):
                raise ShellProcessTerminatedError(cmd, e.status, o)
            else:
                raise ShellError(cmd, o)

        # Remove the echoed command and the final shell prompt
        return self.remove_last_nonempty_line(self.remove_command_echo(o, cmd))

    def cmd_output_safe(self, cmd, timeout=60, internal_timeout=None,
                        print_func=None):
        """
        Send a command and return its output (serial sessions).

        In serial sessions, frequently the kernel might print debug or
        error messages that make read_up_to_prompt to timeout. Let's try
        to be a little more robust and send a carriage return, to see if
        we can get to the prompt.

        :param cmd: Command to send (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)

        :return: The output of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellError: Raised if an unknown error occurs
        """
        logging.debug("Sending command (safe): %s" % cmd)
        self.read_nonblocking(0, timeout)
        self.sendline(cmd)
        o = ""
        success = False
        start_time = time.time()
        while (time.time() - start_time) < timeout:
            try:
                o += self.read_up_to_prompt(0.5)
                success = True
                break
            except ExpectError, e:
                o = self.remove_command_echo(e.output, cmd)
                if isinstance(e, ExpectTimeoutError):
                    self.sendline()
                elif isinstance(e, ExpectProcessTerminatedError):
                    raise ShellProcessTerminatedError(cmd, e.status, o)
                else:
                    raise ShellError(cmd, o)

        if not success:
            raise ShellTimeoutError(cmd, o)

        # Remove the echoed command and the final shell prompt
        return self.remove_last_nonempty_line(self.remove_command_echo(o, cmd))

    def cmd_status_output(self, cmd, timeout=60, internal_timeout=None,
                          print_func=None):
        """
        Send a command and return its exit status and output.

        :param cmd: Command to send (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)

        :return: A tuple (status, output) where status is the exit status and
                output is the output of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellStatusError: Raised if the exit status cannot be obtained
        :raise ShellError: Raised if an unknown error occurs
        """
        o = self.cmd_output(cmd, timeout, internal_timeout, print_func)
        try:
            # Send the 'echo $?' (or equivalent) command to get the exit status
            s = self.cmd_output(self.status_test_command, 10, internal_timeout)
        except ShellError:
            raise ShellStatusError(cmd, o)

        # Get the first line consisting of digits only
        digit_lines = [l for l in s.splitlines() if l.strip().isdigit()]
        if digit_lines:
            return int(digit_lines[0].strip()), o
        else:
            raise ShellStatusError(cmd, o)

    def cmd_status(self, cmd, timeout=60, internal_timeout=None,
                   print_func=None):
        """
        Send a command and return its exit status.

        :param cmd: Command to send (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)

        :return: The exit status of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellStatusError: Raised if the exit status cannot be obtained
        :raise ShellError: Raised if an unknown error occurs
        """
        return self.cmd_status_output(cmd, timeout, internal_timeout,
                                      print_func)[0]

    def cmd(self, cmd, timeout=60, internal_timeout=None, print_func=None,
            ok_status=[0, ], ignore_all_errors=False):
        """
        Send a command and return its output. If the command's exit status is
        nonzero, raise an exception.

        :param cmd: Command to send (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :param ok_status: do not raise ShellCmdError in case that exit status
                is one of ok_status. (default is [0,])
        :param ignore_all_errors: toggles whether or not an exception should be
                raised  on any error.

        :return: The output of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellError: Raised if the exit status cannot be obtained or if
                an unknown error occurs
        :raise ShellStatusError: Raised if the exit status cannot be obtained
        :raise ShellError: Raised if an unknown error occurs
        :raise ShellCmdError: Raised if the exit status is nonzero
        """
        try:
            s, o = self.cmd_status_output(cmd, timeout, internal_timeout,
                                          print_func)
            if s not in ok_status:
                raise ShellCmdError(cmd, s, o)
            return o
        except Exception:
            if ignore_all_errors:
                pass
            else:
                raise

    def get_command_output(self, cmd, timeout=60, internal_timeout=None,
                           print_func=None):
        """
        Alias for cmd_output() for backward compatibility.
        """
        return self.cmd_output(cmd, timeout, internal_timeout, print_func)

    def get_command_status_output(self, cmd, timeout=60, internal_timeout=None,
                                  print_func=None):
        """
        Alias for cmd_status_output() for backward compatibility.
        """
        return self.cmd_status_output(cmd, timeout, internal_timeout,
                                      print_func)

    def get_command_status(self, cmd, timeout=60, internal_timeout=None,
                           print_func=None):
        """
        Alias for cmd_status() for backward compatibility.
        """
        return self.cmd_status(cmd, timeout, internal_timeout, print_func)

########NEW FILE########
__FILENAME__ = arch
import platform
from virttest import utils_misc

ARCH = platform.machine()

if ARCH == "ppc64":
    # From include/linux/sockios.h
    SIOCSIFHWADDR = 0x8924
    SIOCGIFHWADDR = 0x8927
    SIOCGIFFLAGS = 0x8913
    SIOCSIFFLAGS = 0x8914
    SIOCGIFADDR = 0x8915
    SIOCSIFADDR = 0x8916
    SIOCGIFNETMASK = 0x891B
    SIOCSIFNETMASK = 0x891C
    SIOCGIFINDEX = 0x8933
    SIOCBRADDIF = 0x89a2
    SIOCBRDELIF = 0x89a3
    SIOCBRADDBR = 0x89a0
    SIOCBRDELBR = 0x89a1
    # From linux/include/linux/if_tun.h
    TUNSETIFF = 0x800454ca
    TUNGETIFF = 0x400454d2
    TUNGETFEATURES = 0x400454cf
    TUNSETQUEUE = 0x800454d9
    IFF_MULTI_QUEUE = 0x0100
    IFF_TAP = 0x2
    IFF_NO_PI = 0x1000
    IFF_VNET_HDR = 0x4000
    # From linux/include/linux/if.h
    IFF_UP = 0x1
    # From linux/netlink.h
    NETLINK_ROUTE = 0
    NLM_F_REQUEST = 1
    NLM_F_ACK = 4
    RTM_DELLINK = 17
    NLMSG_ERROR = 2
    # From linux/socket.h
    AF_PACKET = 17
else:
    # From include/linux/sockios.h
    SIOCSIFHWADDR = 0x8924
    SIOCGIFHWADDR = 0x8927
    SIOCGIFFLAGS = 0x8913
    SIOCSIFFLAGS = 0x8914
    SIOCGIFADDR = 0x8915
    SIOCSIFADDR = 0x8916
    SIOCGIFNETMASK = 0x891B
    SIOCSIFNETMASK = 0x891C
    SIOCGIFINDEX = 0x8933
    SIOCBRADDIF = 0x89a2
    SIOCBRDELIF = 0x89a3
    SIOCBRADDBR = 0x89a0
    SIOCBRDELBR = 0x89a1
    # From linux/include/linux/if_tun.h
    TUNSETIFF = 0x400454ca
    TUNGETIFF = 0x800454d2
    TUNGETFEATURES = 0x800454cf
    TUNSETQUEUE = 0x400454d9
    IFF_MULTI_QUEUE = 0x0100
    IFF_TAP = 0x0002
    IFF_NO_PI = 0x1000
    IFF_VNET_HDR = 0x4000
    # From linux/include/linux/if.h
    IFF_UP = 0x1
    # From linux/netlink.h
    NETLINK_ROUTE = 0
    NLM_F_REQUEST = 1
    NLM_F_ACK = 4
    RTM_DELLINK = 17
    NLMSG_ERROR = 2
    # From linux/socket.h
    AF_PACKET = 17


def get_kvm_module_list():
    if ARCH == 'x86_64':
        arch_convert = {'GenuineIntel': 'intel', 'AuthenticAMD': 'amd'}
        host_cpu_type = utils_misc.get_cpu_vendor(verbose=False)
        return ["kvm", "kvm-%s" % arch_convert[host_cpu_type]]
    elif ARCH == 'ppc64':
        return ["kvm"]

########NEW FILE########
__FILENAME__ = asset
import urllib2
import logging
import os
import glob
from autotest.client import utils, test_config
from autotest.client.shared import git, error
import data_dir
import re


def get_known_backends():
    """
    Return virtualization backends supported by virt-test.
    """
    # Generic means the test can run in multiple backends, such as libvirt
    # and qemu.
    known_backends = ['generic']
    known_backends += os.listdir(data_dir.BASE_BACKEND_DIR)
    return known_backends


def get_test_provider_names(backend=None):
    """
    Get the names of all test providers available in test-providers.d.

    :return: List with the names of all test providers.
    """
    provider_name_list = []
    provider_dir = data_dir.get_test_providers_dir()
    for provider in glob.glob(os.path.join(provider_dir, '*.ini')):
        provider_name = os.path.basename(provider).split('.')[0]
        provider_info = get_test_provider_info(provider_name)
        if backend is not None:
            if backend in provider_info['backends']:
                provider_name_list.append(provider_name)
        else:
            provider_name_list.append(provider_name)
    return provider_name_list


def get_test_provider_subdirs(backend=None):
    """
    Get information of all test provider subdirs for a given backend.

    If no backend is provided, return all subdirs with tests.

    :param backend: Backend type, such as 'qemu'.
    :return: List of directories that contain tests for the given backend.
    """
    subdir_list = []
    for provider_name in get_test_provider_names():
        provider_info = get_test_provider_info(provider_name)
        backends_info = provider_info['backends']
        if backend is not None:
            if backend in backends_info:
                subdir_list.append(backends_info[backend]['path'])
        else:
            for b in backends_info:
                subdir_list.append(backends_info[b]['path'])
    return subdir_list


def get_test_provider_info(provider):
    """
    Get a dictionary with relevant test provider info, such as:

    * provider uri (git repo or filesystem location)
    * provider git repo data, such as branch, ref, pubkey
    * backends that this provider has tests for. For each backend type the
        provider has tests for, the 'path' will be also available.

    :param provider: Test provider name, such as 'io-github-autotest-qemu'.
    """
    provider_info = {}
    provider_path = os.path.join(data_dir.get_test_providers_dir(),
                                 '%s.ini' % provider)
    provider_cfg = test_config.config_loader(provider_path)
    provider_info['name'] = provider
    provider_info['uri'] = provider_cfg.get('provider', 'uri')
    provider_info['branch'] = provider_cfg.get('provider', 'branch', 'master')
    provider_info['ref'] = provider_cfg.get('provider', 'ref')
    provider_info['pubkey'] = provider_cfg.get('provider', 'pubkey')
    provider_info['backends'] = {}

    for backend in get_known_backends():
        subdir = provider_cfg.get(backend, 'subdir')
        if subdir is not None:
            if provider_info['uri'].startswith('file://'):
                src = os.path.join(provider_info['uri'][7:],
                                   subdir)
            else:
                src = os.path.join(data_dir.get_test_provider_dir(provider),
                                   subdir)
            provider_info['backends'].update({backend: {'path': src}})

    return provider_info


def download_test_provider(provider, update=False):
    """
    Download a test provider defined on a .ini file inside test-providers.d.

    This function will only download test providers that are in git repos.
    Local filesystems don't need this functionality.

    :param provider: Test provider name, such as 'io-github-autotest-qemu'.
    """
    provider_info = get_test_provider_info(provider)
    uri = provider_info.get('uri')
    if not uri.startswith('file://'):
        uri = provider_info.get('uri')
        branch = provider_info.get('branch')
        ref = provider_info.get('ref')
        pubkey = provider_info.get('pubkey')
        download_dst = data_dir.get_test_provider_dir(provider)
        repo_downloaded = os.path.isdir(os.path.join(download_dst, '.git'))
        if not repo_downloaded or update:
            download_dst = git.get_repo(uri=uri, branch=branch, commit=ref,
                                        destination_dir=download_dst)
            os.chdir(download_dst)
            try:
                utils.run('git remote add origin %s' % uri)
            except error.CmdError:
                pass
            utils.run('git pull origin %s' % branch)
        os.chdir(download_dst)
        utils.system('git log -1')


def download_all_test_providers(update=False):
    """
    Download all available test providers.
    """
    for provider in get_test_provider_names():
        download_test_provider(provider, update)


def get_all_assets():
    asset_data_list = []
    download_dir = data_dir.get_download_dir()
    for asset in glob.glob(os.path.join(download_dir, '*.ini')):
        asset_name = os.path.basename(asset).split('.')[0]
        asset_data_list.append(get_asset_info(asset_name))
    return asset_data_list


def get_file_asset(title, src_path, destination):
    if not os.path.isabs(destination):
        destination = os.path.join(data_dir.get_data_dir(), destination)

    for ext in (".xz", ".gz", ".7z", ".bz2"):
        if os.path.exists(src_path + ext):
            destination = destination + ext
            logging.debug('Found source image %s', destination)
            return {
                'url': None, 'sha1_url': None, 'destination': src_path + ext,
                'destination_uncompressed': destination,
                'uncompress_cmd': None, 'shortname': title, 'title': title,
                'downloaded': True}

    if os.path.exists(src_path):
        logging.debug('Found source image %s', destination)
        return {'url': src_path, 'sha1_url': None, 'destination': destination,
                'destination_uncompressed': None, 'uncompress_cmd': None,
                'shortname': title, 'title': title,
                'downloaded': os.path.exists(destination)}

    return None


def get_asset_info(asset):
    asset_info = {}
    asset_path = os.path.join(data_dir.get_download_dir(), '%s.ini' % asset)
    asset_cfg = test_config.config_loader(asset_path)

    asset_info['url'] = asset_cfg.get(asset, 'url')
    asset_info['sha1_url'] = asset_cfg.get(asset, 'sha1_url')
    asset_info['title'] = asset_cfg.get(asset, 'title')
    destination = asset_cfg.get(asset, 'destination')
    if not os.path.isabs(destination):
        destination = os.path.join(data_dir.get_data_dir(), destination)
    asset_info['destination'] = destination
    asset_info['asset_exists'] = os.path.isfile(destination)

    # Optional fields
    d_uncompressed = asset_cfg.get(asset, 'destination_uncompressed')
    if d_uncompressed is not None and not os.path.isabs(d_uncompressed):
        d_uncompressed = os.path.join(data_dir.get_data_dir(),
                                      d_uncompressed)
    asset_info['destination_uncompressed'] = d_uncompressed
    asset_info['uncompress_cmd'] = asset_cfg.get(asset, 'uncompress_cmd')

    return asset_info


def uncompress_asset(asset_info, force=False):
    destination = asset_info['destination']
    uncompress_cmd = asset_info['uncompress_cmd']
    destination_uncompressed = asset_info['destination_uncompressed']

    archive_re = re.compile(r".*\.(gz|xz|7z|bz2)$")
    if destination_uncompressed is not None:
        if uncompress_cmd is None:
            match = archive_re.match(destination)
            if match:
                if match.group(1) == 'gz':
                    uncompress_cmd = ('gzip -cd %s > %s' %
                                      (destination, destination_uncompressed))
                elif match.group(1) == 'xz':
                    uncompress_cmd = ('xz -cd %s > %s' %
                                      (destination, destination_uncompressed))
                elif match.group(1) == 'bz2':
                    uncompress_cmd = ('bzip2 -cd %s > %s' %
                                      (destination, destination_uncompressed))
                elif match.group(1) == '7z':
                    uncompress_cmd = '7za -y e %s' % destination
        else:
            uncompress_cmd = "%s %s" % (uncompress_cmd, destination)

    if uncompress_cmd is not None:
        uncompressed_file_exists = os.path.exists(destination_uncompressed)
        force = (force or not uncompressed_file_exists)

        if os.path.isfile(destination) and force:
            os.chdir(os.path.dirname(destination_uncompressed))
            utils.run(uncompress_cmd)


def download_file(asset_info, interactive=False, force=False):
    """
    Verifies if file that can be find on url is on destination with right hash.

    This function will verify the SHA1 hash of the file. If the file
    appears to be missing or corrupted, let the user know.

    :param asset_info: Dictionary returned by get_asset_info
    """
    file_ok = False
    problems_ignored = False
    had_to_download = False
    sha1 = None

    url = asset_info['url']
    sha1_url = asset_info['sha1_url']
    destination = asset_info['destination']
    title = asset_info['title']

    if sha1_url is not None:
        try:
            logging.info("Verifying expected SHA1 sum from %s", sha1_url)
            sha1_file = urllib2.urlopen(sha1_url)
            sha1_contents = sha1_file.read()
            sha1 = sha1_contents.split(" ")[0]
            logging.info("Expected SHA1 sum: %s", sha1)
        except Exception, e:
            logging.error("Failed to get SHA1 from file: %s", e)
    else:
        sha1 = None

    destination_dir = os.path.dirname(destination)
    if not os.path.isdir(destination_dir):
        os.makedirs(destination_dir)

    if not os.path.isfile(destination):
        logging.warning("File %s not found", destination)
        if interactive:
            answer = utils.ask("Would you like to download it from %s?" % url)
        else:
            answer = 'y'
        if answer == 'y':
            utils.interactive_download(
                url, destination, "Downloading %s" % title)
            had_to_download = True
        else:
            logging.warning("Missing file %s", destination)
    else:
        logging.info("Found %s", destination)
        if sha1 is None:
            answer = 'n'
        else:
            answer = 'y'

        if answer == 'y':
            actual_sha1 = utils.hash_file(destination, method='sha1')
            if actual_sha1 != sha1:
                logging.info("Actual SHA1 sum: %s", actual_sha1)
                if interactive:
                    answer = utils.ask("The file seems corrupted or outdated. "
                                       "Would you like to download it?")
                else:
                    logging.info("The file seems corrupted or outdated")
                    answer = 'y'
                if answer == 'y':
                    logging.info("Updating image to the latest available...")
                    while not file_ok:
                        utils.interactive_download(url, destination, title)
                        sha1_post_download = utils.hash_file(destination,
                                                             method='sha1')
                        had_to_download = True
                        if sha1_post_download != sha1:
                            logging.error("Actual SHA1 sum: %s", actual_sha1)
                            if interactive:
                                answer = utils.ask("The file downloaded %s is "
                                                   "corrupted. Would you like "
                                                   "to try again?" %
                                                   destination)
                            else:
                                answer = 'n'
                            if answer == 'n':
                                problems_ignored = True
                                logging.error("File %s is corrupted" %
                                              destination)
                                file_ok = True
                            else:
                                file_ok = False
                        else:
                            file_ok = True
            else:
                file_ok = True
                logging.info("SHA1 sum check OK")
        else:
            problems_ignored = True
            logging.info("File %s present, but did not verify integrity",
                         destination)

    if file_ok:
        if not problems_ignored:
            logging.info("%s present, with proper checksum", destination)

    uncompress_asset(asset_info=asset_info, force=force or had_to_download)


def download_asset(asset, interactive=True, restore_image=False):
    """
    Download an asset defined on an asset file.

    Asset files are located under /shared/downloads, are .ini files with the
    following keys defined:

    title
        Title string to display in the download progress bar.
    url
        URL of the resource
    sha1_url
        URL with SHA1 information for the resource, in the form
        sha1sum file_basename
    destination
        Location of your file relative to the data directory
        (TEST_SUITE_ROOT/shared/data)
    destination
        Location of the uncompressed file relative to the data
        directory (TEST_SUITE_ROOT/shared/data)
    uncompress_cmd
        Command that needs to be executed with the compressed
        file as a parameter

    :param asset: String describing an asset file.
    :param interactive: Whether to ask the user before downloading the file.
    :param restore_image: If the asset is a compressed image, we can uncompress
                          in order to restore the image.
    """
    asset_info = get_asset_info(asset)
    destination = asset_info['destination']

    if (interactive and not os.path.isfile(destination)):
        answer = utils.ask("File %s not present. Do you want to download it?" %
                           asset_info['title'])
    else:
        answer = "y"

    if answer == "y":
        download_file(asset_info=asset_info, interactive=interactive,
                      force=restore_image)

########NEW FILE########
__FILENAME__ = base_installer
'''
This module implements classes that perform the installation of the
virtualization software on a host system.

These classes can be, and usually are, inherited by subclasses that implement
custom logic for each virtualization hypervisor/software.
'''

import os
import logging
from autotest.client import utils, os_dep
from autotest.client.shared import error
import build_helper
import utils_misc
import yumrepo
import arch
try:
    from staging import utils_koji
except ImportError:
    from autotest.client.shared import utils_koji


class NoModuleError(Exception):

    '''
    Error raised when no suitable modules were found to load
    '''
    pass


class VirtInstallException(Exception):

    '''
    Base virtualization software components installation exception
    '''
    pass


class VirtInstallFailed(VirtInstallException):

    '''
    Installation of virtualization software components failed
    '''
    pass


class VirtInstallNotInstalled(VirtInstallException):

    '''
    Virtualization software components are not installed
    '''
    pass


class BaseInstaller(object):

    '''
    Base virtualization software installer

    This class holds all the skeleton features for installers and should be
    inherited from when creating a new installer.
    '''

    def __init__(self, mode, name, test=None, params=None):
        '''
        Instantiates a new base installer

        :param mode: installer mode, such as git_repo, local_src, etc
        :param name: installer short name, foo for git_repo_foo
        :param test: test
        :param params: params
        '''
        self.mode = mode
        self.name = name
        self.params = params
        self.param_key_prefix = '%s_%s' % (self.mode,
                                           self.name)

        # If a installer has a failure that can be worked around, save that
        self.minor_failure = False
        self.minor_failure_reason = ''

        if test and params:
            self.set_install_params(test, params)

    def _set_test_dirs(self, test):
        '''
        Save common test directories paths as class attributes

        Test variables values are saved here again because it's not possible to
        pickle the test instance inside BaseInstaller due to limitations
        in the pickle protocol. And, in case this pickle thing needs more
        explanation, take a loot at the Env class inside build_helper.

        Besides that, we also ensure that srcdir exists, by creating it if
        necessary.

        For reference:
           * bindir = tests/<test>
           * srcdir = tests/<test>/src
           * resultsdir = results/<job>/<testname.tag>/results

        So, for KVM tests, it'd evaluate to:
           * bindir = tests/kvm/
           * srcdir = tests/kvm/src
           * resultsdir = results/<job>/kvm.<other_variant_names>.build/results
        '''
        self.test_bindir = test.bindir
        self.test_srcdir = test.srcdir
        self.test_builddir = test.builddir
        self.test_resultsdir = test.resultsdir

        #
        # test_builddir is guaranteed to exist, but test_srcdir is not
        #
        if not os.path.isdir(test.srcdir):
            os.makedirs(test.srcdir)

    def _set_param_load_module(self):
        '''
        Checks whether kernel modules should be loaded

        Default behavior is to load modules unless set to 'no'

        Configuration file parameter: load_modules
        Class attribute set: should_load_modules
        '''
        load_modules = self.params.get('load_modules', 'no')
        if not load_modules or load_modules == 'yes':
            self.should_load_modules = True
        elif load_modules == 'no':
            self.should_load_modules = False

    def _set_param_module_list(self):
        '''
        Sets the list of kernel modules to be loaded during installation

        Configuration file parameter: module_list
        Class attribute set: module_list
        '''
        self.module_list = self.params.get('module_list', [])

    def _set_param_save_results(self):
        '''
        Checks whether to save the result of the build on test.resultsdir

        Configuration file parameter: save_results
        Class attribute set: save_results
        '''
        self.save_results = True
        save_results = self.params.get('save_results', 'no')
        if save_results == 'no':
            self.save_results = False

    def _set_param_install_debug_info(self):
        '''
        Sets whether to enable debug information on installed software

        Configuration file parameter: install_debug_info
        Class attribute set: install_debug_info
        '''
        self.install_debug_info = True
        install_debug_info = self.params.get('install_debug_info', 'no')
        if install_debug_info == 'no':
            self.install_debug_info = False

    def _set_param_cleanup(self):
        '''
        Sets whether to enable debug information on installed software

        Configuration file parameter: installer_cleanup
        Class attribute set: cleanup
        '''
        self.cleanup = True
        cleanup = self.params.get('installer_cleanup', 'yes')
        if cleanup == 'no':
            logging.debug("Setting installer cleanup attribute to False")
            self.cleanup = False

    def set_install_params(self, test=None, params=None):
        '''
        Called by test to setup parameters from the configuration file
        '''
        logging.info("calling set install params")
        if test is not None:
            self._set_test_dirs(test)

        if params is not None:
            self.params = params
            self._set_param_load_module()
            self._set_param_module_list()
            self._set_param_save_results()
            self._set_param_install_debug_info()
            self._set_param_cleanup()

    def _install_phase_cleanup(self):
        '''
        Optional install phase for removing previous version of the software

        If a particular virtualization software installation mechanism
        needs to download files (it most probably does), override this
        method with custom functionality.

        This replaces methods such as KojiInstaller._get_packages()
        '''
        pass

    def _install_phase_cleanup_verify(self):
        '''
        Optional install phase for removing previous version of the software

        If a particular virtualization software installation mechanism
        needs to download files (it most probably does), override this
        method with custom functionality.

        This replaces methods such as KojiInstaller._get_packages()
        '''
        pass

    def _install_phase_download(self):
        '''
        Optional install phase for downloading software

        If a particular virtualization software installation mechanism
        needs to download files (it most probably does), override this
        method with custom functionality.

        This replaces methods such as KojiInstaller._get_packages()
        '''
        pass

    def _install_phase_download_verify(self):
        '''
        Optional install phase for checking downloaded software

        If you want to make sure the downloaded software is in good shape,
        override this method.

        Ideas for using this method:
          * check MD5SUM/SHA1SUM for tarball downloads
          * check RPM files, probably by signature (rpm -k)
          * git status and check if there's no locally modified files
        '''
        pass

    def _install_phase_prepare(self):
        '''
        Optional install phase for preparing software

        If a particular virtualization software installation mechanism
        needs to do something to the obtained software, such as extracting
        a tarball or applying patches, this should be done here.
        '''
        pass

    def _install_phase_prepare_verify(self):
        '''
        Optional install phase for checking software preparation

        Ideas for using this method:
          * git status and check if there are locally patched files
        '''
        pass

    def _install_phase_build(self):
        '''
        Optional install phase for building software

        If a particular virtualization software installation mechanism
        needs to compile source code, it should be done here.
        '''
        pass

    def _install_phase_build_verify(self):
        '''
        Optional install phase for checking software build

        Ideas for using this method:
           * running 'make test' or something similar to it
        '''
        pass

    def _install_phase_install(self):
        '''
        Optional install phase for actually installing software

        Ideas for using this method:
           * running 'make install' or something similar to it
           * running 'yum localinstall *.rpm'
        '''
        pass

    def _install_phase_install_verify(self):
        '''
        Optional install phase for checking the installed software

        This should verify the installed software is in a desirable state.
        Ideas for using this include:
           * checking if installed files exists (like os.path.exists())
           * checking packages are indeed installed (rpm -q <pkg>.rpm)
        '''
        pass

    def _install_phase_init(self):
        '''
        Optional install phase for initializing the installed software

        This should initialize the installed software. Ideas for using this:
           * loading kernel modules
           * running services: 'service <daemon> start'
           * linking software (whether built or downloaded) to a common path
        '''
        pass

    def _install_phase_init_verify(self):
        '''
        Optional install phase for checking that software is initialized

        This should verify that the installed software is running. Ideas for
        using this include:
            * checking service (daemon) status: 'service <daemon> status'
            * checking service (functionality) status: 'virsh capabilities'
        '''
        pass

    def write_version_keyval(self, test):
        try:
            version = self.get_version()
        except AttributeError:
            version = "Unknown"
        sw_version = {('software_version_%s' % self.name): version}
        logging.debug("Writing test keyval %s", sw_version)
        test.write_test_keyval(sw_version)

    def load_modules(self, module_list=None):
        '''
        Load Linux Kernel modules the virtualization software may depend on

        If module_directory is not set, the list of modules will simply be
        loaded by the system stock modprobe tool, meaning that modules will be
        looked for in the system default module paths.

        :type module_list: list
        :param module_list: list of kernel modules names to load
        '''
        if module_list is None:
            module_list = self.module_list

        if not module_list:
            raise NoModuleError("Module list empty")

        logging.info("Loading modules from default locations through "
                     "modprobe")
        for module in module_list:
            utils.system("modprobe %s" % module)

    def unload_modules(self, module_list=None):
        '''
        Unloads kernel modules

        By default, if no module list is explicitly provided, the list on
        params (coming from the configuration file) will be used.
        '''
        if module_list is None:
            module_list = self.module_list
        logging.info("Unloading kernel modules: %s" % " ".join(module_list))
        for module in module_list:
            utils.unload_module(module)

    def reload_modules(self):
        """
        Reload the kernel modules (unload, then load)
        """
        self.unload_modules()
        self.load_modules()

    def reload_modules_if_needed(self):
        if self.should_load_modules:
            self.reload_modules()

    def install(self, cleanup=True, download=True, prepare=True,
                build=True, install=True, init=True):
        '''
        Performs the installation of the virtualization software

        This is the main entry point of this class, and should  either
        be reimplemented completely, or simply implement one or many of the
        install  phases.
        '''
        if (cleanup and self.cleanup):
            self._install_phase_cleanup()
            self._install_phase_cleanup_verify()

        if download:
            self._install_phase_download()
            self._install_phase_download_verify()

        if prepare:
            self._install_phase_prepare()
            self._install_phase_prepare_verify()

        if build:
            self._install_phase_build()
            self._install_phase_build_verify()

        if install:
            self._install_phase_install()
            self._install_phase_install_verify()

        if init:
            self._install_phase_init()
            self._install_phase_init_verify()

        self.reload_modules_if_needed()
        if self.save_results:
            utils_misc.archive_as_tarball(self.test_srcdir,
                                          self.test_resultsdir)

    def uninstall(self):
        '''
        Performs the uninstallations of the virtualization software

        Note: This replaces old qemu_installer._clean_previous_install()
        '''
        raise NotImplementedError


class NoopInstaller(BaseInstaller):

    '''
    Dummy installer that does nothing, useful when software is pre-installed
    '''

    def __init__(self, mode, name, test=None, params=None):
        '''
        If no previous install test ran, try to figure out modules to load.

        :param mode (str): Install mode (yum, git, etc).
        :param name (str): Installer name.
        :param test: Virt test object.
        :param params: Dict with test params.
        '''
        if params['vm_type'] == 'qemu':
            params['module_list'] = arch.get_kvm_module_list()
        super(NoopInstaller, self).__init__(mode, name, test, params)

    def install(self):
        logging.info("Assuming virtualization software to be already "
                     "installed. Doing nothing")


class YumInstaller(BaseInstaller):

    '''
    Installs virtualization software using YUM

    Notice: this class implements a change of behaviour if compared to
    qemu_installer.YumInstaller.set_install_params(). There's no longer
    a default package list, as each virtualization technology will have
    a completely different default. This should now be kept at the
    configuration file only.

    For now this class implements support for installing from the configured
    yum repos only. If the use case of installing from local RPM packages
    arises, we'll implement that.
    '''

    def set_install_params(self, test, params):
        super(YumInstaller, self).set_install_params(test, params)
        os_dep.command("rpm")
        os_dep.command("yum")
        if self.install_debug_info:
            os_dep.command("debuginfo-install")
        self.yum_pkgs = eval(params.get("%s_pkgs" % self.param_key_prefix,
                                        "[]"))

    def get_version(self):
        return " ".join(self.yum_pkgs)

    def _install_phase_cleanup(self):
        packages_to_remove = " ".join(self.yum_pkgs)
        utils.system("yum remove -y %s" % packages_to_remove)

    def _install_phase_install(self):
        if self.yum_pkgs:
            os.chdir(self.test_srcdir)
            utils.system("yum --nogpgcheck -y install %s" %
                         " ".join(self.yum_pkgs))
        if self.install_debug_info:
            utils.system("debuginfo-install --enablerepo='*debuginfo' -y %s" %
                         " ".join(self.yum_pkgs))


class KojiInstaller(BaseInstaller):

    '''
    Handles virtualization software installation via koji/brew

    It uses YUM to install and remove packages.

    Change notice: this is not a subclass of YumInstaller anymore. The
    parameters this class uses are different (koji_tag, koji_pgks) and
    the install process runs YUM.
    '''

    def set_install_params(self, test, params):
        super(KojiInstaller, self).set_install_params(test, params)
        os_dep.command("rpm")
        os_dep.command("yum")

        self.tag = params.get("%s_tag" % self.param_key_prefix, None)
        self.koji_cmd = params.get("%s_cmd" % self.param_key_prefix, None)
        if self.tag is not None:
            utils_koji.set_default_koji_tag(self.tag)
        self.koji_pkgs = params.get("%s_pkgs" % self.param_key_prefix,
                                    "").split()
        self.koji_scratch_pkgs = params.get("%s_scratch_pkgs" %
                                            self.param_key_prefix,
                                            "").split()
        self.koji_yumrepo_baseurl = params.get("%s_yumrepo_baseurl" %
                                               self.param_key_prefix, None)
        if self.install_debug_info:
            self._expand_koji_pkgs_with_debuginfo()

    def get_version(self):
        return " ".join(self._get_rpm_file_names())

    def _expand_koji_pkgs_with_debuginfo(self):
        '''
        Include debuginfo RPMs on koji_pkgs

        :return: None
        '''
        logging.debug("Koji package list to be updated with debuginfo pkgs")

        koji_pkgs_with_debug = []
        for pkg_text in self.koji_pkgs:
            pkg = utils_koji.KojiPkgSpec(pkg_text)
            debuginfo_pkg_name = '%s-debuginfo' % pkg.package
            # if no subpackages are set, then all packages will be installed
            # so there's no need to manually include debuginfo packages
            if pkg.subpackages:
                # make sure we do not include the debuginfo package if
                # already specified in the list of subpackages
                if debuginfo_pkg_name not in pkg.subpackages:
                    pkg.subpackages.append(debuginfo_pkg_name)

            pkg_with_debug_text = pkg.to_text()
            logging.debug("KojiPkgSpec with debuginfo package added: %s",
                          pkg_with_debug_text)
            koji_pkgs_with_debug.append(pkg_with_debug_text)

        # swap current koji_pkgs with on that includes debuginfo pkgs
        self.koji_pkgs = koji_pkgs_with_debug

    def _get_rpm_names(self):
        all_rpm_names = []
        koji_client = utils_koji.KojiClient(cmd=self.koji_cmd)
        for pkg_text in self.koji_pkgs:
            pkg = utils_koji.KojiPkgSpec(pkg_text)
            rpm_names = koji_client.get_pkg_rpm_names(pkg)
            all_rpm_names += rpm_names
        for scratch_pkg_text in self.koji_scratch_pkgs:
            pkg = utils_koji.KojiScratchPkgSpec(scratch_pkg_text)
            rpm_urls = koji_client.get_scratch_pkg_urls(pkg)
            file_names = map(os.path.basename, rpm_urls)
            for f in file_names:
                r = utils_koji.RPMFileNameInfo(f)
                all_rpm_names.append(r.get_nvr_info()['name'])
        return all_rpm_names

    def _get_rpm_file_names(self):
        all_rpm_file_names = []
        koji_client = utils_koji.KojiClient(cmd=self.koji_cmd)
        for pkg_text in self.koji_pkgs:
            pkg = utils_koji.KojiPkgSpec(pkg_text)
            rpm_file_names = koji_client.get_pkg_rpm_file_names(pkg)
            all_rpm_file_names += rpm_file_names
        for scratch_pkg_text in self.koji_scratch_pkgs:
            pkg = utils_koji.KojiScratchPkgSpec(scratch_pkg_text)
            rpm_urls = koji_client.get_scratch_pkg_urls(pkg)
            file_names = map(os.path.basename, rpm_urls)
            all_rpm_file_names += file_names
        return all_rpm_file_names

    def _install_phase_cleanup(self):
        removable_packages = " ".join(self._get_rpm_names())
        utils.system("yum -y remove %s" % removable_packages)

    def _install_phase_download(self):
        koji_client = utils_koji.KojiClient(cmd=self.koji_cmd)
        for pkg_text in self.koji_pkgs:
            pkg = utils_koji.KojiPkgSpec(pkg_text)
            if pkg.is_valid():
                koji_client.get_pkgs(pkg, dst_dir=self.test_srcdir)
            else:
                logging.error('Package specification (%s) is invalid: %s' %
                              (pkg, pkg.describe_invalid()))
        for pkg_text in self.koji_scratch_pkgs:
            pkg = utils_koji.KojiScratchPkgSpec(pkg_text)
            koji_client.get_scratch_pkgs(pkg, dst_dir=self.test_srcdir)

    def _install_phase_install(self):
        if self.koji_yumrepo_baseurl is not None:
            repo = yumrepo.YumRepo(self.param_key_prefix,
                                   self.koji_yumrepo_baseurl)
            logging.debug('Enabling YUM Repo "%s" at "%s"',
                          self.param_key_prefix, self.koji_yumrepo_baseurl)
            repo.save()

        os.chdir(self.test_srcdir)
        rpm_file_names = " ".join(self._get_rpm_file_names())
        utils.system("yum --nogpgcheck -y install %s" % rpm_file_names)

        if self.koji_yumrepo_baseurl is not None:
            logging.debug('Disabling YUM Repo "%s" at "%s"',
                          self.param_key_prefix, self.koji_yumrepo_baseurl)
            repo.remove()


class BaseLocalSourceInstaller(BaseInstaller):

    def set_install_params(self, test, params):
        super(BaseLocalSourceInstaller, self).set_install_params(test, params)
        self._set_install_prefix()
        self._set_source_destination()

        #
        # There are really no choices for patch helpers
        #
        self.patch_helper = build_helper.PatchParamHelper(
            self.params,
            self.param_key_prefix,
            self.source_destination)

        #
        # These helpers should be set by child classes
        #
        self.content_helper = None
        self.build_helper = None

    def _set_install_prefix(self):
        '''
        Prefix for installation of application built from source

        When installing virtualization software from *source*, this is where
        the resulting binaries will be installed. Usually this is the value
        passed to the configure script, ie: ./configure --prefix=<value>
        '''
        prefix = os.path.join(self.test_builddir, 'install_root')
        self.install_prefix = os.path.abspath(prefix)

    def _set_source_destination(self):
        '''
        Sets the source code destination directory path
        '''
        self.source_destination = os.path.join(self.test_srcdir,
                                               self.name)

    def _set_build_helper(self):
        '''
        Sets the build helper, default is 'gnu_autotools'
        '''
        build_helper_name = self.params.get('%s_build_helper' %
                                            self.param_key_prefix,
                                            'gnu_autotools')
        if build_helper_name == 'gnu_autotools':
            self.build_helper = build_helper.GnuSourceBuildParamHelper(
                self.params, self.param_key_prefix,
                self.source_destination, self.install_prefix)
        elif build_helper_name == 'linux_kernel':
            self.build_helper = build_helper.LinuxKernelBuildHelper(
                self.params, self.param_key_prefix,
                self.source_destination)

    def _install_phase_prepare(self):
        if self.patch_helper is not None:
            self.patch_helper.execute()

    def _install_phase_download(self):
        if self.content_helper is not None:
            self.content_helper.execute()

    def _install_phase_build(self):
        if self.build_helper is not None:
            if (isinstance(self.build_helper,
                           build_helper.GnuSourceBuildHelper) or
                isinstance(self.build_helper,
                           build_helper.LinuxKernelBuildHelper)):
                try:
                    self.build_helper.execute()
                except build_helper.SourceBuildParallelFailed:
                    # Flag minor the failure
                    self.minor_failure = True
                    self.minor_failure_reason = "Failed to do parallel build"

                except build_helper.SourceBuildFailed:
                    # Failed the current test
                    raise error.TestFail("Failed to build %s" % self.name)
            else:
                self.build_helper.execute()

    def _install_phase_install(self):
        if self.build_helper is not None:
            self.build_helper.install()


class LocalSourceDirInstaller(BaseLocalSourceInstaller):

    '''
    Handles software installation by building/installing from a source dir
    '''

    def set_install_params(self, test, params):
        super(LocalSourceDirInstaller, self).set_install_params(test, params)

        self.content_helper = build_helper.LocalSourceDirParamHelper(
            params,
            self.name,
            self.source_destination)

        self._set_build_helper()


class LocalSourceTarInstaller(BaseLocalSourceInstaller):

    '''
    Handles software installation by building/installing from a tarball
    '''

    def set_install_params(self, test, params):
        super(LocalSourceTarInstaller, self).set_install_params(test, params)

        self.content_helper = build_helper.LocalTarParamHelper(
            params,
            self.name,
            self.source_destination)

        self._set_build_helper()


class RemoteSourceTarInstaller(BaseLocalSourceInstaller):

    '''
    Handles software installation by building/installing from a remote tarball
    '''

    def set_install_params(self, test, params):
        super(RemoteSourceTarInstaller, self).set_install_params(test, params)

        self.content_helper = build_helper.RemoteTarParamHelper(
            params,
            self.name,
            self.source_destination)

        self._set_build_helper()


class GitRepoInstaller(BaseLocalSourceInstaller):

    def set_install_params(self, test, params):
        super(GitRepoInstaller, self).set_install_params(test, params)

        self.content_helper = build_helper.GitRepoParamHelper(
            params,
            self.name,
            self.source_destination)

        self._set_build_helper()

    def get_version(self):
        uri = self.content_helper.uri
        branch = self.content_helper.branch
        commit = self.content_helper.get_top_commit()
        return "%s:%s:%s" % (uri, branch, commit)


class FailedInstaller:

    """
    Class used to be returned instead of the installer if a installation fails

    Useful to make sure no installer object is used if virt installation fails
    """

    def __init__(self, msg="Virtualization software install failed"):
        self._msg = msg

    def load_modules(self):
        """
        Will refuse to load the kerkel modules as install failed
        """
        raise VirtInstallFailed("Kernel modules not available. reason: %s" %
                                self._msg)

########NEW FILE########
__FILENAME__ = bootstrap
import logging
import os
import glob
import shutil
from autotest.client.shared import logging_manager, error
from autotest.client import utils
import utils_misc
import data_dir
import asset
import cartesian_config
import utils_selinux
import defaults

basic_program_requirements = ['7za', 'tcpdump', 'nc', 'ip', 'arping']

recommended_programs = {'qemu': [('qemu-kvm', 'kvm'), ('qemu-img',),
                                 ('qemu-io',)],
                        'libvirt': [('virsh',), ('virt-install',),
                                    ('fakeroot',), ('semanage',),
                                    ('getfattr',), ('restorecon',)],
                        'openvswitch': [],
                        'lvsb': [('semanage',), ('getfattr',), ('restorecon',)],
                        'v2v': [],
                        'libguestfs': [('perl',)]}

mandatory_programs = {'qemu': basic_program_requirements + ['gcc'],
                      'libvirt': basic_program_requirements,
                      'openvswitch': basic_program_requirements,
                      'lvsb': ['virt-sandbox', 'virt-sandbox-service', 'virsh'],
                      'v2v': basic_program_requirements,
                      'libguestfs': basic_program_requirements}

mandatory_headers = {'qemu': ['Python.h', 'types.h', 'socket.h', 'unistd.h'],
                     'libvirt': [],
                     'openvswitch': [],
                     'v2v': [],
                     'lvsb': [],
                     'libguestfs': []}

first_subtest = {'qemu': ['unattended_install', 'steps'],
                 'libvirt': ['unattended_install'],
                 'openvswitch': ['unattended_install'],
                 'v2v': ['unattended_install'],
                 'libguestfs': ['unattended_install'],
                 'lvsb': []}

last_subtest = {'qemu': ['shutdown'],
                'libvirt': ['shutdown', 'remove_guest'],
                'openvswitch': ['shutdown'],
                'v2v': ['shutdown'],
                'libguestfs': ['shutdown'],
                'lvsb': []}

test_filter = ['__init__', 'cfg', 'dropin.py']


def get_guest_os_info_list(test_name, guest_os):
    """
    Returns a list of matching assets compatible with the specified test name
    and guest OS
    """
    os_info_list = []

    cartesian_parser = cartesian_config.Parser()
    cartesian_parser.parse_file(data_dir.get_backend_cfg_path(test_name, 'guest-os.cfg'))
    cartesian_parser.only_filter(guest_os)
    dicts = cartesian_parser.get_dicts()

    for params in dicts:
        image_name = params.get('image_name', 'image').split('/')[-1]
        shortname = params.get('shortname', guest_os)
        os_info_list.append({'asset': image_name, 'variant': shortname})

    if not os_info_list:
        logging.error("Could not find any assets compatible with %s for %s",
                      guest_os, test_name)
        raise ValueError("Missing compatible assets for %s", guest_os)

    return os_info_list


def _get_config_filter():
    config_filter = ['__init__', ]
    for provider_subdir in asset.get_test_provider_subdirs():
        config_filter.append(os.path.join('%s' % provider_subdir, 'cfg'))
    return config_filter

config_filter = _get_config_filter()


def verify_recommended_programs(t_type):
    cmds = recommended_programs[t_type]
    for cmd_aliases in cmds:
        for cmd in cmd_aliases:
            found = None
            try:
                found = utils_misc.find_command(cmd)
                logging.info(found)
                break
            except ValueError:
                pass
        if found is None:
            if len(cmd_aliases) == 1:
                logging.info("Recommended command %s missing. You may "
                             "want to install it if not building from "
                             "source.", cmd_aliases[0])
            else:
                logging.info("Recommended command missing. You may "
                             "want to install it if not building it from "
                             "source. Aliases searched: %s", cmd_aliases)


def verify_mandatory_programs(t_type):
    failed_cmds = []
    cmds = mandatory_programs[t_type]
    for cmd in cmds:
        try:
            logging.info(utils_misc.find_command(cmd))
        except ValueError:
            logging.error("Required command %s is missing. You must "
                          "install it", cmd)
            failed_cmds.append(cmd)

    includes = mandatory_headers[t_type]
    available_includes = glob.glob('/usr/include/*/*')
    for include in available_includes:
        include_basename = os.path.basename(include)
        if include_basename in includes:
            logging.info(include)
            includes.pop(includes.index(include_basename))

    if includes:
        for include in includes:
            logging.error("Required include %s is missing. You may have to "
                          "install it", include)

    failures = failed_cmds + includes

    if failures:
        raise ValueError('Missing (cmds/includes): %s' % " ".join(failures))


def write_subtests_files(config_file_list, output_file_object, test_type=None):
    '''
    Writes a collection of individual subtests config file to one output file

    Optionally, for tests that we know their type, write the 'virt_test_type'
    configuration automatically.
    '''
    if test_type is not None:
        output_file_object.write("    - @type_specific:\n")
        output_file_object.write("        variants subtest:\n")

    for provider_name, config_path in config_file_list:
        config_file = open(config_path, 'r')

        write_test_type_line = False
        write_provider_line = False

        for line in config_file.readlines():
            if line.startswith('- ') and provider_name is not None:
                name, deps = line.split(":")
                name = name.split('-')[-1].strip()
                if name[0] == "@":
                    name = name[1:]
                line = "- %s.%s:%s" % (provider_name, name, deps)

            # special virt_test_type line output
            if test_type is not None:
                if write_test_type_line:
                    type_line = ("                virt_test_type = %s\n" %
                                 test_type)
                    output_file_object.write(type_line)
                    provider_line = ("                provider = %s\n" %
                                     provider_name)
                    output_file_object.write(provider_line)
                    write_test_type_line = False
                elif line.startswith('- '):
                    write_test_type_line = True
                output_file_object.write("            %s" % line)
            else:
                if write_provider_line:
                    provider_line = ("        provider = %s\n" %
                                     provider_name)
                    output_file_object.write(provider_line)
                    write_provider_line = False
                elif line.startswith('- '):
                    write_provider_line = True
                # regular line output
                output_file_object.write("    %s" % line)

        config_file.close()


def get_directory_structure(rootdir, guest_file):
    rootdir = rootdir.rstrip(os.sep)
    start = rootdir.rfind(os.sep) + 1
    previous_indent = 0
    indent = 0
    number_variants = 0
    for path, subdirs, files in os.walk(rootdir):
        folders = path[start:].split(os.sep)
        folders = folders[1:]
        indent = len(folders)
        if indent > previous_indent:
            guest_file.write("%svariants:\n" %
                             (4 * (indent + number_variants - 1) * " "))
            number_variants += 1
        elif indent < previous_indent:
            number_variants = indent
        indent += number_variants
        try:
            base_folder = folders[-1]
        except IndexError:
            base_folder = []
        base_cfg = "%s.cfg" % base_folder
        base_cfg_path = os.path.join(os.path.dirname(path), base_cfg)
        if os.path.isfile(base_cfg_path):
            base_file = open(base_cfg_path, 'r')
            for line in base_file.readlines():
                guest_file.write("%s%s" % ((4 * (indent - 1) * " "), line))
        else:
            if base_folder:
                guest_file.write("%s- %s:\n" %
                                 ((4 * (indent - 1) * " "), base_folder))
        variant_printed = False
        if files:
            files.sort()
            for f in files:
                if f.endswith(".cfg"):
                    bf = f[:len(f) - 4]
                    if bf not in subdirs:
                        if not variant_printed:
                            guest_file.write("%svariants:\n" %
                                             ((4 * (indent) * " ")))
                            variant_printed = True
                        base_file = open(os.path.join(path, f), 'r')
                        for line in base_file.readlines():
                            guest_file.write("%s%s" %
                                             ((4 * (indent + 1) * " "), line))
        indent -= number_variants
        previous_indent = indent


def create_guest_os_cfg(t_type):
    root_dir = data_dir.get_root_dir()
    guest_os_cfg_dir = os.path.join(root_dir, 'shared', 'cfg', 'guest-os')
    guest_os_cfg_path = data_dir.get_backend_cfg_path(t_type, 'guest-os.cfg')
    guest_os_cfg_file = open(guest_os_cfg_path, 'w')
    get_directory_structure(guest_os_cfg_dir, guest_os_cfg_file)


def create_subtests_cfg(t_type):
    root_dir = data_dir.get_root_dir()

    specific_test_list = []
    specific_file_list = []
    specific_subdirs = asset.get_test_provider_subdirs(t_type)
    provider_names_specific = asset.get_test_provider_names(t_type)

    provider_info_specific = []
    for specific_provider in provider_names_specific:
        provider_info_specific.append(asset.get_test_provider_info(specific_provider))

    for subdir in specific_subdirs:
        specific_test_list += data_dir.SubdirGlobList(subdir,
                                                      '*.py',
                                                      test_filter)
        specific_file_list += data_dir.SubdirGlobList(subdir,
                                                      '*.cfg',
                                                      config_filter)

    shared_test_list = []
    shared_file_list = []
    shared_subdirs = asset.get_test_provider_subdirs('generic')
    provider_names_shared = asset.get_test_provider_names('generic')

    provider_info_shared = []
    for shared_provider in provider_names_shared:
        provider_info_shared.append(asset.get_test_provider_info(shared_provider))

    if not t_type == 'lvsb':
        for subdir in shared_subdirs:
            shared_test_list += data_dir.SubdirGlobList(subdir,
                                                        '*.py',
                                                        test_filter)
            shared_file_list += data_dir.SubdirGlobList(subdir,
                                                        '*.cfg',
                                                        config_filter)

    all_specific_test_list = []
    for test in specific_test_list:
        for p in provider_info_specific:
            provider_base_path = p['backends'][t_type]['path']
            if provider_base_path in test:
                provider_name = p['name']
                break

        basename = os.path.basename(test)
        if basename != "__init__.py":
            all_specific_test_list.append("%s.%s" %
                                          (provider_name,
                                           basename.split(".")[0]))
    all_shared_test_list = []
    for test in shared_test_list:
        for p in provider_info_shared:
            provider_base_path = p['backends']['generic']['path']
            if provider_base_path in test:
                provider_name = p['name']
                break

        basename = os.path.basename(test)
        if basename != "__init__.py":
            all_shared_test_list.append("%s.%s" %
                                        (provider_name,
                                         basename.split(".")[0]))

    all_specific_test_list.sort()
    all_shared_test_list.sort()
    all_test_list = set(all_specific_test_list + all_shared_test_list)

    first_subtest_file = []
    last_subtest_file = []
    non_dropin_tests = []
    tmp = []

    for shared_file in shared_file_list:
        provider_name = None
        for p in provider_info_shared:
            provider_base_path = p['backends']['generic']['path']
            if provider_base_path in shared_file:
                provider_name = p['name']
                break

        shared_file_obj = open(shared_file, 'r')
        for line in shared_file_obj.readlines():
            line = line.strip()
            if line.startswith("type"):
                cartesian_parser = cartesian_config.Parser()
                cartesian_parser.parse_string(line)
                td = cartesian_parser.get_dicts().next()
                values = td['type'].split(" ")
                for value in values:
                    if t_type not in non_dropin_tests:
                        non_dropin_tests.append("%s.%s" %
                                                (provider_name, value))

        shared_file_name = os.path.basename(shared_file)
        shared_file_name = shared_file_name.split(".")[0]
        if shared_file_name in first_subtest[t_type]:
            if [provider_name, shared_file] not in first_subtest_file:
                first_subtest_file.append([provider_name, shared_file])
        elif shared_file_name in last_subtest[t_type]:
            if [provider_name, shared_file] not in last_subtest_file:
                last_subtest_file.append([provider_name, shared_file])
        else:
            if [provider_name, shared_file] not in tmp:
                tmp.append([provider_name, shared_file])
    shared_file_list = tmp

    tmp = []
    for shared_file in specific_file_list:
        provider_name = None
        for p in provider_info_specific:
            provider_base_path = p['backends'][t_type]['path']
            if provider_base_path in shared_file:
                provider_name = p['name']
                break

        shared_file_obj = open(shared_file, 'r')
        for line in shared_file_obj.readlines():
            line = line.strip()
            if line.startswith("type"):
                cartesian_parser = cartesian_config.Parser()
                cartesian_parser.parse_string(line)
                td = cartesian_parser.get_dicts().next()
                values = td['type'].split(" ")
                for value in values:
                    if value not in non_dropin_tests:
                        non_dropin_tests.append("%s.%s" %
                                                (provider_name, value))

        shared_file_name = os.path.basename(shared_file)
        shared_file_name = shared_file_name.split(".")[0]
        if shared_file_name in first_subtest[t_type]:
            if [provider_name, shared_file] not in first_subtest_file:
                first_subtest_file.append([provider_name, shared_file])
        elif shared_file_name in last_subtest[t_type]:
            if [provider_name, shared_file] not in last_subtest_file:
                last_subtest_file.append([provider_name, shared_file])
        else:
            if [provider_name, shared_file] not in tmp:
                tmp.append([provider_name, shared_file])
    specific_file_list = tmp

    non_dropin_tests.sort()
    non_dropin_tests = set(non_dropin_tests)
    dropin_tests = all_test_list - non_dropin_tests
    dropin_file_list = []
    tmp_dir = data_dir.get_tmp_dir()
    if not os.path.isdir(tmp_dir):
        os.makedirs(tmp_dir)

    for dropin_test in dropin_tests:
        provider = dropin_test.split(".")[0]
        d_type = dropin_test.split(".")[-1]
        autogen_cfg_path = os.path.join(tmp_dir,
                                        '%s.cfg' % dropin_test)
        autogen_cfg_file = open(autogen_cfg_path, 'w')
        autogen_cfg_file.write("# Drop-in test - auto generated snippet\n")
        autogen_cfg_file.write("- %s:\n" % dropin_test)
        autogen_cfg_file.write("    virt_test_type = %s\n" % t_type)
        autogen_cfg_file.write("    type = %s\n" % d_type)
        autogen_cfg_file.close()
        dropin_file_list.append([provider, autogen_cfg_path])

    dropin_file_list_2 = []
    dropin_tests = os.listdir(os.path.join(data_dir.get_root_dir(), "dropin"))
    dropin_cfg_path = os.path.join(tmp_dir, 'dropin.cfg')
    dropin_cfg_file = open(dropin_cfg_path, 'w')
    dropin_cfg_file.write("# Auto generated snippet for dropin tests\n")
    dropin_cfg_file.write("- dropin:\n")
    dropin_cfg_file.write("    variants:\n")
    for dropin_test in dropin_tests:
        if dropin_test == "README":
            continue
        dropin_cfg_file.write("        - %s:\n" % dropin_test)
        dropin_cfg_file.write("            virt_test_type = %s\n" % t_type)
        dropin_cfg_file.write("            type = dropin\n")
        dropin_cfg_file.write("            start_vm = no\n")
        dropin_cfg_file.write("            dropin_path = %s\n" % dropin_test)
    dropin_cfg_file.close()
    dropin_file_list_2.append(['io-github-autotest-qemu', dropin_cfg_path])

    subtests_cfg = os.path.join(root_dir, 'backends', t_type, 'cfg',
                                'subtests.cfg')
    subtests_file = open(subtests_cfg, 'w')
    subtests_file.write(
        "# Do not edit, auto generated file from subtests config\n")

    subtests_file.write("variants subtest:\n")
    write_subtests_files(first_subtest_file, subtests_file)
    write_subtests_files(specific_file_list, subtests_file, t_type)
    write_subtests_files(shared_file_list, subtests_file)
    write_subtests_files(dropin_file_list, subtests_file)
    write_subtests_files(dropin_file_list_2, subtests_file)
    write_subtests_files(last_subtest_file, subtests_file)

    subtests_file.close()


def create_config_files(test_dir, shared_dir, interactive, step=None,
                        force_update=False):
    def is_file_tracked(fl):
        tracked_result = utils.run("git ls-files %s --error-unmatch" % fl,
                                   ignore_status=True, verbose=False)
        return (tracked_result.exit_status == 0)

    if step is None:
        step = 0
    logging.info("")
    step += 1
    logging.info("%d - Generating config set", step)
    config_file_list = data_dir.SubdirGlobList(os.path.join(test_dir, "cfg"),
                                               "*.cfg",
                                               config_filter)
    config_file_list = [cf for cf in config_file_list if is_file_tracked(cf)]
    config_file_list_shared = glob.glob(os.path.join(shared_dir, "cfg",
                                                     "*.cfg"))

    # Handle overrides of cfg files. Let's say a test provides its own
    # subtest.cfg.sample, this file takes precedence over the shared
    # subtest.cfg.sample. So, yank this file from the cfg file list.

    config_file_list_shared_keep = []
    for cf in config_file_list_shared:
        basename = os.path.basename(cf)
        target = os.path.join(test_dir, "cfg", basename)
        if target not in config_file_list:
            config_file_list_shared_keep.append(cf)

    config_file_list += config_file_list_shared_keep
    for config_file in config_file_list:
        src_file = config_file
        dst_file = os.path.join(test_dir, "cfg", os.path.basename(config_file))
        if not os.path.isfile(dst_file):
            logging.debug("Creating config file %s from sample", dst_file)
            shutil.copyfile(src_file, dst_file)
        else:
            diff_cmd = "diff -Naur %s %s" % (dst_file, src_file)
            diff_result = utils.run(
                diff_cmd, ignore_status=True, verbose=False)
            if diff_result.exit_status != 0:
                logging.info("%s result:\n %s",
                             diff_result.command, diff_result.stdout)
                if interactive:
                    answer = utils.ask("Config file  %s differs from %s."
                                       "Overwrite?" % (dst_file, src_file))
                elif force_update:
                    answer = "y"
                else:
                    answer = "n"

                if answer == "y":
                    logging.debug("Restoring config file %s from sample",
                                  dst_file)
                    shutil.copyfile(src_file, dst_file)
                else:
                    logging.debug("Preserving existing %s file", dst_file)
            else:
                logging.debug("Config file %s exists, not touching", dst_file)


def haz_defcon(datadir, imagesdir, isosdir, tmpdir):
    """
    Compare current types from Defaults, or if default, compare on-disk type
    """
    # Searching through default contexts is very slow.
    # Exploit restorecon -n to find any defaults
    try:
        # First element is list, third tuple item is desired context
        data_type = utils_selinux.diff_defcon(datadir, False)[0][2]
    except IndexError:  # object matches default, get current on-disk context
        data_type = utils_selinux.get_context_of_file(datadir)
    # Extract just the type component
    data_type = utils_selinux.get_type_from_context(data_type)

    try:
        # Do not descend, we want to know the base-dir def. context
        images_type = utils_selinux.diff_defcon(imagesdir, False)[0][2]
    except IndexError:
        images_type = utils_selinux.get_context_of_file(imagesdir)
    images_type = utils_selinux.get_type_from_context(images_type)

    try:
        isos_type = utils_selinux.diff_defcon(isosdir, False)[0][2]
    except IndexError:
        isos_type = utils_selinux.get_context_of_file(isosdir)
    isos_type = utils_selinux.get_type_from_context(isos_type)

    try:
        tmp_type = utils_selinux.diff_defcon(tmpdir, False)[0][2]
    except IndexError:
        tmp_type = utils_selinux.get_context_of_file(tmpdir)
    tmp_type = utils_selinux.get_type_from_context(tmp_type)

    # hard-coded values b/c only four of them and widly-used
    if data_type == 'virt_var_lib_t':
        if images_type == 'virt_image_t':
            if isos_type == 'virt_content_t':
                if tmp_type == 'user_tmp_t':
                    return True  # No changes needed
    return False


def set_defcon(datadir, imagesdir, isosdir, tmpdir):
    """
    Tries to set datadir default contexts returns True if changed
    """
    made_changes = False
    try:
        # Returns list of tuple(pathname, from, to) of context differences
        # between on-disk and defaults.  Only interested in top-level
        # object [0] and the context it would change to [2]
        data_type = utils_selinux.diff_defcon(datadir, False)[0][2]
        # Extrach only the type
        existing_data = utils_selinux.get_type_from_context(data_type)
    except IndexError:
        existing_data = None
    try:
        images_type = utils_selinux.diff_defcon(imagesdir, False)[0][2]
        existing_images = utils_selinux.get_type_from_context(images_type)
    except IndexError:
        existing_images = None
    try:
        isos_type = utils_selinux.diff_defcon(isosdir, False)[0][2]
        existing_isos = utils_selinux.get_type_from_context(isos_type)
    except IndexError:
        existing_isos = None

    try:
        tmp_type = utils_selinux.diff_defcon(tmpdir, False)[0][2]
        existing_tmp = utils_selinux.get_type_from_context(tmp_type)
    except IndexError:
        existing_tmp = None

    # Only print slow info message one time
    could_be_slow = False
    msg = "Defining default contexts, this could take a few seconds..."
    # Changing default contexts is *slow*, avoid it if not necessary
    if existing_data is None or existing_data is not 'virt_var_lib_t':
        # semanage gives errors if don't treat /usr & /usr/local the same
        data_regex = utils_selinux.transmogrify_usr_local(datadir)
        logging.info(msg)
        could_be_slow = True
        # This applies only to datadir symlink, not sub-directories!
        utils_selinux.set_defcon('virt_var_lib_t', data_regex)
        made_changes = True

    if existing_images is None or existing_images is not 'virt_image_t':
        # Applies to imagesdir and everything below
        images_regex = utils_selinux.transmogrify_usr_local(imagesdir)
        images_regex = utils_selinux.transmogrify_sub_dirs(images_regex)
        if not could_be_slow:
            logging.info(msg)
            could_be_slow = True
        utils_selinux.set_defcon('virt_image_t', images_regex)
        made_changes = True

    if existing_isos is None or existing_isos is not 'virt_content_t':
        # Applies to isosdir and everything below
        isos_regex = utils_selinux.transmogrify_usr_local(isosdir)
        isos_regex = utils_selinux.transmogrify_sub_dirs(isos_regex)
        if not could_be_slow:
            logging.info(msg)
            could_be_slow = True
        utils_selinux.set_defcon('virt_content_t', isos_regex)
        made_changes = True

    if existing_tmp is None or existing_tmp is not 'user_tmp_t':
        tmp_regex = utils_selinux.transmogrify_usr_local(tmpdir)
        tmp_regex = utils_selinux.transmogrify_sub_dirs(tmp_regex)
        if not could_be_slow:
            logging.info(msg)
            could_be_slow = True
        utils_selinux.set_defcon('user_tmp_t', tmp_regex)
        made_changes = True

    return made_changes


def verify_selinux(datadir, imagesdir, isosdir, tmpdir,
                   interactive, selinux=False):
    """
    Verify/Set/Warn about SELinux and default file contexts for testing.

    :param datadir: Abs. path to data-directory symlink
    :param imagesdir: Abs. path to data/images directory
    :param isosdir: Abs. path to data/isos directory
    :param tmpdir: Abs. path to virt-test tmp dir
    :param interactive: True if running from console
    :param selinux: Whether setup SELinux contexts for shared/data
    """
    # datadir can be a symlink, but these must not have any
    imagesdir = os.path.realpath(imagesdir)
    isosdir = os.path.realpath(isosdir)
    tmpdir = os.path.realpath(tmpdir)
    needs_relabel = None
    try:
        # Raise SeCmdError if selinux not installed
        if utils_selinux.get_status() == 'enforcing':
            # Check if default contexts are set
            if not haz_defcon(datadir, imagesdir, isosdir, tmpdir):
                if selinux:
                    answer = "y"
                else:
                    if interactive:
                        answer = utils.ask("Setup all undefined default SE"
                                           "Linux contexts for shared/data/?")
                    else:
                        answer = "n"
            else:
                answer = "n"
            if answer.lower() == "y":
                # Assume relabeling is needed if changes made
                needs_relabel = set_defcon(datadir, imagesdir, isosdir, tmpdir)
            # Only relabel if files/dirs don't match default
            labels_ok = utils_selinux.verify_defcon(datadir, False)
            labels_ok &= utils_selinux.verify_defcon(imagesdir, True)
            labels_ok &= utils_selinux.verify_defcon(isosdir, True)
            labels_ok &= utils_selinux.verify_defcon(tmpdir, True)
            if labels_ok:
                needs_relabel = False
            else:
                logging.warning("On-disk SELinux labels do not match defaults")
                needs_relabel = True
        # Disabled or Permissive mode is same result as not installed
        else:
            logging.info("SELinux in permissive or disabled, testing"
                         "in enforcing mode is highly encourraged.")
    except utils_selinux.SemanageError:
        logging.info("Could not set default SELinux contexts. Please")
        logging.info("consider installing the semanage program then ")
        logging.info("verifying and/or running running:")
        # Paths must be transmogrified (changed) into regular expressions
        logging.info("semanage fcontext --add -t virt_var_lib_t '%s'",
                     utils_selinux.transmogrify_usr_local(datadir))
        logging.info("semanage fcontext --add -t virt_image_t '%s'",
                     utils_selinux.transmogrify_usr_local(
                         utils_selinux.transmogrify_sub_dirs(imagesdir)))
        logging.info("semanage fcontext --add -t virt_content_t '%s'",
                     utils_selinux.transmogrify_usr_local(
                         utils_selinux.transmogrify_sub_dirs(isosdir)))
        logging.info("semanage fcontext --add -t user_tmp_t '%s'",
                     utils_selinux.transmogrify_usr_local(
                         utils_selinux.transmogrify_sub_dirs(tmpdir)))
        needs_relabel = None  # Next run will catch if relabeling needed
    except utils_selinux.SelinuxError:  # Catchall SELinux related
        logging.info("SELinux not available, or error in command/setup.")
        logging.info("Please manually verify default file contexts before")
        logging.info("testing with SELinux enabled and enforcing.")
    if needs_relabel:
        if selinux:
            answer = "y"
        else:
            if interactive:
                answer = utils.ask("Relabel from default contexts?")
            else:
                answer = "n"
        if answer.lower() == 'y':
            changes = utils_selinux.apply_defcon(datadir, False)
            changes += utils_selinux.apply_defcon(imagesdir, True)
            changes += utils_selinux.apply_defcon(isosdir, True)
            changes += utils_selinux.apply_defcon(tmpdir, True)
            logging.info("Corrected contexts on %d files/dirs",
                         len(changes))


def bootstrap(test_name, test_dir, base_dir, default_userspace_paths,
              check_modules, online_docs_url, restore_image=False,
              download_image=True, interactive=True, selinux=False,
              verbose=False, update_providers=False,
              guest_os=defaults.DEFAULT_GUEST_OS):
    """
    Common virt test assistant module.

    :param test_name: Test name, such as "qemu".
    :param test_dir: Path with the test directory.
    :param base_dir: Base directory used to hold images and isos.
    :param default_userspace_paths: Important programs for a successful test
            execution.
    :param check_modules: Whether we want to verify if a given list of modules
            is loaded in the system.
    :param online_docs_url: URL to an online documentation system, such as a
            wiki page.
    :param restore_image: Whether to restore the image from the pristine.
    :param interactive: Whether to ask for confirmation.
    :param verbose: Verbose output.
    :param selinux: Whether setup SELinux contexts for shared/data.
    :param update_providers: Whether to update test providers if they are already
            downloaded.
    :param guest_os: Specify the guest image used for bootstrapping. By default
            the JeOS image is used.

    :raise error.CmdError: If JeOS image failed to uncompress
    :raise ValueError: If 7za was not found
    """
    if interactive:
        logging_manager.configure_logging(utils_misc.VirtLoggingConfig(),
                                          verbose=verbose)
    logging.info("%s test config helper", test_name)
    step = 0

    logging.info("")
    step += 1
    logging.info("%d - Updating all test providers", step)
    asset.download_all_test_providers(update_providers)

    logging.info("")
    step += 1
    logging.info("%d - Checking the mandatory programs and headers", step)
    verify_mandatory_programs(test_name)

    logging.info("")
    step += 1
    logging.info("%d - Checking the recommended programs", step)
    verify_recommended_programs(test_name)

    logging.info("")
    step += 1
    logging.info("%d - Verifying directories", step)
    shared_dir = os.path.dirname(data_dir.get_data_dir())
    sub_dir_list = ["images", "isos", "steps_data", "gpg"]
    for sub_dir in sub_dir_list:
        sub_dir_path = os.path.join(base_dir, sub_dir)
        if not os.path.isdir(sub_dir_path):
            logging.debug("Creating %s", sub_dir_path)
            os.makedirs(sub_dir_path)
        else:
            logging.debug("Dir %s exists, not creating",
                          sub_dir_path)

    datadir = data_dir.get_data_dir()
    if test_name == 'libvirt':
        create_config_files(test_dir, shared_dir, interactive, step)
        create_subtests_cfg(test_name)
        create_guest_os_cfg(test_name)
        # Don't bother checking if changes can't be made
        if os.getuid() == 0:
            verify_selinux(datadir,
                           os.path.join(datadir, 'images'),
                           os.path.join(datadir, 'isos'),
                           data_dir.get_tmp_dir(),
                           interactive, selinux)

    # lvsb test doesn't use any shared configs
    elif test_name == 'lvsb':
        create_subtests_cfg(test_name)
        if os.getuid() == 0:
            # Don't bother checking if changes can't be made
            verify_selinux(datadir,
                           os.path.join(datadir, 'images'),
                           os.path.join(datadir, 'isos'),
                           data_dir.get_tmp_dir(),
                           interactive, selinux)
    else:  # Some other test
        create_config_files(test_dir, shared_dir, interactive, step)
        create_subtests_cfg(test_name)
        create_guest_os_cfg(test_name)

    if download_image or restore_image:
        logging.info("")
        step += 2
        logging.info("%s - Verifying (and possibly downloading) guest image",
                     step)
        for os_info in get_guest_os_info_list(test_name, guest_os):
            os_asset = os_info['asset']
            asset.download_asset(os_asset, interactive=interactive,
                                 restore_image=restore_image)

    if check_modules:
        logging.info("")
        step += 1
        logging.info("%d - Checking for modules %s", step,
                     ", ".join(check_modules))
        for module in check_modules:
            if not utils.module_is_loaded(module):
                logging.warning("Module %s is not loaded. You might want to "
                                "load it", module)
            else:
                logging.debug("Module %s loaded", module)

    if online_docs_url:
        logging.info("")
        step += 1
        logging.info("%d - If you wish, take a look at the online docs for "
                     "more info", step)
        logging.info("")
        logging.info(online_docs_url)

########NEW FILE########
__FILENAME__ = build_helper
import logging
import os
import shutil
import tarfile
from autotest.client.shared import git, error
from autotest.client import utils, os_dep
import data_dir


class GitRepoParamHelper(git.GitRepoHelper):

    '''
    Helps to deal with git repos specified in cartersian config files

    This class attempts to make it simple to manage a git repo, by using a
    naming standard that follows this basic syntax:

    <prefix>_name_<suffix>

    <prefix> is always 'git_repo' and <suffix> sets options for this git repo.
    Example for repo named foo:

    git_repo_foo_uri = git://git.foo.org/foo.git
    git_repo_foo_base_uri = /home/user/code/foo
    git_repo_foo_branch = master
    git_repo_foo_lbranch = master
    git_repo_foo_commit = bb5fb8e678aabe286e74c4f2993dc2a9e550b627
    '''

    def __init__(self, params, name, destination_dir):
        '''
        Instantiates a new GitRepoParamHelper
        '''
        self.params = params
        self.name = name
        self.destination_dir = destination_dir
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to this repo

        This method currently does everything that the parent class __init__()
        method does, that is, sets all instance variables needed by other
        methods. That means it's not strictly necessary to call parent's
        __init__().
        '''
        config_prefix = 'git_repo_%s' % self.name
        logging.debug('Parsing parameters for git repo %s, configuration '
                      'prefix is %s' % (self.name, config_prefix))

        self.base_uri = self.params.get('%s_base_uri' % config_prefix)
        if self.base_uri is None:
            logging.debug('Git repo %s base uri is not set' % self.name)
        else:
            logging.debug('Git repo %s base uri: %s' % (self.name,
                                                        self.base_uri))

        self.uri = self.params.get('%s_uri' % config_prefix)
        logging.debug('Git repo %s uri: %s' % (self.name, self.uri))

        self.branch = self.params.get('%s_branch' % config_prefix, 'master')
        logging.debug('Git repo %s branch: %s' % (self.name, self.branch))

        self.lbranch = self.params.get('%s_lbranch' % config_prefix)
        if self.lbranch is None:
            self.lbranch = self.branch
        logging.debug('Git repo %s lbranch: %s' % (self.name, self.lbranch))

        self.commit = self.params.get('%s_commit' % config_prefix)
        if self.commit is None:
            logging.debug('Git repo %s commit is not set' % self.name)
        else:
            logging.debug('Git repo %s commit: %s' % (self.name, self.commit))

        self.tag = self.params.get('%s_tag' % config_prefix)
        if self.tag is None:
            logging.debug('Git repo %s tag is not set' % self.name)
        else:
            logging.debug('Git repo %s tag: %s' % (self.name, self.tag))

        self.key_file = None
        tag_signed = self.params.get('%s_tag_signed' % config_prefix)
        if tag_signed is None:
            logging.warning('Git repo %s tag is not signed' % self.name)
            logging.warning('This means we will not verify if the key was '
                            'made by whomever claims to have made it '
                            '(dangerous)')
        else:
            self.key_file = os.path.join(data_dir.get_data_dir(), 'gpg',
                                         tag_signed)
            if os.path.isfile(self.key_file):
                logging.debug('Git repo %s tag %s will be verified with public '
                              'key file %s', self.name, self.tag, self.key_file)
            else:
                raise error.TestError('GPG public key file %s not found, will '
                                      'not proceed with testing' %
                                      self.key_file)

        self.cmd = os_dep.command('git')

        self.recursive = self.params.get('%s_recursive', 'yes')

    def execute(self):
        super(GitRepoParamHelper, self).execute()

        cwd = os.path.curdir
        os.chdir(self.destination_dir)
        utils.system('git remote add origin %s' % self.uri, ignore_status=True)
        if self.recursive == 'yes':
            utils.system('git submodule init')
            utils.system('git submodule update')

        if self.tag:
            utils.system('git checkout %s' % self.tag)
            if self.key_file is not None:
                try:
                    gnupg_home = os.path.join(data_dir.get_tmp_dir(),
                                              'gnupg')
                    if not os.path.isdir(gnupg_home):
                        os.makedirs(gnupg_home)
                    os.environ['GNUPGHOME'] = gnupg_home
                    utils.system('gpg --import %s' % self.key_file)
                    logging.debug('Verifying if tag is actually signed with '
                                  'GPG key ID %s' % self.key_file)
                    utils.system('git tag -v %s' % self.tag)
                except error.CmdError:
                    raise error.TestError("GPG signature check for git repo "
                                          "%s failed" % self.name)

        # Log the top commit message, good for quick reference
        utils.system('git log -1')

        os.chdir(cwd)


class LocalSourceDirHelper(object):

    '''
    Helper class to deal with source code sitting somewhere in the filesystem
    '''

    def __init__(self, source_dir, destination_dir):
        '''
        :param source_dir:
        :param destination_dir:
        :return: new LocalSourceDirHelper instance
        '''
        self.source = source_dir
        self.destination = destination_dir

    def execute(self):
        '''
        Copies the source directory to the destination directory
        '''
        if os.path.isdir(self.destination):
            shutil.rmtree(self.destination)

        if os.path.isdir(self.source):
            shutil.copytree(self.source, self.destination)


class LocalSourceDirParamHelper(LocalSourceDirHelper):

    '''
    Helps to deal with source dirs specified in cartersian config files

    This class attempts to make it simple to manage a source dir, by using a
    naming standard that follows this basic syntax:

    <prefix>_name_<suffix>

    <prefix> is always 'local_src' and <suffix> sets options for this source
    dir.  Example for source dir named foo:

    local_src_foo_path = /home/user/foo
    '''

    def __init__(self, params, name, destination_dir):
        '''
        Instantiate a new LocalSourceDirParamHelper
        '''
        self.params = params
        self.name = name
        self.destination_dir = destination_dir
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to source dir
        '''
        config_prefix = 'local_src_%s' % self.name
        logging.debug('Parsing parameters for local source %s, configuration '
                      'prefix is %s' % (self.name, config_prefix))

        self.path = self.params.get('%s_path' % config_prefix)
        logging.debug('Local source directory %s path: %s' % (self.name,
                                                              self.path))
        self.source = self.path
        self.destination = self.destination_dir


class LocalTarHelper(object):

    '''
    Helper class to deal with source code in a local tarball
    '''

    def __init__(self, source, destination_dir):
        self.source = source
        self.destination = destination_dir

    def extract(self):
        '''
        Extracts the tarball into the destination directory
        '''
        if os.path.isdir(self.destination):
            shutil.rmtree(self.destination)

        if os.path.isfile(self.source) and tarfile.is_tarfile(self.source):

            name = os.path.basename(self.destination)
            temp_dir = os.path.join(os.path.dirname(self.destination),
                                    '%s.tmp' % name)
            logging.debug('Temporary directory for extracting tarball is %s' %
                          temp_dir)

            if not os.path.isdir(temp_dir):
                os.makedirs(temp_dir)

            tarball = tarfile.open(self.source)
            tarball.extractall(temp_dir)

            #
            # If there's a directory at the toplevel of the tarfile, assume
            # it's the root for the contents, usually source code
            #
            tarball_info = tarball.members[0]
            if tarball_info.isdir():
                content_path = os.path.join(temp_dir,
                                            tarball_info.name)
            else:
                content_path = temp_dir

            #
            # Now move the content directory to the final destination
            #
            shutil.move(content_path, self.destination)

        else:
            raise OSError("%s is not a file or tar file" % self.source)

    def execute(self):
        '''
        Executes all action this helper is supposed to perform

        This is the main entry point method for this class, and all other
        helper classes.
        '''
        self.extract()


class LocalTarParamHelper(LocalTarHelper):

    '''
    Helps to deal with source tarballs specified in cartersian config files

    This class attempts to make it simple to manage a tarball with source code,
    by using a  naming standard that follows this basic syntax:

    <prefix>_name_<suffix>

    <prefix> is always 'local_tar' and <suffix> sets options for this source
    tarball.  Example for source tarball named foo:

    local_tar_foo_path = /tmp/foo-1.0.tar.gz
    '''

    def __init__(self, params, name, destination_dir):
        '''
        Instantiates a new LocalTarParamHelper
        '''
        self.params = params
        self.name = name
        self.destination_dir = destination_dir
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to this local tar helper
        '''
        config_prefix = 'local_tar_%s' % self.name
        logging.debug('Parsing parameters for local tar %s, configuration '
                      'prefix is %s' % (self.name, config_prefix))

        self.path = self.params.get('%s_path' % config_prefix)
        logging.debug('Local source tar %s path: %s' % (self.name,
                                                        self.path))
        self.source = self.path
        self.destination = self.destination_dir


class RemoteTarHelper(LocalTarHelper):

    '''
    Helper that fetches a tarball and extracts it locally
    '''

    def __init__(self, source_uri, destination_dir):
        self.source = source_uri
        self.destination = destination_dir

    def execute(self):
        '''
        Executes all action this helper class is supposed to perform

        This is the main entry point method for this class, and all other
        helper classes.

        This implementation fetches the remote tar file and then extracts
        it using the functionality present in the parent class.
        '''
        name = os.path.basename(self.source)
        base_dest = os.path.dirname(self.destination_dir)
        dest = os.path.join(base_dest, name)
        utils.get_file(self.source, dest)
        self.source = dest
        self.extract()


class RemoteTarParamHelper(RemoteTarHelper):

    '''
    Helps to deal with remote source tarballs specified in cartersian config

    This class attempts to make it simple to manage a tarball with source code,
    by using a  naming standard that follows this basic syntax:

    <prefix>_name_<suffix>

    <prefix> is always 'local_tar' and <suffix> sets options for this source
    tarball.  Example for source tarball named foo:

    remote_tar_foo_uri = http://foo.org/foo-1.0.tar.gz
    '''

    def __init__(self, params, name, destination_dir):
        '''
        Instantiates a new RemoteTarParamHelper instance
        '''
        self.params = params
        self.name = name
        self.destination_dir = destination_dir
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to this remote tar helper
        '''
        config_prefix = 'remote_tar_%s' % self.name
        logging.debug('Parsing parameters for remote tar %s, configuration '
                      'prefix is %s' % (self.name, config_prefix))

        self.uri = self.params.get('%s_uri' % config_prefix)
        logging.debug('Remote source tar %s uri: %s' % (self.name,
                                                        self.uri))
        self.source = self.uri
        self.destination = self.destination_dir


class PatchHelper(object):

    '''
    Helper that encapsulates the patching of source code with patch files
    '''

    def __init__(self, source_dir, patches):
        '''
        Initializes a new PatchHelper
        '''
        self.source_dir = source_dir
        self.patches = patches

    def download(self):
        '''
        Copies patch files from remote locations to the source directory
        '''
        for patch in self.patches:
            utils.get_file(patch, os.path.join(self.source_dir,
                                               os.path.basename(patch)))

    def patch(self):
        '''
        Patches the source dir with all patch files
        '''
        os.chdir(self.source_dir)
        for patch in self.patches:
            utils.system('patch -p1 < %s' % os.path.basename(patch))

    def execute(self):
        '''
        Performs all steps necessary to download patches and apply them
        '''
        self.download()
        self.patch()


class PatchParamHelper(PatchHelper):

    '''
    Helps to deal with patches specified in cartersian config files

    This class attempts to make it simple to patch source coude, by using a
    naming standard that follows this basic syntax:

    [<git_repo>|<local_src>|<local_tar>|<remote_tar>]_<name>_patches

    <prefix> is either a 'local_src' or 'git_repo', that, together with <name>
    specify a directory containing source code to receive the patches. That is,
    for source code coming from git repo foo, patches would be specified as:

    git_repo_foo_patches = ['http://foo/bar.patch', 'http://foo/baz.patch']

    And for for patches to be applied on local source code named also foo:

    local_src_foo_patches = ['http://foo/bar.patch', 'http://foo/baz.patch']
    '''

    def __init__(self, params, prefix, source_dir):
        '''
        Initializes a new PatchParamHelper instance
        '''
        self.params = params
        self.prefix = prefix
        self.source_dir = source_dir
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to this set of patches

        This method currently does everything that the parent class __init__()
        method does, that is, sets all instance variables needed by other
        methods. That means it's not strictly necessary to call parent's
        __init__().
        '''
        logging.debug('Parsing patch parameters for prefix %s' % self.prefix)
        patches_param_key = '%s_patches' % self.prefix

        self.patches_str = self.params.get(patches_param_key, '[]')
        logging.debug('Patches config for prefix %s: %s' % (self.prefix,
                                                            self.patches_str))

        self.patches = eval(self.patches_str)
        logging.debug('Patches for prefix %s: %s' % (self.prefix,
                                                     ", ".join(self.patches)))


class GnuSourceBuildInvalidSource(Exception):

    '''
    Exception raised when build source dir/file is not valid
    '''
    pass


class SourceBuildFailed(Exception):

    '''
    Exception raised when building with parallel jobs fails

    This serves as feedback for code using
    :class:`virttest.build_helper.BuildHelper`.
    '''
    pass


class SourceBuildParallelFailed(Exception):

    '''
    Exception raised when building with parallel jobs fails

    This serves as feedback for code using
    :class:`virttest.build_helper.BuildHelper`.
    '''
    pass


class GnuSourceBuildHelper(object):

    '''
    Handles software installation of GNU-like source code

    This basically means that the build will go though the classic GNU
    autotools steps: ./configure, make, make install
    '''

    def __init__(self, source, build_dir, prefix,
                 configure_options=[]):
        '''
        :type source: string
        :param source: source directory or tarball
        :type prefix: string
        :param prefix: installation prefix
        :type build_dir: string
        :param build_dir: temporary directory used for building the source code
        :type configure_options: list
        :param configure_options: options to pass to configure
        :throws: GnuSourceBuildInvalidSource
        '''
        self.source = source
        self.build_dir = build_dir
        self.prefix = prefix
        self.configure_options = configure_options
        self.install_debug_info = True
        self.include_pkg_config_path()

    def include_pkg_config_path(self):
        '''
        Adds the current prefix to the list of paths that pkg-config searches

        This is currently not optional as there is no observed adverse side
        effects of enabling this. As the "prefix" is usually only valid during
        a test run, we believe that having other pkg-config files (``*.pc``) in
        either ``<prefix>/share/pkgconfig`` or ``<prefix>/lib/pkgconfig`` is
        exactly for the purpose of using them.

        :return: None
        '''
        env_var = 'PKG_CONFIG_PATH'

        include_paths = [os.path.join(self.prefix, 'share', 'pkgconfig'),
                         os.path.join(self.prefix, 'lib', 'pkgconfig')]

        if os.environ.has_key(env_var):
            paths = os.environ[env_var].split(':')
            for include_path in include_paths:
                if include_path not in paths:
                    paths.append(include_path)
            os.environ[env_var] = ':'.join(paths)
        else:
            os.environ[env_var] = ':'.join(include_paths)

        logging.debug('PKG_CONFIG_PATH is: %s' % os.environ['PKG_CONFIG_PATH'])

    def get_configure_path(self):
        '''
        Checks if 'configure' exists, if not, return 'autogen.sh' as a fallback
        '''
        configure_path = os.path.abspath(os.path.join(self.source,
                                                      "configure"))
        autogen_path = os.path.abspath(os.path.join(self.source,
                                                    "autogen.sh"))
        if os.path.exists(configure_path):
            return configure_path
        elif os.path.exists(autogen_path):
            return autogen_path
        else:
            raise GnuSourceBuildInvalidSource(
                'configure script does not exist')

    def get_available_configure_options(self):
        '''
        Return the list of available options of a GNU like configure script

        This will run the "configure" script at the source directory

        :return: list of options accepted by configure script
        '''
        help_raw = utils.system_output('%s --help' % self.get_configure_path(),
                                       ignore_status=True)
        help_output = help_raw.split("\n")
        option_list = []
        for line in help_output:
            cleaned_line = line.lstrip()
            if cleaned_line.startswith("--"):
                option = cleaned_line.split()[0]
                option = option.split("=")[0]
                option_list.append(option)

        return option_list

    def enable_debug_symbols(self):
        '''
        Enables option that leaves debug symbols on compiled software

        This makes debugging a lot easier.
        '''
        enable_debug_option = "--disable-strip"
        if enable_debug_option in self.get_available_configure_options():
            self.configure_options.append(enable_debug_option)
            logging.debug('Enabling debug symbols with option: %s' %
                          enable_debug_option)

    def get_configure_command(self):
        '''
        Formats configure script with all options set

        :return: string with all configure options, including prefix
        '''
        prefix_option = "--prefix=%s" % self.prefix
        options = self.configure_options
        options.append(prefix_option)
        return "%s %s" % (self.get_configure_path(),
                          " ".join(options))

    def configure(self):
        '''
        Runs the "configure" script passing appropriate command line options
        '''
        configure_command = self.get_configure_command()
        logging.info('Running configure on build dir')
        os.chdir(self.build_dir)
        utils.system(configure_command)

    def make_parallel(self):
        '''
        Runs "make" using the correct number of parallel jobs
        '''
        parallel_make_jobs = utils.count_cpus()
        make_command = "make -j %s" % parallel_make_jobs
        logging.info("Running parallel make on build dir")
        os.chdir(self.build_dir)
        utils.system(make_command)

    def make_non_parallel(self):
        '''
        Runs "make", using a single job
        '''
        os.chdir(self.build_dir)
        utils.system("make")

    def make_clean(self):
        '''
        Runs "make clean"
        '''
        os.chdir(self.build_dir)
        utils.system("make clean")

    def make(self, failure_feedback=True):
        '''
        Runs a parallel make, falling back to a single job in failure

        :param failure_feedback: return information on build failure by raising
                                 the appropriate exceptions
        :raise: SourceBuildParallelFailed if parallel build fails, or
                SourceBuildFailed if single job build fails
        '''
        try:
            self.make_parallel()
        except error.CmdError:
            try:
                self.make_clean()
                self.make_non_parallel()
            except error.CmdError:
                if failure_feedback:
                    raise SourceBuildFailed
            if failure_feedback:
                raise SourceBuildParallelFailed

    def make_install(self):
        '''
        Runs "make install"
        '''
        os.chdir(self.build_dir)
        utils.system("make install")

    install = make_install

    def execute(self):
        '''
        Runs appropriate steps for *building* this source code tree
        '''
        if self.install_debug_info:
            self.enable_debug_symbols()
        self.configure()
        self.make()


class LinuxKernelBuildHelper(object):

    '''
    Handles Building Linux Kernel.
    '''

    def __init__(self, params, prefix, source):
        '''
        :type params: dict
        :param params: dictionary containing the test parameters
        :type source: string
        :param source: source directory or tarball
        :type prefix: string
        :param prefix: installation prefix
        '''
        self.params = params
        self.prefix = prefix
        self.source = source
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to guest kernel
        '''
        configure_opt_key = '%s_config' % self.prefix
        self.config = self.params.get(configure_opt_key, '')

        build_image_key = '%s_build_image' % self.prefix
        self.build_image = self.params.get(build_image_key,
                                           'arch/x86/boot/bzImage')

        build_target_key = '%s_build_target' % self.prefix
        self.build_target = self.params.get(build_target_key, 'bzImage')

        kernel_path_key = '%s_kernel_path' % self.prefix
        image_dir = os.path.join(data_dir.get_data_dir(), 'images')
        default_kernel_path = os.path.join(image_dir,
                                           self.build_target)
        self.kernel_path = self.params.get(kernel_path_key,
                                           default_kernel_path)

        logging.info('Parsing Linux kernel build parameters for %s',
                     self.prefix)

    def make_guest_kernel(self):
        '''
        Runs "make", using a single job
        '''
        os.chdir(self.source)
        logging.info("Building guest kernel")
        logging.debug("Kernel config is %s" % self.config)
        utils.get_file(self.config, '.config')

        # FIXME currently no support for builddir
        # run old config
        utils.system('yes "" | make oldconfig > /dev/null')
        parallel_make_jobs = utils.count_cpus()
        make_command = "make -j %s %s" % (
            parallel_make_jobs, self.build_target)
        logging.info("Running parallel make on src dir")
        utils.system(make_command)

    def make_clean(self):
        '''
        Runs "make clean"
        '''
        os.chdir(self.source)
        utils.system("make clean")

    def make(self, failure_feedback=True):
        '''
        Runs a parallel make

        :param failure_feedback: return information on build failure by raising
                                 the appropriate exceptions
        :raise: SourceBuildParallelFailed if parallel build fails, or
        '''
        try:
            self.make_clean()
            self.make_guest_kernel()
        except error.CmdError:
            if failure_feedback:
                raise SourceBuildParallelFailed

    def cp_linux_kernel(self):
        '''
        Copying Linux kernel to target path
        '''
        os.chdir(self.source)
        utils.force_copy(self.build_image, self.kernel_path)

    install = cp_linux_kernel

    def execute(self):
        '''
        Runs appropriate steps for *building* this source code tree
        '''
        self.make()


class GnuSourceBuildParamHelper(GnuSourceBuildHelper):

    '''
    Helps to deal with gnu_autotools build helper in cartersian config files

    This class attempts to make it simple to build source coude, by using a
    naming standard that follows this basic syntax:

    [<git_repo>|<local_src>]_<name>_<option> = value

    To pass extra options to the configure script, while building foo from a
    git repo, set the following variable:

    git_repo_foo_configure_options = --enable-feature
    '''

    def __init__(self, params, name, destination_dir, install_prefix):
        '''
        Instantiates a new GnuSourceBuildParamHelper
        '''
        self.params = params
        self.name = name
        self.destination_dir = destination_dir
        self.install_prefix = install_prefix
        self._parse_params()

    def _parse_params(self):
        '''
        Parses the params items for entries related to source directory

        This method currently does everything that the parent class __init__()
        method does, that is, sets all instance variables needed by other
        methods. That means it's not strictly necessary to call parent's
        __init__().
        '''
        logging.debug('Parsing gnu_autotools build parameters for %s' %
                      self.name)

        configure_opt_key = '%s_configure_options' % self.name
        configure_options = self.params.get(configure_opt_key, '').split()
        logging.debug('Configure options for %s: %s' % (self.name,
                                                        configure_options))

        self.source = self.destination_dir
        self.build_dir = self.destination_dir
        self.prefix = self.install_prefix
        self.configure_options = configure_options
        self.include_pkg_config_path()

        # Support the install_debug_info feature, that automatically
        # adds/keeps debug information on generated libraries/binaries
        install_debug_info_cfg = self.params.get("install_debug_info", "yes")
        self.install_debug_info = install_debug_info_cfg != "no"

########NEW FILE########
__FILENAME__ = cartesian_config
#!/usr/bin/python

"""
Cartesian configuration format file parser.

Filter syntax:

* ``,`` means ``OR``
* ``..`` means ``AND``
* ``.`` means ``IMMEDIATELY-FOLLOWED-BY``
* ``(xx=yy)`` where ``xx=VARIANT_NAME`` and ``yy=VARIANT_VALUE``

Example:

::

     qcow2..(guest_os=Fedora).14, RHEL.6..raw..boot, smp2..qcow2..migrate..ide

means match all dicts whose names have:

::

    (qcow2 AND ((guest_os=Fedora) IMMEDIATELY-FOLLOWED-BY 14)) OR
    ((RHEL IMMEDIATELY-FOLLOWED-BY 6) AND raw AND boot) OR
    (smp2 AND qcow2 AND migrate AND ide)

Note:

* ``qcow2..Fedora.14`` is equivalent to ``Fedora.14..qcow2``.
* ``qcow2..Fedora.14`` is not equivalent to ``qcow2..14.Fedora``.
* ``ide, scsi`` is equivalent to ``scsi, ide``.

Filters can be used in 3 ways:

::

    only <filter>
    no <filter>
    <filter>:

The last one starts a conditional block.

Formal definition: Regexp come from `python <http://docs.python.org/2/library/re.html>`__.
They're not deterministic, but more readable for people. Spaces between
terminals and nonterminals are only for better reading of definitions.

The base of the definitions come verbatim as follows:


::

    E = {\\n, #, :, "-", =, +=, <=, ?=, ?+=, ?<=, !, < , del, @, variants, include, only, no, name, value}

    N = {S, DEL, FILTER, FILTER_NAME, FILTER_GROUP, PN_FILTER_GROUP, STAT, VARIANT, VAR-TYPE, VAR-NAME, VAR-NAME-F, VAR, COMMENT, TEXT, DEPS, DEPS-NAME-F, META-DATA, IDENTIFIER}``


    I = I^n | n in N              // indentation from start of line
                                  // where n is indentation length.
    I = I^n+x | n,x in N          // indentation with shift

    start symbol = S
    end symbol = eps

    S -> I^0+x STATV | eps

    I^n    STATV
    I^n    STATV

    I^n STATV -> I^n STATV \\n I^n STATV | I^n STAT | I^n variants VARIANT
    I^n STAT -> I^n STAT \\n I^n STAT | I^n COMMENT | I^n include INC
    I^n STAT -> I^n del DEL | I^n FILTER

    DEL -> name \\n

    I^n STAT -> I^n name = VALUE | I^n name += VALUE | I^n name <= VALUE
    I^n STAT -> I^n name ?= VALUE | I^n name ?+= VALUE | I^n name ?<= VALUE

    VALUE -> TEXT \\n | 'TEXT' \\n | "TEXT" \\n

    COMMENT_BLOCK -> #TEXT | //TEXT
    COMMENT ->  COMMENT_BLOCK\\n
    COMMENT ->  COMMENT_BLOCK\\n

    TEXT = [^\\n] TEXT            //python format regexp

    I^n    variants VAR #comments:             add possibility for comment
    I^n+x       VAR-NAME: DEPS
    I^n+x+x2        STATV
    I^n         VAR-NAME:

    IDENTIFIER -> [A-Za-z0-9][A-Za-z0-9_-]*

    VARIANT -> VAR COMMENT_BLOCK\\n I^n+x VAR-NAME
    VAR -> VAR-TYPE: | VAR-TYPE META-DATA: | :         // Named | unnamed variant

    VAR-TYPE -> IDENTIFIER

    variants _name_ [xxx] [zzz=yyy] [uuu]:

    META-DATA -> [IDENTIFIER] | [IDENTIFIER=TEXT] | META-DATA META-DATA

    I^n VAR-NAME -> I^n VAR-NAME \\n I^n VAR-NAME | I^n VAR-NAME-N \\n I^n+x STATV
    VAR-NAME-N -> - @VAR-NAME-F: DEPS | - VAR-NAME-F: DEPS
    VAR-NAME-F -> [a-zA-Z0-9\\._-]+                  // Python regexp

    DEPS -> DEPS-NAME-F | DEPS-NAME-F,DEPS
    DEPS-NAME-F -> [a-zA-Z0-9\\._- ]+                // Python regexp

    INC -> name \\n


    FILTER_GROUP: STAT
        STAT

    I^n STAT -> I^n PN_FILTER_GROUP | I^n ! PN_FILTER_GROUP

    PN_FILTER_GROUP -> FILTER_GROUP: \\n I^n+x STAT
    PN_FILTER_GROUP -> FILTER_GROUP: STAT \\n I^n+x STAT

    only FILTER_GROUP
    no FILTER_GROUP

    FILTER -> only FILTER_GROUP \\n | no FILTER_GROUP \\n

    FILTER_GROUP -> FILTER_NAME
    FILTER_GROUP -> FILTER_GROUP..FILTER_GROUP
    FILTER_GROUP -> FILTER_GROUP,FILTER_GROUP

    FILTER_NAME -> FILTER_NAME.FILTER_NAME
    FILTER_NAME -> VAR-NAME-F | (VAR-NAME-F=VAR-NAME-F)

:copyright: Red Hat 2008-2013
"""

import os
import collections
import optparse
import logging
import re
import string
import sys

_reserved_keys = set(("name", "shortname", "dep"))

num_failed_cases = 5


class ParserError(Exception):

    def __init__(self, msg, line=None, filename=None, linenum=None):
        Exception.__init__(self)
        self.msg = msg
        self.line = line
        self.filename = filename
        self.linenum = linenum

    def __str__(self):
        if self.line:
            return "%s: %r (%s:%s)" % (self.msg, self.line,
                                       self.filename, self.linenum)
        else:
            return "%s (%s:%s)" % (self.msg, self.filename, self.linenum)


class LexerError(ParserError):
    pass


class MissingIncludeError(Exception):

    def __init__(self, line, filename, linenum):
        Exception.__init__(self)
        self.line = line
        self.filename = filename
        self.linenum = linenum

    def __str__(self):
        return ("%r (%s:%s): file does not exist or it's not a regular "
                "file" % (self.line, self.filename, self.linenum))


if sys.version_info[0] == 2 and sys.version_info[1] < 6:
    def enum(iterator, start_pos=0):
        for i in iterator:
            yield start_pos, i
            start_pos += 1
else:
    enum = enumerate


def _match_adjacent(block, ctx, ctx_set):
    """
    It try to match as many blocks as possible from context.

    :return: Count of matched blocks.
    """
    if block[0] not in ctx_set:
        return 0
    if len(block) == 1:
        return 1                          # First match and length is 1.
    if block[1] not in ctx_set:
        return int(ctx[-1] == block[0])   # Check match with last from ctx.
    k = 0
    i = ctx.index(block[0])
    while i < len(ctx):                   # Try to  match all of blocks.
        if k > 0 and ctx[i] != block[k]:  # Block not match
            i -= k - 1
            k = 0                         # Start from first block in next ctx.
        if ctx[i] == block[k]:
            k += 1
            if k >= len(block):           # match all of blocks
                break
            if block[k] not in ctx_set:   # block in not in whole ctx.
                break
        i += 1
    return k


def _might_match_adjacent(block, ctx, ctx_set, descendant_labels):
    matched = _match_adjacent(block, ctx, ctx_set)
    for elem in block[matched:]:        # Try to find rest of blocks in subtree
        if elem not in descendant_labels:
            # print "Can't match %s, ctx %s" % (block, ctx)
            return False
    return True


# Filter must inherit from object (otherwise type() won't work)
class Filter(object):
    __slots__ = ["filter"]

    def __init__(self, lfilter):
        self.filter = lfilter
        # print self.filter

    def match(self, ctx, ctx_set):
        for word in self.filter:  # Go through ,
            for block in word:    # Go through ..
                if _match_adjacent(block, ctx, ctx_set) != len(block):
                    break
            else:
                # print "Filter pass: %s ctx: %s" % (self.filter, ctx)
                return True       # All match
        return False

    def might_match(self, ctx, ctx_set, descendant_labels):
        # There is some posibility to match in children blocks.
        for word in self.filter:
            for block in word:
                if not _might_match_adjacent(block, ctx, ctx_set,
                                             descendant_labels):
                    break
            else:
                return True
        # print "Filter not pass: %s ctx: %s" % (self.filter, ctx)
        return False


class NoOnlyFilter(Filter):
    __slots__ = ("line")

    def __init__(self, lfilter, line):
        super(NoOnlyFilter, self).__init__(lfilter)
        self.line = line

    def __eq__(self, o):
        if isinstance(o, self.__class__):
            if self.filter == o.filter:
                return True

        return False


class OnlyFilter(NoOnlyFilter):
    # pylint: disable=W0613

    def is_irrelevant(self, ctx, ctx_set, descendant_labels):
        # Matched in this tree.
        return self.match(ctx, ctx_set)

    def requires_action(self, ctx, ctx_set, descendant_labels):
        # Impossible to match in this tree.
        return not self.might_match(ctx, ctx_set, descendant_labels)

    def might_pass(self, failed_ctx, failed_ctx_set, ctx, ctx_set,
                   descendant_labels):
        for word in self.filter:
            for block in word:
                if (_match_adjacent(block, ctx, ctx_set) >
                        _match_adjacent(block, failed_ctx, failed_ctx_set)):
                    return self.might_match(ctx, ctx_set, descendant_labels)
        return False

    def __str__(self):
        return "Only %s" % (self.filter)

    def __repr__(self):
        return "Only %s" % (self.filter)


class NoFilter(NoOnlyFilter):

    def is_irrelevant(self, ctx, ctx_set, descendant_labels):
        return not self.might_match(ctx, ctx_set, descendant_labels)

    # pylint: disable=W0613
    def requires_action(self, ctx, ctx_set, descendant_labels):
        return self.match(ctx, ctx_set)

    # pylint: disable=W0613
    def might_pass(self, failed_ctx, failed_ctx_set, ctx, ctx_set,
                   descendant_labels):
        for word in self.filter:
            for block in word:
                if (_match_adjacent(block, ctx, ctx_set) <
                        _match_adjacent(block, failed_ctx, failed_ctx_set)):
                    return not self.match(ctx, ctx_set)
        return False

    def __str__(self):
        return "No %s" % (self.filter)

    def __repr__(self):
        return "No %s" % (self.filter)


class BlockFilter(object):
    __slots__ = ["blocked"]

    def __init__(self, blocked):
        self.blocked = blocked

    def apply_to_dict(self, d):
        pass


class Condition(NoFilter):
    __slots__ = ["content"]

    # pylint: disable=W0231
    def __init__(self, lfilter, line):
        super(Condition, self).__init__(lfilter, line)
        self.content = []

    def __str__(self):
        return "Condition %s:%s" % (self.filter, self.content)

    def __repr__(self):
        return "Condition %s:%s" % (self.filter, self.content)


class NegativeCondition(OnlyFilter):
    __slots__ = ["content"]

    # pylint: disable=W0231
    def __init__(self, lfilter, line):
        super(NegativeCondition, self).__init__(lfilter, line)
        self.content = []

    def __str__(self):
        return "NotCond %s:%s" % (self.filter, self.content)

    def __repr__(self):
        return "NotCond %s:%s" % (self.filter, self.content)


class StrReader(object):

    """
    Preprocess an input string for easy reading.
    """

    def __init__(self, s):
        """
        Initialize the reader.

        :param s: The string to parse.
        """
        self.filename = "<string>"
        self._lines = []
        self._line_index = 0
        self._stored_line = None
        for linenum, line in enumerate(s.splitlines()):
            line = line.rstrip().expandtabs()
            stripped_line = line.lstrip()
            indent = len(line) - len(stripped_line)
            if (not stripped_line
                or stripped_line.startswith("#")
                    or stripped_line.startswith("//")):
                continue
            self._lines.append((stripped_line, indent, linenum + 1))

    def get_next_line(self, prev_indent):
        """
        Get the next line in the current block.

        :param prev_indent: The indentation level of the previous block.
        :return: (line, indent, linenum), where indent is the line's
            indentation level.  If no line is available, (None, -1, -1) is
            returned.
        """
        if self._stored_line:
            ret = self._stored_line
            self._stored_line = None
            return ret
        if self._line_index >= len(self._lines):
            return None, -1, -1
        line, indent, linenum = self._lines[self._line_index]
        if indent <= prev_indent:
            return None, indent, linenum
        self._line_index += 1
        return line, indent, linenum

    def set_next_line(self, line, indent, linenum):
        """
        Make the next call to get_next_line() return the given line instead of
        the real next line.
        """
        line = line.strip()
        if line:
            self._stored_line = line, indent, linenum


class FileReader(StrReader):

    """
    Preprocess an input file for easy reading.
    """

    def __init__(self, filename):
        """
        Initialize the reader.

        :parse filename: The name of the input file.
        """
        StrReader.__init__(self, open(filename).read())
        self.filename = filename


class Label(object):
    __slots__ = ["name", "var_name", "long_name", "hash_val", "hash_var"]

    def __init__(self, name, next_name=None):
        if next_name is None:
            self.name = name
            self.var_name = None
        else:
            self.name = next_name
            self.var_name = name

        if self.var_name is None:
            self.long_name = "%s" % (self.name)
        else:
            self.long_name = "(%s=%s)" % (self.var_name, self.name)

        self.hash_val = self.hash_name()
        self.hash_var = None
        if self.var_name:
            self.hash_var = self.hash_variant()

    def __str__(self):
        return self.long_name

    def __repr__(self):
        return self.long_name

    def __eq__(self, o):
        """
        The comparison is asymmetric due to optimization.
        """
        if o.var_name:
            if self.long_name == o.long_name:
                return True
        else:
            if self.name == o.name:
                return True
        return False

    def __ne__(self, o):
        """
        The comparison is asymmetric due to optimization.
        """
        if o.var_name:
            if self.long_name != o.long_name:
                return True
        else:
            if self.name != o.name:
                return True
        return False

    def __hash__(self):
        return self.hash_val

    def hash_name(self):
        return sum([i + 1 * ord(x) for i, x in enumerate(self.name)])

    def hash_variant(self):
        return sum([i + 1 * ord(x) for i, x in enumerate(str(self))])


class Node(object):
    __slots__ = ["var_name", "name", "filename", "dep", "content", "children",
                 "labels", "append_to_shortname", "failed_cases", "default",
                 "q_dict"]

    def __init__(self):
        self.var_name = []
        self.name = []
        self.filename = ""
        self.dep = []
        self.content = []
        self.children = []
        self.labels = set()
        self.append_to_shortname = False
        self.failed_cases = collections.deque()
        self.default = False

    def dump(self, indent, recurse=False):
        print("%s%s" % (" " * indent, self.name))
        print("%s%s" % (" " * indent, self.var_name))
        print("%s%s" % (" " * indent, self))
        print("%s%s" % (" " * indent, self.content))
        print("%s%s" % (" " * indent, self.failed_cases))
        if recurse:
            for child in self.children:
                child.dump(indent + 3, recurse)


match_subtitute = re.compile("\$\{(.+?)\}")


def _subtitution(value, d):
    """
    Only optimization string Template subtitute is quite expensive operation.

    :param value: String where could be $string for subtitution.
    :param d: Dictionary from which should be value subtituted to value.

    :return: Substituted string
    """
    if "$" in value:
        start = 0
        st = ""
        try:
            match = match_subtitute.search(value, start)
            while match:
                val = eval(match.group(1), None, d)
                st += value[start:match.start()] + str(val)
                start = match.end()
                match = match_subtitute.search(value, start)
        except:
            pass
        st += value[start:len(value)]
        return st
    else:
        return value


class Token(object):
    __slots__ = []
    identifier = ""

    def __str__(self):
        return self.identifier

    def __repr__(self):
        return "'%s'" % self.identifier

    def __ne__(self, o):
        """
        The comparison is asymmetric due to optimization.
        """
        if o.identifier != self.identifier:
            return True
        return False


class LIndent(Token):
    __slots__ = ["length"]
    identifier = "indent"

    def __init__(self, length):
        self.length = length

    def __str__(self):
        return "%s %s" % (self.identifier, self.length)

    def __repr__(self):
        return "%s %s" % (self.identifier, self.length)


class LEndL(Token):
    __slots__ = []
    identifier = "endl"


class LEndBlock(LIndent):
    __slots__ = []
    pass


class LIdentifier(str):
    __slots__ = []
    identifier = "Identifier re([A-Za-z0-9][A-Za-z0-9_-]*)"

    def __str__(self):
        return super(LIdentifier, self).__str__()

    def __repr__(self):
        return "'%s'" % self

    def checkChar(self, chars):
        for t in self:
            if not (t in chars):
                raise ParserError("Wrong char %s in %s" % (t, self))
        return self

    def checkAlpha(self):
        """
        Check if string contain only chars
        """
        if not self.isalpha():
            raise ParserError("Some of chars is not alpha in %s" % (self))
        return self

    def checkNumbers(self):
        """
        Check if string contain only chars
        """
        if not self.isdigit():
            raise ParserError("Some of chars is not digit in %s" % (self))
        return self

    def checkCharAlpha(self, chars):
        """
        Check if string contain only chars
        """
        for t in self:
            if not (t in chars or t.isalpha()):
                raise ParserError("Char %s is not alpha or one of special"
                                  "chars [%s] in %s" % (t, chars, self))
        return self

    def checkCharAlphaNum(self, chars):
        """
        Check if string contain only chars
        """
        for t in self:
            if not (t in chars or t.isalnum()):
                raise ParserError("Char %s is not alphanum or one of special"
                                  "chars [%s] in %s" % (t, chars, self))
        return self

    def checkCharNumeric(self, chars):
        """
        Check if string contain only chars
        """
        for t in self:
            if not (t in chars or t.isdigit()):
                raise ParserError("Char %s is not digit or one of special"
                                  "chars [%s] in %s" % (t, chars, self))
        return self


class LWhite(LIdentifier):
    __slots__ = []
    identifier = "WhiteSpace re(\\s)"


class LString(LIdentifier):
    __slots__ = []
    identifier = "String re(.+)"


class LColon(Token):
    __slots__ = []
    identifier = ":"


class LVariants(Token):
    __slots__ = []
    identifier = "variants"


class LDot(Token):
    __slots__ = []
    identifier = "."


class LVariant(Token):
    __slots__ = []
    identifier = "-"


class LDefault(Token):
    __slots__ = []
    identifier = "@"


class LOnly(Token):
    __slots__ = []
    identifier = "only"


class LNo(Token):
    __slots__ = []
    identifier = "no"


class LCond(Token):
    __slots__ = []
    identifier = ""


class LNotCond(Token):
    __slots__ = []
    identifier = "!"


class LOr(Token):
    __slots__ = []
    identifier = ","


class LAnd(Token):
    __slots__ = []
    identifier = ".."


class LCoc(Token):
    __slots__ = []
    identifier = "."


class LComa(Token):
    __slots__ = []
    identifier = ","


class LLBracket(Token):
    __slots__ = []
    identifier = "["


class LRBracket(Token):
    __slots__ = []
    identifier = "]"


class LLRBracket(Token):
    __slots__ = []
    identifier = "("


class LRRBracket(Token):
    __slots__ = []
    identifier = ")"


class LRegExpStart(Token):
    __slots__ = []
    identifier = "${"


class LRegExpStop(Token):
    __slots__ = []
    identifier = "}"


class LInclude(Token):
    __slots__ = []
    identifier = "include"


class LOperators(Token):
    __slots__ = ["name", "value"]
    identifier = ""
    function = None

    def set_operands(self, name, value):
        # pylint: disable=W0201
        self.name = str(name)
        # pylint: disable=W0201
        self.value = str(value)
        return self


class LSet(LOperators):
    __slots__ = []
    identifier = "="

    def apply_to_dict(self, d):
        """
        :param d: Dictionary for apply value
        """
        if self.name not in _reserved_keys:
            d[self.name] = _subtitution(self.value, d)


class LAppend(LOperators):
    __slots__ = []
    identifier = "+="

    def apply_to_dict(self, d):
        if self.name not in _reserved_keys:
            d[self.name] = d.get(self.name, "") + _subtitution(self.value, d)


class LPrepend(LOperators):
    __slots__ = []
    identifier = "<="

    def apply_to_dict(self, d):
        if self.name not in _reserved_keys:
            d[self.name] = _subtitution(self.value, d) + d.get(self.name, "")


class LRegExpSet(LOperators):
    __slots__ = []
    identifier = "?="

    def apply_to_dict(self, d):
        exp = re.compile("%s$" % self.name)
        value = _subtitution(self.value, d)
        for key in d:
            if key not in _reserved_keys and exp.match(key):
                d[key] = value


class LRegExpAppend(LOperators):
    __slots__ = []
    identifier = "?+="

    def apply_to_dict(self, d):
        exp = re.compile("%s$" % self.name)
        value = _subtitution(self.value, d)
        for key in d:
            if key not in _reserved_keys and exp.match(key):
                d[key] += value


class LRegExpPrepend(LOperators):
    __slots__ = []
    identifier = "?<="

    def apply_to_dict(self, d):
        exp = re.compile("%s$" % self.name)
        value = _subtitution(self.value, d)
        for key in d:
            if key not in _reserved_keys and exp.match(key):
                d[key] = value + d[key]


class LDel(LOperators):
    __slots__ = []
    identifier = "del"

    def apply_to_dict(self, d):
        exp = re.compile("%s$" % self.name)
        keys_to_del = collections.deque()
        for key in d:
            if key not in _reserved_keys and exp.match(key):
                keys_to_del.append(key)
        for key in keys_to_del:
            del d[key]


class LApplyPreDict(LOperators):
    __slots__ = []
    identifier = "apply_pre_dict"

    def set_operands(self, name, value):
        # pylint: disable=W0201
        self.name = name
        # pylint: disable=W0201
        self.value = value
        return self

    def apply_to_dict(self, d):
        d.update(self.value)

    def __str__(self):
        return "Apply_pre_dict: %s" % self.value

    def __repr__(self):
        return "Apply_pre_dict: %s" % self.value


class LUpdateFileMap(LOperators):
    __slots__ = ["shortname", "dest"]
    identifier = "update_file_map"

    def set_operands(self, filename, name, dest="_name_map_file"):
        # pylint: disable=W0201
        self.name = name
        # pylint: disable=W0201
        if filename == "<string>":
            self.shortname = filename
        else:
            self.shortname = os.path.basename(filename)

        self.dest = dest
        return self

    def apply_to_dict(self, d):
        dest = self.dest
        if dest not in d:
            d[dest] = {}

        if self.shortname in d[dest]:
            old_name = d[dest][self.shortname]
            d[dest][self.shortname] = "%s.%s" % (self.name, old_name)
        else:
            d[dest][self.shortname] = self.name


spec_iden = "_-"
spec_oper = "+<?"


tokens_map = {"-": LVariant,
              ".": LDot,
              ":": LColon,
              "@": LDefault,
              ",": LComa,
              "[": LLBracket,
              "]": LRBracket,
              "(": LLRBracket,
              ")": LRRBracket,
              "!": LNotCond}


tokens_oper = {"": LSet,
               "+": LAppend,
               "<": LPrepend,
               "?": LRegExpSet,
               "?+": LRegExpAppend,
               "?<": LRegExpPrepend,
               }


tokens_oper_re = [r"\=", r"\+\=", r"\<\=", r"\?\=", r"\?\+\=", r"\?\<\="]


_ops_exp = re.compile(r"|".join(tokens_oper_re))


class Lexer(object):

    def __init__(self, reader):
        self.reader = reader
        self.filename = reader.filename
        self.line = None
        self.linenum = 0
        self.ignore_white = False
        self.rest_as_string = False
        self.match_func_index = 0
        self.generator = self.get_lexer()
        self.prev_indent = 0
        self.fast = False

    def set_prev_indent(self, prev_indent):
        self.prev_indent = prev_indent

    def set_fast(self):
        self.fast = True

    def set_strict(self):
        self.fast = False

    def match(self, line, pos):
        l0 = line[0]
        chars = ""
        m = None
        cind = 0
        if l0 == "v":
            if line.startswith("variants:"):
                yield LVariants()
                yield LColon()
                pos = 9
            elif line.startswith("variants "):
                yield LVariants()
                pos = 8
        elif l0 == "-":
            yield LVariant()
            pos = 1
        elif l0 == "o":
            if line.startswith("only "):
                yield LOnly()
                pos = 4
                while line[pos].isspace():
                    pos += 1
        elif l0 == "n":
            if line.startswith("no "):
                yield LNo()
                pos = 2
                while line[pos].isspace():
                    pos += 1
        elif l0 == "i":
            if line.startswith("include "):
                yield LInclude()
                pos = 7
        elif l0 == "d":
            if line.startswith("del "):
                yield LDel()
                pos = 3
                while line[pos].isspace():
                    pos += 1

        if self.fast and pos == 0:  # due to refexp
            cind = line[pos:].find(":")
            m = _ops_exp.search(line[pos:])

        oper = ""
        token = None

        if self.rest_as_string:
            self.rest_as_string = False
            yield LString(line[pos:].lstrip())
        elif self.fast and m and (cind < 0 or cind > m.end()):
            chars = ""
            yield LIdentifier(line[:m.start()].rstrip())
            yield tokens_oper[m.group()[:-1]]()
            yield LString(line[m.end():].lstrip())
        else:
            li = enum(line[pos:], pos)
            for pos, char in li:
                if char.isalnum() or char in spec_iden:    # alfanum+_-
                    chars += char
                elif char in spec_oper:     # <+?=
                    if chars:
                        yield LIdentifier(chars)
                        oper = ""
                    chars = ""
                    oper += char
                else:
                    if chars:
                        yield LIdentifier(chars)
                        chars = ""
                    if char.isspace():   # Whitespace
                        for pos, char in li:
                            if not char.isspace():
                                if not self.ignore_white:
                                    yield LWhite()
                                break
                    if char.isalnum() or char in spec_iden:
                        chars += char
                    elif char == "=":
                        if oper in tokens_oper:
                            yield tokens_oper[oper]()
                        else:
                            raise LexerError("Unexpected character %s on"
                                             " pos %s" % (char, pos),
                                             self.line, self.filename,
                                             self.linenum)
                        oper = ""
                    elif char in tokens_map:
                        token = tokens_map[char]()
                    elif char == "\"":
                        chars = ""
                        pos, char = li.next()
                        while char != "\"":
                            chars += char
                            pos, char = li.next()
                        yield LString(chars)
                    elif char == "#":
                        break
                    elif char in spec_oper:
                        oper += char
                    else:
                        raise LexerError("Unexpected character %s on"
                                         " pos %s. Special chars are allowed"
                                         " only in variable assignation"
                                         " statement" % (char, pos), line,
                                         self.filename, self.linenum)
                    if token is not None:
                        yield token
                        token = None
                    if self.rest_as_string:
                        self.rest_as_string = False
                        yield LString(line[pos + 1:].lstrip())
                        break
        if chars:
            yield LIdentifier(chars)
            chars = ""
        yield LEndL()

    def get_lexer(self):
        cr = self.reader
        indent = 0
        while True:
            (self.line, indent,
             self.linenum) = cr.get_next_line(self.prev_indent)

            if not self.line:
                yield LEndBlock(indent)
                continue

            yield LIndent(indent)
            for token in self.match(self.line, 0):
                yield token

    def get_until_gen(self, end_tokens=None):
        if end_tokens is None:
            end_tokens = [LEndL]
        token = self.generator.next()
        while type(token) not in end_tokens:
            yield token
            token = self.generator.next()
        yield token

    def get_until(self, end_tokens=None):
        if end_tokens is None:
            end_tokens = [LEndL]
        return [x for x in self.get_until_gen(end_tokens)]

    def flush_until(self, end_tokens=None):
        if end_tokens is None:
            end_tokens = [LEndL]
        for _ in self.get_until_gen(end_tokens):
            pass

    def get_until_check(self, lType, end_tokens=None):
        """
        Read tokens from iterator until get end_tokens or type of token not
        match ltype

        :param lType: List of allowed tokens
        :param end_tokens: List of tokens for end reading
        :return: List of readed tokens.
        """
        if end_tokens is None:
            end_tokens = [LEndL]
        tokens = []
        lType = lType + end_tokens
        for token in self.get_until_gen(end_tokens):
            if type(token) in lType:
                tokens.append(token)
            else:
                raise ParserError("Expected %s got %s" % (lType, type(token)),
                                  self.line, self.filename, self.linenum)
        return tokens

    def get_until_no_white(self, end_tokens=None):
        """
        Read tokens from iterator until get one of end_tokens and strip LWhite

        :param end_tokens:  List of tokens for end reading
        :return: List of readed tokens.
        """
        if end_tokens is None:
            end_tokens = [LEndL]
        return [x for x in self.get_until_gen(end_tokens) if type(x) != LWhite]

    def rest_line_gen(self):
        token = self.generator.next()
        while type(token) != LEndL:
            yield token
            token = self.generator.next()

    def rest_line(self):
        return [x for x in self.rest_line_gen()]

    def rest_line_no_white(self):
        return [x for x in self.rest_line_gen() if type(x) != LWhite]

    def rest_line_as_LString(self):
        self.rest_as_string = True
        lstr = self.generator.next()
        self.generator.next()
        return lstr

    def get_next_check(self, lType):
        token = self.generator.next()
        if type(token) in lType:
            return type(token), token
        else:
            raise ParserError("Expected %s got ['%s']=[%s]" %
                              ([x.identifier for x in lType],
                               token.identifier, token),
                              self.line, self.filename, self.linenum)

    def get_next_check_nw(self, lType):
        token = self.generator.next()
        while type(token) == LWhite:
            token = self.generator.next()
        if type(token) in lType:
            return type(token), token
        else:
            raise ParserError("Expected %s got ['%s']" %
                              ([x.identifier for x in lType],
                               token.identifier),
                              self.line, self.filename, self.linenum)

    def check_token(self, token, lType):
        if type(token) in lType:
            return type(token), token
        else:
            raise ParserError("Expected %s got ['%s']" %
                              ([x.identifier for x in lType],
                               token.identifier),
                              self.line, self.filename, self.linenum)


def next_nw(gener):
    token = gener.next()
    while type(token) == LWhite:
        token = gener.next()
    return token


def cmd_tokens(tokens1, tokens2):
    for x, y in zip(tokens1, tokens2):
        if x != y:
            return False
    else:
        return True


def apply_predict(lexer, node, pre_dict):
    predict = LApplyPreDict().set_operands(None, pre_dict)
    node.content += [(lexer.filename, lexer.linenum, predict)]
    return {}


def parse_filter(lexer, tokens):
    """
    :return: Parsed filter
    """
    or_filters = []
    tokens = iter(tokens + [LEndL()])
    typet, token = lexer.check_token(tokens.next(), [LIdentifier, LLRBracket,
                                                     LEndL, LWhite])
    and_filter = []
    con_filter = []
    dots = 1
    while typet not in [LEndL]:
        if typet in [LIdentifier, LLRBracket]:        # join    identifier
            if typet == LLRBracket:    # (xxx=ttt)
                _, ident = lexer.check_token(next_nw(tokens),
                                             [LIdentifier])  # (iden
                typet, _ = lexer.check_token(next_nw(tokens),
                                             [LSet, LRRBracket])  # =
                if typet == LRRBracket:  # (xxx)
                    token = Label(str(ident))
                elif typet == LSet:    # (xxx = yyyy)
                    _, value = lexer.check_token(next_nw(tokens),
                                                 [LIdentifier, LString])
                    lexer.check_token(next_nw(tokens), [LRRBracket])
                    token = Label(str(ident), str(value))
            else:
                token = Label(token)
            if dots == 1:
                con_filter.append(token)
            elif dots == 2:
                and_filter.append(con_filter)
                con_filter = [token]
            elif dots == 0 or dots > 2:
                raise ParserError("Syntax Error expected \".\" between"
                                  " Identifier.", lexer.line, lexer.filename,
                                  lexer.linenum)

            dots = 0
        elif typet == LDot:         # xxx.xxxx or xxx..xxxx
            dots += 1
        elif typet in [LComa, LWhite]:
            if dots > 0:
                raise ParserError("Syntax Error expected identifier between"
                                  " \".\" and \",\".", lexer.line,
                                  lexer.filename, lexer.linenum)
            if and_filter:
                if con_filter:
                    and_filter.append(con_filter)
                    con_filter = []
                or_filters.append(and_filter)
                and_filter = []
            elif con_filter:
                or_filters.append([con_filter])
                con_filter = []
            elif typet == LIdentifier:
                or_filters.append([[Label(token)]])
            else:
                raise ParserError("Syntax Error expected \",\" between"
                                  " Identifier.", lexer.line, lexer.filename,
                                  lexer.linenum)
            dots = 1
            token = tokens.next()
            while type(token) == LWhite:
                token = tokens.next()
            typet, token = lexer.check_token(token, [LIdentifier,
                                                     LComa, LDot,
                                                     LLRBracket, LEndL])
            continue
        typet, token = lexer.check_token(tokens.next(), [LIdentifier, LComa,
                                                         LDot, LLRBracket,
                                                         LEndL, LWhite])
    if and_filter:
        if con_filter:
            and_filter.append(con_filter)
            con_filter = []
        or_filters.append(and_filter)
        and_filter = []
    if con_filter:
        or_filters.append([con_filter])
        con_filter = []
    return or_filters


class Parser(object):
    # pylint: disable=W0102

    def __init__(self, filename=None, defaults=False, expand_defaults=[],
                 debug=False):
        self.node = Node()
        self.debug = debug
        self.defaults = defaults
        self.expand_defaults = [LIdentifier(x) for x in expand_defaults]

        self.filename = filename
        if self.filename:
            self.parse_file(self.filename)

        self.only_filters = []
        self.no_filters = []
        self.assignments = []

    def _debug(self, s, *args):
        if self.debug:
            logging.debug(s, *args)

    def _warn(self, s, *args):
        logging.warn(s, *args)

    def parse_file(self, filename):
        """
        Parse a file.

        :param filename: Path of the configuration file.
        """
        self.node.filename = filename
        self.node = self._parse(Lexer(FileReader(filename)), self.node)
        self.filename = filename

    def parse_string(self, s):
        """
        Parse a string.

        :param s: String to parse.
        """
        self.node.filename = StrReader("").filename
        self.node = self._parse(Lexer(StrReader(s)), self.node)

    def only_filter(self, variant):
        """
        Apply a only filter programatically and keep track of it.

        Equivalent to parse a "only variant" line.

        :param variant: String with the variant name.
        """
        string = "only %s" % variant
        self.only_filters.append(string)
        self.parse_string(string)

    def no_filter(self, variant):
        """
        Apply a only filter programatically and keep track of it.

        Equivalent to parse a "no variant" line.

        :param variant: String with the variant name.
        """
        string = "no %s" % variant
        self.only_filters.append(string)
        self.parse_string(string)

    def assign(self, key, value):
        """
        Apply a only filter programatically and keep track of it.

        Equivalent to parse a "key = value" line.

        :param variant: String with the variant name.
        """
        string = "%s = %s" % (key, value)
        self.assignments.append(string)
        self.parse_string(string)

    def _parse(self, lexer, node=None, prev_indent=-1):
        if not node:
            node = self.node
        block_allowed = [LVariants, LIdentifier, LOnly,
                         LNo, LInclude, LDel, LNotCond]

        variants_allowed = [LVariant]

        identifier_allowed = [LSet, LAppend, LPrepend,
                              LRegExpSet, LRegExpAppend,
                              LRegExpPrepend, LColon,
                              LEndL]

        varianst_allowed_in = [LLBracket, LColon, LIdentifier, LEndL]
        indent_allowed = [LIndent, LEndBlock]

        allowed = block_allowed
        var_indent = 0
        var_name = ""
        # meta contains variants meta-data
        meta = {}
        # pre_dict contains block of operation without collision with
        # others block or operation. Increase speed almost twice.
        pre_dict = {}
        lexer.set_fast()
        try:
            while True:
                lexer.set_prev_indent(prev_indent)
                typet, token = lexer.get_next_check(indent_allowed)
                if typet == LEndBlock:
                    if pre_dict:
                        # flush pre_dict to node content.
                        pre_dict = apply_predict(lexer, node, pre_dict)
                    return node

                indent = token.length
                typet, token = lexer.get_next_check(allowed)

                if typet == LIdentifier:
                    # Parse:
                    #    identifier .....
                    identifier = lexer.get_until_no_white(identifier_allowed)
                    if isinstance(identifier[-1], LOperators):  # operand = <=
                        # Parse:
                        #    identifier = xxx
                        #    identifier <= xxx
                        #    identifier ?= xxx
                        #    etc..
                        op = identifier[-1]
                        if (len(identifier) == 1):
                            identifier = token
                        else:
                            identifier = [token] + identifier[:-1]
                            identifier = "".join([str(x) for x in identifier])
                        _, value = lexer.get_next_check([LString])
                        if value and (value[0] == value[-1] == '"' or
                                      value[0] == value[-1] == "'"):
                            value = value[1:-1]

                        op.set_operands(identifier, value)
                        d_nin_val = "$" not in value
                        if type(op) == LSet and d_nin_val:  # Optimization
                            op.apply_to_dict(pre_dict)
                        else:
                            if pre_dict:
                                # flush pre_dict to node content.
                                # If block already contain xxx = yyyy
                                # then operation xxx +=, <=, .... are safe.
                                if op.name in pre_dict and d_nin_val:
                                    op.apply_to_dict(pre_dict)
                                    lexer.get_next_check([LEndL])
                                    continue
                                else:
                                    pre_dict = apply_predict(lexer, node,
                                                             pre_dict)

                            node.content += [(lexer.filename,
                                              lexer.linenum,
                                              op)]
                        lexer.get_next_check([LEndL])

                    elif type(identifier[-1]) == LColon:  # condition:
                        # Parse:
                        #    xxx.yyy.(aaa=bbb):
                        identifier = [token] + identifier[:-1]
                        cfilter = parse_filter(lexer, identifier + [LEndL()])
                        next_line = lexer.rest_line_as_LString()
                        if next_line != "":
                            lexer.reader.set_next_line(next_line, indent + 1,
                                                       lexer.linenum)
                        cond = Condition(cfilter, lexer.line)
                        self._parse(lexer, cond, prev_indent=indent)

                        pre_dict = apply_predict(lexer, node, pre_dict)
                        node.content += [(lexer.filename, lexer.linenum, cond)]
                    else:
                        raise ParserError("Syntax ERROR expected \":\" or"
                                          " operand", lexer.line,
                                          lexer.filename, lexer.linenum)

                elif typet == LVariant:
                    # Parse
                    #  - var1: depend1, depend2
                    #      block1
                    #  - var2:
                    #      block2
                    if pre_dict:
                        pre_dict = apply_predict(lexer, node, pre_dict)
                    already_default = False
                    is_default = False
                    meta_with_default = False
                    if "default" in meta:
                        meta_with_default = True
                    meta_in_expand_defautls = False
                    if var_name not in self.expand_defaults:
                        meta_in_expand_defautls = True
                    node4 = Node()
                    while True:
                        lexer.set_prev_indent(var_indent)
                        # Get token from lexer and check syntax.
                        typet, token = lexer.get_next_check_nw([LIdentifier,
                                                                LDefault,
                                                                LIndent,
                                                                LEndBlock])
                        if typet == LEndBlock:
                            break

                        if typet == LIndent:
                            lexer.get_next_check_nw([LVariant])
                            typet, token = lexer.get_next_check_nw(
                                [LIdentifier,
                                 LDefault])

                        if typet == LDefault:  # @
                            is_default = True
                            name = lexer.get_until_check([LIdentifier, LDot],
                                                         [LColon])
                        else:  # identificator
                            is_default = False
                            name = [token] + lexer.get_until_check(
                                [LIdentifier, LDot],
                                [LColon])

                        if len(name) == 2:
                            name = [name[0]]
                            raw_name = name
                        else:
                            raw_name = [x for x in name[:-1]]
                            name = [x for x in name[:-1]
                                    if type(x) == LIdentifier]

                        token = lexer.generator.next()
                        while type(token) == LWhite:
                            token = lexer.generator.next()
                        tokens = None
                        if type(token) != LEndL:
                            tokens = [token] + lexer.get_until([LEndL])
                            deps = parse_filter(lexer, tokens)
                        else:
                            deps = []

                        # Prepare data for dict generator.
                        node2 = Node()
                        node2.children = [node]
                        node2.labels = node.labels

                        if var_name:
                            op = LSet().set_operands(var_name,
                                                     ".".join([str(n) for n in name]))
                            node2.content += [(lexer.filename,
                                               lexer.linenum,
                                               op)]

                        node3 = self._parse(lexer, node2, prev_indent=indent)

                        if var_name:
                            node3.var_name = var_name
                            node3.name = [Label(var_name, str(n))
                                          for n in name]
                        else:
                            node3.name = [Label(str(n)) for n in name]

                        # Update mapping name to file

                        node3.dep = deps

                        if meta_with_default:
                            for wd in meta["default"]:
                                if cmd_tokens(wd, raw_name):
                                    is_default = True
                                    meta["default"].remove(wd)

                        if (is_default and not already_default and
                                meta_in_expand_defautls):
                            node3.default = True
                            already_default = True

                        node3.append_to_shortname = not is_default

                        op = LUpdateFileMap()
                        op.set_operands(lexer.filename,
                                        ".".join(str(x)
                                                 for x in node3.name))
                        node3.content += [(lexer.filename,
                                           lexer.linenum,
                                           op)]

                        op = LUpdateFileMap()
                        op.set_operands(lexer.filename,
                                        ".".join(str(x.name)
                                                 for x in node3.name),
                                        "_short_name_map_file")
                        node3.content += [(lexer.filename,
                                           lexer.linenum,
                                           op)]

                        if node3.default and self.defaults:
                            # Move default variant in front of rest
                            # of all variants.
                            # Speed optimization.
                            node4.children.insert(0, node3)
                        else:
                            node4.children += [node3]
                        node4.labels.update(node3.labels)
                        node4.labels.update(node3.name)

                    if "default" in meta and meta["default"]:
                        raise ParserError("Missing default variant %s" %
                                          (meta["default"]), lexer.line,
                                          lexer.filename, lexer.linenum)
                    allowed = block_allowed
                    node = node4

                elif typet == LVariants:  # _name_ [meta1=xxx] [yyy] [xxx]
                    # Parse
                    #    variants _name_ [meta1] [meta2]:
                    if type(node) in [Condition, NegativeCondition]:
                        raise ParserError("'variants' is not allowed inside a "
                                          "conditional block", lexer.line,
                                          lexer.reader.filename, lexer.linenum)

                    lexer.set_strict()
                    tokens = lexer.get_until_no_white([LLBracket, LColon,
                                                       LIdentifier, LEndL])
                    vtypet = type(tokens[-1])
                    var_name = ""
                    meta.clear()
                    # [meta1=xxx] [yyy] [xxx]
                    while vtypet not in [LColon, LEndL]:
                        if vtypet == LIdentifier:
                            if var_name != "":
                                raise ParserError("Syntax ERROR expected"
                                                  " \"[\" or \":\"",
                                                  lexer.line, lexer.filename,
                                                  lexer.linenum)
                            var_name = tokens[0]
                        elif vtypet == LLBracket:  # [
                            _, ident = lexer.get_next_check_nw([LIdentifier])
                            typet, _ = lexer.get_next_check_nw([LSet,
                                                                LRBracket])
                            if typet == LRBracket:  # [xxx]
                                if ident not in meta:
                                    meta[ident] = []
                                meta[ident].append(True)
                            elif typet == LSet:  # [xxx = yyyy]
                                tokens = lexer.get_until_no_white([LRBracket,
                                                                   LEndL])
                                if type(tokens[-1]) == LRBracket:
                                    if ident not in meta:
                                        meta[ident] = []
                                    meta[ident].append(tokens[:-1])
                                else:
                                    raise ParserError("Syntax ERROR"
                                                      " expected \"]\"",
                                                      lexer.line,
                                                      lexer.filename,
                                                      lexer.linenum)

                        tokens = lexer.get_next_check_nw(varianst_allowed_in)
                        vtypet = type(tokens[-1])

                    if "default" in meta:
                        for wd in meta["default"]:
                            if type(wd) != list:
                                raise ParserError("Syntax ERROR expected "
                                                  "[default=xxx]",
                                                  lexer.line,
                                                  lexer.filename,
                                                  lexer.linenum)

                    if vtypet == LEndL:
                        raise ParserError("Syntax ERROR expected \":\"",
                                          lexer.line, lexer.filename,
                                          lexer.linenum)
                    lexer.get_next_check_nw([LEndL])
                    allowed = variants_allowed
                    var_indent = indent

                elif typet in [LNo, LOnly]:
                    # Parse:
                    #    only/no (filter=text)..aaa.bbb, xxxx
                    lfilter = parse_filter(lexer, lexer.rest_line())

                    pre_dict = apply_predict(lexer, node, pre_dict)
                    if typet == LOnly:
                        node.content += [(lexer.filename, lexer.linenum,
                                          OnlyFilter(lfilter, lexer.line))]
                    else:  # LNo
                        node.content += [(lexer.filename, lexer.linenum,
                                          NoFilter(lfilter, lexer.line))]

                elif typet == LInclude:
                    # Parse:
                    #    include relative file patch to working directory.
                    path = lexer.rest_line_as_LString()
                    filename = os.path.expanduser(path)
                    if (isinstance(lexer.reader, FileReader) and
                            not os.path.isabs(filename)):
                        filename = os.path.join(
                            os.path.dirname(lexer.filename),
                            filename)
                    if not os.path.isfile(filename):
                        raise MissingIncludeError(lexer.line, lexer.filename,
                                                  lexer.linenum)
                    pre_dict = apply_predict(lexer, node, pre_dict)
                    lch = Lexer(FileReader(filename))
                    node = self._parse(lch, node, -1)
                    lexer.set_prev_indent(prev_indent)

                elif typet == LDel:
                    # Parse:
                    #    del operand
                    _, to_del = lexer.get_next_check_nw([LIdentifier])
                    lexer.get_next_check_nw([LEndL])
                    token.set_operands(to_del, None)

                    pre_dict = apply_predict(lexer, node, pre_dict)
                    node.content += [(lexer.filename, lexer.linenum,
                                      token)]

                elif typet == LNotCond:
                    # Parse:
                    #    !xxx.yyy.(aaa=bbb): vvv
                    lfilter = parse_filter(lexer,
                                           lexer.get_until_no_white(
                                               [LColon, LEndL])[:-1])
                    next_line = lexer.rest_line_as_LString()
                    if next_line != "":
                        lexer.reader.set_next_line(next_line, indent + 1,
                                                   lexer.linenum)
                    cond = NegativeCondition(lfilter, lexer.line)
                    self._parse(lexer, cond, prev_indent=indent)
                    lexer.set_prev_indent(prev_indent)

                    pre_dict = apply_predict(lexer, node, pre_dict)
                    node.content += [(lexer.filename, lexer.linenum, cond)]
                else:
                    raise ParserError("Syntax ERROR expected", lexer.line,
                                      lexer.filename, lexer.linenum)
        except Exception:
            self._debug("%s  %s:  %s" % (lexer.filename, lexer.linenum,
                                         lexer.line))
            raise

    def get_dicts(self, node=None, ctx=[], content=[], shortname=[], dep=[]):
        """
        Generate dictionaries from the code parsed so far.  This should
        be called after parsing something.

        :return: A dict generator.
        """
        def process_content(content, failed_filters):
            # 1. Check that the filters in content are OK with the current
            #    context (ctx).
            # 2. Move the parts of content that are still relevant into
            #    new_content and unpack conditional blocks if appropriate.
            #    For example, if an 'only' statement fully matches ctx, it
            #    becomes irrelevant and is not appended to new_content.
            #    If a conditional block fully matches, its contents are
            #    unpacked into new_content.
            # 3. Move failed filters into failed_filters, so that next time we
            #    reach this node or one of its ancestors, we'll check those
            #    filters first.
            blocked_filters = []
            for t in content:
                filename, linenum, obj = t
                if isinstance(obj, LOperators):
                    new_content.append(t)
                    continue
                # obj is an OnlyFilter/NoFilter/Condition/NegativeCondition
                if obj.requires_action(ctx, ctx_set, labels):
                    # This filter requires action now
                    if type(obj) is OnlyFilter or type(obj) is NoFilter:
                        if obj not in blocked_filters:
                            self._debug("    filter did not pass: %r (%s:%s)",
                                        obj.line, filename, linenum)
                            failed_filters.append(t)
                            return False
                        else:
                            continue
                    else:
                        self._debug("    conditional block matches:"
                                    " %r (%s:%s)", obj.line, filename, linenum)
                        # Check and unpack the content inside this Condition
                        # object (note: the failed filters should go into
                        # new_internal_filters because we don't expect them to
                        # come from outside this node, even if the Condition
                        # itself was external)
                        if not process_content(obj.content,
                                               new_internal_filters):
                            failed_filters.append(t)
                            return False
                        continue
                elif obj.is_irrelevant(ctx, ctx_set, labels):
                    # This filter is no longer relevant and can be removed
                    continue
                else:
                    # Keep the filter and check it again later
                    new_content.append(t)
            return True

        def might_pass(failed_ctx,
                       failed_ctx_set,
                       failed_external_filters,
                       failed_internal_filters):
            all_content = content + node.content
            for t in failed_external_filters + failed_internal_filters:
                if t not in all_content:
                    return True
            for t in failed_external_filters:
                _, _, external_filter = t
                if not external_filter.might_pass(failed_ctx,
                                                  failed_ctx_set,
                                                  ctx, ctx_set,
                                                  labels):
                    return False
            for t in failed_internal_filters:
                if t not in node.content:
                    return True

            for t in failed_internal_filters:
                _, _, internal_filter = t
                if not internal_filter.might_pass(failed_ctx,
                                                  failed_ctx_set,
                                                  ctx, ctx_set,
                                                  labels):
                    return False
            return True

        def add_failed_case():
            node.failed_cases.appendleft((ctx, ctx_set,
                                          new_external_filters,
                                          new_internal_filters))
            if len(node.failed_cases) > num_failed_cases:
                node.failed_cases.pop()

        node = node or self.node
        # if self.debug:    #Print dict on which is working now.
        #    node.dump(0)
        # Update dep
        for d in node.dep:
            for dd in d:
                dep = dep + [".".join([str(label) for label in ctx + dd])]
        # Update ctx
        ctx = ctx + node.name
        ctx_set = set(ctx)
        labels = node.labels
        # Get the current name
        name = ".".join([str(label) for label in ctx])

        if node.name:
            self._debug("checking out %r", name)

        # Check previously failed filters
        for i, failed_case in enumerate(node.failed_cases):
            # pylint: disable=W0142
            if not might_pass(*failed_case):
                self._debug("\n*    this subtree has failed before %s\n"
                            "         content: %s\n"
                            "         failcase:%s\n",
                            name, content + node.content, failed_case)
                del node.failed_cases[i]
                node.failed_cases.appendleft(failed_case)
                return
        # Check content and unpack it into new_content
        new_content = []
        new_external_filters = []
        new_internal_filters = []
        if (not process_content(node.content, new_internal_filters) or
                not process_content(content, new_external_filters)):
            add_failed_case()
            self._debug("Failed_cases %s", node.failed_cases)
            return

        # Update shortname
        if node.append_to_shortname:
            shortname = shortname + node.name

        # Recurse into children
        count = 0
        if self.defaults and node.var_name not in self.expand_defaults:
            for n in node.children:
                for d in self.get_dicts(n, ctx, new_content, shortname, dep):
                    count += 1
                    yield d
                if n.default and count:
                    break
        else:
            for n in node.children:
                for d in self.get_dicts(n, ctx, new_content, shortname, dep):
                    count += 1
                    yield d
        # Reached leaf?
        if not node.children:
            self._debug("    reached leaf, returning it")
            d = {"name": name, "dep": dep,
                 "shortname": ".".join([str(sn.name) for sn in shortname])}
            for _, _, op in new_content:
                op.apply_to_dict(d)
            yield d
        # If this node did not produce any dicts, remember the failed filters
        # of its descendants
        elif not count:
            new_external_filters = []
            new_internal_filters = []
            for n in node.children:
                (_, _,
                 failed_external_filters,
                 failed_internal_filters) = n.failed_cases[0]
                for obj in failed_internal_filters:
                    if obj not in new_internal_filters:
                        new_internal_filters.append(obj)
                for obj in failed_external_filters:
                    if obj in content:
                        if obj not in new_external_filters:
                            new_external_filters.append(obj)
                    else:
                        if obj not in new_internal_filters:
                            new_internal_filters.append(obj)
            add_failed_case()


def print_dicts_default(options, dicts):
    """Print dictionaries in the default mode"""
    for i, d in enumerate(dicts):
        if options.fullname:
            print "dict %4d:  %s" % (i + 1, d["name"])
        else:
            print "dict %4d:  %s" % (i + 1, d["shortname"])
        if options.contents:
            keys = d.keys()
            keys.sort()
            for key in keys:
                print "    %s = %s" % (key, d[key])


# pylint: disable=W0613
def print_dicts_repr(options, dicts):
    import pprint
    print "["
    for d in dicts:
        print "%s," % (pprint.pformat(d))
    print "]"


def print_dicts(options, dicts):
    if options.repr_mode:
        print_dicts_repr(options, dicts)
    else:
        print_dicts_default(options, dicts)


if __name__ == "__main__":
    parser = optparse.OptionParser('usage: %prog [options] filename '
                                   '[extra code] ...\n\nExample:\n\n    '
                                   '%prog tests.cfg "only my_set" "no qcow2"')
    parser.add_option("-v", "--verbose", dest="debug", action="store_true",
                      help="include debug messages in console output")
    parser.add_option("-f", "--fullname", dest="fullname", action="store_true",
                      help="show full dict names instead of short names")
    parser.add_option("-c", "--contents", dest="contents", action="store_true",
                      help="show dict contents")
    parser.add_option("-r", "--repr", dest="repr_mode", action="store_true",
                      help="output parsing results Python format")
    parser.add_option("-d", "--defaults", dest="defaults", action="store_true",
                      help="use only default variant of variants if there"
                           " is some")
    parser.add_option("-e", "--expand", dest="expand", type="string",
                      help="list of vartiant which should be expanded when"
                           " defaults is enabled.  \"name, name, name\"")

    options, args = parser.parse_args()
    if not args:
        parser.error("filename required")

    if options.debug:
        logging.basicConfig(level=logging.DEBUG)

    expand = []
    if options.expand:
        expand = [x.strip() for x in options.expand.split(",")]
    c = Parser(args[0], defaults=options.defaults, expand_defaults=expand,
               debug=options.debug)
    for s in args[1:]:
        c.parse_string(s)

    if options.debug:
        c.node.dump(0, True)

    dicts = c.get_dicts()
    print_dicts(options, dicts)

########NEW FILE########
__FILENAME__ = cartesian_config_unittest
#!/usr/bin/python

import unittest
import os
import gzip

import common
import cartesian_config


mydir = os.path.dirname(__file__)
testdatadir = os.path.join(mydir, 'unittest_data')


class CartesianConfigTest(unittest.TestCase):

    def _checkDictionaries(self, parser, reference):
        result = list(parser.get_dicts())
        # as the dictionary list is very large, test each item individually:
        self.assertEquals(len(result), len(reference))
        for resdict, refdict in zip(result, reference):
            # checking the dict name first should make some errors more visible
            self.assertEquals(resdict.get('name'), refdict.get('name'))
            self.assertEquals(resdict, refdict)

    def _checkConfigDump(self, config, dump):
        """Check if the parser output matches a config file dump"""
        configpath = os.path.join(testdatadir, config)
        dumppath = os.path.join(testdatadir, dump)

        if dumppath.endswith('.gz'):
            df = gzip.GzipFile(dumppath, 'r')
        else:
            df = open(dumppath, 'r')
        # we could have used pickle, but repr()-based dumps are easier to
        # enerate, debug, and edit
        dumpdata = eval(df.read())

        p = cartesian_config.Parser(configpath)
        self._checkDictionaries(p, dumpdata)

    def _checkStringConfig(self, string, reference):
        p = cartesian_config.Parser()
        p.parse_string(string)
        self._checkDictionaries(p, reference)

    def _checkStringDump(self, string, dump, defaults=False):
        p = cartesian_config.Parser(defaults=defaults)
        p.parse_string(string)

        self._checkDictionaries(p, dump)

    def testSimpleVariant(self):
        self._checkStringConfig("""
            c = abc
            variants:
                - a:
                    x = va
                - b:
                    x = vb
            """,
                                [
                                    {'_name_map_file': {'<string>': 'a'},
                                     '_short_name_map_file': {'<string>': 'a'},
                                     'c': 'abc',
                                     'dep': [],
                                     'name': 'a',
                                     'shortname': 'a',
                                     'x': 'va'},
                                    {'_name_map_file': {'<string>': 'b'},
                                     '_short_name_map_file': {'<string>': 'b'},
                                     'c': 'abc',
                                     'dep': [],
                                     'name': 'b',
                                     'shortname': 'b',
                                     'x': 'vb'},
                                ])

    def testFilterMixing(self):
        self._checkStringDump("""
            variants:
                - unknown_qemu:
                - rhel64:
            only unknown_qemu
            variants:
                - kvm:
                - nokvm:
            variants:
                - testA:
                    nokvm:
                        no unknown_qemu
                - testB:
            """,
                              [
                                  {'_name_map_file': {'<string>': 'testA.kvm.unknown_qemu'},
                                   '_short_name_map_file': {'<string>': 'testA.kvm.unknown_qemu'},
                                   'dep': [],
                                   'name': 'testA.kvm.unknown_qemu',
                                   'shortname': 'testA.kvm.unknown_qemu'},
                                  {'_name_map_file': {'<string>': 'testB.kvm.unknown_qemu'},
                                   '_short_name_map_file': {'<string>': 'testB.kvm.unknown_qemu'},
                                   'dep': [],
                                   'name': 'testB.kvm.unknown_qemu',
                                   'shortname': 'testB.kvm.unknown_qemu'},
                                  {'_name_map_file': {'<string>': 'testB.nokvm.unknown_qemu'},
                                   '_short_name_map_file': {'<string>': 'testB.nokvm.unknown_qemu'},
                                   'dep': [],
                                   'name': 'testB.nokvm.unknown_qemu',
                                   'shortname': 'testB.nokvm.unknown_qemu'},
                              ])

    def testNameVariant(self):
        self._checkStringDump("""
            variants tests: # All tests in configuration
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
              - test2:
                   run = "test1"

            variants virt_system:
              - @linux:
              - windows:

            variants host_os:
              - linux:
                   image = linux
              - windows:
                   image = windows

            only (host_os=linux)
            """,
                              [
                                  {'_name_map_file': {'<string>': '(host_os=linux).(virt_system=linux).(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'linux.linux.wait.long'},
                                   'dep': [],
                                   'host_os': 'linux',
                                   'image': 'linux',
                                   'name': '(host_os=linux).(virt_system=linux).(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'linux.wait.long',
                                   'tests': 'wait',
                                   'time': 'short_time',
                                   'virt_system': 'linux'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(virt_system=linux).(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'linux.linux.wait.short'},
                                   'dep': ['(host_os=linux).(virt_system=linux).(tests=wait).long'],
                                   'host_os': 'linux',
                                   'image': 'linux',
                                   'name': '(host_os=linux).(virt_system=linux).(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'linux.wait.short',
                                   'tests': 'wait',
                                   'time': 'logn_time',
                                   'virt_system': 'linux'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(virt_system=linux).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'linux.linux.test2'},
                                   'dep': [],
                                   'host_os': 'linux',
                                   'image': 'linux',
                                   'name': '(host_os=linux).(virt_system=linux).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'linux.test2',
                                   'tests': 'test2',
                                   'virt_system': 'linux'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(virt_system=windows).(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'linux.windows.wait.long'},
                                   'dep': [],
                                   'host_os': 'linux',
                                   'image': 'linux',
                                   'name': '(host_os=linux).(virt_system=windows).(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'linux.windows.wait.long',
                                   'tests': 'wait',
                                   'time': 'short_time',
                                   'virt_system': 'windows'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(virt_system=windows).(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'linux.windows.wait.short'},
                                   'dep': ['(host_os=linux).(virt_system=windows).(tests=wait).long'],
                                   'host_os': 'linux',
                                   'image': 'linux',
                                   'name': '(host_os=linux).(virt_system=windows).(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'linux.windows.wait.short',
                                   'tests': 'wait',
                                   'time': 'logn_time',
                                   'virt_system': 'windows'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(virt_system=windows).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'linux.windows.test2'},
                                   'dep': [],
                                   'host_os': 'linux',
                                   'image': 'linux',
                                   'name': '(host_os=linux).(virt_system=windows).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'linux.windows.test2',
                                   'tests': 'test2',
                                   'virt_system': 'windows'},
                              ]
                              )

    def testDefaults(self):
        self._checkStringDump("""
            variants tests:
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
              - test2:
                   run = "test1"

            variants virt_system [ default=  linux ]:
              - linux:
              - @windows:

            variants host_os:
              - linux:
                   image = linux
              - @windows:
                   image = windows
            """,
                              [
                                  {'_name_map_file': {'<string>': '(host_os=windows).(virt_system=linux).(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'windows.linux.wait.long'},
                                   'dep': [],
                                   'host_os': 'windows',
                                   'image': 'windows',
                                   'name': '(host_os=windows).(virt_system=linux).(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'wait.long',
                                   'tests': 'wait',
                                   'time': 'short_time',
                                   'virt_system': 'linux'},
                                  {'_name_map_file': {'<string>': '(host_os=windows).(virt_system=linux).(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'windows.linux.wait.short'},
                                   'dep': ['(host_os=windows).(virt_system=linux).(tests=wait).long'],
                                   'host_os': 'windows',
                                   'image': 'windows',
                                   'name': '(host_os=windows).(virt_system=linux).(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'wait.short',
                                   'tests': 'wait',
                                   'time': 'logn_time',
                                   'virt_system': 'linux'},
                                  {'_name_map_file': {'<string>': '(host_os=windows).(virt_system=linux).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'windows.linux.test2'},
                                   'dep': [],
                                   'host_os': 'windows',
                                   'image': 'windows',
                                   'name': '(host_os=windows).(virt_system=linux).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'test2',
                                   'tests': 'test2',
                                   'virt_system': 'linux'},
                              ],
                              True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants tests [default=system2]:
                  - system1:
                """,
                          [],
                          True)

    def testDel(self):
        self._checkStringDump("""
            variants tests:
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
              - test2:
                   run = "test1"
            """,
                              [
                                  {'_name_map_file': {'<string>': '(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'wait.long'},
                                   'dep': [],
                                   'name': '(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'wait.long',
                                   'tests': 'wait',
                                   'time': 'short_time'},
                                  {'_name_map_file': {'<string>': '(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'wait.short'},
                                   'dep': ['(tests=wait).long'],
                                   'name': '(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'wait.short',
                                   'tests': 'wait',
                                   'time': 'logn_time'},
                                  {'_name_map_file': {'<string>': '(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'test2'},
                                   'dep': [],
                                   'name': '(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'test2',
                                   'tests': 'test2'},
                              ],
                              True)

        self._checkStringDump("""
            variants tests:
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
              - test2:
                   run = "test1"

            del time
            """,
                              [
                                  {'_name_map_file': {'<string>': '(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'wait.long'},
                                   'dep': [],
                                   'name': '(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'wait.long',
                                   'tests': 'wait'},
                                  {'_name_map_file': {'<string>': '(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'wait.short'},
                                   'dep': ['(tests=wait).long'],
                                   'name': '(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'wait.short',
                                   'tests': 'wait'},
                                  {'_name_map_file': {'<string>': '(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'test2'},
                                   'dep': [],
                                   'name': '(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'test2',
                                   'tests': 'test2'},
                              ],
                              True)

    def testError1(self):
        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants tests:
                  wait:
                       run = "wait"
                       variants:
                         - long:
                            time = short_time
                         - short: long
                            time = logn_time
                  - test2:
                       run = "test1"
                """,
                          [],
                          True)

    def testMissingInclude(self):
        self.assertRaises(cartesian_config.MissingIncludeError,
                          self._checkStringDump, """
                include xxxxxxxxx/xxxxxxxxxxx
                """,
                          [],
                          True)

    def testVariableAssignment(self):
        self._checkStringDump("""
            variants tests:
              -system1:
                    var = 1
                    var = 2
                    var += a
                    var <= b
                    system = 2
                    ddd = ${tests + str(int(system) + 3)}4
                    error = ${tests + str(system + 3)}4
                    s.* ?= ${tests + "ahoj"}4
                    s.* ?+= c
                    s.* ?<= d
                    system += 4
                    var += "test"
            """,
                              [
                                  {'_name_map_file': {'<string>': '(tests=system1)'},
                                   '_short_name_map_file': {'<string>': 'system1'},
                                   'ddd': 'system154',
                                   'dep': [],
                                   'error': '${tests + str(system + 3)}4',
                                   'name': '(tests=system1)',
                                   'shortname': 'system1',
                                   'system': 'dsystem1ahoj4c4',
                                   'tests': 'system1',
                                   'var': 'b2atest'},
                              ],
                              True)

    def testCondition(self):
        self._checkStringDump("""
            variants tests [meta1]:
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
              - test2:
                   run = "test1"

            test2: bbb = aaaa
               aaa = 1
            """,
                              [
                                  {'_name_map_file': {'<string>': '(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'wait.long'},
                                   'dep': [],
                                   'name': '(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'wait.long',
                                   'tests': 'wait',
                                   'time': 'short_time'},
                                  {'_name_map_file': {'<string>': '(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'wait.short'},
                                   'dep': ['(tests=wait).long'],
                                   'name': '(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'wait.short',
                                   'tests': 'wait',
                                   'time': 'logn_time'},
                                  {'_name_map_file': {'<string>': '(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'test2'},
                                   'aaa': '1',
                                   'bbb': 'aaaa',
                                   'dep': [],
                                   'name': '(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'test2',
                                   'tests': 'test2'},
                              ],
                              True)
        self._checkStringDump("""
            variants:
                - a:
                    foo = foo
                    c:
                        foo = bar
                - b:
                    foo = foob
            variants:
                - c:
                    bala = lalalala
                    a:
                       bala = balabala
                - d:
            """,
                              [
                                  {'_name_map_file': {'<string>': 'c.a'},
                                   '_short_name_map_file': {'<string>': 'c.a'},
                                   'bala': 'balabala',
                                   'dep': [],
                                   'foo': 'bar',
                                   'name': 'c.a',
                                   'shortname': 'c.a'},
                                  {'_name_map_file': {'<string>': 'c.b'},
                                   '_short_name_map_file': {'<string>': 'c.b'},
                                   'bala': 'lalalala',
                                   'dep': [],
                                   'foo': 'foob',
                                   'name': 'c.b',
                                   'shortname': 'c.b'},
                                  {'_name_map_file': {'<string>': 'd.a'},
                                   '_short_name_map_file': {'<string>': 'd.a'},
                                   'dep': [],
                                   'foo': 'foo',
                                   'name': 'd.a',
                                   'shortname': 'd.a'},
                                  {'_name_map_file': {'<string>': 'd.b'},
                                   '_short_name_map_file': {'<string>': 'd.b'},
                                   'dep': [],
                                   'foo': 'foob',
                                   'name': 'd.b',
                                   'shortname': 'd.b'},
                              ],
                              True)

    def testNegativeCondition(self):
        self._checkStringDump("""
            variants tests [meta1]:
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
              - test2:
                   run = "test1"

            !test2: bbb = aaaa
               aaa = 1
            """,
                              [
                                  {'_name_map_file': {'<string>': '(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'wait.long'},
                                   'aaa': '1',
                                   'bbb': 'aaaa',
                                   'dep': [],
                                   'name': '(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'wait.long',
                                   'tests': 'wait',
                                   'time': 'short_time'},
                                  {'_name_map_file': {'<string>': '(tests=wait).short'},
                                   '_short_name_map_file': {'<string>': 'wait.short'},
                                   'aaa': '1',
                                   'bbb': 'aaaa',
                                   'dep': ['(tests=wait).long'],
                                   'name': '(tests=wait).short',
                                   'run': 'wait',
                                   'shortname': 'wait.short',
                                   'tests': 'wait',
                                   'time': 'logn_time'},
                                  {'_name_map_file': {'<string>': '(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'test2'},
                                   'dep': [],
                                   'name': '(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'test2',
                                   'tests': 'test2'},
                              ],
                              True)

    def testSyntaxErrors(self):
        self.assertRaises(cartesian_config.LexerError,
                          self._checkStringDump, """
                variants tests$:
                  - system1:
                        var = 1
                        var = 2
                        var += a
                        var <= b
                        system = 2
                        s.* ?= ${tests}4
                        s.* ?+= c
                        s.* ?<= d
                        system += 4
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.LexerError,
                          self._checkStringDump, """
                variants tests [defaul$$$$t=system1]:
                  - system1:
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants tests [default=system1] wrong:
                  - system1:
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                only xxx...yyy
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                only xxx..,yyy
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                aaabbbb.ddd
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                aaa.bbb:
                  variants test:
                     -sss:
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants test [sss = bbb:
                     -sss:
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants test [default]:
                     -sss:
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants test [default] ddd:
                     -sss:
                """,
                          [],
                          True)

        self.assertRaises(cartesian_config.ParserError,
                          self._checkStringDump, """
                variants test [default] ddd
                """,
                          [],
                          True)

    def testComplicatedFilter(self):
        self._checkStringDump("""
            variants tests:
              - wait:
                   run = "wait"
                   variants:
                     - long:
                        time = short_time
                     - short: long
                        time = logn_time
                        only (host_os=linux), ( guest_os =    linux  )
              - test2:
                   run = "test1"

            variants guest_os:
              - linux:
                    install = linux
                    no (tests=wait)..short
              - windows:
                    install = windows
                    only test2

            variants host_os:
              - linux:
                    start = linux
              - windows:
                    start = windows
                    only test2
            """,
                              [
                                  {'_name_map_file': {'<string>': '(host_os=linux).(guest_os=linux).(tests=wait).long'},
                                   '_short_name_map_file': {'<string>': 'linux.linux.wait.long'},
                                   'dep': [],
                                   'guest_os': 'linux',
                                   'host_os': 'linux',
                                   'install': 'linux',
                                   'name': '(host_os=linux).(guest_os=linux).(tests=wait).long',
                                   'run': 'wait',
                                   'shortname': 'linux.linux.wait.long',
                                   'start': 'linux',
                                   'tests': 'wait',
                                   'time': 'short_time'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(guest_os=linux).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'linux.linux.test2'},
                                   'dep': [],
                                   'guest_os': 'linux',
                                   'host_os': 'linux',
                                   'install': 'linux',
                                   'name': '(host_os=linux).(guest_os=linux).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'linux.linux.test2',
                                   'start': 'linux',
                                   'tests': 'test2'},
                                  {'_name_map_file': {'<string>': '(host_os=linux).(guest_os=windows).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'linux.windows.test2'},
                                   'dep': [],
                                   'guest_os': 'windows',
                                   'host_os': 'linux',
                                   'install': 'windows',
                                   'name': '(host_os=linux).(guest_os=windows).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'linux.windows.test2',
                                   'start': 'linux',
                                   'tests': 'test2'},
                                  {'_name_map_file': {'<string>': '(host_os=windows).(guest_os=linux).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'windows.linux.test2'},
                                   'dep': [],
                                   'guest_os': 'linux',
                                   'host_os': 'windows',
                                   'install': 'linux',
                                   'name': '(host_os=windows).(guest_os=linux).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'windows.linux.test2',
                                   'start': 'windows',
                                   'tests': 'test2'},
                                  {'_name_map_file': {'<string>': '(host_os=windows).(guest_os=windows).(tests=test2)'},
                                   '_short_name_map_file': {'<string>': 'windows.windows.test2'},
                                   'dep': [],
                                   'guest_os': 'windows',
                                   'host_os': 'windows',
                                   'install': 'windows',
                                   'name': '(host_os=windows).(guest_os=windows).(tests=test2)',
                                   'run': 'test1',
                                   'shortname': 'windows.windows.test2',
                                   'start': 'windows',
                                   'tests': 'test2'},
                              ],
                              True)

        f = "only xxx.yyy..(xxx=333).aaa, ddd (eeee) rrr.aaa"

        self._checkStringDump(f, [], True)

        lexer = cartesian_config.Lexer(cartesian_config.StrReader(f))
        lexer.set_prev_indent(-1)
        lexer.get_next_check([cartesian_config.LIndent])
        lexer.get_next_check([cartesian_config.LOnly])
        p_filter = cartesian_config.parse_filter(lexer, lexer.rest_line())
        self.assertEquals(p_filter,
                          [[[cartesian_config.Label("xxx"),
                             cartesian_config.Label("yyy")],
                            [cartesian_config.Label("xxx", "333"),
                             cartesian_config.Label("aaa")]],
                           [[cartesian_config.Label("ddd")]],
                           [[cartesian_config.Label("eeee")]],
                           [[cartesian_config.Label("rrr"),
                             cartesian_config.Label("aaa")]]],
                          "Failed to parse filter.")

    def testHugeTest1(self):
        self._checkConfigDump('testcfg.huge/test1.cfg',
                              'testcfg.huge/test1.cfg.repr.gz')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = common
import os
import sys


def load_setup_modules(client_dir):
    try:
        sys.path.insert(0, client_dir)
        import setup_modules
    finally:
        sys.path.pop(0)
    return setup_modules

dirname = os.path.dirname(sys.modules[__name__].__file__)
virt_test_dir = os.path.abspath(os.path.join(dirname, ".."))
sys.path.insert(0, virt_test_dir)

try:
    import autotest.client.setup_modules as setup_modules
    client_dir = os.path.dirname(setup_modules.__file__)
    sm = setup_modules
except ImportError:
    try:
        client_dir = os.path.abspath(os.path.join(dirname, "..", "..", ".."))
        sm = load_setup_modules(client_dir)
    except:
        try:
            client_dir = os.path.join(os.environ['AUTOTEST_PATH'], 'client')
        except KeyError:
            print("Environment variable $AUTOTEST_PATH not set. "
                  "please set it to a path containing an autotest checkout")
            print("Or install the autotest-framework package for your distro")
            sys.exit(1)
        if not os.path.isdir(client_dir):
            print('Autotest client library directory was not found at: "%s"' %
                  client_dir)
            print('Please check if the environment variable "$AUTOTEST_PATH" '
                  'points to a valid location')
            sys.exit(1)
        sm = load_setup_modules(client_dir)
sm.setup(base_path=client_dir, root_module_name="autotest.client")

########NEW FILE########
__FILENAME__ = data_dir
#!/usr/bin/python
"""
Library used to provide the appropriate data dir for virt test.
"""
import inspect
import os
import sys
import tempfile
import glob
import shutil

_ROOT_PATH = os.path.join(sys.modules[__name__].__file__, "..", "..")
ROOT_DIR = os.path.abspath(_ROOT_PATH)
BASE_BACKEND_DIR = os.path.join(ROOT_DIR, 'backends')
DATA_DIR = os.path.join(ROOT_DIR, 'shared', 'data')
DEPS_DIR = os.path.join(ROOT_DIR, 'shared', 'deps')
DOWNLOAD_DIR = os.path.join(ROOT_DIR, 'shared', 'downloads')
TEST_PROVIDERS_DIR = os.path.join(ROOT_DIR, 'test-providers.d')
TEST_PROVIDERS_DOWNLOAD_DIR = os.path.join(ROOT_DIR, 'test-providers.d',
                                           'downloads')
TMP_DIR = os.path.join(ROOT_DIR, 'tmp')
BACKING_DATA_DIR = None


class MissingDepsDirError(Exception):
    pass


class UnknownBackendError(Exception):

    def __init__(self, backend):
        self.backend = backend

    def __str__(self):
        return ("Virt Backend %s is not currently supported by virt-test. "
                "Check for typos and the list of supported backends" %
                self.backend)


class SubdirList(list):

    """
    List of all non-hidden subdirectories beneath basedir
    """

    def __in_filter__(self, item):
        if self.filterlist:
            for _filter in self.filterlist:
                if item.count(str(_filter)):
                    return True
            return False
        else:
            return False

    def __set_initset__(self):
        for dirpath, dirnames, filenames in os.walk(self.basedir):
            del filenames  # not used
            # Don't modify list while in use
            del_list = []
            for _dirname in dirnames:
                if _dirname.startswith('.') or self.__in_filter__(_dirname):
                    # Don't descend into filtered or hidden directories
                    del_list.append(_dirname)
                else:
                    self.initset.add(os.path.join(dirpath, _dirname))
            # Remove items in del_list from dirnames list
            for _dirname in del_list:
                del dirnames[dirnames.index(_dirname)]

    def __init__(self, basedir, filterlist=None):
        self.basedir = os.path.abspath(str(basedir))
        self.initset = set([self.basedir])  # enforce unique items
        self.filterlist = filterlist
        self.__set_initset__()
        super(SubdirList, self).__init__(self.initset)


class SubdirGlobList(SubdirList):

    """
    List of all files matching glob in all non-hidden basedir subdirectories
    """

    def __initset_to_globset__(self):
        globset = set()
        for dirname in self.initset:  # dirname is absolute
            pathname = os.path.join(dirname, self.globstr)
            for filepath in glob.glob(pathname):
                if not self.__in_filter__(filepath):
                    globset.add(filepath)
        self.initset = globset

    def __set_initset__(self):
        super(SubdirGlobList, self).__set_initset__()
        self.__initset_to_globset__()

    def __init__(self, basedir, globstr, filterlist=None):
        self.globstr = str(globstr)
        super(SubdirGlobList, self).__init__(basedir, filterlist)


def get_backing_data_dir():
    if os.path.islink(DATA_DIR):
        if os.path.isdir(DATA_DIR):
            return os.readlink(DATA_DIR)
        else:
            # Invalid symlink
            os.unlink(DATA_DIR)
    elif os.path.isdir(DATA_DIR):
        return DATA_DIR

    try:
        return os.environ['VIRT_TEST_DATA_DIR']
    except KeyError:
        pass

    data_dir = '/var/lib/virt_test'
    if os.path.isdir(data_dir):
        try:
            fd, path = tempfile.mkstemp(dir=data_dir)
            os.close(fd)
            os.unlink(path)
            return data_dir
        except OSError:
            pass
    else:
        try:
            os.makedirs(data_dir)
            return data_dir
        except OSError:
            pass

    data_dir = os.path.expanduser('~/virt_test')
    if not os.path.isdir(data_dir):
        os.makedirs(data_dir)
    return os.path.realpath(data_dir)


def set_backing_data_dir(backing_data_dir):
    backing_data_dir = os.path.expanduser(backing_data_dir)
    try:
        os.symlink(backing_data_dir, DATA_DIR)
    except OSError:
        pass  # Assume existing link is correct
    if not os.path.isdir(backing_data_dir):
        os.makedirs(backing_data_dir)


BACKING_DATA_DIR = get_backing_data_dir()
set_backing_data_dir(BACKING_DATA_DIR)


def get_root_dir():
    return ROOT_DIR


def get_data_dir():
    return DATA_DIR


def get_backend_dir(backend_type):
    if backend_type not in os.listdir(BASE_BACKEND_DIR):
        raise UnknownBackendError(backend_type)
    return os.path.join(BASE_BACKEND_DIR, backend_type)


def get_backend_cfg_path(backend_type, cfg_basename):
    return os.path.join(BASE_BACKEND_DIR, backend_type, 'cfg', cfg_basename)


def get_deps_dir(target=None):
    """
    For a given test provider, report the appropriate deps dir.

    The little inspect trick is used to avoid callers having to do
    sys.modules[] tricks themselves.

    :param target: File we want in deps folder. Will return the path to the
                   target if set and available. Or will only return the path
                   to dep folder.
    """
    # Get the frame that called this function
    frame = inspect.stack()[1]
    # This is the module that called the function
    module = inspect.getmodule(frame[0])
    # With the module path, we can keep searching with a parent dir with 'deps'
    # in it, which should be the correct deps directory.
    path = os.path.dirname(module.__file__)
    nesting_limit = 10
    for index in xrange(nesting_limit):
        files = os.listdir(path)
        if 'deps' in files:
            deps = os.path.join(path, 'deps')
            if target:
                if target in os.listdir(deps):
                    return os.path.join(deps, target)
            else:
                return deps
        if '.git' in os.listdir(path):
            raise MissingDepsDirError("Could not find specified deps dir for "
                                      "git repo %s" % path)
        path = os.path.dirname(path)
    raise MissingDepsDirError("Could not find specified deps dir after "
                              "looking %s parent directories" %
                              nesting_limit)


def get_tmp_dir():
    if not os.path.isdir(TMP_DIR):
        os.makedirs(TMP_DIR)
    return TMP_DIR


def get_download_dir():
    return DOWNLOAD_DIR


def get_test_providers_dir():
    """
    Return the base test providers dir (at the moment, test-providers.d).
    """
    if not os.path.isdir(TEST_PROVIDERS_DOWNLOAD_DIR):
        os.makedirs(TEST_PROVIDERS_DOWNLOAD_DIR)
    return TEST_PROVIDERS_DIR


def get_test_provider_dir(provider):
    """
    Return a specific test providers dir, inside the base dir.
    """
    provider_dir = os.path.join(TEST_PROVIDERS_DOWNLOAD_DIR, provider)
    if not provider_dir:
        os.makedirs(provider_dir)
    return provider_dir


def clean_tmp_files():
    if os.path.isdir(TMP_DIR):
        hidden_paths = glob.glob(os.path.join(TMP_DIR, ".??*"))
        paths = glob.glob(os.path.join(TMP_DIR, "*"))
        for path in paths + hidden_paths:
            shutil.rmtree(path, ignore_errors=True)


if __name__ == '__main__':
    print "root dir:         " + ROOT_DIR
    print "tmp dir:          " + TMP_DIR
    print "data dir:         " + DATA_DIR
    print "deps dir:         " + DEPS_DIR
    print "backing data dir: " + BACKING_DATA_DIR
    print "test providers dir: " + TEST_PROVIDERS_DIR

########NEW FILE########
__FILENAME__ = defaults
from autotest.client.shared import distro

DEFAULT_MACHINE_TYPE = "i440fx"
DEFAULT_GUEST_OS = "JeOS.19"


def get_default_guest_os_info():
    """
    Gets the default asset and variant information depending on host OS
    """
    os_info = {'asset': 'jeos-19-64', 'variant': DEFAULT_GUEST_OS}

    detected = distro.detect()
    if detected.name == 'fedora' and int(detected.version) >= 20:
        os_info = {'asset': 'jeos-20-64', 'variant': 'JeOS.20'}

    return os_info

########NEW FILE########
__FILENAME__ = element_path
#
# ElementTree
# $Id: ElementPath.py 1858 2004-06-17 21:31:41Z Fredrik $
#
# limited xpath support for element trees
#
# history:
# 2003-05-23 fl   created
# 2003-05-28 fl   added support for // etc
# 2003-08-27 fl   fixed parsing of periods in element names
#
# Copyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2004 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

# Licensed to PSF under a Contributor Agreement.
# See http://www.python.org/2.4/license for licensing details.

#
# Implementation module for XPath support.  There's usually no reason
# to import this module directly; the <b>ElementTree</b> does this for
# you, if needed.
#

import re

xpath_tokenizer = re.compile(
    "(::|\.\.|\(\)|[/.*:\[\]\(\)@=])|((?:\{[^}]+\})?[^/:\[\]\(\)@=\s]+)|\s+"
).findall


class xpath_descendant_or_self:
    pass

#
# Wrapper for a compiled XPath.


class Path:

    #
    # Create an Path instance from an XPath expression.

    def __init__(self, path):
        tokens = xpath_tokenizer(path)
        # the current version supports 'path/path'-style expressions only
        self.path = []
        self.tag = None
        if tokens and tokens[0][0] == "/":
            raise SyntaxError("cannot use absolute path on element")
        while tokens:
            op, tag = tokens.pop(0)
            if tag or op == "*":
                self.path.append(tag or op)
            elif op == ".":
                pass
            elif op == "/":
                self.path.append(xpath_descendant_or_self())
                continue
            else:
                raise SyntaxError("unsupported path syntax (%s)" % op)
            if tokens:
                op, tag = tokens.pop(0)
                if op != "/":
                    raise SyntaxError(
                        "expected path separator (%s)" % (op or tag)
                    )
        if self.path and isinstance(self.path[-1], xpath_descendant_or_self):
            raise SyntaxError("path cannot end with //")
        if len(self.path) == 1 and isinstance(self.path[0], type("")):
            self.tag = self.path[0]

    #
    # Find first matching object.

    def find(self, element):
        tag = self.tag
        if tag is None:
            nodeset = self.findall(element)
            if not nodeset:
                return None
            return nodeset[0]
        for elem in element:
            if elem.tag == tag:
                return elem
        return None

    #
    # Find text for first matching object.

    def findtext(self, element, default=None):
        tag = self.tag
        if tag is None:
            nodeset = self.findall(element)
            if not nodeset:
                return default
            return nodeset[0].text or ""
        for elem in element:
            if elem.tag == tag:
                return elem.text or ""
        return default

    #
    # Find all matching objects.

    def findall(self, element):
        nodeset = [element]
        index = 0
        while 1:
            try:
                path = self.path[index]
                index = index + 1
            except IndexError:
                return nodeset
            set = []
            if isinstance(path, xpath_descendant_or_self):
                try:
                    tag = self.path[index]
                    if not isinstance(tag, type("")):
                        tag = None
                    else:
                        index = index + 1
                except IndexError:
                    tag = None  # invalid path
                for node in nodeset:
                    new = list(node.getiterator(tag))
                    if new and new[0] is node:
                        set.extend(new[1:])
                    else:
                        set.extend(new)
            else:
                for node in nodeset:
                    for node in node:
                        if path == "*" or node.tag == path:
                            set.append(node)
            if not set:
                return []
            nodeset = set

_cache = {}

#
# (Internal) Compile path.


def _compile(path):
    p = _cache.get(path)
    if p is not None:
        return p
    p = Path(path)
    if len(_cache) >= 100:
        _cache.clear()
    _cache[path] = p
    return p

#
# Find first matching object.


def find(element, path):
    return _compile(path).find(element)

#
# Find text for first matching object.


def findtext(element, path, default=None):
    return _compile(path).findtext(element, default)

#
# Find all matching objects.


def findall(element, path):
    return _compile(path).findall(element)

########NEW FILE########
__FILENAME__ = element_tree
#
# ElementTree
# $Id: ElementTree.py 2326 2005-03-17 07:45:21Z fredrik $
#
# light-weight XML support for Python 1.5.2 and later.
#
# history:
# 2001-10-20 fl   created (from various sources)
# 2001-11-01 fl   return root from parse method
# 2002-02-16 fl   sort attributes in lexical order
# 2002-04-06 fl   TreeBuilder refactoring, added PythonDoc markup
# 2002-05-01 fl   finished TreeBuilder refactoring
# 2002-07-14 fl   added basic namespace support to ElementTree.write
# 2002-07-25 fl   added QName attribute support
# 2002-10-20 fl   fixed encoding in write
# 2002-11-24 fl   changed default encoding to ascii; fixed attribute encoding
# 2002-11-27 fl   accept file objects or file names for parse/write
# 2002-12-04 fl   moved XMLTreeBuilder back to this module
# 2003-01-11 fl   fixed entity encoding glitch for us-ascii
# 2003-02-13 fl   added XML literal factory
# 2003-02-21 fl   added ProcessingInstruction/PI factory
# 2003-05-11 fl   added tostring/fromstring helpers
# 2003-05-26 fl   added ElementPath support
# 2003-07-05 fl   added makeelement factory method
# 2003-07-28 fl   added more well-known namespace prefixes
# 2003-08-15 fl   fixed typo in ElementTree.findtext (Thomas Dartsch)
# 2003-09-04 fl   fall back on emulator if ElementPath is not installed
# 2003-10-31 fl   markup updates
# 2003-11-15 fl   fixed nested namespace bug
# 2004-03-28 fl   added XMLID helper
# 2004-06-02 fl   added default support to findtext
# 2004-06-08 fl   fixed encoding of non-ascii element/attribute names
# 2004-08-23 fl   take advantage of post-2.1 expat features
# 2005-02-01 fl   added iterparse implementation
# 2005-03-02 fl   fixed iterparse support for pre-2.2 versions
# 2012-06-29 cevich@redhat.com Made all classes new-style
# 2012-07-02 cevich@redhat.com Include dist. ElementPath
# 2013-02-27 cevich@redhat.com renamed module files, kept namespace.
#
# Copyright (c) 1999-2005 by Fredrik Lundh.  All rights reserved.
#
# fredrik@pythonware.com
# http://www.pythonware.com
#
# --------------------------------------------------------------------
# The ElementTree toolkit is
#
# Copyright (c) 1999-2005 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

# Licensed to PSF under a Contributor Agreement.
# See http://www.python.org/2.4/license for licensing details.

__all__ = [
    # public symbols
    "Comment",
    "dump",
    "Element", "ElementTree",
    "fromstring",
    "iselement", "iterparse",
    "parse",
    "PI", "ProcessingInstruction",
    "QName",
    "SubElement",
    "tostring",
    "TreeBuilder",
    "VERSION", "XML",
    "XMLParser", "XMLTreeBuilder",
]

#
# The <b>Element</b> type is a flexible container object, designed to
# store hierarchical data structures in memory. The type can be
# described as a cross between a list and a dictionary.
# <p>
# Each element has a number of properties associated with it:
# <ul>
# <li>a <i>tag</i>. This is a string identifying what kind of data
# this element represents (the element type, in other words).</li>
# <li>a number of <i>attributes</i>, stored in a Python dictionary.</li>
# <li>a <i>text</i> string.</li>
# <li>an optional <i>tail</i> string.</li>
# <li>a number of <i>child elements</i>, stored in a Python sequence</li>
# </ul>
#
# To create an element instance, use the {@link #Element} or {@link
# SubElement} factory functions.
# <p>
# The {@link #ElementTree} class can be used to wrap an element
# structure, and convert it from and to XML.
#

import string
import sys
import re

try:
    import autotest.common as common
except ImportError:
    import common

try:
    # pylint: disable=E0611
    import autotest.client.shared.ElementPath as ElementPath
except ImportError:
    from virttest import element_path as ElementPath

# TODO: add support for custom namespace resolvers/default namespaces
# TODO: add improved support for incremental parsing

VERSION = "1.2.6b"

#
# Internal element class.  This class defines the Element interface,
# and provides a reference implementation of this interface.
# <p>
# You should not create instances of this class directly.  Use the
# appropriate factory functions instead, such as {@link #Element}
# and {@link #SubElement}.
#
# :see: Element
# :see: SubElement
# :see: Comment
# :see: ProcessingInstruction


class _ElementInterface(object):
    # <tag attrib>text<child/>...</tag>tail

    #
    # (Attribute) Element tag.

    tag = None

    #
    # (Attribute) Element attribute dictionary.  Where possible, use
    # {@link #_ElementInterface.get},
    # {@link #_ElementInterface.set},
    # {@link #_ElementInterface.keys}, and
    # {@link #_ElementInterface.items} to access
    # element attributes.

    attrib = None

    #
    # (Attribute) Text before first subelement.  This is either a
    # string or the value None, if there was no text.

    text = None

    #
    # (Attribute) Text after this element's end tag, but before the
    # next sibling element's start tag.  This is either a string or
    # the value None, if there was no text.

    tail = None  # text after end tag, if any

    def __init__(self, tag, attrib):
        self.tag = tag
        self.attrib = attrib
        self._children = []

    def __repr__(self):
        return "<Element %s at %x>" % (self.tag, id(self))

    #
    # Creates a new element object of the same type as this element.
    #
    # :param tag Element tag.
    # :param attrib Element attributes, given as a dictionary.
    # :return: A new element instance.

    def makeelement(self, tag, attrib):
        return Element(tag, attrib)

    #
    # Returns the number of subelements.
    #
    # :return: The number of subelements.

    def __len__(self):
        return len(self._children)

    #
    # Returns the given subelement.
    #
    # :param index What subelement to return.
    # :return: The given subelement.
    # @exception IndexError If the given element does not exist.

    def __getitem__(self, index):
        return self._children[index]

    #
    # Replaces the given subelement.
    #
    # :param index What subelement to replace.
    # :param element The new element value.
    # @exception IndexError If the given element does not exist.
    # @exception AssertionError If element is not a valid object.

    def __setitem__(self, index, element):
        assert iselement(element)
        self._children[index] = element

    #
    # Deletes the given subelement.
    #
    # :param index What subelement to delete.
    # @exception IndexError If the given element does not exist.

    def __delitem__(self, index):
        del self._children[index]

    #
    # Returns a list containing subelements in the given range.
    #
    # :param start The first subelement to return.
    # :param stop The first subelement that shouldn't be returned.
    # :return: A sequence object containing subelements.

    def __getslice__(self, start, stop):
        return self._children[start:stop]

    #
    # Replaces a number of subelements with elements from a sequence.
    #
    # :param start The first subelement to replace.
    # :param stop The first subelement that shouldn't be replaced.
    # :param elements A sequence object with zero or more elements.
    # @exception AssertionError If a sequence member is not a valid object.

    def __setslice__(self, start, stop, elements):
        for element in elements:
            assert iselement(element)
        self._children[start:stop] = list(elements)

    #
    # Deletes a number of subelements.
    #
    # :param start The first subelement to delete.
    # :param stop The first subelement to leave in there.

    def __delslice__(self, start, stop):
        del self._children[start:stop]

    #
    # Adds a subelement to the end of this element.
    #
    # :param element The element to add.
    # @exception AssertionError If a sequence member is not a valid object.

    def append(self, element):
        assert iselement(element)
        self._children.append(element)

    #
    # Inserts a subelement at the given position in this element.
    #
    # :param index Where to insert the new subelement.
    # @exception AssertionError If the element is not a valid object.

    def insert(self, index, element):
        assert iselement(element)
        self._children.insert(index, element)

    #
    # Removes a matching subelement.  Unlike the <b>find</b> methods,
    # this method compares elements based on identity, not on tag
    # value or contents.
    #
    # :param element What element to remove.
    # @exception ValueError If a matching element could not be found.
    # @exception AssertionError If the element is not a valid object.

    def remove(self, element):
        assert iselement(element)
        self._children.remove(element)

    #
    # Returns all subelements.  The elements are returned in document
    # order.
    #
    # :return: A list of subelements.
    # @defreturn list of Element instances

    def getchildren(self):
        return self._children

    #
    # Finds the first matching subelement, by tag name or path.
    #
    # :param path What element to look for.
    # :return: The first matching element, or None if no element was found.
    # @defreturn Element or None

    def find(self, path):
        return ElementPath.find(self, path)

    #
    # Finds text for the first matching subelement, by tag name or path.
    #
    # :param path What element to look for.
    # :param default What to return if the element was not found.
    # :return: The text content of the first matching element, or the
    #     default value no element was found.  Note that if the element
    #     has is found, but has no text content, this method returns an
    #     empty string.
    # @defreturn string

    def findtext(self, path, default=None):
        return ElementPath.findtext(self, path, default)

    #
    # Finds all matching subelements, by tag name or path.
    #
    # :param path What element to look for.
    # :return: A list or iterator containing all matching elements,
    #    in document order.
    # @defreturn list of Element instances

    def findall(self, path):
        return ElementPath.findall(self, path)

    #
    # Resets an element.  This function removes all subelements, clears
    # all attributes, and sets the text and tail attributes to None.

    def clear(self):
        self.attrib.clear()
        self._children = []
        self.text = self.tail = None

    #
    # Gets an element attribute.
    #
    # :param key What attribute to look for.
    # :param default What to return if the attribute was not found.
    # :return: The attribute value, or the default value, if the
    #     attribute was not found.
    # @defreturn string or None

    def get(self, key, default=None):
        return self.attrib.get(key, default)

    #
    # Sets an element attribute.
    #
    # :param key What attribute to set.
    # :param value The attribute value.

    def set(self, key, value):
        self.attrib[key] = value

    #
    # Gets a list of attribute names.  The names are returned in an
    # arbitrary order (just like for an ordinary Python dictionary).
    #
    # :return: A list of element attribute names.
    # @defreturn list of strings

    def keys(self):
        return self.attrib.keys()

    #
    # Gets element attributes, as a sequence.  The attributes are
    # returned in an arbitrary order.
    #
    # :return: A list of (name, value) tuples for all attributes.
    # @defreturn list of (string, string) tuples

    def items(self):
        return self.attrib.items()

    #
    # Creates a tree iterator.  The iterator loops over this element
    # and all subelements, in document order, and returns all elements
    # with a matching tag.
    # <p>
    # If the tree structure is modified during iteration, the result
    # is undefined.
    #
    # :param tag What tags to look for (default is to return all elements).
    # :return: A list or iterator containing all the matching elements.
    # @defreturn list or iterator

    def getiterator(self, tag=None):
        nodes = []
        if tag == "*":
            tag = None
        if tag is None or self.tag == tag:
            nodes.append(self)
        for node in self._children:
            nodes.extend(node.getiterator(tag))
        return nodes

# compatibility
_Element = _ElementInterface

#
# Element factory.  This function returns an object implementing the
# standard Element interface.  The exact class or type of that object
# is implementation dependent, but it will always be compatible with
# the {@link #_ElementInterface} class in this module.
# <p>
# The element name, attribute names, and attribute values can be
# either 8-bit ASCII strings or Unicode strings.
#
# :param tag The element name.
# :param attrib An optional dictionary, containing element attributes.
# :param **extra Additional attributes, given as keyword arguments.
# :return: An element instance.
# @defreturn Element


def Element(tag, attrib={}, **extra):
    attrib = attrib.copy()
    attrib.update(extra)
    return _ElementInterface(tag, attrib)

#
# Subelement factory.  This function creates an element instance, and
# appends it to an existing element.
# <p>
# The element name, attribute names, and attribute values can be
# either 8-bit ASCII strings or Unicode strings.
#
# :param parent The parent element.
# :param tag The subelement name.
# :param attrib An optional dictionary, containing element attributes.
# :param **extra Additional attributes, given as keyword arguments.
# :return: An element instance.
# @defreturn Element


def SubElement(parent, tag, attrib={}, **extra):
    attrib = attrib.copy()
    attrib.update(extra)
    element = parent.makeelement(tag, attrib)
    parent.append(element)
    return element

#
# Comment element factory.  This factory function creates a special
# element that will be serialized as an XML comment.
# <p>
# The comment string can be either an 8-bit ASCII string or a Unicode
# string.
#
# :param text A string containing the comment string.
# :return: An element instance, representing a comment.
# @defreturn Element


def Comment(text=None):
    element = Element(Comment)
    element.text = text
    return element

#
# PI element factory.  This factory function creates a special element
# that will be serialized as an XML processing instruction.
#
# :param target A string containing the PI target.
# :param text A string containing the PI contents, if any.
# :return: An element instance, representing a PI.
# @defreturn Element


def ProcessingInstruction(target, text=None):
    element = Element(ProcessingInstruction)
    element.text = target
    if text:
        element.text = element.text + " " + text
    return element

PI = ProcessingInstruction

#
# QName wrapper.  This can be used to wrap a QName attribute value, in
# order to get proper namespace handling on output.
#
# :param text A string containing the QName value, in the form {uri}local,
#     or, if the tag argument is given, the URI part of a QName.
# :param tag Optional tag.  If given, the first argument is interpreted as
#     an URI, and this argument is interpreted as a local name.
# :return: An opaque object, representing the QName.


class QName(object):

    def __init__(self, text_or_uri, tag=None):
        if tag:
            text_or_uri = "{%s}%s" % (text_or_uri, tag)
        self.text = text_or_uri

    def __str__(self):
        return self.text

    def __hash__(self):
        return hash(self.text)

    def __cmp__(self, other):
        if isinstance(other, QName):
            return cmp(self.text, other.text)
        return cmp(self.text, other)

#
# ElementTree wrapper class.  This class represents an entire element
# hierarchy, and adds some extra support for serialization to and from
# standard XML.
#
# :param element Optional root element.
# @keyparam file Optional file handle or name.  If given, the
#     tree is initialized with the contents of this XML file.


class ElementTree(object):

    def __init__(self, element=None, file=None):
        assert element is None or iselement(element)
        self._root = element  # first node
        if file:
            self.parse(file)

    #
    # Gets the root element for this tree.
    #
    # :return: An element instance.
    # @defreturn Element

    def getroot(self):
        return self._root

    #
    # Replaces the root element for this tree.  This discards the
    # current contents of the tree, and replaces it with the given
    # element.  Use with care.
    #
    # :param element An element instance.

    def _setroot(self, element):
        assert iselement(element)
        self._root = element

    #
    # Loads an external XML document into this element tree.
    #
    # :param source A file name or file object.
    # :param parser An optional parser instance.  If not given, the
    #     standard {@link XMLTreeBuilder} parser is used.
    # :return: The document root element.
    # @defreturn Element

    def parse(self, source, parser=None):
        if not hasattr(source, "read"):
            source = open(source, "rb")
        if not parser:
            parser = XMLTreeBuilder()
        while 1:
            data = source.read(32768)
            if not data:
                break
            parser.feed(data)
        self._root = parser.close()
        return self._root

    #
    # Creates a tree iterator for the root element.  The iterator loops
    # over all elements in this tree, in document order.
    #
    # :param tag What tags to look for (default is to return all elements)
    # :return: An iterator.
    # @defreturn iterator

    def getiterator(self, tag=None):
        assert self._root is not None
        return self._root.getiterator(tag)

    #
    # Finds the first toplevel element with given tag.
    # Same as getroot().find(path).
    #
    # :param path What element to look for.
    # :return: The first matching element, or None if no element was found.
    # @defreturn Element or None

    def find(self, path):
        assert self._root is not None
        if path[:1] == "/":
            path = "." + path
        return self._root.find(path)

    #
    # Finds the element text for the first toplevel element with given
    # tag.  Same as getroot().findtext(path).
    #
    # :param path What toplevel element to look for.
    # :param default What to return if the element was not found.
    # :return: The text content of the first matching element, or the
    #     default value no element was found.  Note that if the element
    #     has is found, but has no text content, this method returns an
    #     empty string.
    # @defreturn string

    def findtext(self, path, default=None):
        assert self._root is not None
        if path[:1] == "/":
            path = "." + path
        return self._root.findtext(path, default)

    #
    # Finds all toplevel elements with the given tag.
    # Same as getroot().findall(path).
    #
    # :param path What element to look for.
    # :return: A list or iterator containing all matching elements,
    #    in document order.
    # @defreturn list of Element instances

    def findall(self, path):
        assert self._root is not None
        if path[:1] == "/":
            path = "." + path
        return self._root.findall(path)

    #
    # Writes the element tree to a file, as XML.
    #
    # :param file A file name, or a file object opened for writing.
    # :param encoding Optional output encoding (default is US-ASCII).

    def write(self, file, encoding="us-ascii"):
        assert self._root is not None
        if not hasattr(file, "write"):
            file = open(file, "wb")
        if not encoding:
            encoding = "us-ascii"
        elif encoding != "utf-8" and encoding != "us-ascii":
            file.write("<?xml version='1.0' encoding='%s'?>\n" % encoding)
        self._write(file, self._root, encoding, {})

    def _write(self, file, node, encoding, namespaces):
        # write XML to file
        tag = node.tag
        if tag is Comment:
            file.write("<!-- %s -->" % _escape_cdata(node.text, encoding))
        elif tag is ProcessingInstruction:
            file.write("<?%s?>" % _escape_cdata(node.text, encoding))
        else:
            items = node.items()
            xmlns_items = []  # new namespaces in this scope
            try:
                if isinstance(tag, QName) or tag[:1] == "{":
                    tag, xmlns = fixtag(tag, namespaces)
                    if xmlns:
                        xmlns_items.append(xmlns)
            except TypeError:
                _raise_serialization_error(tag)
            file.write("<" + _encode(tag, encoding))
            if items or xmlns_items:
                items.sort()  # lexical order
                for k, v in items:
                    try:
                        if isinstance(k, QName) or k[:1] == "{":
                            k, xmlns = fixtag(k, namespaces)
                            if xmlns:
                                xmlns_items.append(xmlns)
                    except TypeError:
                        _raise_serialization_error(k)
                    try:
                        if isinstance(v, QName):
                            v, xmlns = fixtag(v, namespaces)
                            if xmlns:
                                xmlns_items.append(xmlns)
                    except TypeError:
                        _raise_serialization_error(v)
                    file.write(" %s=\"%s\"" % (_encode(k, encoding),
                                               _escape_attrib(v, encoding)))
                for k, v in xmlns_items:
                    file.write(" %s=\"%s\"" % (_encode(k, encoding),
                                               _escape_attrib(v, encoding)))
            if node.text or len(node):
                file.write(">")
                if node.text:
                    file.write(_escape_cdata(node.text, encoding))
                for n in node:
                    self._write(file, n, encoding, namespaces)
                file.write("</" + _encode(tag, encoding) + ">")
            else:
                file.write(" />")
            for k, v in xmlns_items:
                del namespaces[v]
        if node.tail:
            file.write(_escape_cdata(node.tail, encoding))

# --------------------------------------------------------------------
# helpers

#
# Checks if an object appears to be a valid element object.
#
# :param An element instance.
# :return: A true value if this is an element object.
# @defreturn flag


def iselement(element):
    # FIXME: not sure about this; might be a better idea to look
    # for tag/attrib/text attributes
    return isinstance(element, _ElementInterface) or hasattr(element, "tag")

#
# Writes an element tree or element structure to sys.stdout.  This
# function should be used for debugging only.
# <p>
# The exact output format is implementation dependent.  In this
# version, it's written as an ordinary XML file.
#
# :param elem An element tree or an individual element.


def dump(elem):
    # debugging
    if not isinstance(elem, ElementTree):
        elem = ElementTree(elem)
    elem.write(sys.stdout)
    tail = elem.getroot().tail
    if not tail or tail[-1] != "\n":
        sys.stdout.write("\n")


def _encode(s, encoding):
    try:
        return s.encode(encoding)
    except AttributeError:
        return s  # 1.5.2: assume the string uses the right encoding

if sys.version[:3] == "1.5":
    _escape = re.compile(r"[&<>\"\x80-\xff]+")  # 1.5.2
else:
    _escape = re.compile(eval(r'u"[&<>\"\u0080-\uffff]+"'))

_escape_map = {
    "&": "&amp;",
    "<": "&lt;",
    ">": "&gt;",
    '"': "&quot;",
}

_namespace_map = {
    # "well-known" namespace prefixes
    "http://www.w3.org/XML/1998/namespace": "xml",
    "http://www.w3.org/1999/xhtml": "html",
    "http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
    "http://schemas.xmlsoap.org/wsdl/": "wsdl",
}


def _raise_serialization_error(text):
    raise TypeError(
        "cannot serialize %r (type %s)" % (text, type(text).__name__)
    )


def _encode_entity(text, pattern=_escape):
    # map reserved and non-ascii characters to numerical entities
    def escape_entities(m, map=_escape_map):
        out = []
        append = out.append
        for char in m.group():
            text = map.get(char)
            if text is None:
                text = "&#%d;" % ord(char)
            append(text)
        return string.join(out, "")
    try:
        return _encode(pattern.sub(escape_entities, text), "ascii")
    except TypeError:
        _raise_serialization_error(text)

#
# the following functions assume an ascii-compatible encoding
# (or "utf-16")


def _escape_cdata(text, encoding=None, replace=string.replace):
    # escape character data
    try:
        if encoding:
            try:
                text = _encode(text, encoding)
            except UnicodeError:
                return _encode_entity(text)
        text = replace(text, "&", "&amp;")
        text = replace(text, "<", "&lt;")
        text = replace(text, ">", "&gt;")
        return text
    except (TypeError, AttributeError):
        _raise_serialization_error(text)


def _escape_attrib(text, encoding=None, replace=string.replace):
    # escape attribute value
    try:
        if encoding:
            try:
                text = _encode(text, encoding)
            except UnicodeError:
                return _encode_entity(text)
        text = replace(text, "&", "&amp;")
        text = replace(text, "'", "&apos;")  # FIXME: overkill
        text = replace(text, "\"", "&quot;")
        text = replace(text, "<", "&lt;")
        text = replace(text, ">", "&gt;")
        return text
    except (TypeError, AttributeError):
        _raise_serialization_error(text)


def fixtag(tag, namespaces):
    # given a decorated tag (of the form {uri}tag), return prefixed
    # tag and namespace declaration, if any
    if isinstance(tag, QName):
        tag = tag.text
    namespace_uri, tag = string.split(tag[1:], "}", 1)
    prefix = namespaces.get(namespace_uri)
    if prefix is None:
        prefix = _namespace_map.get(namespace_uri)
        if prefix is None:
            prefix = "ns%d" % len(namespaces)
        namespaces[namespace_uri] = prefix
        if prefix == "xml":
            xmlns = None
        else:
            xmlns = ("xmlns:%s" % prefix, namespace_uri)
    else:
        xmlns = None
    return "%s:%s" % (prefix, tag), xmlns

#
# Parses an XML document into an element tree.
#
# :param source A filename or file object containing XML data.
# :param parser An optional parser instance.  If not given, the
#     standard {@link XMLTreeBuilder} parser is used.
# :return: An ElementTree instance


def parse(source, parser=None):
    tree = ElementTree()
    tree.parse(source, parser)
    return tree

#
# Parses an XML document into an element tree incrementally, and reports
# what's going on to the user.
#
# :param source A filename or file object containing XML data.
# :param events A list of events to report back.  If omitted, only "end"
#     events are reported.
# :return: A (event, elem) iterator.


class iterparse(object):

    def __init__(self, source, events=None):
        if not hasattr(source, "read"):
            source = open(source, "rb")
        self._file = source
        self._events = []
        self._index = 0
        self.root = self._root = None
        self._parser = XMLTreeBuilder()
        # wire up the parser for event reporting
        parser = self._parser._parser
        append = self._events.append
        if events is None:
            events = ["end"]
        for event in events:
            if event == "start":
                try:
                    parser.ordered_attributes = 1
                    parser.specified_attributes = 1

                    def handler(tag, attrib_in, event=event, append=append,
                                start=self._parser._start_list):
                        append((event, start(tag, attrib_in)))
                    parser.StartElementHandler = handler
                except AttributeError:
                    def handler(tag, attrib_in, event=event, append=append,
                                start=self._parser._start):
                        append((event, start(tag, attrib_in)))
                    parser.StartElementHandler = handler
            elif event == "end":
                def handler(tag, event=event, append=append,
                            end=self._parser._end):
                    append((event, end(tag)))
                parser.EndElementHandler = handler
            elif event == "start-ns":
                def handler(prefix, uri, event=event, append=append):
                    try:
                        uri = _encode(uri, "ascii")
                    except UnicodeError:
                        pass
                    append((event, (prefix or "", uri)))
                parser.StartNamespaceDeclHandler = handler
            elif event == "end-ns":
                def handler(prefix, event=event, append=append):
                    append((event, None))
                parser.EndNamespaceDeclHandler = handler

    def next(self):
        while 1:
            try:
                item = self._events[self._index]
            except IndexError:
                if self._parser is None:
                    self.root = self._root
                    try:
                        raise StopIteration
                    except NameError:
                        raise IndexError
                # load event buffer
                del self._events[:]
                self._index = 0
                data = self._file.read(16384)
                if data:
                    self._parser.feed(data)
                else:
                    self._root = self._parser.close()
                    self._parser = None
            else:
                self._index = self._index + 1
                return item

    try:
        iter

        def __iter__(self):
            return self
    except NameError:
        def __getitem__(self, index):
            return self.next()

#
# Parses an XML document from a string constant.  This function can
# be used to embed "XML literals" in Python code.
#
# :param source A string containing XML data.
# :return: An Element instance.
# @defreturn Element


def XML(text):
    parser = XMLTreeBuilder()
    parser.feed(text)
    return parser.close()

#
# Parses an XML document from a string constant, and also returns
# a dictionary which maps from element id:s to elements.
#
# :param source A string containing XML data.
# :return: A tuple containing an Element instance and a dictionary.
# @defreturn (Element, dictionary)


def XMLID(text):
    parser = XMLTreeBuilder()
    parser.feed(text)
    tree = parser.close()
    ids = {}
    for elem in tree.getiterator():
        id = elem.get("id")
        if id:
            ids[id] = elem
    return tree, ids

#
# Parses an XML document from a string constant.  Same as {@link #XML}.
#
# @def fromstring(text)
# :param source A string containing XML data.
# :return: An Element instance.
# @defreturn Element

fromstring = XML

#
# Generates a string representation of an XML element, including all
# subelements.
#
# :param element An Element instance.
# :return: An encoded string containing the XML data.
# @defreturn string


def tostring(element, encoding=None):
    class dummy(object):
        pass
    data = []
    file = dummy()
    file.write = data.append
    ElementTree(element).write(file, encoding)
    return string.join(data, "")

#
# Generic element structure builder.  This builder converts a sequence
# of {@link #TreeBuilder.start}, {@link #TreeBuilder.data}, and {@link
# TreeBuilder.end} method calls to a well-formed element structure.
# <p>
# You can use this class to build an element structure using a custom XML
# parser, or a parser for some other XML-like format.
#
# :param element_factory Optional element factory.  This factory
#    is called to create new Element instances, as necessary.


class TreeBuilder(object):

    def __init__(self, element_factory=None):
        self._data = []  # data collector
        self._elem = []  # element stack
        self._last = None  # last element
        self._tail = None  # true if we're after an end tag
        if element_factory is None:
            element_factory = _ElementInterface
        self._factory = element_factory

    #
    # Flushes the parser buffers, and returns the toplevel documen
    # element.
    #
    # :return: An Element instance.
    # @defreturn Element

    def close(self):
        assert len(self._elem) == 0, "missing end tags"
        assert self._last is not None, "missing toplevel element"
        return self._last

    def _flush(self):
        if self._data:
            if self._last is not None:
                text = string.join(self._data, "")
                if self._tail:
                    assert self._last.tail is None, "internal error (tail)"
                    self._last.tail = text
                else:
                    assert self._last.text is None, "internal error (text)"
                    self._last.text = text
            self._data = []

    #
    # Adds text to the current element.
    #
    # :param data A string.  This should be either an 8-bit string
    #    containing ASCII text, or a Unicode string.

    def data(self, data):
        self._data.append(data)

    #
    # Opens a new element.
    #
    # :param tag The element name.
    # :param attrib A dictionary containing element attributes.
    # :return: The opened element.
    # @defreturn Element

    def start(self, tag, attrs):
        self._flush()
        self._last = elem = self._factory(tag, attrs)
        if self._elem:
            self._elem[-1].append(elem)
        self._elem.append(elem)
        self._tail = 0
        return elem

    #
    # Closes the current element.
    #
    # :param tag The element name.
    # :return: The closed element.
    # @defreturn Element

    def end(self, tag):
        self._flush()
        self._last = self._elem.pop()
        assert self._last.tag == tag,\
            "end tag mismatch (expected %s, got %s)" % (
                self._last.tag, tag)
        self._tail = 1
        return self._last

#
# Element structure builder for XML source data, based on the
# <b>expat</b> parser.
#
# @keyparam target Target object.  If omitted, the builder uses an
# instance of the standard {@link #TreeBuilder} class.
# @keyparam html Predefine HTML entities.  This flag is not supported
#     by the current implementation.
# :see: #ElementTree
# :see: #TreeBuilder


class XMLTreeBuilder(object):

    def __init__(self, html=0, target=None):
        try:
            from xml.parsers import expat
        except ImportError:
            raise ImportError(
                "No module named expat; use SimpleXMLTreeBuilder instead"
            )
        self._parser = parser = expat.ParserCreate(None, "}")
        if target is None:
            target = TreeBuilder()
        self._target = target
        self._names = {}  # name memo cache
        # callbacks
        parser.DefaultHandlerExpand = self._default
        parser.StartElementHandler = self._start
        parser.EndElementHandler = self._end
        parser.CharacterDataHandler = self._data
        # let expat do the buffering, if supported
        try:
            self._parser.buffer_text = 1
        except AttributeError:
            pass
        # use new-style attribute handling, if supported
        try:
            self._parser.ordered_attributes = 1
            self._parser.specified_attributes = 1
            parser.StartElementHandler = self._start_list
        except AttributeError:
            pass
        encoding = None
        if not parser.returns_unicode:
            encoding = "utf-8"
        # target.xml(encoding, None)
        self._doctype = None
        self.entity = {}

    def _fixtext(self, text):
        # convert text string to ascii, if possible
        try:
            return _encode(text, "ascii")
        except UnicodeError:
            return text

    def _fixname(self, key):
        # expand qname, and convert name string to ascii, if possible
        try:
            name = self._names[key]
        except KeyError:
            name = key
            if "}" in name:
                name = "{" + name
            self._names[key] = name = self._fixtext(name)
        return name

    def _start(self, tag, attrib_in):
        fixname = self._fixname
        tag = fixname(tag)
        attrib = {}
        for key, value in attrib_in.items():
            attrib[fixname(key)] = self._fixtext(value)
        return self._target.start(tag, attrib)

    def _start_list(self, tag, attrib_in):
        fixname = self._fixname
        tag = fixname(tag)
        attrib = {}
        if attrib_in:
            for i in range(0, len(attrib_in), 2):
                attrib[fixname(attrib_in[i])] = self._fixtext(attrib_in[i + 1])
        return self._target.start(tag, attrib)

    def _data(self, text):
        return self._target.data(self._fixtext(text))

    def _end(self, tag):
        return self._target.end(self._fixname(tag))

    def _default(self, text):
        prefix = text[:1]
        if prefix == "&":
            # deal with undefined entities
            try:
                self._target.data(self.entity[text[1:-1]])
            except KeyError:
                from xml.parsers import expat
                raise expat.error(
                    "undefined entity %s: line %d, column %d" %
                    (text, self._parser.ErrorLineNumber,
                     self._parser.ErrorColumnNumber)
                )
        elif prefix == "<" and text[:9] == "<!DOCTYPE":
            self._doctype = []  # inside a doctype declaration
        elif self._doctype is not None:
            # parse doctype contents
            if prefix == ">":
                self._doctype = None
                return
            text = string.strip(text)
            if not text:
                return
            self._doctype.append(text)
            n = len(self._doctype)
            if n > 2:
                type = self._doctype[1]
                if type == "PUBLIC" and n == 4:
                    name, type, pubid, system = self._doctype
                elif type == "SYSTEM" and n == 3:
                    name, type, system = self._doctype
                    pubid = None
                else:
                    return
                if pubid:
                    pubid = pubid[1:-1]
                self.doctype(name, pubid, system[1:-1])
                self._doctype = None

    #
    # Handles a doctype declaration.
    #
    # :param name Doctype name.
    # :param pubid Public identifier.
    # :param system System identifier.

    def doctype(self, name, pubid, system):
        pass

    #
    # Feeds data to the parser.
    #
    # :param data Encoded data.

    def feed(self, data):
        self._parser.Parse(data, 0)

    #
    # Finishes feeding data to the parser.
    #
    # :return: An element structure.
    # @defreturn Element

    def close(self):
        self._parser.Parse("", 1)  # end of data
        tree = self._target.close()
        del self._target, self._parser  # get rid of circular references
        return tree

# compatibility
XMLParser = XMLTreeBuilder

########NEW FILE########
__FILENAME__ = env_process
import os
import time
import commands
import re
import logging
import glob
import threading
import shutil
import sys
import copy
from autotest.client import utils
from autotest.client.shared import error
import aexpect
import qemu_monitor
import ppm_utils
import test_setup
import virt_vm
import video_maker
import utils_misc
import storage
import qemu_storage
import utils_libvirtd
import remote
import data_dir
import utils_net
import utils_disk
import nfs
from autotest.client import local_host


try:
    import PIL.Image
except ImportError:
    logging.warning('No python imaging library installed. PPM image '
                    'conversion to JPEG disabled. In order to enable it, '
                    'please install python-imaging or the equivalent for your '
                    'distro.')

_screendump_thread = None
_screendump_thread_termination_event = None

_vm_register_thread = None
_vm_register_thread_termination_event = None


def preprocess_image(test, params, image_name, vm_process_status=None):
    """
    Preprocess a single QEMU image according to the instructions in params.

    :param test: Autotest test object.
    :param params: A dict containing image preprocessing parameters.
    :param vm_process_status: This is needed in postprocess_image. Add it here
                              only for keep it work with process_images()
    :note: Currently this function just creates an image if requested.
    """
    base_dir = params.get("images_base_dir", data_dir.get_data_dir())

    if not storage.preprocess_image_backend(base_dir, params, image_name):
        logging.error("Backend can't be prepared correctly.")

    image_filename = storage.get_image_filename(params,
                                                base_dir)

    create_image = False
    if params.get("force_create_image") == "yes":
        create_image = True
    elif (params.get("create_image") == "yes" and not
          storage.file_exists(params, image_filename)):
        create_image = True

    if params.get("backup_image_before_testing", "no") == "yes":
        image = qemu_storage.QemuImg(params, base_dir, image_name)
        image.backup_image(params, base_dir, "backup", True, True)
    if create_image:
        image = qemu_storage.QemuImg(params, base_dir, image_name)
        image.create(params)


def preprocess_vm(test, params, env, name):
    """
    Preprocess a single VM object according to the instructions in params.
    Start the VM if requested and get a screendump.

    :param test: An Autotest test object.
    :param params: A dict containing VM preprocessing parameters.
    :param env: The environment (a dict-like object).
    :param name: The name of the VM object.
    """
    vm = env.get_vm(name)
    vm_type = params.get('vm_type')
    target = params.get('target')
    if not vm:
        vm = env.create_vm(vm_type, target, name, params, test.bindir)
    old_vm = copy.copy(vm)

    remove_vm = False
    if params.get("force_remove_vm") == "yes":
        remove_vm = True

    if remove_vm:
        vm.remove()

    start_vm = False
    update_virtnet = False
    gracefully_kill = params.get("kill_vm_gracefully") == "yes"

    if params.get("migration_mode"):
        start_vm = True
    elif params.get("start_vm") == "yes":
        # need to deal with libvirt VM differently than qemu
        if vm_type == 'libvirt' or vm_type == 'v2v':
            if not vm.is_alive():
                start_vm = True
        else:
            if not vm.is_alive():
                start_vm = True
            if params.get("check_vm_needs_restart", "yes") == "yes":
                if vm.needs_restart(name=name,
                                    params=params,
                                    basedir=test.bindir):
                    vm.devices = None
                    start_vm = True
                    old_vm.destroy(gracefully=gracefully_kill)
                    update_virtnet = True

    if start_vm:
        if vm_type == "libvirt" and params.get("type") != "unattended_install":
            vm.params = params
            vm.start()
        elif vm_type == "v2v":
            vm.params = params
            vm.start()
        else:
            if update_virtnet:
                vm.update_vm_id()
                vm.virtnet = utils_net.VirtNet(params, name, vm.instance)
            # Start the VM (or restart it if it's already up)
            if params.get("reuse_previous_config", "no") == "no":
                vm.create(name, params, test.bindir,
                          migration_mode=params.get("migration_mode"),
                          migration_fd=params.get("migration_fd"),
                          migration_exec_cmd=params.get("migration_exec_cmd_dst"))
            else:
                vm.create(migration_mode=params.get("migration_mode"),
                          migration_fd=params.get("migration_fd"),
                          migration_exec_cmd=params.get("migration_exec_cmd_dst"))
    elif not vm.is_alive():    # VM is dead and won't be started, update params
        vm.devices = None
        vm.params = params
    else:       # VM is alive and we don't care
        if params.get("kill_vm_before_test") == "yes":
            # Destroy the VM if kill_vm_before_test = "yes".
            old_vm.destroy(gracefully=gracefully_kill)
        else:
            # VM is alive and we just need to open the serial console
            vm.create_serial_console()

    pause_vm = False

    if params.get("paused_after_start_vm") == "yes":
        pause_vm = True
        # Check the status of vm
        if (not vm.is_alive()) or (vm.is_paused()):
            pause_vm = False

    if pause_vm:
        vm.pause()


def postprocess_image(test, params, image_name, vm_process_status=None):
    """
    Postprocess a single QEMU image according to the instructions in params.

    :param test: An Autotest test object.
    :param params: A dict containing image postprocessing parameters.
    :param vm_process_status: (optional) vm process status like running, dead
                              or None for no vm exist.
    """
    clone_master = params.get("clone_master", None)
    base_dir = data_dir.get_data_dir()
    image = qemu_storage.QemuImg(params, base_dir, image_name)

    check_image_flag = params.get("check_image") == "yes"
    if vm_process_status == "running" and check_image_flag:
        if params.get("skip_image_check_during_running") == "yes":
            logging.debug("Guest is still running, skip the image check.")
            check_image_flag = False
        else:
            image_info_output = image.info()
            image_info = {}
            for image_info_item in image_info_output.splitlines():
                option = image_info_item.split(":")
                if len(option) == 2:
                    image_info[option[0].strip()] = option[1].strip()
            if ("lazy refcounts" in image_info
                    and image_info["lazy refcounts"] == "true"):
                logging.debug("Should not check image while guest is alive"
                              " when the image is create with lazy refcounts."
                              " Skip the image check.")
                check_image_flag = False

    if check_image_flag:
        try:
            if clone_master is None:
                image.check_image(params, base_dir)
            elif clone_master == "yes":
                if image_name in params.get("master_images_clone").split():
                    image.check_image(params, base_dir)
            # Allow test to overwrite any pre-testing  automatic backup
            # with a new backup. i.e. assume pre-existing image/backup
            # would not be usable after this test succeeds. The best
            # example for this is when 'unattended_install' is run.
            if params.get("backup_image", "no") == "yes":
                image.backup_image(params, base_dir, "backup", True)
            elif params.get("restore_image", "no") == "yes":
                image.backup_image(params, base_dir, "restore", True)
        except Exception, e:
            if params.get("restore_image_on_check_error", "no") == "yes":
                image.backup_image(params, base_dir, "restore", True)
            if params.get("remove_image_on_check_error", "no") == "yes":
                cl_images = params.get("master_images_clone", "")
                if image_name in cl_images.split():
                    image.remove()
            if (params.get("skip_cluster_leak_warn") == "yes"
                    and "Leaked clusters" in e.message):
                logging.warn(e.message)
            else:
                raise e
    if params.get("restore_image_after_testing", "no") == "yes":
        image.backup_image(params, base_dir, "restore", True)
    if params.get("remove_image") == "yes":
        if clone_master is None:
            image.remove()
        elif clone_master == "yes":
            if image_name in params.get("master_images_clone").split():
                image.remove()


def postprocess_vm(test, params, env, name):
    """
    Postprocess a single VM object according to the instructions in params.
    Kill the VM if requested and get a screendump.

    :param test: An Autotest test object.
    :param params: A dict containing VM postprocessing parameters.
    :param env: The environment (a dict-like object).
    :param name: The name of the VM object.
    """
    vm = env.get_vm(name)
    if not vm:
        return

    # Close all SSH sessions that might be active to this VM
    for s in vm.remote_sessions[:]:
        try:
            s.close()
            vm.remote_sessions.remove(s)
        except Exception:
            pass

    if params.get("kill_vm") == "yes":
        kill_vm_timeout = float(params.get("kill_vm_timeout", 0))
        if kill_vm_timeout:
            utils_misc.wait_for(vm.is_dead, kill_vm_timeout, 0, 1)
        vm.destroy(gracefully=params.get("kill_vm_gracefully") == "yes")


def process_command(test, params, env, command, command_timeout,
                    command_noncritical):
    """
    Pre- or post- custom commands to be executed before/after a test is run

    :param test: An Autotest test object.
    :param params: A dict containing all VM and image parameters.
    :param env: The environment (a dict-like object).
    :param command: Command to be run.
    :param command_timeout: Timeout for command execution.
    :param command_noncritical: If True test will not fail if command fails.
    """
    # Export environment vars
    for k in params:
        os.putenv("KVM_TEST_%s" % k, str(params[k]))
    # Execute commands
    try:
        utils.system("cd %s; %s" % (test.bindir, command))
    except error.CmdError, e:
        if command_noncritical:
            logging.warn(e)
        else:
            raise


class _CreateImages(threading.Thread):

    """
    Thread which creates images. In case of failure it stores the exception
    in self.exc_info
    """

    def __init__(self, image_func, test, images, params, exit_event,
                 vm_process_status):
        threading.Thread.__init__(self)
        self.image_func = image_func
        self.test = test
        self.images = images
        self.params = params
        self.exit_event = exit_event
        self.exc_info = None
        self.vm_process_status = vm_process_status

    def run(self):
        try:
            _process_images_serial(self.image_func, self.test, self.images,
                                   self.params, self.exit_event,
                                   self.vm_process_status)
        except Exception:
            self.exc_info = sys.exc_info()
            self.exit_event.set()


def process_images(image_func, test, params, vm_process_status=None):
    """
    Wrapper which chooses the best way to process images.

    :param image_func: Process function
    :param test: An Autotest test object.
    :param params: A dict containing all VM and image parameters.
    :param vm_process_status: (optional) vm process status like running, dead
                              or None for no vm exist.
    """
    images = params.objects("images")
    if len(images) > 20:    # Lets do it in parallel
        _process_images_parallel(image_func, test, params,
                                 vm_process_status=vm_process_status)
    else:
        _process_images_serial(image_func, test, images, params,
                               vm_process_status=vm_process_status)


def _process_images_serial(image_func, test, images, params, exit_event=None,
                           vm_process_status=None):
    """
    Original process_image function, which allows custom set of images
    :param image_func: Process function
    :param test: An Autotest test object.
    :param images: List of images (usually params.objects("images"))
    :param params: A dict containing all VM and image parameters.
    :param exit_event: (optional) exit event which interrupts the processing
    :param vm_process_status: (optional) vm process status like running, dead
                              or None for no vm exist.
    """
    for image_name in images:
        image_params = params.object_params(image_name)
        image_func(test, image_params, image_name, vm_process_status)
        if exit_event and exit_event.is_set():
            logging.error("Received exit_event, stop processing of images.")
            break


def _process_images_parallel(image_func, test, params, vm_process_status=None):
    """
    The same as _process_images but in parallel.
    :param image_func: Process function
    :param test: An Autotest test object.
    :param params: A dict containing all VM and image parameters.
    :param vm_process_status: (optional) vm process status like running, dead
                              or None for no vm exist.
    """
    images = params.objects("images")
    no_threads = min(len(images) / 5,
                     2 * local_host.LocalHost().get_num_cpu())
    exit_event = threading.Event()
    threads = []
    for i in xrange(no_threads):
        imgs = images[i::no_threads]
        threads.append(_CreateImages(image_func, test, imgs, params,
                                     exit_event, vm_process_status))
        threads[-1].start()
    finished = False
    while not finished:
        finished = True
        for thread in threads:
            if thread.is_alive():
                finished = False
                time.sleep(0.5)
                break
    if exit_event.is_set():     # Failure in some thread
        logging.error("Image processing failed:")
        for thread in threads:
            if thread.exc_info:     # Throw the first failure
                raise thread.exc_info[1], None, thread.exc_info[2]
    del exit_event
    del threads[:]


def process(test, params, env, image_func, vm_func, vm_first=False):
    """
    Pre- or post-process VMs and images according to the instructions in params.
    Call image_func for each image listed in params and vm_func for each VM.

    :param test: An Autotest test object.
    :param params: A dict containing all VM and image parameters.
    :param env: The environment (a dict-like object).
    :param image_func: A function to call for each image.
    :param vm_func: A function to call for each VM.
    :param vm_first: Call vm_func first or not.
    """
    def _call_vm_func():
        for vm_name in params.objects("vms"):
            vm_params = params.object_params(vm_name)
            vm_func(test, vm_params, env, vm_name)

    def _call_image_func():
        if params.get("skip_image_processing") == "yes":
            return

        if params.objects("vms"):
            for vm_name in params.objects("vms"):
                vm_params = params.object_params(vm_name)
                vm = env.get_vm(vm_name)
                unpause_vm = False
                if vm is None or vm.is_dead():
                    vm_process_status = 'dead'
                else:
                    vm_process_status = 'running'
                if vm is not None and vm.is_alive() and not vm.is_paused():
                    vm.pause()
                    unpause_vm = True
                    vm_params['skip_cluster_leak_warn'] = "yes"
                try:
                    process_images(image_func, test, vm_params,
                                   vm_process_status)
                finally:
                    if unpause_vm:
                        vm.resume()
        else:
            process_images(image_func, test, params)

    if not vm_first:
        _call_image_func()

    _call_vm_func()

    if vm_first:
        _call_image_func()


@error.context_aware
def preprocess(test, params, env):
    """
    Preprocess all VMs and images according to the instructions in params.
    Also, collect some host information, such as the KVM version.

    :param test: An Autotest test object.
    :param params: A dict containing all VM and image parameters.
    :param env: The environment (a dict-like object).
    """
    error.context("preprocessing")
    # First, let's verify if this test does require root or not. If it
    # does and the test suite is running as a regular user, we shall just
    # throw a TestNAError exception, which will skip the test.
    if params.get('requires_root', 'no') == 'yes':
        utils_misc.verify_running_as_root()

    port = params.get('shell_port')
    prompt = params.get('shell_prompt')
    address = params.get('ovirt_node_address')
    username = params.get('ovirt_node_user')
    password = params.get('ovirt_node_password')

    setup_pb = False
    for nic in params.get('nics', "").split():
        nic_params = params.object_params(nic)
        if nic_params.get('netdst') == 'private':
            setup_pb = True
            params_pb = nic_params
            params['netdst_%s' % nic] = nic_params.get("priv_brname", 'atbr0')

    if setup_pb:
        brcfg = test_setup.PrivateBridgeConfig(params_pb)
        brcfg.setup()

    base_dir = data_dir.get_data_dir()
    if params.get("storage_type") == "iscsi":
        iscsidev = qemu_storage.Iscsidev(params, base_dir, "iscsi")
        params["image_name"] = iscsidev.setup()
        params["image_raw_device"] = "yes"

    if params.get("storage_type") == "lvm":
        lvmdev = qemu_storage.LVMdev(params, base_dir, "lvm")
        params["image_name"] = lvmdev.setup()
        params["image_raw_device"] = "yes"
        env.register_lvmdev("lvm_%s" % params["main_vm"], lvmdev)

    if params.get("storage_type") == "nfs":
        image_nfs = nfs.Nfs(params)
        image_nfs.setup()
        image_name_only = os.path.basename(params["image_name"])
        params['image_name'] = os.path.join(image_nfs.mount_dir,
                                            image_name_only)
        for image_name in params.objects("images"):
            name_tag = "image_name_%s" % image_name
            if params.get(name_tag):
                image_name_only = os.path.basename(params[name_tag])
                params[name_tag] = os.path.join(image_nfs.mount_dir,
                                                image_name_only)

    # Start tcpdump if it isn't already running
    # The fact it has to be started here is so that the test params
    # have to be honored.
    env.start_tcpdump(params)

    # Destroy and remove VMs that are no longer needed in the environment
    requested_vms = params.objects("vms")
    for key in env.keys():
        vm = env[key]
        if not isinstance(vm, virt_vm.BaseVM):
            continue
        if vm.name not in requested_vms:
            vm.destroy()
            del env[key]

    if (params.get("auto_cpu_model") == "yes" and
            params.get("vm_type") == "qemu"):
        if not env.get("cpu_model"):
            env["cpu_model"] = utils_misc.get_qemu_best_cpu_model(params)
        params["cpu_model"] = env.get("cpu_model")

    kvm_ver_cmd = params.get("kvm_ver_cmd", "")

    if kvm_ver_cmd:
        try:
            cmd_result = utils.run(kvm_ver_cmd)
            kvm_version = cmd_result.stdout.strip()
        except error.CmdError:
            kvm_version = "Unknown"
    else:
        # Get the KVM kernel module version and write it as a keyval
        if os.path.exists("/dev/kvm"):
            try:
                kvm_version = open("/sys/module/kvm/version").read().strip()
            except Exception:
                kvm_version = os.uname()[2]
        else:
            logging.warning("KVM module not loaded")
            kvm_version = "Unknown"

    logging.debug("KVM version: %s" % kvm_version)
    test.write_test_keyval({"kvm_version": kvm_version})

    # Get the KVM userspace version and write it as a keyval
    kvm_userspace_ver_cmd = params.get("kvm_userspace_ver_cmd", "")

    if kvm_userspace_ver_cmd:
        try:
            cmd_result = utils.run(kvm_userspace_ver_cmd)
            kvm_userspace_version = cmd_result.stdout.strip()
        except error.CmdError:
            kvm_userspace_version = "Unknown"
    else:
        qemu_path = utils_misc.get_qemu_binary(params)
        version_line = commands.getoutput("%s -help | head -n 1" % qemu_path)
        matches = re.findall("[Vv]ersion .*?,", version_line)
        if matches:
            kvm_userspace_version = " ".join(matches[0].split()[1:]).strip(",")
        else:
            kvm_userspace_version = "Unknown"

    logging.debug("KVM userspace version: %s" % kvm_userspace_version)
    test.write_test_keyval({"kvm_userspace_version": kvm_userspace_version})

    libvirtd_inst = utils_libvirtd.Libvirtd()

    if params.get("setup_hugepages") == "yes":
        h = test_setup.HugePageConfig(params)
        suggest_mem = h.setup()
        if suggest_mem is not None:
            params['mem'] = suggest_mem
        if params.get("vm_type") == "libvirt":
            libvirtd_inst.restart()

    if params.get("setup_thp") == "yes":
        thp = test_setup.TransparentHugePageConfig(test, params)
        thp.setup()

    if params.get("setup_ksm") == "yes":
        ksm = test_setup.KSMConfig(params, env)
        ksm.setup(env)

    if params.get("vm_type") == "libvirt":
        if params.get("setup_libvirt_polkit") == "yes":
            pol = test_setup.LibvirtPolkitConfig(params)
            try:
                pol.setup()
            except test_setup.PolkitWriteLibvirtdConfigError, e:
                logging.error("e")
            except test_setup.PolkitRulesSetupError, e:
                logging.error("e")
            except Exception, e:
                logging.error("Unexpected error:" % e)
            libvirtd_inst.restart()

    # Execute any pre_commands
    if params.get("pre_command"):
        process_command(test, params, env, params.get("pre_command"),
                        int(params.get("pre_command_timeout", "600")),
                        params.get("pre_command_noncritical") == "yes")

    # if you want set "pci=nomsi" before test, set "disable_pci_msi = yes"
    # and pci_msi_sensitive = "yes"
    if params.get("pci_msi_sensitive", "no") == "yes":
        disable_pci_msi = params.get("disable_pci_msi", "no")
        image_filename = storage.get_image_filename(params,
                                                    data_dir.get_data_dir())
        grub_file = params.get("grub_file", "/boot/grub2/grub.cfg")
        kernel_cfg_pos_reg = params.get("kernel_cfg_pos_reg",
                                        r".*vmlinuz-\d+.*")
        msi_keyword = params.get("msi_keyword", " pci=nomsi")

        disk_obj = utils_disk.GuestFSModiDisk(image_filename)
        kernel_config_ori = disk_obj.read_file(grub_file)
        kernel_config = re.findall(kernel_cfg_pos_reg, kernel_config_ori)
        if not kernel_config:
            raise error.TestError("Cannot find the kernel config, reg is %s" %
                                  kernel_cfg_pos_reg)
        kernel_config_line = kernel_config[0]

        kernel_need_modify = False
        if disable_pci_msi == "yes":
            if not re.findall(msi_keyword, kernel_config_line):
                kernel_config_set = kernel_config_line + msi_keyword
                kernel_need_modify = True
        else:
            if re.findall(msi_keyword, kernel_config_line):
                kernel_config_set = re.sub(msi_keyword, "", kernel_config_line)
                kernel_need_modify = True

        if kernel_need_modify:
            for vm in env.get_all_vms():
                if vm:
                    vm.destroy()
                    env.unregister_vm(vm.name)
            disk_obj.replace_image_file_content(grub_file, kernel_config_line,
                                                kernel_config_set)
        logging.debug("Guest cmdline 'pci=nomsi' setting is: [ %s ]" %
                      disable_pci_msi)

    kernel_extra_params = params.get("kernel_extra_params")
    if kernel_extra_params:
        image_filename = storage.get_image_filename(params,
                                                    data_dir.get_data_dir())
        grub_file = params.get("grub_file", "/boot/grub2/grub.cfg")
        kernel_cfg_pos_reg = params.get("kernel_cfg_pos_reg",
                                        r".*vmlinuz-\d+.*")

        disk_obj = utils_disk.GuestFSModiDisk(image_filename)
        kernel_config_ori = disk_obj.read_file(grub_file)
        kernel_config = re.findall(kernel_cfg_pos_reg, kernel_config_ori)
        if not kernel_config:
            raise error.TestError("Cannot find the kernel config, reg is %s" %
                                  kernel_cfg_pos_reg)
        kernel_config_line = kernel_config[0]

        kernel_need_modify = False
        if not re.findall(kernel_extra_params, kernel_config_line):
            kernel_config_set = kernel_config_line + kernel_extra_params
            kernel_need_modify = True

        if kernel_need_modify:
            for vm in env.get_all_vms():
                if vm:
                    vm.destroy()
                    env.unregister_vm(vm.name)
            disk_obj.replace_image_file_content(grub_file, kernel_config_line,
                                                kernel_config_set)
        logging.debug("Guest cmdline extra_params setting is: [ %s ]" %
                      kernel_extra_params)

    # Clone master image from vms.
    base_dir = data_dir.get_data_dir()
    if params.get("master_images_clone"):
        for vm_name in params.get("vms").split():
            vm = env.get_vm(vm_name)
            if vm:
                vm.destroy()
                env.unregister_vm(vm_name)

            vm_params = params.object_params(vm_name)
            for image in vm_params.get("master_images_clone").split():
                image_obj = qemu_storage.QemuImg(params, base_dir, image)
                image_obj.clone_image(params, vm_name, image, base_dir)

    # Preprocess all VMs and images
    if params.get("not_preprocess", "no") == "no":
        process(test, params, env, preprocess_image, preprocess_vm)

    # Start the screendump thread
    if params.get("take_regular_screendumps") == "yes":
        global _screendump_thread, _screendump_thread_termination_event
        _screendump_thread_termination_event = threading.Event()
        _screendump_thread = threading.Thread(target=_take_screendumps,
                                              name='ScreenDump',
                                              args=(test, params, env))
        _screendump_thread.start()

    # Start the register query thread
    if params.get("store_vm_register") == "yes":
        global _vm_register_thread, _vm_register_thread_termination_event
        _vm_register_thread_termination_event = threading.Event()
        _vm_register_thread = threading.Thread(target=_store_vm_register,
                                               name='VmRegister',
                                               args=(test, params, env))
        _vm_register_thread.start()

    return params


@error.context_aware
def postprocess(test, params, env):
    """
    Postprocess all VMs and images according to the instructions in params.

    :param test: An Autotest test object.
    :param params: Dict containing all VM and image parameters.
    :param env: The environment (a dict-like object).
    """
    error.context("postprocessing")
    err = ""

    # Postprocess all VMs and images
    try:
        process(test, params, env, postprocess_image, postprocess_vm,
                vm_first=True)
    except Exception, details:
        err += "\nPostprocess: %s" % str(details).replace('\\n', '\n  ')
        logging.error(details)

    # Terminate the screendump thread
    global _screendump_thread, _screendump_thread_termination_event
    if _screendump_thread is not None:
        _screendump_thread_termination_event.set()
        _screendump_thread.join(10)
        _screendump_thread = None

    # Encode an HTML 5 compatible video from the screenshots produced

    dirs = re.findall("(screendump\S*_[0-9]+)", str(os.listdir(test.debugdir)))
    for dir in dirs:
        screendump_dir = os.path.join(test.debugdir, dir)
        if (params.get("encode_video_files", "yes") == "yes" and
                glob.glob("%s/*" % screendump_dir)):
            try:
                video = video_maker.GstPythonVideoMaker()
                if (video.has_element('vp8enc') and video.has_element('webmmux')):
                    video_file = os.path.join(test.debugdir, "%s-%s.webm" %
                                              (screendump_dir, test.iteration))
                else:
                    video_file = os.path.join(test.debugdir, "%s-%s.ogg" %
                                              (screendump_dir, test.iteration))
                logging.debug("Encoding video file %s", video_file)
                video.start(screendump_dir, video_file)

            except Exception, detail:
                logging.info(
                    "Video creation failed for %s: %s", screendump_dir, detail)

    # Warn about corrupt PPM files
    for f in glob.glob(os.path.join(test.debugdir, "*.ppm")):
        if not ppm_utils.image_verify_ppm_file(f):
            logging.warn("Found corrupt PPM file: %s", f)

    # Should we convert PPM files to PNG format?
    if params.get("convert_ppm_files_to_png", "no") == "yes":
        try:
            for f in glob.glob(os.path.join(test.debugdir, "*.ppm")):
                if ppm_utils.image_verify_ppm_file(f):
                    new_path = f.replace(".ppm", ".png")
                    image = PIL.Image.open(f)
                    image.save(new_path, format='PNG')
        except NameError:
            pass

    # Should we keep the PPM files?
    if params.get("keep_ppm_files", "no") != "yes":
        for f in glob.glob(os.path.join(test.debugdir, '*.ppm')):
            os.unlink(f)

    # Should we keep the screendump dirs?
    if params.get("keep_screendumps", "no") != "yes":
        for d in glob.glob(os.path.join(test.debugdir, "screendumps_*")):
            if os.path.isdir(d) and not os.path.islink(d):
                shutil.rmtree(d, ignore_errors=True)

    # Should we keep the video files?
    if params.get("keep_video_files", "yes") != "yes":
        for f in (glob.glob(os.path.join(test.debugdir, '*.ogg')) +
                  glob.glob(os.path.join(test.debugdir, '*.webm'))):
            os.unlink(f)

    # Terminate the register query thread
    global _vm_register_thread, _vm_register_thread_termination_event
    if _vm_register_thread is not None:
        _vm_register_thread_termination_event.set()
        _vm_register_thread.join()
        _vm_register_thread = None

    # Kill all unresponsive VMs
    if params.get("kill_unresponsive_vms") == "yes":
        for vm in env.get_all_vms():
            if vm.is_dead() or vm.is_paused():
                continue
            try:
                # Test may be fast, guest could still be booting
                if len(vm.virtnet) > 0:
                    session = vm.wait_for_login(timeout=vm.LOGIN_WAIT_TIMEOUT)
                    session.close()
                else:
                    session = vm.wait_for_serial_login(
                        timeout=vm.LOGIN_WAIT_TIMEOUT)
                    session.close()
            except (remote.LoginError, virt_vm.VMError, IndexError), e:
                logging.warn(e)
                vm.destroy(gracefully=False)

    # Kill VMs with deleted disks
    for vm in env.get_all_vms():
        destroy = False
        vm_params = params.object_params(vm.name)
        for image in vm_params.objects('images'):
            if params.object_params(image).get('remove_image') == 'yes':
                destroy = True
        if destroy and not vm.is_dead():
            logging.debug('Image of VM %s was removed, destroing it.', vm.name)
            vm.destroy()

    # Terminate the tcpdump thread
    env.stop_tcpdump()

    # Kill all aexpect tail threads
    aexpect.kill_tail_threads()

    living_vms = [vm for vm in env.get_all_vms() if vm.is_alive()]
    # Close all monitor socket connections of living vm.
    for vm in living_vms:
        if hasattr(vm, "monitors"):
            for m in vm.monitors:
                try:
                    m.close()
                except Exception:
                    pass
        # Close the serial console session, as it'll help
        # keeping the number of filedescriptors used by virt-test honest.
        vm.cleanup_serial_console()

    libvirtd_inst = utils_libvirtd.Libvirtd()

    if params.get("setup_hugepages") == "yes":
        try:
            h = test_setup.HugePageConfig(params)
            h.cleanup()
            if params.get("vm_type") == "libvirt":
                libvirtd_inst.restart()
        except Exception, details:
            err += "\nHP cleanup: %s" % str(details).replace('\\n', '\n  ')
            logging.error(details)

    if params.get("setup_thp") == "yes":
        try:
            thp = test_setup.TransparentHugePageConfig(test, params)
            thp.cleanup()
        except Exception, details:
            err += "\nTHP cleanup: %s" % str(details).replace('\\n', '\n  ')
            logging.error(details)

    if params.get("setup_ksm") == "yes":
        try:
            ksm = test_setup.KSMConfig(params, env)
            ksm.cleanup(env)
        except Exception, details:
            err += "\nKSM cleanup: %s" % str(details).replace('\\n', '\n  ')
            logging.error(details)

    if params.get("vm_type") == "libvirt":
        if params.get("setup_libvirt_polkit") == "yes":
            try:
                pol = test_setup.LibvirtPolkitConfig(params)
                pol.cleanup()
                libvirtd_inst.restart()
            except test_setup.PolkitConfigCleanupError, e:
                err += "\nPolkit cleanup: %s" % str(e).replace('\\n', '\n  ')
                logging.error(e)
            except Exception, details:
                err += "\nPolkit cleanup: %s" % str(details
                                                    ).replace('\\n', '\n  ')
                logging.error("Unexpected error: %s" % details)

    # Execute any post_commands
    if params.get("post_command"):
        try:
            process_command(test, params, env, params.get("post_command"),
                            int(params.get("post_command_timeout", "600")),
                            params.get("post_command_noncritical") == "yes")
        except Exception, details:
            err += "\nPostprocess command: %s" % str(details).replace('\n',
                                                                      '\n  ')
            logging.error(details)

    base_dir = data_dir.get_data_dir()
    if params.get("storage_type") == "iscsi":
        try:
            iscsidev = qemu_storage.Iscsidev(params, base_dir, "iscsi")
            iscsidev.cleanup()
        except Exception, details:
            err += "\niscsi cleanup: %s" % str(details).replace('\\n', '\n  ')
            logging.error(details)

    if params.get("storage_type") == "lvm":
        try:
            lvmdev = env.get_lvmdev("lvm_%s" % params["main_vm"])
            lvmdev.cleanup()
        except Exception, details:
            err += "\nLVM cleanup: %s" % str(details).replace('\\n', '\n  ')
            logging.error(details)
        env.unregister_lvmdev("lvm_%s" % params["main_vm"])

    if params.get("storage_type") == "nfs":
        try:
            image_nfs = nfs.Nfs(params)
            image_nfs.cleanup()
        except Exception, details:
            err += "\nnfs cleanup: %s" % str(details).replace('\\n', '\n  ')

    setup_pb = False
    for nic in params.get('nics', "").split():
        if params.get('netdst_%s' % nic) == 'private':
            setup_pb = True
            break
    else:
        setup_pb = params.get("netdst") == 'private'

    if setup_pb:
        try:
            brcfg = test_setup.PrivateBridgeConfig()
            brcfg.cleanup()
        except Exception, details:
            err += "\nPB cleanup: %s" % str(details).replace('\\n', '\n  ')
            logging.error(details)

    if err:
        raise virt_vm.VMError("Failures occurred while postprocess:%s" % err)


def postprocess_on_error(test, params, env):
    """
    Perform postprocessing operations required only if the test failed.

    :param test: An Autotest test object.
    :param params: A dict containing all VM and image parameters.
    :param env: The environment (a dict-like object).
    """
    params.update(params.object_params("on_error"))


def _take_screendumps(test, params, env):
    global _screendump_thread_termination_event
    temp_dir = test.debugdir
    if params.get("screendump_temp_dir"):
        temp_dir = utils_misc.get_path(test.bindir,
                                       params.get("screendump_temp_dir"))
        try:
            os.makedirs(temp_dir)
        except OSError:
            pass
    temp_filename = os.path.join(temp_dir, "scrdump-%s.ppm" %
                                 utils_misc.generate_random_string(6))
    delay = float(params.get("screendump_delay", 5))
    quality = int(params.get("screendump_quality", 30))
    inactivity_treshold = float(params.get("inactivity_treshold", 1800))
    inactivity_watcher = params.get("inactivity_watcher", "log")

    cache = {}
    counter = {}
    inactivity = {}

    while True:
        for vm in env.get_all_vms():
            if vm.instance not in counter.keys():
                counter[vm.instance] = 0
            if vm.instance not in inactivity.keys():
                inactivity[vm.instance] = time.time()
            if not vm.is_alive():
                continue
            vm_pid = vm.get_pid()
            try:
                vm.screendump(filename=temp_filename, debug=False)
            except qemu_monitor.MonitorError, e:
                logging.warn(e)
                continue
            except AttributeError, e:
                logging.warn(e)
                continue
            if not os.path.exists(temp_filename):
                logging.warn("VM '%s' failed to produce a screendump", vm.name)
                continue
            if not ppm_utils.image_verify_ppm_file(temp_filename):
                logging.warn("VM '%s' produced an invalid screendump", vm.name)
                os.unlink(temp_filename)
                continue
            screendump_dir = os.path.join(test.debugdir,
                                          "screendumps_%s_%s" % (vm.name,
                                                                 vm_pid))
            try:
                os.makedirs(screendump_dir)
            except OSError:
                pass
            counter[vm.instance] += 1
            screendump_filename = os.path.join(screendump_dir, "%04d.jpg" %
                                               counter[vm.instance])
            vm.verify_bsod(screendump_filename)
            image_hash = utils.hash_file(temp_filename)
            if image_hash in cache:
                time_inactive = time.time() - inactivity[vm.instance]
                if time_inactive > inactivity_treshold:
                    msg = (
                        "%s screen is inactive for more than %d s (%d min)" %
                        (vm.name, time_inactive, time_inactive / 60))
                    if inactivity_watcher == "error":
                        try:
                            raise virt_vm.VMScreenInactiveError(vm,
                                                                time_inactive)
                        except virt_vm.VMScreenInactiveError:
                            logging.error(msg)
                            # Let's reset the counter
                            inactivity[vm.instance] = time.time()
                            test.background_errors.put(sys.exc_info())
                    elif inactivity_watcher == 'log':
                        logging.debug(msg)
                try:
                    os.link(cache[image_hash], screendump_filename)
                except OSError:
                    pass
            else:
                inactivity[vm.instance] = time.time()
                try:
                    try:
                        image = PIL.Image.open(temp_filename)
                        image.save(screendump_filename, format="JPEG",
                                   quality=quality)
                        cache[image_hash] = screendump_filename
                    except IOError, error_detail:
                        logging.warning("VM '%s' failed to produce a "
                                        "screendump: %s", vm.name, error_detail)
                        # Decrement the counter as we in fact failed to
                        # produce a converted screendump
                        counter[vm.instance] -= 1
                except NameError:
                    pass
            os.unlink(temp_filename)

        if _screendump_thread_termination_event is not None:
            if _screendump_thread_termination_event.isSet():
                _screendump_thread_termination_event = None
                break
            _screendump_thread_termination_event.wait(delay)
        else:
            # Exit event was deleted, exit this thread
            break


def store_vm_register(vm, log_filename, append=False):
    """
    Store the register information of vm into a log file

    :param vm: VM object
    :type vm: vm object
    :param log_filename: log file name
    :type log_filename: string
    :param append: Add the log to the end of the log file or not
    :type append: bool
    :return: Store the vm register information to log file or not
    :rtype: bool
    """
    try:
        output = vm.monitor.info('registers', debug=False)
        timestamp = time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())
    except qemu_monitor.MonitorError, e:
        logging.warn(e)
        return False

    log_filename = "%s_%s" % (log_filename, timestamp)
    if append:
        vr_log = open(log_filename, 'r+')
        vr_log.seek(0, 2)
        output += "\n"
    else:
        vr_log = open(log_filename, 'w')
    vr_log.write(output)
    vr_log.close()
    return True


def _store_vm_register(test, params, env):
    def report_result(status, results):
        msg = "%s." % status
        for vm_name in results.keys():
            if results[vm_name] > 0:
                msg += " Used to failed to get register info from guest"
                msg += " %s for %s times." % (vm_name, results[vm_name])

        if msg != "%s." % status:
            logging.debug(msg)

    global _vm_register_thread_termination_event
    delay = float(params.get("vm_register_delay", 5))
    counter = {}
    vm_register_error_count = {}
    while True:
        for vm in env.get_all_vms():
            if vm.name not in vm_register_error_count:
                vm_register_error_count[vm.name] = 0

            if not vm.is_alive():
                if vm_register_error_count[vm.name] < 1:
                    logging.warn("%s is not alive. Can not query the "
                                 "register status" % vm.name)
                vm_register_error_count[vm.name] += 1
                continue
            vm_pid = vm.get_pid()
            vr_dir = utils_misc.get_path(test.debugdir,
                                         "vm_register_%s_%s" % (vm.name,
                                                                vm_pid))
            try:
                os.makedirs(vr_dir)
            except OSError:
                pass

            if vm not in counter:
                counter[vm] = 1
            vr_filename = utils_misc.get_path(vr_dir, "%04d" % counter[vm])
            stored_log = store_vm_register(vm, vr_filename)
            if vm_register_error_count[vm.name] >= 1:
                logging.debug("%s alive now. Used to failed to get register"
                              " info from guest %s"
                              " times" % (vm.name,
                                          vm_register_error_count[vm.name]))
                vm_register_error_count[vm.name] = 0
            if stored_log:
                counter[vm] += 1

        if _vm_register_thread_termination_event is not None:
            if _vm_register_thread_termination_event.isSet():
                _vm_register_thread_termination_event = None
                report_result("Thread quit", vm_register_error_count)
                break
            _vm_register_thread_termination_event.wait(delay)
        else:
            report_result("Thread quit", vm_register_error_count)
            # Exit event was deleted, exit this thread
            break

########NEW FILE########
__FILENAME__ = funcatexit
"""
funcatexit.py - allow programmer to define multiple exit functions to be
executed upon normal cases termination. Can be used for the environment clean
up functions. The basic idea is like atexit from python libs.
"""

__all__ = ["register", "run_exitfuncs", "unregister"]

from autotest.client.shared import error
import traceback


def run_exitfuncs(env, test_type):
    """
    Run any registered exit functions.
    exithandlers is traversed in reverse order so functions are executed
    last in, first out.

    param env: the global objects used by tests
    param test_type: test type mark for exit functions
    """
    error_message = ""
    if env.data.get("exithandlers__%s" % test_type):
        exithandlers = env.data.get("exithandlers__%s" % test_type)
        while exithandlers:
            func, targs, kargs = exithandlers.pop()
            try:
                func(*targs, **kargs)
            except Exception, details:
                error_message += "Error in %s:" % func.func_name
                error_message += " %s\n" % details
                traceback.print_exc()

    return error_message


def register(env, test_type, func, *targs, **kargs):
    """
    Register a function to be executed upon case termination.
    func is returned to facilitate usage as a decorator.

    param env: the global objects used by tests
    param test_type: test type mark for exit functions
    param func: function to be called at exit
    param targs: optional arguments to pass to func
    param kargs: optional keyword arguments to pass to func
    """
    # Check for unpickable arguments
    if func.func_name not in func.func_globals:
        raise error.TestError("Trying to register function '%s', which is not "
                              "declared at module scope (not in globals). "
                              "Please contact the test developer to fix it."
                              % func)
    for arg in targs:
        if hasattr(arg, '__slots__') and not hasattr(arg, '__getstate__'):
            raise error.TestError("Trying to register exitfunction '%s' with "
                                  "unpickable targument '%s'. Please contact "
                                  "the test developer to fix it."
                                  % (func, arg))
    for key, arg in kargs.iteritems():
        if hasattr(arg, '__slots__') and not hasattr(arg, '__getstate__'):
            raise error.TestError("Trying to register exitfunction '%s' with "
                                  "unpickable kargument '%s=%s'. Please "
                                  "contact the test developer to fix it."
                                  % (func, key, arg))
    exithandlers = "exithandlers__%s" % test_type
    if not env.data.get(exithandlers):
        env.data[exithandlers] = []

    env.data[exithandlers].append((func, targs, kargs))
    return func


def unregister(env, test_type, func, *targs, **kargs):
    """
    Unregister a function to be executed upon case termination.
    func is returned to facilitate usage as a decorator.

    param env: the global objects used by tests
    param test_type: test type mark for exit functions
    param func: function to be called at exit
    param targs: optional arguments to pass to func
    param kargs: optional keyword arguments to pass to func
    """
    exithandlers = "exithandlers__%s" % test_type
    if env.data.get(exithandlers):
        env.data[exithandlers].remove((func, targs, kargs))
    return func

########NEW FILE########
__FILENAME__ = gluster
"""
GlusterFS Support
This file has the functions that helps
* To create/check gluster volume.
* To start/check gluster services.
* To create gluster uri which can be used as disk image file path.
"""

import logging
import os
import re
import shutil
from autotest.client.shared import utils, error
import data_dir
import utils_misc
import utils_net
import socket


class GlusterError(Exception):
    pass


class GlusterBrickError(GlusterError):

    def __init__(self, error_mgs):
        super(GlusterBrickError, self).__init__(error_mgs)
        self.error_mgs = error_mgs

    def __str__(self):
        return ("Gluster: %s" % (self.error_mgs))


@error.context_aware
def glusterd_start():
    """
    Check for glusterd status
    """
    cmd = "service glusterd status"
    output = utils.system_output(cmd, ignore_status=True)
    if 'inactive' or 'stopped' in output:
        cmd = "service glusterd start"
        error.context("Starting gluster dameon failed")
        output = utils.system_output(cmd)


@error.context_aware
def is_gluster_vol_started(vol_name):
    """
    Returns if the volume is started, if not send false
    """
    cmd = "gluster volume info %s" % vol_name
    error.context("Gluster volume info failed for volume: %s" % vol_name)
    vol_info = utils.system_output(cmd)
    volume_status = re.findall(r'Status: (\S+)', vol_info)
    if 'Started' in volume_status:
        return True
    else:
        return False


@error.context_aware
def gluster_vol_start(vol_name):
    """
    Starts the volume if it is stopped
    """
    # Check if the volume is stopped, if then start
    if not is_gluster_vol_started(vol_name):
        error.context("Gluster volume start failed for volume; %s" % vol_name)
        cmd = "gluster volume start %s" % vol_name
        utils.system(cmd)
        return True
    else:
        return True


@error.context_aware
def gluster_vol_stop(vol_name, force=False):
    """
    Starts the volume if it is stopped
    """
    # Check if the volume is stopped, if then start
    if is_gluster_vol_started(vol_name):
        error.context("Gluster volume stop for volume; %s" % vol_name)
        if force:
            cmd = "gluster volume stop %s force" % vol_name
        else:
            cmd = "gluster volume stop %s" % vol_name
        utils.run(cmd, ignore_status=False,
                  stdout_tee=utils.TEE_TO_LOGS,
                  stderr_tee=utils.TEE_TO_LOGS,
                  stdin="y\n",
                  verbose=True)
        return True
    else:
        return True


@error.context_aware
def gluster_vol_delete(vol_name):
    """
    Starts the volume if it is stopped
    """
    # Check if the volume is stopped, if then start
    if not is_gluster_vol_started(vol_name):
        error.context("Gluster volume delete; %s" % vol_name)
        cmd = "gluster volume delete %s" % vol_name
        utils.run(cmd, ignore_status=False,
                  stdout_tee=utils.TEE_TO_LOGS,
                  stderr_tee=utils.TEE_TO_LOGS,
                  stdin="y\n",
                  verbose=True)
        return True
    else:
        return False


@error.context_aware
def is_gluster_vol_avail(vol_name):
    """
    Returns if the volume already available
    """
    cmd = "gluster volume info"
    error.context("Gluster volume info failed")
    output = utils.system_output(cmd)
    volume_name = re.findall(r'Volume Name: (%s)\n' % vol_name, output)
    if volume_name:
        return gluster_vol_start(vol_name)


def gluster_brick_create(brick_path, force=False):
    """
    Creates brick
    """
    if os.path.isdir(brick_path) and force:
        gluster_brick_delete(brick_path)
    try:
        os.mkdir(brick_path)
        return True
    except OSError, details:
        logging.error("Not able to create brick folder %s", details)


def gluster_brick_delete(brick_path):
    """
    Creates brick
    """
    if os.path.isdir(brick_path):
        try:
            shutil.rmtree(brick_path)
            return True
        except OSError, details:
            logging.error("Not able to create brick folder %s", details)


@error.context_aware
def gluster_vol_create(vol_name, hostname, brick_path, force=False):
    """
    Gluster Volume Creation
    """
    # Create a brick
    if is_gluster_vol_avail(vol_name):
        gluster_vol_stop(vol_name, True)
        gluster_vol_delete(vol_name)
        gluster_brick_delete(brick_path)

    gluster_brick_create(brick_path)

    cmd = "gluster volume create %s %s:/%s" % (vol_name, hostname,
                                               brick_path)
    error.context("Volume creation failed")
    utils.system(cmd)
    return is_gluster_vol_avail(vol_name)


def glusterfs_mount(g_uri, mount_point):
    """
    Mount gluster volume to mountpoint.

    :param g_uri: stripped gluster uri from create_gluster_uri(.., True)
    :type g_uri: str
    """
    utils_misc.mount(g_uri, mount_point, "glusterfs", None,
                     False, "fuse.glusterfs")


@error.context_aware
def create_gluster_vol(params):
    vol_name = params.get("gluster_volume_name")
    force = params.get('force_recreate_gluster') == "yes"

    brick_path = params.get("gluster_brick")
    if not os.path.isabs(brick_path):  # do nothing when path is absolute
        base_dir = params.get("images_base_dir", data_dir.get_data_dir())
        brick_path = os.path.join(base_dir, brick_path)

    error.context("Host name lookup failed")
    hostname = socket.gethostname()
    if not hostname or hostname == "(none)":
        if_up = utils_net.get_net_if(state="UP")
        for i in if_up:
            ipv4_value = utils_net.get_net_if_addrs(i)["ipv4"]
            logging.debug("ipv4_value is %s", ipv4_value)
            if ipv4_value != []:
                ip_addr = ipv4_value[0]
                break
        hostname = ip_addr

    # Start the gluster dameon, if not started
    glusterd_start()
    # Check for the volume is already present, if not create one.
    if not is_gluster_vol_avail(vol_name) or force:
        return gluster_vol_create(vol_name, hostname, brick_path, force)
    else:
        return True


@error.context_aware
def create_gluster_uri(params, stripped=False):
    """
    Find/create gluster volume
    """
    vol_name = params.get("gluster_volume_name")

    error.context("Host name lookup failed")
    hostname = socket.gethostname()
    gluster_server = params.get("gluster_server")
    gluster_port = params.get("gluster_port", "0")
    if not gluster_server:
        gluster_server = hostname
    if not gluster_server or gluster_server == "(none)":
        if_up = utils_net.get_net_if(state="UP")
        ip_addr = utils_net.get_net_if_addrs(if_up[0])["ipv4"][0]
        gluster_server = ip_addr

    # Start the gluster dameon, if not started
    # Building gluster uri
    gluster_uri = None
    if stripped:
        gluster_uri = "%s:/%s" % (gluster_server, vol_name)
    else:
        gluster_uri = "gluster://%s:%s/%s/" % (gluster_server, gluster_port,
                                               vol_name)
    return gluster_uri


def file_exists(params, filename_path):
    sg_uri = create_gluster_uri(params, stripped=True)
    g_uri = create_gluster_uri(params, stripped=False)
    # Using directly /tmp dir because directory should be really temporary and
    # should be deleted immediately when no longer needed and
    # created directory don't file tmp dir by any data.
    tmpdir = "gmount-%s" % (utils_misc.generate_random_string(6))
    tmpdir_path = os.path.join("/tmp", tmpdir)
    while os.path.exists(tmpdir_path):
        tmpdir = "gmount-%s" % (utils_misc.generate_random_string(6))
        tmpdir_path = os.path.join("/tmp", tmpdir)
    ret = False
    try:
        try:
            os.mkdir(tmpdir_path)
            glusterfs_mount(sg_uri, tmpdir_path)
            mount_filename_path = os.path.join(tmpdir_path,
                                               filename_path[len(g_uri):])
            if os.path.exists(mount_filename_path):
                ret = True
        except Exception, e:
            logging.error("Failed to mount gluster volume %s to"
                          " mount dir %s: %s" % (sg_uri, tmpdir_path, e))
    finally:
        if utils_misc.umount(sg_uri, tmpdir_path, "glusterfs", False,
                             "fuse.glusterfs"):
            try:
                os.rmdir(tmpdir_path)
            except OSError:
                pass
        else:
            logging.warning("Unable to unmount tmp directory %s with glusterfs"
                            " mount.", tmpdir_path)
    return ret


def get_image_filename(params, image_name, image_format):
    """
    Form the image file name using gluster uri
    """

    img_name = image_name.split('/')[-1]
    gluster_uri = create_gluster_uri(params)
    image_filename = "%s%s.%s" % (gluster_uri, img_name, image_format)
    return image_filename

########NEW FILE########
__FILENAME__ = guest_agent
"""
Interfaces to the virt agent.

:copyright: 2008-2012 Red Hat Inc.
"""

import socket
import time
import logging
import random
from autotest.client.shared import error
from qemu_monitor import Monitor, MonitorError

try:
    import json
except ImportError:
    logging.warning("Could not import json module. "
                    "virt agent functionality disabled.")


class VAgentError(MonitorError):
    pass


class VAgentConnectError(VAgentError):
    pass


class VAgentSocketError(VAgentError):

    def __init__(self, msg, e):
        VAgentError.__init__(self)
        self.msg = msg
        self.e = e

    def __str__(self):
        return "%s    (%s)" % (self.msg, self.e)


class VAgentLockError(VAgentError):
    pass


class VAgentProtocolError(VAgentError):
    pass


class VAgentNotSupportedError(VAgentError):
    pass


class VAgentCmdError(VAgentError):

    def __init__(self, cmd, args, data):
        VAgentError.__init__(self)
        self.ecmd = cmd
        self.eargs = args
        self.edata = data

    def __str__(self):
        return ("Virt Agent command %r failed    (arguments: %r,    "
                "error message: %r)" % (self.ecmd, self.eargs, self.edata))


class VAgentSyncError(VAgentError):

    def __init__(self, vm_name):
        VAgentError.__init__(self)
        self.vm_name = vm_name

    def __str__(self):
        return "Could not sync with guest agent in vm '%s'" % self.vm_name


class VAgentSuspendError(VAgentError):
    pass


class VAgentSuspendUnknownModeError(VAgentSuspendError):

    def __init__(self, mode):
        VAgentSuspendError.__init__(self)
        self.mode = mode

    def __str__(self):
        return "Not supported suspend mode '%s'" % self.mode


class VAgentFreezeStatusError(VAgentError):

    def __init__(self, vm_name, status, expected):
        VAgentError.__init__(self)
        self.vm_name = vm_name
        self.status = status
        self.expected = expected

    def __str__(self):
        return ("Unexpected guest FS status '%s' (expected '%s') in vm "
                "'%s'" % (self.status, self.expected, self.vm_name))


class QemuAgent(Monitor):

    """
    Wraps qemu guest agent commands.
    """

    READ_OBJECTS_TIMEOUT = 5
    CMD_TIMEOUT = 20
    RESPONSE_TIMEOUT = 20
    PROMPT_TIMEOUT = 20

    SERIAL_TYPE_VIRTIO = "virtio"
    SERIAL_TYPE_ISA = "isa"
    SUPPORTED_SERIAL_TYPE = [SERIAL_TYPE_VIRTIO, SERIAL_TYPE_ISA]

    SHUTDOWN_MODE_POWERDOWN = "powerdown"
    SHUTDOWN_MODE_REBOOT = "reboot"
    SHUTDOWN_MODE_HALT = "halt"

    SUSPEND_MODE_DISK = "disk"
    SUSPEND_MODE_RAM = "ram"
    SUSPEND_MODE_HYBRID = "hybrid"

    FSFREEZE_STATUS_FROZEN = "frozen"
    FSFREEZE_STATUS_THAWED = "thawed"

    def __init__(self, vm, name, serial_type, serial_filename,
                 get_supported_cmds=False, suppress_exceptions=False):
        """
        Connect to the guest agent socket, Also make sure the json
        module is available.

        :param vm: The VM object who has this GuestAgent.
        :param name: Guest agent identifier.
        :param serial_type: Specific which serial type (firtio or isa) guest
                agent will use.
        :param serial_filename: Guest agent socket filename.
        :param get_supported_cmds: Try to get supported cmd list when initiation.
        :param suppress_exceptions: If True, ignore VAgentError exception.

        :raise VAgentConnectError: Raised if the connection fails and
                suppress_exceptions is False
        :raise VAgentNotSupportedError: Raised if the serial type is
                neither 'virtio' nor 'isa' and suppress_exceptions is False
        :raise VAgentNotSupportedError: Raised if json isn't available and
                suppress_exceptions is False
        """
        try:
            if serial_type not in self.SUPPORTED_SERIAL_TYPE:
                raise VAgentNotSupportedError("Not supported serial type: "
                                              "'%s'" % serial_type)

            Monitor.__init__(self, vm, name, serial_filename)
            # Make sure json is available
            try:
                json
            except NameError:
                raise VAgentNotSupportedError("guest agent requires the json"
                                              " module (Python 2.6 and up)")

            # Set a reference to the VM object that has this GuestAgent.
            self.vm = vm

            if get_supported_cmds:
                self._get_supported_cmds()

        # pylint: disable=E0712
        except VAgentError, e:
            self._close_sock()
            if suppress_exceptions:
                logging.warn(e)
            else:
                raise

    # Methods only used inside this class
    def _build_cmd(self, cmd, args=None):
        obj = {"execute": cmd}
        if args is not None:
            obj["arguments"] = args
        return obj

    def _read_objects(self, timeout=READ_OBJECTS_TIMEOUT):
        """
        Read lines from the guest agent socket and try to decode them.
        Stop when all available lines have been successfully decoded, or when
        timeout expires. Return all decoded objects.

        :param timeout: Time to wait for all lines to decode successfully
        :return: A list of objects
        """
        if not self._data_available():
            return []
        s = ""
        end_time = time.time() + timeout
        while self._data_available(end_time - time.time()):
            s += self._recvall()
            # Make sure all lines are decodable
            for line in s.splitlines():
                if line:
                    try:
                        json.loads(line)
                    except Exception:
                        # Found an incomplete or broken line -- keep reading
                        break
            else:
                # All lines are OK -- stop reading
                break
        # Decode all decodable lines
        objs = []
        for line in s.splitlines():
            try:
                objs += [json.loads(line)]
                self._log_lines(line)
            except Exception:
                pass
        return objs

    def _send(self, data):
        """
        Send raw data without waiting for response.

        :param data: Data to send
        :raise VAgentSocketError: Raised if a socket error occurs
        """
        try:
            self._socket.sendall(data)
            self._log_lines(str(data))
        except socket.error, e:
            raise VAgentSocketError("Could not send data: %r" % data, e)

    def _get_response(self, timeout=RESPONSE_TIMEOUT):
        """
        Read a response from the guest agent socket.

        :param id: If not None, look for a response with this id
        :param timeout: Time duration to wait for response
        :return: The response dict
        """
        end_time = time.time() + timeout
        while self._data_available(end_time - time.time()):
            for obj in self._read_objects():
                if isinstance(obj, dict):
                    if "return" in obj or "error" in obj:
                        return obj
        # Return empty dict when timeout.
        return {}

    def _sync(self, timeout=RESPONSE_TIMEOUT * 3):
        """
        Helper for guest agent socket sync.

        The guest agent doesn't provide a command id in its response,
        so we have to send 'guest-sync' cmd by ourselves to keep the
        socket synced.

        :param timeout: Time duration to wait for response
        :return: True if socket is synced.
        """
        def check_result(response):
            if response:
                self._log_response(cmd, r)
            if "return" in response:
                return response["return"]
            if "error" in response:
                raise VAgentError("Get an error message when waiting for sync"
                                  " with qemu guest agent, check the debug log"
                                  " for the future message,"
                                  " detail: '%s'" % r["error"])

        cmd = "guest-sync"
        rnd_num = random.randint(1000, 9999)
        args = {"id": rnd_num}
        self._log_command(cmd)
        cmdobj = self._build_cmd(cmd, args)
        data = json.dumps(cmdobj) + "\n"
        # Send command
        r = self.cmd_raw(data)
        if check_result(r) == rnd_num:
            return True

        # We don't get the correct response of 'guest-sync' cmd,
        # thus wait for the response until timeout.
        start_time = time.time()
        while (time.time() - start_time) < timeout:
            r = self._get_response()
            if check_result(r) == rnd_num:
                return True
        return False

    def _get_supported_cmds(self):
        """
        Get supported qmp cmds list.
        """
        self._sync()
        cmds = self.cmd("guest-info", debug=False)
        if cmds and cmds.has_key("supported_commands"):
            cmd_list = cmds["supported_commands"]
            self._supported_cmds = [n["name"] for n in cmd_list if
                                    isinstance(n, dict) and n.has_key("name")]

        if not self._supported_cmds:
            # If initiation fails, set supported list to a None-only list.
            self._supported_cmds = [None]
            logging.warn("Could not get supported guest agent cmds list")

    def _has_command(self, cmd):
        """
        Check wheter guest agent support 'cmd'.

        :param cmd: command string which will be checked.

        :return: True if cmd is supported, False if not supported.
        """
        # Initiate supported cmds list if it's empty.
        if not self._supported_cmds:
            self.get_supported_cmds()

        # If the first element in supported cmd list is 'None', it means
        # autotest fails to get the cmd list, so bypass cmd checking.
        if self._supported_cmds[0] is None:
            return True

        if cmd and cmd in self._supported_cmds:
            return True
        return False

    def _log_command(self, cmd, debug=True, extra_str=""):
        """
        Print log message beening sent.

        :param cmd: Command string.
        :param debug: Whether to print the commands.
        :param extra_str: Extra string would be printed in log.
        """
        if self.debug_log or debug:
            logging.debug("(vagent %s) Sending command '%s' %s",
                          self.name, cmd, extra_str)

    def _log_response(self, cmd, resp, debug=True):
        """
        Print log message for guest agent cmd's response.

        :param cmd: Command string.
        :param resp: Response from guest agent command.
        :param debug: Whether to print the commands.
        """
        def _log_output(o, indent=0):
            logging.debug("(vagent %s)    %s%s",
                          self.name, " " * indent, o)

        def _dump_list(li, indent=0):
            for l in li:
                if isinstance(l, dict):
                    _dump_dict(l, indent + 2)
                else:
                    _log_output(str(l), indent)

        def _dump_dict(di, indent=0):
            for k, v in di.iteritems():
                o = "%s%s: " % (" " * indent, k)
                if isinstance(v, dict):
                    _log_output(o, indent)
                    _dump_dict(v, indent + 2)
                elif isinstance(v, list):
                    _log_output(o, indent)
                    _dump_list(v, indent + 2)
                else:
                    o += str(v)
                    _log_output(o, indent)

        if self.debug_log or debug:
            logging.debug("(vagent %s) Response to '%s' "
                          "(re-formated)", self.name, cmd)
            if isinstance(resp, dict):
                _dump_dict(resp)
            elif isinstance(resp, list):
                _dump_list(resp)
            else:
                for l in str(resp).splitlines():
                    _log_output(l)

    # Public methods
    def cmd(self, cmd, args=None, timeout=CMD_TIMEOUT, debug=True,
            success_resp=True):
        """
        Send a guest agent command and return the response if success_resp.

        :param cmd: Command to send
        :param args: A dict containing command arguments, or None
        :param timeout: Time duration to wait for response
        :param debug: Whether to print the commands being sent and responses
        :param fd: file object or file descriptor to pass

        :return: The response received

        :raise VAgentLockError: Raised if the lock cannot be acquired
        :raise VAgentSocketError: Raised if a socket error occurs
        :raise VAgentProtocolError: Raised if no response is received
        :raise VAgentCmdError: Raised if the response is an error message
        """
        self._log_command(cmd, debug)
        # Send command
        cmdobj = self._build_cmd(cmd, args)
        data = json.dumps(cmdobj) + "\n"
        r = self.cmd_raw(data, timeout, success_resp)

        if not success_resp:
            return ""

        if "return" in r:
            ret = r["return"]
            if ret:
                self._log_response(cmd, ret, debug)
            return ret
        if "error" in r:
            raise VAgentCmdError(cmd, args, r["error"])

    def cmd_raw(self, data, timeout=CMD_TIMEOUT, success_resp=True):
        """
        Send a raw string to the guest agent and return the response.
        Unlike cmd(), return the raw response dict without performing
        any checks on it.

        :param data: The data to send
        :param timeout: Time duration to wait for response
        :return: The response received
        :raise VAgentLockError: Raised if the lock cannot be acquired
        :raise VAgentSocketError: Raised if a socket error occurs
        :raise VAgentProtocolError: Raised if no response is received
        """
        if not self._acquire_lock():
            raise VAgentLockError("Could not acquire exclusive lock to send "
                                  "data: %r" % data)

        try:
            self._read_objects()
            self._send(data)
            # Return directly for some cmd without any response.
            if not success_resp:
                return {}

            # Read response
            r = self._get_response(timeout)

        finally:
            self._lock.release()

        if r is None:
            raise VAgentProtocolError(
                "Received no response to data: %r" % data)
        return r

    def cmd_obj(self, obj, timeout=CMD_TIMEOUT):
        """
        Transform a Python object to JSON, send the resulting string to
        the guest agent, and return the response.
        Unlike cmd(), return the raw response dict without performing any
        checks on it.

        :param obj: The object to send
        :param timeout: Time duration to wait for response
        :return: The response received
        :raise VAgentLockError: Raised if the lock cannot be acquired
        :raise VAgentSocketError: Raised if a socket error occurs
        :raise VAgentProtocolError: Raised if no response is received
        """
        return self.cmd_raw(json.dumps(obj) + "\n", timeout)

    def verify_responsive(self):
        """
        Make sure the guest agent is responsive by sending a command.
        """
        cmd = "guest-ping"
        if self._has_command(cmd):
            self.cmd(cmd=cmd, debug=False)

    @error.context_aware
    def shutdown(self, mode=SHUTDOWN_MODE_POWERDOWN):
        """
        Send "guest-shutdown", this cmd would not return any response.

        :param mode: Speicfy shutdown mode, now qemu guest agent supports
                     'powerdown', 'reboot', 'halt' 3 modes.
        :return: True if shutdown cmd is sent successfully, False if
                 'shutdown' is unsupported.
        """
        cmd = "guest-shutdown"
        if not self._has_command(cmd):
            return False

        args = None
        if mode in [self.SHUTDOWN_MODE_POWERDOWN, self.SHUTDOWN_MODE_REBOOT,
                    self.SHUTDOWN_MODE_HALT]:
            args = {"mode": mode}
        self.cmd(cmd=cmd, args=args, success_resp=False)
        return True

    @error.context_aware
    def sync(self):
        """
        Sync guest agent with cmd 'guest-sync'.
        """
        cmd = "guest-sync"
        if not self._has_command(cmd):
            return

        synced = self._sync()
        if not synced:
            raise VAgentSyncError(self.vm.name)

    @error.context_aware
    def suspend(self, mode=SUSPEND_MODE_RAM):
        """
        This function tries to execute the scripts provided by the pm-utils
        package via guest agent interface. If it's not available, the suspend
        operation will be performed by manually writing to a sysfs file.

        Notes:

        #. For the best results it's strongly recommended to have the
           ``pm-utils`` package installed in the guest.
        #. The ``ram`` and 'hybrid' mode require QEMU to support the
           ``system_wakeup`` command.  Thus, it's *required* to query QEMU
           for the presence of the ``system_wakeup`` command before issuing
           guest agent command.

        :param mode: Specify suspend mode, could be one of ``disk``, ``ram``,
                     ``hybrid``.
        :return: True if shutdown cmd is sent successfully, False if
                 ``suspend`` is unsupported.
        :raise VAgentSuspendUnknownModeError: Raise if mode is not supported.
        """
        error.context("Suspend guest '%s' to '%s'" % (self.vm.name, mode))

        if mode not in [self.SUSPEND_MODE_DISK, self.SUSPEND_MODE_RAM,
                        self.SUSPEND_MODE_HYBRID]:
            raise VAgentSuspendUnknownModeError("Not supported suspend"
                                                " mode '%s'" % mode)

        cmd = "guest-suspend-%s" % mode
        if not self._has_command(cmd):
            return False

        # First, sync with guest.
        self.sync()

        # Then send suspend cmd.
        self.cmd(cmd=cmd, success_resp=False)

        return True

    def get_fsfreeze_status(self):
        """
        Get guest 'fsfreeze' status. The status could be 'frozen' or 'thawed'.
        """
        cmd = "guest-fsfreeze-status"
        if self._has_command(cmd):
            return self.cmd(cmd=cmd)

    def verify_fsfreeze_status(self, expected):
        """
        Verify the guest agent fsfreeze status is same as expected, if not,
        raise a VAgentFreezeStatusError.

        :param expected: The expected status.
        :raise VAgentFreezeStatusError: Raise if the guest fsfreeze status is
                unexpected.
        """
        status = self.get_fsfreeze_status()
        if status != expected:
            raise VAgentFreezeStatusError(self.vm.name, status, expected)

    @error.context_aware
    def fsfreeze(self, check_status=True):
        """
        Freeze File system on guest.

        :param check_status: Force this function to check the fsreeze status
                             before/after sending cmd.
        :return: Frozen FS number if cmd succeed, -1 if guest agent doesn't
                 support fsfreeze cmd.
        """
        error.context("Freeze all FS in guest '%s'" % self.vm.name)
        if check_status:
            self.verify_fsfreeze_status(self.FSFREEZE_STATUS_THAWED)

        cmd = "guest-fsfreeze-freeze"
        if self._has_command(cmd):
            ret = self.cmd(cmd=cmd)
            if check_status:
                try:
                    self.verify_fsfreeze_status(self.FSFREEZE_STATUS_FROZEN)
                # pylint: disable=E0712
                except VAgentFreezeStatusError:
                    # When the status is incorrect, reset fsfreeze status to
                    # 'thawed'.
                    self.cmd(cmd="guest-fsreeze-thaw")
                    raise
            return ret
        return -1

    @error.context_aware
    def fsthaw(self, check_status=True):
        """
        Thaw File system on guest.

        :param check_status: Force this function to check the fsreeze status
                             before/after sending cmd.
        :return: Thaw FS number if cmd succeed, -1 if guest agent doesn't
                 support fsfreeze cmd.
        """
        error.context("thaw all FS in guest '%s'" % self.vm.name)
        if check_status:
            self.verify_fsfreeze_status(self.FSFREEZE_STATUS_FROZEN)

        cmd = "guest-fsfreeze-thaw"
        if self._has_command(cmd):
            ret = self.cmd(cmd=cmd)
            if check_status:
                try:
                    self.verify_fsfreeze_status(self.FSFREEZE_STATUS_THAWED)
                # pylint: disable=E0712
                except VAgentFreezeStatusError:
                    # When the status is incorrect, reset fsfreeze status to
                    # 'thawed'.
                    self.cmd(cmd=cmd)
                    raise
            return ret
        return -1

########NEW FILE########
__FILENAME__ = http_server
import os
import posixpath
import urlparse
import urllib
import logging
import BaseHTTPServer
import SimpleHTTPServer


class HTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):

    def do_GET(self):
        """
        Serve a GET request.
        """
        rg = self.parse_header_byte_range()
        if rg:
            f = self.send_head_range(rg[0], rg[1])
            if f:
                self.copyfile_range(f, self.wfile, rg[0], rg[1])
                f.close()
        else:
            f = self.send_head()
            if f:
                self.copyfile(f, self.wfile)
                f.close()

    def parse_header_byte_range(self):
        range_param = 'Range'
        range_discard = 'bytes='
        if self.headers.has_key(range_param):
            rg = self.headers.get(range_param)
            if rg.startswith(range_discard):
                rg = rg[len(range_discard):]
                begin, end = rg.split('-')
                return (int(begin), int(end))
        return None

    def copyfile_range(self, source_file, output_file, range_begin, range_end):
        """
        Copies a range of a file to destination.
        """
        range_size = range_end - range_begin + 1
        source_file.seek(range_begin)
        buf = source_file.read(range_size)
        output_file.write(buf)

    def send_head_range(self, range_begin, range_end):
        path = self.translate_path(self.path)
        f = None
        if os.path.isdir(path):
            for index in "index.html", "index.htm":
                index = os.path.join(path, index)
                if os.path.exists(index):
                    path = index
                    break
            else:
                return self.list_directory(path)
        ctype = self.guess_type(path)
        try:
            # Always read in binary mode. Opening files in text mode may cause
            # newline translations, making the actual size of the content
            # transmitted *less* than the content-length!
            f = open(path, 'rb')
        except IOError:
            self.send_error(404, "File not found")
            return None
        self.send_response(206, "Partial Content")
        file_size = str(os.fstat(f.fileno())[6])
        range_size = str(range_end - range_begin + 1)
        self.send_header("Accept-Ranges", "bytes")
        self.send_header("Content-Length", range_size)
        self.send_header("Content-Range", "bytes %s-%s/%s" % (range_begin,
                                                              range_end,
                                                              file_size))
        self.send_header("Content-type", ctype)
        self.end_headers()
        return f

    def translate_path(self, path):
        """
        Translate a /-separated PATH to the local filename syntax.

        Components that mean special things to the local file system
        (e.g. drive or directory names) are ignored.  (XXX They should
        probably be diagnosed.)

        """
        # abandon query parameters
        path = urlparse.urlparse(path)[2]
        path = posixpath.normpath(urllib.unquote(path))
        words = path.split('/')
        words = filter(None, words)
        path = self.server.cwd
        for word in words:
            _, word = os.path.splitdrive(word)
            _, word = os.path.split(word)
            if word in (os.curdir, os.pardir):
                continue
            path = os.path.join(path, word)
        return path

    def address_string(self):
        '''
        This HTTP server does not care about name resolution for the requests

        The first reason is that most of the times our clients are going to be
        virtual machines without a proper name resolution setup. Also, by not
        resolving names, we should be a bit faster and be resilient about
        misconfigured or resilient name servers.
        '''
        return self.client_address[0]

    def log_message(self, fmt, *args):
        logging.debug("builtin http server handling request from %s: %s" %
                      (self.address_string(), fmt % args))


def http_server(port=8000, cwd=None, terminate_callable=None):
    http = BaseHTTPServer.HTTPServer(('', port), HTTPRequestHandler)
    http.timeout = 1

    if cwd is None:
        cwd = os.getcwd()
    http.cwd = cwd

    while True:
        if terminate_callable is not None:
            terminate = terminate_callable()
        else:
            terminate = False

        if terminate:
            break

        http.handle_request()


if __name__ == '__main__':
    http_server()

########NEW FILE########
__FILENAME__ = installer
'''
Installer classes are responsible for building and installing virtualization
specific software components. This is the main entry point for tests that
wish to install virtualization software components.

The most common use case is to simply call make_installer() inside your tests.
'''

from autotest.client.shared import error
import base_installer
import qemu_installer

__all__ = ['InstallerRegistry', 'INSTALLER_REGISTRY', 'make_installer',
           'run_installers']


class InstallerRegistry(dict):

    '''
    Holds information on known installer classes

    This class is used to create a single instance, named INSTALLER_REGISTRY,
    that will hold all information on known installer types.

    For registering a new installer class, use the register() method. If the
    virt type is not set explicitly, it will be set to 'base'. Example:

    >>> INSTALLER_REGISTRY.register('yum', base_installer.YumInstaller)

    If you want to register a virt specific installer class, set the virt
    (third) param:

    >>> INSTALLER_REGISTRY.register('yum', qemu_installer.YumInstaller, 'qemu')

    For getting a installer class, use the get_installer() method. This method
    has a fallback option 'get_default_virt' that will return a generic virt
    installer if set to true.
    '''

    DEFAULT_VIRT_NAME = 'base'

    def __init__(self, **kwargs):
        dict.__init__(self, **kwargs)
        self[self.DEFAULT_VIRT_NAME] = {}

    def register(self, mode, klass, virt=None):
        '''
        Register a class as responsible for installing virt software components

        If virt is not set, it will assume a default of 'base'.
        '''
        if virt is None:
            virt = self.DEFAULT_VIRT_NAME
        elif not self.has_key(virt):
            self[virt] = {}

        self[virt][mode] = klass

    def get_installer(self, mode, virt=None, get_default_virt=False):
        '''
        Gets a installer class that should be able to install the virt software

        Always try to use classes that are specific to the virtualization
        technology that is being tested. If you have confidence that the
        installation is rather trivial and does not require custom steps, you
        may be able to get away with a base class (by setting get_default_virt
        to True).
        '''
        if virt is None:
            virt = self.DEFAULT_VIRT_NAME
        if not self.has_key(virt):
            # return a base installer so the test could and give it a try?
            if get_default_virt:
                return self[self.DEFAULT_VIRT_NAME].get(mode)
        else:
            return self[virt].get(mode)

    def get_modes(self, virt=None):
        '''
        Returns a list of all registered installer modes
        '''
        if virt is None:
            virt = self.DEFAULT_VIRT_NAME

        if not self.has_key(virt):
            return []

        return self[virt].keys()


#
# InstallerRegistry unique instance
#
INSTALLER_REGISTRY = InstallerRegistry()


#
# Register base installers
#
INSTALLER_REGISTRY.register('yum',
                            base_installer.YumInstaller)
INSTALLER_REGISTRY.register('koji',
                            base_installer.KojiInstaller)
INSTALLER_REGISTRY.register('git_repo',
                            base_installer.GitRepoInstaller)
INSTALLER_REGISTRY.register('local_src',
                            base_installer.LocalSourceDirInstaller)
INSTALLER_REGISTRY.register('local_tar',
                            base_installer.LocalSourceTarInstaller)
INSTALLER_REGISTRY.register('remote_tar',
                            base_installer.RemoteSourceTarInstaller)

#
# Register KVM specific installers
#
INSTALLER_REGISTRY.register('yum',
                            base_installer.YumInstaller,
                            'qemu')
INSTALLER_REGISTRY.register('koji',
                            base_installer.KojiInstaller,
                            'qemu')
INSTALLER_REGISTRY.register('git_repo',
                            qemu_installer.GitRepoInstaller,
                            'qemu')
INSTALLER_REGISTRY.register('local_src',
                            qemu_installer.LocalSourceDirInstaller,
                            'qemu')
INSTALLER_REGISTRY.register('local_tar',
                            qemu_installer.LocalSourceTarInstaller,
                            'qemu')
INSTALLER_REGISTRY.register('remote_tar',
                            qemu_installer.RemoteSourceTarInstaller,
                            'qemu')


def installer_name_split(fullname, virt=None):
    '''
    Split a full installer name into mode and short name

    Examples:
       git_repo_foo -> (git_repo, foo)
       local_src_foo -> (local_src, foo)
    '''
    for mode in INSTALLER_REGISTRY.get_modes(virt):
        if fullname.startswith('%s_' % mode):
            _, _name = fullname.split(mode)
            name = _name[1:]
            return (mode, name)

    return (None, None)


def make_installer(fullname, params, test=None):
    '''
    Installer factory: returns a new installer for the chosen mode and vm type

    This is the main entry point for acquiring an installer. Tests, such as
    the build test, should use this function.

    Param priority evaluation order is 'install_mode', then 'mode'. For virt
    type, 'vm_type' is consulted.

    :param fullname: the full name of instance, eg: git_repo_foo
    :param params: dictionary with parameters generated from cartersian config
    :param test: the test instance
    '''
    virt = params.get("vm_type", None)

    mode, name = installer_name_split(fullname, virt)
    if mode is None or name is None:

        error_msg = ('Invalid installer mode or name for "%s". Probably an '
                     'installer has not been registered' % fullname)
        if virt is not None:
            error_msg += ' specifically for virt type "%s"' % virt

        raise error.TestError(error_msg)

    klass = INSTALLER_REGISTRY.get_installer(mode, virt)
    if klass is None:
        raise error.TestError('Installer mode %s is not registered' % mode)
    else:
        return klass(mode, name, test, params)


def run_installers(params, test=None):
    '''
    Runs the installation routines for all installers, one at a time

    This is usually the main entry point for tests
    '''
    for name in params.get("installers", "").split():
        installer = make_installer(name, params, test)
        installer.install()

########NEW FILE########
__FILENAME__ = installer_unittest
#!/usr/bin/python

import unittest

import common
import installer
import cartesian_config


class installer_test(unittest.TestCase):

    def setUp(self):
        self.registry = installer.InstallerRegistry()

    def test_register_get_installer(self):
        install_mode = 'custom_install_mode'
        virt_type = 'custom_virt_type'

        class CustomVirtInstaller:
            pass

        self.registry.register(install_mode, CustomVirtInstaller, virt_type)
        klass = self.registry.get_installer(install_mode, virt_type)
        self.assertTrue(klass is CustomVirtInstaller)

    def test_register_get_installer_default(self):
        install_mode = 'base_install_mode'

        class BaseVirtInstaller:
            pass

        self.registry.register(install_mode, BaseVirtInstaller)
        klass = self.registry.get_installer(install_mode,
                                            get_default_virt=True)
        self.assertTrue(klass is BaseVirtInstaller)

        klass = self.registry.get_installer(install_mode,
                                            virt=None,
                                            get_default_virt=True)
        self.assertTrue(klass is BaseVirtInstaller)

    def test_make_installer(self):
        config = """install_mode = test_install_mode
vm_type = test"""

        class Installer:

            def __init__(self, mode, name, test, params):
                pass

        installer.INSTALLER_REGISTRY.register('test_install_mode',
                                              Installer,
                                              'test')

        config_parser = cartesian_config.Parser()
        config_parser.parse_string(config)
        params = config_parser.get_dicts().next()

        instance = installer.make_installer("test_install_mode_test", params)
        self.assertTrue(isinstance(instance, Installer))


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = iscsi
"""
Basic iscsi support for Linux host with the help of commands
iscsiadm and tgtadm.

This include the basic operates such as login and get device name by
target name. And it can support the real iscsi access and emulated
iscsi in localhost then access it.
"""


import re
import os
import logging
from autotest.client import os_dep
from autotest.client.shared import utils, error


def iscsi_get_sessions():
    """
    Get the iscsi sessions activated
    """
    cmd = "iscsiadm --mode session"

    output = utils.system_output(cmd, ignore_status=True)
    sessions = []
    if "No active sessions" not in output:
        for session in output.splitlines():
            ip_addr = session.split()[2].split(',')[0]
            target = session.split()[3]
            sessions.append((ip_addr, target))
    return sessions


def iscsi_get_nodes():
    """
    Get the iscsi nodes
    """
    cmd = "iscsiadm --mode node"

    output = utils.system_output(cmd)
    pattern = r"(\d+\.\d+\.\d+\.\d+|\W:{2}\d\W):\d+,\d+\s+([\w\.\-:\d]+)"
    nodes = []
    if "No records found" not in output:
        nodes = re.findall(pattern, output)
    return nodes


def iscsi_login(target_name):
    """
    Login to a target with the target name

    :param target_name: Name of the target
    """
    cmd = "iscsiadm --mode node --login --targetname %s" % target_name
    output = utils.system_output(cmd)

    target_login = ""
    if "successful" in output:
        target_login = target_name

    return target_login


def iscsi_logout(target_name=None):
    """
    Logout from a target. If the target name is not set then logout all
    targets.

    :params target_name: Name of the target.
    """
    if target_name:
        cmd = "iscsiadm --mode node --logout -T %s" % target_name
    else:
        cmd = "iscsiadm --mode node --logout all"
    output = utils.system_output(cmd)

    target_logout = ""
    if "successful" in output:
        target_logout = target_name

    return target_logout


def iscsi_discover(portal_ip):
    """
    Query from iscsi server for available targets

    :param portal_ip: Ip for iscsi server
    """
    cmd = "iscsiadm -m discovery -t sendtargets -p %s" % portal_ip
    output = utils.system_output(cmd, ignore_status=True)

    session = ""
    if "Invalid" in output:
        logging.debug(output)
    else:
        session = output
    return session


class Iscsi(object):

    """
    Basic iscsi support class. Will handle the emulated iscsi export and
    access to both real iscsi and emulated iscsi device.
    """

    def __init__(self, params, root_dir="/tmp"):
        os_dep.command("iscsiadm")
        self.target = params.get("target")
        self.export_flag = False
        if params.get("portal_ip"):
            self.portal_ip = params.get("portal_ip")
        else:
            self.portal_ip = utils.system_output("hostname")
        if params.get("iscsi_thread_id"):
            self.id = params.get("iscsi_thread_id")
        else:
            self.id = utils.generate_random_string(4)
        self.initiator = params.get("initiator")
        if params.get("emulated_image"):
            self.initiator = None
            os_dep.command("tgtadm")
            emulated_image = params.get("emulated_image")
            self.emulated_image = os.path.join(root_dir, emulated_image)
            self.emulated_id = ""
            self.emulated_size = params.get("image_size")
            self.unit = self.emulated_size[-1].upper()
            self.emulated_size = self.emulated_size[:-1]
            # maps K,M,G,T => (count, bs)
            emulated_size = {'K': (1, 1),
                             'M': (1, 1024),
                             'G': (1024, 1024),
                             'T': (1024, 1048576),
                             }
            if emulated_size.has_key(self.unit):
                block_size = emulated_size[self.unit][1]
                size = int(self.emulated_size) * emulated_size[self.unit][0]
                self.create_cmd = ("dd if=/dev/zero of=%s count=%s bs=%sK"
                                   % (self.emulated_image, size, block_size))

    def logged_in(self):
        """
        Check if the session is login or not.
        """
        sessions = iscsi_get_sessions()
        login = False
        if self.target in map(lambda x: x[1], sessions):
            login = True
        return login

    def portal_visible(self):
        """
        Check if the portal can be found or not.
        """
        return bool(re.findall("%s$" % self.target,
                               iscsi_discover(self.portal_ip), re.M))

    def login(self):
        """
        Login session for both real iscsi device and emulated iscsi. Include
        env check and setup.
        """
        login_flag = False
        if self.portal_visible():
            login_flag = True
        elif self.initiator:
            logging.debug("Try to update iscsi initiatorname")
            cmd = "mv /etc/iscsi/initiatorname.iscsi "
            cmd += "/etc/iscsi/initiatorname.iscsi-%s" % self.id
            utils.system(cmd)
            fd = open("/etc/iscsi/initiatorname.iscsi", 'w')
            fd.write("InitiatorName=%s" % self.initiator)
            fd.close()
            utils.system("service iscsid restart")
            if self.portal_visible():
                login_flag = True
        elif self.emulated_image:
            self.export_target()
            utils.system("service iscsid restart")
            if self.portal_visible():
                login_flag = True

        if login_flag:
            iscsi_login(self.target)

    def get_device_name(self):
        """
        Get device name from the target name.
        """
        cmd = "iscsiadm -m session -P 3"
        device_name = ""
        if self.logged_in():
            output = utils.system_output(cmd)
            pattern = r"Target:\s+%s.*?disk\s(\w+)\s+\S+\srunning" % self.target
            device_name = re.findall(pattern, output, re.S)
            try:
                device_name = "/dev/%s" % device_name[0]
            except IndexError:
                logging.error("Can not find target '%s' after login.", self.target)
        else:
            logging.error("Session is not logged in yet.")
        return device_name

    def get_target_id(self):
        """
        Get target id from image name. Only works for emulated iscsi device
        """
        cmd = "tgtadm --lld iscsi --mode target --op show"
        target_info = utils.system_output(cmd)
        target_id = ""
        for line in re.split("\n", target_info):
            if re.findall("Target\s+(\d+)", line):
                target_id = re.findall("Target\s+(\d+)", line)[0]
            if re.findall("Backing store path:\s+(/+.+)", line):
                if self.emulated_image in line:
                    break
        else:
            target_id = ""

        return target_id

    def export_target(self):
        """
        Export target in localhost for emulated iscsi
        """
        if not os.path.isfile(self.emulated_image):
            utils.system(self.create_cmd)
        cmd = "tgtadm --lld iscsi --mode target --op show"
        try:
            output = utils.system_output(cmd)
        except error.CmdError:
            utils.system("service tgtd restart")
            output = utils.system_output(cmd)
        if not re.findall("%s$" % self.target, output, re.M):
            logging.debug("Need to export target in host")
            output = utils.system_output(cmd)
            used_id = re.findall("Target\s+(\d+)", output)
            emulated_id = 1
            while str(emulated_id) in used_id:
                emulated_id += 1
            self.emulated_id = str(emulated_id)
            cmd = "tgtadm --mode target --op new --tid %s" % self.emulated_id
            cmd += " --lld iscsi --targetname %s" % self.target
            utils.system(cmd)
            cmd = "tgtadm --lld iscsi --op bind --mode target "
            cmd += "--tid %s -I ALL" % self.emulated_id
            utils.system(cmd)
        else:
            target_strs = re.findall("Target\s+(\d+):\s+%s$" %
                                     self.target, output, re.M)
            self.emulated_id = target_strs[0].split(':')[0].split()[-1]

        cmd = "tgtadm --lld iscsi --mode target --op show"
        try:
            output = utils.system_output(cmd)
        except error.CmdError:   # In case service stopped
            utils.system("service tgtd restart")
            output = utils.system_output(cmd)

        # Create a LUN with emulated image
        if re.findall(self.emulated_image, output, re.M):
            # Exist already
            logging.debug("Exported image already exists.")
            self.export_flag = True
            return
        else:
            luns = len(re.findall("\s+LUN:\s(\d+)", output, re.M))
            cmd = "tgtadm --mode logicalunit --op new "
            cmd += "--tid %s --lld iscsi " % self.emulated_id
            cmd += "--lun %s " % luns
            cmd += "--backing-store %s" % self.emulated_image
            utils.system(cmd)
            self.export_flag = True

    def delete_target(self):
        """
        Delete target from host.
        """
        cmd = "tgtadm --lld iscsi --mode target --op show"
        output = utils.system_output(cmd)
        if re.findall("%s$" % self.target, output, re.M):
            if self.emulated_id:
                cmd = "tgtadm --lld iscsi --mode target --op delete "
                cmd += "--tid %s" % self.emulated_id
                utils.system(cmd)

    def logout(self):
        """
        Logout from target.
        """
        if self.logged_in():
            iscsi_logout(self.target)

    def cleanup(self):
        """
        Clean up env after iscsi used.
        """
        self.logout()
        if os.path.isfile("/etc/iscsi/initiatorname.iscsi-%s" % self.id):
            cmd = " mv /etc/iscsi/initiatorname.iscsi-%s" % self.id
            cmd += " /etc/iscsi/initiatorname.iscsi"
            utils.system(cmd)
            cmd = "service iscsid restart"
            utils.system(cmd)
        if self.export_flag:
            self.delete_target()

########NEW FILE########
__FILENAME__ = iscsi_unittest
#!/usr/bin/python
import unittest
import os

try:
    import autotest.common as common
except ImportError:
    import common

import iscsi
from autotest.client.shared.test_utils import mock
from autotest.client import os_dep
from autotest.client.shared import utils


class iscsi_test(unittest.TestCase):

    def setup_stubs_init(self):
        os_dep.command.expect_call("iscsiadm")
        utils.system_output.expect_call("hostname").and_return("localhost")
        os_dep.command.expect_call("tgtadm")

    def setup_stubs_login(self, iscsi_obj):
        c_cmd = "dd if=/dev/zero of=/tmp/iscsitest count=1024 bs=1K"
        lg_cmd = "iscsiadm --mode node --login --targetname "
        lg_cmd += "%s" % iscsi_obj.target
        self.setup_stubs_portal_visible(iscsi_obj)
        os.path.isfile.expect_call(iscsi_obj.emulated_image).and_return(False)
        utils.system.expect_call(c_cmd)
        self.setup_stubs_export_target(iscsi_obj)
        utils.system.expect_call("service iscsid restart")
        self.setup_stubs_portal_visible(iscsi_obj, "127.0.0.1:3260,1 %s"
                                        % iscsi_obj.target)
        lg_msg = "successful"
        utils.system_output.expect_call(lg_cmd).and_return(lg_msg)

    def setup_stubs_get_device_name(self, iscsi_obj):
        s_msg = "tcp [15] 127.0.0.1:3260,1 %s" % iscsi_obj.target
        utils.system_output.expect_call("iscsiadm --mode session",
                                        ignore_status=True
                                        ).and_return(s_msg)
        detail = "Target: iqn.iscsitest\n Attached scsi disk "
        detail += "sdb State running"
        utils.system_output.expect_call("iscsiadm -m session -P 3"
                                        ).and_return(detail)

    def setup_stubs_cleanup(self, iscsi_obj, fname=""):
        s_msg = "tcp [15] 127.0.0.1:3260,1 %s" % iscsi_obj.target
        utils.system_output.expect_call("iscsiadm --mode session",
                                        ignore_status=True
                                        ).and_return(s_msg)

        out_cmd = "iscsiadm --mode node --logout -T %s" % iscsi_obj.target
        utils.system_output.expect_call(out_cmd).and_return("successful")
        os.path.isfile.expect_call(fname).and_return(False)
        s_cmd = "tgtadm --lld iscsi --mode target --op show"
        utils.system_output.expect_call(s_cmd
                                        ).and_return("Target 1: iqn.iscsitest")
        d_cmd = "tgtadm --lld iscsi --mode target --op delete"
        d_cmd += " --tid %s" % iscsi_obj.emulated_id
        utils.system.expect_call(d_cmd)

    def setup_stubs_logged_in(self, result=""):
        utils.system_output.expect_call("iscsiadm --mode session",
                                        ignore_status=True
                                        ).and_return(result)

    def setup_stubs_portal_visible(self, iscsi_obj, result=""):
        host_name = iscsi_obj.portal_ip
        v_cmd = "iscsiadm -m discovery -t sendtargets -p %s" % host_name
        utils.system_output.expect_call(v_cmd,
                                        ignore_status=True).and_return(result)

    def setup_stubs_export_target(self, iscsi_obj):
        s_cmd = "tgtadm --lld iscsi --mode target --op show"
        utils.system_output.expect_call(s_cmd).and_return("")
        utils.system_output.expect_call(s_cmd).and_return("")
        t_cmd = "tgtadm --mode target --op new --tid"
        t_cmd += " %s --lld iscsi " % iscsi_obj.emulated_id
        t_cmd += "--targetname %s" % iscsi_obj.target
        utils.system.expect_call(t_cmd)
        l_cmd = "tgtadm --lld iscsi --op bind --mode target"
        l_cmd += " --tid %s -I ALL" % iscsi_obj.emulated_id
        utils.system.expect_call(l_cmd)
        utils.system_output.expect_call(s_cmd).and_return("")
        t_cmd = "tgtadm --mode logicalunit --op new "
        t_cmd += "--tid %s --lld iscsi " % iscsi_obj.emulated_id
        t_cmd += "--lun %s " % 0
        t_cmd += "--backing-store %s" % iscsi_obj.emulated_image
        utils.system.expect_call(t_cmd)

    def setup_stubs_get_target_id(self):
        s_cmd = "tgtadm --lld iscsi --mode target --op show"
        s_msg = "Target 1: iqn.iscsitest\nBacking store path: /tmp/iscsitest"
        utils.system_output.expect_call(s_cmd).and_return(s_msg)

    def setUp(self):
        # The normal iscsi with iscsi server should configure following
        # parameters. As this will need env support only test emulated
        # iscsi in local host.
        # self.iscsi_params = {"target": "",
        #                       "portal_ip": "",
        #                       "initiator": ""}

        self.iscsi_emulated_params = {"emulated_image": "/tmp/iscsitest",
                                      "target": "iqn.iscsitest",
                                      "image_size": "1024K"}
        self.god = mock.mock_god()
        self.god.stub_function(os_dep, "command")
        self.god.stub_function(utils, "system")
        self.god.stub_function(utils, "system_output")
        self.god.stub_function(os.path, "isfile")

    def tearDown(self):
        self.god.unstub_all()

    def test_iscsi_get_device_name(self):
        self.setup_stubs_init()
        iscsi_emulated = iscsi.Iscsi(self.iscsi_emulated_params)
        iscsi_emulated.emulated_id = "1"
        self.setup_stubs_login(iscsi_emulated)
        iscsi_emulated.login()
        self.setup_stubs_get_device_name(iscsi_emulated)
        self.assertNotEqual(iscsi_emulated.get_device_name(), "")
        fname = "/etc/iscsi/initiatorname.iscsi-%s" % iscsi_emulated.id
        self.setup_stubs_cleanup(iscsi_emulated, fname=fname)
        iscsi_emulated.cleanup()
        self.god.check_playback()

    def test_iscsi_login(self):
        self.setup_stubs_init()
        iscsi_emulated = iscsi.Iscsi(self.iscsi_emulated_params)
        self.setup_stubs_logged_in()
        self.assertFalse(iscsi_emulated.logged_in())
        result = "tcp [15] 127.0.0.1:3260,1 %s" % iscsi_emulated.target
        self.setup_stubs_logged_in(result)
        self.assertTrue(iscsi_emulated.logged_in())

    def test_iscsi_visible(self):
        self.setup_stubs_init()
        iscsi_emulated = iscsi.Iscsi(self.iscsi_emulated_params)
        self.setup_stubs_portal_visible(iscsi_emulated)
        self.assertFalse(iscsi_emulated.portal_visible())
        self.setup_stubs_portal_visible(iscsi_emulated, "127.0.0.1:3260,1 %s"
                                        % iscsi_emulated.target)

    def test_iscsi_target_id(self):
        self.setup_stubs_init()
        iscsi_emulated = iscsi.Iscsi(self.iscsi_emulated_params)
        self.setup_stubs_get_target_id()
        self.assertNotEqual(iscsi_emulated.get_target_id(), "")


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = libvirt_network_unittest
#!/usr/bin/env python
"""
Unit tests for Manipulator classes in libvirt_xml module.
"""
import unittest

import common
from virsh_unittest import FakeVirshFactory
from autotest.client.utils import CmdResult
from libvirt_xml.network_xml import NetworkXML
from staging.backports import itertools

# The output of virsh.net_list with only default net
_DEFAULT_NET = (' Name                 State      Autostart     Persistent\n'
                '----------------------------------------------------------\n'
                ' default              active     yes           yes\n')

# Set initial state of test net
global _net_state
_net_state = {'active': False,
              'autostart': False,
              'persistent': False}


class NetworkTestBase(unittest.TestCase):

    """
    Base class for NetworkXML test providing fake virsh commands.
    """

    @staticmethod
    def _net_list(option='--all', **dargs):
        """Bogus net_list command"""
        cmd = 'virsh net-list --all'
        if not _net_state['active'] and not _net_state['persistent']:
            test_net = ''
        else:
            if _net_state['active']:
                active = 'active'
            else:
                active = 'inactive'

            if _net_state['persistent']:
                persistent = 'yes'
            else:
                persistent = 'no'

            if _net_state['autostart']:
                autostart = 'yes'
            else:
                autostart = 'no'

            test_net = ' %-21s%-11s%-14s%-11s\n' % (
                'unittest', active, autostart, persistent)
        output = _DEFAULT_NET + test_net
        return CmdResult(cmd, output)

    @staticmethod
    def _net_define(xmlfile='unittest.xml', **dargs):
        """Bogus net_define command"""
        _net_state['persistent'] = True

    @staticmethod
    def _net_undefine(name='unittest', **dargs):
        """Bogus net_undefine command"""
        _net_state['persistent'] = False
        _net_state['autostart'] = False

    @staticmethod
    def _net_start(name='unittest', **dargs):
        """Bogus net_start command"""
        _net_state['active'] = True

    @staticmethod
    def _net_destroy(name='unittest', **dargs):
        """Bogus net_destroy command"""
        _net_state['active'] = False

    @staticmethod
    def _net_autostart(name='unittest', extra='', **dargs):
        """Bogus net_autostart command"""
        if _net_state['persistent']:
            if extra == '--disable':
                _net_state['autostart'] = False
            else:
                _net_state['autostart'] = True
        else:
            _net_state['autostart'] = False

    def setUp(self):
        # Use defined virsh methods below
        self.bogus_virsh = FakeVirshFactory(preserve=['net_state_dict'])
        self.bogus_virsh.__super_set__('net_list', self._net_list)
        self.bogus_virsh.__super_set__('net_define', self._net_define)
        self.bogus_virsh.__super_set__('net_undefine', self._net_undefine)
        self.bogus_virsh.__super_set__('net_start', self._net_start)
        self.bogus_virsh.__super_set__('net_destroy', self._net_destroy)
        self.bogus_virsh.__super_set__('net_autostart', self._net_autostart)


class NetworkXMLTest(NetworkTestBase):

    """
    Unit test class for manipulator methods in NetworkXML class.
    """

    def test_sync_and_state_dict(self):
        """
        Unit test for sync and state_dict methods of NetworkXML class.

        Traverse all possible state and call sync using the state.
        """

        # Test sync without state option
        test_xml = NetworkXML(network_name='unittest',
                              virsh_instance=self.bogus_virsh)
        test_xml.sync()
        new_state = test_xml.state_dict()
        state = {'active': True,
                 'persistent': True,
                 'autostart': True}
        self.assertEqual(state, new_state)

        for values in itertools.product([True, False], repeat=3):
            # Change network to all possible states.
            keys = ['active', 'persistent', 'autostart']
            state = dict(zip(keys, values))
            test_xml.sync(state=state)

            # Check result's validity.
            new_state = test_xml.state_dict()
            # Transient network can't set autostart
            if state == {'active': True,
                         'persistent': False,
                         'autostart': True}:
                state = {'active': True,
                         'persistent': False,
                         'autostart': False}
            # Non-exist network should return None when retieving state.
            if not state['active'] and not state['persistent']:
                assert new_state is None
            else:
                self.assertEqual(state, new_state)

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = libvirt_storage
"""
Classes and functions to handle block/disk images for libvirt.

This exports:
  - two functions for get image/blkdebug filename
  - class for image operates and basic parameters
  - class for storage pool operations
"""

import re
import logging
import time
from autotest.client.shared import error
import storage
import virsh


class QemuImg(storage.QemuImg):

    """
    libvirt class for handling operations of disk/block images.
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images.
        """
        storage.QemuImg(params, root_dir, tag)
        # Please init image_cmd for libvirt in this class
        # self.image_cmd =

    def create(self, params):
        """
        Create an image.

        :param params: Dictionary containing the test parameters.

        :note: params should contain:
        """
        raise NotImplementedError

    def convert(self, params, root_dir):
        """
        Convert image

        :param params: A dict
        :param root_dir: dir for save the convert image

        :note: params should contain:
        """
        raise NotImplementedError

    def rebase(self, params):
        """
        Rebase image

        :param params: A dict

        :note: params should contain:
        """
        raise NotImplementedError

    def commit(self):
        """
        Commit image to it's base file
        """
        raise NotImplementedError

    def snapshot_create(self):
        """
        Create a snapshot image.

        :note: params should contain:
        """
        raise NotImplementedError

    def snapshot_del(self, blkdebug_cfg=""):
        """
        Delete a snapshot image.

        :param blkdebug_cfg: The configure file of blkdebug

        :note: params should contain:
               snapshot_image_name -- the name of snapshot image file
        """
        raise NotImplementedError

    def remove(self):
        """
        Remove an image file.

        :note: params should contain:
        """
        raise NotImplementedError

    def check_image(self, params, root_dir):
        """
        Check an image using the appropriate tools for each virt backend.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.

        :note: params should contain:

        :raise VMImageCheckError: In case qemu-img check fails on the image.
        """
        raise NotImplementedError


class StoragePool(object):

    """
    Pool Manager for libvirt storage with virsh commands
    """

    def __init__(self, virsh_instance=virsh):
        # An instance of Virsh class
        # Help to setup connection to virsh instance
        self.virsh_instance = virsh_instance

    def list_pools(self):
        """
        Return a dict include pools' information with structure:
            pool_name ==> pool_details(a dict: feature ==> value)
        """
        # Allow it raise exception if command has executed failed.
        result = self.virsh_instance.pool_list("--all", ignore_status=False)
        pools = {}
        lines = result.stdout.strip().splitlines()
        if len(lines) > 2:
            head = lines[0]
            lines = lines[2:]
        else:
            return pools

        for line in lines:
            details = line.split()
            details_dict = {}
            head_iter = enumerate(head.split())
            while True:
                try:
                    (index, column) = head_iter.next()
                except StopIteration:
                    break
                if re.match("[N|n]ame", column):
                    pool_name = details[index]
                else:
                    details_dict[column] = details[index]
            pools[pool_name] = details_dict
        return pools

    def pool_exists(self, name):
        """
        Check whether pool exists on given libvirt
        """
        try:
            pools = self.list_pools()
        except error.CmdError:
            return False

        return name in pools

    def pool_state(self, name):
        """
        Get pool's state.

        :return: active/inactive, and None when something wrong.
        """
        try:
            pools = self.list_pools()
        except error.CmdError:
            return None

        if self.pool_exists(name):
            details_dict = pools[name]
            try:
                return details_dict['State']
            except KeyError:
                pass
        return None

    def pool_info(self, name):
        """
        Get pool's information.

        :return: A dict include pool's information:
                Name ==> value
                UUID ==> value
                ...
        """
        info = {}
        try:
            result = self.virsh_instance.pool_info(name, ignore_status=False)
        except error.CmdError:
            return info

        for line in result.stdout.splitlines():
            params = line.split(':')
            if len(params) == 2:
                name = params[0].strip()
                value = params[1].strip()
                info[name] = value
        return info

    def get_pool_uuid(self, name):
        """
        Get pool's uuid.

        :return: Pool uuid.
        """
        return self.pool_info(name)["UUID"]

    def is_pool_active(self, name):
        """
        Check whether pool is active on given libvirt
        """
        if self.pool_state(name) == "active":
            return True
        return False

    def is_pool_persistent(self, name):
        """
        Check whether pool is persistent
        """
        if self.pool_info(name)["Persistent"] == "yes":
            return True
        return False

    def delete_pool(self, name):
        """
        Destroy and Delete a pool if it exists on given libvirt
        """
        if self.is_pool_active(name):
            if not self.virsh_instance.pool_destroy(name):
                # TODO: Allow pool_destroy to raise exception.
                #       Because some testcase rely on this function,
                #       I should start this work after this module is accepted.
                logging.error("Destroy pool '%s' failed.", name)
                return False

        if self.pool_exists(name):
            try:
                self.virsh_instance.pool_undefine(name, ignore_status=False)
            except error.CmdError:
                logging.error("Undefine pool '%s' failed.", name)
                return False
        logging.info("Deleted pool '%s'", name)
        return True

    def set_pool_autostart(self, name):
        """
        Set given pool as autostart
        """
        try:
            self.virsh_instance.pool_autostart(name, ignore_status=False)
        except error.CmdError:
            logging.error("Autostart pool '%s' failed.", name)
            return False
        logging.info("Set pool '%s' autostart.", name)
        return True

    def build_pool(self, name):
        """
        Build pool.
        """
        try:
            self.virsh_instance.pool_build(name, ignore_status=False)
        except error.CmdError:
            logging.error("Build pool '%s' failed.", name)
            return False
        logging.info("Built pool '%s'", name)
        return True

    def start_pool(self, name):
        """
        Start pool if it is inactive.
        """
        if self.is_pool_active(name):
            logging.info("Pool '%s' is already active.", name)
            return True
        try:
            self.virsh_instance.pool_start(name, ignore_status=False)
        except error.CmdError:
            logging.error("Start pool '%s' failed.", name)
            return False
        logging.info("Started pool '%s'", name)
        return True

    def destroy_pool(self, name):
        """
        Destroy pool if it is active.
        """
        if not self.is_pool_active(name):
            logging.info("pool '%s' is already inactive.", name)
            return True
        return self.virsh_instance.pool_destroy(name)

    def define_dir_pool(self, name, target_path):
        """
        Define a directory type pool.
        """
        try:
            self.virsh_instance.pool_define_as(name, "dir", target_path,
                                               ignore_status=False)
        except error.CmdError:
            logging.error("Define dir pool '%s' failed.", name)
            return False
        logging.info("Defined pool '%s'", name)
        return True

    def define_fs_pool(self, name, block_device, target_path):
        """
        Define a filesystem type pool.
        """
        try:
            self.virsh_instance.pool_define_as(name, "fs", target_path,
                                               extra="--source-dev %s" % block_device,
                                               ignore_status=False)
        except error.CmdError:
            logging.error("Define fs pool '%s' failed.", name)
            return False
        logging.info("Defined pool '%s'", name)
        return True

    def define_lvm_pool(self, name, block_device, vg_name, target_path):
        """
        Define a lvm type pool.
        """
        try:
            extra = "--source-dev %s --source-name %s" % (block_device,
                                                          vg_name)
            self.virsh_instance.pool_define_as(name, "logical", target_path,
                                               extra, ignore_status=False)
        except error.CmdError:
            logging.error("Define logic pool '%s' failed.", name)
            return False
        logging.info("Defined pool '%s'", name)
        return True

    def define_disk_pool(self, name, block_device, target_path):
        """
        Define a disk type pool.
        """
        try:
            extra = "--source-dev %s" % block_device
            self.virsh_instance.pool_define_as(name, "disk", target_path,
                                               extra, ignore_status=False)
        except error.CmdError:
            logging.error("Define disk pool '%s' failed.", name)
            return False
        logging.info("Defined pool '%s'", name)
        return True

    def define_iscsi_pool(self, name, source_host, source_dev, target_path):
        """
        Define a iscsi type pool.
        """
        try:
            extra = "--source-host %s  --source-dev %s" % (source_host,
                                                           source_dev)
            self.virsh_instance.pool_define_as(name, "iscsi", target_path,
                                               extra, ignore_status=False)
        except error.CmdError:
            logging.error("Define iscsi pool '%s' failed.", name)
            return False
        logging.info("Define pool '%s'", name)
        return True

    def define_netfs_pool(self, name, source_host, source_path, target_path):
        """
        Define a netfs type pool.
        """
        try:
            extra = "--source-host %s --source-path %s" % (source_host,
                                                           target_path)
            self.virsh_instance.pool_define_as(name, "netfs", target_path,
                                               extra, ignore_status=False)
        except error.CmdError:
            logging.error("Define netfs pool '%s' failed.", name)
            return False
        logging.info("Define pool '%s'", name)
        return True


class PoolVolume(object):

    """Volume Manager for libvirt storage pool."""

    def __init__(self, pool_name, virsh_instance=virsh):
        self.pool_name = pool_name
        self.virsh_instance = virsh_instance

    def list_volumes(self):
        """
        Return a dict include volumes' name(key) and path(value).
        """
        result = self.virsh_instance.vol_list(self.pool_name,
                                              ignore_status=False)
        volumes = {}
        lines = result.stdout.strip().splitlines()
        if len(lines) > 2:
            head = lines[0]
            lines = lines[2:]
        else:
            return volumes

        for line in lines:
            # Path may be not standard unix path
            try:
                path = re.findall("\s+/.*", line)[0]
            except IndexError:
                # Do not find a path
                path = ""
            name = line.split(path)[0].lstrip()
            volumes[name] = path.strip()
        return volumes

    def volume_exists(self, name):
        try:
            volumes = self.list_volumes()
        except error.CmdError:
            return False
        return name in volumes

    def volume_info(self, name):
        """
        Get volume's information with command vol-info.
        """
        info = {}
        try:
            result = self.virsh_instance.vol_info(name, self.pool_name,
                                                  ignore_status=False)
        except error.CmdError, detail:
            logging.error("Get volume information failed:%s", detail)
            return info

        for line in result.stdout.strip().splitlines():
            attr = line.split(':')[0]
            value = line.split("%s:" % attr)[-1].strip()
            info[attr] = value
        return info

    def create_volume(self, name, capability,
                      allocation=None, frmt=None):
        """
        Create a volume in pool.
        """
        if self.volume_exists(name):
            logging.debug("Volume '%s' already exists.", name)
            return False
        try:
            self.virsh_instance.vol_create_as(name, self.pool_name,
                                              capability, allocation, frmt,
                                              ignore_status=False, debug=True)
        except error.CmdError, detail:
            logging.error("Create volume failed:%s", detail)
            return False

        if not self.volume_exists(name):
            logging.error("Created volume does not exist:%s",
                          self.list_volumes())
            return False
        return True

    def delete_volume(self, name):
        """
        Remove a volume.
        """
        if self.volume_exists(name):
            try:
                self.virsh_instance.vol_delete(name, self.pool_name,
                                               ignore_status=False)
            except error.CmdError, detail:
                logging.error("Delete volume failed:%s", detail)
                return False
            if not self.volume_exists(name):
                logging.debug("Volume '%s' has been deleted.", name)
                return True
            else:
                logging.debug("Delete volume '%s' failed.", name)
                return False
        else:
            logging.info("Volume '%s' does not exist.", name)
            return True     # Return True for expected result

########NEW FILE########
__FILENAME__ = libvirt_storage_unittest
#!/usr/bin/python
import unittest

import common
from autotest.client.utils import CmdResult
import libvirt_storage
from virsh_unittest import FakeVirshFactory

# The output of virsh.pool_list with only default pool
_DEFAULT_POOL = ("Name                 State      Autostart\n"
                 "-----------------------------------------\n"
                 "default              active      yes    \n")

# Set output of virsh.pool_list
global _pools_output
_pools_output = _DEFAULT_POOL


class PoolTestBase(unittest.TestCase):

    @staticmethod
    def _pool_list(option="--all", **dargs):
        # Bogus output of virsh commands
        cmd = "virsh pool-list --all"
        output = _pools_output
        return CmdResult(cmd, output)

    @staticmethod
    def _pool_info(name="default", **dargs):
        cmd = "virsh pool-info %s" % name
        default_output = (
            "Name:           default\n"
            "UUID:           bfe5d630-ec5d-86c2-ecca-8a5210493db7\n"
            "State:          running\n"
            "Persistent:     yes\n"
            "Autostart:      yes\n"
            "Capacity:       47.93 GiB\n"
            "Allocation:     36.74 GiB\n"
            "Available:      11.20 GiB\n")
        if name == "default":
            return CmdResult(cmd, default_output)
        else:
            return CmdResult(cmd)

    @staticmethod
    def _pool_define_as(name="unittest", pool_type="dir",
                        target="/var/tmp", **dargs):
        unittest_pool = "unittest             inactive    no\n"
        global _pools_output
        _pools_output = _DEFAULT_POOL + unittest_pool
        return True

    @staticmethod
    def _pool_build(name="unittest", **dargs):
        return True

    @staticmethod
    def _pool_start(name="unittest", **dargs):
        unittest_pool = "unittest             active     no\n"
        global _pools_output
        _pools_output = _DEFAULT_POOL + unittest_pool
        return True

    @staticmethod
    def _pool_autostart(name="unittest", **dargs):
        unittest_pool = "unittest             active     yes\n"
        global _pools_output
        _pools_output = _DEFAULT_POOL + unittest_pool
        return True

    @staticmethod
    def _pool_destroy(name="unittest", **dargs):
        unittest_pool = "unittest             inactive    yes\n"
        global _pools_output
        _pools_output = _DEFAULT_POOL + unittest_pool
        return True

    @staticmethod
    def _pool_undefine(name="unittest", **dargs):
        global _pools_output
        _pools_output = _DEFAULT_POOL
        return True

    def setUp(self):
        # To avoid not installed libvirt packages
        self.bogus_virsh = FakeVirshFactory()
        # Use defined virsh methods needed in this unittest
        self.bogus_virsh.__super_set__('pool_list', self._pool_list)
        self.bogus_virsh.__super_set__('pool_info', self._pool_info)
        self.bogus_virsh.__super_set__('pool_define_as', self._pool_define_as)
        self.bogus_virsh.__super_set__('pool_build', self._pool_build)
        self.bogus_virsh.__super_set__('pool_start', self._pool_start)
        self.bogus_virsh.__super_set__('pool_destroy', self._pool_destroy)
        self.bogus_virsh.__super_set__('pool_undefine', self._pool_undefine)
        self.bogus_virsh.__super_set__('pool_autostart', self._pool_autostart)
        self.sp = libvirt_storage.StoragePool(virsh_instance=self.bogus_virsh)


class ExistPoolTest(PoolTestBase):

    def test_exist_pool(self):
        pools = self.sp.list_pools()
        assert isinstance(pools, dict)
        # Test pool_state
        self.assertTrue(self.sp.pool_state("default") in ['active', 'inactive'])
        # Test pool_info
        self.assertNotEqual(self.sp.pool_info("default"), {})


class NewPoolTest(PoolTestBase):

    def test_dir_pool(self):
        # Used for auto cleanup
        self.pool_name = "unittest"
        global _pools_output
        self.assertTrue(self.sp.define_dir_pool(self.pool_name, "/var/tmp"))
        self.assertTrue(self.sp.build_pool(self.pool_name))
        self.assertTrue(self.sp.start_pool(self.pool_name))
        self.assertTrue(self.sp.set_pool_autostart(self.pool_name))
        self.assertTrue(self.sp.delete_pool(self.pool_name))

    def tearDown(self):
        # Confirm created pool has been cleaned up
        self.sp.delete_pool(self.pool_name)


class NotExpectedPoolTest(PoolTestBase):

    def test_not_exist_pool(self):
        self.assertFalse(self.sp.pool_exists("NOTEXISTPOOL"))
        assert self.sp.pool_state("NOTEXISTPOOL") is None
        self.assertEqual(self.sp.pool_info("NOTEXISTPOOL"), {})


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = libvirt_vm
"""
Utility classes and functions to handle Virtual Machine creation using libvirt.

:copyright: 2011 Red Hat Inc.
"""

import time
import os
import logging
import fcntl
import re
import shutil
import tempfile
from autotest.client.shared import error
from autotest.client import utils
import utils_misc
import virt_vm
import storage
import aexpect
import remote
import virsh
import libvirt_xml
import data_dir
import xml_utils


def normalize_connect_uri(connect_uri):
    """
    Processes connect_uri Cartesian into something virsh can use

    :param connect_uri: Cartesian Params setting
    :return: Normalized connect_uri
    """
    if connect_uri == 'default':
        return None
    else:  # Validate and canonicalize uri early to catch problems
        result = virsh.canonical_uri(uri=connect_uri)
        if not result:
            raise ValueError("Normalizing connect_uri %s failed" % connect_uri)
        return result


def complete_uri(ip_address):
    """
    Return a complete URI with the combination of ip_address and local uri.
    It is useful when you need to connect remote hypervisor.

    :param ip_address: an ip address or a hostname
    :return: a complete uri
    """
    # Allow to raise CmdError if canonical_uri is failed
    uri = virsh.canonical_uri(ignore_status=False)
    driver = uri.split(":")[0]
    # The libvirtd daemon's mode(system or session on qemu)
    daemon_mode = uri.split("/")[-1]
    complete_uri = "%s+ssh://%s/%s" % (driver, ip_address, daemon_mode)
    return complete_uri


def get_uri_with_transport(uri_type='qemu', transport="", dest_ip=""):
    """
    Return a URI to connect driver on dest with a specificed transport.

    :param origin_uri: The URI on dest used to connect itself directly.
    :param transport: The transport type connect to dest.
    :param dest_ip: The ip of destination.
    """
    _type2uri_ = {'qemu': "qemu:///system",
                  'qemu_system': "qemu:///system",
                  'qemu_session': "qemu:///session",
                  'lxc': "lxc:///",
                  'xen': "xen:///"}
    try:
        origin_uri = _type2uri_[uri_type]
    except KeyError:
        raise ValueError("Param uri_type = %s is not supported." % (uri_type))

    # For example:
    #   ("qemu:///system")-->("qemu", "system")
    #   ("lxc:///")-->("lxc", "")
    origin_uri_elems = origin_uri.split(":///")
    transport_uri_driver = origin_uri_elems[0]
    transport_uri_dest = origin_uri_elems[-1]
    if transport:
        transport_uri_driver = ("%s+%s" % (transport_uri_driver, transport))

    transport_uri_dest = ("://%s/%s" % (dest_ip, transport_uri_dest))
    return ("%s%s" % (transport_uri_driver, transport_uri_dest))


class VM(virt_vm.BaseVM):

    """
    This class handles all basic VM operations for libvirt.
    """

    def __init__(self, name, params, root_dir, address_cache, state=None):
        """
        Initialize the object and set a few attributes.

        :param name: The name of the object
        :param params: A dict containing VM params
                (see method make_create_command for a full description)
        :param root_dir: Base directory for relative filenames
        :param address_cache: A dict that maps MAC addresses to IP addresses
        :param state: If provided, use this as self.__dict__
        """

        if state:
            self.__dict__ = state
        else:
            self.process = None
            self.serial_ports = []
            self.serial_console = None
            self.redirs = {}
            self.vnc_port = None
            self.vnc_autoport = True
            self.pci_assignable = None
            self.netdev_id = []
            self.device_id = []
            self.pci_devices = []
            self.uuid = None
            self.remote_sessions = []

        self.spice_port = 8000
        self.name = name
        self.params = params
        self.root_dir = root_dir
        self.address_cache = address_cache
        self.vnclisten = "0.0.0.0"
        self.connect_uri = normalize_connect_uri(params.get("connect_uri",
                                                            "default"))
        if self.connect_uri:
            self.driver_type = virsh.driver(uri=self.connect_uri)
        else:
            self.driver_type = 'qemu'
        self.params['driver_type_' + self.name] = self.driver_type
        # virtnet init depends on vm_type/driver_type being set w/in params
        super(VM, self).__init__(name, params)
        logging.info("Libvirt VM '%s', driver '%s', uri '%s'",
                     self.name, self.driver_type, self.connect_uri)

    def verify_alive(self):
        """
        Make sure the VM is alive.

        :raise VMDeadError: If the VM is dead
        """
        if not self.is_alive():
            raise virt_vm.VMDeadError("Domain %s is inactive" % self.name,
                                      self.state())

    def is_alive(self):
        """
        Return True if VM is alive.
        """
        return virsh.is_alive(self.name, uri=self.connect_uri)

    def is_dead(self):
        """
        Return True if VM is dead.
        """
        return virsh.is_dead(self.name, uri=self.connect_uri)

    def is_paused(self):
        """
        Return True if VM is paused.
        """
        return (self.state() == "paused")

    def is_persistent(self):
        """
        Return True if VM is persistent.
        """
        try:
            dominfo = (virsh.dominfo(self.name,
                                     uri=self.connect_uri).stdout.strip())
            return bool(re.search(r"^Persistent:\s+[Yy]es", dominfo,
                                  re.MULTILINE))
        except error.CmdError:
            return False

    def is_autostart(self):
        """
        Return True if VM is autostart.
        """
        try:
            dominfo = (virsh.dominfo(self.name,
                                     uri=self.connect_uri).stdout.strip())
            return bool(re.search(r"^Autostart:\s+enable", dominfo,
                                  re.MULTILINE))
        except error.CmdError:
            return False

    def exists(self):
        """
        Return True if VM exists.
        """
        return virsh.domain_exists(self.name, uri=self.connect_uri)

    def undefine(self):
        """
        Undefine the VM.
        """
        try:
            virsh.undefine(self.name, uri=self.connect_uri,
                           ignore_status=False)
        except error.CmdError, detail:
            logging.error("Undefined VM %s failed:\n%s", self.name, detail)
            return False
        return True

    def define(self, xml_file):
        """
        Define the VM.
        """
        if not os.path.exists(xml_file):
            logging.error("File %s not found." % xml_file)
            return False
        try:
            virsh.define(xml_file, uri=self.connect_uri,
                         ignore_status=False)
        except error.CmdError, detail:
            logging.error("Defined VM from %s failed:\n%s", xml_file, detail)
            return False
        return True

    def state(self):
        """
        Return domain state.
        """
        return virsh.domstate(self.name, uri=self.connect_uri).stdout.strip()

    def get_id(self):
        """
        Return VM's ID.
        """
        return virsh.domid(self.name, uri=self.connect_uri).stdout.strip()

    def get_xml(self):
        """
        Return VM's xml file.
        """
        return virsh.dumpxml(self.name, uri=self.connect_uri).stdout.strip()

    def backup_xml(self, active=False):
        """
        Backup the guest's xmlfile.
        """
        # Since backup_xml() is not a function for testing,
        # we have to handle the exception here.
        try:
            xml_file = tempfile.mktemp(dir="/tmp")

            if active:
                extra = ""
            else:
                extra = "--inactive"

            virsh.dumpxml(self.name, extra=extra,
                          to_file=xml_file, uri=self.connect_uri)
            return xml_file
        except Exception, detail:
            if os.path.exists(xml_file):
                os.remove(xml_file)
            logging.error("Failed to backup xml file:\n%s", detail)
            return ""

    def clone(self, name=None, params=None, root_dir=None, address_cache=None,
              copy_state=False):
        """
        Return a clone of the VM object with optionally modified parameters.
        The clone is initially not alive and needs to be started using create().
        Any parameters not passed to this function are copied from the source
        VM.

        :param name: Optional new VM name
        :param params: Optional new VM creation parameters
        :param root_dir: Optional new base directory for relative filenames
        :param address_cache: A dict that maps MAC addresses to IP addresses
        :param copy_state: If True, copy the original VM's state to the clone.
                Mainly useful for make_create_command().
        """
        if name is None:
            name = self.name
        if params is None:
            params = self.params.copy()
        if root_dir is None:
            root_dir = self.root_dir
        if address_cache is None:
            address_cache = self.address_cache
        if copy_state:
            state = self.__dict__.copy()
        else:
            state = None
        return VM(name, params, root_dir, address_cache, state)

    def make_create_command(self, name=None, params=None, root_dir=None):
        """
        Generate a libvirt command line. All parameters are optional. If a
        parameter is not supplied, the corresponding value stored in the
        class attributes is used.

        :param name: The name of the object
        :param params: A dict containing VM params
        :param root_dir: Base directory for relative filenames

        :note: The params dict should contain:
               mem -- memory size in MBs
               cdrom -- ISO filename to use with the qemu -cdrom parameter
               extra_params -- a string to append to the qemu command
               shell_port -- port of the remote shell daemon on the guest
               (SSH, Telnet or the home-made Remote Shell Server)
               shell_client -- client program to use for connecting to the
               remote shell daemon on the guest (ssh, telnet or nc)
               x11_display -- if specified, the DISPLAY environment variable
               will be be set to this value for the qemu process (useful for
               SDL rendering)
               images -- a list of image object names, separated by spaces
               nics -- a list of NIC object names, separated by spaces

               For each image in images:
               drive_format -- string to pass as 'if' parameter for this
               image (e.g. ide, scsi)
               image_snapshot -- if yes, pass 'snapshot=on' to qemu for
               this image
               image_boot -- if yes, pass 'boot=on' to qemu for this image
               In addition, all parameters required by get_image_filename.

               For each NIC in nics:
               nic_model -- string to pass as 'model' parameter for this
               NIC (e.g. e1000)
        """
        # helper function for command line option wrappers
        def has_option(help_text, option):
            return bool(re.search(r"--%s" % option, help_text, re.MULTILINE))

        # Wrappers for all supported libvirt command line parameters.
        # This is meant to allow support for multiple libvirt versions.
        # Each of these functions receives the output of 'libvirt --help' as a
        # parameter, and should add the requested command line option
        # accordingly.

        def add_name(help_text, name):
            return " --name '%s'" % name

        def add_machine_type(help_text, machine_type):
            if has_option(help_text, "machine"):
                return " --machine %s" % machine_type
            else:
                return ""

        def add_hvm_or_pv(help_text, hvm_or_pv):
            if hvm_or_pv == "hvm":
                return " --hvm --accelerate"
            elif hvm_or_pv == "pv":
                return " --paravirt"
            else:
                logging.warning("Unknown virt type hvm_or_pv, using default.")
                return ""

        def add_mem(help_text, mem):
            return " --ram=%s" % mem

        def add_check_cpu(help_text):
            if has_option(help_text, "check-cpu"):
                return " --check-cpu"
            else:
                return ""

        def add_smp(help_text, smp):
            return " --vcpu=%s" % smp

        def add_location(help_text, location):
            if has_option(help_text, "location"):
                return " --location %s" % location
            else:
                return ""

        def add_cdrom(help_text, filename, index=None):
            if has_option(help_text, "cdrom"):
                return " --cdrom %s" % filename
            else:
                return ""

        def add_pxe(help_text):
            if has_option(help_text, "pxe"):
                return " --pxe"
            else:
                return ""

        def add_import(help_text):
            if has_option(help_text, "import"):
                return " --import"
            else:
                return ""

        def add_drive(help_text, filename, pool=None, vol=None, device=None,
                      bus=None, perms=None, size=None, sparse=False,
                      cache=None, fmt=None):
            cmd = " --disk"
            if filename:
                cmd += " path=%s" % filename
            elif pool:
                if vol:
                    cmd += " vol=%s/%s" % (pool, vol)
                else:
                    cmd += " pool=%s" % pool
            if device:
                cmd += ",device=%s" % device
            if bus:
                cmd += ",bus=%s" % bus
            if perms:
                cmd += ",%s" % perms
            if size:
                cmd += ",size=%s" % size.rstrip("Gg")
            if sparse:
                cmd += ",sparse=false"
            if fmt:
                cmd += ",format=%s" % fmt
            if cache:
                cmd += ",cache=%s" % cache
            return cmd

        def add_floppy(help_text, filename):
            return " --disk path=%s,device=floppy,ro" % filename

        def add_vnc(help_text, vnc_port=None):
            if vnc_port:
                return " --vnc --vncport=%d" % (vnc_port)
            else:
                return " --vnc"

        def add_vnclisten(help_text, vnclisten):
            if has_option(help_text, "vnclisten"):
                return " --vnclisten=%s" % (vnclisten)
            else:
                return ""

        def add_sdl(help_text):
            if has_option(help_text, "sdl"):
                return " --sdl"
            else:
                return ""

        def add_nographic(help_text):
            return " --nographics"

        def add_video(help_text, video_device):
            if has_option(help_text, "video"):
                return " --video=%s" % (video_device)
            else:
                return ""

        def add_uuid(help_text, uuid):
            if has_option(help_text, "uuid"):
                return " --uuid %s" % uuid
            else:
                return ""

        def add_os_type(help_text, os_type):
            if has_option(help_text, "os-type"):
                return " --os-type %s" % os_type
            else:
                return ""

        def add_os_variant(help_text, os_variant):
            if has_option(help_text, "os-variant"):
                return " --os-variant %s" % os_variant
            else:
                return ""

        def add_pcidevice(help_text, pci_device):
            if has_option(help_text, "host-device"):
                return " --host-device %s" % pci_device
            else:
                return ""

        def add_soundhw(help_text, sound_device):
            if has_option(help_text, "soundhw"):
                return " --soundhw %s" % sound_device
            else:
                return ""

        def add_serial(help_text):
            if has_option(help_text, "serial"):
                return " --serial pty"

        def add_kernel_cmdline(help_text, cmdline):
            return " -append %s" % cmdline

        def add_connect_uri(help_text, uri):
            if uri and has_option(help_text, "connect"):
                return " --connect=%s" % uri
            else:
                return ""

        def add_security(help_text, sec_type, sec_label=None, sec_relabel=None):
            """
            Return security options for install command.
            """
            if has_option(help_text, "security"):
                result = " --security"
                if sec_type == 'static':
                    if sec_label is None:
                        raise ValueError("Seclabel is not setted for static.")
                    result += " type=static,label=%s" % (sec_label)
                elif sec_type == 'dynamic':
                    result += " type=dynamic"
                else:
                    raise ValueError("Security type %s is not supported."
                                     % sec_type)
                if sec_relabel is not None:
                    result += ",relabel=%s" % sec_relabel
            else:
                result = ""

            return result

        def add_nic(help_text, nic_params):
            """
            Return additional command line params based on dict-like nic_params
            """
            mac = nic_params.get('mac')
            nettype = nic_params.get('nettype')
            netdst = nic_params.get('netdst')
            nic_model = nic_params.get('nic_model')
            if nettype:
                result = " --network=%s" % nettype
            else:
                result = ""
            if has_option(help_text, "bridge"):
                # older libvirt (--network=NATdev --bridge=bridgename
                # --mac=mac)
                if nettype != 'user':
                    result += ':%s' % netdst
                if mac:  # possible to specify --mac w/o --network
                    result += " --mac=%s" % mac
            else:
                # newer libvirt (--network=mynet,model=virtio,mac=00:11)
                if nettype != 'user':
                    result += '=%s' % netdst
                if nettype and nic_model:  # only supported along with nettype
                    result += ",model=%s" % nic_model
                if nettype and mac:
                    result += ',mac=%s' % mac
                elif mac:  # possible to specify --mac w/o --network
                    result += " --mac=%s" % mac
            logging.debug("vm.make_create_command.add_nic returning: %s",
                          result)
            return result

        # End of command line option wrappers

        if name is None:
            name = self.name
        if params is None:
            params = self.params
        if root_dir is None:
            root_dir = self.root_dir

        # Clone this VM using the new params
        vm = self.clone(name, params, root_dir, copy_state=True)

        virt_install_binary = utils_misc.get_path(
            root_dir,
            params.get("virt_install_binary",
                       "virt-install"))

        help_text = utils.system_output("%s --help" % virt_install_binary)

        # Find all supported machine types, so we can rule out an unsupported
        # machine type option passed in the configuration.
        hvm_or_pv = params.get("hvm_or_pv", "hvm")
        # default to 'uname -m' output
        arch_name = params.get("vm_arch_name", utils.get_current_kernel_arch())
        capabs = libvirt_xml.CapabilityXML()
        try:
            support_machine_type = capabs.os_arch_machine_map[hvm_or_pv][arch_name]
        except KeyError, detail:
            if detail.args[0] == hvm_or_pv:
                raise KeyError("No libvirt support for %s virtualization, "
                               "does system hardware + software support it?"
                               % hvm_or_pv)
            elif detail.args[0] == arch_name:
                raise KeyError("No libvirt support for %s virtualization of "
                               "%s, does system hardware + software support "
                               "it?" % (hvm_or_pv, arch_name))
            raise
        logging.debug("Machine types supported for %s/%s: %s",
                      hvm_or_pv, arch_name, support_machine_type)

        # Start constructing the qemu command
        virt_install_cmd = ""
        # Set the X11 display parameter if requested
        if params.get("x11_display"):
            virt_install_cmd += "DISPLAY=%s " % params.get("x11_display")
        # Add the qemu binary
        virt_install_cmd += virt_install_binary

        # set connect uri
        virt_install_cmd += add_connect_uri(help_text, self.connect_uri)

        # hvm or pv specified by libvirt switch (pv used  by Xen only)
        if hvm_or_pv:
            virt_install_cmd += add_hvm_or_pv(help_text, hvm_or_pv)

        # Add the VM's name
        virt_install_cmd += add_name(help_text, name)

        machine_type = params.get("machine_type")
        if machine_type:
            if machine_type in support_machine_type:
                virt_install_cmd += add_machine_type(help_text, machine_type)
            else:
                raise error.TestNAError("Unsupported machine type %s." %
                                        (machine_type))

        mem = params.get("mem")
        if mem:
            virt_install_cmd += add_mem(help_text, mem)

        # TODO: should we do the check before we call ? negative case ?
        check_cpu = params.get("use_check_cpu")
        if check_cpu:
            virt_install_cmd += add_check_cpu(help_text)

        smp = params.get("smp")
        if smp:
            virt_install_cmd += add_smp(help_text, smp)

        # TODO: directory location for vmlinuz/kernel for cdrom install ?
        location = None
        if params.get("medium") == 'url':
            location = params.get('url')

        elif params.get("medium") == 'kernel_initrd':
            # directory location of kernel/initrd pair (directory layout must
            # be in format libvirt will recognize)
            location = params.get("image_dir")

        elif params.get("medium") == 'nfs':
            location = "nfs:%s:%s" % (params.get("nfs_server"),
                                      params.get("nfs_dir"))

        elif params.get("medium") == 'cdrom':
            if params.get("use_libvirt_cdrom_switch") == 'yes':
                virt_install_cmd += add_cdrom(
                    help_text, params.get("cdrom_cd1"))
            elif params.get("unattended_delivery_method") == "integrated":
                cdrom_path = os.path.join(data_dir.get_data_dir(),
                                          params.get("cdrom_unattended"))
                virt_install_cmd += add_cdrom(help_text, cdrom_path)
            else:
                location = data_dir.get_data_dir()
                kernel_dir = os.path.dirname(params.get("kernel"))
                kernel_parent_dir = os.path.dirname(kernel_dir)
                pxeboot_link = os.path.join(kernel_parent_dir, "pxeboot")
                if os.path.islink(pxeboot_link):
                    os.unlink(pxeboot_link)
                if os.path.isdir(pxeboot_link):
                    logging.info("Removed old %s leftover directory",
                                 pxeboot_link)
                    shutil.rmtree(pxeboot_link)
                os.symlink(kernel_dir, pxeboot_link)

        elif params.get("medium") == "import":
            virt_install_cmd += add_import(help_text)

        if location:
            virt_install_cmd += add_location(help_text, location)

        if params.get("display") == "vnc":
            if params.get("vnc_autoport") == "yes":
                vm.vnc_autoport = True
            else:
                vm.vnc_autoport = False
            if not vm.vnc_autoport and params.get("vnc_port"):
                vm.vnc_port = int(params.get("vnc_port"))
            virt_install_cmd += add_vnc(help_text, vm.vnc_port)
            if params.get("vnclisten"):
                vm.vnclisten = params.get("vnclisten")
            virt_install_cmd += add_vnclisten(help_text, vm.vnclisten)
        elif params.get("display") == "sdl":
            virt_install_cmd += add_sdl(help_text)
        elif params.get("display") == "nographic":
            virt_install_cmd += add_nographic(help_text)

        video_device = params.get("video_device")
        if video_device:
            virt_install_cmd += add_video(help_text, video_device)

        sound_device = params.get("sound_device")
        if sound_device:
            virt_install_cmd += add_soundhw(help_text, sound_device)

        # if none is given a random UUID will be generated by libvirt
        if params.get("uuid"):
            virt_install_cmd += add_uuid(help_text, params.get("uuid"))

        # selectable OS type
        if params.get("use_os_type") == "yes":
            virt_install_cmd += add_os_type(help_text, params.get("os_type"))

        # selectable OS variant
        if params.get("use_os_variant") == "yes":
            virt_install_cmd += add_os_variant(
                help_text, params.get("os_variant"))

        # Add serial console
        virt_install_cmd += add_serial(help_text)

        # If the PCI assignment step went OK, add each one of the PCI assigned
        # devices to the command line.
        if self.pci_devices:
            for pci_id in self.pci_devices:
                virt_install_cmd += add_pcidevice(help_text, pci_id)

        for image_name in params.objects("images"):
            image_params = params.object_params(image_name)

            base_dir = image_params.get("images_base_dir",
                                        data_dir.get_data_dir())

            filename = storage.get_image_filename(image_params,
                                                  base_dir)
            if image_params.get("use_storage_pool") == "yes":
                filename = None
                virt_install_cmd += add_drive(help_text,
                                              filename,
                                              image_params.get("image_pool"),
                                              image_params.get("image_vol"),
                                              image_params.get("image_device"),
                                              image_params.get("image_bus"),
                                              image_params.get("image_perms"),
                                              image_params.get("image_size"),
                                              image_params.get("drive_sparse"),
                                              image_params.get("drive_cache"),
                                              image_params.get("image_format"))

            if image_params.get("boot_drive") == "no":
                continue
            if filename:
                virt_install_cmd += add_drive(help_text,
                                              filename,
                                              None,
                                              None,
                                              None,
                                              image_params.get("drive_format"),
                                              None,
                                              image_params.get("image_size"),
                                              image_params.get("drive_sparse"),
                                              image_params.get("drive_cache"),
                                              image_params.get("image_format"))

        unattended_integrated = (params.get('unattended_delivery_method') !=
                                 'integrated')
        xen_pv = self.driver_type == 'xen' and params.get('hvm_or_pv') == 'pv'
        if unattended_integrated and not xen_pv:
            for cdrom in params.objects("cdroms"):
                cdrom_params = params.object_params(cdrom)
                iso = cdrom_params.get("cdrom")
                if params.get("use_libvirt_cdrom_switch") == 'yes':
                    # we don't want to skip the winutils iso
                    if not cdrom == 'winutils':
                        logging.debug(
                            "Using --cdrom instead of --disk for install")
                        logging.debug("Skipping CDROM:%s:%s", cdrom, iso)
                        continue
                if params.get("medium") == 'cdrom_no_kernel_initrd':
                    if iso == params.get("cdrom_cd1"):
                        logging.debug("Using cdrom or url for install")
                        logging.debug("Skipping CDROM: %s", iso)
                        continue

                if iso:
                    iso_path = utils_misc.get_path(root_dir, iso)
                    iso_image_pool = image_params.get("iso_image_pool")
                    iso_image_vol = image_params.get("iso_image_vol")
                    virt_install_cmd += add_drive(help_text,
                                                  iso_path,
                                                  iso_image_pool,
                                                  virt_install_cmd,
                                                  'cdrom',
                                                  None,
                                                  None,
                                                  None,
                                                  None,
                                                  None,
                                                  None)

        # We may want to add {floppy_otps} parameter for -fda
        # {fat:floppy:}/path/. However vvfat is not usually recommended.
        # Only support to add the main floppy if you want to add the second
        # one please modify this part.
        floppy = params.get("floppy_name")
        if floppy:
            floppy = utils_misc.get_path(data_dir.get_data_dir(), floppy)
            virt_install_cmd += add_drive(help_text, floppy,
                                          None,
                                          None,
                                          'floppy',
                                          None,
                                          None,
                                          None,
                                          None,
                                          None,
                                          None)

        # setup networking parameters
        for nic in vm.virtnet:
            # make_create_command can be called w/o vm.create()
            nic = vm.add_nic(**dict(nic))
            logging.debug("make_create_command() setting up command for"
                          " nic: %s" % str(nic))
            virt_install_cmd += add_nic(help_text, nic)

        if params.get("use_no_reboot") == "yes":
            virt_install_cmd += " --noreboot"

        if params.get("use_autostart") == "yes":
            virt_install_cmd += " --autostart"

        if params.get("virt_install_debug") == "yes":
            virt_install_cmd += " --debug"

        # bz still open, not fully functional yet
        if params.get("use_virt_install_wait") == "yes":
            virt_install_cmd += (" --wait %s" %
                                 params.get("virt_install_wait_time"))

        kernel_params = params.get("kernel_params")
        if kernel_params:
            virt_install_cmd += " --extra-args '%s'" % kernel_params

        virt_install_cmd += " --noautoconsole"

        sec_type = params.get("sec_type", None)
        if sec_type:
            sec_label = params.get("sec_label", None)
            sec_relabel = params.get("sec_relabel", None)
            virt_install_cmd += add_security(help_text, sec_type=sec_type,
                                             sec_label=sec_label,
                                             sec_relabel=sec_relabel)

        return virt_install_cmd

    def get_serial_console_filename(self, name):
        """
        Return the serial console filename.

        :param name: The serial port name.
        """
        return "serial-%s-%s.log" % (name, self.name)

    def get_serial_console_filenames(self):
        """
        Return a list of all serial console filenames
        (as specified in the VM's params).
        """
        return [self.get_serial_console_filename(_) for _ in
                self.params.objects("isa_serials")]

    def create_serial_console(self):
        """
        Establish a session with the serial console.

        The libvirt version uses virsh console to manage it.
        """
        if not self.serial_ports:
            for serial in self.params.objects("isa_serials"):
                self.serial_ports.append(serial)
        if self.serial_console is None:
            try:
                cmd = 'virsh'
                if self.connect_uri:
                    cmd += ' --uri=%s' % self.connect_uri
                cmd += (" console %s %s" % (self.name, self.serial_ports[0]))
            except IndexError:
                raise virt_vm.VMConfigMissingError(self.name, "isa_serial")
            output_func = utils_misc.log_line  # Because qemu-kvm uses this
            # Because qemu-kvm hard-codes this
            output_filename = self.get_serial_console_filename(self.serial_ports[0])
            output_params = (output_filename,)
            prompt = self.params.get("shell_prompt", "[\#\$]")
            self.serial_console = aexpect.ShellSession(command=cmd, auto_close=False,
                                                       output_func=output_func,
                                                       output_params=output_params)
            # Cause serial_console.close() to close open log file
            self.serial_console.set_log_file(output_filename)

    def set_root_serial_console(self, device, remove=False):
        """
        Allow or ban root to login through serial console.

        :param device: device to set root login
        :param allow_root: do remove operation
        """
        try:
            session = self.login()
        except (remote.LoginError, virt_vm.VMError), e:
            logging.debug(e)
        else:
            try:
                securetty_output = session.cmd_output("cat /etc/securetty")
                devices = str(securetty_output).strip().splitlines()
                if device not in devices:
                    if not remove:
                        session.sendline("echo %s >> /etc/securetty" % device)
                else:
                    if remove:
                        session.sendline("sed -i -e /%s/d /etc/securetty"
                                         % device)
                logging.debug("Set root login for %s successfully.", device)
                return True
            finally:
                session.close()
        logging.debug("Set root login for %s failed.", device)
        return False

    def set_kernel_console(self, device, speed=None, remove=False):
        """
        Set kernel parameter for given console device.

        :param device: a console device
        :param speed: speed of serial console
        :param remove: do remove operation
        """
        try:
            session = self.login()
        except (remote.LoginError, virt_vm.VMError), e:
            logging.debug(e)
        else:
            try:
                grub = "/etc/grub.cfg"
                if session.cmd_status("ls /etc/grub2.cfg"):
                    grub = "/etc/grub2.cfg"
                kernel_params = "console=%s" % device
                if speed is not None:
                    kernel_params += ",%s" % speed

                output = session.cmd_output("cat %s" % grub)
                if not re.search("console=%s" % device, output):
                    if not remove:
                        session.sendline("sed -i -e \'s/vmlinuz-.*/& %s/g\' %s"
                                         % (kernel_params, grub))
                else:
                    if remove:
                        session.sendline("sed -i -e \'s/console=%s\w*\s//g\'"
                                         " %s" % (device, grub))
                logging.debug("Set kernel params for %s successfully.", device)
                return True
            finally:
                session.close()
        logging.debug("Set kernel params for %s failed.", device)
        return False

    def set_console_getty(self, device, getty="mgetty", remove=False):
        """
        Set getty for given console device.

        :param device: a console device
        :param getty: getty type: agetty, mgetty and so on.
        :param remove: do remove operation
        """
        try:
            session = self.login()
        except (remote.LoginError, virt_vm.VMError), e:
            logging.debug(e)
        else:
            try:
                # Only configurate RHEL5 and below
                regex = "gettys are handled by"
                # As of RHEL7 systemd message is displayed
                regex += "|inittab is no longer used when using systemd"
                output = session.cmd_output("cat /etc/inittab")
                if re.search(regex, output):
                    logging.debug("Skip setting inittab for %s", device)
                    return True
                getty_str = "co:2345:respawn:/sbin/%s %s" % (getty, device)
                matched_str = "respawn:/sbin/*getty %s" % device
                if not re.search(matched_str, output):
                    if not remove:
                        session.sendline("echo %s >> /etc/inittab" % getty_str)
                else:
                    if remove:
                        session.sendline("sed -i -e /%s/d "
                                         "/etc/inittab" % matched_str)
                logging.debug("Set inittab for %s successfully.", device)
                return True
            finally:
                session.close()
        logging.debug("Set inittab for %s failed.", device)
        return False

    def cleanup_serial_console(self):
        """
        Close serial console and associated log file
        """
        if self.serial_console is not None:
            self.serial_console.close()
            self.serial_console = None
        if hasattr(self, "migration_file"):
            try:
                os.unlink(self.migration_file)
            except OSError:
                pass

    @error.context_aware
    def create(self, name=None, params=None, root_dir=None, timeout=5.0,
               migration_mode=None, mac_source=None, autoconsole=True):
        """
        Start the VM by running a qemu command.
        All parameters are optional. If name, params or root_dir are not
        supplied, the respective values stored as class attributes are used.

        :param name: The name of the object
        :param params: A dict containing VM params
        :param root_dir: Base directory for relative filenames
        :param migration_mode: If supplied, start VM for incoming migration
                using this protocol (either 'tcp', 'unix' or 'exec')
        :param migration_exec_cmd: Command to embed in '-incoming "exec: ..."'
                (e.g. 'gzip -c -d filename') if migration_mode is 'exec'
        :param mac_source: A VM object from which to copy MAC addresses. If not
                specified, new addresses will be generated.

        :raise VMCreateError: If qemu terminates unexpectedly
        :raise VMKVMInitError: If KVM initialization fails
        :raise VMHugePageError: If hugepage initialization fails
        :raise VMImageMissingError: If a CD image is missing
        :raise VMHashMismatchError: If a CD image hash has doesn't match the
                expected hash
        :raise VMBadPATypeError: If an unsupported PCI assignment type is
                requested
        :raise VMPAError: If no PCI assignable devices could be assigned
        """
        error.context("creating '%s'" % self.name)
        self.destroy(free_mac_addresses=False)
        if name is not None:
            self.name = name
        if params is not None:
            self.params = params
        if root_dir is not None:
            self.root_dir = root_dir
        name = self.name
        params = self.params
        root_dir = self.root_dir

        # Verify the md5sum of the ISO images
        for cdrom in params.objects("cdroms"):
            if params.get("medium") == "import":
                break
            cdrom_params = params.object_params(cdrom)
            iso = cdrom_params.get("cdrom")
            xen_pv = (self.driver_type == 'xen' and
                      params.get('hvm_or_pv') == 'pv')
            iso_is_ks = os.path.basename(iso) == 'ks.iso'
            if xen_pv and iso_is_ks:
                continue
            if iso:
                iso = utils_misc.get_path(data_dir.get_data_dir(), iso)
                if not os.path.exists(iso):
                    raise virt_vm.VMImageMissingError(iso)
                compare = False
                if cdrom_params.get("skip_hash"):
                    logging.debug("Skipping hash comparison")
                elif cdrom_params.get("md5sum_1m"):
                    logging.debug("Comparing expected MD5 sum with MD5 sum of "
                                  "first MB of ISO file...")
                    actual_hash = utils.hash_file(iso, 1048576, method="md5")
                    expected_hash = cdrom_params.get("md5sum_1m")
                    compare = True
                elif cdrom_params.get("md5sum"):
                    logging.debug("Comparing expected MD5 sum with MD5 sum of "
                                  "ISO file...")
                    actual_hash = utils.hash_file(iso, method="md5")
                    expected_hash = cdrom_params.get("md5sum")
                    compare = True
                elif cdrom_params.get("sha1sum"):
                    logging.debug("Comparing expected SHA1 sum with SHA1 sum "
                                  "of ISO file...")
                    actual_hash = utils.hash_file(iso, method="sha1")
                    expected_hash = cdrom_params.get("sha1sum")
                    compare = True
                if compare:
                    if actual_hash == expected_hash:
                        logging.debug("Hashes match")
                    else:
                        raise virt_vm.VMHashMismatchError(actual_hash,
                                                          expected_hash)

        # Make sure the following code is not executed by more than one thread
        # at the same time
        lockfile = open("/tmp/libvirt-autotest-vm-create.lock", "w+")
        fcntl.lockf(lockfile, fcntl.LOCK_EX)

        try:
            # Handle port redirections
            redir_names = params.objects("redirs")
            host_ports = utils_misc.find_free_ports(
                5000, 6000, len(redir_names))
            self.redirs = {}
            for i in range(len(redir_names)):
                redir_params = params.object_params(redir_names[i])
                guest_port = int(redir_params.get("guest_port"))
                self.redirs[guest_port] = host_ports[i]

            # Find available PCI devices
            self.pci_devices = []
            for device in params.objects("pci_devices"):
                self.pci_devices.append(device)

            # Find available VNC port, if needed
            if params.get("display") == "vnc":
                if params.get("vnc_autoport") == "yes":
                    self.vnc_port = None
                    self.vnc_autoport = True
                else:
                    self.vnc_port = utils_misc.find_free_port(5900, 6100)
                    self.vnc_autoport = False

            # Find available spice port, if needed
            if params.get("spice"):
                self.spice_port = utils_misc.find_free_port(8000, 8100)

            # Find random UUID if specified 'uuid = random' in config file
            if params.get("uuid") == "random":
                f = open("/proc/sys/kernel/random/uuid")
                self.uuid = f.read().strip()
                f.close()

            # Generate or copy MAC addresses for all NICs
            for nic in self.virtnet:
                nic_params = dict(nic)
                if mac_source is not None:
                    # Will raise exception if source doesn't
                    # have cooresponding nic
                    logging.debug("Copying mac for nic %s from VM %s",
                                  nic.nic_name, mac_source.name)
                    nic_params['mac'] = mac_source.get_mac_address(
                        nic.nic_name)
                # make_create_command() calls vm.add_nic (i.e. on a copy)
                nic = self.add_nic(**nic_params)
                logging.debug('VM.create activating nic %s' % nic)
                self.activate_nic(nic.nic_name)

            # Make qemu command
            install_command = self.make_create_command()

            logging.info("Running libvirt command (reformatted):")
            for item in install_command.replace(" -", " \n    -").splitlines():
                logging.info("%s", item)
            try:
                utils.run(install_command, verbose=False)
            except error.CmdError, details:
                stderr = details.result_obj.stderr.strip()
                # This is a common newcomer mistake, be more helpful...
                if stderr.count('IDE CDROM must use'):
                    testname = params.get('name', "")
                    if testname.count('unattended_install.cdrom'):
                        if not testname.count('http_ks'):
                            e_msg = ("Install command "
                                     "failed:\n%s \n\nNote: "
                                     "Older versions of "
                                     "libvirt won't work "
                                     "properly with kickstart "
                                     "on cdrom  install. "
                                     "Try using the "
                                     "unattended_install.cdrom.http_ks method "
                                     "instead." % details.result_obj)
                            raise error.TestNAError(e_msg)
                if stderr.count('failed to launch bridge helper'):
                    if utils_misc.selinux_enforcing():
                        raise error.TestNAError("SELinux is enabled and "
                                                "preventing the bridge "
                                                "helper from accessing "
                                                "the bridge.  Consider "
                                                "running as root or "
                                                "placing SELinux into "
                                                "permissive mode.")
                # some other problem happened, raise normally
                raise
            # Wait for the domain to be created
            utils_misc.wait_for(func=self.is_alive, timeout=60,
                                text=("waiting for domain %s to start" %
                                      self.name))
            self.uuid = virsh.domuuid(self.name,
                                      uri=self.connect_uri).stdout.strip()
            # Create isa serial ports.
            self.create_serial_console()
        finally:
            fcntl.lockf(lockfile, fcntl.LOCK_UN)
            lockfile.close()

    def migrate(self, dest_uri="", option="--live --timeout 60", extra="",
                ignore_status=False, debug=False):
        """
        Migrate a VM to a remote host.

        :param dest_uri: Destination libvirt URI
        :param option: Migration options before <domain> <desturi>
        :param extra: Migration options after <domain> <desturi>
        :return: True if command succeeded
        """
        logging.info("Migrating VM %s from %s to %s" %
                     (self.name, self.connect_uri, dest_uri))
        result = virsh.migrate(self.name, dest_uri, option,
                               extra, uri=self.connect_uri,
                               ignore_status=ignore_status,
                               debug=debug)
        # Close down serial_console logging process
        self.cleanup_serial_console()
        # On successful migration, point to guests new hypervisor.
        # Since dest_uri could be None, checking it is necessary.
        if result.exit_status == 0 and dest_uri:
            self.connect_uri = dest_uri
        self.create_serial_console()
        return result

    def attach_interface(self, option="", ignore_status=False,
                         debug=False):
        """
        Attach a NIC to VM.
        """
        return virsh.attach_interface(self.name, option,
                                      uri=self.connect_uri,
                                      ignore_status=ignore_status,
                                      debug=debug)

    def detach_interface(self, option="", ignore_status=False,
                         debug=False):
        """
        Detach a NIC to VM.
        """
        return virsh.detach_interface(self.name, option,
                                      uri=self.connect_uri,
                                      ignore_status=ignore_status,
                                      debug=debug)

    def destroy(self, gracefully=True, free_mac_addresses=True):
        """
        Destroy the VM.

        If gracefully is True, first attempt to shutdown the VM with a shell
        command. If that fails, send SIGKILL to the qemu process.

        :param gracefully: If True, an attempt will be made to end the VM
                using a shell command before trying to end the qemu process
                with a 'quit' or a kill signal.
        :param free_mac_addresses: If vm is undefined with libvirt, also
                                   release/reset associated mac address
        """
        try:
            # Is it already dead?
            if self.is_alive():
                logging.debug("Destroying VM")
                if gracefully and self.params.get("shutdown_command"):
                    # Try to destroy with shell command
                    logging.debug("Trying to shutdown VM with shell command")
                    try:
                        session = self.login()
                    except (remote.LoginError, virt_vm.VMError), e:
                        logging.debug(e)
                    else:
                        try:
                            # Send the shutdown command
                            session.sendline(
                                self.params.get("shutdown_command"))
                            logging.debug("Shutdown command sent; waiting for VM "
                                          "to go down...")
                            if utils_misc.wait_for(self.is_dead, 60, 1, 1):
                                logging.debug("VM is down")
                                return
                        finally:
                            session.close()
                virsh.destroy(self.name, uri=self.connect_uri)

        finally:
            self.cleanup_serial_console()
        if free_mac_addresses:
            if self.is_persistent():
                logging.warning("Requested MAC address release from "
                                "persistent vm %s. Ignoring." % self.name)
            else:
                logging.debug("Releasing MAC addresses for vm %s." % self.name)
                for nic_name in self.virtnet.nic_name_list():
                    self.virtnet.free_mac_address(nic_name)

    def remove(self):
        self.destroy(gracefully=True, free_mac_addresses=False)
        if not self.undefine():
            raise virt_vm.VMRemoveError("VM '%s' undefine error" % self.name)
        self.destroy(gracefully=False, free_mac_addresses=True)
        logging.debug("VM '%s' was removed", self.name)

    def get_uuid(self):
        """
        Return VM's UUID.
        """
        uuid = virsh.domuuid(self.name, uri=self.connect_uri).stdout.strip()
        # only overwrite it if it's not set
        if self.uuid is None:
            self.uuid = uuid
        return self.uuid

    def get_ifname(self, nic_index=0):
        raise NotImplementedError

    def get_virsh_mac_address(self, nic_index=0):
        """
        Get the MAC of this VM domain.

        :param nic_index: Index of the NIC
        :raise VMMACAddressMissingError: If no MAC address is defined for the
                requested NIC
        """
        cmd_result = virsh.dumpxml(self.name, uri=self.connect_uri)
        if cmd_result.exit_status:
            raise error.TestFail("dumpxml %s failed.\n"
                                 "Detail: %s.\n" % (self.name, cmd_result))
        thexml = cmd_result.stdout.strip()
        xtf = xml_utils.XMLTreeFile(thexml)
        interfaces = xtf.find('devices').findall('interface')
        # Range check
        try:
            mac = interfaces[nic_index].find('mac').get('address')
            if mac is not None:
                return mac
        except IndexError:
            pass  # Allow other exceptions through
        # IndexError (range check) or mac is None
        raise virt_vm.VMMACAddressMissingError(nic_index)

    def get_pid(self):
        """
        Return the VM's PID.

        :return: int with PID. If VM is not alive, returns None.
        """
        pid_file = "/var/run/libvirt/qemu/%s.pid" % self.name
        pid = None
        if os.path.exists(pid_file):
            try:
                pid_file_contents = open(pid_file).read()
                pid = int(pid_file_contents)
            except IOError:
                logging.error("Could not read %s to get PID", pid_file)
            except TypeError:
                logging.error("PID file %s has invalid contents: '%s'",
                              pid_file, pid_file_contents)
        else:
            logging.debug("PID file %s not present", pid_file)

        return pid

    def get_vcpus_pid(self):
        """
        Return the vcpu's pid for a given VM.

        :return: list of PID of vcpus of a VM.
        """
        output = virsh.qemu_monitor_command(self.name, "info cpus",
                                            uri=self.connect_uri)
        vcpu_pids = re.findall(r'thread_id=(\d+)', output.stdout)
        return vcpu_pids

    def get_shell_pid(self):
        """
        Return the PID of the parent shell process.

        :note: This works under the assumption that ``self.process.get_pid()``
            returns the PID of the parent shell process.
        """
        return self.process.get_pid()

    def get_shared_meminfo(self):
        """
        Returns the VM's shared memory information.

        :return: Shared memory used by VM (MB)
        """
        if self.is_dead():
            logging.error("Could not get shared memory info from dead VM.")
            return None

        filename = "/proc/%d/statm" % self.get_pid()
        shm = int(open(filename).read().split()[2])
        # statm stores informations in pages, translate it to MB
        return shm * 4.0 / 1024

    def activate_nic(self, nic_index_or_name):
        # TODO: Implement nic hotplugging
        pass  # Just a stub for now

    def deactivate_nic(self, nic_index_or_name):
        # TODO: Implement nic hot un-plugging
        pass  # Just a stub for now

    @error.context_aware
    def reboot(self, session=None, method="shell", nic_index=0, timeout=240):
        """
        Reboot the VM and wait for it to come back up by trying to log in until
        timeout expires.

        :param session: A shell session object or None.
        :param method: Reboot method.  Can be "shell" (send a shell reboot
                command).
        :param nic_index: Index of NIC to access in the VM, when logging in
                after rebooting.
        :param timeout: Time to wait for login to succeed (after rebooting).
        :return: A new shell session object.
        """
        error.base_context("rebooting '%s'" % self.name, logging.info)
        error.context("before reboot")
        session = session or self.login(timeout=timeout)
        error.context()

        if method == "shell":
            session.sendline(self.params.get("reboot_command"))
        else:
            raise virt_vm.VMRebootError("Unknown reboot method: %s" % method)

        error.context("waiting for guest to go down", logging.info)
        if not utils_misc.wait_for(lambda: not
                                   session.is_responsive(timeout=30),
                                   120, 0, 1):
            raise virt_vm.VMRebootError("Guest refuses to go down")
        session.close()

        error.context("logging in after reboot", logging.info)
        return self.wait_for_login(nic_index, timeout=timeout)

    def screendump(self, filename, debug=False):
        if debug:
            logging.debug("Requesting screenshot %s" % filename)
        return virsh.screenshot(self.name, filename, uri=self.connect_uri)

    def start(self, autoconsole=True):
        """
        Starts this VM.
        """
        self.uuid = virsh.domuuid(self.name,
                                  uri=self.connect_uri).stdout.strip()
        # Pull in mac addresses from libvirt guest definition
        for index, nic in enumerate(self.virtnet):
            try:
                mac = self.get_virsh_mac_address(index)
                if not nic.has_key('mac'):
                    logging.debug("Updating nic %d with mac %s on vm %s"
                                  % (index, mac, self.name))
                    nic.mac = mac
                elif nic.mac != mac:
                    logging.warning("Requested mac %s doesn't match mac %s "
                                    "as defined for vm %s", nic.mac, mac,
                                    self.name)
                # TODO: Checkout/Set nic_model, nettype, netdst also
            except virt_vm.VMMACAddressMissingError:
                logging.warning("Nic %d requested by test but not defined for"
                                " vm %s" % (index, self.name))

        logging.debug("Starting vm '%s'", self.name)
        result = virsh.start(self.name, uri=self.connect_uri)
        if not result.exit_status:
            # Wait for the domain to be created
            has_started = utils_misc.wait_for(func=self.is_alive, timeout=60,
                                              text=("waiting for domain %s "
                                                    "to start" % self.name))
            if has_started is None:
                raise virt_vm.VMStartError(self.name, "libvirt domain not "
                                                      "active after start")
            self.uuid = virsh.domuuid(self.name,
                                      uri=self.connect_uri).stdout.strip()
            # Establish a session with the serial console
            if autoconsole:
                self.create_serial_console()
        else:
            raise virt_vm.VMStartError(self.name, result.stderr.strip())

    def wait_for_shutdown(self, count=60):
        """
        Return True on successful domain shutdown.

        Wait for a domain to shutdown, libvirt does not block on domain
        shutdown so we need to watch for successful completion.

        :param name: VM name
        :param name: Optional timeout value
        """
        timeout = count
        while count > 0:
            # check every 5 seconds
            if count % 5 == 0:
                if virsh.is_dead(self.name, uri=self.connect_uri):
                    logging.debug("Shutdown took %d seconds", timeout - count)
                    return True
            count -= 1
            time.sleep(1)
            logging.debug("Waiting for guest to shutdown %d", count)
        return False

    def shutdown(self):
        """
        Shuts down this VM.
        """
        try:
            if self.state() != 'shut off':
                virsh.shutdown(self.name, uri=self.connect_uri)
            if self.wait_for_shutdown():
                logging.debug("VM %s shut down", self.name)
                self.cleanup_serial_console()
                return True
            else:
                logging.error("VM %s failed to shut down", self.name)
                return False
        except error.CmdError:
            logging.error("VM %s failed to shut down", self.name)
            return False

    def pause(self):
        try:
            state = self.state()
            if state != 'paused':
                virsh.suspend(
                    self.name, uri=self.connect_uri, ignore_statues=False)
            return True
        except:
            logging.error("VM %s failed to suspend", self.name)
            return False

    def resume(self):
        try:
            virsh.resume(self.name, ignore_status=False, uri=self.connect_uri)
            if self.is_alive():
                logging.debug("Resumed VM %s", self.name)
                return True
            else:
                return False
        except error.CmdError, detail:
            logging.error("Resume VM %s failed:\n%s", self.name, detail)
            return False

    def save_to_file(self, path):
        """
        Override BaseVM save_to_file method
        """
        if self.is_dead():
            raise virt_vm.VMStatusError("Cannot save a VM that is %s" % self.state())
        logging.debug("Saving VM %s to %s" % (self.name, path))
        result = virsh.save(self.name, path, uri=self.connect_uri)
        if result.exit_status:
            raise virt_vm.VMError("Save VM to %s failed.\n"
                                  "Detail: %s." % (path, result.stderr))
        if self.is_alive():
            raise virt_vm.VMStatusError("VM not shut off after save")
        self.cleanup_serial_console()

    def restore_from_file(self, path):
        """
        Override BaseVM restore_from_file method
        """
        if self.is_alive():
            raise virt_vm.VMStatusError(
                "Can not restore VM that is %s" % self.state())
        logging.debug("Restoring VM from %s" % path)
        result = virsh.restore(path, uri=self.connect_uri)
        if result.exit_status:
            raise virt_vm.VMError("Restore VM from %s failed.\n"
                                  "Detail: %s." % (path, result.stderr))
        if self.is_dead():
            raise virt_vm.VMStatusError(
                "VM should not be %s after restore." % self.state())
        self.create_serial_console()

    def vcpupin(self, vcpu, cpu_list, options=""):
        """
        To pin vcpu to cpu_list
        """
        result = virsh.vcpupin(self.name, vcpu, cpu_list,
                               options, uri=self.connect_uri)
        if result.exit_status:
            raise error.TestFail("Virsh vcpupin command failed.\n"
                                 "Detail: %s.\n" % result)

    def dominfo(self):
        """
        Return a dict include vm's information.
        """
        output = virsh.dominfo(self.name, uri=self.connect_uri).stdout.strip()
        # Key: word before ':' | value: content after ':' (stripped)
        dominfo_dict = {}
        for line in output.splitlines():
            key = line.split(':')[0].strip()
            value = line.split(':')[-1].strip()
            dominfo_dict[key] = value
        return dominfo_dict

    def vcpuinfo(self):
        """
        Return a dict's list include vm's vcpu information.
        """
        output = virsh.vcpuinfo(self.name,
                                uri=self.connect_uri).stdout.strip()
        # Key: word before ':' | value: content after ':' (stripped)
        vcpuinfo_list = []
        vcpuinfo_dict = {}
        for line in output.splitlines():
            key = line.split(':')[0].strip()
            value = line.split(':')[-1].strip()
            vcpuinfo_dict[key] = value
            if key == "CPU Affinity":
                vcpuinfo_list.append(vcpuinfo_dict)
        return vcpuinfo_list

    def get_used_mem(self):
        """
        Get vm's current memory(kilobytes).
        """
        dominfo_dict = self.dominfo()
        memory = dominfo_dict['Used memory'].split(' ')[0]  # strip off ' kb'
        return int(memory)

    def get_blk_devices(self):
        """
        Get vm's block devices.

        Return a dict include all devices detail info.
        example:
        {target: {'type': value, 'device': value, 'source': value}}
        """
        domblkdict = {}
        options = "--details"
        result = virsh.domblklist(self.name, options, ignore_status=True,
                                  uri=self.connect_uri)
        blklist = result.stdout.strip().splitlines()
        if result.exit_status != 0:
            logging.info("Get vm devices failed.")
        else:
            blklist = blklist[2:]
            for line in blklist:
                linesplit = line.split(None, 4)
                target = linesplit[2]
                blk_detail = {'type': linesplit[0],
                              'device': linesplit[1],
                              'source': linesplit[3]}
                domblkdict[target] = blk_detail
        return domblkdict

    def get_disk_devices(self):
        """
        Get vm's disk type block devices.
        """
        blk_devices = self.get_blk_devices()
        disk_devices = {}
        for target in blk_devices:
            details = blk_devices[target]
            if details['device'] == "disk":
                disk_devices[target] = details
        return disk_devices

    def get_first_disk_devices(self):
        """
        Get vm's first disk type block devices.
        """
        disk = {}
        options = "--details"
        result = virsh.domblklist(self.name, options, ignore_status=True,
                                  uri=self.connect_uri)
        blklist = result.stdout.strip().splitlines()
        if result.exit_status != 0:
            logging.info("Get vm devices failed.")
        else:
            blklist = blklist[2:]
            linesplit = blklist[0].split(None, 4)
            disk = {'type': linesplit[0],
                    'device': linesplit[1],
                    'target': linesplit[2],
                    'source': linesplit[3]}
        return disk

    def get_max_mem(self):
        """
        Get vm's maximum memory(kilobytes).
        """
        dominfo_dict = self.dominfo()
        max_mem = dominfo_dict['Max memory'].split(' ')[0]  # strip off 'kb'
        return int(max_mem)

    def domjobabort(self):
        """
        Abort job for vm.
        """
        result = virsh.domjobabort(self.name, ignore_status=True)
        if result.exit_status:
            logging.debug(result)
            return False
        return True

    def dump(self, path, option=""):
        """
        Dump self to path.

        :raise: error.TestFail if dump fail.
        """
        cmd_result = virsh.dump(self.name, path=path, option=option,
                                uri=self.connect_uri)
        if cmd_result.exit_status:
            raise error.TestFail("Failed to dump %s to %s.\n"
                                 "Detail: %s." % (self.name, path, cmd_result))

########NEW FILE########
__FILENAME__ = accessors
"""
Specializations of base.AccessorBase for particular XML manipulation types
"""

import logging
import re
import sys
from virttest import xml_utils
from virttest.propcan import PropCanBase
from virttest.libvirt_xml import xcepts, base
# The backports module will take care of picking the builtin if available
from virttest.staging.backports import bin


def type_check(name, thing, expected):
    """
    Check that thing is expected subclass or instance, raise ValueError if not
    """
    is_a = type(thing)
    is_a_name = str(is_a)
    if not isinstance(expected, list):
        expected = [expected]
    for e in expected:
        try:
            it_is = issubclass(thing, e)
        except TypeError:
            it_is = isinstance(thing, e)
        if it_is:
            return
    raise ValueError('%s value is not any of %s, it is a %s'
                     % (name, expected, is_a_name))


def add_to_slots(*args):
    """
    Return list of AccessorBase.__all_slots__ + args
    """
    for slot in args:
        type_check('slot name', slot, str)
    return AccessorBase.__all_slots__ + args


class AccessorBase(PropCanBase):

    """
    Base class for a callable operating on a LibvirtXMLBase subclass instance
    """

    # Gets AccessorGeneratorBase subclass's required_accessor_data_keys added
    __slots__ = ('operation', 'property_name', 'libvirtxml')

    def __init__(self, operation, property_name, libvirtxml, **dargs):
        """
        Initialize accessor to operate on lvxml with accessor_data for property

        :param operation: Debug String for 'Getter', 'Setter', or 'Delter'
        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param dargs: Necessary for subclasses to extend required parameters
        """
        type_check('Parameter property_name', property_name, str)
        type_check('Operation attribute', operation, str)
        type_check('__slots__ attribute', self.__all_slots__, [tuple, list])
        type_check('Parameter libvirtxml', libvirtxml, base.LibvirtXMLBase)

        super(AccessorBase, self).__init__()

        self.__dict_set__('operation', operation)
        self.__dict_set__('property_name', property_name)
        self.__dict_set__('libvirtxml', libvirtxml)

        for slot in self.__all_slots__:
            if slot in AccessorBase.__all_slots__:
                continue  # already checked these
            # Don't care about value type
            if slot not in dargs:
                raise ValueError('Required accessor generator parameter %s'
                                 % slot)
            self.__dict_set__(slot, dargs[slot])

    # Subclass expected to override this and specify parameters
    __call__ = NotImplementedError

    def __repr__(self):
        return ("%s's %s for %s with %s"
                % (self.libvirtxml.__class__.__name__, self.operation,
                   self.property_name, str(dict(self))))

    def xmltreefile(self):
        """
        Retrieve xmltreefile instance from libvirtxml instance
        """
        return self.libvirtxml.xmltreefile

    def element_by_parent(self, parent_xpath, tag_name, create=True):
        """
        Retrieve/create an element instance at parent_xpath/tag_name

        :param parent_xpath: xpath of parent element
        :param tag_name: name of element under parent to retrieve/create
        :param create: True to create new element if not exist
        :return: ElementTree.Element instance
        :raise: LibvirtXMLError: If element not exist & create=False
        """
        type_check('parent_xpath', parent_xpath, str)
        type_check('tag_name', tag_name, str)
        parent_element = self.xmltreefile().find(parent_xpath)
        if (parent_element == self.xmltreefile().getroot() and
                parent_element.tag == tag_name):
            return parent_element
        excpt_str = ('Exception thrown from %s for property "%s" while'
                     ' looking for element tag "%s", on parent at xpath'
                     ' "%s", in XML\n%s\n' % (self.operation,
                                              self.property_name, tag_name, parent_xpath,
                                              str(self.xmltreefile())))
        if parent_element is None:
            if create:
                # This will only work for simple XPath strings
                self.xmltreefile().create_by_xpath(parent_xpath)
                parent_element = self.xmltreefile().find(parent_xpath)
            # if create or not, raise if not exist
            if parent_element is None:
                raise xcepts.LibvirtXMLAccessorError(excpt_str)
        try:
            element = parent_element.find(tag_name)
        except:
            logging.error(excpt_str)
            raise
        if element is None:
            if create:  # Create the element
                element = xml_utils.ElementTree.SubElement(parent_element,
                                                           tag_name)
            else:  # create is False
                raise xcepts.LibvirtXMLNotFoundError('Error in %s for property '
                                                     '"%s", element tag "%s" not '
                                                     'found on parent at xpath "%s"'
                                                     ' in XML\n%s\n'
                                                     % (self.operation,
                                                        self.property_name,
                                                        tag_name, parent_xpath,
                                                        str(self.xmltreefile())))
        return element


class ForbiddenBase(AccessorBase):

    """
    Raise LibvirtXMLAccessorError when called w/ or w/o a value arg.
    """

    __slots__ = []

    def __call__(self, value=None):
        if value:
            raise xcepts.LibvirtXMLForbiddenError("%s %s to '%s' on %s "
                                                  "forbidden"
                                                  % (self.operation,
                                                     self.property_name,
                                                     str(value),
                                                     str(self)))
        else:
            raise xcepts.LibvirtXMLForbiddenError("%s %s on %s "
                                                  "forbidden"
                                                  % (self.operation,
                                                     self.property_name,
                                                     str(self)))


class AccessorGeneratorBase(object):

    """
    Accessor method/class generator for specific property name
    """

    def __init__(self, property_name, libvirtxml, forbidden=None, **dargs):
        """
        Initialize accessor methods, marking operations in forbidden as such

        :param property_name: Name of the property
        :param libvirtxml: Instance reference to LibvirtXMLBase subclass
        :param forbidden: Optional string list of 'get', 'set', and/or 'del'
        :param dargs: Specific AccessorGeneratorBase subclass info.
        """
        if forbidden is None:
            forbidden = []
        type_check('forbidden', forbidden, list)
        self.forbidden = forbidden

        type_check('libvirtxml', libvirtxml, base.LibvirtXMLBase)
        self.libvirtxml = libvirtxml

        type_check('property_name', property_name, str)
        self.property_name = property_name

        self.dargs = dargs

        # Lookup all property names possibly needing accessors
        for operation in ('get', 'set', 'del'):
            self.set_if_not_defined(operation)

    def set_if_not_defined(self, operation):
        """
        Setup a callable instance for operation only if not already defined
        """
        # Don't overwrite methods in libvirtxml instance
        if not hasattr(self.libvirtxml, self.accessor_name(operation)):
            if operation not in self.forbidden:
                self.assign_callable(operation, self.make_callable(operation))
            else:  # operation is forbidden
                self.assign_callable(operation, self.make_forbidden(operation))

    def accessor_name(self, operation):
        """
        Return instance name for operation, defined by subclass (i.e. 'get_foo')
        """
        return "%s_%s" % (operation, self.property_name)

    @staticmethod
    def callable_name(operation):
        """
        Return class name for operation (i.e. 'Getter'), defined by subclass.
        """
        return operation.capitalize() + 'ter'

    def make_callable(self, operation):
        """
        Return an callable instance for operation
        """
        callable_class = getattr(self, self.callable_name(operation))
        return callable_class(
            self.callable_name(operation), self.property_name,
            self.libvirtxml, **self.dargs)

    def make_forbidden(self, operation):
        """
        Return a forbidden callable instance for operation
        """
        return ForbiddenBase(operation, self.property_name, self.libvirtxml)

    def assign_callable(self, operation, callable_inst):
        """
        Set reference on objectified libvirtxml instance to callable_inst
        """
        self.libvirtxml.__super_set__(self.accessor_name(operation),
                                      callable_inst)


# Implementation of specific accessor generator subclasses follows


class AllForbidden(AccessorGeneratorBase):

    """
    Class of forbidden accessor classes for those undefined on libvirtxml
    """

    def __init__(self, property_name, libvirtxml):
        """
        Create exception raising accessors for those undefined on libvirtxml

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        """
        super(AllForbidden, self).__init__(property_name=property_name,
                                           libvirtxml=libvirtxml,
                                           forbidden=['get', 'set', 'del'])


class XMLElementText(AccessorGeneratorBase):

    """
    Class of accessor classes operating on element.text
    """

    required_dargs = ('parent_xpath', 'tag_name')

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, tag_name=None):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'get', 'set', 'del'
        :param parent_xpath: XPath string of parent element
        :param tag_name: element tag name to manipulate text attribute on.
        """
        super(XMLElementText, self).__init__(property_name, libvirtxml,
                                             forbidden,
                                             parent_xpath=parent_xpath,
                                             tag_name=tag_name)

    class Getter(AccessorBase):

        """
        Retrieve text on element
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self):
            return self.element_by_parent(self.parent_xpath,
                                          self.tag_name, create=False).text

    class Setter(AccessorBase):

        """
        Set text to value on element
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self, value):
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=True)
            element.text = str(value)
            self.xmltreefile().write()

    class Delter(AccessorBase):

        """
        Remove element and ignore if it doesn't exist (same as False)
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self):
            try:
                element = self.element_by_parent(self.parent_xpath,
                                                 self.tag_name, create=False)
            except (xcepts.LibvirtXMLNotFoundError,  # element doesn't exist
                    xcepts.LibvirtXMLAccessorError):  # parent doesn't exist
                pass  # already gone
            else:
                parent = self.xmltreefile().find(self.parent_xpath)
                if parent is not None:
                    parent.remove(element)
                    self.xmltreefile().write()


class XMLElementInt(AccessorGeneratorBase):

    """
    Class of accessor classes operating on element.text as an integer
    """
    __radix2func_dict__ = {0: int,
                           2: bin,
                           8: oct,
                           10: int,
                           16: hex}

    required_dargs = ('parent_xpath', 'tag_name', 'radix')

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, tag_name=None, radix=10):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'Getter', 'Setter', 'Delter'
        :param parent_xpath: XPath string of parent element
        :param tag_name: element tag name to manipulate text attribute on.
        """
        try:
            self.__radix2func_dict__[radix]
        except KeyError:
            raise xcepts.LibvirtXMLError("Param radix=%s for XMLElementInt "
                                         "is not accepted." % radix)
        super(XMLElementInt, self).__init__(property_name, libvirtxml,
                                            forbidden,
                                            parent_xpath=parent_xpath,
                                            tag_name=tag_name,
                                            radix=radix)

    class Getter(AccessorBase):

        """
        Retrieve text on element and convert to int
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'radix')

        def __call__(self):
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=False)
            try:
                result = int(element.text, self.radix)
            except ValueError:
                raise xcepts.LibvirtXMLError("Value of %s in %s is %s,"
                                             "not a Integer." % (self.tag_name,
                                                                 self.parent_xpath, element.text))
            return result

    class Setter(AccessorBase):

        """
        Set text on element after converting to int then to str
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'radix')

        def __call__(self, value):
            type_check(self.property_name + ' value', value, int)
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=True)
            convertFunc = XMLElementInt.__radix2func_dict__[self.radix]
            element.text = str(convertFunc(value))
            self.xmltreefile().write()

    Delter = XMLElementText.Delter


class XMLElementBool(AccessorGeneratorBase):

    """
    Class of accessor classes operating purely element existence
    """

    required_dargs = ('parent_xpath', 'tag_name')

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, tag_name=None):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'get', 'set', 'del'
        :param parent_xpath: XPath string of parent element
        :param tag_name: element tag name to manipulate text attribute on.
        """
        super(XMLElementBool, self).__init__(property_name, libvirtxml,
                                             forbidden,
                                             parent_xpath=parent_xpath,
                                             tag_name=tag_name)

    class Getter(AccessorBase):

        """
        Retrieve text on element
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self):
            try:
                # Throws exception if parent path or element not exist
                self.element_by_parent(self.parent_xpath, self.tag_name,
                                       create=False)
                return True
            except (xcepts.LibvirtXMLAccessorError,
                    xcepts.LibvirtXMLNotFoundError):
                return False

    class Setter(AccessorBase):

        """
        Create element when True, delete when false
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self, value):
            if bool(value) is True:
                self.element_by_parent(self.parent_xpath, self.tag_name,
                                       create=True)
            else:
                delattr(self.libvirtxml, self.property_name)
            self.xmltreefile().write()

    Delter = XMLElementText.Delter


class XMLAttribute(AccessorGeneratorBase):

    """
    Class of accessor classes operating on an attribute of an element
    """

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, tag_name=None, attribute=None):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'Getter', 'Setter', 'Delter'
        :param parent_xpath: XPath string of parent element
        :param tag_name: element tag name to manipulate text attribute on.
        :param attribute: Attribute name to manupulate
        """
        super(XMLAttribute, self).__init__(property_name, libvirtxml,
                                           forbidden, parent_xpath=parent_xpath,
                                           tag_name=tag_name, attribute=attribute)

    class Getter(AccessorBase):

        """
        Get attribute value
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'attribute')

        def __call__(self):
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=False)
            value = element.get(self.attribute, None)
            if value is None:
                raise xcepts.LibvirtXMLNotFoundError("Attribute %s not found"
                                                     "on element %s"
                                                     % (self.attribute,
                                                        element.tag))
            return value

    class Setter(AccessorBase):

        """
        Set attribute value
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'attribute')

        def __call__(self, value):
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=True)
            element.set(self.attribute, str(value))
            self.xmltreefile().write()

    class Delter(AccessorBase):

        """
        Remove attribute
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'attribute')

        def __call__(self):
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=False)
            try:
                del element.attrib[self.attribute]
            except KeyError:
                pass  # already doesn't exist
            self.xmltreefile().write()


class XMLElementDict(AccessorGeneratorBase):

    """
    Class of accessor classes operating as a dictionary of attributes
    """

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, tag_name=None):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'Getter', 'Setter', 'Delter'
        :param parent_xpath: XPath string of parent element
        :param tag_name: element tag name to manipulate text attribute on.
        """
        super(XMLElementDict, self).__init__(property_name, libvirtxml,
                                             forbidden,
                                             parent_xpath=parent_xpath,
                                             tag_name=tag_name)

    class Getter(AccessorBase):

        """
        Retrieve attributes on element
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self):
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=False)
            return dict(element.items())

    class Setter(AccessorBase):

        """
        Set attributes to value on element
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name')

        def __call__(self, value):
            type_check(self.property_name + ' value', value, dict)
            element = self.element_by_parent(self.parent_xpath,
                                             self.tag_name, create=True)
            for attr_key, attr_value in value.items():
                element.set(str(attr_key), str(attr_value))
            self.xmltreefile().write()

    # Inheriting from XMLElementText not work right
    Delter = XMLElementText.Delter


class XMLElementNest(AccessorGeneratorBase):

    """
    Class of accessor classes operating on a LibvirtXMLBase subclass
    """

    required_dargs = ('parent_xpath', 'tag_name', 'subclass', 'subclass_dargs')

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, tag_name=None, subclass=None,
                 subclass_dargs=None):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'Getter', 'Setter', 'Delter'
        :param parent_xpath: XPath string of parent element
        :param tag_name: element tag name to manipulate text attribute on.
        :param subclass: A LibvirtXMLBase subclass with root tag == tag_name
        :param subclass_dargs: dict. to pass as kw args to subclass.__init__

        N/B: Works ONLY if tag_name is unique within parent element
        """
        type_check('subclass', subclass, base.LibvirtXMLBase)
        type_check('subclass_dargs', subclass_dargs, dict)
        super(XMLElementNest, self).__init__(property_name, libvirtxml,
                                             forbidden,
                                             parent_xpath=parent_xpath,
                                             tag_name=tag_name,
                                             subclass=subclass,
                                             subclass_dargs=subclass_dargs)

    class Getter(AccessorBase):

        """
        Retrieve instance of subclass with it's xml set to rerooted xpath/tag
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'subclass',
                                 'subclass_dargs')

        def __call__(self):
            xmltreefile = self.xmltreefile()
            # Don't re-invent XPath generation method/behavior
            nested_root_element = self.element_by_parent(self.parent_xpath,
                                                         self.tag_name,
                                                         create=False)
            nested_root_xpath = xmltreefile.get_xpath(nested_root_element)
            # Try to make XMLTreeFile copy, rooted at nested_root_xpath
            # with copies of any/all child elements also
            nested_xtf = xmltreefile.reroot(nested_root_xpath)
            # Create instance of subclass to assign nested_xtf onto
            nestedinst = self.subclass(**self.subclass_dargs)
            # nestedxml.xmltreefile.restore() will fail on nested_xtf.__del__
            nestedinst.set_xml(str(nested_xtf))  # set from string not filename!
            return nestedinst

    class Setter(AccessorBase):

        """
        Set attributes to value on element
        """

        __slots__ = add_to_slots('parent_xpath', 'tag_name', 'subclass')

        def __call__(self, value):
            type_check('Instance of %s' % self.subclass.__name__,
                       value,
                       self.subclass)
            # Will overwrite if exists
            existing_element = self.element_by_parent(self.parent_xpath,
                                                      self.tag_name,
                                                      create=True)
            existing_parent = self.xmltreefile().get_parent(existing_element)
            self.xmltreefile().remove(existing_element)
            existing_parent.append(value.xmltreefile.getroot())
            self.xmltreefile().write()

    # Nothing fancy, just make sure that part of tree doesn't exist
    Delter = XMLElementText.Delter


class XMLElementList(AccessorGeneratorBase):

    """
    Class of accessor classes operating on a list of child elements

    Other generators here have a hard-time dealing with XML that has
    multiple child-elements with the same tag.  This class allows
    treating these structures as lists of arbitrary user-defined
    objects.  User-defined marshal functions are called to perform
    the conversion to/from the format described in __init__.
    """

    required_dargs = ('parent_xpath', 'tag_name', 'marshal_from', 'marshal_to')

    def __init__(self, property_name, libvirtxml, forbidden=None,
                 parent_xpath=None, marshal_from=None, marshal_to=None):
        """
        Create undefined accessors on libvirt instance

        :param property_name: String name of property (for exception detail)
        :param libvirtxml: An instance of a LibvirtXMLBase subclass
        :param forbidden: Optional list of 'Getter', 'Setter', 'Delter'
        :param parent_xpath: XPath string of parent element
        :param marshal_from: Callable, passed the item, index, and
                              libvirtxml instance.  Must return tuple
                              of tag-name, and an attribute-dict or raise
                              ValueError exception.
        :param marshal_to: Callable. Passed a the item tag, attribute-dict.,
                            index, and libvirtxml instance.  Returns
                            item value accepted by marshal_from or None to skip
        """
        if not callable(marshal_from) or not callable(marshal_to):
            raise ValueError("Both marshal_from and marshal_to must be "
                             "callable")
        super(XMLElementList, self).__init__(property_name, libvirtxml,
                                             forbidden,
                                             parent_xpath=parent_xpath,
                                             marshal_from=marshal_from,
                                             marshal_to=marshal_to)

    class Getter(AccessorBase):

        """
        Retrieve list of values as returned by the marshal_to callable
        """

        __slots__ = add_to_slots('parent_xpath', 'marshal_to')

        def __call__(self):
            # Parent structure cannot be pre-determined as in other classes
            parent = self.xmltreefile().find(self.parent_xpath)
            if parent is None:
                # Used as "undefined" signal, raising exception may
                # not be appropriate when other accessors are used
                # to generate missing structure.
                return None
            result = []
            # Give user-defined marshal functions a way to act on
            # item order if needed, and/or help with error reporting.
            index = 0
            # user-defined marshal functions might want to use
            # index numbers to filter/skip certain elements
            # but also support specific item ordering.
            for child in parent.getchildren():
                # Call user-defined helper to translate Element
                # into simple pre-defined format.
                item = self.marshal_to(child.tag, dict(child.items()),
                                       index, self.libvirtxml)
                if item is not None:
                    result.append(item)
                # Always use absolute index (even if item was None)
                index += 1
            return result

    class Setter(AccessorBase):

        """
        Set child elements as returned by the marshal_to callable
        """

        __slots__ = add_to_slots('parent_xpath', 'marshal_from')

        def __call__(self, value):
            type_check('value', value, list)
            # Allow other classes to generate parent structure
            parent = self.xmltreefile().find(self.parent_xpath)
            if parent is None:
                raise xcepts.LibvirtXMLNotFoundError
            # Remove existing by calling accessor method, allowing
            # any "untouchable" or "filtered" elements (by marshal)
            # to be ignored and left as-is.
            delattr(self.libvirtxml, self.property_name)
            # Allow user-defined marshal function to determine
            # if item order is important.  Also give more meaningful
            # exception message below, if there is a problem.
            index = 0
            for item in value:
                try:
                    # Call user-defined conversion from simple
                    # format, back to Element instances.
                    element_tuple = self.marshal_from(item, index,
                                                      self.libvirtxml)
                except ValueError:
                    # Defined in marshal API, to help with error reporting
                    # and debugging with more rich message.
                    msg = ("Call to %s by set accessor method for property %s "
                           "with unsupported item type %s, at index %d, "
                           " with value %s." % (str(self.marshal_from),
                                                self.property_name,
                                                str(type(item)),
                                                index,
                                                str(item)))
                    raise xcepts.LibvirtXMLAccessorError(msg)
                xml_utils.ElementTree.SubElement(parent,
                                                 element_tuple[0],
                                                 element_tuple[1])
                index += 1
            self.xmltreefile().write()

    class Delter(AccessorBase):

        """
        Remove ALL child elements for which marshal_to does NOT return None
        """

        __slots__ = add_to_slots('parent_xpath', 'marshal_to')

        def __call__(self):
            parent = self.xmltreefile().find(self.parent_xpath)
            if parent is None:
                raise xcepts.LibvirtXMLNotFoundError("Parent element %s not "
                                                     "found" % self.parent_xpath)
            # Don't delete while traversing list
            todel = []
            index = 0
            for child in parent.getchildren():
                item = self.marshal_to(child.tag, dict(child.items()),
                                       index, self.libvirtxml)
                # Always use absolute index (even if item was None)
                index += 1
                # Account for case where child elements are mixed in
                # with other elements not supported by this class.
                # Also permits marshal functions to do element filtering
                # if the class should only address specificly attributed
                # elements.
                if item is not None:
                    todel.append(child)
            for child in todel:
                parent.remove(child)

########NEW FILE########
__FILENAME__ = base
import logging
import imp

from autotest.client import utils
from virttest import propcan, xml_utils, virsh
from virttest.libvirt_xml import xcepts


class LibvirtXMLBase(propcan.PropCanBase):

    """
    Base class for common attributes/methods applying to all sub-classes

    Properties:
        xml:
            virtual XMLTreeFile instance
        get:
            xml filename string
        set:
            create new XMLTreeFile instance from string or filename
        del:
            deletes property, closes & unlinks any temp. files
        xmltreefile:
            XMLTreeFile instance
        virsh:
            virsh module or Virsh class instance
        set:
            validates and sets value
        get:
            returns value
        del:
            removes value
        validates:
            virtual boolean, read-only, True/False from virt-xml-validate
    """

    __slots__ = ('xml', 'virsh', 'xmltreefile', 'validates')
    __uncompareable__ = __slots__
    __schema_name__ = None

    def __init__(self, virsh_instance=virsh):
        """
        Initialize instance with connection to virsh

        :param virsh_instance: virsh module or instance to use
        """
        self.__dict_set__('xmltreefile', None)
        self.__dict_set__('validates', None)
        super(LibvirtXMLBase, self).__init__({'virsh': virsh_instance,
                                              'xml': None})
        # Can't use accessors module here, would make circular dep.

    def __str__(self):
        """
        Returns raw XML as a string
        """
        return str(self.__dict_get__('xml'))

    def __eq__(self, other):
        # Dynamic accessor methods mean we cannot compare class objects
        # directly
        if self.__class__.__name__ != other.__class__.__name__:
            return False
        # Don't assume both instances have same comparables
        uncomparable = set(self.__uncompareable__)
        uncomparable |= set(other.__uncompareable__)
        dict_1 = {}
        dict_2 = {}
        slots = set(self.__all_slots__) | set(other.__all_slots__)
        for slot in slots - uncomparable:
            try:
                dict_1[slot] = getattr(self, slot)
            except xcepts.LibvirtXMLNotFoundError:
                pass  # Unset virtual values won't have keys
            try:
                dict_2[slot] = getattr(other, slot)
            except xcepts.LibvirtXMLNotFoundError:
                pass  # Unset virtual values won't have keys
        return dict_1 == dict_2

    def __contains__(self, key):
        """
        Also hide any Libvirt_xml API exceptions behind standard python behavior
        """
        try:
            return super(LibvirtXMLBase, self).__contains__(key)
        except xcepts.LibvirtXMLError:
            return False
        return True

    def set_virsh(self, value):
        """Accessor method for virsh property, make sure it's right type"""
        value_type = type(value)
        # issubclass can't work for classes using __slots__ (i.e. no __bases__)
        if hasattr(value, 'VIRSH_EXEC') or hasattr(value, 'virsh_exec'):
            self.__dict_set__('virsh', value)
        else:
            raise xcepts.LibvirtXMLError("virsh parameter must be a module "
                                         "named virsh or subclass of virsh.VirshBase "
                                         "not a %s" % str(value_type))

    def set_xml(self, value):
        """
        Accessor method for 'xml' property to load using xml_utils.XMLTreeFile
        """
        # Always check to see if a "set" accessor is being called from __init__
        if not self.__super_get__('INITIALIZED'):
            self.__dict_set__('xml', value)
        else:
            try:
                if self.__dict_get__('xml') is not None:
                    del self['xml']  # clean up old temporary files
            except KeyError:
                pass  # Allow other exceptions through
            # value could be filename or a string full of XML
            self.__dict_set__('xml', xml_utils.XMLTreeFile(value))

    def get_xml(self):
        """
        Accessor method for 'xml' property returns xmlTreeFile backup filename
        """
        return self.xmltreefile.name  # The filename

    def get_xmltreefile(self):
        """
        Return the xmltreefile object backing this instance
        """
        try:
            # don't call get_xml() recursivly
            xml = self.__dict_get__('xml')
            if xml is None:
                raise KeyError
        except (KeyError, AttributeError):
            raise xcepts.LibvirtXMLError("No xml data has been loaded")
        return xml  # XMLTreeFile loaded by set_xml() method

    def set_xmltreefile(self, value):
        """
        Point instance directly at an already initialized XMLTreeFile instance
        """
        if not issubclass(type(value), xml_utils.XMLTreeFile):
            raise xcepts.LibvirtXMLError("xmltreefile value must be XMLTreefile"
                                         " type or subclass, not a %s"
                                         % type(value))
        self.__dict_set__('xml', value)

    def del_xmltreefile(self):
        """
        Remove all backing XML
        """
        self.__dict_del__('xml')

    def copy(self):
        """
        Returns a copy of instance not sharing any references or modifications
        """
        # help keep line length short, virsh is not a property
        the_copy = self.__class__(virsh_instance=self.virsh)
        try:
            # file may not be accessible, obtain XML string value
            xmlstr = str(self.__dict_get__('xml'))
            # Create fresh/new XMLTreeFile along with tmp files from XML content
            # content
            the_copy.__dict_set__('xml', xml_utils.XMLTreeFile(xmlstr))
        except xcepts.LibvirtXMLError:  # Allow other exceptions through
            pass  # no XML was loaded yet
        return the_copy

    def get_validates(self):
        """
        Accessor method for 'validates' property returns virt-xml-validate T/F
        """
        # self.xml is the filename
        ret = self.virt_xml_validate(self.xml,
                                     self.__super_get__('__schema_name__'))
        if ret.exit_status == 0:
            return True
        else:
            logging.debug(ret)
            return False

    def set_validates(self, value):
        """
        Raises LibvirtXMLError
        """
        del value  # not needed
        raise xcepts.LibvirtXMLError("Read only property")

    def del_validates(self):
        """
        Raises LibvirtXMLError
        """
        raise xcepts.LibvirtXMLError("Read only property")

    def restore(self):
        """
        Restore current xml content to original source content
        """
        self.xmltreefile.restore()

    @staticmethod
    def virt_xml_validate(filename, schema_name=None):
        """
        Return CmdResult from running virt-xml-validate on backing XML
        """
        command = 'virt-xml-validate %s' % filename
        if schema_name:
            command += ' %s' % schema_name
        cmdresult = utils.run(command, ignore_status=True)
        return cmdresult


def load_xml_module(path, name, type_list):
    """
    Returns named xml element's handler class

    :param path: the xml module path
    :param name: the xml module name
    :param type_list: the supported type list of xml module names
    :return: the named xml element's handler class
    """
    # Module names and tags are always all lower-case
    name = str(name).lower()
    errmsg = ("Unknown/unsupported type '%s', supported types %s"
              % (str(name), type_list))
    if name not in type_list:
        raise xcepts.LibvirtXMLError(errmsg)
    try:
        filename, pathname, description = imp.find_module(name,
                                                          [path])
        mod_obj = imp.load_module(name, filename, pathname, description)
        # Enforce capitalized class names
        return getattr(mod_obj, name.capitalize())
    except TypeError, detail:
        raise xcepts.LibvirtXMLError(errmsg + ': %s' % str(detail))
    except ImportError, detail:
        raise xcepts.LibvirtXMLError("Can't find module %s in %s: %s"
                                     % (name, path, str(detail)))
    except AttributeError, detail:
        raise xcepts.LibvirtXMLError("Can't find class %s in %s module in "
                                     "%s: %s"
                                     % (name.capitalize(), name, pathname,
                                        str(detail)))

########NEW FILE########
__FILENAME__ = capability_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatcaps.html
"""

from virttest import xml_utils
from virttest.libvirt_xml import base, accessors, xcepts


class CapabilityXML(base.LibvirtXMLBase):

    """
    Handler of libvirt capabilities and nonspecific item operations.

    Properties:
        uuid:
            string of host uuid
        os_arch_machine_map:
            dict, read-only
        get:
            dict map from os type names to dict map from arch names
    """

    # TODO: Add more __slots__ and accessors to get some useful stats
    # e.g. guest_count etc.

    __slots__ = ('uuid', 'os_arch_machine_map', 'cpu_count', 'arch', 'model',
                 'vendor', 'feature_list',)
    __schema_name__ = "capability"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementText(property_name="uuid",
                                 libvirtxml=self,
                                 forbidden=['set', 'del'],
                                 parent_xpath='/host',
                                 tag_name='uuid')
        # This will skip self.get_os_arch_machine_map() defined below
        accessors.AllForbidden(property_name="os_arch_machine_map",
                               libvirtxml=self)
        # This will skip self.get_cpu_count() defined below
        accessors.AllForbidden(property_name="cpu_count",
                               libvirtxml=self)
        # The set action is for test.
        accessors.XMLElementText(property_name="arch",
                                 libvirtxml=self,
                                 forbidden=['del'],
                                 parent_xpath='/host/cpu',
                                 tag_name='arch')
        accessors.XMLElementText(property_name="model",
                                 libvirtxml=self,
                                 forbidden=['del'],
                                 parent_xpath='/host/cpu',
                                 tag_name='model')
        accessors.XMLElementText(property_name="vendor",
                                 libvirtxml=self,
                                 forbidden=['del'],
                                 parent_xpath='/host/cpu',
                                 tag_name='vendor')
        # This will skip self.get_feature_list() defined below
        accessors.AllForbidden(property_name="feature_list",
                               libvirtxml=self)
        super(CapabilityXML, self).__init__(virsh_instance)
        # calls set_xml accessor method
        self['xml'] = self.__dict_get__('virsh').capabilities()

    def get_os_arch_machine_map(self):
        """
        Accessor method for os_arch_machine_map property (in __slots__)
        """
        oamm = {}  # Schema {<os_type>:{<arch name>:[<machine>, ...]}}
        xmltreefile = self.__dict_get__('xml')
        for guest in xmltreefile.findall('guest'):
            os_type_name = guest.find('os_type').text
            # Multiple guest definitions can share same os_type (e.g. hvm, pvm)
            if os_type_name == 'xen':
                os_type_name = 'pv'
            amm = oamm.get(os_type_name, {})
            for arch in guest.findall('arch'):
                arch_name = arch.get('name')
                mmap = amm.get(arch_name, [])
                for machine in arch.findall('machine'):
                    machine_text = machine.text
                    # Don't add duplicate entries
                    if not mmap.count(machine_text):
                        mmap.append(machine_text)
                amm[arch_name] = mmap
            oamm[os_type_name] = amm
        return oamm

    def get_feature_list(self):
        """
        Accessor method for feature_list property (in __slots__)
        """
        feature_list = []  # [<feature1>, <feature2>, ...]
        xmltreefile = self.__dict_get__('xml')
        for feature_node in xmltreefile.findall('/host/cpu/feature'):
            feature_list.append(feature_node)
        return feature_list

    def get_feature_name(self, num):
        """
        Get assigned feature name

        :param num: Assigned feature number
        :return: Assigned feature name
        """
        count = len(self.feature_list)
        if num >= count:
            raise xcepts.LibvirtXMLError("Get %d from %d features:"
                                         % (num, count))
        feature_name = self.feature_list[num].get('name')
        return feature_name

    def get_cpu_count(self):
        """
        Accessor method for cpu_count property (in __slots__)
        """
        cpu_count = 0
        xmltreefile = self.__dict_get__('xml')
        for cpus in xmltreefile.findall('/host/topology/cells/cell/cpus'):
            cpu_num = cpus.get('num')
            cpu_count += int(cpu_num)
        return cpu_count

    def remove_feature(self, num):
        """
        Remove a assigned feature from xml

        :param num: Assigned feature number
        """
        xmltreefile = self.__dict_get__('xml')
        count = len(self.feature_list)
        if num >= count:
            raise xcepts.LibvirtXMLError("Remove %d from %d features:"
                                         % (num, count))
        feature_remove_node = self.feature_list[num]
        cpu_node = xmltreefile.find('/host/cpu')
        cpu_node.remove(feature_remove_node)

    def check_feature_name(self, name):
        """
        Check feature name valid or not.

        :param name: The checked feature name
        :return: True if check pass
        """
        sys_feature = []
        cpu_xml_file = open('/proc/cpuinfo', 'r')
        for line in cpu_xml_file.readlines():
            if line.find('flags') != -1:
                feature_names = line.split(':')[1].strip()
                sys_sub_feature = feature_names.split(' ')
                sys_feature = list(set(sys_feature + sys_sub_feature))
        cpu_xml_file.close()
        return (name in sys_feature)

    def set_feature(self, num, value):
        """
        Set a assigned feature value to xml

        :param num: Assigned feature number
        :param value: The feature name modified to
        """
        count = len(self.feature_list)
        if num >= count:
            raise xcepts.LibvirtXMLError("Set %d from %d features:"
                                         % (num, count))
        feature_set_node = self.feature_list[num]
        feature_set_node.set('name', value)

    def add_feature(self, value):
        """
        Add a feature Element to xml

        :param value: The added feature name
        """
        xmltreefile = self.__dict_get__('xml')
        cpu_node = xmltreefile.find('/host/cpu')
        xml_utils.ElementTree.SubElement(cpu_node, 'feature', {'name': value})

########NEW FILE########
__FILENAME__ = address
"""
Address device / device descriptor class

http://libvirt.org/formatdomain.html#elementsAddress
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.devices import base


class Address(base.TypedDeviceBase):

    __slots__ = ('attrs',)

    def __init__(self, type_name, virsh_instance=base.base.virsh):
        # Blindly accept any/all attributes as simple dictionary
        accessors.XMLElementDict('attrs', self, parent_xpath='/',
                                 tag_name='address')
        super(self.__class__, self).__init__(device_tag='address',
                                             type_name=type_name,
                                             virsh_instance=virsh_instance)

    @classmethod
    def new_from_dict(cls, attributes, virsh_instance=base.base.virsh):
        # type_name is manditory, throw exception if doesn't exist
        try:
            # pop() so don't process again in loop below
            instance = cls(type_name=attributes.pop('type_name'),
                           virsh_instance=virsh_instance)
        except (KeyError, AttributeError):
            raise xcepts.LibvirtXMLError("type_name is manditory for "
                                         "Address class")
        # Stick property values in as attributes
        xtfroot = instance.xmltreefile.getroot()
        for key, value in attributes.items():
            xtfroot.set(key, value)
        return instance

    @classmethod
    def new_from_element(cls, element, virsh_instance=base.base.virsh):
        # element uses type attribute, class uses type_name
        edict = dict(element.items())
        try:
            edict['type_name'] = edict.pop('type')
        except (KeyError, AttributeError):
            raise xcepts.LibvirtXMLError("type attribute is manditory for "
                                         "Address class")
        return cls.new_from_dict(edict, virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = base
"""
Common base classes for devices
"""

import logging
from StringIO import StringIO
from virttest import xml_utils
from virttest.libvirt_xml import base, xcepts, accessors
from virttest.xml_utils import ElementTree


class UntypedDeviceBase(base.LibvirtXMLBase):

    """
    Base class implementing common functions for all device XML w/o a type attr.
    """

    __slots__ = ('device_tag',)

    # Subclasses are expected to hide device_tag
    def __init__(self, device_tag, virsh_instance=base.virsh):
        """
        Initialize untyped device instance's basic XML with device_tag
        """
        super(UntypedDeviceBase, self).__init__(virsh_instance=virsh_instance)
        # Just a regular dictionary value
        # (Using a property to change element tag won't work)
        self['device_tag'] = device_tag
        # setup bare-bones XML
        self.xml = u"<%s/>" % device_tag

    def from_element(self, element):
        """
        Stateful component to helper method for new_from_element.
        """
        class_name = self.__class__.__name__
        if element.tag != class_name.lower():
            raise xcepts.LibvirtXMLError('Refusing to create %s instance'
                                         'from %s tagged element'
                                         % (class_name, element.tag))
        # XMLTreeFile only supports element trees
        etree = xml_utils.ElementTree.ElementTree(element)
        # ET only writes to open file-like objects
        xmlstr = StringIO()
        # Need element tree string value to initialize LibvirtXMLBase.xml
        etree.write(xmlstr, xml_utils.ENCODING)
        # Create a new XMLTreeFile object based on string input
        self.xml = xmlstr.getvalue()

    @classmethod
    def new_from_element(cls, element, virsh_instance=base.virsh):
        """
        Create a new device XML instance from an single ElementTree element
        """
        # subclasses __init__ only takes virsh_instance parameter
        instance = cls(virsh_instance=virsh_instance)
        instance.from_element(element)
        return instance

    @classmethod
    def new_from_dict(cls, properties, virsh_instance=base.virsh):
        """
        Create a new device XML instance from a dict-like object
        """
        instance = cls(virsh_instance=virsh_instance)
        for key, value in properties.items():
            setattr(instance, key, value)
        return instance

    # Add accessors here to be used by any elements
    def _get_list(self, tag_filter):
        """
        Return a list of dictionaries containing element's attributes.
        """
        dict_list = []
        elements = self.xmltreefile.findall(tag_filter)
        for element in elements:
            dict_list.append(dict(element.items()))
        return dict_list

    def _set_list(self, tag_name, value):
        """
        Set all elements to the value list of dictionaries of element's
        attributes.
        """
        xcept = xcepts.LibvirtXMLError("Must set %s child %s elements from"
                                       " a list of dictionary"
                                       % (self.device_tag, tag_name))
        if not isinstance(value, list):
            raise xcept
        # Start with clean slate
        self._del_list(tag_name)
        for dict_item in value:
            if not isinstance(dict_item, dict):
                raise xcept
            ElementTree.SubElement(self.xmltreefile.getroot(),
                                   tag_name, dict_item)
        self.xmltreefile.write()

    def _del_list(self, tag_filter):
        """
        Remove the list of dictionaries containing each element's attributes.
        """
        element = self.xmltreefile.find(tag_filter)
        while element is not None:
            self.xmltreefile.getroot().remove(element)
            element = self.xmltreefile.find(tag_filter)
        self.xmltreefile.write()

    def _add_item(self, prop_name, **attributes):
        """
        Convenience method for appending an element from dictionary of
        attributes.
        """
        items = self[prop_name]  # xml element name
        items.append(attributes)
        self[prop_name] = items

    def _update_item(self, prop_name, index, **attributes):
        """
        Convenience method for merging values into an element's attributes
        """
        items = self[prop_name]  # xml element name
        item = items[index]
        item.update(attributes)
        self[prop_name] = items


class TypedDeviceBase(UntypedDeviceBase):

    """
    Base class implementing common functions for all device XML w/o a type attr.
    """

    __slots__ = ('type_name',)

    # Subclasses are expected to hide device_tag
    def __init__(self, device_tag, type_name, virsh_instance=base.virsh):
        """
        Initialize Typed device instance's basic XML with type_name & device_tag
        """
        # generate getter, setter, deleter for 'type_name' property
        accessors.XMLAttribute('type_name', self,
                               # each device is it's own XML "document"
                               # because python 2.6 ElementPath is broken
                               parent_xpath='/',
                               tag_name=device_tag,
                               attribute='type')
        super(TypedDeviceBase, self).__init__(device_tag=device_tag,
                                              virsh_instance=virsh_instance)
        # Calls accessor to modify xml
        self.type_name = type_name

    @classmethod
    def new_from_element(cls, element, virsh_instance=base.virsh):
        """
        Hides type_name from superclass new_from_element().
        """
        type_name = element.get('type', None)
        # subclasses must hide device_tag parameter
        instance = cls(type_name=type_name,
                       virsh_instance=virsh_instance)
        instance.from_element(element)
        return instance


# Metaclass is a type-of-types or a class-generating class.
# Using it here to avoid copy-pasting very similar class
# definitions into every unwritten device module.
#
# Example usage for stub disk device:
#
# class Disk(base.TypedDeviceBase):
#     __metaclass__ = base.StubDeviceMeta
#     _device_tag = 'disk'
#     _def_type_name = 'block'
#
# will become defined as:
#
# class Disk(base.TypedDeviceBase):
#     def __init__(self, type_name='block', virsh_instance=base.virsh):
#         issue_warning()
#         super(Disk, self).__init__(device_tag='disk'),
#                                    type_name=type_name,
#                                    virsh_instance=virsh_instance)
#

class StubDeviceMeta(type):

    """
    Metaclass for generating stub Device classes where not fully implemented yet
    """

    warning_issued = False

    # mcs is the class object being generated, name is it's name, bases
    # is tuple of all baseclasses, and dct is what will become mcs's
    # __dict__ after super(...).__init__() is called.
    def __init__(mcs, name, bases, dct):
        """
        Configuration for new class
        """

        # Keep pylint happy
        dct = dict(dct)

        # Call type() to setup new class and store it as 'mcs'
        super(StubDeviceMeta, mcs).__init__(name, bases, dct)

        # Needed for UntypedDeviceBase __init__'s default argument value
        # i.e. device_tag='disk' as specified by specific device class
        if not hasattr(mcs, '_device_tag'):
            raise ValueError(
                "Class %s requires a _device_tag attribute" % name)

        # Same message for both TypedDeviceBase & UntypedDeviceBase subclasses
        message = ("Detected use of a stub device XML for a %s class. These "
                   "only implement a minimal interface that is very likely to "
                   "change in future versions.  This warning will only be "
                   " logged once." % name)

        def issue_warning():
            """
            Closure for created __init__ to only print message once.
            """
            # Examine the CLASS variable
            if not StubDeviceMeta.warning_issued:
                # Set the CLASS variable
                StubDeviceMeta.warning_issued = True
                logging.warning(message)
            else:
                pass  # do nothing

        # Create the proper init function for subclass type
        if TypedDeviceBase in bases:
            # Needed for TypedDeviceBase __init__'s default argument value
            # i.e. type_name='pci' as specified by specific device class.
            if not hasattr(mcs, '_def_type_name'):
                raise ValueError("TypedDevice sub-Class %s must define a "
                                 "_def_type_name attribute" % name)
            # form __init__() and it's arguments for generated class

            def stub_init(self, type_name=getattr(mcs, '_def_type_name'),
                          virsh_instance=base.virsh):
                """
                Initialize stub typed device instance
                """
                # issue warning only when some code instantiats
                # object from generated class
                issue_warning()
                # Created class __init__ still needs to call superclass
                # __init__ (i.e. UntypedDeviceBase or TypedDeviceBase)
                TypedDeviceBase.__init__(self, device_tag=getattr(mcs,
                                                                  '_device_tag'),
                                         type_name=type_name,
                                         virsh_instance=virsh_instance)
        elif UntypedDeviceBase in bases:
            # generate __init__() for untyped devices (similar to above)
            def stub_init(self, virsh_instance=base.virsh):
                """
                Initialize stub un-typed device instance
                """
                issue_warning()
                UntypedDeviceBase.__init__(self, device_tag=getattr(mcs,
                                                                    '_device_tag'),
                                           virsh_instance=virsh_instance)
        else:
            # unexpected usage
            raise TypeError("Class %s is not a subclass of TypedDeviceBase or "
                            "UntypedDeviceBase")
        # Point the generated class's __init__ at the generated function above
        setattr(mcs, '__init__', stub_init)

########NEW FILE########
__FILENAME__ = channel
"""
Classes to support XML for channel devices

http://libvirt.org/formatdomain.html#elementCharSerial
"""

from virttest.libvirt_xml import base
from virttest.libvirt_xml.devices.character import CharacterBase


class Channel(CharacterBase):

    __slots__ = []

    def __init__(self, type_name='unix', virsh_instance=base.virsh):
        super(
            Channel, self).__init__(device_tag='channel', type_name=type_name,
                                    virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = character
"""
Generic character device support for serial, parallel, channel, and console

http://libvirt.org/formatdomain.html#elementCharSerial
"""

from virttest.libvirt_xml.devices import base


class CharacterBase(base.TypedDeviceBase):

    __slots__ = ('sources', 'targets')

    # Not overriding __init__ because ABC cannot hide device_tag as expected

    # Accessors just wrap private helpers in UntypedDeviceBase class
    def get_sources(self):
        """
        Return a list of dictionaries containing each source's attributes.
        """
        return self._get_list('source')

    def set_sources(self, value):
        """
        Set all sources to the value list of dictionaries of source attributes.
        """
        self._set_list('source', value)

    def del_sources(self):
        """
        Remove the list of dictionaries containing each source's attributes.
        """
        self._del_list('source')

    def get_targets(self):
        """
        Return a list of dictionaries containing each target's attributes.
        """
        return self._get_list('target')

    def set_targets(self, value):
        """
        Set all sources to the value list of dictionaries of target attributes.
        """
        self._set_list('target', value)

    def del_targets(self):
        """
        Remove the list of dictionaries containing each target's attributes.
        """
        self._del_list('target')

    # Some convenience methods so appending to sources/targets is easier
    def add_source(self, **attributes):
        """
        Convenience method for appending a source from dictionary of attributes
        """
        self._add_item('sources', **attributes)

    def add_target(self, **attributes):
        """
        Convenience method for appending a target from dictionary of attributes
        """
        self._add_item('targets', **attributes)

    def update_source(self, index, **attributes):
        """
        Convenience method for merging values into a source's attributes
        """
        self._update_item('sources', index, **attributes)

    def update_target(self, index, **attributes):
        """
        Convenience method for merging values into a target's attributes
        """
        self._update_item('targets', index, **attributes)

########NEW FILE########
__FILENAME__ = console
"""
Console device support class(es)

http://libvirt.org/formatdomain.html#elementCharSerial
"""

from virttest.libvirt_xml import base
from virttest.libvirt_xml.devices.character import CharacterBase


class Console(CharacterBase):

    __slots__ = []

    def __init__(self, type_name='pty', virsh_instance=base.virsh):
        super(
            Console, self).__init__(device_tag='console', type_name=type_name,
                                    virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = controller
"""
controller device support class(es)

http://libvirt.org/formatdomain.html#elementsControllers
"""

from virttest.libvirt_xml import accessors
from virttest.libvirt_xml.devices import base


class Controller(base.TypedDeviceBase):

    __slots__ = ('type', 'index', 'model',)

    def __init__(self, type_name, virsh_instance=base.base.virsh):
        super(Controller, self).__init__(device_tag='controller',
                                         type_name=type_name,
                                         virsh_instance=virsh_instance)
        accessors.XMLAttribute('type', self, parent_xpath='/',
                               tag_name='controller', attribute='type')
        accessors.XMLAttribute('index', self, parent_xpath='/',
                               tag_name='controller', attribute='index')
        accessors.XMLAttribute('model', self, parent_xpath='/',
                               tag_name='controller', attribute='model')

########NEW FILE########
__FILENAME__ = disk
"""
disk device support class(es)

http://libvirt.org/formatdomain.html#elementsDisks
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.devices import base, librarian


class Disk(base.TypedDeviceBase):

    """
    Disk device XML class

    Properties:
        device:
            string, how exposted to guest
        rawio:
            string (yes/no), disk needs rawio capability
        sgio:
            string, "filtered" or "unfiltered"
        snapshot:
            string, "yes", "no", "internal" or "external"
        driver:
            dict, keys: name, type, cache, error_policy, io, ioeventfd,
            event_idx, copy_on_read, discard
        target:
            dict, keys: dev, bus, tray
        address:
            libvirt_xml.devices.Address instance
        boot:
            string, boot order number to use if not using boot in os element
        readonly:
            bool, True/False
        transient:
            bool, True/False
        share:
            bool, True/False
        mirror:
            bool, read-only, True if block copy started
        ready:
            bool, read-only, True if disk ready for pivot
        iotune:
            libvirt_xml.devices.Disk.IOTune instance
        source:
            libvirt_xml.devices.Disk.DiskSource instance
    """

    __slots__ = ('device', 'rawio', 'sgio', 'snapshot', 'driver', 'target',
                 'address', 'boot', 'readonly', 'transient', 'share',
                 'mirror', 'ready', 'iotune', 'source')

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLAttribute('device', self, parent_xpath='/',
                               tag_name='disk', attribute='device')
        accessors.XMLAttribute('rawio', self, parent_xpath='/',
                               tag_name='disk', attribute='rawio')
        accessors.XMLAttribute('sgio', self, parent_xpath='/',
                               tag_name='disk', attribute='sgio')
        accessors.XMLAttribute('snapshot', self, parent_xpath='/',
                               tag_name='disk', attribute='snapshot')
        accessors.XMLElementDict('driver', self, parent_xpath='/',
                                 tag_name='driver')
        accessors.XMLElementDict('target', self, parent_xpath='/',
                                 tag_name='target')
        accessors.XMLElementNest('address', self, parent_xpath='/',
                                 tag_name='address', subclass=self.Address,
                                 subclass_dargs={'type_name': 'drive',
                                                 'virsh_instance': virsh_instance})
        accessors.XMLAttribute('boot', self, parent_xpath='/',
                               tag_name='boot', attribute='order')
        accessors.XMLElementBool('readonly', self, parent_xpath='/',
                                 tag_name='readonly')
        accessors.XMLElementBool('transient', self, parent_xpath='/',
                                 tag_name='transient')
        accessors.XMLElementBool('share', self, parent_xpath='/',
                                 tag_name='shareable')
        accessors.XMLElementNest('source', self, parent_xpath='/',
                                 tag_name='source', subclass=self.DiskSource,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        ro = ['set', 'del']
        accessors.XMLElementBool('mirror', self, forbidden=ro,
                                 parent_xpath='/', tag_name='mirror')
        accessors.XMLElementBool('ready', self, forbidden=ro,
                                 parent_xpath='/', tag_name='ready')
        accessors.XMLElementNest('iotune', self, parent_xpath='/',
                                 tag_name='iotune', subclass=self.IOTune,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Disk, self).__init__(device_tag='disk', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_disk_source(self, **dargs):
        """
        Return a new disk source instance and set properties from dargs
        """
        new_one = self.DiskSource(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def new_iotune(self, **dargs):
        """
        Return a new disk IOTune instance and set properties from dargs
        """
        new_one = self.IOTune(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def new_disk_address(self, type_name='drive', **dargs):
        """
        Return a new disk Address instance and set properties from dargs
        """
        new_one = self.Address(type_name=type_name, virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    # For convenience
    Address = librarian.get('address')

    class DiskSource(base.base.LibvirtXMLBase):

        """
        Disk source device XML class

        Properties:

        attrs: Dictionary of attributes, qualifying the disk type
        seclabels: list of libvirt_xml.devices.seclabel.Seclabel instances
        hosts: list of dictionaries describing network host properties
        """

        __slots__ = ('attrs', 'seclabels', 'hosts',)

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLElementDict('attrs', self, parent_xpath='/',
                                     tag_name='source')
            accessors.XMLElementList('seclabels', self, parent_xpath='/',
                                     marshal_from=self.marshal_from_seclabel,
                                     marshal_to=self.marshal_to_seclabel)
            accessors.XMLElementList('hosts', self, parent_xpath='/',
                                     marshal_from=self.marshal_from_host,
                                     marshal_to=self.marshal_to_host)
            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<source/>'

        @staticmethod
        def marshal_from_seclabel(item, index, libvirtxml):
            """Convert a Seclabel instance into tag + attributes"""
            del index           # not used
            del libvirtxml      # not used
            root = item.xmltreefile.getroot()
            if root.tag == 'seclabel':
                return (root.tag, dict(root.items))
            else:
                raise xcepts.LibvirtXMLError("Expected a list of seclabel "
                                             "instances, not a %s" % str(item))

        @staticmethod
        def marshal_to_seclabel(tag, attr_dict, index, libvirtxml):
            """Convert a tag + attributes into a Seclabel instance"""
            del index           # not used
            if tag != 'seclabel':
                return None     # Don't convert this item
            Seclabel = librarian.get('seclabel')
            newone = Seclabel(virsh_instance=libvirtxml.virsh)
            newone.update(attr_dict)
            return newone

        @staticmethod
        def marshal_from_host(item, index, libvirtxml):
            """Convert a dictionary into a tag + attributes"""
            del index           # not used
            del libvirtxml      # not used
            if not isinstance(item, dict):
                raise xcepts.LibvirtXMLError("Expected a dictionary of host "
                                             "attributes, not a %s"
                                             % str(item))
            return ('host', dict(item))  # return copy of dict, not reference

        @staticmethod
        def marshal_to_host(tag, attr_dict, index, libvirtxml):
            """Convert a tag + attributes into a dictionary"""
            del index                    # not used
            del libvirtxml               # not used
            if tag != 'host':
                return None              # skip this one
            return dict(attr_dict)       # return copy of dict, not reference

    class IOTune(base.base.LibvirtXMLBase):

        """
        IOTune device XML class

        Properties:

        total_bytes_sec: str(int)
        read_bytes_sec: str(int)
        write_bytes_sec: str(int)
        total_iops_sec: str(int)
        read_iops_sec: str(int)
        write_iops_sec: str(int)
        """

        __slots__ = ('total_bytes_sec', 'read_bytes_sec', 'write_bytes_sec',
                     'total_iops_sec', 'read_iops_sec', 'write_iops_sec')

        def __init__(self, virsh_instance=base.base.virsh):
            for slot in self.__all_slots__:
                if slot in base.base.LibvirtXMLBase.__all_slots__:
                    continue    # don't add these
                else:
                    accessors.XMLElementInt(slot, self, parent_xpath='/',
                                            tag_name=slot)
            super(Disk.IOTune, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<iotune/>'

########NEW FILE########
__FILENAME__ = emulator
"""
Support for the pseudo 'emulator' device XML

http://libvirt.org/formatdomain.html#elementsDevices
"""

from virttest.libvirt_xml import accessors
from virttest.libvirt_xml.devices import base


class Emulator(base.UntypedDeviceBase):

    __slots__ = ('path',)

    def __init__(self, virsh_instance=base.base.virsh):
        accessors.XMLElementText('path', self, parent_xpath='/',
                                 tag_name='emulator')
        super(Emulator, self).__init__(device_tag='emulator',
                                       virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = filesystem
"""
filesystem device support class(es)

http://libvirt.org/formatdomain.html#elementsFilesystems
"""

from virttest.libvirt_xml.devices import base


class Filesystem(base.TypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'filesystem'
    _def_type_name = 'file'

########NEW FILE########
__FILENAME__ = graphics
"""
graphics framebuffer device support class(es)

http://libvirt.org/formatdomain.html#elementsGraphics
"""

from virttest.libvirt_xml import accessors, vm_xml
from virttest.libvirt_xml.devices import base


class Graphics(base.TypedDeviceBase):

    __slots__ = ('passwd', 'channel', 'autoport', 'port', 'tlsPort')

    def __init__(self, type_name='vnc', virsh_instance=base.base.virsh):
        # Add additional attribute 'passwd' for security
        accessors.XMLAttribute('passwd', self, parent_xpath='/',
                               tag_name='graphics', attribute='passwd')
        accessors.XMLAttribute('autoport', self, parent_xpath='/',
                               tag_name='graphics', attribute='autoport')
        accessors.XMLAttribute('port', self, parent_xpath='/',
                               tag_name='graphics', attribute='port')
        accessors.XMLAttribute('tlsPort', self, parent_xpath='/',
                               tag_name='graphics', attribute='tlsPort')
        super(Graphics, self).__init__(device_tag='graphics',
                                       type_name=type_name,
                                       virsh_instance=virsh_instance)

    def get_channel(self):
        """
        Return a list of dictionaries containing each channel's attributes
        """
        return self._get_list('channel')

    def set_channel(self, value):
        """
        Set all channel to the value list of dictionaries of channel attributes
        """
        self._set_list('channel', value)

    def del_channel(self):
        """
        Remove the list of dictionaries containing each channel's attributes
        """
        self._del_list('channel')

    def add_channel(self, **attributes):
        """
        Convenience method for appending channel from dictionary of attributes
        """
        self._add_item('channel', **attributes)

    @staticmethod
    def change_graphic_type_passwd(vm_name, graphic, passwd=None):
        """
        Change the graphic type name and passwd

        :param vm_name: name of vm
        :param graphic: graphic type, spice or vnc
        :param passwd: password for graphic
        """
        vmxml = vm_xml.VMXML.new_from_dumpxml(vm_name)
        devices = vmxml.devices
        graphics = devices.by_device_tag('graphics')[0]
        graphics.type_name = graphic
        if passwd is not None:
            graphics.passwd = passwd
        vmxml.devices = devices
        vmxml.define()

    @staticmethod
    def add_ssl_spice_graphic(vm_name, passwd=None):
        """
        Add spice ssl graphic with passwd

        :param vm_name: name of vm
        :param passwd: password for graphic
        """
        vmxml = vm_xml.VMXML.new_from_dumpxml(vm_name)
        grap = vmxml.get_device_class('graphics')(type_name='spice')
        if passwd is not None:
            grap.passwd = passwd
        grap.autoport = "yes"
        grap.add_channel(name='main', mode='secure')
        grap.add_channel(name='inputs', mode='secure')
        vmxml.devices = vmxml.devices.append(grap)
        vmxml.define()

    @staticmethod
    def del_graphic(vm_name):
        """
        Del original graphic device

        :param vm_name: name of vm
        """
        vmxml = vm_xml.VMXML.new_from_dumpxml(vm_name)
        vmxml.xmltreefile.remove_by_xpath('/devices/graphics')
        vmxml.xmltreefile.write()
        vmxml.define()

########NEW FILE########
__FILENAME__ = hostdev
"""
hostdev device support class(es)

http://libvirt.org/formatdomain.html#elementsHostDev
"""

from virttest.libvirt_xml.devices import base
from virttest.libvirt_xml import accessors


class Hostdev(base.TypedDeviceBase):

    __slots__ = ('mode', 'type', 'source_address', 'managed')

    def __init__(self, type_name="hostdev", virsh_instance=base.base.virsh):
        accessors.XMLAttribute('type', self, parent_xpath='/',
                               tag_name='hostdev', attribute='type')
        accessors.XMLAttribute('mode', self, parent_xpath='/',
                               tag_name='hostdev', attribute='mode')
        accessors.XMLAttribute('managed', self, parent_xpath='/',
                               tag_name='hostdev', attribute='managed')
        accessors.XMLElementDict('source_address', self, parent_xpath='/source',
                                 tag_name='address')
        super(self.__class__, self).__init__(device_tag='hostdev',
                                             type_name=type_name,
                                             virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = hub
"""
hub device support class(es)

http://libvirt.org/formatdomain.html#elementsHub
"""

from virttest.libvirt_xml.devices import base


class Hub(base.TypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'hub'
    _def_type_name = 'usb'

########NEW FILE########
__FILENAME__ = input
"""
input device support class(es)

http://libvirt.org/formatdomain.html#elementsInput
"""

from virttest.libvirt_xml.devices import base


class Input(base.TypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'input'
    _def_type_name = 'mouse'

########NEW FILE########
__FILENAME__ = interface
"""
interface device support class(es)

http://libvirt.org/formatdomain.html#elementsNICS
"""

from virttest.libvirt_xml import accessors
from virttest.libvirt_xml.devices import base


class Interface(base.TypedDeviceBase):

    __slots__ = ('source', 'mac_address', 'bandwidth_inbound',
                 'bandwidth_outbound', 'portgroup', 'model')

    def __init__(self, type_name, virsh_instance=base.base.virsh):
        super(Interface, self).__init__(device_tag='interface',
                                        type_name=type_name,
                                        virsh_instance=virsh_instance)
        accessors.XMLElementDict(property_name="source",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/',
                                 tag_name='source')
        accessors.XMLAttribute(property_name="mac_address",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/',
                               tag_name='mac',
                               attribute='address')
        accessors.XMLElementDict(property_name="bandwidth_inbound",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/bandwidth',
                                 tag_name='inbound')
        accessors.XMLElementDict(property_name="bandwidth_outbound",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/bandwidth',
                                 tag_name='outbound')
        accessors.XMLAttribute(property_name="portgroup",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/',
                               tag_name='source',
                               attribute='portgroup')
        accessors.XMLAttribute(property_name="model",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/',
                               tag_name='model',
                               attribute='type')

########NEW FILE########
__FILENAME__ = lease
"""
lease device support class(es)

http://libvirt.org/formatdomain.html#elementsLease
"""

from virttest.libvirt_xml.devices import base


class Lease(base.UntypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'lease'

########NEW FILE########
__FILENAME__ = librarian
"""
Module to hide underlying device xml handler class implementation
"""

import os
from virttest.libvirt_xml import base

# Avoid accidental names like __init__, librarian, and/or other support modules
DEVICE_TYPES = ['disk', 'filesystem', 'controller', 'lease',
                'hostdev', 'redirdev', 'smartcard', 'interface', 'input',
                'hub', 'graphics', 'video', 'parallel', 'serial', 'console',
                'channel', 'sound', 'watchdog', 'memballoon', 'rng',
                'seclabel', 'address', 'emulator']


def get(name):
    """
    Returns named device xml element's handler class

    :param name: the device name
    :return: the named device xml element's handler class
    """
    mod_path = os.path.abspath(os.path.dirname(__file__))
    handler_cl = base.load_xml_module(mod_path, name, DEVICE_TYPES)
    return handler_cl

########NEW FILE########
__FILENAME__ = memballoon
"""
memballoon device support class(es)

http://libvirt.org/formatdomain.html#elementsMemBalloon
"""

from virttest.libvirt_xml.devices import base


class Memballoon(base.UntypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'memballoon'

########NEW FILE########
__FILENAME__ = parallel
"""
Parallel device support class(es)

http://libvirt.org/formatdomain.html#elementCharSerial
"""

from virttest.libvirt_xml import base
from virttest.libvirt_xml.devices.character import CharacterBase


class Parallel(CharacterBase):

    __slots__ = []

    def __init__(self, type_name='pty', virsh_instance=base.virsh):
        super(Parallel, self).__init__(device_tag='parallel',
                                       type_name=type_name,
                                       virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = redirdev
"""
redirdev device support class(es)

http://libvirt.org/formatdomain.html#elementsRedir
"""

from virttest.libvirt_xml.devices import base


class Redirdev(base.TypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'redirdev'
    _def_type_name = 'spicevmc'

########NEW FILE########
__FILENAME__ = rng
"""
random number generator device support class(es)

http://libvirt.org/formatdomain.html#elementsRng
"""

from virttest.libvirt_xml.devices import base


class Rng(base.UntypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'rng'

########NEW FILE########
__FILENAME__ = seclabel
"""
seclabel device support class(es)

http://libvirt.org/formatdomain.html#seclabel
"""

from virttest.libvirt_xml.devices import base


class Seclabel(base.TypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'seclabel'
    _def_type_name = 'static'

########NEW FILE########
__FILENAME__ = serial
"""
Classes to support XML for serial devices

http://libvirt.org/formatdomain.html#elementCharSerial
"""

from virttest.libvirt_xml import base, accessors
from virttest.libvirt_xml.devices.character import CharacterBase


class Serial(CharacterBase):

    __slots__ = ('protocol_type',)

    def __init__(self, type_name='pty', virsh_instance=base.virsh):
        # Additional attribute for protocol type (raw, telnet, telnets, tls)
        accessors.XMLAttribute('protocol_type', self, parent_xpath='/',
                               tag_name='protocol', attribute='type')
        super(Serial, self).__init__(device_tag='serial', type_name=type_name,
                                     virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = smartcard
"""
smartcard device support class(es)

http://libvirt.org/formatdomain.html#elementsSmartcard
"""

from virttest.libvirt_xml.devices import base


class Smartcard(base.UntypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'smartcard'

########NEW FILE########
__FILENAME__ = sound
"""
sound device support class(es)

http://libvirt.org/formatdomain.html#elementsSound
"""

from virttest.libvirt_xml.devices import base


class Sound(base.UntypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'sound'

########NEW FILE########
__FILENAME__ = video
"""
video device support class(es)

http://libvirt.org/formatdomain.html#elementsVideo
"""

from virttest.libvirt_xml import accessors
from virttest.libvirt_xml.devices import base


class Video(base.TypedDeviceBase):

    __slots__ = ('model_type', 'model_ram', 'model_vram', 'model_heads',
                 'primary', 'acceleration', 'address')

    def __init__(self, type_name, virsh_instance=base.base.virsh):
        accessors.XMLAttribute('model_type', self,
                               parent_xpath='/',
                               tag_name='model',
                               attribute='type')
        accessors.XMLAttribute('model_ram', self,
                               parent_xpath='/',
                               tag_name='model',
                               attribute='ram')
        accessors.XMLAttribute('model_vram', self,
                               parent_xpath='/',
                               tag_name='model',
                               attribute='vram')
        accessors.XMLAttribute('model_heads', self,
                               parent_xpath='/',
                               tag_name='model',
                               attribute='heads')
        accessors.XMLAttribute('primary', self,
                               parent_xpath='/',
                               tag_name='model',
                               attribute='primary')
        accessors.XMLElementDict('acceleration', self,
                                 parent_xpath='/model',
                                 tag_name='acceleration')
        accessors.XMLElementDict('address', self,
                                 parent_xpath='/',
                                 tag_name='address')
        super(Video, self).__init__(device_tag='video',
                                    type_name=type_name,
                                    virsh_instance=virsh_instance)

########NEW FILE########
__FILENAME__ = watchdog
"""
watchdog device support class(es)

http://libvirt.org/formatdomain.html#elementsWatchdog
"""

from virttest.libvirt_xml.devices import base


class Watchdog(base.UntypedDeviceBase):
    # TODO: Write this class
    __metaclass__ = base.StubDeviceMeta
    _device_tag = 'watchdog'

########NEW FILE########
__FILENAME__ = network_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatnetwork.html
"""

import logging
from virttest import xml_utils
from virttest.libvirt_xml import base, xcepts, accessors


class RangeList(list):

    """
    A list of start & end address tuples
    """

    def __init__(self, iterable=None):
        """
        Initialize from list/tuple of two-item tuple start/end address strings
        """
        x_str = "iterable must contain two-item tuples of start/end addresses"
        newone = []
        for item in iterable:
            if not issubclass(type(item), tuple):
                raise xcepts.LibvirtXMLError(x_str)
            if len(item) is not 2:
                raise xcepts.LibvirtXMLError(x_str)
            # Assume strings will be validated elsewhere
            newone.append(tuple(item))
        super(RangeList, self).__init__(newone)

    def append_to_element(self, element):
        """
        Adds range described by instance to ElementTree.element
        """
        if not issubclass(type(element), xml_utils.ElementTree.Element):
            raise ValueError(
                "Element is not a ElementTree.Element or subclass")
        for start, end in self:
            serange = {'start': start, 'end': end}
            element.append(xml_utils.ElementTree.Element('range', serange))


class IPXML(base.LibvirtXMLBase):

    """
    IP address block, optionally containing DHCP range information

    Properties:
        dhcp_ranges: RangeList instances (list-like)
        address: string IP address
        netmask: string IP's netmask
    """

    __slots__ = ('dhcp_ranges', 'address', 'netmask')

    def __init__(self, address='192.168.122.1', netmask='255.255.255.0',
                 virsh_instance=base.virsh):
        """
        Create new IPXML instance based on address/mask
        """
        accessors.XMLAttribute(
            'address', self, parent_xpath='/', tag_name='ip',
            attribute='address')
        accessors.XMLAttribute(
            'netmask', self, parent_xpath='/', tag_name='ip',
            attribute='netmask')
        super(IPXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<ip address='%s' netmask='%s'></ip>" % (address, netmask)

    def get_dhcp_ranges(self):
        """
        Returns all XML described DHCP ranges as a RangeList object
        """
        xmltreefile = self.__dict_get__('xml')
        newlist = []
        for element in xmltreefile.findall('/ip/dhcp/range'):
            start = element.get('start')  # attribute of range tag
            end = element.get('end')
            newlist.append((start, end, ))
        return RangeList(newlist)

    def set_dhcp_ranges(self, value):
        """
        Sets XML described DHCP ranges from a RangeList object
        """
        if not issubclass(type(value), RangeList) or value is not None:
            raise xcepts.LibvirtXMLError("Value is not a RangeList or subclassa"
                                         " instance.")
        # Always start from clean-slate
        self.del_dhcp_ranges()
        if value is None:
            return  # ip element has no dhcp block
        xmltreefile = self.__dict_get__('xml')
        dhcp = xml_utils.ElementTree.Element('dhcp')
        ip_elem = xmltreefile.find('/ip')
        if ip_elem is None:
            raise xcepts.LibvirtXMLError("Network contains no IP element")
        ip_elem.append(dhcp)
        value.append_to_element(dhcp)
        xmltreefile.write()

    def del_dhcp_ranges(self):
        """
        Removes all DHCP ranges from XML
        """
        xmltreefile = self.__dict_get__('xml')
        element = xmltreefile.find('/dhcp')
        if element is not None:
            xmltreefile.remove(element)


class PortgroupXML(base.LibvirtXMLBase):

    """
    Accessor methods for PortgroupXML class in NetworkXML.

    Properties:
        name:
            string, operates on 'name' attribute of portgroup tag
        default:
            string of yes or no, operates on 'default' attribute of
            portgroup tag
        virtualport_type:
            string, operates on 'type' attribute of virtualport tag in
            portgroup.
        bandwidth_inbound:
            dict, operates on inbound tag in bandwidth which is child
            of portgroup.
        bandwidth_outbound:
            dict, operates on outbound tag in bandwidth which is child
            of portgroup.
    """

    __slots__ = ('name', 'default', 'virtualport_type',
                 'bandwidth_inbound', 'bandwidth_outbound')

    def __init__(self, virsh_instance=base.virsh):
        """
        Create new PortgroupXML instance.
        """
        accessors.XMLAttribute('name', self, parent_xpath='/',
                               tag_name='portgroup', attribute='name')
        accessors.XMLAttribute('default', self, parent_xpath='/',
                               tag_name='portgroup', attribute='default')
        accessors.XMLAttribute('virtualport_type', self, parent_xpath='/',
                               tag_name='virtualport', attribute='type')
        accessors.XMLElementDict('bandwidth_inbound', self,
                                 parent_xpath='/bandwidth',
                                 tag_name='inbound')
        accessors.XMLElementDict('bandwidth_outbound', self,
                                 parent_xpath='/bandwidth',
                                 tag_name='outbound')
        super(PortgroupXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<portgroup></portgroup>"


class NetworkXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for NetworkXML class.

    Properties:
        name:
            string, operates on XML name tag
        uuid:
            string, operates on uuid tag
        fwd_mode:
            string, operates on mode attribute of forward tag
        mac:
            string, operates on address attribute of mac tag
        ip:
            string operate on ip/dhcp ranges as IPXML instances
        bridge:
            dict, operates on bridge attributes
        bandwidth_inbound:
            dict, operates on inbound under bandwidth.
        bandwidth_outbound:
            dict, operates on outbound under bandwidth.
        portgroup:
            PortgroupXML instance to access portgroup tag.

        defined:
            virtual boolean, callout to virsh methods
        get:
            True if libvirt knows network name
        set:
            True defines network, False undefines to libvirt
        del:
            Undefines network to libvirt

        active:
            virtual boolean, callout to virsh methods
        get:
            True if network is active to libvirt
        set:
            True activates network, False deactivates to libvirt
        del:
            Deactivates network to libvirt

        autostart:
            virtual boolean, callout to virsh methods
        get:
            True if libvirt autostarts network with same name
        set:
            True to set autostart, False to unset to libvirt
        del:
            Unset autostart to libvirt

        persistent:
            virtual boolean, callout to virsh methods
        get:
            True if network was defined, False if only created.
        set:
            Same as defined property
        del:
            Same as defined property
    """

    __slots__ = ('name', 'uuid', 'bridge', 'defined', 'active',
                 'autostart', 'persistent', 'fwd_mode', 'mac', 'ip',
                 'bandwidth_inbound', 'bandwidth_outbound', 'portgroup')

    __uncompareable__ = base.LibvirtXMLBase.__uncompareable__ + (
        'defined', 'active',
        'autostart', 'persistent')

    __schema_name__ = "network"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementText('name', self, parent_xpath='/',
                                 tag_name='name')
        accessors.XMLElementText('uuid', self, parent_xpath='/',
                                 tag_name='uuid')
        accessors.XMLAttribute('fwd_mode', self, parent_xpath='/',
                               tag_name='forward', attribute='mode')
        accessors.XMLAttribute('mac', self, parent_xpath='/',
                               tag_name='mac', attribute='address')
        accessors.XMLElementDict('bridge', self, parent_xpath='/',
                                 tag_name='bridge')
        accessors.XMLElementDict('bandwidth_inbound', self,
                                 parent_xpath='/bandwidth',
                                 tag_name='inbound')
        accessors.XMLElementDict('bandwidth_outbound', self,
                                 parent_xpath='/bandwidth',
                                 tag_name='outbound')
        super(NetworkXMLBase, self).__init__(virsh_instance=virsh_instance)

    def __check_undefined__(self, errmsg):
        if not self.defined:
            raise xcepts.LibvirtXMLError(errmsg)

    def get_defined(self):
        """
        Accessor for 'define' property - does this name exist in network list
        """
        params = {'only_names': True, 'virsh_instance': self.virsh}
        return self.name in self.virsh.net_state_dict(**params)

    def set_defined(self, value):
        """Accessor method for 'define' property, set True to define."""
        if not self.__super_get__('INITIALIZED'):
            pass  # do nothing
        value = bool(value)
        if value:
            self.virsh.net_define(self.xml)  # send it the filename
        else:
            del self.defined

    def del_defined(self):
        """Accessor method for 'define' property, undefines network"""
        self.__check_undefined__("Cannot undefine non-existant network")
        self.virsh.net_undefine(self.name)

    def get_active(self):
        """Accessor method for 'active' property (True/False)"""
        self.__check_undefined__("Cannot determine activation for undefined "
                                 "network")
        state_dict = self.virsh.net_state_dict(virsh_instance=self.virsh)
        return state_dict[self.name]['active']

    def set_active(self, value):
        """Accessor method for 'active' property, sets network active"""
        if not self.__super_get__('INITIALIZED'):
            pass  # do nothing
        self.__check_undefined__("Cannot activate undefined network")
        value = bool(value)
        if value:
            if not self.active:
                self.virsh.net_start(self.name)
            else:
                pass  # don't activate twice
        else:
            if self.active:
                del self.active
            else:
                pass  # don't deactivate twice

    def del_active(self):
        """Accessor method for 'active' property, stops network"""
        self.__check_undefined__("Cannot deactivate undefined network")
        if self.active:
            self.virsh.net_destroy(self.name)
        else:
            pass  # don't destroy twice

    def get_autostart(self):
        """Accessor method for 'autostart' property, True if set"""
        self.__check_undefined__("Cannot determine autostart for undefined "
                                 "network")
        state_dict = self.virsh.net_state_dict(virsh_instance=self.virsh)
        return state_dict[self.name]['autostart']

    def set_autostart(self, value):
        """Accessor method for 'autostart' property, sets/unsets autostart"""
        if not self.__super_get__('INITIALIZED'):
            pass  # do nothing
        self.__check_undefined__("Cannot set autostart for undefined network")
        value = bool(value)
        if value:
            if not self.autostart:
                self.virsh.net_autostart(self.name)
            else:
                pass  # don't set autostart twice
        else:
            if self.autostart:
                del self.autostart
            else:
                pass  # don't unset autostart twice

    def del_autostart(self):
        """Accessor method for 'autostart' property, unsets autostart"""
        if not self.defined:
            raise xcepts.LibvirtXMLError("Can't autostart nonexistant network")
        self.virsh.net_autostart(self.name, "--disable")

    def get_persistent(self):
        """Accessor method for 'persistent' property"""
        state_dict = self.virsh.net_state_dict(virsh_instance=self.virsh)
        return state_dict[self.name]['persistent']

    # Copy behavior for consistency
    set_persistent = set_defined
    del_persistent = del_defined

    def get_ip(self):
        xmltreefile = self.__dict_get__('xml')
        try:
            ip_root = xmltreefile.reroot('/ip')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        ipxml = IPXML(virsh_instance=self.__dict_get__('virsh'))
        ipxml.xmltreefile = ip_root
        return ipxml

    def set_ip(self, value):
        if not issubclass(type(value), IPXML):
            raise xcepts.LibvirtXMLError("value must be a IPXML or subclass")
        xmltreefile = self.__dict_get__('xml')
        # nuke any existing IP block
        self.del_ip()
        # IPXML root element is whole IP element tree
        root = xmltreefile.getroot()
        root.append(value.xmltreefile.getroot())
        xmltreefile.write()

    def del_ip(self):
        xmltreefile = self.__dict_get__('xml')
        element = xmltreefile.find('/ip')
        if element is not None:
            xmltreefile.remove(element)
            xmltreefile.write()

    def get_portgroup(self):
        try:
            portgroup_root = self.xmltreefile.reroot('/portgroup')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        portgroup_xml = PortgroupXML(virsh_instance=self.__dict_get__('virsh'))
        portgroup_xml.xmltreefile = portgroup_root
        return portgroup_xml

    def set_portgroup(self, value):
        if not issubclass(type(value), PortgroupXML):
            raise xcepts.LibvirtXMLError("value must be a PortgroupXML"
                                         "instance or subclass.")
        self.del_portgroup()
        root = self.xmltreefile.getroot()
        root.append(value.xmltreefile.getroot())
        self.xmltreefile.write()

    def del_portgroup(self):
        element = self.xmltreefile.find("/portgroup")
        if element is not None:
            self.xmltreefile.remove(element)
            self.xmltreefile.write()


class NetworkXML(NetworkXMLBase):

    """
    Manipulators of a Virtual Network through it's XML definition.
    """

    __slots__ = []

    def __init__(self, network_name='default', virsh_instance=base.virsh):
        """
        Initialize new instance with empty XML
        """
        super(NetworkXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<network><name>%s</name></network>" % network_name

    @staticmethod  # wraps __new__
    def new_all_networks_dict(virsh_instance=base.virsh):
        """
        Return a dictionary of names to NetworkXML instances for all networks

        :param virsh: virsh module or instance to use
        :return: Dictionary of network name to NetworkXML instance
        """
        result = {}
        # Values should all share virsh property
        new_netxml = NetworkXML(virsh_instance=virsh_instance)
        params = {'only_names': True, 'virsh_instance': virsh_instance}
        networks = new_netxml.virsh.net_state_dict(**params).keys()
        for net_name in networks:
            new_copy = new_netxml.copy()
            new_copy.xml = virsh_instance.net_dumpxml(net_name).stdout.strip()
            result[net_name] = new_copy
        return result

    @staticmethod
    def new_from_net_dumpxml(network_name, virsh_instance=base.virsh):
        """
        Return new NetworkXML instance from virsh net-dumpxml command

        :param network_name: Name of network to net-dumpxml
        :param virsh_instance: virsh module or instance to use
        :return: New initialized NetworkXML instance
        """
        netxml = NetworkXML(virsh_instance=virsh_instance)
        netxml['xml'] = virsh_instance.net_dumpxml(network_name).stdout.strip()
        return netxml

    @staticmethod
    def get_uuid_by_name(network_name, virsh_instance=base.virsh):
        """
        Return Network's uuid by Network's name.

        :param network_name: Network's name
        :return: Network's uuid
        """
        network_xml = NetworkXML.new_from_net_dumpxml(network_name,
                                                      virsh_instance)
        return network_xml.uuid

    def debug_xml(self):
        """
        Dump contents of XML file for debugging
        """
        xml = str(self)  # LibvirtXMLBase.__str__ returns XML content
        for debug_line in str(xml).splitlines():
            logging.debug("Network XML: %s", debug_line)

    def state_dict(self):
        """
        Return a dict containing states of active/autostart/persistent

        :return: A dict contains active/autostart/persistent as keys
                 and boolean as values or None if network doesn't exist.
        """
        if self.defined:
            return self.virsh.net_state_dict(virsh_instance=self.virsh)[self.name]

    def create(self):
        """
        Adds non-persistant / transient network to libvirt with net-create
        """
        self.virsh.net_create(self.xml)

    def orbital_nuclear_strike(self):
        """It's the only way to really be sure.  Remove all libvirt state"""
        try:
            self['active'] = False  # deactivate (stop) network if active
        except xcepts.LibvirtXMLError, detail:
            # inconsequential, network will be removed
            logging.warning(detail)
        try:
            self['defined'] = False  # undefine (delete) network if persistent
        except xcepts.LibvirtXMLError, detail:
            # network already gone
            logging.warning(detail)

    def exists(self):
        """
        Return True if network already exists.
        """
        cmd_result = self.virsh.net_uuid(self.name)
        return (cmd_result.exit_status == 0)

    def undefine(self):
        """
        Undefine network witch name is self.name.
        """
        self.virsh.net_destroy(self.name)
        cmd_result = self.virsh.net_undefine(self.name)
        if cmd_result.exit_status:
            raise xcepts.LibvirtXMLError("Failed to undefine network %s.\n"
                                         "Detail: %s" %
                                         (self.name, cmd_result.stderr))

    def define(self):
        """
        Define network from self.xml.
        """
        cmd_result = self.virsh.net_define(self.xml)
        if cmd_result.exit_status:
            raise xcepts.LibvirtXMLError("Failed to define network %s.\n"
                                         "Detail: %s" %
                                         (self.name, cmd_result.stderr))

    def start(self):
        """
        Start network with self.virsh.
        """
        cmd_result = self.virsh.net_start(self.name)
        if cmd_result.exit_status:
            raise xcepts.LibvirtXMLError("Failed to start network %s.\n"
                                         "Detail: %s" %
                                         (self.name, cmd_result.stderr))

    def sync(self, state=None):
        """
        Make the change of "self" take effect on network.
        Recover network to designated state if option state is set.

        :param state: a boolean dict contains active/persistent/autostart as
                      keys
        """
        if self['defined']:
            if self['active']:
                del self['active']
            if self['defined']:
                del self['defined']

        self['defined'] = True
        if state:
            self['active'] = state['active']
            if not state['persistent']:
                del self['persistent']
            if self.defined:
                self['autostart'] = state['autostart']
        else:
            self['active'] = True
            self['autostart'] = True

########NEW FILE########
__FILENAME__ = nodedev_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatnode.html
"""

import os
from virttest.libvirt_xml import base, xcepts, accessors


class CAPXML(base.LibvirtXMLBase):

    """
    The base class for capability.
    """

    def get_sysfs_sub_path(self):
        """
        return the sub path store the info of capibility.
        """
        raise NotImplementedError('get_sysfs_sub_path is not implemented.')

    @staticmethod
    def get_key2filename_dict():
        """
        Return a dict which contain the key and the name
        of info file.
        """
        raise NotImplementedError('get_key2filename_dict is not implemeneted.')

    def get_key2value_dict(self):
        """
        Reutn a dict which contain the key and the value
        in capability xml.
        """
        raise NotImplementedError('get_key2value_dict is not implemented.')


class SystemXML(CAPXML):

    """
    class for capability which type is system.
    """
    __slots__ = ('product', 'hdware_vendor', 'hdware_serial', 'hdware_uuid',
                 'firmware_vendor', 'firmversion', 'firm_release_date')

    __sysfs_sub_path__ = 'dmi/id/'

    __key2filename_dict__ = {'product': 'product_name',
                             'hdware_vendor': 'sys_vendor',
                             'hdware_serial': 'product_serial',
                             'hdware_uuid': 'product_uuid',
                             'firmware_vendor': 'bios_vendor',
                             'firmversion': 'bios_version',
                             'firm_release_date': 'bios_date'}

    @staticmethod
    def get_key2filename_dict():
        """
        Return a dict which contain the key and the name
        of info file for System node device.
        """
        return SystemXML.__key2filename_dict__

    def get_key2value_dict(self):
        """
        return the dict key2value

        key: the key in xml need to check.
        value: value in xml for this key.
        """
        key2value_dict = {}
        for key in SystemXML.__key2filename_dict__:
            key2value_dict[key] = self[key]

        return key2value_dict

    @staticmethod
    def make_sysfs_sub_path():
        """
        return __sysfs_sub_path__ immediately.
        """
        return SystemXML.__sysfs_sub_path__

    def get_sysfs_sub_path(self):
        """
        Return the sysfs_subdir.
        """
        return self.make_sysfs_sub_path()


class NetXML(CAPXML):

    """
    class for capability whose type is net.
    """
    __slots__ = ('interface', 'address')

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementText('interface', self, parent_xpath='/',
                                 tag_name='interface')
        accessors.XMLElementText('address', self, parent_xpath='/',
                                 tag_name='address')


class StorageXML(CAPXML):

    """
    class for capability whose type is storage.
    """
    __slots__ = ('block', 'bus', 'driver_type')

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementText('block', self, parent_xpath='/',
                                 tag_name='block')
        accessors.XMLElementText('bus', self, parent_xpath='/',
                                 tag_name='bus')
        accessors.XMLElementText('driver_type', self, parent_xpath='/',
                                 tag_name='driver_type')


class PCIXML(CAPXML):

    """
    class for capability whose type is pci.
    """
    __slots__ = ('domain', 'bus', 'slot', 'function', 'product_id',
                 'vendor_id')

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementInt('domain', self, parent_xpath='/',
                                tag_name='domain')
        accessors.XMLElementInt('bus', self, parent_xpath='/',
                                tag_name='bus')
        accessors.XMLElementInt('slot', self, parent_xpath='/',
                                tag_name='slot')
        accessors.XMLElementInt('function', self, parent_xpath='/',
                                tag_name='function')
        accessors.XMLAttribute('product_id', self, parent_xpath='/',
                               tag_name='product', attribute='id')
        accessors.XMLAttribute('vendor_id', self, parent_xpath='/',
                               tag_name='vendor', attribute='id')
        super(PCIXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = (' <capability type=\'pci\'></capability>')

    @staticmethod
    def make_sysfs_sub_path(domain, bus, slot, function):
        """
        Make sysfs_sub_path for pci by domain,bus,slot and function.
        """
        pci_bus_path = ("%04x:%02x" % (domain, bus))
        pci_device_path = ("%04x:%02x:%02x.%01x" % (domain, bus,
                                                    slot, function))
        pci_sysfs_sub_path = ("pci_bus/%s/device/%s"
                              % (pci_bus_path, pci_device_path))

        return pci_sysfs_sub_path

    def get_sysfs_sub_path(self):
        """
        Return the sysfs_subdir in .

        Example:
            pci_bus/0000\:00/device/0000\:00\:00.0/
        """
        domain = self.domain
        bus = self.bus
        slot = self.slot
        function = self.function

        return PCIXML.make_sysfs_sub_path(domain, bus, slot, function)

    __key2filename_dict__ = {'product_id': 'device',
                             'vendor_id': 'vendor'}

    @staticmethod
    def get_key2filename_dict():
        """
        return the dict key2filename.
        key: the keys in pcixml need to check.
        filename: the name of file stored info for this key.
        """
        return PCIXML.__key2filename_dict__

    def get_key2value_dict(self):
        """
        return the dict key2value

        key: the key in xml need to check.
        value: value in xml for this key.
        """
        key2value_dict = {}
        for key in PCIXML.__key2filename_dict__:
            key2value_dict[key] = self[key]

        return key2value_dict

    def get_address_dict(self):
        """
        Return a dict contain the address.
        """
        address = {'domain': self.domain, 'bus': self.bus,
                   'slot': self.slot, 'function': self.function}
        return address


class NodedevXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for NodedevXML class.

    """

    __slots__ = ('name', 'parent', 'cap_type', 'cap',
                 'sysfs_main_path', 'host', 'fc_type',
                 'wwnn', 'wwpn', 'fabric_wwn')

    __schema_name__ = "nodedev"

    __sysfs_dir__ = "/sys/class"

    __type2class_dict__ = {'system': 'SystemXML',
                           'pci': 'PCIXML',
                           'usb_device': 'USBDeviceXML',
                           'usb': 'USBXML',
                           'net': 'NetXML',
                           'scsi_host': 'SCSIHostXML',
                           'scsi': 'SCSIXML',
                           'storage': 'StorageXML'}

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementText('name', self, parent_xpath='/',
                                 tag_name='name')
        accessors.XMLElementText('parent', self, parent_xpath='/',
                                 tag_name='parent')
        accessors.XMLAttribute('cap_type', self, parent_xpath='/',
                               tag_name='capability', attribute='type')
        accessors.XMLElementText('host', self, parent_xpath='/capability',
                                 tag_name='host')
        accessors.XMLAttribute('fc_type', self, parent_xpath='/capability',
                               tag_name='capability', attribute='type')
        accessors.XMLElementText('wwnn', self,
                                 parent_xpath='/capability/capability',
                                 tag_name='wwnn')
        accessors.XMLElementText('wwpn', self,
                                 parent_xpath='/capability/capability',
                                 tag_name='wwpn')
        accessors.XMLElementText('fabric_wwn', self,
                                 parent_xpath='/capability/capability',
                                 tag_name='fabric_wwn')
        super(NodedevXMLBase, self).__init__(virsh_instance=virsh_instance)
        self.xml = '<device></device>'

    @staticmethod
    def get_cap_by_type(cap_type):
        """
        Init a cap class for a specific type.

        :param cap_type: the type of capability.
        :return: instanse of the cap.
        """
        cap_class_name = NodedevXMLBase.__type2class_dict__[cap_type]
        cap_class = globals()[cap_class_name]
        capxml = cap_class()

        return capxml

    def get_cap(self):
        """
        Return the capability of nodedev_xml.
        """
        try:
            cap_root = self.xmltreefile.reroot('/capability')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        capxml = NodedevXMLBase.get_cap_by_type(self.cap_type)
        capxml.xmltreefile = cap_root
        return capxml

    def set_cap(self, value):
        """
        Set the capability by value.
        """
        if not issubclass(type(value), CAPXML):
            raise xcepts.LibvirtXMLError("value must be a CAPXML or subclass")
        # remove any existing capability block
        self.del_cap()
        root = self.xmltreefile.getroot()
        root.append(value.getroot())
        self.xmltreefile.write()

    def del_cap(self):
        """
        Delete the capability from nodedev xml.
        """
        element = self.xmltreefile.find('/capability')
        if element is not None:
            self.mltreefile.remove(element)
        self.xmltreefile.write()

    def get_sysfs_sub_path(self):
        """
        Get the sub sysfs path of the capability.
        """
        capxml = self.cap
        sysfs_sub_path = capxml.get_sysfs_sub_path()

        return sysfs_sub_path

    def get_sysfs_path(self):
        """
        Get the abs path of the capability info.
        """
        sysfs_main_path = self.__sysfs_dir__
        sysfs_sub_path = self.get_sysfs_sub_path()

        sysfs_path = os.path.join(sysfs_main_path, sysfs_sub_path)
        return sysfs_path


class NodedevXML(NodedevXMLBase):

    """
    class for Node device XML.
    """

    __slots__ = []

    def __init__(self, virsh_instance=base.virsh):
        """
        Initialize new instance.
        """
        super(NodedevXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = ('<device></device>')

    @staticmethod
    def new_from_dumpxml(dev_name, virsh_instance=base.virsh):
        """
        Get a instance of NodedevXML by dumpxml dev_name.
        """
        nodedevxml = NodedevXML(virsh_instance=virsh_instance)
        dumpxml_result = virsh_instance.nodedev_dumpxml(dev_name)
        if dumpxml_result.exit_status:
            raise xcepts.LibvirtXMLError("Nodedev_dumpxml %s failed.\n"
                                         "Error: %s."
                                         % (dev_name, dumpxml_result.stderr))
        nodedevxml.xml = dumpxml_result.stdout

        return nodedevxml

    def get_key2value_dict(self):
        """
        Get the dict which contain key and value in xml.
        key: keys in nodedev xml need to check.
        value: value in xml for the key.
        """
        capxml = self.cap
        key2value_dict = capxml.get_key2value_dict()

        return key2value_dict

    def get_key2syspath_dict(self):
        """
        Get the dict which contains key and path.
        key: keys in nodedev xml need to check.
        syspath: the abs path for the file stores info for the key.
        """
        sysfs_path = self.get_sysfs_path()
        capxml = self.cap
        key2filename_dict = capxml.__class__.get_key2filename_dict()

        key2syspath_dict = {}
        for key in key2filename_dict:
            filename = key2filename_dict[key]
            abs_syspath = os.path.join(sysfs_path, filename)
            key2syspath_dict[key] = abs_syspath

        return key2syspath_dict

########NEW FILE########
__FILENAME__ = ah
"""
ah protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMisc
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Ah(base.TypedDeviceBase):

    """
    Create new Ah xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Ah.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='ah', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Ah, self).__init__(protocol_tag='ah', type_name=type_name,
                                 virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return ah attribute dict

        :return: None if no ah in xml, dict of ah's attributes.
        """
        try:
            ah_node = self.xmltreefile.reroot('/ah')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = ah_node.getroot()
        ah_attr = dict(node.items())

        return ah_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Ah attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='ah', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='ah', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='ah', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='ah', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='ah', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='ah', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='ah', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='ah', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='ah', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='ah', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='ah', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='ah', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='ah', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='ah', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='ah', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='ah', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='ah', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<ah/>'

########NEW FILE########
__FILENAME__ = ah_ipv6
"""
ah-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMiscv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Ah_ipv6(base.TypedDeviceBase):

    """
    Create new Ah_ipv6 xml instances


    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Ah_ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='ah_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Ah_ipv6, self).__init__(protocol_tag='ah-ipv6',
                                      type_name=type_name,
                                      virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return ah-ipv6 attribute dict

        :return: None if no ah-ipv6 in xml, dict of ah-ipv6's attributes.
        """
        try:
            ah_node = self.xmltreefile.reroot('/ah-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = ah_node.getroot()
        ah_attr = dict(node.items())

        return ah_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Ah_ipv6 attribute XML class


        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='ah-ipv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<ah-ipv6/>'

########NEW FILE########
__FILENAME__ = all
"""
all protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMisc
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class All(base.TypedDeviceBase):

    """
    Create new All xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.All.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='all', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(All, self).__init__(protocol_tag='all',
                                  type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return 'all' attribute dict

        :return: None if no 'all' in xml, dict of all's attributes.
        """
        try:
            all_node = self.xmltreefile.reroot('/all')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = all_node.getroot()
        all_attr = dict(node.items())

        return all_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        All attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='all', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='all', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='all', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='all', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='all', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='all', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='all', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='all', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='all', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='all', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='all', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='all', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='all', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='all', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='all', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='all', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='all', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<all/>'

########NEW FILE########
__FILENAME__ = all_ipv6
"""
all-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMiscv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class All_ipv6(base.TypedDeviceBase):

    """
    Create new All_ipv6 xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.All_ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='all_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(All_ipv6, self).__init__(protocol_tag='all-ipv6',
                                       type_name=type_name,
                                       virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return all-ipv6 attribute dict

        :return: None if no all-ipv6 in xml, dict of all-ipv6's attributes.
        """
        try:
            all_node = self.xmltreefile.reroot('/all-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = all_node.getroot()
        all_attr = dict(node.items())

        return all_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        All_ipv6 attribute XML class


        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='all-ipv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<all-ipv6/>'

########NEW FILE########
__FILENAME__ = arp
"""
arp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoARP
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Arp(base.TypedDeviceBase):

    """
    Create new Arp xml instances

    Properties:

    attrs: libvirt_xml.nwfilter_protocols.Arp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='arp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Arp, self).__init__(protocol_tag='arp', type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return arp attribute dict

        :return: None if no arp in xml, dict of arp's attributes.
        """
        try:
            arp_node = self.xmltreefile.reroot('/arp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = arp_node.getroot()
        arp_attr = dict(node.items())

        return arp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Arp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacaddr: string, Mask applied to MAC address of destination
        hwtype: string, Hardware type
        protocoltype: string, Protocol type
        opcode: string, Opcode
        arpsrcmacaddr: string, Source MAC address in ARP/RARP packet
        arpdstmacaddr: string, Destination MAC address in ARP/RARP packet
        arpsrcipaddr: string, Source IP address in ARP/RARP packet
        arpdstipaddr: string, Destination IP address in ARP/RARP packet
        comment: string, text with max. 256 characters
        gratuitous: string, boolean indicating whether to check for gratuitous ARP packet
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'hwtype', 'protocoltype', 'opcode', 'arpsrcmacaddr',
                     'arpdstmacaddr', 'arpsrcipaddr', 'arpdstipaddr',
                     'comment', 'gratuitous')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='arp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='arp', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='arp', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='arp', attribute='dstmacmask')
            accessors.XMLAttribute('hwtype', self, parent_xpath='/',
                                   tag_name='arp', attribute='hwtype')
            accessors.XMLAttribute('protocoltype', self, parent_xpath='/',
                                   tag_name='arp', attribute='protocoltype')
            accessors.XMLAttribute('opcode', self, parent_xpath='/',
                                   tag_name='arp', attribute='opcode')
            accessors.XMLAttribute('arpsrcmacaddr', self, parent_xpath='/',
                                   tag_name='arp', attribute='arpsrcmacaddr')
            accessors.XMLAttribute('arpdstmacaddr', self, parent_xpath='/',
                                   tag_name='arp', attribute='arpdstmacaddr')
            accessors.XMLAttribute('arpsrcipaddr', self, parent_xpath='/',
                                   tag_name='arp', attribute='arpsrcipaddr')
            accessors.XMLAttribute('arpdstipaddr', self, parent_xpath='/',
                                   tag_name='arp', attribute='arpdstipaddr')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='arp', attribute='comment')
            accessors.XMLAttribute('gratuitous', self, parent_xpath='/',
                                   tag_name='arp', attribute='gratuitous')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<arp/>'

########NEW FILE########
__FILENAME__ = base
"""
Common base classes for filter rule protocols
"""

import logging
from StringIO import StringIO
from virttest import xml_utils
from virttest.libvirt_xml import base, xcepts, accessors


class UntypedDeviceBase(base.LibvirtXMLBase):

    """
    Base class implementing common functions for all rule protocol XML w/o a
    type attr.
    """

    __slots__ = ('protocol_tag',)

    # Subclasses are expected to hide protocol_tag
    def __init__(self, protocol_tag, virsh_instance=base.virsh):
        """
        Initialize untyped filter rule instance's basic XML with protocol_tag
        """
        super(UntypedDeviceBase, self).__init__(virsh_instance=virsh_instance)
        # Just a regular dictionary value
        # (Using a property to change element tag won't work)
        self['protocol_tag'] = protocol_tag
        # setup bare-bones XML
        self.xml = u"<%s/>" % protocol_tag

    def from_element(self, element):
        """
        Stateful component to helper method for new_from_element.
        """
        class_name = self.__class__.__name__
        if element.tag != class_name.lower():
            raise xcepts.LibvirtXMLError('Refusing to create %s instance'
                                         'from %s tagged element'
                                         % (class_name, element.tag))
        # XMLTreeFile only supports element trees
        etree = xml_utils.ElementTree.ElementTree(element)
        # ET only writes to open file-like objects
        xmlstr = StringIO()
        # Need element tree string value to initialize LibvirtXMLBase.xml
        etree.write(xmlstr, xml_utils.ENCODING)
        # Create a new XMLTreeFile object based on string input
        self.xml = xmlstr.getvalue()

    @classmethod
    def new_from_element(cls, element, virsh_instance=base.virsh):
        """
        Create a new filter rule XML instance from an single ElementTree
        element
        """
        # subclasses __init__ only takes virsh_instance parameter
        instance = cls(virsh_instance=virsh_instance)
        instance.from_element(element)
        return instance

    @classmethod
    def new_from_dict(cls, properties, virsh_instance=base.virsh):
        """
        Create a new filter rule XML instance from a dict-like object
        """
        instance = cls(virsh_instance=virsh_instance)
        for key, value in properties.items():
            setattr(instance, key, value)
        return instance


class TypedDeviceBase(UntypedDeviceBase):

    """
    Base class implementing common functions for all filter rule XML w/o a
    type attr.
    """

    __slots__ = ('type_name',)

    # Subclasses are expected to hide protocol_tag
    def __init__(self, protocol_tag, type_name, virsh_instance=base.virsh):
        """
        Initialize Typed filter rule protocol instance's basic XML with
        type_name & protocol_tag
        """
        # generate getter, setter, deleter for 'type_name' property
        accessors.XMLAttribute('type_name', self,
                               # each rule protocol is it's own XML "document"
                               # because python 2.6 ElementPath is broken
                               parent_xpath='/',
                               tag_name=protocol_tag,
                               attribute='type')
        super(TypedDeviceBase, self).__init__(protocol_tag=protocol_tag,
                                              virsh_instance=virsh_instance)
        # Calls accessor to modify xml
        self.type_name = type_name

    @classmethod
    def new_from_element(cls, element, virsh_instance=base.virsh):
        """
        Hides type_name from superclass new_from_element().
        """
        type_name = element.get('type', None)
        # subclasses must hide protocol_tag parameter
        instance = cls(type_name=type_name,
                       virsh_instance=virsh_instance)
        instance.from_element(element)
        return instance

########NEW FILE########
__FILENAME__ = esp
"""
esp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMisc
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Esp(base.TypedDeviceBase):

    """
    Create new Esp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Esp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='esp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Esp, self).__init__(protocol_tag='esp', type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return esp attribute dict

        :return: None if no esp in xml, dict of esp's attributes.
        """
        try:
            esp_node = self.xmltreefile.reroot('/esp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = esp_node.getroot()
        esp_attr = dict(node.items())

        return esp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Esp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='esp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='esp', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='esp', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='esp', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='esp', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='esp', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='esp', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='esp', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='esp', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='esp', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='esp', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='esp', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='esp', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='esp', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='esp', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='esp', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='esp', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<esp/>'

########NEW FILE########
__FILENAME__ = esp_ipv6
"""
esp-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMiscv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Esp_ipv6(base.TypedDeviceBase):

    """
    Create new Esp_ipv6 xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Esp_ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='esp_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Esp_ipv6, self).__init__(protocol_tag='esp-ipv6',
                                       type_name=type_name,
                                       virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return esp-ipv6 attribute dict

        :return: None if no esp-ipv6 in xml, dict of esp-ipv6's attributes.
        """
        try:
            esp_node = self.xmltreefile.reroot('/esp-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = esp_node.getroot()
        esp_attr = dict(node.items())

        return esp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Esp_ipv6 attribute XML class


        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='esp-ipv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<esp-ipv6/>'

########NEW FILE########
__FILENAME__ = icmp
"""
icmp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoICMP
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Icmp(base.TypedDeviceBase):

    """
    Create new Icmp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Icmp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='icmp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Icmp, self).__init__(protocol_tag='icmp', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return icmp attribute dict

        :return: None if no icmp in xml, dict of icmp's attributes.
        """
        try:
            icmp_node = self.xmltreefile.reroot('/icmp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = icmp_node.getroot()
        icmp_attr = dict(node.items())

        return icmp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Icmp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        type: string, ICMP type
        code: string, ICMP code
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'type', 'code', 'dscp', 'comment', 'state', 'ipset',
                     'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='icmp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='icmp', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='icmp', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='icmp', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='icmp', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='icmp', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dstipto')
            accessors.XMLAttribute('type', self, parent_xpath='/',
                                   tag_name='icmp', attribute='type')
            accessors.XMLAttribute('code', self, parent_xpath='/',
                                   tag_name='icmp', attribute='code')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='icmp', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='icmp', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='icmp', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='icmp', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='icmp', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<icmp/>'

########NEW FILE########
__FILENAME__ = icmpv6
"""
icmpv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoICMPv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Icmpv6(base.TypedDeviceBase):

    """
    Create new Icmpv6 xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Icmpv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='icmpv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Icmpv6, self).__init__(protocol_tag='icmpv6',
                                     type_name=type_name,
                                     virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return icmpv6 attribute dict

        :return: None if no icmpv6 in xml, dict of icmpv6's attributes.
        """
        icmpv6_node = self.xmltreefile.reroot('/icmpv6')
        node = icmpv6_node.getroot()
        icmpv6_attr = dict(node.items())

        return icmpv6_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Icmpv6 attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IPv6 address
        srcipmask: string, Mask applied to source IPv6 address
        dstipaddr: string, Destination IPv6 address
        dstipmask: string, Mask applied to destination IPv6 address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        type: string, ICMPv6 type
        code: string, ICMPv6 code
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'type', 'code', 'dscp', 'comment', 'state',
                     'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='dstipto')
            accessors.XMLAttribute('type', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='type')
            accessors.XMLAttribute('code', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='code')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='icmpv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<icmpv6/>'

########NEW FILE########
__FILENAME__ = igmp
"""
igmp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMisc
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Igmp(base.TypedDeviceBase):

    """
    Create new Igmp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Igmp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='igmp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Igmp, self).__init__(protocol_tag='igmp', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return igmp attribute dict

        :return: None if no igmp in xml, dict of igmp's attributes.
        """
        igmp_node = self.xmltreefile.reroot('/igmp')
        node = igmp_node.getroot()
        igmp_attr = dict(node.items())

        return igmp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Igmp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='igmp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='igmp', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='igmp', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='igmp', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='igmp', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='igmp', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='igmp', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='igmp', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='igmp', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='igmp', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='igmp', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<igmp/>'

########NEW FILE########
__FILENAME__ = ip
"""
ipv4 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoIP
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Ip(base.TypedDeviceBase):

    """
    Create new Ip xml instances

    Properties:

    attrs: libvirt_xml.nwfilter_protocols.Ip.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='ip', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Ip, self).__init__(protocol_tag='ip', type_name=type_name,
                                 virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return ip attribute dict

        :return: None if no ip in xml, dict of ip's attributes.
        """
        try:
            ip_node = self.xmltreefile.reroot('/ip')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = ip_node.getroot()
        ip_attr = dict(node.items())

        return ip_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Ip attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacaddr: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        ip_protocol: string, Layer 4 protocol identifier
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'ip_protocol', 'srcportstart', 'srcportend',
                     'dstportstart', 'dstportend', 'dscp', 'comment')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='ip', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='ip', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='ip', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='ip', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='ip', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='ip', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='ip', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='ip', attribute='dstipmask')
            accessors.XMLAttribute('ip_protocol', self, parent_xpath='/',
                                   tag_name='ip', attribute='protocol')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='ip', attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='ip', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='ip', attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='ip', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='ip', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='ip', attribute='comment')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<ip/>'

########NEW FILE########
__FILENAME__ = ipv6
"""
ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoIPv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Ipv6(base.TypedDeviceBase):

    """
    Create new Ipv6 xml instances

    Properties:

    attrs: libvirt_xml.nwfilter_protocols.Ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Ipv6, self).__init__(protocol_tag='ipv6', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return ipv6 attribute dict

        :return: None if no ipv6 in xml, dict of ipv6's attributes.
        """
        try:
            ipv6_node = self.xmltreefile.reroot('/ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = ipv6_node.getroot()
        ipv6_attr = dict(node.items())

        return ipv6_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Ipv6 attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacaddr: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        ip_protocol: string, Layer 4 protocol identifier
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'ip_protocol', 'srcportstart', 'srcportend',
                     'dstportstart', 'dstportend', 'dscp', 'comment')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='dstipmask')
            accessors.XMLAttribute('ip_protocol', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='protocol')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='dstportend')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='ipv6', attribute='comment')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<ipv6/>'

########NEW FILE########
__FILENAME__ = librarian
"""
Module to hide underlying filter protocol xml handler class implementation
"""

import os
from virttest.libvirt_xml import base

# Avoid accidental names like __init__, librarian, and/or other support modules
FILTER_TYPES = ['mac', 'vlan', 'stp', 'arp', 'rarp', 'ip', 'ipv6',
                'tcp', 'udp', 'sctp', 'icmp', 'igmp', 'esp', 'ah',
                'udplite', 'all', 'tcp_ipv6', 'udp_ipv6', 'sctp_ipv6',
                'icmpv6', 'esp_ipv6', 'ah_ipv6', 'udplite_ipv6', 'all_ipv6']


def get(name):
    """
    Returns named filter protocol xml element's handler class

    :param name: the filter protocol name
    :return: named filter protocol xml element's handler class
    """
    mod_path = os.path.abspath(os.path.dirname(__file__))
    handler_cl = base.load_xml_module(mod_path, name, FILTER_TYPES)
    return handler_cl

########NEW FILE########
__FILENAME__ = mac
"""
mac protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMAC
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Mac(base.TypedDeviceBase):

    """
    Create new Mac xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Mac.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='mac', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Mac, self).__init__(protocol_tag='mac', type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return mac attribute dict

        :return: None if no mac in xml, dict of mac's attributes.
        """
        try:
            mac_node = self.xmltreefile.reroot('/mac')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = mac_node.getroot()
        mac_attr = dict(node.items())

        return mac_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Mac attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacaddr: string, Mask applied to MAC address of destination
        protocolid: string, Layer 3 protocol ID
        comment: string, text with max. 256 characters
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'protocolid', 'comment')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='mac', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='mac', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='mac', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='mac', attribute='dstmacmask')
            accessors.XMLAttribute('protocolid', self, parent_xpath='/',
                                   tag_name='mac', attribute='protocolid')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='mac', attribute='comment')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<mac/>'

########NEW FILE########
__FILENAME__ = rarp
"""
rarp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoARP
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Rarp(base.TypedDeviceBase):

    """
    Create new Rarp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Rarp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='rarp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Rarp, self).__init__(protocol_tag='rarp', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return rarp attribute dict

        :return: None if no rarp in xml, dict of rarp's attributes.
        """
        try:
            rarp_node = self.xmltreefile.reroot('/rarp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = rarp_node.getroot()
        rarp_attr = dict(node.items())

        return rarp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Rarp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacaddr: string, Mask applied to MAC address of destination
        hwtype: string, Hardware type
        protocoltype: string, Protocol type
        opcode: string, Opcode
        arpsrcmacaddr: string, Source MAC address in ARP/RARP packet
        arpdstmacaddr: string, Destination MAC address in ARP/RARP packet
        arpsrcipaddr: string, Source IP address in ARP/RARP packet
        arpdstipaddr: string, Destination IP address in ARP/RARP packet
        comment: string, text with max. 256 characters
        gratuitous: string, boolean indicating whether to check for gratuitous ARP packet
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'hwtype', 'protocoltype', 'opcode', 'arpsrcmacaddr',
                     'arpdstmacaddr', 'arpsrcipaddr', 'arpdstipaddr',
                     'comment', 'gratuitous')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='rarp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='rarp', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='rarp', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='rarp', attribute='dstmacmask')
            accessors.XMLAttribute('hwtype', self, parent_xpath='/',
                                   tag_name='rarp', attribute='hwtype')
            accessors.XMLAttribute('protocoltype', self, parent_xpath='/',
                                   tag_name='rarp', attribute='protocoltype')
            accessors.XMLAttribute('opcode', self, parent_xpath='/',
                                   tag_name='rarp', attribute='opcode')
            accessors.XMLAttribute('arpsrcmacaddr', self, parent_xpath='/',
                                   tag_name='rarp', attribute='arpsrcmacaddr')
            accessors.XMLAttribute('arpdstmacaddr', self, parent_xpath='/',
                                   tag_name='rarp', attribute='arpdstmacaddr')
            accessors.XMLAttribute('arpsrcipaddr', self, parent_xpath='/',
                                   tag_name='rarp', attribute='arpsrcipaddr')
            accessors.XMLAttribute('arpdstipaddr', self, parent_xpath='/',
                                   tag_name='rarp', attribute='arpdstipaddr')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='rarp', attribute='comment')
            accessors.XMLAttribute('gratuitous', self, parent_xpath='/',
                                   tag_name='rarp', attribute='gratuitous')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<rarp/>'

########NEW FILE########
__FILENAME__ = sctp
"""
sctp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoTCP-ipv4
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Sctp(base.TypedDeviceBase):

    """
    Create new Sctp xml instances

    Properties:

    attrs: libvirt_xml.nwfilter_protocols.Sctp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='sctp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Sctp, self).__init__(protocol_tag='sctp', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return sctp attribute dict

        :return: None if no sctp in xml, dict of sctp's attributes.
        """
        try:
            sctp_node = self.xmltreefile.reroot('/sctp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = sctp_node.getroot()
        sctp_attr = dict(node.items())

        return sctp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Sctp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'srcportstart', 'srcportend', 'dstportstart',
                     'dstportend', 'dscp', 'comment', 'state', 'ipset',
                     'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dstipto')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='sctp', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='sctp', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='sctp', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='sctp', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='sctp', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='sctp', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<sctp/>'

########NEW FILE########
__FILENAME__ = sctp_ipv6
"""
sctp-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoTCP-ipv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Sctp_ipv6(base.TypedDeviceBase):

    """
    Create new Sctp_ipv6 xml instances

    Properties:

    attrs: libvirt_xml.nwfilter_protocols.Sctp_ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='sctp_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Sctp_ipv6, self).__init__(protocol_tag='sctp-ipv6',
                                        type_name=type_name,
                                        virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return sctp-ipv6 attribute dict

        :return: None if no sctp-ipv6 in xml, dict of sctp-ipv6's attributes.
        """
        try:
            sctp_node = self.xmltreefile.reroot('/sctp-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = sctp_node.getroot()
        sctp_attr = dict(node.items())

        return sctp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Sctp_ipv6 attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED,INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'srcportstart', 'srcportend', 'dstportstart',
                     'dstportend', 'dscp', 'comment', 'state', 'ipset',
                     'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='dstipto')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='sctp-ipv6',
                                   attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='sctp-ipv6',
                                   attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='sctp-ipv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<sctp-ipv6/>'

########NEW FILE########
__FILENAME__ = stp
"""
stp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoSTP
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Stp(base.TypedDeviceBase):

    """
    Create new Stp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Stp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='stp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Stp, self).__init__(protocol_tag='stp', type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return stp attribute dict

        :return: None if no stp in xml, dict of stp's attributes.
        """
        try:
            stp_node = self.xmltreefile.reroot('/stp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
            node = stp_node.getroot()
            stp_attr = dict(node.items())

        return stp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Stp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        type: string, Bridge Protocol Data Unit (BPDU) type
        flags: string, BPDU flag
        root_priority: string, Root priority (range start)
        root_priority_hi: string, Root priority range end
        root_address: string, Root MAC address
        root_address_mask: string, BPDU sender MAC address
        root_cost: string, Root path cost (range start)
        root_cost_hi: string, Root path cost range end
        sender_priority: string, Sender priority (range start)
        sender_priority_hi: string, Sender priority range end
        sender_address: string, BPDU sender MAC address
        sender_address_mask: string, BPDU sender MAC address mask
        port: string, Port identifier (range start)
        port_hi: string, Port identifier range end
        msg_age: string, Message age timer (range start)
        msg_age_hi: string, Message age timer range end
        max_age: string, Maximum age timer (range start)
        max_age_hi: string, Maximum age timer range end
        hello_time: string, Hello time timer (range start)
        hello_time_hi: string, Hello time timer range end
        forward_delay: string, Forward delay (range start)
        forward_delay_hi: string, Forward delay range end
        comment: string, text with max. 256 characters
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'type', 'flags',
                     'root_priority', 'root_priority_hi', 'root_address',
                     'root_address_mask', 'root_cost', 'root_cost_hi',
                     'sender_priority', 'sender_priority_hi', 'sender_address',
                     'sender_address_mask', 'port', 'port_hi', 'msg_age',
                     'msg_age_hi', 'max_age', 'max_age_hi', 'hello_time',
                     'hello_time_hi', 'forward_delay', 'forward_delay_hi',
                     'comment')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='stp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='stp', attribute='srcmacmask')
            accessors.XMLAttribute('type', self, parent_xpath='/',
                                   tag_name='stp', attribute='type')
            accessors.XMLAttribute('flags', self, parent_xpath='/',
                                   tag_name='stp', attribute='flags')
            accessors.XMLAttribute('root_priority', self, parent_xpath='/',
                                   tag_name='stp', attribute='root-priority')
            accessors.XMLAttribute('root_priority-hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='root-priority-hi')
            accessors.XMLAttribute('root_address', self, parent_xpath='/',
                                   tag_name='stp', attribute='root-address')
            accessors.XMLAttribute('root_address_mask', self,
                                   parent_xpath='/', tag_name='stp',
                                   attribute='root-address-mask')
            accessors.XMLAttribute('root_cost', self, parent_xpath='/',
                                   tag_name='stp', attribute='root-cost')
            accessors.XMLAttribute('root_cost_hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='root-cost-hi')
            accessors.XMLAttribute('sender_priority', self, parent_xpath='/',
                                   tag_name='stp', attribute='sender-priority')
            accessors.XMLAttribute('sender_priority_hi', self,
                                   parent_xpath='/', tag_name='stp',
                                   attribute='sender-priority-hi')
            accessors.XMLAttribute('sender_address', self, parent_xpath='/',
                                   tag_name='stp', attribute='sender-address')
            accessors.XMLAttribute('sender_address_mask', self,
                                   parent_xpath='/', tag_name='stp',
                                   attribute='sender-address-mask')
            accessors.XMLAttribute('port', self, parent_xpath='/',
                                   tag_name='stp', attribute='port')
            accessors.XMLAttribute('port_hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='port_hi')
            accessors.XMLAttribute('msg_age', self, parent_xpath='/',
                                   tag_name='stp', attribute='msg-age')
            accessors.XMLAttribute('msg_age_hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='msg-age-hi')
            accessors.XMLAttribute('max-age', self, parent_xpath='/',
                                   tag_name='stp', attribute='max-age')
            accessors.XMLAttribute('max-age-hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='max-age-hi')
            accessors.XMLAttribute('hello-time', self, parent_xpath='/',
                                   tag_name='stp', attribute='hello-time')
            accessors.XMLAttribute('hello-time-hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='hello-time-hi')
            accessors.XMLAttribute('forward-delay', self, parent_xpath='/',
                                   tag_name='stp', attribute='forward-delay')
            accessors.XMLAttribute('forward-delay-hi', self, parent_xpath='/',
                                   tag_name='stp', attribute='forward-delay-hi')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='stp', attribute='comment')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<stp/>'

########NEW FILE########
__FILENAME__ = tcp
"""
tcp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoTCP-ipv4
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Tcp(base.TypedDeviceBase):

    """
    Create new Tcp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Tcp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='tcp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Tcp, self).__init__(protocol_tag='tcp', type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return tcp attribute dict

        :return: None if no tcp in xml, dict of tcp's attributes.
        """
        try:
            tcp_node = self.xmltreefile.reroot('/tcp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = tcp_node.getroot()
        tcp_attr = dict(node.items())

        return tcp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Tcp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED, INVALID or NONE
        flags: string, TCP-only: format of mask/flags with mask and flags each being a comma separated list of SYN,ACK,URG,PSH,FIN,RST or NONE or ALL
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'srcportstart', 'srcportend', 'dstportstart',
                     'dstportend', 'dscp', 'comment', 'state', 'flags',
                     'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dstipto')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='tcp', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='tcp', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='tcp', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='tcp', attribute='state')
            accessors.XMLAttribute('flags', self, parent_xpath='/',
                                   tag_name='tcp', attribute='flags')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='tcp', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='tcp', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<tcp/>'

########NEW FILE########
__FILENAME__ = tcp_ipv6
"""
tcp-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoTCP-ipv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Tcp_ipv6(base.TypedDeviceBase):

    """
    Create new Tcp_ipv6 xml instances

    Properties:
        attrs: ``libvirt_xml.nwfilter_protocols.Tcp_ipv6.Attr`` instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='tcp_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Tcp_ipv6, self).__init__(protocol_tag='tcp-ipv6',
                                       type_name=type_name,
                                       virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return tcp-ipv6 attribute dict

        :return: None if no tcp-ipv6 in xml, dict of tcp-ipv6's attributes.
        """
        try:
            tcp_node = self.xmltreefile.reroot('/tcp-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = tcp_node.getroot()
        tcp_attr = dict(node.items())

        return tcp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Tcp_ipv6 attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED, INVALID or NONE
        flags: string, TCP-only: format of mask/flags with mask and flags each being a comma separated list of SYN,ACK,URG,PSH,FIN,RST or NONE or ALL
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'srcportstart', 'srcportend', 'dstportstart',
                     'dstportend', 'dscp', 'comment', 'state', 'flags',
                     'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='dstipto')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='tcp-ipv6',
                                   attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='tcp-ipv6',
                                   attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='state')
            accessors.XMLAttribute('flags', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='flags')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='tcp-ipv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<tcp-ipv6/>'

########NEW FILE########
__FILENAME__ = udp
"""
udp protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoTCP-ipv4
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Udp(base.TypedDeviceBase):

    """
    Create new Udp xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Udp.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='udp', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Udp, self).__init__(protocol_tag='udp', type_name=type_name,
                                  virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return udp attribute dict

        :return: None if no udp in xml, dict of udp's attributes.
        """
        try:
            udp_node = self.xmltreefile.reroot('/udp')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = udp_node.getroot()
        udp_attr = dict(node.items())

        return udp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Udp attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED, INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'srcportstart', 'srcportend', 'dstportstart',
                     'dstportend', 'dscp', 'comment', 'state', 'ipset',
                     'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='udp', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='udp', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='udp', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='udp', attribute='dstipto')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='udp', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='udp', attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='udp', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='udp', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='udp', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='udp', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='udp', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='udp', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<udp/>'

########NEW FILE########
__FILENAME__ = udplite
"""
udplite protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMisc
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Udplite(base.TypedDeviceBase):

    """
    Create new Udplite xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Udplite.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='udplite', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Udplite, self).__init__(protocol_tag='udplite',
                                      type_name=type_name,
                                      virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return udplite attribute dict

        :return: None if no udplite in xml, dict of udplite's attributes.
        """
        try:
            udplite_node = self.xmltreefile.reroot('/udplite')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = udplite_node.getroot()
        udplite_attr = dict(node.items())

        return udplite_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Udplite attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED, INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='udplite', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='udplite', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='udplite', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='udplite', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='udplite', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='udplite', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='udplite', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='udplite', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='udplite', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='udplite', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='udplite', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<udplite/>'

########NEW FILE########
__FILENAME__ = udplite_ipv6
"""
udplite-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoMiscv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Udplite_ipv6(base.TypedDeviceBase):

    """
    Create new Udplite_ipv6 xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Udplite_ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='udplite_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Udplite_ipv6, self).__init__(protocol_tag='udplite-ipv6',
                                           type_name=type_name,
                                           virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return udplite-ipv6 attribute dict

        :return: None if no udplite-ipv6 in xml, dict of udplite-ipv6's
                 attributes.
        """
        try:
            udplite_node = self.xmltreefile.reroot('/udplite-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = udplite_node.getroot()
        udplite_attr = dict(node.items())

        return udplite_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Udplite_ipv6 attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacmask: string, Mask applied to MAC address of destination
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED, INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'srcipaddr', 'srcipmask', 'dstipaddr', 'dstipmask',
                     'srcipfrom', 'srcipto', 'dstipfrom', 'dstipto',
                     'dscp', 'comment', 'state', 'ipset', 'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dstmacmask')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dstipto')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='udplite-ipv6',
                                   attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<udplite-ipv6/>'

########NEW FILE########
__FILENAME__ = udp_ipv6
"""
udp-ipv6 protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoTCP-ipv6
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Udp_ipv6(base.TypedDeviceBase):

    """
    Create new Udp_ipv6 xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Udp_ipv6.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='udp_ipv6', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Udp_ipv6, self).__init__(protocol_tag='udp-ipv6',
                                       type_name=type_name,
                                       virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return udp-ipv6 attribute dict

        :return: None if no udp-ipv6 in xml, dict of udp-ipv6's attributes.
        """
        try:
            udp_node = self.xmltreefile.reroot('/udp-ipv6')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = udp_node.getroot()
        udp_attr = dict(node.items())

        return udp_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Udp_ipv6 attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcipaddr: string, Source IP address
        srcipmask: string, Mask applied to source IP address
        dstipaddr: string, Destination IP address
        dstipmask: string, Mask applied to destination IP address
        srcipfrom: string, Start of range of source IP address
        srcipto: string, End of range of source IP address
        dstipfrom: string, Start of range of destination IP address
        dstipto: string, End of range of destination IP address
        srcportstart: string, Start of range of valid source ports; requires protocol
        srcportend: string, End of range of valid source ports; requires protocol
        dstportstart: string, Start of range of valid destination ports; requires protocol
        dstportend: string, End of range of valid destination ports; requires protocol
        comment: string, text with max. 256 characters
        state: string, comma separated list of NEW,ESTABLISHED,RELATED, INVALID or NONE
        ipset: The name of an IPSet managed outside of libvirt
        ipsetflags: flags for the IPSet; requires ipset attribute
        """

        __slots__ = ('srcmacaddr', 'srcipaddr', 'srcipmask', 'dstipaddr',
                     'dstipmask', 'srcipfrom', 'srcipto', 'dstipfrom',
                     'dstipto', 'srcportstart', 'srcportend', 'dstportstart',
                     'dstportend', 'dscp', 'comment', 'state', 'ipset',
                     'ipsetflags')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='srcmacaddr')
            accessors.XMLAttribute('srcipaddr', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='srcipaddr')
            accessors.XMLAttribute('srcipmask', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='srcipmask')
            accessors.XMLAttribute('dstipaddr', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='dstipaddr')
            accessors.XMLAttribute('dstipmask', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='dstipmask')
            accessors.XMLAttribute('srcipfrom', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='srcipfrom')
            accessors.XMLAttribute('srcipto', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='srcipto')
            accessors.XMLAttribute('dstipfrom', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='dstipfrom')
            accessors.XMLAttribute('dstipto', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='dstipto')
            accessors.XMLAttribute('srcportstart', self, parent_xpath='/',
                                   tag_name='udp-ipv6',
                                   attribute='srcportstart')
            accessors.XMLAttribute('srcportend', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='srcportend')
            accessors.XMLAttribute('dstportstart', self, parent_xpath='/',
                                   tag_name='udp-ipv6',
                                   attribute='dstportstart')
            accessors.XMLAttribute('dstportend', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='dstportend')
            accessors.XMLAttribute('dscp', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='dscp')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='comment')
            accessors.XMLAttribute('state', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='state')
            accessors.XMLAttribute('ipset', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='ipset')
            accessors.XMLAttribute('ipsetflags', self, parent_xpath='/',
                                   tag_name='udp-ipv6', attribute='ipsetflags')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<udp-ipv6/>'

########NEW FILE########
__FILENAME__ = vlan
"""
vlan protocl support class(es)

http://libvirt.org/formatnwfilter.html#nwfelemsRulesProtoVLAN
"""

from virttest.libvirt_xml import accessors, xcepts
from virttest.libvirt_xml.nwfilter_protocols import base


class Vlan(base.TypedDeviceBase):

    """
    Create new Vlan xml instances

    Properties:
        attrs: libvirt_xml.nwfilter_protocols.Vlan.Attr instance
    """

    __slots__ = ('attrs',)

    def __init__(self, type_name='file', virsh_instance=base.base.virsh):
        accessors.XMLElementNest('attrs', self, parent_xpath='/',
                                 tag_name='vlan', subclass=self.Attr,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(Vlan, self).__init__(protocol_tag='vlan', type_name=type_name,
                                   virsh_instance=virsh_instance)

    def new_attr(self, **dargs):
        """
        Return a new Attr instance and set properties from dargs

        :param dargs: dict of attributes
        :return: new Attr instance
        """
        new_one = self.Attr(virsh_instance=self.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def get_attr(self):
        """
        Return vlan attribute dict

        :return: None if no vlan in xml, dict of vlan's attributes.
        """
        try:
            vlan_node = self.xmltreefile.reroot('/vlan')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        node = vlan_node.getroot()
        vlan_attr = dict(node.items())

        return vlan_attr

    class Attr(base.base.LibvirtXMLBase):

        """
        Vlan attribute XML class

        Properties:

        srcmacaddr: string, MAC address of sender
        srcmacmask: string, Mask applied to MAC address of sender
        dstmacaddr: string, MAC address of destination
        dstmacaddr: string, Mask applied to MAC address of destination
        vlanid: string, VLAN ID
        encap_protocol: string, Encapsulated layer 3 protocol ID
        comment: string, text with max. 256 characters
        """

        __slots__ = ('srcmacaddr', 'srcmacmask', 'dstmacaddr', 'dstmacmask',
                     'vlanid', 'encap_protocol', 'comment')

        def __init__(self, virsh_instance=base.base.virsh):
            accessors.XMLAttribute('srcmacaddr', self, parent_xpath='/',
                                   tag_name='vlan', attribute='srcmacaddr')
            accessors.XMLAttribute('srcmacmask', self, parent_xpath='/',
                                   tag_name='vlan', attribute='srcmacmask')
            accessors.XMLAttribute('dstmacaddr', self, parent_xpath='/',
                                   tag_name='vlan', attribute='dstmacaddr')
            accessors.XMLAttribute('dstmacmask', self, parent_xpath='/',
                                   tag_name='vlan', attribute='dstmacmask')
            accessors.XMLAttribute('vlanid', self, parent_xpath='/',
                                   tag_name='vlan', attribute='vlanid')
            accessors.XMLAttribute('encap_protocol', self, parent_xpath='/',
                                   tag_name='vlan', attribute='encap-protocol')
            accessors.XMLAttribute('comment', self, parent_xpath='/',
                                   tag_name='vlan', attribute='comment')

            super(self.__class__, self).__init__(virsh_instance=virsh_instance)
            self.xml = '<vlan/>'

########NEW FILE########
__FILENAME__ = nwfilter_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatnwfilter.html
"""

from virttest.libvirt_xml import base, xcepts, accessors
from virttest.libvirt_xml.nwfilter_protocols import librarian


class NwfilterRulesProtocol(list):

    """
    List of protocol instances from classes handed out by librarian.get
    """

    @staticmethod
    def __type_check__(other):
        try:
            # Raise error if object isn't dict-like or doesn't have key
            device_tag = other['device_tag']
            # Check that we have support for this type
            librarian.get(device_tag)
        except (AttributeError, TypeError, xcepts.LibvirtXMLError):
            # Required to always raise TypeError for list API in VMXML class
            raise TypeError("Unsupported item type: %s" % str(type(other)))

    def __setitem__(self, key, value):
        self.__type_check__(value)
        super(NwfilterRulesProtocol, self).__setitem__(key, value)
        return self

    def append(self, value):
        self.__type_check__(value)
        super(NwfilterRulesProtocol, self).append(value)
        return self

    def extend(self, iterable):
        # Make sure __type_check__ happens
        for item in iterable:
            self.append(item)
        return self

    def by_device_tag(self, tag):
        result = NwfilterRulesProtocol()
        for protocol in self:
            if protocol.device_tag == tag:
                result.append(protocol)
        return result


class NwfilterXMLRules(base.LibvirtXMLBase):

    """
    Create new NwfilterXMLRules instance.

    Properties:
        rule_action: string, rule action
        rule_direction: string, rule direction
        priority: string, rule priority
        statematch: string, rule statematch
    """

    __slots__ = ('rule_action', 'rule_direction', 'rule_priority',
                 'rule_statematch')

    def __init__(self, protocol=None, virsh_instance=base.virsh):
        accessors.XMLAttribute('rule_action', self, parent_xpath='/',
                               tag_name='rule', attribute='action')
        accessors.XMLAttribute('rule_direction', self, parent_xpath='/',
                               tag_name='rule', attribute='direction')
        accessors.XMLAttribute('rule_priority', self, parent_xpath='/',
                               tag_name='rule', attribute='priority')
        accessors.XMLAttribute('rule_statematch', self, parent_xpath='/',
                               tag_name='rule', attribute='statematch')

        super(NwfilterXMLRules, self).__init__(virsh_instance=virsh_instance)
        self.xml = '<rule></rule>'

    def backup_rule(self):
        """
        Return backup rule instance

        :return: the backup of rule instance
        """
        backup = NwfilterXMLRules(virsh_instance=self.__dict_get__('virsh'))
        backup.xmltreefile = self.xmltreefile.backup_copy()

        return backup

    def get_protocol(self, protocol=None):
        """
        Return None if protocol is None, else return specific class instance

        :param protocol: specific protocol type in rules
        :return: specific protocol class instance from librarian.get
        """
        if protocol:
            protocol_class = librarian.get(protocol)
            protocol_node = self.xmltreefile.getroot().getchildren()[0]
            protocol_node.tag = protocol
            new_one = protocol_class.new_from_element(protocol_node)
            new_one.xmltreefile = self.xmltreefile
        else:
            new_one = None

        return new_one

    def new_protocol(self, **dargs):
        """
        Return a new rule protocol instance and set properties from dargs
        """
        protocol_tag = dargs.get("name")
        new_one = librarian.get(protocol_tag)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

    def del_protocol(self):
        """
        Delete protocol in rule xml
        """
        protocol_node = self.xmltreefile.getroot().getchildren()
        if protocol_node:
            self.xmltreefile.remove(protocol_node[0])
            self.xmltreefile.write()


class NwfilterXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for NwfilterXML class.

    Properties:
        filter_name: string, filter name
        filter_chain: string, filter name
        filter_priority: string, filter priority
        uuid: string, operates on uuid tag
        filterref: string, operates on filterref tag
        filterref_name: string, reference filter name
    """

    __slots__ = base.LibvirtXMLBase.__slots__ + ('filter_name', 'filter_chain',
                                                 'filter_priority',
                                                 'uuid', 'filterref',
                                                 'filterref_name')

    __uncompareable__ = base.LibvirtXMLBase.__uncompareable__

    __schema_name__ = "nwfilter"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLAttribute('filter_name', self, parent_xpath='/',
                               tag_name='filter', attribute='name')
        accessors.XMLAttribute('filter_chain', self, parent_xpath='/',
                               tag_name='filter', attribute='chain')
        accessors.XMLAttribute('filter_priority', self, parent_xpath='/',
                               tag_name='filter', attribute='priority')
        accessors.XMLElementText('uuid', self, parent_xpath='/',
                                 tag_name='uuid')
        accessors.XMLElementText('filterref', self, parent_xpath='/',
                                 tag_name='filterref')
        accessors.XMLAttribute('filterref_name', self, parent_xpath='/',
                               tag_name='filterref', attribute='filter')

        super(NwfilterXMLBase, self).__init__(virsh_instance=virsh_instance)

    def get_rule_index(self, rule_protocol=None):
        """
        Return rule index list for specific protocol

        :param rule_protocol: the specific protocol type in rules
        :return: rule index list
        """
        rule_index = []
        source_root = self.xmltreefile.findall('rule')
        for i in range(len(source_root)):
            if rule_protocol:
                protocol_node = source_root[i].getchildren()[0]
                if protocol_node.tag == rule_protocol:
                    rule_index.append(i)
            else:
                rule_index.append(i)

        return rule_index

    def get_rule(self, rule_index=0, rule_protocol=None):
        """
        Return NwfilterXMLRules instance for specific protocol and index

        :param rule_index: rule's index number
        :param rule_protocol: the specific protocol type in rules
        :return: New initialized NwfilterXMLRules instance
        """
        index = self.get_rule_index(rule_protocol)
        if rule_index not in index:
            raise xcepts.LibvirtXMLError("rule index %s is not valid" %
                                         rule_index)
        source_root = self.xmltreefile.findall('rule')
        rulexml = NwfilterXMLRules(virsh_instance=self.__dict_get__('virsh'))
        rulexml.xmltreefile = self.xmltreefile.backup_copy()
        rulexml.xmltreefile._setroot(source_root[rule_index])
        rulexml.xmltreefile.write()
        rulexml.xmltreefile.flush()

        return rulexml

    def del_rule(self, rule_index=0):
        """
        Delete rule with specific index

        :param rule_index: rule's index number
        """
        source_root = self.xmltreefile.findall('rule')
        self.xmltreefile.remove(source_root[rule_index])
        self.xmltreefile.write()

    def set_rule(self, value, rule_index=0):
        """
        Delete rule with specific index and add new given value

        :param rule_index: rule's index number
        :param value: NwfilterXMLRules instance
        """
        if not issubclass(type(value), NwfilterXMLRules):
            raise xcepts.LibvirtXMLError(
                "Value must be a NwfilterXMLRules or subclass")
        try:
            source_root = self.xmltreefile.findall('rule')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        if source_root[rule_index] is not None:
            self.del_rule(rule_index)
        root = self.xmltreefile.getroot()
        root.insert(rule_index, value.xmltreefile.getroot())
        self.xmltreefile.write()

    def add_rule(self, value):
        """
        Add new rule into filter

        :param value: NwfilterXMLRules instance
        """
        if not issubclass(type(value), NwfilterXMLRules):
            raise xcepts.LibvirtXMLError(
                "Value must be a NwfilterXMLRules or subclass")
        root = self.xmltreefile.getroot()
        root.append(value.xmltreefile.getroot())
        self.xmltreefile.write()

    def get_protocol_attr(self, rule_index=0, protocol=None):
        """
        Return protocol dict of specific rule index and protocol type

        :param rule_index: rule's index number
        :param protocol: the specific protocol type in rules
        :return: protocol attribute dict
        """
        rule = self.get_rule(rule_index, protocol)
        if protocol:
            protocol = rule.get_protocol(protocol)
            attr = protocol.get_attr()
        else:
            attr = None

        return attr


class NwfilterXML(NwfilterXMLBase):

    """
    Manipulators of a nwfilter through it's XML definition.
    """

    __slots__ = NwfilterXMLBase.__slots__

    def __init__(self, virsh_instance=base.virsh):
        """
        Initialize new instance with empty XML
        """
        super(NwfilterXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<filter></filter>"

    @staticmethod
    def new_from_filter_dumpxml(uuid, options="", virsh_instance=base.virsh):
        """
        Return new NwfilterXML instance from virsh filter-dumpxml command

        :param uuid: filter's uuid
        :param virsh_instance: virsh module or instance to use
        :return: New initialized NwfilterXML instance
        """
        filter_xml = NwfilterXML(virsh_instance=virsh_instance)
        filter_xml['xml'] = virsh_instance.nwfilter_dumpxml(uuid,
                                                            options=options
                                                            ).stdout.strip()

        return filter_xml

    def get_all_rules(self):
        """
        Return all rules dict with protocol attribute.

        :return: all rules dict with key as rule index number
        """
        rule_dict_attr = {}
        rule_nodes = self.xmltreefile.findall('rule')
        for i in range(len(rule_nodes)):
            if rule_nodes[i].getchildren():
                protocol_node = rule_nodes[i].getchildren()[0]
                protocol = protocol_node.tag
                pro_dict = dict(protocol_node.items())
                rule_dict = dict(rule_nodes[i].items())
                rule_dict.update(pro_dict)
                rule_dict['protocol'] = protocol
                rule_dict_attr[i] = rule_dict
            else:
                rule_dict = dict(rule_nodes[i].items())
                rule_dict_attr[i] = rule_dict

        return rule_dict_attr

    def get_rules_dict(self, filter_name, options="",
                       virsh_instance=base.virsh):
        """
        Return all rules dict with protocol attribute for given filter

        :param filter_name: name or uuid of filter
        :param options: extra options
        :return: all rules dictionary with index as key
        """
        filxml = NwfilterXML.new_from_filter_dumpxml(filter_name,
                                                     virsh_instance=base.virsh)
        rules = filxml.get_all_rules()

        return rules

    def get_all_protocols(self, protocol=None):
        """
        Put all type of protocol into a NwfilterRulesProtocol instance.
        Return all protocols class list if protocol as None, else return
        specific protocol type class list.

        :param protocol: specific protocol type in rules
        :return: NwfilterRulesProtocol instance list
        """
        protocols = NwfilterRulesProtocol()
        all_rules = self.xmltreefile.findall('rule')

        for i in all_rules:
            protocol_node = i.getchildren()
            if protocol_node:
                if protocol:
                    # Each rule node only have one protocol node, so
                    # only use protocol_node[0]
                    if protocol_node[0].tag == protocol:
                        protocol_class = librarian.get(protocol)
                        new_one = protocol_class.new_from_element(
                            protocol_node[0])
                        protocols.device_tag = protocol
                        protocols.append(new_one)
                else:
                    protocol_class = librarian.get(protocol_node[0].tag)
                    new_one = protocol_class.new_from_element(
                        protocol_node[0])
                    protocols.device_tag = protocol_node[0].tag
                    protocols.append(new_one)

        return protocols

########NEW FILE########
__FILENAME__ = pool_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatstorage.html#StoragePool
"""
import os
import logging
import tempfile
from autotest.client.shared import error
from virttest import libvirt_storage
from virttest.libvirt_xml import base, xcepts, accessors


class SourceXML(base.LibvirtXMLBase):

    """
    Source block in pool xml, optionally containing different elements and
    attributes which dependent on pool type.
    """

    __slots__ = ('device_path', 'vg_name', 'host_name', 'dir_path',
                 'adp_type', 'adp_name', 'adp_parent', 'adp_wwnn',
                 'adp_wwpn')

    def __init__(self, virsh_instance=base.virsh):
        """
        Create new SourceXML instance.
        """
        accessors.XMLAttribute(property_name='device_path',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='device',
                               attribute='path')
        accessors.XMLElementText(property_name='vg_name',
                                 libvirtxml=self,
                                 parent_xpath='/',
                                 tag_name='name')
        accessors.XMLAttribute(property_name='host_name',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='host',
                               attribute='name')
        accessors.XMLAttribute(property_name='dir_path',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='dir',
                               attribute='path')
        accessors.XMLAttribute(property_name='adp_type',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='adapter',
                               attribute='type')
        accessors.XMLAttribute(property_name='adp_name',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='adapter',
                               attribute='name')
        accessors.XMLAttribute(property_name='adp_parent',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='adapter',
                               attribute='parent')
        accessors.XMLAttribute(property_name='adp_wwnn',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='adapter',
                               attribute='wwnn')
        accessors.XMLAttribute(property_name='adp_wwpn',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='adapter',
                               attribute='wwpn')
        super(SourceXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<source></source>"


class PoolXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for PoolXML class.

    Properties:
        pool_type:
            string, pool type
        name:
            string, pool name
        uuid:
            string, pool uuid
        capacity:
            integer, pool total capacity
        allocation:
            integer, pool allocated capacity
        available:
            integer, pool available capacity
        source:
            PoolSourceXML instanc
        target:
            string, target path of pool
    """

    __slots__ = ('pool_type', 'name', 'uuid', 'capacity',
                 'allocation', 'available', 'source', 'target_path')
    __uncompareable__ = base.LibvirtXMLBase.__uncompareable__

    __schema_name__ = "pool"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLAttribute(property_name='pool_type',
                               libvirtxml=self,
                               parent_xpath='/',
                               tag_name='pool',
                               attribute='type')
        accessors.XMLElementText(property_name='name',
                                 libvirtxml=self,
                                 parent_xpath='/',
                                 tag_name='name')
        accessors.XMLElementText(property_name='uuid',
                                 libvirtxml=self,
                                 parent_xpath='/',
                                 tag_name='uuid')
        accessors.XMLElementInt(property_name='capacity',
                                libvirtxml=self,
                                parent_xpath='/',
                                tag_name='capacity')
        accessors.XMLElementInt(property_name='allocation',
                                libvirtxml=self,
                                parent_xpath='/',
                                tag_name='allocation')
        accessors.XMLElementInt(property_name='available',
                                libvirtxml=self,
                                parent_xpath='/',
                                tag_name='available')
        accessors.XMLElementText(property_name='target_path',
                                 libvirtxml=self,
                                 parent_xpath='/target',
                                 tag_name='path')
        super(PoolXMLBase, self).__init__(virsh_instance=virsh_instance)

    def get_source(self):
        xmltreefile = self.__dict_get__('xml')
        try:
            source_root = xmltreefile.reroot('/source')
        except KeyError, detail:
            raise xcepts.LibvirtXMLError(detail)
        sourcexml = SourceXML(virsh_instance=self.__dict_get__('virsh'))
        sourcexml.xmltreefile = source_root
        return sourcexml

    def del_source(self):
        xmltreefile = self.__dict_get__('xml')
        element = xmltreefile.find('/source')
        if element is not None:
            xmltreefile.remove(element)
            xmltreefile.write()

    def set_source(self, value):
        if not issubclass(type(value), SourceXML):
            raise xcepts.LibvirtXMLError(
                "Value must be a SourceXML or subclass")
        xmltreefile = self.__dict_get__('xml')
        self.del_source()
        root = xmltreefile.getroot()
        root.append(value.xmltreefile.getroot())
        xmltreefile.write()


class PoolXML(PoolXMLBase):

    """
    Manipulators of a libvirt Pool through it's XML definition.
    """

    __slots__ = []

    def __init__(self, pool_type='dir', virsh_instance=base.virsh):
        """
        Initialize new instance with empty XML
        """
        super(PoolXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<pool type='%s'></pool>" % pool_type

    @staticmethod
    def new_from_dumpxml(name, virsh_instance=base.virsh):
        """
        Return new PoolXML instance from virsh pool-dumpxml command

        :param name: Name of pool to pool-dumpxml
        :param virsh_instance: Virsh module or instance to use
        :return: new initialized PoolXML instance
        """
        pool_xml = PoolXML(virsh_instance=virsh_instance)
        pool_xml['xml'] = virsh_instance.pool_dumpxml(name)
        return pool_xml

    @staticmethod
    def get_type(name, virsh_instance=base.virsh):
        """
        Return pool type by pool name

        :param name: pool name
        :return: pool type
        """
        pool_xml = PoolXML.new_from_dumpxml(name, virsh_instance)
        return pool_xml.pool_type

    @staticmethod
    def get_pool_details(name, virsh_instance=base.virsh):
        """
        Return pool details by pool name.

        :param name: pool name
        :return: a dict which include a series of pool details
        """
        pool_xml = PoolXML.new_from_dumpxml(name, virsh_instance)
        pool_details = {}
        pool_details['type'] = pool_xml.pool_type
        pool_details['uuid'] = pool_xml.uuid
        pool_details['capacity'] = pool_xml.capacity
        pool_details['allocation'] = pool_xml.allocation
        pool_details['available'] = pool_xml.available
        pool_details['target_path'] = pool_xml.target_path
        return pool_details

    def pool_undefine(self):
        """
        Undefine pool with libvirt retaining XML in instance
        """
        try:
            self.virsh.pool_undefine(self.name, ignore_status=False)
        except error.CmdError:
            logging.error("Undefine pool '%s' failed.", self.name)
            return False

    def pool_define(self):
        """
        Define pool with virsh from this instance
        """
        result = self.virsh.pool_define(self.xml)
        if result.exit_status:
            logging.error("Define %s failed.\n"
                          "Detail: %s.", self.name, result.stderr)
            return False
        return True

    @staticmethod
    def pool_rename(name, new_name, uuid=None, virsh_instance=base.virsh):
        """
        Rename a pool from pool XML.
        :param name: Original pool name.
        :param new_name: new name of pool.
        :param uuid: new pool uuid, if None libvirt will generate automatically.
        :return:
        """
        pool_ins = libvirt_storage.StoragePool()
        if not pool_ins.is_pool_persistent(name):
            logging.error("Cannot rename for transient pool")
            return False
        start_pool = False
        if pool_ins.is_pool_active(name):
            virsh_instance.pool_destroy(name)
            start_pool = True
        poolxml = PoolXML.new_from_dumpxml(name, virsh_instance)
        backup = poolxml.copy()
        if not pool_ins.delete_pool(name):
            del poolxml
            raise xcepts.LibvirtXMLError("Error occur while deleting pool: %s"
                                         % name)
        # Alter the XML
        poolxml.name = new_name
        if uuid is None:
            del poolxml.uuid
        else:
            poolxml.uuid = uuid
        # Re-define XML to libvirt
        logging.debug("Rename pool: %s to %s.", name, new_name)
        # error message for failed define
        error_msg = "Error reported while defining pool:\n"
        try:
            if not poolxml.pool_define():
                raise xcepts.LibvirtXMLError(error_msg + "%s"
                                             % poolxml.get('xml'))
        except error.CmdError, detail:
            del poolxml
            # Allow exceptions thrown here since state will be undefined
            backup.pool_define()
            raise xcepts.LibvirtXMLError(error_msg + "%s" % detail)
        if start_pool:
            pool_ins.start_pool(new_name)
        return True

    @staticmethod
    def backup_xml(name, virsh_instance=base.virsh):
        """
        Backup the pool xml file.
        """
        try:
            xml_file = tempfile.mktemp(dir="/tmp")
            virsh_instance.pool_dumpxml(name, to_file=xml_file)
            return xml_file
        except Exception, detail:
            if os.path.exists(xml_file):
                os.remove(xml_file)
            logging.error("Failed to backup xml file:\n%s", detail)
            return ""

    def debug_xml(self):
        """
        Dump contents of XML file for debugging
        """
        xml = str(self)
        for debug_line in str(xml).splitlines():
            logging.debug("Pool XML: %s", debug_line)

########NEW FILE########
__FILENAME__ = secret_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatsecret.html
"""

from virttest.libvirt_xml import base, accessors


class SecretXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for SecretXML class.

    Properties:
        secret_ephemeral:
            yes or no, operates on XML secret tag
        secret_private:
            yes or no, operates on XML secret tag
        description:
            string, operates on description tag
        uuid:
            string, operates on uuid tag
        usage:
            string, operates on usage tag
        volume:
            the volume file path, sub-tag of the usage tag,
            operates on volume tag
    """

    __slots__ = ('secret_ephemeral', 'secret_private', 'description',
                 'uuid', 'usage', 'volume')

    __uncompareable__ = base.LibvirtXMLBase.__uncompareable__

    __schema_name__ = "secret"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLAttribute('secret_ephemeral', self, parent_xpath='/',
                               tag_name='secret', attribute='ephemeral')
        accessors.XMLAttribute('secret_private', self, parent_xpath='/',
                               tag_name='secret', attribute='private')
        accessors.XMLElementText('uuid', self, parent_xpath='/',
                                 tag_name='uuid')
        accessors.XMLElementText('description', self, parent_xpath='/',
                                 tag_name='description')
        accessors.XMLAttribute('usage', self, parent_xpath='/',
                               tag_name='usage', attribute='type')
        accessors.XMLElementText('volume', self, parent_xpath='/usage',
                                 tag_name='volume')
        super(SecretXMLBase, self).__init__(virsh_instance=virsh_instance)


class SecretXML(SecretXMLBase):

    """
    Manipulators of a secret through it's XML definition.
    """

    __slots__ = []

    def __init__(self, ephemeral='yes', private='no',
                 virsh_instance=base.virsh):
        """
        Initialize new instance with empty XML
        """
        super(SecretXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<secret ephemeral='%s' private='%s'><description>\
                     </description></secret>" % (ephemeral, private)

    @staticmethod
    def new_from_secret_dumpxml(uuid, virsh_instance=base.virsh):
        """
        Return new SecretXML instance from virsh secret-dumpxml command

        :param uuid: secret's uuid
        :param virsh_instance: virsh module or instance to use
        :return: New initialized SecretXML instance
        """
        secret_xml = SecretXML(virsh_instance=virsh_instance)
        secret_xml['xml'] = virsh_instance.secret_dumpxml(uuid).stdout.strip()

        return secret_xml

    @staticmethod
    def get_secret_details_by_uuid(uuid, virsh_instance=base.virsh):
        """
        Return secret XML by secret's uuid

        :param uuid: secret's uuid
        :return: secret XML dictionary
        """
        secret_xml = {}
        sec_xml = SecretXML.new_from_secret_dumpxml(uuid, virsh_instance)

        secret_xml['secret_ephemeral'] = sec_xml.secret_ephemeral
        secret_xml['secret_private'] = sec_xml.secret_private
        secret_xml['uuid'] = sec_xml.uuid
        secret_xml['description'] = sec_xml.description
        secret_xml['usage'] = sec_xml.usage
        secret_xml['volume'] = sec_xml.volume

        return secret_xml

########NEW FILE########
__FILENAME__ = sysinfo_xml
"""
Module simplifying manipulation of sysinfo XML
"""

from virttest.libvirt_xml import base


class SysinfoXML(base.LibvirtXMLBase):

    """
    Handler of libvirt sysinfo xml.
    """

    # TODO: Add more __slots__, accessors and functions to get some useful
    # stats

    __slots__ = []

    def __init__(self, virsh_instance=base.virsh):
        """
        Initialize new instance with empty XML
        """
        super(SysinfoXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<sysinfo></sysinfo>"

    def get_all_processors(self):
        """
        Get all processors dict with entry name as key.

        :return: all processors dict with entry name as key
        """
        processor_dict = {}
        processor_nodes = self.xmltreefile.findall('processor')
        for i in range(len(processor_nodes)):
            temp_dict = {}
            entry_nodes = processor_nodes[i].getchildren()
            if entry_nodes:
                for entry in entry_nodes:
                    entry_attr = dict(entry.items())
                    if entry_attr.has_key('name'):
                        temp_dict[entry_attr['name']] = entry.text
                processor_dict[i] = temp_dict

        return processor_dict

########NEW FILE########
__FILENAME__ = vm_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatdomain.html
"""

import logging
from autotest.client.shared import error
from virttest import xml_utils
from virttest.libvirt_xml import base, accessors, xcepts
from virttest.libvirt_xml.devices import librarian


class VMXMLDevices(list):

    """
    List of device instances from classes handed out by librarian.get()
    """

    @staticmethod
    def __type_check__(other):
        try:
            # Raise error if object isn't dict-like or doesn't have key
            device_tag = other['device_tag']
            # Check that we have support for this type
            librarian.get(device_tag)
        except (AttributeError, TypeError, xcepts.LibvirtXMLError):
            # Required to always raise TypeError for list API in VMXML class
            raise TypeError("Unsupported item type: %s" % str(type(other)))

    def __setitem__(self, key, value):
        self.__type_check__(value)
        super(VMXMLDevices, self).__setitem__(key, value)
        return self

    def append(self, value):
        self.__type_check__(value)
        super(VMXMLDevices, self).append(value)
        return self

    def extend(self, iterable):
        # Make sure __type_check__ happens
        for item in iterable:
            self.append(item)
        return self

    def by_device_tag(self, tag):
        result = VMXMLDevices()
        for device in self:
            if device.device_tag == tag:
                result.append(device)
        return result


class VMXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for VMXML class properties (items in __slots__)

    Properties:
        hypervisor_type: string, hypervisor type name
            get: return domain's type attribute value
            set: change domain type attribute value
            del: raise xcepts.LibvirtXMLError
        vm_name: string, name of the vm
            get: return text value of name tag
            set: set text value of name tag
            del: raise xcepts.LibvirtXMLError
        uuid: string, uuid string for vm
            get: return text value of uuid tag
            set: set text value for (new) uuid tag (unvalidated)
            del: remove uuid tag
        vcpu, max_mem, current_mem: integers
            get: returns integer
            set: set integer
            del: removes tag
        numa: dictionary
            get: return dictionary of numatune/memory attributes
            set: set numatune/memory attributes from dictionary
            del: remove numatune/memory tag
        devices: VMXMLDevices (list-like)
            get: returns VMXMLDevices instance for all devices
            set: Define all devices from VMXMLDevices instance
            del: remove all devices
        cputune: VMCPUTune
            get: return VMCPUTune instance for the domain.
            set: Define cputune tag from a VMCPUTune instance.
            del: remove cputune tag
        current_vcpu: string, 'current' attribute of vcpu tag
            get: return a string for 'current' attribute of vcpu
            set: change 'current' attribute of vcpu
            del: remove 'current' attribute of vcpu
        placement: string, 'placement' attribute of vcpu tag
            get: return a string for 'placement' attribute of vcpu
            set: change 'placement' attribute of vcpu
            del: remove 'placement' attribute of vcpu
        emulatorpin: string, cpuset value (see man virsh: cpulist)
            get: return text value of cputune/emulatorpin attributes
            set: set cputune/emulatorpin attributes from string
            del: remove cputune/emulatorpin tag
    """

    # Additional names of attributes and dictionary-keys instances may contain
    __slots__ = ('hypervisor_type', 'vm_name', 'uuid', 'vcpu', 'max_mem',
                 'current_mem', 'numa', 'devices', 'seclabel',
                 'cputune', 'placement', 'current_vcpu', 'os', 'os_type',
                 'os_arch', 'os_init')

    __uncompareable__ = base.LibvirtXMLBase.__uncompareable__

    __schema_name__ = "domain"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLAttribute(property_name="hypervisor_type",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/',
                               tag_name='domain',
                               attribute='type')
        accessors.XMLElementText(property_name="vm_name",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/',
                                 tag_name='name')
        accessors.XMLElementText(property_name="uuid",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/',
                                 tag_name='uuid')
        accessors.XMLElementInt(property_name="vcpu",
                                libvirtxml=self,
                                forbidden=None,
                                parent_xpath='/',
                                tag_name='vcpu')
        accessors.XMLAttribute(property_name="current_vcpu",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/',
                               tag_name='vcpu',
                               attribute='current')
        accessors.XMLAttribute(property_name="placement",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/',
                               tag_name='vcpu',
                               attribute='placement')
        accessors.XMLElementInt(property_name="max_mem",
                                libvirtxml=self,
                                forbidden=None,
                                parent_xpath='/',
                                tag_name='memory')
        accessors.XMLElementInt(property_name="current_mem",
                                libvirtxml=self,
                                forbidden=None,
                                parent_xpath='/',
                                tag_name='currentMemory')
        accessors.XMLElementText(property_name="os",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/',
                                 tag_name='os')
        accessors.XMLElementText(property_name="os_type",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/os',
                                 tag_name='type')
        accessors.XMLAttribute(property_name="os_arch",
                               libvirtxml=self,
                               forbidden=None,
                               parent_xpath='/os',
                               tag_name='type',
                               attribute='arch')
        accessors.XMLElementText(property_name="os_init",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='/os',
                                 tag_name='init')
        accessors.XMLElementDict(property_name="numa",
                                 libvirtxml=self,
                                 forbidden=None,
                                 parent_xpath='numatune',
                                 tag_name='memory')
        accessors.XMLElementNest(property_name='cputune',
                                 libvirtxml=self,
                                 parent_xpath='/',
                                 tag_name='cputune',
                                 subclass=VMCPUTune,
                                 subclass_dargs={
                                     'virsh_instance': virsh_instance})
        super(VMXMLBase, self).__init__(virsh_instance=virsh_instance)

    def get_devices(self, device_type=None):
        """
        Put all nodes of devices into a VMXMLDevices instance.
        """
        devices = VMXMLDevices()
        all_devices = self.xmltreefile.find('devices')
        if device_type is not None:
            device_nodes = all_devices.findall(device_type)
        else:
            device_nodes = all_devices
        for node in device_nodes:
            device_tag = node.tag
            device_class = librarian.get(device_tag)
            new_one = device_class.new_from_element(node,
                                                    virsh_instance=self.virsh)
            devices.append(new_one)
        return devices

    def set_devices(self, value):
        """
        Define devices based on contents of VMXMLDevices instance
        """
        value_type = type(value)
        if not issubclass(value_type, VMXMLDevices):
            raise xcepts.LibvirtXMLError("Value %s Must be a VMXMLDevices or "
                                         "subclass not a %s"
                                         % (str(value), str(value_type)))
        # Start with clean slate
        exist_dev = self.xmltreefile.find('devices')
        if exist_dev is not None:
            self.del_devices()
        if len(value) > 0:
            devices_element = xml_utils.ElementTree.SubElement(
                self.xmltreefile.getroot(), 'devices')
            for device in value:
                # Separate the element from the tree
                device_element = device.xmltreefile.getroot()
                devices_element.append(device_element)
        self.xmltreefile.write()

    def del_devices(self):
        """
        Remove all devices
        """
        self.xmltreefile.remove_by_xpath('/devices')
        self.xmltreefile.write()

    def get_seclabel(self):
        """
        Return seclabel + child attribute dict or raise LibvirtXML error

        :return: None if no seclabel in xml,
                 dict of seclabel's attributs and children.
        """
        __children_list__ = ['label', 'baselabel', 'imagelabel']

        seclabel_node = self.xmltreefile.find("seclabel")
        # no seclabel tag found in xml.
        if seclabel_node is None:
            raise xcepts.LibvirtXMLError("Seclabel for this domain does not "
                                         "exist")
        seclabel = dict(seclabel_node.items())
        for child_name in __children_list__:
            child_node = seclabel_node.find(child_name)
            if child_node is not None:
                seclabel[child_name] = child_node.text

        return seclabel

    def set_seclabel(self, seclabel_dict):
        """
        Set seclabel of vm. Modify the attributs and children if seclabel
        exists and create a new seclabel if seclabel is not found in
        xmltreefile.
        """
        __attributs_list__ = ['type', 'model', 'relabel']
        __children_list__ = ['label', 'baselabel', 'imagelabel']

        # check the type of seclabel_dict.
        if not isinstance(seclabel_dict, dict):
            raise xcepts.LibvirtXMLError("seclabel_dict should be a instance of"
                                         "dict, but not a %s.\n"
                                         % type(seclabel_dict))
        seclabel_node = self.xmltreefile.find("seclabel")
        if seclabel_node is None:
            seclabel_node = xml_utils.ElementTree.SubElement(
                self.xmltreefile.getroot(),
                "seclabel")

        for key, value in seclabel_dict.items():
            if key in __children_list__:
                child_node = seclabel_node.find(key)
                if child_node is None:
                    child_node = xml_utils.ElementTree.SubElement(
                        seclabel_node,
                        key)
                child_node.text = value

            elif key in __attributs_list__:
                seclabel_node.set(key, value)

            else:
                continue

        self.xmltreefile.write()

    def del_seclabel(self):
        """
        Remove the seclabel tag from a domain
        """
        try:
            self.xmltreefile.remove_by_xpath("/seclabel")
        except (AttributeError, TypeError):
            pass  # Element already doesn't exist
        self.xmltreefile.write()


class VMXML(VMXMLBase):

    """
    Higher-level manipulations related to VM's XML or guest/host state
    """

    # Must copy these here or there will be descriptor problems
    __slots__ = []

    def __init__(self, hypervisor_type='kvm', virsh_instance=base.virsh):
        """
        Create new VM XML instance
        """
        super(VMXML, self).__init__(virsh_instance=virsh_instance)
        # Setup some bare-bones XML to build upon
        self.xml = u"<domain type='%s'></domain>" % hypervisor_type

    @staticmethod  # static method (no self) needed b/c calls VMXML.__new__
    def new_from_dumpxml(vm_name, options="", virsh_instance=base.virsh):
        """
        Return new VMXML instance from virsh dumpxml command

        :param vm_name: Name of VM to dumpxml
        :param virsh_instance: virsh module or instance to use
        :return: New initialized VMXML instance
        """
        # TODO: Look up hypervisor_type on incoming XML
        vmxml = VMXML(virsh_instance=virsh_instance)
        vmxml['xml'] = virsh_instance.dumpxml(vm_name,
                                              extra=options).stdout.strip()
        return vmxml

    @staticmethod
    def new_from_inactive_dumpxml(vm_name, options="", virsh_instance=base.virsh):
        """
        Return new VMXML instance of inactive domain from virsh dumpxml command

        :param vm_name: Name of VM to dumpxml
        :param options: virsh dumpxml command's options
        :param virsh_instance: virsh module or instance to use
        :return: New initialized VMXML instance
        """
        if options.find("--inactive") == -1:
            options += " --inactive"
        return VMXML.new_from_dumpxml(vm_name, options, virsh_instance)

    @staticmethod
    def get_device_class(type_name):
        """
        Return class that handles type_name devices, or raise exception.
        """
        return librarian.get(type_name)

    def undefine(self, options=None):
        """Undefine this VM with libvirt retaining XML in instance"""
        return self.virsh.remove_domain(self.vm_name, options)

    def define(self):
        """Define VM with virsh from this instance"""
        result = self.virsh.define(self.xml)
        if result.exit_status:
            logging.debug("Define %s failed.\n"
                          "Detail: %s.", self.vm_name, result.stderr)
            return False
        return True

    def sync(self, options=None):
        """Rebuild VM with the config file."""
        # If target vm no longer exist, this will raise an exception.
        try:
            backup = self.new_from_dumpxml(self.vm_name)
        except IOError:
            logging.debug("Failed to backup %s.", self.vm_name)
            backup = None

        if not self.undefine(options):
            raise xcepts.LibvirtXMLError("Failed to undefine %s."
                                         % self.vm_name)
        if not self.define():
            if backup:
                backup.define()
            raise xcepts.LibvirtXMLError("Failed to define %s, from %s."
                                         % (self.vm_name, self.xml))

    @staticmethod
    def vm_rename(vm, new_name, uuid=None, virsh_instance=base.virsh):
        """
        Rename a vm from its XML.

        :param vm: VM class type instance
        :param new_name: new name of vm
        :param uuid: new_vm's uuid, if None libvirt will generate.
        :return: a new VM instance
        """
        if vm.is_alive():
            vm.destroy(gracefully=True)
        vmxml = VMXML.new_from_dumpxml(vm_name=vm.name,
                                       virsh_instance=virsh_instance)
        backup = vmxml.copy()
        # can't do in-place rename, must operate on XML
        if not vmxml.undefine():
            del vmxml  # clean up temporary files
            raise xcepts.LibvirtXMLError("Error reported while undefining VM")
        # Alter the XML
        vmxml.vm_name = new_name
        if uuid is None:
            # invalidate uuid so libvirt will regenerate
            del vmxml.uuid
            vm.uuid = None
        else:
            vmxml.uuid = uuid
            vm.uuid = uuid
        # Re-define XML to libvirt
        logging.debug("Rename %s to %s.", vm.name, new_name)
        # error message for failed define
        error_msg = "Error reported while defining VM:\n"
        try:
            if not vmxml.define():
                raise xcepts.LibvirtXMLError(error_msg + "%s"
                                             % vmxml.get('xml'))
        except error.CmdError, detail:
            del vmxml  # clean up temporary files
            # Allow exceptions thrown here since state will be undefined
            backup.define()
            raise xcepts.LibvirtXMLError(error_msg + "%s" % detail)
        # Keep names uniform
        vm.name = new_name
        return vm

    @staticmethod
    def set_vm_vcpus(vm_name, value, current=None, virsh_instance=base.virsh):
        """
        Convenience method for updating 'vcpu' and 'current' attribute property
        of a defined VM

        :param vm_name: Name of defined vm to change vcpu elemnet data
        :param value: New data value, None to delete.
        :param current: New current value, None will not change current value
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        if value is not None:
            if current is not None:
                if current > value:
                    raise xcepts.LibvirtXMLError(
                        "The cpu current value %s is larger than max number %s"
                        % (current, value))
                else:
                    vmxml['vcpu'] = value  # call accessor method to change XML
                    vmxml['current_vcpu'] = current
        else:  # value is None
            del vmxml.vcpu
        vmxml.undefine()
        vmxml.define()
        # Temporary files for vmxml cleaned up automatically
        # when it goes out of scope here.

    @staticmethod
    def check_cpu_mode(mode):
        """
        Check input cpu mode invalid or not.

        :param mode: the mode of cpu:'host-model'...
        """
        # Possible values for the mode attribute are:
        # "custom", "host-model", "host-passthrough"
        cpu_mode = ["custom", "host-model", "host-passthrough"]
        if mode.strip() not in cpu_mode:
            raise xcepts.LibvirtXMLError(
                "The cpu mode '%s' is invalid!" % mode)

    def get_disk_all(self):
        """
        Return VM's disk from XML definition, None if not set
        """
        disk_nodes = self.xmltreefile.find('devices').findall('disk')
        disks = {}
        for node in disk_nodes:
            dev = node.find('target').get('dev')
            disks[dev] = node
        return disks

    @staticmethod
    def get_disk_source(vm_name, option="", virsh_instance=base.virsh):
        """
        Get block device  of a defined VM's disks.

        :param vm_name: Name of defined vm.
        :param option: extra option.
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, option,
                                       virsh_instance=virsh_instance)
        disks = vmxml.get_disk_all()
        return disks.values()

    @staticmethod
    def get_disk_blk(vm_name, virsh_instance=base.virsh):
        """
        Get block device  of a defined VM's disks.

        :param vm_name: Name of defined vm.
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        disks = vmxml.get_disk_all()
        return disks.keys()

    @staticmethod
    def get_disk_count(vm_name, virsh_instance=base.virsh):
        """
        Get count of VM's disks.

        :param vm_name: Name of defined vm.
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        disks = vmxml.get_disk_all()
        if disks is not None:
            return len(disks)
        return 0

    @staticmethod
    def check_disk_exist(vm_name, disk_src, virsh_instance=base.virsh):
        """
        Check if given disk exist in VM.

        :param vm_name: Domain name.
        :param disk_src: Domian disk source path or darget dev.
        :return: True/False
        """
        found = False
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        if not vmxml.get_disk_count(vm_name, virsh_instance=virsh_instance):
            raise xcepts.LibvirtXMLError("No disk in domain %s." % vm_name)
        blk_list = vmxml.get_disk_blk(vm_name, virsh_instance=virsh_instance)
        disk_list = vmxml.get_disk_source(vm_name, virsh_instance=virsh_instance)
        try:
            file_list = []
            for disk in disk_list:
                file_list.append(disk.find('source').get('file'))
        except AttributeError:
            logging.debug("No 'file' type disk.")
        if disk_src in file_list + blk_list:
            found = True
        return found

    @staticmethod
    def check_disk_type(vm_name, disk_src, disk_type, virsh_instance=base.virsh):
        """
        Check if disk type is correct in VM

        :param vm_name: Domain name.
        :param disk_src: Domain disk source path
        :return: True/False
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        if not vmxml.get_disk_count(vm_name, virsh_instance=virsh_instance):
            raise xcepts.LibvirtXMLError("No disk in domain %s." % vm_name)
        disks = vmxml.get_disk_source(vm_name, virsh_instance=virsh_instance)

        found = False
        try:
            for disk in disks:
                disk_dev = ""
                if disk_type == "file":
                    disk_dev = disk.find('source').get('file')
                elif disk_type == "block":
                    disk_dev = disk.find('source').get('dev')
                if disk_src == disk_dev:
                    found = True
        except AttributeError:
            logging.debug("No '%s' type disk." % disk_type)

        return found

    @staticmethod
    def get_numa_params(vm_name, virsh_instance=base.virsh):
        """
        Return VM's numa setting from XML definition
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        return vmxml.numa

    def get_primary_serial(self):
        """
        Get a dict with primary serial features.
        """
        xmltreefile = self.__dict_get__('xml')
        primary_serial = xmltreefile.find('devices').find('serial')
        serial_features = {}
        serial_type = primary_serial.get('type')
        serial_port = primary_serial.find('target').get('port')
        # Support node here for more features
        serial_features['serial'] = primary_serial
        # Necessary features
        serial_features['type'] = serial_type
        serial_features['port'] = serial_port
        return serial_features

    @staticmethod
    def set_primary_serial(vm_name, dev_type, port, path=None,
                           virsh_instance=base.virsh):
        """
        Set primary serial's features of vm_name.

        :param vm_name: Name of defined vm to set primary serial.
        :param dev_type: the type of ``serial:pty,file...``
        :param port: the port of serial
        :param path: the path of serial, it is not necessary for pty
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        xmltreefile = vmxml.__dict_get__('xml')
        try:
            serial = vmxml.get_primary_serial()['serial']
        except AttributeError:
            logging.debug("Can not find any serial, now create one.")
            # Create serial tree, default is pty
            serial = xml_utils.ElementTree.SubElement(
                xmltreefile.find('devices'),
                'serial', {'type': 'pty'})
            # Create elements of serial target, default port is 0
            xml_utils.ElementTree.SubElement(serial, 'target', {'port': '0'})

        serial.set('type', dev_type)
        serial.find('target').set('port', port)
        # path may not be exist.
        if path is not None:
            serial.find('source').set('path', path)
        else:
            try:
                source = serial.find('source')
                serial.remove(source)
            except AssertionError:
                pass  # Element not found, already removed.
        xmltreefile.write()
        vmxml.set_xml(xmltreefile.name)
        vmxml.undefine()
        vmxml.define()

    @staticmethod
    def set_agent_channel(vm_name):
        """
        Add channel for guest agent running

        :param vm_name: Name of defined vm to set agent channel
        """
        vmxml = VMXML.new_from_dumpxml(vm_name)

        try:
            exist = vmxml.__dict_get__('xml').find('devices').findall('channel')
            findc = 0
            for ec in exist:
                if ec.find('target').get('name') == "org.qemu.guest_agent.0":
                    findc = 1
                    break
            if findc == 0:
                raise AttributeError("Cannot find guest agent channel")
        except AttributeError:
            channel = vmxml.get_device_class('channel')(type_name='unix')
            channel.add_source(mode='bind',
                               path='/var/lib/libvirt/qemu/guest.agent')
            channel.add_target(type='virtio',
                               name='org.qemu.guest_agent.0')
            vmxml.devices = vmxml.devices.append(channel)
            vmxml.define()

    @staticmethod
    def remove_agent_channel(vm_name):
        """
        Delete channel for guest agent

        :param vm_name: Name of defined vm to remove agent channel
        """
        vmxml = VMXML.new_from_dumpxml(vm_name)

        try:
            exist = vmxml.__dict_get__('xml').find('devices').findall('channel')
            for ec in exist:
                if ec.find('target').get('name') == "org.qemu.guest_agent.0":
                    channel = vmxml.get_device_class('channel')(type_name='unix')
                    channel.add_source(mode='bind',
                                       path=ec.find('source').get('path'))
                    channel.add_target(type='virtio',
                                       name=ec.find('target').get('name'))
                    vmxml.del_device(channel)
            vmxml.define()
        except AttributeError:
            raise xcepts.LibvirtXMLError("Fail to remove agent channel!")

    def get_iface_all(self):
        """
        Get a dict with interface's mac and node.
        """
        iface_nodes = self.xmltreefile.find('devices').findall('interface')
        interfaces = {}
        for node in iface_nodes:
            mac_addr = node.find('mac').get('address')
            interfaces[mac_addr] = node
        return interfaces

    @staticmethod
    def get_iface_by_mac(vm_name, mac, virsh_instance=base.virsh):
        """
        Get the interface if mac is matched.

        :param vm_name: Name of defined vm.
        :param mac: a mac address.
        :return: return a dict include main interface's features
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        interfaces = vmxml.get_iface_all()
        try:
            interface = interfaces[mac]
        except KeyError:
            interface = None
        if interface is not None:  # matched mac exists.
            iface_type = interface.get('type')
            source = interface.find('source').get(iface_type)
            features = {}
            features['type'] = iface_type
            features['mac'] = mac
            features['source'] = source
            return features
        else:
            return None

    @staticmethod
    def get_iface_dev(vm_name, virsh_instance=base.virsh):
        """
        Return VM's interface device from XML definition, None if not set
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        ifaces = vmxml.get_iface_all()
        if ifaces:
            return ifaces.keys()
        return None

    @staticmethod
    def get_first_mac_by_name(vm_name, virsh_instance=base.virsh):
        """
        Convenience method for getting first mac of a defined VM

        :param: vm_name: Name of defined vm to get mac
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, virsh_instance=virsh_instance)
        xmltreefile = vmxml.__dict_get__('xml')
        try:
            iface = xmltreefile.find('devices').find('interface')
            return iface.find('mac').get('address')
        except AttributeError:
            return None

    @staticmethod
    def get_iftune_params(vm_name, options="", virsh_instance=base.virsh):
        """
        Return VM's interface tuning setting from XML definition
        """
        vmxml = VMXML.new_from_dumpxml(vm_name, options=options,
                                       virsh_instance=virsh_instance)
        xmltreefile = vmxml.__dict_get__('xml')
        iftune_params = {}
        bandwidth = None
        try:
            bandwidth = xmltreefile.find('devices/interface/bandwidth')
            try:
                iftune_params['inbound'] = bandwidth.find(
                    'inbound').get('average')
                iftune_params['outbound'] = bandwidth.find(
                    'outbound').get('average')
            except AttributeError:
                logging.error("Can't find <inbound> or <outbound> element")
        except AttributeError:
            logging.error("Can't find <bandwidth> element")

        return iftune_params

    def get_net_all(self):
        """
        Return VM's net from XML definition, None if not set
        """
        xmltreefile = self.__dict_get__('xml')
        net_nodes = xmltreefile.find('devices').findall('interface')
        nets = {}
        for node in net_nodes:
            dev = node.find('target').get('dev')
            nets[dev] = node
        return nets

    # TODO re-visit this method after the libvirt_xml.devices.interface module
    #     is implemented
    @staticmethod
    def get_net_dev(vm_name):
        """
        Get net device of a defined VM's nets.

        :param vm_name: Name of defined vm.
        """
        vmxml = VMXML.new_from_dumpxml(vm_name)
        nets = vmxml.get_net_all()
        if nets is not None:
            return nets.keys()
        return None

    @staticmethod
    def set_cpu_mode(vm_name, mode='host-model'):
        """
        Set cpu's mode of VM.

        :param vm_name: Name of defined vm to set cpu mode.
        :param mode: the mode of cpu:'host-model'...
        """
        vmxml = VMXML.new_from_dumpxml(vm_name)
        vmxml.check_cpu_mode(mode)
        xmltreefile = vmxml.__dict_get__('xml')
        try:
            cpu = xmltreefile.find('/cpu')
            logging.debug("Current cpu mode is '%s'!", cpu.get('mode'))
            cpu.set('mode', mode)
        except AttributeError:
            logging.debug("Can not find any cpu, now create one.")
            cpu = xml_utils.ElementTree.SubElement(xmltreefile.getroot(),
                                                   'cpu', {'mode': mode})
        xmltreefile.write()
        vmxml.undefine()
        vmxml.define()

    def add_device(self, value):
        """
        Add a device into VMXML.

        :param value: instance of device in libvirt_xml/devices/
        """
        devices = self.get_devices()
        for device in devices:
            if device == value:
                logging.debug("Device %s is already in VM %s.", value, self)
                return
        devices.append(value)
        self.set_devices(devices)

    def del_device(self, value):
        """
        Remove a device from VMXML

        :param value: instance of device in libvirt_xml/devices/
        """
        devices = self.get_devices()
        not_found = True
        for device in devices:
            if device == value:
                not_found = False
                devices.remove(device)
                break
        if not_found:
            logging.debug("Device %s does not exist in VM %s." % self)
            return
        self.set_devices(devices)

    @staticmethod
    def add_security_info(vmxml, passwd):
        """
        Add passwd for graphic

        :param vmxml: instance of VMXML
        :param passwd: Password you want to set
        """
        devices = vmxml.devices
        graphics_index = devices.index(devices.by_device_tag('graphics')[0])
        graphics = devices[graphics_index]
        graphics.passwd = passwd
        vmxml.devices = devices
        vmxml.define()

    def add_hostdev(self, source_address, mode='subsystem',
                    type='pci',
                    managed='yes'):
        """
        Add a hostdev device to guest.
        """
        dev = self.get_device_class('hostdev')()
        dev.mode = mode
        dev.type = type
        dev.managed = managed
        dev.source_address = source_address
        self.add_device(dev)


class VMCPUXML(VMXML):

    """
    Higher-level manipulations related to VM's XML(CPU)
    """

    # Must copy these here or there will be descriptor problems
    __slots__ = ('model', 'vendor', 'feature_list',)

    def __init__(self, virsh_instance=base.virsh, vm_name='', mode='host-model'):
        """
        Create new VMCPU XML instance
        """
        # The set action is for test.
        accessors.XMLElementText(property_name="model",
                                 libvirtxml=self,
                                 forbidden=['del'],
                                 parent_xpath='/cpu',
                                 tag_name='model')
        accessors.XMLElementText(property_name="vendor",
                                 libvirtxml=self,
                                 forbidden=['del'],
                                 parent_xpath='/cpu',
                                 tag_name='vendor')
        # This will skip self.get_feature_list() defined below
        accessors.AllForbidden(property_name="feature_list",
                               libvirtxml=self)
        super(VMCPUXML, self).__init__(virsh_instance=virsh_instance)
        # Setup some bare-bones XML to build upon
        self.set_cpu_mode(vm_name, mode)
        self['xml'] = self.__dict_get__('virsh').dumpxml(vm_name,
                                                         extra="--update-cpu").stdout.strip()

    def get_feature_list(self):
        """
        Accessor method for feature_list property (in __slots__)
        """
        feature_list = []
        xmltreefile = self.__dict_get__('xml')
        for feature_node in xmltreefile.findall('/cpu/feature'):
            feature_list.append(feature_node)
        return feature_list

    def get_feature_name(self, num):
        """
        Get assigned feature name

        :param num: Assigned feature number
        :return: Assigned feature name
        """
        count = len(self.feature_list)
        if num >= count:
            raise xcepts.LibvirtXMLError("Get %d from %d features"
                                         % (num, count))
        feature_name = self.feature_list[num].get('name')
        return feature_name

    def remove_feature(self, num):
        """
        Remove a assigned feature from xml

        :param num: Assigned feature number
        """
        xmltreefile = self.__dict_get__('xml')
        count = len(self.feature_list)
        if num >= count:
            raise xcepts.LibvirtXMLError("Remove %d from %d features"
                                         % (num, count))
        feature_remove_node = self.feature_list[num]
        cpu_node = xmltreefile.find('/cpu')
        cpu_node.remove(feature_remove_node)

    @staticmethod
    def check_feature_name(value):
        """
        Check feature name valid or not.

        :param value: The feature name
        :return: True if check pass
        """
        sys_feature = []
        cpu_xml_file = open('/proc/cpuinfo', 'r')
        for line in cpu_xml_file.readline():
            if line.find('flags') != -1:
                feature_names = line.split(':')[1].strip()
                sys_sub_feature = feature_names.split(' ')
                sys_feature = list(set(sys_feature + sys_sub_feature))
        return (value in sys_feature)

    def set_feature(self, num, value):
        """
        Set a assigned feature value to xml

        :param num: Assigned feature number
        :param value: The feature name modified to
        """
        count = len(self.feature_list)
        if num >= count:
            raise xcepts.LibvirtXMLError("Set %d from %d features"
                                         % (num, count))
        feature_set_node = self.feature_list[num]
        feature_set_node.set('name', value)

    def add_feature(self, value):
        """
        Add a feature Element to xml

        :param num: Assigned feature number
        """
        xmltreefile = self.__dict_get__('xml')
        cpu_node = xmltreefile.find('/cpu')
        xml_utils.ElementTree.SubElement(cpu_node, 'feature', {'name': value})


class VMClockXML(VMXML):

    """
    Higher-level manipulations related to VM's XML(Clock)
    """

    # Must copy these here or there will be descriptor problems
    __slots__ = ('offset', 'timezone', 'adjustment', 'timers')

    def __init__(self, virsh_instance=base.virsh, offset="utc"):
        """
        Create new VMClock XML instance
        """
        # The set action is for test.
        accessors.XMLAttribute(property_name="offset",
                               libvirtxml=self,
                               forbidden=[],
                               parent_xpath='/',
                               tag_name='clock',
                               attribute='offset')
        accessors.XMLAttribute(property_name="timezone",
                               libvirtxml=self,
                               forbidden=[],
                               parent_xpath='/',
                               tag_name='clock',
                               attribute='timezone')
        accessors.XMLAttribute(property_name="adjustment",
                               libvirtxml=self,
                               forbidden=[],
                               parent_xpath='/',
                               tag_name='clock',
                               attribute='adjustment')
        accessors.XMLElementList(property_name="timers",
                                 libvirtxml=self,
                                 forbidden=[],
                                 parent_xpath="/clock",
                                 marshal_from=self.marshal_from_timer,
                                 marshal_to=self.marshal_to_timer)
        super(VMClockXML, self).__init__(virsh_instance=virsh_instance)
        # Set default offset for clock
        self.offset = offset

    def from_dumpxml(self, vm_name, virsh_instance=base.virsh):
        """Helper to load xml from domain."""
        self.xml = VMXML.new_from_dumpxml(vm_name,
                                          virsh_instance=virsh_instance).xml

    # Sub-element of clock
    class Timer(VMXML):

        """Timer element of clock"""

        __slots__ = ('name', 'present')

        def __init__(self, virsh_instance=base.virsh, timer_name="tsc"):
            """
            Create new Timer XML instance
            """
            # The set action is for test.
            accessors.XMLAttribute(property_name="name",
                                   libvirtxml=self,
                                   forbidden=[],
                                   parent_xpath='/clock',
                                   tag_name='timer',
                                   attribute='name')
            accessors.XMLAttribute(property_name="present",
                                   libvirtxml=self,
                                   forbidden=[],
                                   parent_xpath='/clock',
                                   tag_name='timer',
                                   attribute='present')
            super(VMClockXML.Timer, self).__init__(virsh_instance=virsh_instance)
            # name is mandatory for timer
            self.name = timer_name

        def update(self, attr_dict):
            for attr, value in attr_dict.items():
                setattr(self, attr, value)

    @staticmethod
    def marshal_from_timer(item, index, libvirtxml):
        """Convert a Timer instance into tag + attributes"""
        del index
        del libvirtxml
        timer = item.xmltreefile.find("clock/timer")
        try:
            return (timer.tag, dict(timer.items()))
        except AttributeError:  # Didn't find timer
            raise xcepts.LibvirtXMLError("Expected a list of timer "
                                         "instances, not a %s" % str(item))

    @staticmethod
    def marshal_to_timer(tag, attr_dict, index, libvirtxml):
        """Convert a tag + attributes to a Timer instance"""
        del index
        if tag == 'timer':
            newone = VMClockXML.Timer(virsh_instance=libvirtxml.virsh)
            newone.update(attr_dict)
            return newone
        else:
            return None


class VMCPUTune(base.LibvirtXMLBase):

    """
    CPU tuning tag XML class

    Elements:
        vcpupins:             list of dict - vcpu, cpuset
        emulatorpin:          attribute    - cpuset
        shares:               int
        period:               int
        quota:                int
        emulator_period:      int
        emulator_quota:       int
    """

    __slots__ = ('vcpupins', 'emulatorpin', 'shares', 'period', 'quota',
                 'emulator_period', 'emulator_quota')

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementList('vcpupins', self, parent_xpath='/',
                                 marshal_from=self.marshal_from_vcpupins,
                                 marshal_to=self.marshal_to_vcpupins)
        accessors.XMLAttribute('emulatorpin', self, parent_xpath='/',
                               tag_name='emulatorpin', attribute='cpuset')
        for slot in self.__all_slots__:
            if slot in ('shares', 'period', 'quota', 'emulator_period',
                        'emulator_quota'):
                accessors.XMLElementInt(slot, self, parent_xpath='/',
                                        tag_name=slot)
        super(self.__class__, self).__init__(virsh_instance=virsh_instance)
        self.xml = '<cputune/>'

    @staticmethod
    def marshal_from_vcpupins(item, index, libvirtxml):
        """
        Convert a dict to vcpupin tag and attributes.
        """
        del index
        del libvirtxml
        if not isinstance(item, dict):
            raise xcepts.LibvirtXMLError("Expected a dictionary of host "
                                         "attributes, not a %s"
                                         % str(item))
        return ('vcpupin', dict(item))

    @staticmethod
    def marshal_to_vcpupins(tag, attr_dict, index, libvirtxml):
        """
        Convert a vcpupin tag and attributes to a dict.
        """
        del index
        del libvirtxml
        if tag != 'vcpupin':
            return None
        return dict(attr_dict)

########NEW FILE########
__FILENAME__ = vol_xml
"""
Module simplifying manipulation of XML described at
http://libvirt.org/formatstorage.html#StorageVol
"""

from virttest.libvirt_xml import base, accessors


class VolXMLBase(base.LibvirtXMLBase):

    """
    Accessor methods for VolXML class.

    Properties:
        name: string, operates on XML name tag
        key: string, operates on key tag
        capacity: integer, operates on capacity attribute of capacity tag
        allocation: integer, operates on allocation attribute of allocation
        format: string, operates on type attribute of format tag
        path: string, operates on path attribute of path tag
        owner, integer, operates on owner attribute of owner tag
        group, integer, operates on group attribute of group tag
        mode: string, operates on mode attribute of mode tag
        label: string, operates on label attribute of label tag
        compat: string, operates on compat attribute of label tag
        lazy_refcounts: bool, True/False
    """

    __slots__ = ('name', 'key', 'capacity', 'allocation', 'format', 'path',
                 'owner', 'group', 'mode', 'label', 'compat', 'lazy_refcounts')

    __uncompareable__ = base.LibvirtXMLBase.__uncompareable__

    __schema_name__ = "storagevol"

    def __init__(self, virsh_instance=base.virsh):
        accessors.XMLElementText('name', self, parent_xpath='/',
                                 tag_name='name')
        accessors.XMLElementText('key', self, parent_xpath='/',
                                 tag_name='key')
        accessors.XMLElementInt('capacity', self, parent_xpath='/',
                                tag_name='capacity')
        accessors.XMLElementInt('allocation', self, parent_xpath='/',
                                tag_name='allocation')
        accessors.XMLAttribute('format', self, parent_xpath='/target',
                               tag_name='format', attribute='type')
        accessors.XMLElementText('path', self, parent_xpath='/target',
                                 tag_name='path')
        accessors.XMLElementInt('owner', self,
                                parent_xpath='/target/permissions',
                                tag_name='owner')
        accessors.XMLElementInt('group', self,
                                parent_xpath='/target/permissions',
                                tag_name='group')
        accessors.XMLElementText('mode', self,
                                 parent_xpath='/target/permissions',
                                 tag_name='mode')
        accessors.XMLElementText('label', self,
                                 parent_xpath='/target/permissions',
                                 tag_name='label')
        accessors.XMLElementText('compat', self, parent_xpath='/target',
                                 tag_name='compat')
        accessors.XMLElementBool('lazy_refcounts', self,
                                 parent_xpath='/target/features',
                                 tag_name='lazy_refcounts')
        super(VolXMLBase, self).__init__(virsh_instance=virsh_instance)


class VolXML(VolXMLBase):

    """
    Manipulators of a Virtual Vol through it's XML definition.
    """

    __slots__ = []

    def __init__(self, vol_name='default', virsh_instance=base.virsh):
        """
        Initialize new instance with empty XML
        """
        super(VolXML, self).__init__(virsh_instance=virsh_instance)
        self.xml = u"<volume><name>%s</name></volume>" % vol_name

    @staticmethod
    def new_from_vol_dumpxml(vol_name, pool_name, virsh_instance=base.virsh):
        """
        Return new VolXML instance from virsh vol-dumpxml command

        :param vol_name: Name of vol to vol-dumpxml
        :param virsh_instance: virsh module or instance to use
        :return: New initialized VolXML instance
        """
        volxml = VolXML(virsh_instance=virsh_instance)
        volxml['xml'] = virsh_instance.vol_dumpxml(vol_name, pool_name)\
                                      .stdout.strip()
        return volxml

    @staticmethod
    def get_vol_details_by_name(vol_name, pool_name, virsh_instance=base.virsh):
        """
        Return volume xml dictionary by Vol's uuid or name.

        :param vol_name: Vol's name
        :return: volume xml dictionary
        """
        volume_xml = {}
        vol_xml = VolXML.new_from_vol_dumpxml(vol_name, pool_name,
                                              virsh_instance)
        volume_xml['key'] = vol_xml.key
        volume_xml['path'] = vol_xml.path
        volume_xml['format'] = vol_xml.format
        volume_xml['capacity'] = vol_xml.capacity
        volume_xml['allocation'] = vol_xml.allocation
        return volume_xml

    @staticmethod
    def new_vol(**dargs):
        """
        Return a new VolXML instance and set properties from dargs

        :param dargs: param dictionary
        :return: new VolXML instance
        """
        new_one = VolXML(virsh_instance=base.virsh)
        for key, value in dargs.items():
            setattr(new_one, key, value)
        return new_one

########NEW FILE########
__FILENAME__ = xcepts
"""
Module of common exceptions used in libvirt_xml package
"""


class LibvirtXMLError(Exception):

    """
    Error originating within libvirt_xml module
    """

    def __init__(self, details=''):
        self.details = details
        Exception.__init__(self)

    def __str__(self):
        return str(self.details)


class LibvirtXMLAccessorError(LibvirtXMLError):

    """
    LibvirtXMLError related to an accessor generator class/method
    """
    pass


class LibvirtXMLForbiddenError(LibvirtXMLError):

    """
    LibvirtXMLError raised when operating on a property is prohibited
    """
    pass


class LibvirtXMLNotFoundError(LibvirtXMLError):

    """
    LibvirtXMLError related when an element cannot be found
    """
    pass

########NEW FILE########
__FILENAME__ = libvirt_xml_unittest
#!/usr/bin/python

import unittest
import os
import shutil
import logging

import common
from virttest import xml_utils, utils_misc, data_dir
from virttest.virsh_unittest import FakeVirshFactory
from autotest.client import utils
from autotest.client.shared import error
from virttest.libvirt_xml import accessors, vm_xml, xcepts, network_xml, base
from virttest.libvirt_xml import nodedev_xml
from virttest.libvirt_xml.devices import librarian
from virttest.libvirt_xml.devices import base as devices_base
from virttest.libvirt_xml import capability_xml

# save a copy
ORIGINAL_DEVICE_TYPES = list(librarian.DEVICE_TYPES)
UUID = "8109c109-1551-cb11-8e2c-bc43745252ef"
_CAPABILITIES = """<capabilities><host>
<uuid>%s</uuid><cpu><arch>x86_64</arch><model>
SandyBridge</model><vendor>Intel</vendor><topology sockets='1' cores='1'
threads='1'/><feature name='vme'/></cpu><power_management><suspend_mem/>
<suspend_disk/></power_management><migration_features><live/><uri_transports>
<uri_transport>tcp</uri_transport></uri_transports></migration_features>
<topology><cells num='1'><cell id='0'><cpus num='1'><cpu id='0'/></cpus></cell>
</cells></topology><secmodel><model>selinux</model><doi>0</doi></secmodel>
</host><guest><os_type>hvm</os_type><arch name='x86_64'><wordsize>64</wordsize>
<emulator>/usr/libexec/qemu-kvm</emulator><machine>rhel6.3.0</machine><machine
canonical='rhel6.3.0'>pc</machine><domain type='qemu'></domain><domain
type='kvm'><emulator>/usr/libexec/qemu-kvm</emulator></domain></arch><features>
<cpuselection/><deviceboot/><acpi default='on' toggle='yes'/><apic default='on'
toggle='no'/></features></guest></capabilities>"""
CAPABILITIES = _CAPABILITIES % UUID


class LibvirtXMLTestBase(unittest.TestCase):

    # Override instance methods needed for testing

    # domain_xml
    # usage:
    #    xml = __domain_xml__ % (name, uuid)
    __domain_xml__ = ('<domain type="kvm">'
                      '    <name>%s</name>'
                      '    <uuid>%s</uuid>'
                      '    <cputune>'
                      '      <vcpupin vcpu="0" cpuset="1-4,^2"/>'
                      '      <vcpupin vcpu="1" cpuset="0,1"/>'
                      '      <vcpupin vcpu="2" cpuset="2,3"/>'
                      '      <vcpupin vcpu="3" cpuset="0,4"/>'
                      '      <emulatorpin cpuset="1-3"/>'
                      '      <shares>2048</shares>'
                      '      <period>1000000</period>'
                      '      <quota>-1</quota>'
                      '      <emulator_period>1000000</emulator_period>'
                      '      <emulator_quota>-1</emulator_quota>'
                      '    </cputune>'
                      '    <devices>'  # Tests below depend on device order

                      '       <serial type="pty">'
                      '           <target port="0"/>'
                      '       </serial>'
                      '       <serial type="pty">'
                      '           <target port="1"/>'
                      '           <source path="/dev/null"/>'
                      '       </serial>'
                      '       <serial type="tcp">'
                      '         <source mode="connect" host="1.2.3.4"\
                                                        service="2445"/>'
                      '         <protocol type="raw"/>'
                      '         <target port="2"/>'
                      '       </serial>'
                      '       <serial type="udp">'
                      '         <source mode="bind" host="1.2.3.4"\
                                                        service="2445"/>'
                      '         <source mode="connect" host="4.3.2.1"\
                                                        service="5442"/>'
                      '         <target port="3"/>'
                      '       </serial>'

                      '       <channel type="foo1">'
                      '         <source mode="foo2" path="foo3" />'
                      '         <target name="foo4" type="foo5" />'
                      '       </channel>'
                      '       <channel type="bar1">'
                      '         <source mode="bar2" path="bar3" />'
                      '         <target name="bar4" type="bar5" />'
                      '       </channel>'

                      '       <graphics type="vnc" port="-1" autoport="yes"/>'

                      '       <disk type="file" device="disk">'
                      '         <driver name="qemu" type="qcow2"/>'
                      '         <source file="/foo/bar/baz.qcow2"/>'
                      '         <target dev="vda" bus="virtio"/>'
                      '         <address type="pci" domain="0x0000"'
                      '               bus="0x00" slot="0x04" function="0x0"/>'
                      '       </disk>'

                      '    </devices>'

                      '    <seclabel type="sec_type" model="sec_model">'
                      '       <label>sec_label</label>'
                      '       <baselabel>sec_baselabel</baselabel>'
                      '       <imagelabel>sec_imagelabel</imagelabel>'
                      '    </seclabel>'

                      '</domain>')

    __doms_dir__ = None

    @staticmethod
    def _capabilities(option='', **dargs):
        # Compacted to save space
        return CAPABILITIES

    @staticmethod
    def _domuuid(name, **dargs):
        return "ddb0cf86-5ba8-4f83-480a-d96f54339219"

    @staticmethod
    def _define(file_path, **dargs):
        vmxml = xml_utils.XMLTreeFile(file_path)
        dom_name = vmxml.find('name').text
        xml_path = os.path.join(LibvirtXMLTestBase.__doms_dir__,
                                '%s.xml' % dom_name)
        shutil.copy(file_path, xml_path)

    @staticmethod
    def _dumpxml(name, to_file="", **dargs):
        """
        Get a xml from name.
        """
        if not name:
            cmd = "virsh dumpxml %s" % name
            stdout = "error: command 'dumpxml' requires <domain> option"
            stderr = stdout
            exit_status = 1
            result = utils.CmdResult(cmd, stdout, stderr, exit_status)
            raise error.CmdError(cmd, result,
                                 "Virsh Command returned non-zero exit status")

        file_path = os.path.join(LibvirtXMLTestBase.__doms_dir__,
                                 '%s.xml' % name)
        if os.path.exists(file_path):
            xml_file = open(file_path, 'r')
            domain_xml = xml_file.read()
        else:
            xml_file = open(file_path, 'w')
            domain_xml = LibvirtXMLTestBase.__domain_xml__ % (name,
                                                              LibvirtXMLTestBase._domuuid(None))
            xml_file.write(domain_xml)
        xml_file.close()

        cmd = "virsh dumpxml %s" % name
        stdout = domain_xml
        stderr = ""
        exit_status = 0
        return utils.CmdResult(cmd, stdout, stderr, exit_status)

    @staticmethod
    def _nodedev_dumpxml(name, options="", to_file=None, **dargs):
        # Must mirror virsh.nodedev_dumpxml() API but can't test this option
        if options != "":
            raise ValueError('Dummy virsh for testing does not support options'
                             ' parameter')
        if to_file is not None:
            raise ValueError('Dummy virsh for testing does not support to_file'
                             ' parameter')
        if name is not 'pci_0000_00_00_0':
            raise ValueError('Dummy virsh for testing only support '
                             ' device name pci_0000_00_00_0')
        xml = ("<device>"
               "<name>pci_0000_00_00_0</name>"
               "<path>/sys/devices/pci0000:00/0000:00:00.0</path>"
               "<parent>computer</parent>"
               "<capability type='pci'>"
               "<domain>0</domain>"
               "<bus>0</bus>"
               "<slot>0</slot>"
               "<function>0</function>"
               "<product id='0x25c0'>5000X Chipset Memory Controller Hub</product>"
               "<vendor id='0x8086'>Intel Corporation</vendor>"
               "</capability>"
               "</device>")
        return utils.CmdResult('virsh nodedev-dumpxml pci_0000_00_00_0',
                               xml, '', 0)

    def setUp(self):
        self.dummy_virsh = FakeVirshFactory()
        # make a tmp_dir to store informations.
        LibvirtXMLTestBase.__doms_dir__ = os.path.join(data_dir.get_tmp_dir(),
                                                       'domains')
        if not os.path.isdir(LibvirtXMLTestBase.__doms_dir__):
            os.makedirs(LibvirtXMLTestBase.__doms_dir__)

        # Normally not kosher to call super_set, but required here for testing
        self.dummy_virsh.__super_set__('capabilities', self._capabilities)
        self.dummy_virsh.__super_set__('dumpxml', self._dumpxml)
        self.dummy_virsh.__super_set__('domuuid', self._domuuid)
        self.dummy_virsh.__super_set__('define', self._define)
        self.dummy_virsh.__super_set__('nodedev_dumpxml', self._nodedev_dumpxml)

    def tearDown(self):
        librarian.DEVICE_TYPES = list(ORIGINAL_DEVICE_TYPES)
        if os.path.isdir(self.__doms_dir__):
            shutil.rmtree(self.__doms_dir__)


# AccessorsTest.test_XMLElementNest is namespace sensitive
class Baz(base.LibvirtXMLBase):
    __slots__ = ('foobar',)

    def __init__(self, parent, virsh_instance):
        accessors.XMLElementText('foobar', self, ['set', 'del'],
                                 '/', 'baz')
        super(Baz, self).__init__(virsh_instance=virsh_instance)
        # must setup some basic XML inside for this element
        self.xml = """<baz></baz>"""
        # Test nested argument passing
        parent.assertTrue(isinstance(parent, AccessorsTest))
        parent.assertTrue(self.foobar is None)
        # Forbidden should still catch these
        parent.assertRaises(xcepts.LibvirtXMLForbiddenError,
                            self.__setattr__, 'foobar', None)
        parent.assertRaises(xcepts.LibvirtXMLForbiddenError,
                            self.__setitem__, 'foobar', None)
        parent.assertRaises(xcepts.LibvirtXMLForbiddenError,
                            self.__delattr__, 'foobar')
        parent.assertRaises(xcepts.LibvirtXMLForbiddenError,
                            self.__delitem__, 'foobar')


# AccessorsTest.test_XMLElementNest is namespace sensitive
class Bar(base.LibvirtXMLBase):
    __slots__ = ('baz',)

    def __init__(self, parent, virsh_instance):
        subclass_dargs = {'parent': parent,
                          'virsh_instance': virsh_instance}
        accessors.XMLElementNest('baz', self, None,
                                 '/', 'baz', Baz, subclass_dargs)
        super(Bar, self).__init__(virsh_instance=virsh_instance)
        # must setup some basic XML inside for this element
        self.xml = """<bar></bar>"""
        parent.assertTrue(isinstance(parent, AccessorsTest))
        parent.assertRaises(xcepts.LibvirtXMLNotFoundError,
                            self.__getattr__, 'baz')
        parent.assertRaises(xcepts.LibvirtXMLNotFoundError,
                            self.__getitem__, 'baz')
        # Built-in type-checking
        parent.assertRaises(ValueError, self.__setattr__,
                            'baz', True)  # bool() is not a Bar()
        parent.assertRaises(ValueError, self.__setitem__,
                            'baz', None)


class AccessorsTest(LibvirtXMLTestBase):

    def test_type_check(self):
        class bar(object):
            pass

        class foo(bar):
            pass
        # Save some typing
        type_check = accessors.type_check
        foobar = foo()
        self.assertEqual(type_check("foobar", foobar, bar), None)
        self.assertEqual(type_check("foobar", foobar, object), None)
        self.assertRaises(ValueError, type_check, "foobar", foobar, list)
        self.assertRaises(TypeError, type_check, "foobar", foobar, None)
        self.assertRaises(TypeError, type_check, "foobar", None, foobar)
        self.assertRaises(TypeError, type_check, None, "foobar", foobar)

    def test_required_slots(self):
        class Foo(accessors.AccessorGeneratorBase):

            class Getter(accessors.AccessorBase):
                __slots__ = accessors.add_to_slots('foo', 'bar')
                pass
        lvx = base.LibvirtXMLBase(self.dummy_virsh)
        forbidden = ['set', 'del']
        self.assertRaises(ValueError, Foo, 'foobar', lvx, forbidden)
        self.assertRaises(ValueError, Foo, 'foobar', lvx, forbidden, foo='')
        self.assertRaises(ValueError, Foo, 'foobar', lvx, forbidden, bar='')

    def test_accessor_base(self):
        class ABSubclass(accessors.AccessorBase):
            pass
        lvx = base.LibvirtXMLBase(self.dummy_virsh)
        # operation attribute check should fail
        self.assertRaises(ValueError, accessors.AccessorBase,
                          'foobar', lvx, lvx)
        abinst = ABSubclass('Getter', 'foobar', lvx)
        self.assertEqual(abinst.property_name, 'foobar')
        # test call to get_libvirtxml() accessor
        self.assertEqual(abinst.libvirtxml, lvx)

    def test_XMLElementInt(self):
        class FooBar(base.LibvirtXMLBase):
            __slots__ = ('auto_test',
                         'bin_test',
                         'oct_test',
                         'dec_test',
                         'hex_test')
        lvx = FooBar(self.dummy_virsh)
        lvx.xml = ('<integer>'
                   ' <auto>00</auto>'
                   ' <bin>10</bin>'
                   ' <oct>10</oct>'
                   ' <dec>10</dec>'
                   ' <hex>10</hex>'
                   '</integer>')

        name_radix = {'auto': 0, 'bin': 2, 'oct': 8, 'dec': 10, 'hex': 16}
        for name, radix in name_radix.items():
            accessors.XMLElementInt(name + '_test', lvx,
                                    parent_xpath='/',
                                    tag_name=name,
                                    radix=radix)
            self.assertEqual(lvx[name + '_test'], radix)

        self.assertRaises(ValueError,
                          lvx.__setitem__, 'bin_test', 'text')

    def test_AllForbidden(self):
        class FooBar(base.LibvirtXMLBase):
            __slots__ = ('test',)
        lvx = FooBar(self.dummy_virsh)
        accessors.AllForbidden('test', lvx)
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvx.__getitem__, 'test')
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvx.__setitem__, 'test', 'foobar')
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvx.__delitem__, 'test')

    def test_not_enuf_dargs(self):
        class FooBar(base.LibvirtXMLBase):
            __slots__ = ('test',)
        foobar = FooBar(self.dummy_virsh)
        self.assertRaises(ValueError,
                          accessors.XMLElementText, 'test',
                          foobar, '/')
        self.assertRaises(TypeError,
                          accessors.XMLElementText)
        self.assertRaises(TypeError,
                          accessors.XMLElementText, 'test')

    def test_too_many_dargs(self):
        class FooBar(base.LibvirtXMLBase):
            __slots__ = ('test',)
        foobar = FooBar(self.dummy_virsh)
        self.assertRaises(ValueError,
                          accessors.XMLElementText, 'test',
                          foobar, '/', 'foobar')
        self.assertRaises(ValueError,
                          accessors.XMLElementText, 'test',
                          None, None, None, None)

    def test_create_by_xpath(self):
        class FooBar(base.LibvirtXMLBase):
            __slots__ = ('test',)

            def __init__(self, virsh_instance):
                super(FooBar, self).__init__(virsh_instance)
                accessors.XMLElementDict('test', self, None, 'foo/bar', 'baz')
        foobar = FooBar(self.dummy_virsh)
        foobar.xml = '<test></test>'
        test_dict = {'test1': '1', 'test2': '2'}
        foobar.test = test_dict
        self.assertEqual(foobar.test, test_dict)
        element = foobar.xmltreefile.find('foo/bar/baz')
        self.assertTrue(element is not None)
        element_dict = dict(element.items())
        self.assertEqual(test_dict, element_dict)

    def test_XMLElementNest(self):
        class Foo(base.LibvirtXMLBase):
            __slots__ = ('bar',)

            def __init__(self, parent, virsh_instance):
                subclass_dargs = {'parent': parent,
                                  'virsh_instance': virsh_instance}
                accessors.XMLElementNest('bar', self, None,
                                         '/', 'bar', Bar, subclass_dargs)
                super(Foo, self).__init__(virsh_instance=virsh_instance)
                parent.assertTrue(isinstance(parent, AccessorsTest))
                self.set_xml("""
                    <foo>
                        <bar>
                            <baz>foobar</baz>
                        </bar>
                     </foo>""")
                parent.assertTrue(isinstance(self.bar, Bar))
                parent.assertTrue(isinstance(self.bar.baz, Baz))
                parent.assertEqual(self.bar.baz.foobar, 'foobar')
                parent.assertRaises(ValueError, self.bar.__setattr__,
                                    'baz', Bar)  # Baz is not a Bar()

        foo = Foo(parent=self, virsh_instance=self.dummy_virsh)
        self.assertEqual(foo.bar.baz.foobar, 'foobar')
        baz = Baz(parent=self, virsh_instance=self.dummy_virsh)
        # setting foobar is forbidden, have to go the long way around
        baz.xml = """<baz>test value</baz>"""
        bar = foo.bar  # Creates new Bar instance
        bar.baz = baz
        foo.bar = bar  # Point at new Bar instance
        # TODO: Make 'foo.bar.baz = baz' work
        self.assertEqual(foo.bar.baz.foobar, 'test value')
        self.assertTrue(isinstance(foo.bar.baz, Baz))

    def test_XMLElementBool_simple(self):
        class Foo(base.LibvirtXMLBase):
            __slots__ = ('bar', 'baz')

            def __init__(self, virsh_instance):
                accessors.XMLElementBool('bar', self,
                                         parent_xpath='/', tag_name='bar')
                accessors.XMLElementBool('baz', self,
                                         parent_xpath='/', tag_name='bar')
                super(Foo, self).__init__(virsh_instance=virsh_instance)
                self.xml = '<foo/>'
        foo = Foo(self.dummy_virsh)
        self.assertFalse(foo.bar)
        self.assertFalse(foo['bar'])
        self.assertFalse(foo.baz)
        self.assertFalse(foo['baz'])
        foo.bar = True
        self.assertTrue(foo.bar)
        self.assertTrue(foo['bar'])
        self.assertTrue(foo.baz)
        self.assertTrue(foo['baz'])
        del foo.baz
        self.assertFalse(foo.bar)
        self.assertFalse(foo['bar'])
        self.assertFalse(foo.baz)
        self.assertFalse(foo['baz'])

    def test_XMLElementBool_deep(self):
        class Foo(base.LibvirtXMLBase):
            __slots__ = ('bar', 'baz', 'foo')

            def __init__(self, virsh_instance):
                accessors.XMLElementBool('foo', self,
                                         parent_xpath='/l1', tag_name='foo')
                accessors.XMLElementBool('bar', self,
                                         parent_xpath='/l1/l2/l3', tag_name='bar')
                accessors.XMLElementBool('baz', self,
                                         parent_xpath='/l1/l2', tag_name='baz')
                super(Foo, self).__init__(virsh_instance=virsh_instance)
                self.xml = '<root/>'
        foo = Foo(self.dummy_virsh)
        for attr in "foo bar baz".split():
            self.assertFalse(getattr(foo, attr))
        del foo.foo
        for attr in "bar baz".split():
            self.assertFalse(getattr(foo, attr))
        self.assertFalse(foo.foo)
        foo.bar = True
        for attr in "foo baz".split():
            self.assertFalse(getattr(foo, attr))
        self.assertTrue(foo.bar)
        for attr in "foo bar baz".split():
            foo[attr] = True
            self.assertTrue(getattr(foo, attr))
        foo.del_baz()
        for attr in "foo bar".split():
            self.assertTrue(getattr(foo, attr))
        self.assertFalse(foo.baz)

    def test_XMLElementList(self):
        class Whatchamacallit(object):

            def __init__(self, secret_sauce):
                self.secret_sauce = str(secret_sauce)

            @staticmethod
            def from_it(item, index, lvxml):
                if not isinstance(item, Whatchamacallit):
                    raise ValueError
                return ('whatchamacallit',
                        {'secret_sauce': str(item.secret_sauce)})

            @staticmethod
            def to_it(tag, attrs, index, lvxml):
                if not tag.startswith('whatchamacallit'):
                    return None
                else:
                    return Whatchamacallit(attrs.get('secret_sauce'))

        class Foo(base.LibvirtXMLBase):
            __slots__ = ('bar',)

            def __init__(self, virsh_instance):
                accessors.XMLElementList('bar', self, parent_xpath='/bar',
                                         marshal_from=Whatchamacallit.from_it,
                                         marshal_to=Whatchamacallit.to_it)
                super(Foo, self).__init__(virsh_instance=virsh_instance)
                self.xml = """<foo><bar>
                                  <notone secret_sauce='snafu'/>
                                  <whatchamacallit secret_sauce='foobar'/>
                                  <whatchamacallit secret_sauce='5'/>
                              </bar></foo>"""
        foo = Foo(virsh_instance=self.dummy_virsh)
        existing = foo.bar
        self.assertEqual(len(existing), 2)
        self.assertEqual(existing[0].secret_sauce, 'foobar')
        self.assertEqual(existing[1].secret_sauce, '5')
        foo.bar = existing
        existing[0].secret_sauce = existing[1].secret_sauce = None
        # No value change
        self.assertEqual(foo.bar[0].secret_sauce, 'foobar')
        self.assertEqual(foo.bar[1].secret_sauce, '5')
        existing.append(Whatchamacallit('None'))
        foo.bar = existing  # values changed
        test = foo.bar
        self.assertEqual(test[0].secret_sauce, 'None')
        self.assertEqual(test[1].secret_sauce, 'None')
        self.assertEqual(test[2].secret_sauce, 'None')


class TestLibvirtXML(LibvirtXMLTestBase):

    def _from_scratch(self):
        return capability_xml.CapabilityXML(virsh_instance=self.dummy_virsh)

    def test_uuid(self):
        lvxml = self._from_scratch()
        test_uuid = lvxml.uuid
        self.assertEqual(test_uuid, UUID)
        test_uuid = lvxml['uuid']
        self.assertEqual(test_uuid, UUID)
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvxml.__setattr__,
                          'uuid', 'foobar')
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvxml.__delitem__,
                          'uuid')

    def test_os_arch_machine_map(self):
        lvxml = self._from_scratch()
        expected = {'hvm': {'x86_64': ['rhel6.3.0', 'pc']}}
        test_oamm = lvxml.os_arch_machine_map
        self.assertEqual(test_oamm, expected)
        test_oamm = lvxml['os_arch_machine_map']
        self.assertEqual(test_oamm, expected)
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvxml.__setattr__,
                          'os_arch_machine_map', 'foobar')
        self.assertRaises(xcepts.LibvirtXMLForbiddenError,
                          lvxml.__delitem__,
                          'os_arch_machine_map')


class TestVMXML(LibvirtXMLTestBase):

    def _from_scratch(self):
        vmxml = vm_xml.VMXML('test1', virsh_instance=self.dummy_virsh)
        vmxml.vm_name = 'test2'
        vmxml.uuid = 'test3'
        vmxml.vcpu = 4
        return vmxml

    def test_getters(self):
        vmxml = self._from_scratch()
        self.assertEqual(vmxml.hypervisor_type, 'test1')
        self.assertEqual(vmxml.vm_name, 'test2')
        self.assertEqual(vmxml.uuid, 'test3')
        self.assertEqual(vmxml.vcpu, 4)

    def test_valid_xml(self):
        vmxml = self._from_scratch()
        test_xtf = xml_utils.XMLTreeFile(vmxml.xml)  # re-parse from filename
        self.assertEqual(test_xtf.getroot().get('type'), 'test1')
        self.assertEqual(test_xtf.find('name').text, 'test2')
        self.assertEqual(test_xtf.find('uuid').text, 'test3')
        self.assertEqual(test_xtf.find('vcpu').text, '4')

    def test_new_from_dumpxml(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        self.assertEqual(vmxml.vm_name, 'foobar')
        self.assertEqual(vmxml.uuid, self._domuuid(None))
        self.assertEqual(vmxml.hypervisor_type, 'kvm')

    def test_restore(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        vmxml.vm_name = 'test name'
        vmxml.uuid = 'test uuid'
        vmxml.hypervisor_type = 'atari'
        # Changes verified in test_new_from_dumpxml() above
        vmxml.restore()
        self.assertEqual(vmxml.vm_name, 'foobar')
        self.assertEqual(vmxml.uuid, self._domuuid(None))
        self.assertEqual(vmxml.hypervisor_type, 'kvm')

    def test_seclabel(self):
        vmxml = self._from_scratch()

        # should not raise an exception
        del vmxml.seclabel

        self.assertRaises(xcepts.LibvirtXMLError,
                          getattr, vmxml, 'seclabel')

        vmxml.set_seclabel({'type': "dynamic"})
        self.assertEqual(vmxml.seclabel['type'], 'dynamic')
        self.assertEqual(len(vmxml.seclabel), 1)

        seclabel_dict = {'type': 'test_type', 'model': 'test_model',
                         'relabel': 'test_relabel', 'label': 'test_label',
                         'baselabel': 'test_baselabel',
                         'imagelabel': 'test_imagelabel'}
        vmxml.set_seclabel(seclabel_dict)

        seclabel = vmxml.get_seclabel()

        for key, value in seclabel_dict.items():
            self.assertEqual(seclabel[key], value)

        # test attribute-like access also
        for key, value in vmxml.seclabel.items():
            self.assertEqual(seclabel_dict[key], value)


class testNetworkXML(LibvirtXMLTestBase):

    def _from_scratch(self):
        netxml = network_xml.NetworkXML(network_name='test0',
                                        virsh_instance=self.dummy_virsh)
        self.assertEqual(netxml.name, 'test0')
        netxml.name = 'test1'
        netxml.uuid = 'test2'
        netxml.bridge = {'test3': 'test4'}

        ipxml = network_xml.IPXML()
        ipxml.address = ('address_test')
        ipxml.netmask = ('netmask_test')
        netxml.ip = ipxml
        return netxml

    def test_getters(self):
        netxml = self._from_scratch()
        self.assertEqual(netxml.name, 'test1')
        self.assertEqual(netxml.uuid, 'test2')
        self.assertEqual(netxml.bridge, {'test3': 'test4'})

    def test_valid_xml(self):
        netxml = self._from_scratch()
        test_xtf = xml_utils.XMLTreeFile(netxml.xml)  # re-parse from filename
        self.assertEqual(test_xtf.find('name').text, 'test1')
        self.assertEqual(test_xtf.find('uuid').text, 'test2')
        self.assertEqual(test_xtf.find('bridge').get('test3'), 'test4')

    def test_ip_getter(self):
        netxml = self._from_scratch()
        ipxml = netxml.ip
        self.assertEqual(ipxml.address, 'address_test')
        self.assertEqual(ipxml.netmask, 'netmask_test')


class testLibrarian(LibvirtXMLTestBase):

    def test_bad_names(self):
        for badname in ('__init__', 'librarian', '__doc__', '/dev/null', '',
                        None):
            self.assertRaises(xcepts.LibvirtXMLError, librarian.get, badname)

    def test_no_module(self):
        # Bypass type-check to induse module load failure
        original_device_types = librarian.DEVICE_TYPES
        for badname in ('DoesNotExist', '/dev/null', '', None):
            librarian.DEVICE_TYPES.append(badname)
            self.assertRaises(xcepts.LibvirtXMLError, librarian.get,
                              badname)

    def test_serial_class(self):
        Serial = librarian.get('serial')
        self.assertTrue(issubclass(Serial, devices_base.UntypedDeviceBase))
        self.assertTrue(issubclass(Serial, devices_base.TypedDeviceBase))


class testStubXML(LibvirtXMLTestBase):

    class UntypedFoobar(devices_base.UntypedDeviceBase):
        __metaclass__ = devices_base.StubDeviceMeta
        _device_tag = 'foobar'

    class TypedFoobar(devices_base.TypedDeviceBase):
        __metaclass__ = devices_base.StubDeviceMeta
        _device_tag = 'foo'
        _def_type_name = 'bar'

    def setUp(self):
        logging.disable(logging.WARNING)
        super(testStubXML, self).setUp()

    def test_untyped_device_stub(self):
        foobar = self.UntypedFoobar(virsh_instance=self.dummy_virsh)
        self.assertEqual(foobar.virsh.domuuid(None),
                         "ddb0cf86-5ba8-4f83-480a-d96f54339219")
        self.assertEqual(foobar.device_tag, 'foobar')
        self.assertEqual(unicode(foobar),
                         u"<?xml version='1.0' encoding='UTF-8'?>\n<foobar />")

    def test_typed_device_stub(self):
        foobar = self.TypedFoobar(virsh_instance=self.dummy_virsh)
        self.assertEqual(foobar.virsh.domuuid(None),
                         "ddb0cf86-5ba8-4f83-480a-d96f54339219")
        self.assertEqual(foobar.device_tag, 'foo')
        self.assertEqual(foobar.type_name, 'bar')
        self.assertEqual(unicode(foobar),
                         u'<?xml version=\'1.0\' encoding=\'UTF-8\'?>\n<foo type="bar" />')


class testCharacterXML(LibvirtXMLTestBase):

    def test_arbitrart_attributes(self):
        parallel = librarian.get('parallel')(virsh_instance=self.dummy_virsh)
        serial = librarian.get('serial')(virsh_instance=self.dummy_virsh)
        channel = librarian.get('channel')(virsh_instance=self.dummy_virsh)
        console = librarian.get('console')(virsh_instance=self.dummy_virsh)
        for chardev in (parallel, serial, channel, console):
            attribute1 = utils_misc.generate_random_string(10)
            value1 = utils_misc.generate_random_string(10)
            attribute2 = utils_misc.generate_random_string(10)
            value2 = utils_misc.generate_random_string(10)
            chardev.add_source(**{attribute1: value1, attribute2: value2})
            chardev.add_target(**{attribute1: value1, attribute2: value2})
            self.assertEqual(chardev.sources, chardev.targets)


class testSerialXML(LibvirtXMLTestBase):

    XML = u"<serial type='pty'><source path='/dev/null'/>\
                                        <target port='-1'/></serial>"

    def _from_scratch(self):
        serial = librarian.get('Serial')(virsh_instance=self.dummy_virsh)
        self.assertEqual(serial.device_tag, 'serial')
        self.assertEqual(serial.type_name, 'pty')
        self.assertEqual(serial.virsh, self.dummy_virsh)
        serial.add_source(path='/dev/null')
        serial.add_target(port="-1")
        return serial

    def test_getters(self):
        serial = self._from_scratch()
        self.assertEqual(serial.sources[0]['path'], '/dev/null')
        self.assertEqual(serial.targets[0]['port'], '-1')

    def test_from_element(self):
        element = xml_utils.ElementTree.fromstring(self.XML)
        serial1 = self._from_scratch()
        serial2 = librarian.get('Serial').new_from_element(element)
        self.assertEqual(serial1, serial2)
        # Can't in-place modify the dictionary since it's virtual
        serial2.update_target(0, port="0")
        self.assertTrue(serial1 != serial2)
        serial1.targets = [{'port': '0'}]
        self.assertEqual(serial1, serial2)

    def test_vm_get_by_class(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        serial_devices = vmxml.get_devices(device_type='serial')
        self.assertEqual(len(serial_devices), 4)

    def test_vm_get_modify(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        devices = vmxml['devices']
        serial1 = devices[0]
        serial2 = devices[1]
        serial3 = devices[2]
        serial4 = devices[3]
        self.assertEqual(serial1.device_tag, 'serial')
        self.assertEqual(serial2.device_tag, 'serial')
        self.assertEqual(serial1.type_name, 'pty')
        self.assertEqual(serial2.type_name, 'pty')
        self.assertFalse(serial1 == serial2)
        self.assertEqual(serial1.sources, [])
        # mix up access style
        serial1.add_source(**serial2.sources[0])
        self.assertFalse(serial1 == serial2)
        serial1.update_target(0, port="1")
        self.assertEqual(serial1, serial2)
        # Exercize bind mode
        self.assertEqual(serial3.type_name, 'tcp')
        source_connect = serial3.sources[0]
        self.assertEqual(source_connect, {'mode': "connect", 'host': '1.2.3.4',
                                          'service': '2445'})
        self.assertEqual(serial3.protocol_type, 'raw')
        self.assertEqual(serial3.targets[0]['port'], '2')
        # Exercize udp type
        self.assertEqual(serial4.type_name, 'udp')
        source_bind = serial4.sources[0]
        source_connect = serial4.sources[1]
        self.assertEqual(source_bind['host'], "1.2.3.4")
        self.assertEqual(source_connect['host'], "4.3.2.1")
        self.assertEqual(source_bind['service'], '2445')
        self.assertEqual(source_connect['service'], '5442')


class testVMCPUTune(LibvirtXMLTestBase):

    def test_get_set_del(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        cputune = vmxml.cputune

        # Get, modify, set and delete integer and attribute elements
        self.assertEqual(cputune.shares, 2048)
        self.assertEqual(cputune.period, 1000000)
        self.assertEqual(cputune.quota, -1)
        self.assertEqual(cputune.emulatorpin, '1-3')
        self.assertEqual(cputune.emulator_period, 1000000)
        self.assertEqual(cputune.emulator_quota, -1)
        cputune.shares = 0
        self.assertEqual(cputune.shares, 0)
        cputune.emulatorpin = '2-4'
        self.assertEqual(cputune.emulatorpin, '2-4')
        del cputune.shares
        self.assertRaises(xcepts.LibvirtXMLNotFoundError,
                          cputune.__getitem__, 'shares')
        del cputune.emulatorpin
        self.assertRaises(xcepts.LibvirtXMLNotFoundError,
                          cputune.__getitem__, 'emulatorpin')

        # Get, modify, set and delete vcpupins
        vcpupins = cputune.vcpupins
        self.assertEqual(len(vcpupins), 4)
        self.assertEqual(vcpupins[3], {'vcpu': '3', 'cpuset': '0,4'})
        vcpupins.append({'vcpu': '4', 'cpuset': '2-4,^3'})
        cputune.vcpupins = vcpupins
        self.assertEqual(len(cputune.vcpupins), 5)
        self.assertEqual(cputune.vcpupins[4],
                         {'vcpu': '4', 'cpuset': '2-4,^3'})
        del cputune.vcpupins
        self.assertEqual(cputune.vcpupins, [])


class testDiskXML(LibvirtXMLTestBase):

    def _check_disk(self, disk):
        self.assertEqual(disk.type_name, "file")
        self.assertEqual(disk.device, "disk")
        for propname in ('rawio', 'sgio', 'snapshot', 'iotune'):
            self.assertRaises(xcepts.LibvirtXMLNotFoundError,
                              disk.__getitem__, propname)
            self.assertRaises(xcepts.LibvirtXMLNotFoundError,
                              disk.__getattr__, propname)
            self.assertRaises(xcepts.LibvirtXMLNotFoundError,
                              getattr(disk, 'get_' + propname))
        self.assertEqual(disk.driver, {'name': 'qemu', 'type': 'qcow2'})
        self.assertEqual(disk.target['dev'], 'vda')
        self.assertEqual(disk.target['bus'], 'virtio')
        source = disk.source
        self.assertEqual(source.attrs, {'file': '/foo/bar/baz.qcow2'})
        self.assertEqual(source.seclabels, [])
        self.assertEqual(source.hosts, [])
        self.assertEqual(disk.address.attrs, {"domain": "0x0000",
                                              "bus": "0x00", "slot": "0x04",
                                              "function": "0x0", "type": "pci"})

    def test_vm_get(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        for device in vmxml.devices:
            if device.device_tag is 'disk':
                self._check_disk(device)
            else:
                continue

    def test_vm_get_by_class(self):
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        disk_devices = vmxml.get_devices(device_type='disk')
        self.assertEqual(len(disk_devices), 1)
        self._check_disk(disk_devices[0])


class testAddressXML(LibvirtXMLTestBase):

    def test_required(self):
        address = librarian.get('address')
        self.assertRaises(xcepts.LibvirtXMLError,
                          address.new_from_dict,
                          {}, self.dummy_virsh)
        # no type_name attribute
        element = xml_utils.ElementTree.Element('address', {'foo': 'bar'})
        self.assertRaises(xcepts.LibvirtXMLError,
                          address.new_from_element,
                          element, self.dummy_virsh)
        element.set('type', 'foobar')
        new_address = address.new_from_element(element, self.dummy_virsh)
        the_dict = {'type_name': 'foobar', 'foo': 'bar'}
        another_address = address.new_from_dict(the_dict, self.dummy_virsh)
        self.assertEqual(str(new_address), str(another_address))


class testVMXMLDevices(LibvirtXMLTestBase):

    def test_channels(self):
        logging.disable(logging.WARNING)
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        channels = vmxml.devices.by_device_tag('channel')
        self.assertEqual(len(channels), 2)
        self.assertTrue(isinstance(channels, vm_xml.VMXMLDevices))
        self.assertEqual(channels[0].type_name, 'foo1')
        self.assertEqual(channels[1].type_name, 'bar1')
        one = channels.pop()
        two = channels.pop()
        self.assertEqual(len(channels), 0)

    def test_graphics(self):
        logging.disable(logging.WARNING)
        vmxml = vm_xml.VMXML.new_from_dumpxml('foobar',
                                              virsh_instance=self.dummy_virsh)
        devices = vmxml.devices
        # Assume only one graphics device, take first in list
        graphics_index = devices.index(devices.by_device_tag('graphics')[0])
        # Make copy of existing graphics device
        graphics = devices[graphics_index]
        # Modify copy
        graphics.passwd = 'foobar'
        # Remove existing graphics device
        del devices[graphics_index]
        # Add modified copy (another copy)
        devices.append(graphics)
        # clean up graphics temp files
        del graphics
        # Copy modified devices to vm
        vmxml.devices = devices
        # clean up devices temp files
        del devices
        # Check result
        self.assertEqual(vmxml.devices[-1].passwd, 'foobar')


class testCAPXML(LibvirtXMLTestBase):

    def test_capxmlbase(self):
        capxmlbase = nodedev_xml.CAPXML()
        self.assertRaises(NotImplementedError,
                          capxmlbase.get_sysfs_sub_path)
        self.assertRaises(NotImplementedError,
                          capxmlbase.get_key2filename_dict)
        self.assertRaises(NotImplementedError,
                          capxmlbase.get_key2value_dict)


class testNodedevXMLBase(LibvirtXMLTestBase):

    def _from_scratch(self):
        nodedevxml = nodedev_xml.NodedevXMLBase(virsh_instance=self.dummy_virsh)
        nodedevxml.name = 'name_test'
        nodedevxml.parent = 'parent_test'

        return nodedevxml

    def test_getter(self):
        nodedevxml = self._from_scratch()
        self.assertEqual(nodedevxml.name, 'name_test')
        self.assertEqual(nodedevxml.parent, 'parent_test')

    def test_static(self):
        base = nodedev_xml.NodedevXMLBase
        cap_list = ['system', 'pci']
        for cap_type in cap_list:
            result = base.get_cap_by_type(cap_type)
            self.assertTrue(isinstance(result, nodedev_xml.CAPXML))


class testNodedevXML(LibvirtXMLTestBase):

    def test_new_from_dumpxml(self):
        NodedevXML = nodedev_xml.NodedevXML
        nodedevxml = NodedevXML.new_from_dumpxml('pci_0000_00_00_0',
                                                 virsh_instance=self.dummy_virsh)
        self.assertTrue(isinstance(nodedevxml, NodedevXML))

    def test_get_key2value_dict(self):
        NodedevXML = nodedev_xml.NodedevXML
        xml = NodedevXML.new_from_dumpxml('pci_0000_00_00_0',
                                          virsh_instance=self.dummy_virsh)
        result = xml.get_key2value_dict()

        self.assertTrue(isinstance(result, dict))

    def test_get_key2syspath_dict(self):
        NodedevXML = nodedev_xml.NodedevXML
        xml = NodedevXML.new_from_dumpxml('pci_0000_00_00_0',
                                          virsh_instance=self.dummy_virsh)
        result = xml.get_key2syspath_dict()
        self.assertTrue(isinstance(result, dict))


class testPCIXML(LibvirtXMLTestBase):

    def _from_scratch(self):
        pcixml = nodedev_xml.PCIXML()
        pcixml.domain = 0x10
        pcixml.bus = 0x20
        pcixml.slot = 0x30
        pcixml.function = 0x1
        pcixml.vendor_id = '0x123'
        pcixml.product_id = '0x123'

        return pcixml

    def test_static(self):
        PCIXML = nodedev_xml.PCIXML
        result = PCIXML.make_sysfs_sub_path(0x10, 0x20, 0x30, 0x1)
        self.assertEqual(result, 'pci_bus/0010:20/device/0010:20:30.1')

    def test_get_path(self):
        pcixml = self._from_scratch()
        result = pcixml.get_sysfs_sub_path()
        self.assertEqual(result, 'pci_bus/0010:20/device/0010:20:30.1')

    def test_get_key2filename_dict(self):
        PCIXML = nodedev_xml.PCIXML
        self.assertTrue(isinstance(PCIXML.get_key2filename_dict(), dict))

    def test_get_key2value_dict(self):
        pcixml = self._from_scratch()
        result = pcixml.get_key2value_dict()
        self.assertTrue(isinstance(result, dict))


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = lvm
"""
Base module for support lvm in qemu test;

For EmulatedLVM, no need any special configuration, lvm params will generate
automatically. Of course, customizable params is accept;
For real lvm partition, we need to specify some params, at lest, vg_name and
it's a real volume group on your host. If not, both pv_name and vg_name are
required and a new volumegroup will be created on device named pv_name, But
it will destroy data on your device and it's not recommended;

Required params:
    lv_name:
        lv_name like /dev/vg/lv; If not params["vg_name"]
        is requried and if lv_name not set, use guest_name as
        lv_name; device mapper path (eg, /dev/mapper/vg-lv)
        doesn't support it now;
    lv_size
        string (eg, 30G) if not set image_size will be used;
    vg_name
        LogicalVolume group name, eg, "test_vg";
    pv_name
        PhysicalVolume name eg, /dev/sdb or /dev/sdb1;
"""
import os
import re
import math
import logging
import utils_misc
from autotest.client import os_dep
from autotest.client.shared import error
from autotest.client.shared import utils


UNIT = "B"
COMMON_OPTS = "--noheading --nosuffix --unit=%s" % UNIT


def normalize_data_size(size):
    if re.match(".*\d$", str(size)):
        size = "%s%s" % (size, UNIT)
    size = float(utils_misc.normalize_data_size(size, UNIT, 1024))
    return int(math.ceil(size))


def cmd_output(cmd, res="[\w/]+"):
    result = utils.run(cmd, ignore_status=True)
    if result.exit_status != 0:
        logging.warn(result)
        return None
    output = result.stdout
    for line in output.splitlines():
        val = re.findall(res, line)
        if val:
            return val[0]
    return None


class Volume(object):

    def __init__(self, name, size):
        self.name = name
        self.path = name
        self.size = normalize_data_size(size)

    def get_attr(self, cmd, attr, res="[\w/]+"):
        """
        Get attribue of volume, if not found return None;

        :param cmd: command used to display volume info;
        :param attr: attribue name of the volume;
        :param res: regular expression to reading the attribue;
        :return: string or None
        """
        if attr:
            return cmd_output(cmd, res)
        return None

    def exists(self):
        """
        Check is the volume really exists or not;
        """
        return os.path.exists(self.path)

    def umount(self, extra_args="-f"):
        """
        Unmount volume;
        """
        if self.exists():
            cmd = "umount %s" % extra_args
            fd = open("/proc/mounts", "r")
            for line in fd.readlines():
                dev, mount_point = line.split()[0], line.split()[2]
                if os.path.exists(dev) and os.path.samefile(dev, self.path):
                    utils.system("%s %s" % (cmd, mount_point))
            fd.close()


class PhysicalVolume(Volume):

    def __init__(self, name, size):
        super(PhysicalVolume, self).__init__(name, size)
        self.vg = None

    def create(self, extra_args="-ff --yes"):
        """
        Create physical volume on specify physical volume;

        :param extra_args: extra argurments for pvcreate command;
        :raise: CmdError or TestError;
        :return: physical volume abspath
        """
        if not self.exists():
            raise error.TestError("Physical device not found")
        self.umount()
        cmd = "pvcreate %s %s" % (extra_args, self.name)
        utils.system(cmd)
        logging.info("Create physical volume: %s", self.name)
        return self.path

    def remove(self, extra_args=" -ff --yes"):
        """
        Remove a physical volume

        :param extra_args: extra argurments for ``pvremove`` command
        :raise: CmdError
        """
        cmd = "lvm pvremove %s %s" % (extra_args, self.name)
        utils.system(cmd)
        logging.info("logical physical volume (%s) removed", self.name)

    def resize(self, size, extra_args="-ff --yes"):
        """
        Resize a physical volume;

        :param size: new size of the physical volume device;
        :param extra_args: extra argurments for pvresize command;
        """
        size = int(math.ceil(normalize_data_size(size)))
        cmd = "lvm pvresize %s --setphysicalvolumesize=%s%s %s" % (extra_args,
                                                                   size,
                                                                   UNIT,
                                                                   self.name)
        utils.system(cmd)
        self.size = size
        logging.info("resize volume %s to %s B" % (self.name, self.size))

    def display(self):
        """
        Show physical volume detials

        :raise: CmdError
        """
        cmd = "pvdisplay %s" % self.name
        utils.system(cmd)

    def get_attr(self, attr):
        """
        Get attribue of physical volume, if not found return None;

        :param attr: attribue name of the volume;
        :return: string or None
        """
        cmd = "lvm pvs -o %s %s %s" % (attr, COMMON_OPTS, self.name)
        return super(PhysicalVolume, self).get_attr(cmd, attr)

    def set_vg(self, vg):
        """
        Set VolumeGroup of the physical volume device;

        :param vg: VolumeGroup object
        """
        if isinstance(vg, VolumeGroup):
            self.vg = vg


class VolumeGroup(object):

    def __init__(self, name, size, pvs):
        self.name = name
        self.size = normalize_data_size(size)
        self.pvs = pvs
        self.lvs = []

    def create(self, extra_args="-ff --yes"):
        """
        Create volume group with specify physical volumes;

        :param extra_args: extra argurments for lvm command;
        :raise: CmdError or TestError;
        :return: volume group name;
        """
        cmd = "lvm vgcreate  %s %s" % (extra_args, self.name)
        for pv in self.pvs:
            if pv.vg and pv.vg.name != self.name:
                try:
                    pv.vg.reduce_pv(pv)
                except:
                    pv.vg.remove()
            cmd += " %s" % pv.name
        utils.system(cmd)
        logging.info("Create new volumegroup %s", self.name)
        return self.name

    def remove(self, extra_args="-ff --yes"):
        """
        Remove the VolumeGroup;

        :param extra_args: extra argurments for lvm command;
        """
        cmd = "lvm vgremove %s %s" % (extra_args, self.name)
        utils.system(cmd)
        logging.info("logical volume-group(%s) removed", self.name)

    def get_attr(self, attr):
        """
        Get VolumeGroup attribue;

        :param attr: attribue name;
        :return: string or None;
        """
        cmd = "lvm vgs -o %s %s %s" % (attr, COMMON_OPTS, self.name)
        return cmd_output(cmd)

    def append_lv(self, lv):
        """
        Collect Logical Volumes on the VolumeGroup;

        :param lv: LogicalVolume Object
        """
        if isinstance(lv, LogicalVolume):
            if lv not in self.lvs:
                self.lvs.append(lv)

    def reduce_pv(self, pv, extra_args="-ff --yes"):
        """
        Reduce a PhysicalVolume from VolumeGroup;

        :param pv: PhysicalVolume object;
        :param extra_args: extra argurments pass to lvm command;
        """
        if not isinstance(pv, PhysicalVolume):
            raise TypeError("Need a PhysicalVolume object")
        cmd = "lvm vgreduce %s %s %s" % (extra_args, self.name, pv.name)
        utils.system(cmd)
        self.pvs.remove(pv)
        logging.info("reduce volume %s from volume group %s" % (pv.name,
                                                                self.name))

    def extend_pv(self, pv, extra_args=""):
        """
        Add PhysicalVolume into VolumeGroup;

        :param pv: PhysicalVolume object
        :param extra_args: extra argurments used for vgextend command
        """
        if not isinstance(pv, PhysicalVolume):
            raise TypeError("Need a PhysicalVolume object")
        cmd = "lvm vgextend %s %s" % (self.name, pv.name)
        utils.system(cmd)
        self.pvs.append(pv)
        logging.info("add volume %s to volumegroup %s" % (pv.name, self.name))

    def exists(self):
        """
        Check VolumeGroup exists or not;

        :return: bool type, if exists True else False;
        """
        vg_name = self.get_attr("vg_name")
        return bool(vg_name)


class LogicalVolume(Volume):

    def __init__(self, name, size, vg):
        super(LogicalVolume, self).__init__(name, size)
        self.vg = vg
        self.path = os.path.join("/dev", vg.name, name)

    def create(self):
        """
        Create LogicalVolume device;

        :return: path of logical volume;
        """
        vg_name = self.vg.name
        cmd = "lvm lvcreate -L %s%s -n %s %s" % (self.size,
                                                 UNIT,
                                                 self.name,
                                                 vg_name)
        utils.system(cmd)
        logging.info("create logical volume %s", self.path)
        return self.get_attr("lv_path")

    def remove(self, extra_args="-ff --yes"):
        """
        Remove LogicalVolume device;

        :param extra_args: extra argurments pass to lvm command;
        """
        self.umount()
        cmd = "lvm lvremove %s %s/%s" % (extra_args, self.vg.name, self.name)
        utils.system(cmd)
        logging.info("logical volume(%s) removed", self.name)

    def resize(self, size, extra_args="-ff"):
        """
        Resize LogicalVolume to new size;

        :param size: new size of logical volume;
        :param extra_args: extra argurments pass to lvm command;
        :return: size of logical volume;
        """
        path = self.get_attr("lv_path")
        size = str(size)
        if size.startswith("+"):
            size = self.size + normalize_data_size(size[1:])
        elif size.startswith("-"):
            size = self.size - normalize_data_size(size[1:])
        else:
            size = normalize_data_size(size)
        cmd = "lvm lvresize -n -L %s%s %s %s" % (size, UNIT, path, extra_args)
        utils.system(cmd)
        self.size = size
        logging.info("resize logical volume %s size to %s" % (self.path,
                                                              self.size))
        return size

    def display(self, extra_args=""):
        """
        Shown logical volume detials, warper of lvm command lvdisplay;

        :extra_args: extra argurments pass to lvdisplay command;
        :raise: CmdError when command exit code not equal 0;
        """
        path = self.get_attr("lv_path")
        cmd = "lvm lvs %s %s" % (extra_args, path)
        return utils.system(cmd)

    def get_attr(self, attr):
        """
        Get logical volume attribues if not found return None;

        :param attr: attribue name;
        :return: attribue value string or None;
        :raise: CmdError when command exit code not equal 0;
        """
        cmd = "lvm lvs -o %s %s %s" % (attr, COMMON_OPTS, self.path)
        return super(LogicalVolume, self).get_attr(cmd, attr)


class LVM(object):

    def __init__(self, params):
        os_dep.command("lvm")
        self.params = self.__format_params(params)
        self.pvs = self.__reload_pvs()
        self.vgs = self.__reload_vgs()
        self.lvs = self.__reload_lvs()
        self.trash = []

    def generate_id(self, params):
        """
        Create prefix with image_name;
        """
        black_str = re.compile(r"[-./]")
        return black_str.sub("_", os.path.basename(params["image_name"]))

    def __format_params(self, params):
        """
        Reformat test params;

        :param params: dict of test params;
        :return: dict of test params;
        """
        lv_size = params.get("lv_size")
        if lv_size is None:
            lv_size = params["image_size"]
        params["lv_size"] = normalize_data_size(lv_size)

        lv_name = params.get("lv_name")
        if lv_name is None:
            lv_name = "lv_%s" % self.generate_id(params)
            params["lv_name"] = lv_name

        vg_name = params.get("vg_name")
        if vg_name is None:
            vg_name = "vg_%s" % self.generate_id(params)
            params["vg_name"] = vg_name
        if lv_name.startswith("/dev"):
            if "mapper" not in lv_name:
                match = re.search("/dev/([\w_]+)/([\w_]+)", lv_name)
                vg_name, lv_name = [x[1:] for x in match.groups()]
                params["lv_name"] = lv_name
                params["vg_name"] = vg_name
        return params

    def register(self, vol):
        """
        Register new volume;

        :param vol: Volume object or VolumeGroup objects
        """
        if isinstance(vol, Volume) or isinstance(vol, VolumeGroup):
            self.trash.append(vol)
            logging.info("Install new volume %s", vol.name)

    def unregister(self, vol):
        """
        Unregister volume or VolumeGroup;

        :param vol: Volume object or VolumeGroup objects
        """
        if vol in self.trash:
            self.trash.remove(vol)
            logging.info("Uninstall volume %s", vol.name)

    def __reload_lvs(self):
        """
        Create LogicalVolume objects for exist Logical volumes;

        :return: list of Volume object
        """
        lvs = []
        cmd = "lvm lvs -o lv_name,lv_size,vg_name %s" % COMMON_OPTS
        output = utils.system_output(cmd)
        for line in output.splitlines():
            lv_name, lv_size, vg_name = line.split()
            vg = self.get_vol(vg_name, "vgs")
            lv = LogicalVolume(lv_name, lv_size, vg)
            vg.append_lv(lv)
            lvs.append(lv)
        return lvs

    def __reload_vgs(self):
        """
        Create VolumeGroup objects for exist volumegroups;

        :return: list of Volume object
        """
        vgs = []
        cmd = "lvm vgs -opv_name,vg_name,vg_size %s" % COMMON_OPTS
        output = utils.system_output(cmd)
        for line in output.splitlines():
            pv_name, vg_name, vg_size = line.split()
            pv = self.get_vol(pv_name, "pvs")
            vg = VolumeGroup(vg_name, vg_size, [pv])
            pv.set_vg(vg)
            vgs.append(vg)
        return vgs

    def __reload_pvs(self):
        """
        Create PhysicalVolume objects for exist physical volumes;

        :return: list of Volume object
        """
        pvs = []
        cmd = "lvm pvs -opv_name,pv_size %s" % COMMON_OPTS
        output = utils.system_output(cmd)
        for line in output.splitlines():
            pv_name, pv_size = line.split()
            pv = PhysicalVolume(pv_name, pv_size)
            pvs.append(pv)
        return pvs

    def get_vol(self, vname, vtype):
        """
        Get a exists volume object;

        :param vname: volume name;
        :param vtype: volume type eg, 'pvs', 'vgs', 'lvs';
        :return: Volume object or None;
        """
        if vtype:
            vols = getattr(self, vtype)
            for vol in vols:
                if vol.name == vname:
                    return vol
        return None

    def setup_pv(self, vg):
        """
        Create a physical volume devices;

        :param params["pv_name"]: Physical volume devices path or mount point;
        :param vg: VolumeGroup object;
        :return: list of PhysicalVolume object;
        """
        pvs = []
        cmd = "lvm pvs -opv_name,pv_size %s %s" % (COMMON_OPTS, vg.name)
        output = utils.system_output(cmd)
        for line in output.splitlines():
            pv_name, pv_size = line.split()
            pv = self.get_vol(pv_name, "pvs")
            if pv is None:
                pv = PhysicalVolume(pv_name, pv_size)
                pv.create()
                self.register(pv)
            else:
                logging.info("PhysicalVolume(%s) really exists" % pv_name +
                             "skip to create it")
            pv.set_vg(vg)
            pvs.append(pv)
        else:
            for pv_name in self.params["pv_name"].split():
                pv = PhysicalVolume(pv_name, 0)
                pv.create()
                self.register(pv)
                pv.set_vg(vg)
                pvs.append(pv)
        for pv in pvs:
            pv.set_vg(vg)
        return pvs

    def setup_vg(self, lv):
        """
        Setup logical volumegroup which specify on volumegroup specify by
        params["vg_name"];

        :param params["vg_name"]: volumegroup name;
        :return: volumegroup object;
        """
        vg_name = self.params["vg_name"]
        vg = self.get_vol(vg_name, "vgs")
        if vg is None:
            pvs = self.setup_pv(vg)
            vg = VolumeGroup(vg_name, 0, pvs)
            vg.create()
            self.register(vg)
        else:
            logging.info("VolumeGroup(%s) really exists" % vg_name +
                         "skip to create it")
            pv_name = self.params.get("pv_name")
            if pv_name:
                # if set pv_name then add pvs into volume group
                pvs = self.setup_pv(vg)
                for pv in pvs:
                    vg.extend_pv(pv)
        vg.append_lv(lv)
        return vg

    def setup_lv(self):
        """
        Setup a logical volume, if a exist logical volume resize it
        else then create it on specify volumegroup;

        :param params["lv_name"]: logical volume name;
        :param params["lv_name"]: logical volume size;
        :return: logical volume object;
        """
        lv_name = self.params["lv_name"]
        lv_size = self.params["lv_size"]
        lv = self.get_vol(lv_name, "lvs")
        # Check is it a exist lv if exist return the volume object
        # else then create it;
        if lv is None:
            vg = self.setup_vg(lv)
            lv = LogicalVolume(lv_name, lv_size, vg)
            lv.create()
            self.register(lv)
        else:
            logging.info("LogicalVolume(%s) really exists " % lv_name +
                         "skip to create it")
        if lv.size != lv_size:
            lv.display()
            logging.warn("lv size(%s) mismath," % lv.size +
                         "requried size %s;" % lv_size)
            lv.resize(lv_size)
        return lv

    def setup(self):
        """
        Main function to setup a lvm environments;

        :return: LogicalVolume path
        """
        self.rescan()
        lv = self.setup_lv()
        return lv.get_attr("lv_path")

    def cleanup(self):
        """
        Remove useless lv, vg and pv then reload lvm releated service;
        """
        if self.params.get("force_remove_image", "no") == "yes":
            self.trash.reverse()
            for vol in self.trash:
                if isinstance(vol, LogicalVolume):
                    vol.umount()
                if isinstance(vol, PhysicalVolume):
                    vg = vol.vg
                    if vg is not None:
                        vg.reduce_pv(vol)
                vol.remove()
                self.unregister(vol)
        self.rescan()

    def rescan(self):
        """
        Rescan lvm , used before create volume or after remove volumes;
        """
        lvm_reload_cmd = self.params.get("lvm_reload_cmd")
        if lvm_reload_cmd:
            utils.system(lvm_reload_cmd, ignore_status=True)
            logging.info("reload lvm monitor service")


class EmulatedLVM(LVM):

    def __init__(self, params, root_dir="/tmp"):
        os_dep.command("losetup")
        os_dep.command("dd")
        super(EmulatedLVM, self).__init__(params)
        self.data_dir = root_dir

    def get_emulate_image_name(self):
        img_path = self.params.get("emulated_image")
        if img_path is None:
            img_path = self.generate_id(self.params)
        return utils_misc.get_path(self.data_dir, img_path)

    def make_emulate_image(self):
        """
        Create emulate image via dd with 8M block size;
        """
        img_size = self.params["lv_size"]
        img_path = self.get_emulate_image_name()
        bs_size = normalize_data_size("8M")
        count = int(math.ceil(img_size / bs_size)) + 8
        logging.info("create emulated image file(%s)" % img_path)
        cmd = "dd if=/dev/zero of=%s bs=8M count=%s" % (img_path, count)
        utils.system(cmd)
        self.params["pv_size"] = count * bs_size
        return img_path

    def make_volume(self, img_file, extra_args=""):
        """
        Map a file to loop back device;

        :param img_file: image file path;
        :return: loop back device name;
        """
        cmd = "losetup %s --show --find %s" % (extra_args, img_file)
        pv_name = utils.system_output(cmd)
        self.params["pv_name"] = pv_name.strip()
        return pv_name

    def setup_pv(self, vg):
        """
        Setup physical volume device if exists return it directly;
        """
        pvs = []
        emulate_image_file = self.get_emulate_image_name()
        cmd = "losetup -j %s" % emulate_image_file
        output = utils.system_output(cmd)
        try:
            pv_name = re.findall("(/dev/loop\d+)", output, re.M | re.I)[-1]
            pv = self.get_vol(pv_name, "pvs")
        except IndexError:
            pv = None
        if pv is None:
            img_file = self.make_emulate_image()
            pv_name = self.make_volume(img_file)
            pv_size = self.params["pv_size"]
            pv = PhysicalVolume(pv_name, pv_size)
            pv.create()
            self.register(pv)
        else:
            logging.warn("PhysicalVolume(%s) really exists" % pv_name +
                         "skip to create it")
        pv.set_vg(vg)
        pvs.append(pv)
        return pvs

    def setup(self):
        """
        Main function to setup a lvm environments;

        :return: LogicalVolume path
        """
        self.rescan()
        lv = self.setup_lv()
        if "/dev/loop" not in lv.get_attr("devices"):
            lv.display()
            raise error.TestError("logical volume exists but is not a " +
                                  "emulated logical device")
        return lv.get_attr("lv_path")

    def cleanup(self):
        """
        Cleanup created logical volumes;
        """
        super(EmulatedLVM, self).cleanup()
        if self.params.get("remove_emulated_image", "no") == "yes":
            emulate_image_file = self.get_emulate_image_name()
            cmd = "losetup -j %s" % emulate_image_file
            output = utils.system_output(cmd)
            devices = re.findall("(/dev/loop\d+)", output, re.M | re.I)
            for dev in devices:
                cmd = "losetup -d %s" % dev
                logging.info("disconnect %s", dev)
                utils.system(cmd, ignore_status=True)
            emulate_image_file = self.get_emulate_image_name()
            cmd = "rm -f %s" % emulate_image_file
            utils.system(cmd, ignore_status=True)
            logging.info("remove emulate image file %s", emulate_image_file)

########NEW FILE########
__FILENAME__ = lvsb
"""
Higher order classes and functions for Libvirt Sandbox (lxc) container testing

:copyright: 2013 Red Hat Inc.
"""

import datetime
import time
import logging
import lvsb_base

# This utility function lets test-modules quickly create a list of all
# sandbox aggregate types, themselves containing a list of individual
# sandboxes.


def make_sandboxes(params, env, extra_ns=None):
    """
    Return list of instantiated lvsb_testsandboxes classes from params

    :param params: an undiluted Params instance
    :param env: the current env instance
    :param extra_ns: An extra, optional namespace to search for classes
    """
    namespace = globals()  # stuff in this module
    # For specialized sandbox types, allow their class to be defined
    # inside test module or elsewhere.
    if extra_ns is not None:
        namespace.update(extra_ns)  # copy in additional symbols
    names = namespace.keys()
    # Test may require more than one sandbox agregator class
    pobs = params.objects('lvsb_testsandboxes')  # manditory parameter
    # filter out non-TestSandboxes subclasses
    for name in names:
        try:
            if not issubclass(namespace[name], lvsb_base.TestSandboxes):
                # Working on name list, okay to modify dict
                del namespace[name]
        except TypeError:
            # Symbol wasn't a class, just ignore it
            pass
    # Return a list of instantiated sandbox_testsandboxes's classes
    return [namespace[type_name](params, env) for type_name in pobs]


# TestSandboxes subclasses defined below, or inside other namespaces like
# a test module.  They simply help the test-module iterate over many
# aggregate manager classes and the sandboxes they contain.

class TestBaseSandboxes(lvsb_base.TestSandboxes):

    """
    Simplistic sandbox aggregate manager
    """

    def __init__(self, params, env):
        """
        Initialize to run, all SandboxCommandBase's
        """
        super(TestBaseSandboxes, self).__init__(params, env)
        self.init_sandboxes()  # create instances of SandboxCommandBase
        # Point all of them at the same local uri
        self.for_each(lambda sb: sb.add_optarg('-c', self.uri))
        # The flag doesn't require sandbox name
        if not self.flag:
            # Use each instances name() method to produce name argument
            self.for_each(lambda sb: sb.add_optarg('-n', sb.name))

    def command_suffixes(self):
        """
        Append command after a --
        """
        # Command should follow after a --
        self.for_each(lambda sb: sb.add_mm())
        # Each one gets the same command (that's why it's simple)
        self.for_each(lambda sb: sb.add_pos(self.command))

    def results(self, each_timeout=5):
        """
        Run sandboxe(s), allowing each_timeout to complete, return output list
        """
        # Sandboxes run asynchronously, prevent them from running forever
        start = datetime.datetime.now()
        total_timeout_seconds = each_timeout * self.count
        timeout_at = start + datetime.timedelta(seconds=total_timeout_seconds)
        # No need to write a method just to call the run method
        self.for_each(lambda sb: sb.run())
        while datetime.datetime.now() < timeout_at:
            # Wait until number of running sandboxes is zero
            if bool(self.are_running()):
                time.sleep(0.1)  # Don't busy-wait
                continue
            else:  # none are running
                break
        # Needed for accurate time in logging message below
        end = datetime.datetime.now()
        # Needed for logging message if none exited before timeout
        still_running = self.are_running()
        # Cause all exited sessions to clean up when sb.stop() called
        self.for_each(lambda sb: sb.auto_clean(True))
        # If raise, auto_clean will make sure cleanup happens
        if bool(still_running):
            raise lvsb_base.SandboxException("%d of %d sandboxes are still "
                                             "running after "
                                             "the timeout of %d seconds."
                                             % (still_running,
                                                self.count,
                                                total_timeout_seconds))
        # Kill off all sandboxes, just to be safe
        self.for_each(lambda sb: sb.stop())
        logging.info("%d sandboxe(s) finished in %s", self.count,
                     end - start)
        # Return a list of stdout contents from each
        return self.for_each(lambda sb: sb.recv())


# TestBaseSandboxes subclasses which just runs simple default
# options with the same command.

class TestSimpleSandboxes(TestBaseSandboxes):

    """
    Executes a command with simple options
    """

    def __init__(self, params, env):
        """
        Initialize to run, all SandboxCommandBase's
        """
        super(TestSimpleSandboxes, self).__init__(params, env)
        # Appends command after options
        self.command_suffixes()


# TestBaseSandboxes subclasses which runs complex options and allows
# iterating for the options with the same command.

class TestComplexSandboxes(TestBaseSandboxes):

    """
    Executes a command with complex options
    """

    def __init__(self, params, env):
        super(TestComplexSandboxes, self).__init__(params, env)
        # Appends command options
        if self.opts:
            for k, v in self.opts:
                self.for_each(lambda sb: sb.add_optarg(k, v))
            # Appends command after options
            self.command_suffixes()
        if self.flag:
            for k in self.flag:
                self.for_each(lambda sb: sb.add_flag(k))
            # only '-h' and '-V' flags don't require '--' with command
            if "-h" not in self.flag and "-V" not in self.flag:
                # Appends command after options
                self.command_suffixes()

########NEW FILE########
__FILENAME__ = lvsbs
"""
Higher order classes for Libvirt Sandbox Service (lxc) service container testing
"""

from autotest.client import utils
from autotest.client.shared.service import COMMANDS
from virttest.staging import service
import lvsb_base
import virsh


class SandboxService(object):

    """
    Management for a single new/existing sandboxed service
    """

    def __init__(self, params, service_name, uri='lxc:///'):
        """Initialize connection to sandbox service with name and parameters"""
        # Intended workflow is:
        #   Use virt-sandbox-service for create/destroy
        #   Use service/systemd for runtime management
        #   Use virsh for list/edit/modify manipulation
        self.virsh = virsh.Virsh(uri=uri, ignore_status=True)
        self.command = lvsb_base.SandboxCommandBase(params, service_name)
        self.command.BINARY_PATH_PARAM = params.get('virt_sandbox_service_binary',
                                                    "virt-sandbox-service")
        self.command.add_optarg('--connect', uri)
        # We need to pass self.service_name to service.Factory.create_service to
        # create a service. Then we will get a SpecificServiceManager object as
        # self.service. But SpecificServiceManager is not pickleable, save init
        # args here.
        self._run = utils.run
        self.service = service.Factory.create_service(self.service_name,
                                                      run=self._run)
        # make self.start() --> self.service.start()
        self._bind_service_commands()

    def _bind_service_commands(self):
        """Setup service methods locally for __init__ and __setstate__"""
        for command in COMMANDS:
            # Use setattr to keep pylint quiet
            setattr(self, command, getattr(self.service, command))

    def __getstate__(self):
        """Serialize instance for pickling"""
        # SandboxCommandBase is directly pickleable
        return {'command': self.command, 'run': self._run, 'virsh': dict(virsh)}

    def __setstate__(self, state):
        """Actualize instance from state"""
        # virsh is it's own dict of init params
        self.virsh = virsh.Virsh(**state['virsh'])
        # already used it's own get/sets state methods when unpickling state
        self.command = state['command']
        # Recreate SpecificServiceManager from the init args
        self._run = state['run']
        self.service = service.Factory.create_service(self.service_name,
                                                      run=self._run)
        self._bind_service_commands()

    # Enforce read-only at all levels
    @property
    def service_name(self):
        return self.command.name

    # property accessor functions must be defined before naming attribute
    def __get_uri__(self):
        return self.virsh.uri

    def __set_uri__(self, uri):
        self.virsh.uri = uri

    def __del_uri__(self):
        # Virsh class interface insists this attribute exist, but can be None
        self.virsh.uri = None

    # Property definition must follow accessor definitions
    uri = property(__get_uri__, __set_uri__, __del_uri__)

    def create(self):
        return self.command.run(extra='create')

    def destroy(self):
        return self.command.run(extra='destroy')

    # Specialized list calls can just call self.virsh.dom_list() directly
    @property  # behave like attribute to make value-access easier
    def list(self):
        """
        Return list of dictionaries mapping column names to values
        """
        # For simple callers, just return list of names to be convenient
        cmdresult = self.virsh.dom_list()  # uri is passed automatically
        result = []
        column_names = None  # scope outside loop
        for lineno, line in cmdresult.stdout.strip():
            if lineno == 0:
                column_names = line.strip().split()
                assert len(column_names) > 2
            else:
                assert column_names is not None
                # raises exception when column_names & value count mismatch
                items = [(column_names[index].lower(), value.lower())
                         for index, value in line.strip().split()]
                # combine [('id',99), ('name', 'foobar'), ('state', 'running')]
                result.append(dict(items))
        return result

    # Specialized list calls can just call self.virsh.dom_list() directly
    @property  # behave like attribute for easy passing to XML handling methods
    def xmlstr(self):
        return self.virsh.dumpxml(self.service_name).stdout.strip()

########NEW FILE########
__FILENAME__ = lvsb_base
"""
Base classes supporting Libvirt Sandbox (lxc) container testing

:copyright: 2013 Red Hat Inc.
"""

import logging
import signal
import aexpect


class SandboxException(Exception):

    """
    Basic exception class for problems occurring in SandboxBase or subclasses
    """

    def __init__(self, message):
        super(SandboxException, self).__init__()
        self.message = message

    def __str__(self):
        return self.message


# This is to allow us to alter back-end session management w/o affecting
# sandbox subclasses
class SandboxSession(object):

    """
    Connection instance to asynchronous I/O redirector process
    """

    # Assist with warning on re-use
    used = False

    def __init__(self):
        self.session = None  # createdby new_session

    @property
    def connected(self):
        """
        Represents True/False value if background process was created/opened
        """
        if self.session is None:
            return False
        else:
            return True

    @property
    def session_id(self):
        """
        Returns unique & persistent identifier for the background process
        """
        if self.connected:
            return self.session.get_id()
        else:
            raise SandboxException("Can't get id of non-running sandbox "
                                   "session")

    def new_session(self, command):
        """
        Create and set new opaque session object
        """
        # Allow this to be called more than once w/o consequence
        self.close_session(warn_if_nonexist=self.used)
        self.session = aexpect.Expect(command, auto_close=False)
        self.used = True

    def open_session(self, a_id):
        """
        Restore connection to existing session identified by a_id
        """
        # Allow this to be called more than once w/o consequence
        self.close_session(warn_if_nonexist=self.used)
        aexpect.Expect(a_id=a_id)
        self.used = True

    def close_session(self, warn_if_nonexist=True):
        """
        Finalize assigned opaque session object
        """
        # Allow this to be called more than once w/o consequence
        if self.connected:
            self.session.close()
        else:
            if warn_if_nonexist:
                logging.warning("Closing nonexisting sandbox session")

    def kill_session(self, sig=signal.SIGTERM):
        """
        Send a signal to the opaque session object
        """
        if self.connected:
            self.session.kill(sig=sig)
        else:
            raise SandboxException("Can't send signal to inactive sandbox "
                                   "session")

    def send(self, a_string):
        """Send a_string to session"""
        if self.connected:
            self.session.send(a_string)
        else:
            raise SandboxException("Can't send to an inactive sandbox session")

    def recv(self):
        """Return combined stdout/stderr output received so far"""
        if self.connected:
            return self.session.get_output()
        else:
            raise SandboxException("Can't get output from finalized sandbox "
                                   "session")

    def recvout(self):
        """Return just stdout output"""
        # FIXME: aexpect combines stdout and stderr in a single pipe :(
        raise NotImplementedError

    def recverr(self):
        """Return just stderr output"""
        # FIXME: aexpect combines stdout and stderr in a single pipe :(
        raise NotImplementedError

    def exit_code(self):
        """Block, and return exit code from session"""
        if self.connected:
            return self.session.get_status()
        else:
            raise SandboxException("Can't get exit code from finalized sandbox "
                                   "session")

    def is_running(self):
        """Return True if exit_code() would block"""
        if self.connected:
            return self.session.is_alive()
        else:
            return None

    def auto_clean(self, boolean):
        """Make session cleanup on GC if True"""
        if self.connected:
            self.session.auto_close = boolean
        else:
            raise SandboxException("Can't set auto_clean on disconnected "
                                   "sandbox session")


class SandboxBase(object):

    """
    Base operations for sandboxed command
    """

    # Provide unique instance number for each sandbox
    instances = None

    def __init__(self, params):
        """
        Create a new sandbox interface instance based on this type from params
        """
        # Un-pickling instances doesn't call init again
        if self.__class__.instances is None:
            self.__class__.instances = 1
        else:
            self.__class__.instances += 1
        # store a copy for use to avoid referencing class attribute
        self.identifier = self.__class__.instances
        # Allow global 'lvsb_*' keys to be overridden for specific subclass
        self.params = params.object_params(self.__class__.__name__)
        self.options = None  # opaque value consumed by make_command()
        # Aexpect has some well hidden bugs, private attribute hides
        # interface in case it changes from fixes or gets swapped out
        # entirely.
        self._session = SandboxSession()

    # Allow running sandboxes to persist across multiple tests if needed
    def __getstate__(self):
        """Serialize instance for pickling"""
        # Regular dictionary format for now, but could change later
        state = {'params': self.params,
                 'identifier': self.identifier,
                 'options': self.options}
        # Critical info. to re-connect to session when un-pickle
        if self._session.connected:
            state['session_id'] = self._session.session_id
        return state

    def __setstate__(self, state):
        """Actualize instance from state"""
        for key in ('identifier', 'params', 'options'):
            setattr(self, key, state[key])
        if state.haskey('session_id'):
            self._session = SandboxSession()
            self._session.open_session(state['session_id'])

    def run(self, extra=None):
        """
        Launch new sandbox as asynchronous background sandbox process

        :param extra: String of extra command-line to use but not store
        """
        sandbox_cmdline = self.make_sandbox_command_line(extra)
        logging.debug("Launching %s", sandbox_cmdline)
        self._session.new_session(sandbox_cmdline)

    def stop(self):
        """Destroy but don't finalize asynchronous background sandbox process"""
        self._session.kill_session()

    def fini(self):
        """
        Finalize asynchronous background sandbox process (destroys state!)
        """
        self._session.close_session()

    def send(self, data):
        """Send data to asynchronous background sandbox process"""
        self._session.send(data)

    def recv(self):
        """
        Return stdout and stderr from asynchronous background sandbox process
        """
        return self._session.recv()

    def recvout(self):
        """
        Return only stdout from asynchronous background sandbox process
        """
        return self._session.recvout()

    def recverr(self):
        """
        return only stderr from asynchronous background sandbox process
        """
        return self._session.recverr()

    def running(self):
        """
        Return True/False if asynchronous background sandbox process executing
        """
        return self._session.is_running()

    def exit_code(self):
        """
        Block until asynchronous background sandbox process ends, returning code
        """
        return self._session.exit_code()

    def auto_clean(self, boolean):
        """
        Change behavior of asynchronous background sandbox process on __del__
        """
        self._session.auto_clean(boolean)

    def make_sandbox_command_line(self, extra=None):
        """
        Return the fully formed command-line for the sandbox using self.options
        """
        # These are the abstract methods subclasses must override
        raise NotImplementedError


class SandboxCommandBase(SandboxBase):

    """
    Connection to a single new or existing sandboxed command
    """

    BINARY_PATH_PARAM = 'virt_sandbox_binary'

    # Cache generated name first time it is requested
    _name = None

    def __init__(self, params, name=None):
        """
        Initialize sandbox-command with params and name, autogenerate if None
        """
        if name is not None:
            self._name = name
        super(SandboxCommandBase, self).__init__(params)

    def __getstate__(self):
        """Serialize instance for pickling"""
        state = super(SandboxCommandBase, self).__getstate__()
        state['name'] = self._name
        return state

    def __setstate__(self, state):
        """Actualize instance from state"""
        self._name = state.pop('name')
        super(SandboxCommandBase, self).__setstate__(state)

    def __get_name__(self):
        """
        Represent a unique sandbox name generated from class and identifier
        """
        # Use shortest possible unique names for instances to be easier
        # to track and make name-comparison fast when there are 10000's
        # of sandboxes. Only use upper-case letters from class name along
        # with instance identifier attribute.
        if self._name is None:
            class_name = self.__class__.__name__
            class_initials = class_name.translate(None,
                                                  'abcdefghijklmnopqrstuvwxyz')
            self._name = "%s_%d" % (class_initials, self.identifier)
        return self._name

    @staticmethod
    def __set_name__(value):
        del value  # not used
        raise SandboxException("Name is read-only")

    @staticmethod
    def __del_name__():
        raise SandboxException("Name is read-only")

    name = property(__get_name__, __set_name__, __del_name__)

    @staticmethod
    def flaten_options(options):
        """
        Convert a list of tuples into space-seperated options+argument string
        """
        result_list = []
        for option, argument in options:
            # positional argument
            if option is None:
                if argument is not None:
                    result_list.append(argument)
                # both empty, ignore
            else:  # option is not None
                # --flag
                if argument is None:
                    result_list.append(option)
                else:  # argument is not None
                    # --option argument or -o argument
                    result_list.append("%s %s" % (option, argument))
        if len(result_list) > 0:
            return " " + " ".join(result_list)
        else:  # they were all (None, None)
            return ""

    def make_sandbox_command_line(self, extra=None):
        """Return entire command-line string needed to start sandbox"""
        command = self.params[self.BINARY_PATH_PARAM]  # mandatory param
        if self.options is not None:
            command += self.flaten_options(self.options)
        if extra is not None:
            command += ' ' + extra
        return command

    def add_optarg(self, option, argument):
        """
        Add an option with an argument into the list of command line options
        """
        if self.options is None:
            self.options = []
        self.options.append((option, argument))

    def add_flag(self, option):
        """
        Add a flag into the list of command line options
        """
        # Tuple encoding required for flaten_options()
        self.add_optarg(option, None)

    def add_pos(self, argument):
        """
        Add a positional option into the list of command line options
        """
        # Tuple encoding required for flaten_options()
        self.add_optarg(None, argument)

    def add_mm(self):
        """
        Append a -- to the end of the current option list
        """
        self.add_pos('--')

    def list_long_options(self):
        """
        Return a list of all long options with an argument
        """
        return [opt for opt, arg in self.options
                if opt.startswith('--') and arg is not None]

    def list_short_options(self):
        """
        Return a list of all short options with an argument
        """
        result = []
        for opt, arg in self.options:
            if arg is None:
                continue  # flag or positional
            if len(opt) > 1 and opt[0] == '-' and opt[1] != '-':
                result.append(opt)

    def list_flags(self):
        """
        Return a list of all flags (options without arguments)
        """
        return [opt for opt, arg in self.options
                if opt.startswith('--') and arg is None]

    def list_pos(self):
        """
        Return a list of all positional arguments
        """
        return [arg for opt, arg in self.options if opt is None]


# Instances are similar to a list-of-lists- multiple kinds (classes) of
# multiple sandobx executions.
class TestSandboxes(object):

    """
    Aggregate manager class of SandboxCommandBase or subclass instances
    """

    # The class of each sandbox instance to operate on
    SANDBOX_TYPE = SandboxCommandBase

    def __init__(self, params, env):
        """
        Create instance(s) of sandbox from a command
        """
        # public attribute for access to each sandbox execution
        self.sandboxes = []
        # Each sandbox type will object_params() itself
        self.params = params
        # In case a subclass wants to interface with tests before/after
        self.env = env
        # Parse out aggregate manager class-specific params
        pop = self.params.object_params(self.__class__.__name__)
        # Allows iterating over all sandboxes e.g. with for_each()
        self.count = int(pop.get('lvsb_count', '1'))
        # Simple-case is all sandboxes on the local host
        self.uri = pop.get('lvsb_uri', 'lxc:///')
        # The command to run inside the sandbox
        self.command = pop.get('lvsb_command')
        # Allows iterating for the options
        self.opts_count = int(pop.get('lvsb_opts_count', '1'))
        # FIXME: should automatically generate this
        self.lvsb_option_mapper = {'optarg': {'connect': '-c', 'name': '-n',
                                              'mount': '-m', 'include': '-i',
                                              'includefile': '-I', 'network': '-N',
                                              'security': '-s'},
                                   'flag': {'help': '-h', 'version': '-V',
                                            'debug': '-d', 'privileged': '-p',
                                            'shell': '-l'}}
        # The list to save options
        self.opts = []
        self.flag = []
        for k in self.lvsb_option_mapper.keys():
            # k may be 'optarg' or 'flag'
            for key, value in self.lvsb_option_mapper[k].items():
                base_name = 'lvsb_%s_options' % key
                for key_gen, option in params.object_counts('lvsb_opts_count',
                                                            base_name):
                    # k is 'optarg'
                    if option and value:
                        self.opts.append((value, option))
                    # k is 'flag'
                    if params.has_key(key_gen) and not option:
                        self.flag.append(value)

        logging.debug("All of options(%s) and flags(%s)", self.opts, self.flag)

    def init_sandboxes(self):
        """
        Create self.count Sandbox instances
        """
        # self.sandboxes probably empty, can't use for_each()
        for index in xrange(0, self.count):
            del index  # Keep pylint happy
            self.sandboxes.append(self.SANDBOX_TYPE(self.params))

    def for_each(self, do_something, *args, **dargs):
        """
        Iterate over all sandboxes, calling do_something on each

        :param do_sometihng: Called with the item and ``*args``, ``**dargs``
        """
        # Simplify making the same call to every running sandbox
        return [do_something(sandbox, *args, **dargs)
                for sandbox in self.sandboxes]

    def are_running(self):
        """
        Return the number of sandbox processes still running
        """
        running = 0
        for is_running in self.for_each(lambda sb: sb.running()):
            if is_running:
                running += 1
        return running

    def are_failed(self):
        """
        Return the number of sandbox processes with non-zero exit codes
        """
        # Warning, this will block if self.are_running() > 0
        failed = 0
        for exit_code in self.for_each(lambda sb: sb.exit_code()):
            if exit_code != 0:
                failed += 1
        return failed

########NEW FILE########
__FILENAME__ = nfs
"""
Basic nfs support for Linux host. It can support the remote
nfs mount and the local nfs set up and mount.
"""
import re
import os
import logging
from autotest.client import os_dep
from autotest.client.shared import utils, error
from virttest import utils_misc

from virttest.staging import service


def nfs_exported():
    """
    Get the list for nfs file system already exported

    :return: a list of nfs that is already exported in system
    :rtype: a lit of nfs file system exported
    """
    exportfs = utils.system_output("exportfs -v")
    if not exportfs:
        return {}

    nfs_exported_dict = {}
    for fs_info in re.findall("[/\w+]+.*?\(.*?\)", exportfs, re.S):
        fs_info = fs_info.strip().split()
        if len(fs_info) == 2:
            nfs_src = fs_info[0]
            access_ip = re.findall(r"(.*)\(", fs_info[1])[0]
            if "world" in access_ip:
                access_ip = "*"
            nfs_tag = "%s_%s" % (nfs_src, access_ip)
            permission = re.findall(r"\((.*)\)", fs_info[1])[0]
            nfs_exported_dict[nfs_tag] = permission

    return nfs_exported_dict


class Exportfs(object):

    """
    Add or remove one entry to exported nfs file system.
    """

    def __init__(self, path, client="*", options="", ori_exported=None):
        if ori_exported is None:
            ori_exported = []
        self.path = path
        self.client = client
        self.options = options.split(",")
        self.ori_exported = ori_exported
        self.entry_tag = "%s_%s" % (self.path, self.client)
        self.already_exported = False
        self.ori_options = ""

    def is_exported(self):
        """
        Check if the directory is already exported.

        :return: If the entry is exported
        :rtype: Boolean
        """
        ori_exported = self.ori_exported or nfs_exported()
        if self.entry_tag in ori_exported.keys():
            return True
        return False

    def need_reexport(self):
        """
        Check if the entry is already exported but the options are not
        the same as we required.

        :return: Need re export the entry or not
        :rtype: Boolean
        """
        ori_exported = self.ori_exported or nfs_exported()
        if self.is_exported():
            exported_options = ori_exported[self.entry_tag]
            options = [_ for _ in self.options if _ not in exported_options]
            if options:
                self.ori_options = exported_options
                return True
        return False

    def unexport(self):
        """
        Unexport an entry.
        """
        if self.is_exported():
            unexport_cmd = "exportfs -u %s:%s" % (self.client, self.path)
            utils.system(unexport_cmd)
        else:
            logging.warn("Target %s %s is not exported yet."
                         "Can not unexport it." % (self.client, self.path))

    def reset_export(self):
        """
        Reset the exportfs to the original status before we export the
        specific entry.
        """
        self.unexport()
        if self.ori_options:
            tmp_options = self.options
            self.options = self.ori_options.split(",")
            self.export()
            self.options = tmp_options

    def export(self):
        """
        Export one directory if it is not in exported list.

        :return: Export nfs file system succeed or not
        """
        if self.is_exported():
            if self.need_reexport():
                self.unexport()
            else:
                self.already_exported = True
                logging.warn("Already exported target."
                             " Don't need export it again")
                return True
        export_cmd = "exportfs"
        if self.options:
            export_cmd += " -o %s" % ",".join(self.options)
        export_cmd += " %s:%s" % (self.client, self.path)
        try:
            utils.system(export_cmd)
        except error.CmdError, export_failed_err:
            logging.error("Can not export target: %s" % export_failed_err)
            return False
        return True


class Nfs(object):

    """
    Nfs class for handle nfs mount and umount. If a local nfs service is
    required, it will configure a local nfs server accroding the params.
    """

    def __init__(self, params):
        self.mount_dir = params.get("nfs_mount_dir")
        self.mount_options = params.get("nfs_mount_options")
        self.mount_src = params.get("nfs_mount_src")
        self.nfs_setup = False
        os_dep.command("mount")
        self.unexportfs_in_clean = False

        if params.get("setup_local_nfs") == "yes":
            self.nfs_setup = True
            os_dep.command("service")
            os_dep.command("exportfs")
            self.nfs_service = service.Factory.create_service("nfs")

            self.export_dir = (params.get("export_dir")
                               or self.mount_src.split(":")[-1])
            self.export_ip = params.get("export_ip", "*")
            self.export_options = params.get("export_options", "").strip()
            self.exportfs = Exportfs(self.export_dir, self.export_ip,
                                     self.export_options)
            self.mount_src = "127.0.0.1:%s" % self.export_dir

    def is_mounted(self):
        """
        Check the NFS is mounted or not.

        :return: If the src is mounted as expect
        :rtype: Boolean
        """
        return utils_misc.is_mounted(self.mount_src, self.mount_dir, "nfs")

    def mount(self):
        """
        Mount source into given mount point.
        """
        return utils_misc.mount(self.mount_src, self.mount_dir, "nfs",
                                perm=self.mount_options)

    def umount(self):
        """
        Umount the given mount point.
        """
        return utils_misc.umount(self.mount_src, self.mount_dir, "nfs")

    def setup(self):
        """
        Setup NFS in host.

        Mount NFS as configured. If a local nfs is requested, setup the NFS
        service and exportfs too.
        """
        if self.nfs_setup:
            if not self.nfs_service.status():
                logging.debug("Restart NFS service.")
                self.nfs_service.restart()

            if not os.path.isdir(self.export_dir):
                os.makedirs(self.export_dir)
            self.exportfs.export()
            self.unexportfs_in_clean = not self.exportfs.already_exported

        logging.debug("Mount %s to %s" % (self.mount_src, self.mount_dir))
        if os.path.exists(self.mount_dir) and not os.path.isdir(self.mount_dir):
            raise OSError(
                "Mount point %s is not a directory, check your setup." %
                self.mount_dir)

        if not os.path.isdir(self.mount_dir):
            os.makedirs(self.mount_dir)
        self.mount()

    def cleanup(self):
        """
        Clean up the host env.

        Umount NFS from the mount point. If there has some change for exported
        file system in host when setup, also clean up that.
        """
        self.umount()
        if self.nfs_setup and self.unexportfs_in_clean:
            self.exportfs.reset_export()

########NEW FILE########
__FILENAME__ = nfs_unittest
#!/usr/bin/python
import unittest
import os

import common
from autotest.client.shared.test_utils import mock
from autotest.client import os_dep
from autotest.client.shared import utils

from virttest import nfs
from virttest import utils_misc

from virttest.staging import service


class FakeService(object):

    def __init__(self, service_name):
        self.fake_cmds = [{"cmd": "status", "stdout": True},
                          {"cmd": "restart", "stdout": ""}]

    def get_stdout(self, cmd):
        for fake_cmd in self.fake_cmds:
            if fake_cmd['cmd'] == cmd:
                return fake_cmd['stdout']
        raise ValueError("Could not locate locate '%s' on fake cmd db" % cmd)

    def status(self):
        return self.get_stdout("status")

    def restart(self):
        return self.get_stdout("restart")


class nfs_test(unittest.TestCase):

    def setup_stubs_init(self):
        os_dep.command.expect_call("mount")
        os_dep.command.expect_call("service")
        os_dep.command.expect_call("exportfs")
        service.Factory.create_service.expect_call("nfs").and_return(
            FakeService("nfs"))
        mount_src = self.nfs_params.get("nfs_mount_src")
        export_dir = (self.nfs_params.get("export_dir")
                      or mount_src.split(":")[-1])
        export_ip = self.nfs_params.get("export_ip", "*")
        export_options = self.nfs_params.get("export_options", "").strip()
        nfs.Exportfs.expect_new(export_dir, export_ip, export_options)

    def setup_stubs_setup(self, nfs_obj):
        os.makedirs.expect_call(nfs_obj.export_dir)
        nfs_obj.exportfs.export.expect_call()
        os.makedirs.expect_call(nfs_obj.mount_dir)
        utils_misc.mount.expect_call(nfs_obj.mount_src, nfs_obj.mount_dir,
                                     "nfs", perm=nfs_obj.mount_options)

    def setup_stubs_is_mounted(self, nfs_obj):
        utils_misc.is_mounted.expect_call(nfs_obj.mount_src,
                                          nfs_obj.mount_dir,
                                          "nfs").and_return(True)

    def setup_stubs_cleanup(self, nfs_obj):
        utils_misc.umount.expect_call(nfs_obj.mount_src,
                                      nfs_obj.mount_dir,
                                      "nfs")
        nfs_obj.exportfs.reset_export.expect_call()

    def setUp(self):
        self.nfs_params = {"nfs_mount_dir": "/mnt/nfstest",
                           "nfs_mount_options": "rw",
                           "nfs_mount_src": "127.0.0.1:/mnt/nfssrc",
                           "setup_local_nfs": "yes",
                           "export_options": "rw,no_root_squash"}
        self.god = mock.mock_god()
        self.god.stub_function(os_dep, "command")
        self.god.stub_function(utils, "system")
        self.god.stub_function(utils, "system_output")
        self.god.stub_function(os.path, "isfile")
        self.god.stub_function(os, "makedirs")
        self.god.stub_function(utils_misc, "is_mounted")
        self.god.stub_function(utils_misc, "mount")
        self.god.stub_function(utils_misc, "umount")
        self.god.stub_function(service.Factory, "create_service")
        attr = getattr(nfs, "Exportfs")
        setattr(attr, "already_exported", False)
        mock_class = self.god.create_mock_class_obj(attr, "Exportfs")
        self.god.stub_with(nfs, "Exportfs", mock_class)

    def tearDown(self):
        self.god.unstub_all()

    def test_nfs_setup(self):
        self.setup_stubs_init()
        nfs_local = nfs.Nfs(self.nfs_params)
        self.setup_stubs_setup(nfs_local)
        nfs_local.setup()
        self.setup_stubs_is_mounted(nfs_local)
        self.assertTrue(nfs_local.is_mounted())
        self.setup_stubs_cleanup(nfs_local)
        nfs_local.cleanup()
        self.god.check_playback()


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = openvswitch
import logging
import re
import os
import signal
try:
    import autotest.common as common
except ImportError:
    import common
from autotest.client import utils, os_dep
from autotest.client.shared import error
from versionable_class import VersionableClass, Manager, factory
import utils_misc

# Register to class manager.
man = Manager(__name__)


class ServiceManagerInterface(object):

    def __new__(cls, *args, **kargs):
        ServiceManagerInterface.master_class = ServiceManagerInterface
        return super(ServiceManagerInterface, cls).__new__(cls, *args, **kargs)

    @classmethod
    def get_version(cls):
        """
        Get version of ServiceManager.
        :return: Version of ServiceManager.
        """
        return open("/proc/1/comm", "r").read().strip()

    def stop(self, service_name):
        raise NotImplementedError("Method 'stop' must be"
                                  " implemented in child class")

    def start(self, service_name):
        raise NotImplementedError("Method 'start' must be"
                                  " implemented in child class")

    def restart(self, service_name):
        raise NotImplementedError("Method 'restart' must be"
                                  " implemented in child class")

    def status(self, service_name):
        raise NotImplementedError("Method 'status' must be"
                                  " implemented in child class")


class ServiceManagerSysvinit(ServiceManagerInterface):

    @classmethod
    def _is_right_ver(cls):
        version = cls.get_version()
        if version == "init":
            return True
        return False

    def stop(self, service_name):
        utils.run("/etc/init.d/%s stop" % (service_name))

    def start(self, service_name):
        utils.run("/etc/init.d/%s start" % (service_name))

    def restart(self, service_name):
        utils.run("/etc/init.d/%s restart" % (service_name))


class ServiceManagerSystemD(ServiceManagerSysvinit):

    @classmethod
    def _is_right_ver(cls):
        version = cls.get_version()
        if version == "systemd":
            return True
        return False

    def stop(self, service_name):
        utils.run("systemctl stop %s.service" % (service_name))

    def start(self, service_name):
        utils.run("systemctl start %s.service" % (service_name))

    def restart(self, service_name):
        utils.run("systemctl restart %s.service" % (service_name))

    def status(self, service_name):
        utils.run("systemctl show %s.service" % (service_name))


class ServiceManager(VersionableClass):
    __master__ = ServiceManagerSystemD


class OpenVSwitchControl(object):

    """
    Class select the best matches control class for installed version
    of OpenVSwitch.

    OpenVSwtich parameters are described in man ovs-vswitchd.conf.db
    """
    def __new__(cls, db_path=None, db_socket=None, db_pidfile=None,
                ovs_pidfile=None, dbschema=None, install_prefix=None):
        """
        Makes initialization of OpenVSwitch.

        :param tmpdir: Tmp directory for save openvswitch test files.
        :param db_path: Path of OVS databimpoty ase.
        :param db_socket: Path of OVS db socket.
        :param db_pidfile: Path of OVS db ovsdb-server pid.
        :param ovs_pidfile: Path of OVS ovs-vswitchd pid.
        :param install_prefix: Path where is openvswitch installed.
        """
        # if path is None set default path.
        if not install_prefix:
            install_prefix = "/"
        if not db_path:
            db_path = os.path.join(install_prefix,
                                   "/etc/openvswitch/conf.db")
        if not db_socket:
            db_socket = os.path.join(install_prefix,
                                     "/var/run/openvswitch/db.sock")
        if not db_pidfile:
            db_pidfile = os.path.join(install_prefix,
                                      "/var/run/openvswitch/ovsdb-server.pid")
        if not ovs_pidfile:
            ovs_pidfile = os.path.join(install_prefix,
                                       "/var/run/openvswitch/ovs-vswitchd.pid")
        if not dbschema:
            dbschema = os.path.join(install_prefix,
                                    "/usr/share/openvswitch/vswitch.ovsschema")

        OpenVSwitchControl.install_prefix = install_prefix

        OpenVSwitchControl.db_path = db_path
        OpenVSwitchControl.db_socket = db_socket
        OpenVSwitchControl.db_pidfile = db_pidfile
        OpenVSwitchControl.ovs_pidfile = ovs_pidfile

        OpenVSwitchControl.dbschema = install_prefix, dbschema
        os.environ["PATH"] = (os.path.join(install_prefix, "usr/bin:") +
                              os.environ["PATH"])
        os.environ["PATH"] = (os.path.join(install_prefix, "usr/sbin:") +
                              os.environ["PATH"])

        return super(OpenVSwitchControl, cls).__new__(cls)

    @staticmethod
    def convert_version_to_int(version):
        """
        :param version: (int) Converted from version string 1.4.0 => int 140
        """
        if (isinstance(version, int)):
            return version
        try:
            int_ver = int(version.replace(".", ""))
        except:
            raise error.AutotestError("Wrong version format '%s'" % (version))
        return int_ver

    @classmethod
    def get_version(cls):
        """
        Get version of installed OpenVSwtich.

        :return: Version of OpenVSwtich.
        """
        version = None
        try:
            result = utils.run(os_dep.command("ovs-vswitchd"),
                               args=["--version"])
            pattern = "ovs-vswitchd \(Open vSwitch\) (.+)"
            version = re.search(pattern, result.stdout).group(1)
        except error.CmdError:
            logging.debug("OpenVSwitch is not available in system.")
        return version

    def status(self):
        raise NotImplementedError()

    def add_br(self, br_name):
        raise NotImplementedError()

    def del_br(self, br_name):
        raise NotImplementedError()

    def br_exist(self, br_name):
        raise NotImplementedError()

    def list_br(self):
        raise NotImplementedError()

    def add_port(self, br_name, port_name):
        raise NotImplementedError()

    def del_port(self, br_name, port_name):
        raise NotImplementedError()

    def add_port_tag(self, port_name, tag):
        raise NotImplementedError()

    def add_port_trunk(self, port_name, trunk):
        raise NotImplementedError()

    def set_vlanmode(self, port_name, vlan_mode):
        raise NotImplementedError()

    def check_port_in_br(self, br_name, port_name):
        raise NotImplementedError()


class OpenVSwitchControlDB_140(OpenVSwitchControl):

    """
    Don't use this class directly. This class is automatically selected by
    OpenVSwitchControl.
    """
    @classmethod
    def _is_right_ver(cls):
        """
        Check condition for select control class.

        :param version: version of OpenVSwtich
        """
        version = cls.get_version()
        if version is not None:
            int_ver = cls.convert_version_to_int(version)
            if int_ver >= 140:
                return True
        return False

    # TODO: implement database manipulation methods.


class OpenVSwitchControlDB_CNT(VersionableClass):
    __master__ = OpenVSwitchControlDB_140


class OpenVSwitchControlCli_140(OpenVSwitchControl):

    """
    Don't use this class directly. This class is automatically selected by
    OpenVSwitchControl.
    """
    @classmethod
    def _is_right_ver(cls):
        """
        Check condition for select control class.

        :param version: version of OpenVSwtich
        """
        version = cls.get_version()
        if version is not None:
            int_ver = cls.convert_version_to_int(version)
            if int_ver >= 140:
                return True
        return False

    def ovs_vsctl(self, parmas, ignore_status=False):
        return utils.run(os_dep.command("ovs-vsctl"), timeout=10,
                         ignore_status=ignore_status, verbose=False,
                         args=["--db=unix:%s" % (self.db_socket)] + parmas)

    def status(self):
        return self.ovs_vsctl(["show"]).stdout

    def add_br(self, br_name):
        self.ovs_vsctl(["add-br", br_name])

    def add_fake_br(self, br_name, parent, vlan):
        self.ovs_vsctl(["add-br", br_name, parent, vlan])

    def del_br(self, br_name):
        try:
            self.ovs_vsctl(["del-br", br_name])
        except error.CmdError, e:
            logging.debug(e.result_obj)
            raise

    def br_exist(self, br_name):
        try:
            self.ovs_vsctl(["br-exists", br_name])
        except error.CmdError, e:
            if e.result_obj.exit_status == 2:
                return False
            else:
                raise
        return True

    def list_br(self):
        return self.ovs_vsctl(["list-br"]).stdout.splitlines()

    def add_port(self, br_name, port_name):
        self.ovs_vsctl(["add-port", br_name, port_name])

    def del_port(self, br_name, port_name):
        self.ovs_vsctl(["del-port", br_name, port_name])

    def add_port_tag(self, port_name, tag):
        self.ovs_vsctl(["set", "Port", port_name, "tag=%s" % tag])

    def add_port_trunk(self, port_name, trunk):
        """
        :param trunk: list of vlans id.
        """
        trunk = map(lambda x: str(x), trunk)
        trunk = "[" + ",".join(trunk) + "]"
        self.ovs_vsctl(["set", "Port", port_name, "trunk=%s" % trunk])

    def set_vlanmode(self, port_name, vlan_mode):
        self.ovs_vsctl(["set", "Port", port_name, "vlan-mode=%s" % vlan_mode])

    def list_ports(self, br_name):
        return self.ovs_vsctl(["list-ports", br_name]).stdout.splitlines()

    def port_to_br(self, port_name):
        """
        Return bridge which contain port.

        :param port_name: Name of port.
        :return: Bridge name or None if there is no bridge which contain port.
        """
        bridge = None
        try:
            bridge = self.ovs_vsctl(["port-to-br", port_name]).stdout.strip()
        except error.CmdError, e:
            if e.result_obj.exit_status == 1:
                pass
        return bridge


class OpenVSwitchControlCli_CNT(VersionableClass):
    __master__ = OpenVSwitchControlCli_140


class OpenVSwitchSystem(OpenVSwitchControlCli_CNT, OpenVSwitchControlDB_CNT):

    """
    OpenVSwtich class.
    """

    def __init__(self, db_path=None, db_socket=None, db_pidfile=None,
                 ovs_pidfile=None, dbschema=None, install_prefix=None):
        """
        Makes initialization of OpenVSwitch.

        :param db_path: Path of OVS database.
        :param db_socket: Path of OVS db socket.
        :param db_pidfile: Path of OVS db ovsdb-server pid.
        :param ovs_pidfile: Path of OVS ovs-vswitchd pid.
        :param install_prefix: Path where is openvswitch installed.
        """
        sup = super(man[self.__class__, OpenVSwitchSystem], self)
        sup.__init__(self, db_path, db_socket, db_pidfile, ovs_pidfile,
                     dbschema, install_prefix)

        self.cleanup = False
        self.pid_files_path = None

    def is_installed(self):
        """
        Check if OpenVSwitch is already installed in system on default places.

        :return: Version of OpenVSwtich.
        """
        if self.get_version():
            return True
        else:
            return False

    def check_db_daemon(self):
        """
        Check if OVS daemon is started correctly.
        """
        working = utils_misc.program_is_alive(
            "ovsdb-server", self.pid_files_path)
        if not working:
            logging.error("OpenVSwitch database daemon with PID in file %s"
                          " not working.", self.db_pidfile)
        return working

    def check_switch_daemon(self):
        """
        Check if OVS daemon is started correctly.
        """
        working = utils_misc.program_is_alive(
            "ovs-vswitchd", self.pid_files_path)
        if not working:
            logging.error("OpenVSwitch switch daemon with PID in file %s"
                          " not working.", self.ovs_pidfile)
        return working

    def check_db_file(self):
        """
        Check if db_file exists.
        """
        exists = os.path.exists(self.db_path)
        if not exists:
            logging.error("OpenVSwitch database file %s not exists.",
                          self.db_path)
        return exists

    def check_db_socket(self):
        """
        Check if db socket exists.
        """
        exists = os.path.exists(self.db_socket)
        if not exists:
            logging.error("OpenVSwitch database socket file %s not exists.",
                          self.db_socket)
        return exists

    def check(self):
        return (self.check_db_daemon() and self.check_switch_daemon() and
                self.check_db_file() and self.check_db_socket())

    def init_system(self):
        """
        Create new dbfile without any configuration.
        """
        sm = factory(ServiceManager)()
        try:
            if utils.load_module("openvswitch"):
                sm.restart("openvswitch")
        except error.CmdError:
            logging.error("Service OpenVSwitch is probably not"
                          " installed in system.")
            raise
        self.pid_files_path = "/var/run/openvswitch/"

    def clean(self):
        """
        Empty cleanup function
        """
        pass


class OpenVSwitch(OpenVSwitchSystem):

    """
    OpenVSwtich class.
    """

    def __init__(self, tmpdir, db_path=None, db_socket=None, db_pidfile=None,
                 ovs_pidfile=None, dbschema=None, install_prefix=None):
        """
        Makes initialization of OpenVSwitch.

        :param tmpdir: Tmp directory for save openvswitch test files.
        :param db_path: Path of OVS database.
        :param db_socket: Path of OVS db socket.
        :param db_pidfile: Path of OVS db ovsdb-server pid.
        :param ovs_pidfile: Path of OVS ovs-vswitchd pid.
        :param install_prefix: Path where is openvswitch installed.
        """
        super(man[self, OpenVSwitch], self).__init__(db_path, db_socket,
                                                     db_pidfile, ovs_pidfile,
                                                     dbschema, install_prefix)
        self.tmpdir = "/%s/openvswitch" % (tmpdir)
        try:
            os.mkdir(self.tmpdir)
        except OSError, e:
            if e.errno != 17:
                raise

    def init_db(self):
        utils.run(os_dep.command("ovsdb-tool"), timeout=10,
                  args=["create", self.db_path, self.dbschema])
        utils.run(os_dep.command("ovsdb-server"), timeout=10,
                  args=["--remote=punix:%s" % (self.db_socket),
                        "--remote=db:Open_vSwitch,manager_options",
                        "--pidfile=%s" % (self.db_pidfile),
                        "--detach"])
        self.ovs_vsctl(["--no-wait", "init"])

    def start_ovs_vswitchd(self):
        utils.run(os_dep.command("ovs-vswitchd"), timeout=10,
                  args=["--detach",
                        "--pidfile=%s" % (self.ovs_pidfile),
                        "unix:%s" % (self.db_socket)])

    def init_new(self):
        """
        Create new dbfile without any configuration.
        """
        self.db_path = os.path.join(self.tmpdir, "conf.db")
        self.db_socket = os.path.join(self.tmpdir, "db.sock")
        self.db_pidfile = utils_misc.get_pid_path("ovsdb-server")
        self.ovs_pidfile = utils_misc.get_pid_path("ovs-vswitchd")
        self.dbschema = "/usr/share/openvswitch/vswitch.ovsschema"

        self.cleanup = True
        sm = ServiceManager()
        # Stop system openvswitch
        try:
            sm.stop("openvswitch")
        except error.CmdError:
            pass
        utils.load_module("openvswitch")
        self.clean()
        if (os.path.exists(self.db_path)):
            os.remove(self.db_path)

        self.init_db()
        self.start_ovs_vswitchd()

    def clean(self):
        logging.debug("Killall ovsdb-server")
        utils.signal_program("ovsdb-server")
        if (utils_misc.program_is_alive("ovsdb-server")):
            utils.signal_program("ovsdb-server", signal.SIGKILL)
        logging.debug("Killall ovs-vswitchd")
        utils.signal_program("ovs-vswitchd")
        if (utils_misc.program_is_alive("ovs-vswitchd")):
            utils.signal_program("ovs-vswitchd", signal.SIGKILL)

########NEW FILE########
__FILENAME__ = ovirt
"""
oVirt SDK wrapper module.

:copyright: 2008-2012 Red Hat Inc.
"""


import time
import logging

try:
    from ovirtsdk.api import API
    from ovirtsdk.xml import params as param
except ImportError:
    logging.info("ovirtsdk module not present, please install it")

import virt_vm


_api = None
_connected = False


def connect(params):
    """
    Connect ovirt manager API.
    """
    url = params.get('ovirt_engine_url')
    username = params.get('ovirt_engine_user')
    password = params.get('ovirt_engine_password')
    version = params.get('ovirt_engine_version')

    if url is None or username is None or password is None:
        logging.error('ovirt_engine[url|user|password] are necessary!!')

    if version is None:
        version = param.Version(major='3', minor='0')
    else:
        version = param.Version(version)

    global _api, _connected

    try:
        # Try to connect oVirt API if connection doesn't exist,
        # otherwise, directly return existing API connection.
        if not _connected:
            _api = API(url, username, password)
            _connected = True
            return (_api, version)
        else:
            return (_api, version)
    except Exception, e:
        logging.error('Failed to connect: %s\n' % str(e))
    else:
        logging.info('Succeed to connect oVirt/Rhevm manager\n')


def disconnect():
    """
    Disconnect ovirt manager connection.
    """
    global _api, _connected

    if _connected:
        return _api.disconnect()


class VMManager(virt_vm.BaseVM):

    """
    This class handles all basic VM operations for oVirt.
    """

    def __init__(self, params, root_dir, address_cache=None, state=None):
        """
        Initialize the object and set a few attributes.

        :param name: The name of the object
        :param params: A dict containing VM params (see method
                       make_qemu_command for a full description)
        :param root_dir: Base directory for relative filenames
        :param address_cache: A dict that maps MAC addresses to IP addresses
        :param state: If provided, use this as self.__dict__
        """

        if state:
            self.__dict__ = state
        else:
            self.process = None
            self.serial_console = None
            self.redirs = {}
            self.vnc_port = 5900
            self.vnclisten = "0.0.0.0"
            self.pci_assignable = None
            self.netdev_id = []
            self.device_id = []
            self.pci_devices = []
            self.uuid = None
            self.only_pty = False

        self.spice_port = 8000
        self.name = params.get("vm_name", "")
        self.params = params
        self.root_dir = root_dir
        self.address_cache = address_cache
        self.vnclisten = "0.0.0.0"
        self.driver_type = "v2v"

        super(VMManager, self).__init__(self.name, params)
        (self.api, self.version) = connect(params)

        if self.name:
            self.instance = self.api.vms.get(self.name)

    def list(self):
        """
        List all of VMs.
        """
        vm_list = []
        try:
            vms = self.api.vms.list(query='name=*')
            for i in range(len(vms)):
                vm_list.append(vms[i].name)
            return vm_list
        except Exception, e:
            logging.error('Failed to get vms:\n%s' % str(e))

    def state(self):
        """
        Return VM state.
        """
        try:
            return self.instance.status.state
        except Exception, e:
            logging.error('Failed to get %s status:\n%s' % (self.name, str(e)))

    def get_mac_address(self):
        """
        Return MAC address of a VM.
        """
        try:
            return self.instance.nics.get().get_mac().get_address()
        except Exception, e:
            logging.error('Failed to get %s status:\n%s' % (self.name, str(e)))

    def lookup_by_storagedomains(self, storage_name):
        """
        Lookup VM object in storage domain according to VM name.
        """
        try:
            storage = self.api.storagedomains.get(storage_name)
            return storage.vms.get(self.name)
        except Exception, e:
            logging.error('Failed to get %s from %s:\n%s' % (self.name,
                                                             storage_name, str(e)))

    def is_alive(self):
        """
        Judge if a VM is alive.
        """
        if self.state() == 'up':
            logging.info('The %s status is <Up>' % self.name)
            return True
        else:
            logging.debug('The %s status is <not Up>' % self.name)
            return False

    def is_dead(self):
        """
        Judge if a VM is dead.
        """
        if self.state() == 'down':
            logging.info('The %s status is <Down>' % self.name)
            return True
        else:
            logging.debug('The %s status is <not Down>' % self.name)
            return False

    def is_paused(self):
        return False

    def start(self):
        """
        Start a VM.
        """
        try:
            if self.state() != 'up':
                logging.info('Starting VM %s' % self.name)
                self.instance.start()
                logging.info('Waiting for VM to reach <Up> status ...')
                while self.state() != 'up':
                    self.instance = self.api.vms.get(self.name)
                    time.sleep(1)
            else:
                logging.debug('VM already up')
        except Exception, e:
            logging.error('Failed to start VM:\n%s' % str(e))

    def suspend(self):
        """
        Suspend a VM.
        """
        while self.state() != 'suspended':
            try:
                logging.info('Suspend VM %s' % self.name)
                self.instance.suspend()
                logging.info('Waiting for VM to reach <Suspended> status ...')
                while self.state() != 'suspended':
                    self.instance = self.api.vms.get(self.name)
                    time.sleep(1)

            except Exception, e:
                if e.reason == 'Bad Request' \
                        and 'asynchronous running tasks' in e.detail:
                    logging.warning("VM has asynchronous running tasks, "
                                    "trying again")
                    time.sleep(1)
                else:
                    logging.error('Failed to suspend VM:\n%s' % str(e))
                    break

    def resume(self):
        """
        Resume a suspended VM.
        """
        try:
            if self.state() != 'up':
                logging.info('Resume VM %s' % self.name)
                self.instance.start()
                logging.info('Waiting for VM to <Resume> status ...')
                while self.state() != 'up':
                    self.instance = self.api.vms.get(self.name)
                    time.sleep(1)
            else:
                logging.debug('VM already up')
        except Exception, e:
            logging.error('Failed to resume VM:\n%s' % str(e))

    def shutdown(self):
        """
        Shut down a running VM.
        """
        try:
            if self.state() != 'down':
                logging.info('Stop VM %s' % self.name)
                self.instance.stop()
                logging.info('Waiting for VM to reach <Down> status ...')
                while self.state() != 'down':
                    self.instance = self.api.vms.get(self.name)
                    time.sleep(1)
            else:
                logging.debug('VM already down')
        except Exception, e:
            logging.error('Failed to Stop VM:\n%s' % str(e))

    def delete(self):
        """
        Delete a VM.
        """
        try:
            if self.state() == 'down':
                logging.info('Delete VM %s' % self.name)
                self.instance.delete()
                logging.info('Waiting for VM to be <Deleted> ...')
                while self.name in [self.instance.name for self.instance
                                    in self.api.vms.list()]:
                    time.sleep(1)
                logging.info('VM was removed successfully')
            else:
                logging.debug('VM already is down status')
        except Exception, e:
            logging.error('Failed to remove VM:\n%s' % str(e))

    def destroy(self):
        """
        Destroy a VM.
        """
        if self.api.vms is None:
            return

        self.shutdown()

    def delete_from_export_domain(self, export_name):
        """
        Remove a VM from specified export domain.

        :param export_name: export domain name.
        """
        vm = self.lookup_by_storagedomains(export_name)
        try:
            vm.delete()
        except Exception, e:
            logging.error('Failed to remove VM:\n%s' % str(e))

    def import_from_export_domain(self, export_name, storage_name,
                                  cluster_name):
        """
        Import a VM from export domain to data domain.

        :param export_name: Export domain name.
        :param storage_name: Storage domain name.
        :param cluster_name: Cluster name.
        """
        vm = self.lookup_by_storagedomains(export_name)
        storage_domains = self.api.storagedomains.get(storage_name)
        clusters = self.api.clusters.get(cluster_name)
        try:
            logging.info('Import VM %s' % self.name)
            vm.import_vm(param.Action(storage_domain=storage_domains,
                                      cluster=clusters))
            logging.info('Waiting for VM to reach <Down> status ...')
            while self.state() != 'down':
                self.instance = self.api.vms.get(self.name)
                time.sleep(1)
            logging.info('VM was imported successfully')
        except Exception, e:
            logging.error('Failed to import VM:\n%s' % str(e))

    def export_from_export_domain(self, export_name):
        """
        Export a VM from storage domain to export domain.

        :param export_name: Export domain name.
        """
        storage_domains = self.api.storagedomains.get(export_name)
        try:
            logging.info('Export VM %s' % self.name)
            self.instance.export(param.Action(storage_domain=storage_domains))
            logging.info('Waiting for VM to reach <Down> status ...')
            while self.state() != 'down':
                self.instance = self.api.vms.get(self.name)
                time.sleep(1)
            logging.info('VM was exported successfully')
        except Exception, e:
            logging.error('Failed to export VM:\n%s' % str(e))

    def snapshot(self, snapshot_name='my_snapshot'):
        """
        Create a snapshot to VM.

        :param snapshot_name: 'my_snapshot' is default snapshot name.
        """
        snap_params = param.Snapshot(description=snapshot_name,
                                     vm=self.instance)
        try:
            logging.info('Creating a snapshot %s for VM %s'
                         % (snapshot_name, self.name))
            self.instance.snapshots.add(snap_params)
            logging.info('Waiting for snapshot creation to finish ...')
            while self.state() == 'image_locked':
                self.instance = self.api.vms.get(self.name)
                time.sleep(1)
            logging.info('Snapshot was created successfully')
        except Exception, e:
            logging.error('Failed to create a snapshot:\n%s' % str(e))

    def create_template(self, cluster_name, template_name='my_template'):
        """
        Create a template from VM.

        :param cluster_name: cluster name.
        :param template_name: 'my_template' is default template name.
        """
        cluster = self.api.clusters.get(cluster_name)

        tmpl_params = param.Template(name=template_name,
                                     vm=self.instance,
                                     cluster=cluster)
        try:
            logging.info('Creating a template %s from VM %s'
                         % (template_name, self.name))
            self.api.templates.add(tmpl_params)
            logging.info('Waiting for VM to reach <Down> status ...')
            while self.state() != 'down':
                self.instance = self.api.vms.get(self.name)
                time.sleep(1)
        except Exception, e:
            logging.error('Failed to create a template from VM:\n%s' % str(e))

    def add(self, memory, disk_size, cluster_name, storage_name,
            nic_name='eth0', network_interface='virtio',
            network_name='ovirtmgmt', disk_interface='virtio',
            disk_format='raw', template_name='Blank'):
        """
        Create VM with one NIC and one Disk.

        :param memory: VM's memory size such as 1024*1024*1024=1GB.
        :param disk_size: VM's disk size such as 512*1024=512MB.
        :param nic_name: VM's NICs name such as 'eth0'.
        :param network_interface: VM's network interface such as 'virtio'.
        :param network_name: network such as ovirtmgmt for ovirt, rhevm for rhel.
        :param disk_format: VM's disk format such as 'raw' or 'cow'.
        :param disk_interface: VM's disk interface such as 'virtio'.
        :param cluster_name: cluster name.
        :param storage_name: storage domain name.
        :param template_name: VM's template name, default is 'Blank'.
        """
        # network name is ovirtmgmt for ovirt, rhevm for rhel.
        vm_params = param.VM(name=self.name, memory=memory,
                             cluster=self.api.clusters.get(cluster_name),
                             template=self.api.templates.get(template_name))

        storage = self.api.storagedomains.get(storage_name)

        storage_params = param.StorageDomains(storage_domain=[storage])

        nic_params = param.NIC(name=nic_name,
                               network=param.Network(name=network_name),
                               interface=network_interface)

        disk_params = param.Disk(storage_domains=storage_params,
                                 size=disk_size,
                                 type_='system',
                                 status=None,
                                 interface=disk_interface,
                                 format=disk_format,
                                 sparse=True,
                                 bootable=True)

        try:
            logging.info('Creating a VM %s' % self.name)
            self.api.vms.add(vm_params)

            logging.info('NIC is added to VM %s' % self.name)
            self.instance.nics.add(nic_params)

            logging.info('Disk is added to VM %s' % self.name)
            self.instance.disks.add(disk_params)

            logging.info('Waiting for VM to reach <Down> status ...')
            while self.state() != 'down':
                time.sleep(1)

        except Exception, e:
            logging.error('Failed to create VM with disk and NIC\n%s' % str(e))

    def add_vm_from_template(self, cluster_name, template_name='Blank',
                             new_name='my_new_vm'):
        """
        Create a VM from template.

        :param cluster_name: cluster name.
        :param template_name: default template is 'Blank'.
        :param new_name: 'my_new_vm' is a default new VM's name.
        """
        vm_params = param.VM(name=new_name,
                             cluster=self.api.clusters.get(cluster_name),
                             template=self.api.templates.get(template_name))
        try:
            logging.info('Creating a VM %s from template %s'
                         % (new_name, template_name))
            self.api.vms.add(vm_params)
            logging.info('Waiting for VM to reach <Down> status ...')
            while self.state() != 'down':
                self.instance = self.api.vms.get(self.name)
                time.sleep(1)
            logging.info('VM was created from template successfully')
        except Exception, e:
            logging.error('Failed to create VM from template:\n%s' % str(e))

    def get_address(self, index=0):
        """
        Return the address of the guest through ovirt node tcpdump cache.

        :param index: Name or index of the NIC whose address is requested.
        :return: IP address of NIC.
        :raise VMIPAddressMissingError: If no IP address is found for the the
                NIC's MAC address
        """
        nic = self.virtnet[index]
        if nic.nettype == 'bridge':
            mac = self.get_mac_address()
            ip = self.address_cache.get(mac)
            # TODO: Verify MAC-IP address mapping on remote ovirt node
            if not ip:
                raise virt_vm.VMIPAddressMissingError(mac)
            return ip
        else:
            raise ValueError("Ovirt only support bridge nettype now.")


class DataCenterManager(object):

    """
    This class handles all basic datacenter operations.
    """

    def __init__(self, params):
        self.name = params.get("dc_name", "")
        self.params = params
        (self.api, self.version) = connect(params)

        if self.name:
            self.instance = self.api.datacenters.get(self.name)

    def list(self):
        """
        List all of datacenters.
        """
        dc_list = []
        try:
            logging.info('List Data centers')
            dcs = self.api.datacenters.list(query='name=*')
            for i in range(len(dcs)):
                dc_list.append(dcs[i].name)
            return dc_list
        except Exception, e:
            logging.error('Failed to get data centers:\n%s' % str(e))

    def add(self, storage_type):
        """
        Add a new data center.
        """
        if not self.name:
            self.name = "my_datacenter"
        try:
            logging.info('Creating a %s type datacenter %s'
                         % (storage_type, self.name))
            if self.api.datacenters.add(param.DataCenter(
                name=self.name,
                storage_type=storage_type,
                                        version=self.version)):
                logging.info('Data center was created successfully')
        except Exception, e:
            logging.error('Failed to create data center:\n%s' % str(e))


class ClusterManager(object):

    """
    This class handles all basic cluster operations.
    """

    def __init__(self, params):
        self.name = params.get("cluster_name", "")
        self.params = params
        (self.api, self.version) = connect(params)

        if self.name:
            self.instance = self.api.clusters.get(self.name)

    def list(self):
        """
        List all of clusters.
        """
        cluster_list = []
        try:
            logging.info('List clusters')
            clusters = self.api.clusters.list(query='name=*')
            for i in range(len(clusters)):
                cluster_list.append(clusters[i].name)
            return cluster_list
        except Exception, e:
            logging.error('Failed to get clusters:\n%s' % str(e))

    def add(self, dc_name, cpu_type='Intel Nehalem Family'):
        """
        Add a new cluster into data center.
        """
        if not self.name:
            self.name = "my_cluster"

        dc = self.api.datacenters.get(dc_name)
        try:
            logging.info('Creating a cluster %s in datacenter %s'
                         % (self.name, dc_name))
            if self.api.clusters.add(param.Cluster(name=self.name,
                                                   cpu=param.CPU(id=cpu_type),
                                                   data_center=dc,
                                                   version=self.version)):
                logging.info('Cluster was created successfully')
        except Exception, e:
            logging.error('Failed to create cluster:\n%s' % str(e))


class HostManager(object):

    """
    This class handles all basic host operations.
    """

    def __init__(self, params):
        self.name = params.get("hostname", "")
        self.params = params
        (self.api, self.version) = connect(params)

        if self.name:
            self.instance = self.api.hosts.get(self.name)

    def list(self):
        """
        List all of hosts.
        """
        host_list = []
        try:
            logging.info('List hosts')
            hosts = self.api.hosts.list(query='name=*')
            for i in range(len(hosts)):
                host_list.append(hosts[i].name)
            return host_list
        except Exception, e:
            logging.error('Failed to get hosts:\n%s' % str(e))

    def state(self):
        """
        Return host state.
        """
        try:
            return self.instance.status.state
        except Exception, e:
            logging.error('Failed to get %s status:\n%s' % (self.name, str(e)))

    def add(self, host_address, host_password, cluster_name):
        """
        Register a host into specified cluster.
        """
        if not self.name:
            self.name = 'my_host'

        clusters = self.api.clusters.get(cluster_name)
        host_params = param.Host(name=self.name, address=host_address,
                                 cluster=clusters, root_password=host_password)
        try:
            logging.info('Registing a host %s into cluster %s'
                         % (self.name, cluster_name))
            if self.api.hosts.add(host_params):
                logging.info('Waiting for host to reach the <Up> status ...')
                while self.state() != 'up':
                    time.sleep(1)
                else:
                    logging.info('Host is up')
                logging.info('Host was installed successfully')
        except Exception, e:
            logging.error('Failed to install host:\n%s' % str(e))

    def get_address(self):
        """
        Return host IP address.
        """
        try:
            logging.info('Get host %s IP' % self.name)
            return self.instance.get_address()
        except Exception, e:
            logging.error('Failed to get host %s IP address:\n%s' %
                          (self.name, str(e)))


class StorageDomainManager(object):

    """
    This class handles all basic storage domain operations.
    """

    def __init__(self, params):
        self.name = params.get("storage_name", "")
        self.params = params
        (self.api, self.version) = connect(params)

        if self.name:
            self.instance = self.api.storagedomains.get(self.name)

    def list(self):
        """
        List all of storagedomains.
        """
        storage_list = []
        try:
            logging.info('List storage domains')
            storages = self.api.storagedomains.list()
            for i in range(len(storages)):
                storage_list.append(storages[i].name)
            return storage_list
        except Exception, e:
            logging.error('Failed to get storage domains:\n%s' % str(e))

    def attach_iso_export_domain_into_datacenter(self, address, path,
                                                 dc_name, host_name,
                                                 domain_type,
                                                 storage_type='nfs',
                                                 name='my_iso'):
        """
        Attach ISO/export domain into data center.

        :param name: ISO or Export name.
        :param host_name: host name.
        :param dc_name: data center name.
        :param path: ISO/export domain path.
        :param address: ISO/export domain address.
        :param domain_type: storage domain type, it may be 'iso' or 'export'.
        :param storage_type: storage type, it may be 'nfs', 'iscsi', or 'fc'.
        """
        dc = self.api.datacenters.get(dc_name)
        host = self.api.hosts.get(host_name)
        storage_params = param.Storage(type_=storage_type,
                                       address=address,
                                       path=path)

        storage_domain__params = param.StorageDomain(name=name,
                                                     data_center=dc,
                                                     type_=domain_type,
                                                     host=host,
                                                     storage=storage_params)

        try:
            logging.info('Create/import ISO storage domain %s' % name)
            if self.api.storagedomains.add(storage_domain__params):
                logging.info('%s domain was created/imported successfully'
                             % domain_type)

            logging.info('Attach ISO storage domain %s' % name)
            if self.api.datacenters.get(dc_name).storagedomains.add(
                    self.api.storagedomains.get(name)):
                logging.info('%s domain was attached successfully'
                             % domain_type)

            logging.info('Activate ISO storage domain %s' % name)
            if self.api.datacenters.get(dc_name).storagedomains.get(
                    name).activate():
                logging.info('%s domain was activated successfully'
                             % domain_type)
        except Exception, e:
            logging.error('Failed to add %s domain:\n%s'
                          % (domain_type, str(e)))

########NEW FILE########
__FILENAME__ = ovs_utils
import logging
import os
import re
import shutil
from autotest.client.shared import error, utils
from virttest import utils_net


class Machine(object):

    def __init__(self, vm=None, src=None):
        self.vm = vm
        self.session = None
        self.runner = utils_net.local_runner
        self.runner_status = utils_net.local_runner_status
        self.bg_runner = utils.BgJob
        self.src = src
        self.addrs = None
        if vm:
            self.session = vm.wait_for_login()
            self.runner = self.session.cmd
            self.runner_status = self.session.cmd_status
            self.bg_runner = self.session.sendline
            self.src = os.path.join("/", "tmp", "src")

    def is_virtual(self):
        """
        :return: True when Machine is virtual.
        """
        return self.vm is not None

    def cmd(self, cmd, timeout=60):
        """
        Return outpu of command.
        """
        return self.runner(cmd, timeout=timeout)

    def cmd_state(self, cmd, timeout=60):
        """
        Return status of command.
        """
        return self.runner_status(cmd, timeout=timeout)

    def cmd_in_src(self, cmd, timeout=60):
        cmd = os.path.join(self.src, cmd)
        return self.runner(cmd, timeout=timeout)

    def fill_addrs(self):
        self.addrs = utils_net.get_net_if_and_addrs(self.runner)
        if self.vm:
            self.vm.fill_addrs(self.addrs)

    def get_linkv6_addr(self, ifname):
        """
        Get IPv6 address with link range.

        :param ifname: String or int. Int could be used only for virt Machine.
        :return: IPv6 link address.
        """
        if self.is_virtual() and type(ifname) is int:
            ifname = self.vm.virtnet[ifname].g_nic_name
        return utils_net.ipv6_from_mac_addr(self.addrs[ifname]['mac'])

    def ping(self, dst, iface=None, count=1, vlan=0, ipv=None):
        """
        Ping destination.
        """
        if ipv is None:
            ipv = "ipv6"

        if ipv == "ipv6":
            if iface is None:
                raise error.TestError("For ipv6 ping, interface can't be None")

            if self.vm:
                iface = self.get_if_vlan_name(
                    self.vm.virtnet[iface].g_nic_name,
                    vlan)
                return ping6(iface, dst, count,
                             self.runner)
            else:
                iface = self.get_if_vlan_name(iface, vlan)
                return ping6(iface, dst, count, self.runner)
        elif ipv == "ipv4":
            return ping4(iface, dst, count, self.runner)

    def add_vlan_iface(self, iface, vlan_id):
        """
        Add vlan link for interface

        :param iface: Interface on which should be added vlan.
        :param vlan_id: Id of vlan.
        """
        self.cmd("ip link add link %s name %s-vl%s type vlan id %s" %
                 (iface, iface, vlan_id, vlan_id))

    def del_vlan_iface(self, iface, vlan_id):
        """
        Del vlan link for interface

        :param iface: Interface from which should be deleted vlan.
        :param vlan_id: Id of vlan.
        """
        self.cmd("ip link del %s" % (iface))

    def bring_iface_up(self, iface):
        """
        Bring interface up
        """
        self.cmd("ip link set %s up" % (iface))

    def bring_iface_down(self, iface):
        """
        Bring interface up
        """
        self.cmd("ip link set %s down" % (iface))

    def get_vlans_ifname(self):
        """
        Return vlans interface name.

        :return: dict of {"ifname": [(vlanid, ifname),(...)],...}
        """
        ret = dict()
        vlans = self.cmd("cat /proc/net/vlan/config")
        v = re.findall("^(\S+)\s*\|\s*(\S+)\s*\|\s*(\S+)\s*$",
                       vlans, re.MULTILINE)
        for vl_ifname, vl_id, ifname in v:
            if ifname in ret:
                ret[ifname][int(vl_id)] = vl_ifname
            else:
                ret[ifname] = {int(vl_id): vl_ifname}

        return ret

    def get_if_vlan_name(self, ifname, vlan_id=0):
        if vlan_id == 0:
            return ifname

        vlans = self.get_vlans_ifname()
        if ifname in vlans:
            if vlan_id in vlans[ifname]:
                return vlans[ifname][vlan_id]
            else:
                raise utils_net.VlanError(ifname,
                                          "Interface %s has no vlan with"
                                          " id %s" % (ifname, vlan_id))
        else:
            raise utils_net.VlanError(ifname,
                                      "Interface %s has no vlans" % (ifname))

    def prepare_directory(self, path, cleanup=False):
        """
        Prepare dest directory. Create if directory not exist.

        :param path: Path to directory
        :param cleanup: It true clears the contents of directory.
        """
        if self.cmd_state("test -x %s" % path):
            self.cmd("mkdir -p %s" % path)

        if cleanup:
            self.cmd("rm -rf %s" % (os.path.join(path, "*")))

    def copy_to(self, src, dst):
        if self.vm:
            self.vm.copy_files_to(src, dst)
        else:
            shutil.copy(src, dst)

    def compile_autotools_app_tar(self, path, package_name):
        """
        Compile app on machine in src dir.

        :param path: Path where shoule be program compiled.
        :param dst_dir: Installation path.
        """
        logging.debug("Install %s to %s.", package_name, self.src)
        self.prepare_directory(self.src)

        pack_dir = None
        if package_name.endswith("tar.gz"):
            pack_dir = package_name[0:-len(".tar.gz")]
            unpack_cmd = ("tar -xvzf %s; cd %s;" % (package_name, pack_dir))
        elif package_name.endswith("tgz"):
            pack_dir = package_name[0:-len(".tgz")]
            unpack_cmd = ("tar -xvzf %s; cd %s;" % (package_name, pack_dir))
        elif package_name.endswith(("tar.bz2")):
            pack_dir = package_name[0:-len(".tar.br2")]
            unpack_cmd = ("tar -xvjf %s; cd %s;" % (package_name, pack_dir))

        self.copy_to(os.path.join(path, package_name), self.src)
        self.cmd("sync")
        self.cmd("cd %s; %s ./configure && make;" % (self.src, unpack_cmd),
                 timeout=240)
        self.cmd("sync")

    def __getattr__(self, name):
        if self.vm:
            try:
                return self.vm.__getattribute__(name)
            except AttributeError:
                return self.session.__getattribute__(name)
        raise AttributeError("Cannot find attribute %s in class" % name)


def ping6(iface, dst_ip, count=1, runner=None):
    """
    Format command for ipv6.
    """
    if runner is None:
        runner = utils.run
    return runner("ping6 -I %s %s -c %s" % (iface, dst_ip, count))


def ping4(iface, dst_ip, count=1, runner=None):
    """
    Format command for ipv4.
    """
    if runner is None:
        runner = utils.run
    ping_cmd = "ping %s -c %s" % (dst_ip, count)
    if iface is not None:
        ping_cmd += " -I %s" % iface
    return runner(ping_cmd)

########NEW FILE########
__FILENAME__ = passfd
'''
passfd.py: Python library to pass file descriptors across UNIX domain sockets

This simple extension provides two functions to pass and receive file
descriptors across UNIX domain sockets, using the BSD-4.3+ sendmsg() and
recvmsg() interfaces.

Direct bindings to sendmsg and recvmsg are not provided, as the API does
not map nicely into Python.

Please note that this only supports BSD-4.3+ style file descriptor
passing, and was only tested on Linux. Patches are welcomed!

For more information, see one of the R. Stevens' books:
 - Richard Stevens: Unix Network Programming, Prentice Hall, 1990;
   chapter 6.10

 - Richard Stevens: Advanced Programming in the UNIX Environment,
   Addison-Wesley, 1993; chapter 15.3
'''

#
# Copyright (C) 2010 Martin Ferrari <martin.ferrari@gmail.com>
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the Free
# Software Foundation; either version 2 of the License, or (at your option)
# any later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
# more details.
#
# You should have received a copy of the GNU General Public License along with
# this program; if not, write to the Free Software Foundation, Inc., 51
# Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#

import socket
import _passfd


def __check_socket(sock):
    if hasattr(sock, 'family') and sock.family != socket.AF_UNIX:
        raise ValueError("Only AF_UNIX sockets are allowed")

    if hasattr(sock, 'fileno'):
        sock = sock.fileno()

    if not isinstance(sock, int):
        raise TypeError("An socket object or file descriptor was expected")

    return sock


def __check_fd(fd):
    try:
        fd = fd.fileno()
    except AttributeError:
        pass
    if not isinstance(fd, int):
        raise TypeError("An file object or file descriptor was expected")

    return fd


def sendfd(sock, fd, message="NONE"):
    """
    Sends a message and piggybacks a file descriptor via a Unix domain socket

    Note that the file descriptor cannot be sent by itself, at least
    one byte of payload needs to be sent also.

    :param sock: socket object or file descriptor for an `AF_UNIX` socket
    :param fd: file object or file descriptor to pass
    :param message: message to send
    :return: On success, sendfd returns the number of bytes sent, not including
             the file descriptor nor the control data.  If there was no message
             to send, 0 is returned.
    """
    return _passfd.sendfd(__check_socket(sock), __check_fd(fd), message)


def recvfd(sock, msg_buf=4096):
    """
    Receive a message and a file descriptor from a Unix domain socket.

    :param sock: file descriptor or socket object for an ``AF_UNIX`` socket
    :param buffersize: maximum message size to receive

    :return: On success, recvfd returns a tuple containing the received
             file descriptor and message

    :raise OSError: is raised if recvmsg fails
    :raise RuntimeError: is raised if the received data does not carry
           exactly one file descriptor, or if the received file descriptor
           is not valid.
    """
    (ret, msg) = _passfd.recvfd(__check_socket(sock), msg_buf)
    print ret
    print msg

    # -1 should raise OSError
    if ret == -2:
        raise RuntimeError("The message received did not contain exactly one" +
                           " file descriptor")
    if ret == -3:
        raise RuntimeError("The received file descriptor is not valid")
    assert ret >= 0

    return (ret, msg)

########NEW FILE########
__FILENAME__ = postprocess_iozone
#!/usr/bin/python
"""
Postprocessing module for IOzone. It is capable to pick results from an
IOzone run, calculate the geometric mean for all throughput results for
a given file size or record size, and then generate a series of 2D and 3D
graphs. The graph generation functionality depends on gnuplot, and if it
is not present, functionality degrates gracefully.

:copyright: Red Hat 2010
"""
import os
import sys
import optparse
import logging
import math
import time
import common
from autotest.client.shared import logging_config, logging_manager
from autotest.client.shared import error
from autotest.client import utils, os_dep
import utils_misc


_LABELS = ['file_size', 'record_size', 'write', 'rewrite', 'read', 'reread',
           'randread', 'randwrite', 'bkwdread', 'recordrewrite', 'strideread',
           'fwrite', 'frewrite', 'fread', 'freread']


def geometric_mean(values):
    """
    Evaluates the geometric mean for a list of numeric values.

    :param values: List with values.
    :return: Single value representing the geometric mean for the list values.
    :see: `Geometric mean definition <http://en.wikipedia.org/wiki/Geometric_mean>`__
    """
    try:
        values = [int(value) for value in values]
    except ValueError:
        return None
    n = len(values)
    if n == 0:
        return None
    return math.exp(sum([math.log(x) for x in values]) / n)


def compare_matrices(matrix1, matrix2, treshold=0.05):
    """
    Compare 2 matrices nxm and return a matrix nxm with comparison data

    :param matrix1: Reference Matrix with numeric data
    :param matrix2: Matrix that will be compared
    :param treshold: Any difference bigger than this percent treshold will be
            reported.
    """
    improvements = 0
    regressions = 0
    same = 0

    new_matrix = []
    for line1, line2 in zip(matrix1, matrix2):
        new_line = []
        for element1, element2 in zip(line1, line2):
            ratio = float(element2) / float(element1)
            if ratio < (1 - treshold):
                regressions += 1
                new_line.append((100 * ratio - 1) - 100)
            elif ratio > (1 + treshold):
                improvements += 1
                new_line.append("+" + str((100 * ratio - 1) - 100))
            else:
                same + 1
                if line1.index(element1) == 0:
                    new_line.append(element1)
                else:
                    new_line.append(".")
        new_matrix.append(new_line)

    total = improvements + regressions + same

    return (new_matrix, improvements, regressions, total)


class IOzoneAnalyzer(object):

    """
    Analyze an unprocessed IOzone file, and generate the following types of
    report:

    * Summary of throughput for all file and record sizes combined
    * Summary of throughput for all file sizes
    * Summary of throughput for all record sizes

    If more than one file is provided to the analyzer object, a comparison
    between the two runs is made, searching for regressions in performance.
    """

    def __init__(self, list_files, output_dir):
        self.list_files = list_files
        if not os.path.isdir(output_dir):
            os.makedirs(output_dir)
        self.output_dir = output_dir
        logging.info("Results will be stored in %s", output_dir)

    def average_performance(self, results, size=None):
        """
        Flattens a list containing performance results.

        :param results: List of n lists containing data from performance runs.
        :param size: Numerical value of a size (say, file_size) that was used
                to filter the original results list.
        :return: List with 1 list containing average data from the performance
                run.
        """
        average_line = []
        if size is not None:
            average_line.append(size)
        for i in range(2, 15):
            average = geometric_mean([line[i] for line in results]) / 1024.0
            average = int(average)
            average_line.append(average)
        return average_line

    def process_results(self, results, label=None):
        """
        Process a list of IOzone results according to label.

        :param label: IOzone column label that we'll use to filter and compute
                    geometric mean results, in practical term either 'file_size'
                    or 'record_size'.
        :param result: A list of n x m columns with original iozone results.
        :return: A list of n-? x (m-1) columns with geometric averages for
                values of each label (ex, average for all file_sizes).
        """
        performance = []
        if label is not None:
            index = _LABELS.index(label)
            sizes = utils_misc.unique([line[index] for line in results])
            sizes.sort()
            for size in sizes:
                r_results = [line for line in results if line[index] == size]
                performance.append(self.average_performance(r_results, size))
        else:
            performance.append(self.average_performance(results))

        return performance

    def parse_file(self, fileobj):
        """
        Parse an IOzone results file.

        :param file: File object that will be parsed.
        :return: Matrix containing IOzone results extracted from the file.
        """
        lines = []
        for line in fileobj.readlines():
            fields = line.split()
            if len(fields) != 15:
                continue
            try:
                lines.append([int(i) for i in fields])
            except ValueError:
                continue
        return lines

    def report(self, overall_results, record_size_results, file_size_results):
        """
        Generates analysis data for IOZone run.

        Generates a report to both logs (where it goes with nice headers) and
        output files for further processing (graph generation).

        :param overall_results: 1x15 Matrix containing IOzone results for all
                file sizes
        :param record_size_results: nx15 Matrix containing IOzone results for
                each record size tested.
        :param file_size_results: nx15 Matrix containing file size results
                for each file size tested.
        """
        # Here we'll use the logging system to put the output of our analysis
        # to files
        logger = logging.getLogger()
        formatter = logging.Formatter("")

        logging.info("")
        logging.info(
            "TABLE:  SUMMARY of ALL FILE and RECORD SIZES                        Results in MB/sec")
        logging.info("")
        logging.info(
            "FILE & RECORD  INIT    RE              RE    RANDOM  RANDOM  BACKWD   RECRE  STRIDE    F       FRE     F       FRE")
        logging.info(
            "SIZES (KB)     WRITE   WRITE   READ    READ    READ   WRITE    READ   WRITE    READ    WRITE   WRITE   READ    READ")
        logging.info(
            "-------------------------------------------------------------------------------------------------------------------")
        for result_line in overall_results:
            logging.info(
                "ALL            %-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s" %
                tuple(result_line))
        logging.info("")

        logging.info("DRILLED DATA:")

        logging.info("")
        logging.info(
            "TABLE:  RECORD Size against all FILE Sizes                          Results in MB/sec")
        logging.info("")
        logging.info(
            "RECORD    INIT    RE              RE    RANDOM  RANDOM  BACKWD   RECRE  STRIDE    F       FRE     F       FRE ")
        logging.info(
            "SIZE (KB) WRITE   WRITE   READ    READ    READ   WRITE    READ   WRITE    READ    WRITE   WRITE   READ    READ")
        logging.info(
            "--------------------------------------------------------------------------------------------------------------")

        foutput_path = os.path.join(self.output_dir, '2d-datasource-file')
        if os.path.isfile(foutput_path):
            os.unlink(foutput_path)
        foutput = logging.FileHandler(foutput_path)
        foutput.setFormatter(formatter)
        logger.addHandler(foutput)
        for result_line in record_size_results:
            logging.info(
                "%-10s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s" %
                tuple(result_line))
        logger.removeHandler(foutput)

        logging.info("")

        logging.info("")
        logging.info(
            "TABLE:  FILE Size against all RECORD Sizes                          Results in MB/sec")
        logging.info("")
        logging.info(
            "RECORD    INIT    RE              RE    RANDOM  RANDOM  BACKWD   RECRE  STRIDE    F       FRE     F       FRE ")
        logging.info(
            "SIZE (KB) WRITE   WRITE   READ    READ    READ   WRITE    READ   WRITE    READ    WRITE   WRITE   READ    READ")
        logging.info(
            "--------------------------------------------------------------------------------------------------------------")

        routput_path = os.path.join(self.output_dir, '2d-datasource-record')
        if os.path.isfile(routput_path):
            os.unlink(routput_path)
        routput = logging.FileHandler(routput_path)
        routput.setFormatter(formatter)
        logger.addHandler(routput)
        for result_line in file_size_results:
            logging.info(
                "%-10s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s%-8s" %
                tuple(result_line))
        logger.removeHandler(routput)

        logging.info("")

    def report_comparison(self, record, file_size_results):
        """
        Generates comparison data for 2 IOZone runs.

        It compares 2 sets of nxm results and outputs a table with differences.
        If a difference higher or smaller than 5% is found, a warning is
        triggered.

        :param record: Tuple with 4 elements containing results for record size.
        :param file_size_results: Tuple with 4 elements containing results for file size.
        """
        (record_size, record_improvements, record_regressions,
         record_total) = record
        (file_size, file_improvements, file_regressions,
         file_total) = file_size_results
        logging.info("ANALYSIS of DRILLED DATA:")

        logging.info("")
        logging.info(
            "TABLE:  RECsize Difference between runs                            Results are % DIFF")
        logging.info("")
        logging.info(
            "RECORD    INIT    RE              RE    RANDOM  RANDOM  BACKWD   RECRE  STRIDE    F       FRE     F       FRE ")
        logging.info(
            "SIZE (KB) WRITE   WRITE   READ    READ    READ   WRITE    READ   WRITE    READ    WRITE   WRITE   READ    READ")
        logging.info(
            "--------------------------------------------------------------------------------------------------------------")
        for result_line in record_size:
            logging.info(
                "%-10s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s" %
                tuple(result_line))
        logging.info("REGRESSIONS: %d (%.2f%%)    Improvements: %d (%.2f%%)",
                     record_regressions,
                     (100 * record_regressions / float(record_total)),
                     record_improvements,
                     (100 * record_improvements / float(record_total)))
        logging.info("")

        logging.info("")
        logging.info(
            "TABLE:  FILEsize Difference between runs                           Results are % DIFF")
        logging.info("")
        logging.info(
            "RECORD    INIT    RE              RE    RANDOM  RANDOM  BACKWD   RECRE  STRIDE    F       FRE     F       FRE ")
        logging.info(
            "SIZE (KB) WRITE   WRITE   READ    READ    READ   WRITE    READ   WRITE    READ    WRITE   WRITE   READ    READ")
        logging.info(
            "--------------------------------------------------------------------------------------------------------------")
        for result_line in file_size:
            logging.info(
                "%-10s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s%-8.6s" %
                tuple(result_line))
        logging.info("REGRESSIONS: %d (%.2f%%)    Improvements: %d (%.2f%%)",
                     file_regressions,
                     (100 * file_regressions / float(file_total)),
                     file_improvements,
                     (100 * file_improvements / float(file_total)))
        logging.info("")

    def analyze(self):
        """
        Analyzes and eventually compares sets of IOzone data.
        """
        overall = []
        record_size = []
        file_size = []
        for path in self.list_files:
            fileobj = open(path, 'r')
            logging.info('FILE: %s', path)

            results = self.parse_file(fileobj)

            overall_results = self.process_results(results)
            record_size_results = self.process_results(results, 'record_size')
            file_size_results = self.process_results(results, 'file_size')
            self.report(
                overall_results, record_size_results, file_size_results)

            if len(self.list_files) == 2:
                overall.append(overall_results)
                record_size.append(record_size_results)
                file_size.append(file_size_results)

        if len(self.list_files) == 2:
            record_comparison = compare_matrices(*record_size)
            file_comparison = compare_matrices(*file_size)
            self.report_comparison(record_comparison, file_comparison)


class IOzonePlotter(object):

    """
    Plots graphs based on the results of an IOzone run.

    Plots graphs based on the results of an IOzone run. Uses gnuplot to
    generate the graphs.
    """

    def __init__(self, results_file, output_dir):
        self.active = True
        try:
            self.gnuplot = os_dep.command("gnuplot")
        except Exception:
            logging.error("Command gnuplot not found, disabling graph "
                          "generation")
            self.active = False

        if not os.path.isdir(output_dir):
            os.makedirs(output_dir)
        self.output_dir = output_dir

        if not os.path.isfile(results_file):
            logging.error("Invalid file %s provided, disabling graph "
                          "generation", results_file)
            self.active = False
            self.results_file = None
        else:
            self.results_file = results_file
            self.generate_data_source()

    def generate_data_source(self):
        """
        Creates data file without headers for gnuplot consumption.
        """
        results_file = open(self.results_file, 'r')
        self.datasource = os.path.join(self.output_dir, '3d-datasource')
        datasource = open(self.datasource, 'w')
        for line in results_file.readlines():
            fields = line.split()
            if len(fields) != 15:
                continue
            try:
                for i in fields:
                    int(i)
                datasource.write(line)
            except ValueError:
                continue
        datasource.close()

    def plot_2d_graphs(self):
        """
        For each one of the throughput parameters, generate a set of gnuplot
        commands that will create a parametric surface with file size vs.
        record size vs. throughput.
        """
        datasource_2d = os.path.join(self.output_dir, '2d-datasource-file')
        for index, label in zip(range(2, 15), _LABELS[2:]):
            commands_path = os.path.join(self.output_dir, '2d-%s.do' % label)
            commands = ""
            commands += "set title 'Iozone performance: %s'\n" % label
            commands += "set logscale x\n"
            commands += "set xlabel 'File size (KB)'\n"
            commands += "set ylabel 'Througput (MB/s)'\n"
            commands += "set terminal png small size 450 350\n"
            commands += "set output '%s'\n" % os.path.join(self.output_dir,
                                                           '2d-%s.png' % label)
            commands += ("plot '%s' using 1:%s title '%s' with lines \n" %
                         (datasource_2d, index, label))
            commands_file = open(commands_path, 'w')
            commands_file.write(commands)
            commands_file.close()
            try:
                utils.system("%s %s" % (self.gnuplot, commands_path))
            except error.CmdError:
                logging.error("Problem plotting from commands file %s",
                              commands_path)

    def plot_3d_graphs(self):
        """
        For each one of the throughput parameters, generate a set of gnuplot
        commands that will create a parametric surface with file size vs.
        record size vs. throughput.
        """
        for index, label in zip(range(1, 14), _LABELS[2:]):
            commands_path = os.path.join(self.output_dir, '%s.do' % label)
            commands = ""
            commands += "set title 'Iozone performance: %s'\n" % label
            commands += "set grid lt 2 lw 1\n"
            commands += "set surface\n"
            commands += "set parametric\n"
            commands += "set xtics\n"
            commands += "set ytics\n"
            commands += "set logscale x 2\n"
            commands += "set logscale y 2\n"
            commands += "set logscale z\n"
            commands += "set xrange [2.**5:2.**24]\n"
            commands += "set xlabel 'File size (KB)'\n"
            commands += "set ylabel 'Record size (KB)'\n"
            commands += "set zlabel 'Througput (KB/s)'\n"
            commands += "set style data lines\n"
            commands += "set dgrid3d 80,80, 3\n"
            commands += "set terminal png small size 900 700\n"
            commands += "set output '%s'\n" % os.path.join(self.output_dir,
                                                           '%s.png' % label)
            commands += ("splot '%s' using 1:2:%s title '%s'\n" %
                         (self.datasource, index, label))
            commands_file = open(commands_path, 'w')
            commands_file.write(commands)
            commands_file.close()
            try:
                utils.system("%s %s" % (self.gnuplot, commands_path))
            except error.CmdError:
                logging.error("Problem plotting from commands file %s",
                              commands_path)

    def plot_all(self):
        """
        Plot all graphs that are to be plotted, provided that we have gnuplot.
        """
        if self.active:
            self.plot_2d_graphs()
            self.plot_3d_graphs()


class AnalyzerLoggingConfig(logging_config.LoggingConfig):

    def configure_logging(self, results_dir=None, verbose=False):
        super(AnalyzerLoggingConfig, self).configure_logging(use_console=True,
                                                             verbose=verbose)


if __name__ == "__main__":
    parser = optparse.OptionParser("usage: %prog [options] [filenames]")
    options, args = parser.parse_args()

    logging_manager.configure_logging(AnalyzerLoggingConfig())

    if args:
        filenames = args
    else:
        parser.print_help()
        sys.exit(1)

    if len(args) > 2:
        parser.print_help()
        sys.exit(1)

    o = os.path.join(os.getcwd(),
                     "iozone-graphs-%s" % time.strftime('%Y-%m-%d-%H.%M.%S'))
    if not os.path.isdir(o):
        os.makedirs(o)

    a = IOzoneAnalyzer(list_files=filenames, output_dir=o)
    a.analyze()
    p = IOzonePlotter(results_file=filenames[0], output_dir=o)
    p.plot_all()

########NEW FILE########
__FILENAME__ = ppm_utils
"""
Utility functions to deal with ppm (qemu screendump format) files.

:copyright: Red Hat 2008-2009
"""

import os
import struct
import time
import re
import glob
import logging
try:
    from PIL import Image
except ImportError:
    Image = None
    logging.warning('No python imaging library installed. Windows guest '
                    'BSOD detection disabled. In order to enable it, '
                    'please install python-imaging or the equivalent for your '
                    'distro.')
try:
    import hashlib
except ImportError:
    import md5

# Some directory/filename utils, for consistency


def md5eval(data):
    """
    Returns a md5 hash evaluator. This function is implemented in order to
    encapsulate objects in a way that is compatible with python 2.4 and
    python 2.6 without warnings.

    :param data: Optional input string that will be used to update the object.
    """
    try:
        hsh = hashlib.new('md5')
    except NameError:
        hsh = md5.new()
    if data:
        hsh.update(data)

    return hsh


def find_id_for_screendump(md5sum, data_dir):
    """
    Search dir for a PPM file whose name ends with md5sum.

    :param md5sum: md5 sum string
    :param dir: Directory that holds the PPM files.
    :return: The file's basename without any preceding path, e.g.
             ``20080101_120000_d41d8cd98f00b204e9800998ecf8427e.ppm``
    """
    try:
        files = os.listdir(data_dir)
    except OSError:
        files = []
    for fl in files:
        exp = re.compile(r"(.*_)?" + md5sum + r"\.ppm", re.IGNORECASE)
        if exp.match(fl):
            return fl


def generate_id_for_screendump(md5sum, data_dir):
    """
    Generate a unique filename using the given MD5 sum.

    :return: Only the file basename, without any preceding path. The
             filename consists of the current date and time, the MD5 sum and a
             ``.ppm`` extension, e.g.
             ``20080101_120000_d41d8cd98f00b204e9800998ecf8427e.ppm``.
    """
    filename = time.strftime("%Y%m%d_%H%M%S") + "_" + md5sum + ".ppm"
    return filename


def get_data_dir(steps_filename):
    """
    Return the data dir of the given steps filename.
    """
    filename = os.path.basename(steps_filename)
    return os.path.join(os.path.dirname(steps_filename), "..", "steps_data",
                        filename + "_data")


# Functions for working with PPM files

def image_read_from_ppm_file(filename):
    """
    Read a PPM image.

    :return: A 3 element tuple containing the width, height and data of the
            image.
    """
    fin = open(filename, "rb")
    fin.readline()
    l2 = fin.readline()
    fin.readline()
    data = fin.read()
    fin.close()

    (w, h) = map(int, l2.split())
    return (w, h, data)


def image_write_to_ppm_file(filename, width, height, data):
    """
    Write a PPM image with the given width, height and data.

    :param filename: PPM file path
    :param width: PPM file width (pixels)
    :param height: PPM file height (pixels)
    """
    fout = open(filename, "wb")
    fout.write("P6\n")
    fout.write("%d %d\n" % (width, height))
    fout.write("255\n")
    fout.write(data)
    fout.close()


def image_crop(width, height, data, x1, y1, dx, dy):
    """
    Crop an image.

    :param width: Original image width
    :param height: Original image height
    :param data: Image data
    :param x1: Desired x coordinate of the cropped region
    :param y1: Desired y coordinate of the cropped region
    :param dx: Desired width of the cropped region
    :param dy: Desired height of the cropped region
    :return: A 3-tuple containing the width, height and data of the
             cropped image.
    """
    if x1 > width - 1:
        x1 = width - 1
    if y1 > height - 1:
        y1 = height - 1
    if dx > width - x1:
        dx = width - x1
    if dy > height - y1:
        dy = height - y1
    newdata = ""
    index = (x1 + y1 * width) * 3
    for _ in range(dy):
        newdata += data[index:(index + dx * 3)]
        index += width * 3
    return (dx, dy, newdata)


def image_md5sum(width, height, data):
    """
    Return the md5sum of an image.

    :param width: PPM file width
    :param height: PPM file height
    :param data: PPM file data
    """
    header = "P6\n%d %d\n255\n" % (width, height)
    hsh = md5eval(header)
    hsh.update(data)
    return hsh.hexdigest()


def get_region_md5sum(width, height, data, x1, y1, dx, dy,
                      cropped_image_filename=None):
    """
    Return the md5sum of a cropped region.

    :param width: Original image width
    :param height: Original image height
    :param data: Image data
    :param x1: Desired x coord of the cropped region
    :param y1: Desired y coord of the cropped region
    :param dx: Desired width of the cropped region
    :param dy: Desired height of the cropped region
    :param cropped_image_filename: if not None, write the resulting cropped
            image to a file with this name
    """
    (cw, ch, cdata) = image_crop(width, height, data, x1, y1, dx, dy)
    # Write cropped image for debugging
    if cropped_image_filename:
        image_write_to_ppm_file(cropped_image_filename, cw, ch, cdata)
    return image_md5sum(cw, ch, cdata)


def image_verify_ppm_file(filename):
    """
    Verify the validity of a PPM file.

    :param filename: Path of the file being verified.
    :return: True if filename is a valid PPM image file. This function
             reads only the first few bytes of the file so it should be rather
             fast.
    """
    try:
        size = os.path.getsize(filename)
        fin = open(filename, "rb")
        assert(fin.readline().strip() == "P6")
        (width, height) = map(int, fin.readline().split())
        assert(width > 0 and height > 0)
        assert(fin.readline().strip() == "255")
        size_read = fin.tell()
        fin.close()
        assert(size - size_read == width * height * 3)
        return True
    except Exception:
        return False


def image_comparison(width, height, data1, data2):
    """
    Generate a green-red comparison image from two given images.

    :param width: Width of both images
    :param height: Height of both images
    :param data1: Data of first image
    :param data2: Data of second image
    :return: A 3-element tuple containing the width, height and data of the
            generated comparison image.

    :note: Input images must be the same size.
    """
    newdata = ""
    i = 0
    while i < width * height * 3:
        # Compute monochromatic value of current pixel in data1
        pixel1_str = data1[i:i + 3]
        temp = struct.unpack("BBB", pixel1_str)
        value1 = int((temp[0] + temp[1] + temp[2]) / 3)
        # Compute monochromatic value of current pixel in data2
        pixel2_str = data2[i:i + 3]
        temp = struct.unpack("BBB", pixel2_str)
        value2 = int((temp[0] + temp[1] + temp[2]) / 3)
        # Compute average of the two values
        value = int((value1 + value2) / 2)
        # Scale value to the upper half of the range [0, 255]
        value = 128 + value / 2
        # Compare pixels
        if pixel1_str == pixel2_str:
            # Equal -- give the pixel a greenish hue
            newpixel = [0, value, 0]
        else:
            # Not equal -- give the pixel a reddish hue
            newpixel = [value, 0, 0]
        newdata += struct.pack("BBB", newpixel[0], newpixel[1], newpixel[2])
        i += 3
    return (width, height, newdata)


def image_fuzzy_compare(width, height, data1, data2):
    """
    Return the degree of equality of two given images.

    :param width: Width of both images
    :param height: Height of both images
    :param data1: Data of first image
    :param data2: Data of second image
    :return: Ratio equal_pixel_count / total_pixel_count.

    :note: Input images must be the same size.
    """
    equal = 0.0
    different = 0.0
    i = 0
    while i < width * height * 3:
        pixel1_str = data1[i:i + 3]
        pixel2_str = data2[i:i + 3]
        # Compare pixels
        if pixel1_str == pixel2_str:
            equal += 1.0
        else:
            different += 1.0
        i += 3
    return equal / (equal + different)


def image_average_hash(image, img_wd=8, img_ht=8):
    """
    Resize and convert the image, then get image data as sequence object,
    calculate the average hash
    :param image: an image path or an opened image object
    """
    if not isinstance(image, Image.Image):
        image = Image.open(image)
    image = image.resize((img_wd, img_ht), Image.ANTIALIAS).convert('L')
    avg = reduce(lambda x, y: x + y, image.getdata()) / (img_wd * img_ht)

    def _hta(i):
        if i < avg:
            return 0
        else:
            return 1
    return reduce(lambda x, (y, z): x | (z << y),
                  enumerate(map(_hta, image.getdata())), 0)


def cal_hamming_distance(h1, h2):
    """
    Calculate the hamming distance
    """
    h_distance, distance = 0, h1 ^ h2
    while distance:
        h_distance += 1
        distance &= distance - 1
    return h_distance


def img_ham_distance(base_img, comp_img):
    """
    Calculate two images hamming distance
    """
    base_img_ahash = image_average_hash(base_img)
    comp_img_ahash = image_average_hash(comp_img)
    return cal_hamming_distance(comp_img_ahash, base_img_ahash)


def img_similar(base_img, comp_img, threshold=10):
    """
    check whether two images are similar by hamming distance
    """
    try:
        hamming_distance = img_ham_distance(base_img, comp_img)
    except IOError:
        return False

    if hamming_distance < threshold:
        return True
    else:
        return False


def have_similar_img(base_img, comp_img_path, threshold=10):
    """
    Check whether comp_img_path have a image looks like base_img.
    """
    support_img_format = ['jpg', 'jpeg', 'gif', 'png', 'pmp']
    comp_images = []
    if os.path.isdir(comp_img_path):
        for ext in support_img_format:
            comp_images.extend([os.path.join(comp_img_path, x) for x in
                                glob.glob1(comp_img_path, '*.%s' % ext)])
    else:
        comp_images.append(comp_img_path)

    for img in comp_images:
        if img_similar(base_img, img, threshold):
            return True
    return False

########NEW FILE########
__FILENAME__ = propcan
"""
Class which allows property and dict-like access to a fixed set of instance
attributes.  Attributes are locked by __slots__, however accessor methods
may be created/removed on instances, or defined by the subclass.  An
INITIALIZED attribute is provided to signel completion of __init__()
for use by accessor methods (i.e. so they know when __init__ may be
setting values).

Subclasses must define a __slots__ class attribute containing the list
of attribute names to reserve.  All additional subclass descendents
must explicitly copy __slots__ from the parent in their definition.

Users of subclass instances are expected to get/set/del attributes
only via the standard object or dict-like interface.  i.e.

instance.attribute = whatever
or
instance['attribute'] = whatever

Internally, methods are free to call the accessor methods.  Only
accessor methods should use the special __dict_*__() and __super_*__() methods.
These are there to allow convenient access to the internal dictionary
values and subclass-defined attributes (such as __slots__).

example:

::

    class A(PropCan):
       # Class with *attributes*
        __slots__ = ('a', 'b')
        # 'a' has defined a set/get/del by definition of method with prefix
        #     set_a, get_a, del_a
        # 'b' doesn't have defined set/get/del then classic set/get/del will be
        #     called instead.


        def __init__(self, a=1, b='b'):
           super(A, self).__init__(a, b)


        def set_a(self, value)
            # If is_instance(obj, A) then obj.a = "val" call this method.
            self.__dict_set__("a", value)


        def get_a(self, value)
            # If is_instance(obj, A) then xx = obj.a call this method.
            return self.__dict_get__("a")


        def del_a(self, value)
            # If is_instance(obj, A) then del obj.a call this method.
            self.__dict_del__("a")


    class B(PropCan):
       # Class without *attributes*
       # ***** Even if class doesn't have attributes there should be
       # defined __slots__ = []. Because it is preferred by new style of class.
       # *****
        __slots__ = []


        def __init__(self):
           super(B, self).__init__()
"""


class PropCanInternal(object):

    """
    Semi-private methods for use only by PropCanBase subclasses (NOT instances)
    """

    # The following methods are intended for use by accessor-methods
    # where they may need to bypass the special attribute/key handling

    def __dict_get__(self, key):
        """
        Get a key unconditionally, w/o checking for accessor method or __slots__
        """
        return dict.__getitem__(self, key)

    def __dict_set__(self, key, value):
        """
        Set a key unconditionally, w/o checking for accessor method or __slots__
        """
        dict.__setitem__(self, key, value)

    def __dict_del__(self, key):
        """
        Del key unconditionally, w/o checking for accessor method or __slots__
        """
        return dict.__delitem__(self, key)

    def __super_get__(self, key):
        """
        Get attribute unconditionally, w/o checking accessor method or __slots__
        """
        return object.__getattribute__(self, key)

    def __super_set__(self, key, value):
        """
        Set attribute unconditionally, w/o checking accessor method or __slots__
        """
        object.__setattr__(self, key, value)

    def __super_del__(self, key):
        """
        Del attribute unconditionally, w/o checking accessor method or __slots__
        """
        object.__delattr__(self, key)


class classproperty(property):

    def __get__(self, obj, type_):
        data = self.fget.__get__(None, type_)()
        return data

    def __set__(self, obj, value):
        cls = type(obj)
        return self.fset.__get__(None, cls)(value)


class PropCanBase(dict, PropCanInternal):

    """
    Objects with optional accessor methods and dict-like access to fixed set of keys
    """

    # get_*(), set_*(), del_*() accessor methods called from subclass
    # __init__ sometimes need special handling, this is the signal.
    INITIALIZED = False

    # Help debugging by making all slot values available in all subclasses
    # cache the value on first call
    ___all_slots__ = None

    @classproperty
    @classmethod
    def __all_slots__(cls):
        if not cls.___all_slots__:
            all_slots = []
            for cls_slots in [getattr(_cls, '__slots__', [])
                              for _cls in cls.__mro__]:
                all_slots += cls_slots
            cls.___all_slots__ = tuple(all_slots)
        return cls.___all_slots__

    def __new__(cls, *args, **dargs):
        if not hasattr(cls, '__slots__'):
            raise NotImplementedError("Class '%s' must define __slots__ "
                                      "property" % str(cls))
        newone = super(PropCanBase, cls).__new__(cls, *args, **dargs)
        cls.___all_slots__ = tuple()
        return newone

    def __init__(self, *args, **dargs):
        """
        Initialize contents directly or by way of accessors

        :param args: Initial values for __slots__ keys, same as dict.
        :param dargs: Initial values for __slots__ keys, same as dict.
        """
        # Params are initialized here, not in super
        super(PropCanBase, self).__init__()
        # No need to re-invent dict argument processing
        values = dict(*args, **dargs)
        for key in self.__all_slots__:
            value = values.get(key, "@!@!@!SENTINEL!@!@!@")
            if value is not "@!@!@!SENTINEL!@!@!@":
                # Call accessor methods if present
                self[key] = value
        # Let accessor methods know initialization is complete
        self.__super_set__('INITIALIZED', True)

    def __getitem__(self, key):
        try:
            accessor = super(PropCanBase,
                             self).__getattribute__('get_%s' % key)
        except AttributeError:
            return super(PropCanBase, self).__getitem__(key)
        return accessor()

    def __setitem__(self, key, value):
        self.__canhaz__(key, KeyError)
        try:
            accessor = super(PropCanBase,
                             self).__getattribute__('set_%s' % key)
        except AttributeError:
            return super(PropCanBase, self).__setitem__(key, value)
        return accessor(value)

    def __delitem__(self, key):
        try:
            accessor = super(PropCanBase,
                             self).__getattribute__('del_%s' % key)
        except AttributeError:
            return super(PropCanBase, self).__delitem__(key)
        return accessor()

    def __get__(self, key):
        try:
            # Attempt to call accessor methods first whenever possible
            self.__canhaz__(key, KeyError)
            return self.__getitem__(key)
        except KeyError:
            # Allow subclasses to define attributes if required
            return super(PropCanBase, self).__getattribute__(key)

    def __set__(self, key, value):
        self.__canhaz__(key)
        try:
            return self.__setitem__(key, value)
        except KeyError, detail:
            # Prevent subclass instances from defining normal attributes
            raise AttributeError(str(detail))

    def __getattr__(self, key):
        try:
            # Attempt to call accessor methods first whenever possible
            self.__canhaz__(key, KeyError)
            return self.__getitem__(key)
        except KeyError:
            # Allow subclasses to define attributes if required
            return super(PropCanBase, self).__getattribute__(key)

    def __setattr__(self, key, value):
        self.__canhaz__(key)
        try:
            return self.__setitem__(key, value)
        except KeyError, detail:
            # Prevent subclass instances from defining normal attributes
            raise AttributeError(str(detail))

    def __delattr__(self, key):
        self.__canhaz__(key)
        try:
            return self.__delitem__(key)
        except KeyError, detail:
            # Prevent subclass instances from deleting normal attributes
            raise AttributeError(str(detail))

    def __canhaz__(self, key, excpt=AttributeError):
        """
        Quickly determine if an accessor or instance attribute name is defined.
        """
        slots = self.__all_slots__
        keys = slots + ('get_%s' % key, 'set_%s' % key, 'del_%s' % key)
        if key not in keys:
            raise excpt("Key '%s' not found in super class attributes or in %s"
                        % (str(key), str(keys)))

    def copy(self):
        """
        Copy properties by value, not by reference.
        """
        return self.__class__(dict(self))

    def update(self, other=None, excpt=AttributeError, **kwargs):
        """
        Update properties in __all_slots__ with another dict.
        """
        _tmp_dict = dict()
        _other_dict = dict()

        if other:
            _other_dict = dict(other)

        try:
            _tmp_dict.update(_other_dict)
            _tmp_dict.update(kwargs)
        except TypeError, detail:
            raise excpt(detail)

        for item in _tmp_dict.keys():
            self[item] = _tmp_dict[item]


class PropCan(PropCanBase):

    """
    Special value handling on retrieval of None values
    """

    def __len__(self):
        length = 0
        for key in self.__all_slots__:
            # special None/False value handling
            if self.__contains__(key):
                length += 1
        return length

    def __contains__(self, key):
        try:
            value = self.__dict_get__(key)
        except (KeyError, AttributeError):
            return False
        # Avoid inf. recursion if value == self
        if issubclass(type(value), type(self)) or value:
            return True
        return False

    def __eq__(self, other):
        # special None/False value handling
        return dict([(key, value) for key, value in self.items()]) == other

    def __ne__(self, other):
        return not self.__eq__(other)

    def keys(self):
        # special None/False value handling
        return [key for key in self.__all_slots__
                if self.__contains__(key)]

    def values(self):
        # special None/False value handling
        return [self[key] for key in self.keys()]

    def items(self):
        return tuple([(key, self[key]) for key in self.keys()])

    has_key = __contains__

    def set_if_none(self, key, value):
        """
        Set the value of key, only if it's not set or None
        """
        if key not in self:
            self[key] = value

    def set_if_value_not_none(self, key, value):
        """
        Set the value of key, only if value is not None
        """
        if value:
            self[key] = value

########NEW FILE########
__FILENAME__ = propcan_unittest
#!/usr/bin/python
import unittest
import logging

import common
import propcan


class TestPropCanBase(unittest.TestCase):

    def test_empty_init(self):
        self.assertRaises(NotImplementedError, propcan.PropCanBase)

    def test_empty_params_init(self):
        self.assertRaises(NotImplementedError,
                          propcan.PropCanBase,
                          {'foo': 'bar'})

    def test_single_init(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo',)
        testcan = FooBar(foo='bar')
        self.assertEqual(len(testcan), 1)
        self.assertEqual(testcan['foo'], 'bar')
        self.assertEqual(testcan.foo, 'bar')

    def test_double_init(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', 'bar')
        testcan = FooBar(foo='bar', bar='foo')
        self.assertEqual(len(testcan), 2)
        self.assertEqual(testcan['foo'], 'bar')
        self.assertEqual(testcan['bar'], 'foo')
        self.assertEqual(len(testcan), 2)
        self.assertEqual(testcan.foo, 'bar')
        self.assertEqual(testcan.bar, 'foo')

    def test_slots_restrict(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo',)
        testcan = FooBar(foo='bar')
        self.assertEqual(len(testcan), 1)
        self.assertEqual(testcan['foo'], 'bar')
        self.assertEqual(testcan.foo, 'bar')
        self.assertRaises(AttributeError, setattr, testcan, 'bar', 'foo')
        self.assertRaises(KeyError, testcan.__setitem__, 'bar', 'foo')

    def test_mixed_init(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', 'bar')
        testcan = FooBar({'foo': 'bar'})
        self.assertEqual(len(testcan), 1)
        self.assertEqual(testcan['foo'], 'bar')
        self.assertEqual(len(testcan), 1)
        self.assertEqual(testcan.foo, 'bar')
        self.assertRaises(KeyError, testcan.__getitem__, 'bar')
        self.assertRaises(AttributeError, getattr, testcan, 'bar')
        self.assertRaises(KeyError, testcan.__delitem__, 'bar')
        self.assertRaises(AttributeError, delattr, testcan, 'bar')

    def test_subclass_single_init_setter(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', )
            it_works = False

            def set_foo(self, value):
                self.__dict_set__('foo', value)
                if value == 'bar':
                    self.__super_set__('it_works', True)
        testcan = FooBar()
        self.assertEqual(len(testcan), 0)
        self.assertFalse(testcan.it_works)
        self.assertRaises(KeyError, testcan.__getitem__, 'foo')
        self.assertRaises(AttributeError, getattr, testcan, 'foo')
        testcan['foo'] = 'bar'
        self.assertEqual(len(testcan), 1)
        self.assertTrue(testcan.it_works)

    def test_subclass_single_init_getter(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', )
            it_works = False

            def get_foo(self):
                value = self.__dict_get__('foo')
                if value == 'bar':
                    self.__super_set__('it_works', True)
                return value
        testcan = FooBar()
        self.assertFalse(testcan.it_works)
        self.assertEqual(len(testcan), 0)
        testcan['foo'] = 'bar'
        self.assertEqual(len(testcan), 1)
        # verify __super_set__() doesn't call getter
        self.assertFalse(testcan.it_works)
        self.assertEqual(testcan['foo'], 'bar')
        self.assertEqual(testcan.foo, 'bar')
        self.assertTrue(testcan.it_works)

    def test_subclass_single_init_delter(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', )
            it_works = False

            def del_foo(self):
                value = self.__dict_get__('foo')
                if value == 'bar':
                    self.__super_set__('it_works', True)
                self.__dict_del__('foo')
        testcan = FooBar()
        self.assertEqual(len(testcan), 0)
        self.assertFalse(testcan.it_works)
        self.assertFalse(hasattr(testcan, 'foo'))
        self.assertFalse(testcan.has_key('foo'))
        testcan['foo'] = 'bar'
        self.assertEqual(len(testcan), 1)
        self.assertEqual(testcan['foo'], 'bar')
        self.assertEqual(testcan.foo, 'bar')
        del testcan['foo']
        self.assertEqual(len(testcan), 0)
        self.assertTrue(testcan.it_works)

    def test_subclass_no_mask_attributeerror(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', )

            def del_foo(self):
                raise AttributeError("Del Test")

            def set_foo(self, value):
                raise AttributeError("Set Test")

            def get_foo(self):
                raise AttributeError("Get Test")
        testcan = FooBar()
        self.assertRaises(AttributeError, testcan.__getitem__, 'foo')
        self.assertRaises(AttributeError, testcan.__setitem__, 'foo', None)
        self.assertRaises(AttributeError, testcan.__delitem__, 'foo')
        self.assertRaises(AttributeError, testcan.__getattr__, 'foo')
        self.assertRaises(AttributeError, testcan.__setattr__, 'foo', None)
        self.assertRaises(AttributeError, testcan.__delattr__, 'foo')

    def test_dict_methods_1(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', 'bar')
        testcan = FooBar(foo='bar', bar='foo')
        testdict = {}
        for key, value in testcan.items():
            testdict[key] = value
        self.assertEqual(testcan, testdict)

    def test_dict_methods_2(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', 'bar')
        testcan = FooBar(foo='bar', bar='foo')
        testdict = testcan.copy()
        self.assertEqual(testcan, testdict)
        testcan['foo'] = 'foo'
        testcan['bar'] = 'bar'
        self.assertTrue(testcan.foo != testdict.foo)
        self.assertTrue(testcan.bar != testdict.bar)
        testdict['foo'] = 'foo'
        testdict['bar'] = 'bar'
        self.assertTrue(testcan.foo == testdict.foo)
        self.assertTrue(testcan.bar == testdict.bar)

    def test_update(self):
        class FooBar(propcan.PropCanBase):
            __slots__ = ('foo', 'bar')

        testdict = FooBar()
        other = {'foo': 1, 'bar': 2}
        testdict.update(other)
        self.assertEqual(testdict, other)

        other = 'string'
        self.assertRaises(ValueError, testdict.update, other)

        other = {'foo': 1, 'bar': 2, 'v3': 3}
        self.assertRaises(KeyError, testdict.update, other)

        kwargs = {'foo': "foo", 'bar': "bar"}
        testdict.update(**kwargs)
        self.assertEqual(testdict, kwargs)


class TestPropCan(unittest.TestCase):

    def setUp(self):
        logging.disable(logging.INFO)

    def test_extranious_init(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCan):
            __slots__ = ('foo', )
        testcan = FooBar((('foo', 'bar'), ('bar', 'foo'),))
        self.assertEqual(len(testcan), 1)
        testcan = FooBar(bar='foo')
        self.assertEqual(len(testcan), 0)

    def test_init_None_value(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCan):
            __slots__ = ('foo', )
        testcan = FooBar(foo=None)
        self.assertEqual(len(testcan), 0)
        self.assertEqual(testcan['foo'], None)
        self.assertEqual(testcan.foo, None)

    def test_compare(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCan):
            __slots__ = ('foo', 'bar')
        testcan = FooBar(foo=None, bar='foo')
        self.assertEqual(len(testcan), 1)
        self.assertTrue(testcan == {'bar': 'foo'})
        testcan.foo = 'bar'
        self.assertEqual(len(testcan), 2)
        self.assertTrue(testcan == {'bar': 'foo', 'foo': 'bar'})
        self.assertTrue(testcan == {'foo': 'bar', 'bar': 'foo'})
        testcan.bar = None
        self.assertEqual(len(testcan), 1)
        self.assertTrue(testcan == {'foo': 'bar'})

    def test_odd_values(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCan):
            __slots__ = ('foo', 'bar', 'baz')
        testcan = FooBar()
        self.assertEqual(len(testcan), 0)
        testcan.foo = type('blah', (), {})
        self.assertEqual(len(testcan), 1)
        testcan['bar'] = testcan
        self.assertEqual(len(testcan), 2)
        setattr(testcan, 'baz', lambda self: str(self))
        self.assertEqual(len(testcan), 3)

    def test_printables(self):
        # Pylint false negative
        # pylint: disable=E1001
        class FooBar(propcan.PropCan):
            __slots__ = ('foo', 'bar', 'baz')
        testcan = FooBar()
        self.assertEqual(len(testcan), 0)
        for value in ('foobar', u'foobar', 1, 1.1, 12345L, ):
            setattr(testcan, 'bar', value)
            self.assertEqual(len(testcan), 1)
            self.assertTrue(testcan == {'bar': value})
            self.assertEqual(str(testcan), str({'bar': value}))

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = qbuses
"""
Autotest representations of qemu buses.

These classes emulates the usual qemu buses behaviors in order to create
or match the autotest params into qemu qdev structure.

:copyright: 2012-2013 Red Hat Inc.
"""
# Autotest imports
import qdevices
from utils import none_or_int


#
# Bus representations
# HDA, I2C, IDE, ISA, PCI, SCSI, System, uhci, ehci, ohci, xhci, ccid,
# virtio-serial-bus
#
class QSparseBus(object):

    """
    Universal bus representation object.

    It creates an abstraction of the way how buses works in qemu. Additionally
    it can store incorrect records (out-of-range addr, multiple devs, ...).
    Everything with bad* prefix means it concerns the bad records (badbus).

    You can insert and remove device to certain address, address ranges or let
    the bus assign first free address. The order of addr_spec does matter since
    the last item is incremented first.

    There are 3 different address representation used:

    stor_addr
        stored address representation '$first-$second-...-$ZZZ'
    addr
        internal address representation [$first, $second, ..., $ZZZ]
    device_addr
        qemu address stored into separate device params (bus, port)
        device{$param1:$first, $param2:$second, ..., $paramZZZ, $ZZZ}

    :note: When you insert a device, it's properties might be updated (addr,..)
    """

    def __init__(self, bus_item, addr_spec, busid, bus_type=None, aobject=None,
                 atype=None):
        """
        :param bus_item: Name of the parameter which specifies bus (bus)
        :type bus_item: str
        :param addr_spec: Bus address specification [names][lengths]
        :type addr_spec: list of lists
        :param busid: id of the bus (pci.0)
        :type busid: str
        :param bus_type: type of the bus (pci)
        :type bus_type: dict
        :param aobject: Related autotest object (image1)
        :type aobject: str
        :param atype: Autotest bus type
        :type atype: str
        """
        self.busid = busid
        self.type = bus_type
        self.aobject = aobject
        self.bus = {}                       # Normal bus records
        self.bus_item = bus_item            # bus param name
        self.addr_items = addr_spec[0]      # [names][lengths]
        self.addr_lengths = addr_spec[1]
        self.atype = atype
        self.__device = None
        self.first_port = [0] * len(addr_spec[0])

    def __str__(self):
        """ default string representation """
        return self.str_short()

    def __getitem__(self, item):
        """
        :param item: autotest id or QObject-like object
        :return: First matching object from this bus
        :raise KeyError: In case no match was found
        """
        if isinstance(item, qdevices.QBaseDevice):
            if item in self.bus.itervalues():
                return item
        else:
            for device in self.bus.itervalues():
                if device.get_aid() == item:
                    return device
        raise KeyError("Device %s is not in %s" % (item, self))

    def get(self, item):
        """
        :param item: autotest id or QObject-like object
        :return: First matching object from this bus or None
        """
        if item in self:
            return self[item]

    def __delitem__(self, item):
        """
        Remove device from bus
        :param item: autotest id or QObject-like object
        :raise KeyError: In case no match was found
        """
        self.remove(self[item])

    def __len__(self):
        """ :return: Number of devices in this bus """
        return len(self.bus)

    def __contains__(self, item):
        """
        Is specified item in this bus?
        :param item: autotest id or QObject-like object
        :return: True - yes, False - no
        """
        if isinstance(item, qdevices.QBaseDevice):
            if item in self.bus.itervalues():
                return True
        else:
            for device in self:
                if device.get_aid() == item:
                    return True
        return False

    def __iter__(self):
        """ Iterate over all defined devices. """
        return self.bus.itervalues()

    def str_short(self):
        """ short string representation """
        if self.atype:
            bus_type = self.atype
        else:
            bus_type = self.type
        return "%s(%s): %s" % (self.busid, bus_type, self._str_devices())

    def _str_devices(self):
        """ short string representation of the good bus """
        out = '{'
        for addr in sorted(self.bus.keys()):
            out += "%s:%s," % (addr, self.bus[addr])
        if out[-1] == ',':
            out = out[:-1]
        return out + '}'

    def str_long(self):
        """ long string representation """
        if self.atype:
            bus_type = self.atype
        else:
            bus_type = self.type
        return "Bus %s, type=%s\nSlots:\n%s" % (self.busid, bus_type,
                                                self._str_devices_long())

    def _str_devices_long(self):
        """ long string representation of devices in the good bus """
        out = ""
        for addr, dev in self.bus.iteritems():
            out += '%s< %4s >%s\n  ' % ('-' * 15, addr,
                                        '-' * 15)
            if isinstance(dev, str):
                out += '"%s"\n  ' % dev
            else:
                out += dev.str_long().replace('\n', '\n  ')
                out = out[:-3]
            out += '\n'
        return out

    def _increment_addr(self, addr, last_addr=None):
        """
        Increment addr base of addr_pattern and last used addr
        :param addr: addr_pattern
        :param last_addr: previous address
        :return: last_addr + 1
        """
        if not last_addr:
            last_addr = [0] * len(self.addr_lengths)
        i = -1
        while True:
            if i < -len(self.addr_lengths):
                return False
            if addr[i] is not None:
                i -= 1
                continue
            last_addr[i] += 1
            if last_addr[i] < self.addr_lengths[i]:
                return last_addr
            last_addr[i] = 0
            i -= 1

    @staticmethod
    def _addr2stor(addr):
        """
        Converts internal addr to storable/hashable address
        :param addr: internal address [addr1, addr2, ...]
        :return: storable address "addr1-addr2-..."
        """
        out = ""
        for value in addr:
            if value is None:
                out += '*-'
            else:
                out += '%s-' % value
        if out:
            return out[:-1]
        else:
            return "*"

    def _dev2addr(self, device):
        """
        Parse the internal address out of the device
        :param device: qdevices.QBaseDevice device
        :return: internal address  [addr1, addr2, ...]
        """
        addr = []
        for key in self.addr_items:
            addr.append(none_or_int(device.get_param(key)))
        return addr

    def _set_first_addr(self, addr_pattern):
        """
        :param addr_pattern: Address pattern (full qualified or with Nones)
        :return: first valid address based on addr_pattern
        """
        use_reserved = True
        if addr_pattern is None:
            addr_pattern = [None] * len(self.addr_lengths)
        # set first usable addr
        last_addr = addr_pattern[:]
        if None in last_addr:  # Address is not fully specified
            use_reserved = False    # Use only free address
            for i in xrange(len(last_addr)):
                if last_addr[i] is None:
                    last_addr[i] = self.first_port[i]
        return last_addr, use_reserved

    def get_free_slot(self, addr_pattern):
        """
        Finds unoccupied address

        :param addr_pattern: Address pattern (full qualified or with Nones)
        :return: First free address when found, (free or reserved for this dev)
                 None when no free address is found, (all occupied)
                 False in case of incorrect address (oor)
        """
        # init
        last_addr, use_reserved = self._set_first_addr(addr_pattern)
        # Check the addr_pattern ranges
        for i in xrange(len(self.addr_lengths)):
            if (last_addr[i] < self.first_port[i] or
                    last_addr[i] >= self.addr_lengths[i]):
                return False
        # Increment addr until free match is found
        while last_addr is not False:
            if self._addr2stor(last_addr) not in self.bus:
                return last_addr
            if (use_reserved and
                    self.bus[self._addr2stor(last_addr)] == "reserved"):
                return last_addr
            last_addr = self._increment_addr(addr_pattern, last_addr)
        return None     # No free matching address found

    def _check_bus(self, device):
        """
        Check, whether this device can be plugged into this bus.
        :param device: qdevices.QBaseDevice device
        :return: True in case ids are correct, False when not
        """
        if (device.get_param(self.bus_item) and
                device.get_param(self.bus_item) != self.busid):
            return False
        else:
            return True

    def _set_device_props(self, device, addr):
        """
        Set the full device address
        :param device: qdevices.QBaseDevice device
        :param addr: internal address  [addr1, addr2, ...]
        """
        if self.bus_item:
            device.set_param(self.bus_item, self.busid)
        for i in xrange(len(self.addr_items)):
            device.set_param(self.addr_items[i], addr[i])

    def _update_device_props(self, device, addr):
        """
        Update values of previously set address items.
        :param device: qdevices.QBaseDevice device
        :param addr: internal address  [addr1, addr2, ...]
        """
        if device.get_param(self.bus_item) is not None:
            device.set_param(self.bus_item, self.busid)
        for i in xrange(len(self.addr_items)):
            if device.get_param(self.addr_items[i]) is not None:
                device.set_param(self.addr_items[i], addr[i])

    def reserve(self, addr):
        """
        Reserve the slot
        :param addr: Desired address
        :type addr: internal [addr1, addr2, ..] or stor format "addr1-addr2-.."
        """
        if not isinstance(addr, str):
            addr = self._addr2stor(addr)
        self.bus[addr] = "reserved"

    def insert(self, device, strict_mode=False):
        """
        Insert device into this bus representation.

        :param device: qdevices.QBaseDevice device
        :param strict_mode: Use strict mode (set optional params)
        :return: list of added devices on success,
                 string indicating the failure on failure.
        """
        additional_devices = []
        if not self._check_bus(device):
            return "BusId"
        try:
            addr_pattern = self._dev2addr(device)
        except (ValueError, LookupError):
            return "BasicAddress"
        addr = self.get_free_slot(addr_pattern)
        if addr is None:
            if None in addr_pattern:
                return "NoFreeSlot"
            else:
                return "UsedSlot"
        elif addr is False:
            return "BadAddr(%s)" % addr
        else:
            additional_devices.extend(self._insert(device,
                                                   self._addr2stor(addr)))
        if strict_mode:     # Set full address in strict_mode
            self._set_device_props(device, addr)
        else:
            self._update_device_props(device, addr)
        return additional_devices

    def _insert(self, device, addr):
        """
        Insert device into good bus
        :param device: qdevices.QBaseDevice device
        :param addr: internal address  [addr1, addr2, ...]
        :return: List of additional devices
        """
        self.bus[addr] = device
        return []

    def remove(self, device):
        """
        Remove device from this bus
        :param device: qdevices.QBaseDevice device
        :return: True when removed, False when the device wasn't found
        """
        if device in self.bus.itervalues():
            remove = None
            for key, item in self.bus.iteritems():
                if item is device:
                    remove = key
                    break
            if remove is not None:
                del(self.bus[remove])
                return True
        return False

    def set_device(self, device):
        """ Set the device in which this bus belongs """
        self.__device = device

    def get_device(self):
        """ Get device in which this bus is present """
        return self.__device

    def match_bus(self, bus_spec, type_test=True):
        """
        Check if the bus matches the bus_specification.
        :param bus_spec: Bus specification
        :type bus_spec: dict
        :param type_test: Match only type
        :type type_test: bool
        :return: True when the bus matches the specification
        :rtype: bool
        """
        if type_test and bus_spec.get('type'):
            if isinstance(bus_spec['type'], (tuple, list)):
                for bus_type in bus_spec['type']:
                    if bus_type == self.type:
                        return True
                return False
            elif self.type == bus_spec['type']:
                return True
        for key, value in bus_spec.iteritems():
            if isinstance(value, (tuple, list)):
                for val in value:
                    if self.__dict__.get(key, None) == val:
                        break
                else:
                    return False
            elif self.__dict__.get(key, None) != value:
                return False
        return True


class QStrictCustomBus(QSparseBus):

    """
    Similar to QSparseBus. The address starts with 1 and addr is always set
    """

    def __init__(self, bus_item, addr_spec, busid, bus_type=None, aobject=None,
                 atype=None, first_port=None):
        super(QStrictCustomBus, self).__init__(bus_item, addr_spec, busid,
                                               bus_type, aobject, atype)
        if first_port:
            self.first_port = first_port

    def _update_device_props(self, device, addr):
        """ in case this is usb-hub update the child port_prefix """
        self._set_device_props(device, addr)


class QUSBBus(QSparseBus):

    """
    USB bus representation including usb-hub handling.
    """

    def __init__(self, length, busid, bus_type, aobject=None,
                 port_prefix=None):
        """
        Bus type have to be generalized and parsed from original bus type:
        (usb-ehci == ehci, ich9-usb-uhci1 == uhci, ...)
        """
        # There are various usb devices for the same bus type, use only portion
        for bus in ('uhci', 'ehci', 'ohci', 'xhci'):
            if bus in bus_type:
                bus_type = bus
                break
        # Usb ports are counted from 1 so the length have to be +1
        super(QUSBBus, self).__init__('bus', [['port'], [length + 1]], busid,
                                      bus_type, aobject)
        self.__port_prefix = port_prefix
        self.__length = length
        self.first_port = [1]

    def _check_bus(self, device):
        """ Check port prefix in order to match addresses in usb-hubs """
        if not super(QUSBBus, self)._check_bus(device):
            return False
        port = device.get_param('port')   # 2.1.6
        if port or port == 0:   # If port is specified
            idx = str(port).rfind('.')
            if idx != -1:   # Strip last number and compare with port_prefix
                return port[:idx] == self.__port_prefix
            # Port is number, match only root usb bus
            elif self.__port_prefix != "":
                return False
        return True

    def _dev2addr(self, device):
        """
        Parse the internal address out of the device
        :param device: qdevices.QBaseDevice device
        :return: internal address  [addr1, addr2, ...]
        """
        value = device.get_param('port')
        if value is None:
            addr = [None]
        else:
            addr = [int(value[len(self.__port_prefix) + 1:])]
        return addr

    def __hook_child_bus(self, device, addr):
        """ If this is usb-hub, add child bus """
        # only usb hub needs customization
        if device.get_param('driver') != 'usb-hub':
            return
        _bus = [_ for _ in device.child_bus if not isinstance(_, QUSBBus)]
        _bus.append(QUSBBus(8, self.busid, self.type, device.get_aid(),
                            str(addr[0])))
        device.child_bus = _bus

    def _set_device_props(self, device, addr):
        """ in case this is usb-hub update the child port_prefix """
        if addr[0] or addr[0] is 0:
            if self.__port_prefix:
                addr = ['%s.%s' % (self.__port_prefix, addr[0])]
        self.__hook_child_bus(device, addr)
        super(QUSBBus, self)._set_device_props(device, addr)

    def _update_device_props(self, device, addr):
        """ in case this is usb-hub update the child port_prefix """
        self._set_device_props(device, addr)


class QDriveBus(QSparseBus):

    """
    QDrive bus representation (single slot, drive=...)
    """

    def __init__(self, busid, aobject=None):
        """
        :param busid: id of the bus (pci.0)
        :param aobject: Related autotest object (image1)
        """
        super(QDriveBus, self).__init__('drive', [[], []], busid, 'QDrive',
                                        aobject)

    def get_free_slot(self, addr_pattern):
        """ Use only drive as slot """
        if 'drive' in self.bus:
            return None
        else:
            return True

    @staticmethod
    def _addr2stor(addr):
        """ address is always drive """
        return 'drive'

    def _update_device_props(self, device, addr):
        """
        Always set -drive property, it's mandatory. Also for hotplug purposes
        store this bus device into hook variable of the device.
        """
        self._set_device_props(device, addr)
        if hasattr(device, 'hook_drive_bus'):
            device.hook_drive_bus = self.get_device()


class QDenseBus(QSparseBus):

    """
    Dense bus representation. The only difference from SparseBus is the output
    string format. DenseBus iterates over all addresses and show free slots
    too. SparseBus on the other hand prints always the device address.
    """

    def _str_devices_long(self):
        """ Show all addresses even when they are unused """
        out = ""
        addr_pattern = [None] * len(self.addr_items)
        addr = self._set_first_addr(addr_pattern)[0]
        while addr:
            dev = self.bus.get(self._addr2stor(addr))
            out += '%s< %4s >%s\n  ' % ('-' * 15, self._addr2stor(addr),
                                        '-' * 15)
            if hasattr(dev, 'str_long'):
                out += dev.str_long().replace('\n', '\n  ')
                out = out[:-3]
            elif isinstance(dev, str):
                out += '"%s"' % dev
            else:
                out += "%s" % dev
            out += '\n'
            addr = self._increment_addr(addr_pattern, addr)
        return out

    def _str_devices(self):
        """ Show all addresses even when they are unused, don't print addr """
        out = '['
        addr_pattern = [None] * len(self.addr_items)
        addr = self._set_first_addr(addr_pattern)[0]
        while addr:
            out += "%s," % self.bus.get(self._addr2stor(addr))
            addr = self._increment_addr(addr_pattern, addr)
        if out[-1] == ',':
            out = out[:-1]
        return out + ']'


class QPCIBus(QSparseBus):

    """
    PCI Bus representation (bus&addr, uses hex digits)
    """

    def __init__(self, busid, bus_type, aobject=None, length=32, first_port=0):
        """ bus&addr, 32 slots """
        super(QPCIBus, self).__init__('bus', [['addr', 'func'], [length, 8]],
                                      busid, bus_type, aobject)
        self.first_port = (first_port, 0)

    @staticmethod
    def _addr2stor(addr):
        """ force all items as hexadecimal values """
        out = ""
        for value in addr:
            if value is None:
                out += '*-'
            else:
                out += '%02x-' % value
        if out:
            return out[:-1]
        else:
            return "*"

    def _dev2addr(self, device):
        """ Read the values in base of 16 (hex) """
        addr = device.get_param('addr')
        if isinstance(addr, int):     # only addr
            return [addr, 0]
        elif not addr:    # not defined
            return [None, 0]
        elif isinstance(addr, str):     # addr or addr.func
            addr = [int(_, 16) for _ in addr.split('.', 1)]
            if len(addr) < 2:   # only addr
                addr.append(0)
        return addr

    def _set_device_props(self, device, addr):
        """ Convert addr to the format used by qtree """
        device.set_param(self.bus_item, self.busid)
        orig_addr = device.get_param('addr')
        if addr[1] or (isinstance(orig_addr, str) and
                       orig_addr.find('.') != -1):
            device.set_param('addr', '%02x.%x' % (addr[0], addr[1]))
        else:
            device.set_param('addr', '%02x' % (addr[0]))

    def _update_device_props(self, device, addr):
        """ Always set properties """
        self._set_device_props(device, addr)

    def _increment_addr(self, addr, last_addr=None):
        """ Don't use multifunction address by default """
        if addr[1] is None:
            addr[1] = 0
        return super(QPCIBus, self)._increment_addr(addr, last_addr=last_addr)


class QPCISwitchBus(QPCIBus):

    """
    PCI Switch bus representation (creates downstream device while inserting
    a device).
    """

    def __init__(self, busid, bus_type, downstream_type, aobject=None):
        super(QPCISwitchBus, self).__init__(busid, bus_type, aobject)
        self.__downstream_ports = {}
        self.__downstream_type = downstream_type

    def add_downstream_port(self, addr):
        """
        Add downstream port of the certain address
        """
        if addr not in self.__downstream_ports:
            bus_id = "%s.%s" % (self.busid, int(addr, 16))
            bus = QPCIBus(bus_id, 'PCIE', bus_id)
            self.__downstream_ports[addr] = bus
            downstream = qdevices.QDevice(self.__downstream_type,
                                          {'id': bus_id,
                                           'bus': self.busid,
                                           'addr': addr},
                                          aobject=self.aobject,
                                          parent_bus={'busid': '_PCI_CHASSIS'},
                                          child_bus=bus)
            return downstream

    def _insert(self, device, addr):
        """
        Instead of the device inserts the downstream port. The device is
        inserted later during _set_device_props into this downstream port.
        """
        _addr = addr.split('-')[0]
        added_devices = []
        downstream = self.add_downstream_port(_addr)
        if downstream is not None:
            added_devices.append(downstream)
            added_devices.extend(super(QPCISwitchBus, self)._insert(downstream,
                                                                    addr))

        bus_id = "%s.%s" % (self.busid, int(_addr, 16))
        device['bus'] = bus_id

        return added_devices

    def _set_device_props(self, device, addr):
        """
        Instead of setting the addr this insert the device into the
        downstream port.
        """
        self.__downstream_ports['%02x' % addr[0]].insert(device)


class QSCSIBus(QSparseBus):

    """
    SCSI bus representation (bus + 2 leves, don't iterate over lun by default)
    """

    def __init__(self, busid, bus_type, addr_spec, aobject=None, atype=None):
        """
        :param busid: id of the bus (mybus.0)
        :param bus_type: type of the bus (virtio-scsi-pci, lsi53c895a, ...)
        :param addr_spec: Ranges of addr_spec [scsiid_range, lun_range]
        :param aobject: Related autotest object (image1)
        :param atype: Autotest bus type
        :type atype: str
        """
        super(QSCSIBus, self).__init__('bus', [['scsi-id', 'lun'], addr_spec],
                                       busid, bus_type, aobject, atype)

    def _increment_addr(self, addr, last_addr=None):
        """
        Qemu doesn't increment lun automatically so don't use it when
        it's not explicitelly specified.
        """
        if addr[1] is None:
            addr[1] = 0
        return super(QSCSIBus, self)._increment_addr(addr, last_addr=last_addr)


class QBusUnitBus(QDenseBus):

    """ Implementation of bus-unit bus (ahci, ide) """

    def __init__(self, busid, bus_type, lengths, aobject=None, atype=None):
        """
        :param busid: id of the bus (mybus.0)
        :type busid: str
        :param bus_type: type of the bus (ahci)
        :type bus_type: str
        :param lenghts: lenghts of [buses, units]
        :type lenghts: list of lists
        :param aobject: Related autotest object (image1)
        :type aobject: str
        :param atype: Autotest bus type
        :type atype: str
        """
        if len(lengths) != 2:
            raise ValueError("len(lenghts) have to be 2 (%s)" % self)
        super(QBusUnitBus, self).__init__('bus', [['bus', 'unit'], lengths],
                                          busid, bus_type, aobject, atype)

    def _update_device_props(self, device, addr):
        """ Always set the properties """
        return self._set_device_props(device, addr)

    def _set_device_props(self, device, addr):
        """This bus is compound of m-buses + n-units, set properties """
        device.set_param('bus', "%s.%s" % (self.busid, addr[0]))
        device.set_param('unit', addr[1])

    def _check_bus(self, device):
        """ This bus is compound of m-buses + n-units, check correct busid """
        bus = device.get_param('bus')
        if isinstance(bus, str):
            bus = bus.rsplit('.', 1)
            if len(bus) == 2 and bus[0] != self.busid:  # aaa.3
                return False
            elif not bus[0].isdigit() and bus[0] != self.busid:     # aaa
                return False
        return True  # None, 5, '3'

    def _dev2addr(self, device):
        """ This bus is compound of m-buses + n-units, parse addr from dev """
        bus = None
        unit = None
        busid = device.get_param('bus')
        if isinstance(busid, str):
            if busid.isdigit():
                bus = int(busid)
            else:
                busid = busid.rsplit('.', 1)
                if len(busid) == 2 and busid[1].isdigit():
                    bus = int(busid[1])
        if isinstance(busid, int):
            bus = busid
        if device.get_param('unit'):
            unit = int(device.get_param('unit'))
        return [bus, unit]


class QAHCIBus(QBusUnitBus):

    """ AHCI bus (ich9-ahci, ahci) """

    def __init__(self, busid, aobject=None):
        """ 6xbus, 2xunit """
        super(QAHCIBus, self).__init__(busid, 'IDE', [6, 1], aobject, 'ahci')


class QIDEBus(QBusUnitBus):

    """ IDE bus (piix3-ide) """

    def __init__(self, busid, aobject=None):
        """ 2xbus, 2xunit """
        super(QIDEBus, self).__init__(busid, 'IDE', [2, 2], aobject, 'ide')


class QFloppyBus(QDenseBus):

    """
    Floppy bus (-global isa-fdc.drive?=$drive)
    """

    def __init__(self, busid, aobject=None):
        """ property <= [driveA, driveB] """
        super(QFloppyBus, self).__init__(None, [['property'], [2]], busid,
                                         'floppy', aobject)

    @staticmethod
    def _addr2stor(addr):
        """ translate as drive$CHAR """
        return "drive%s" % chr(65 + addr[0])  # 'A' + addr

    def _dev2addr(self, device):
        """ Read None, number or drive$CHAR and convert to int() """
        addr = device.get_param('property')
        if isinstance(addr, str):
            if addr.startswith('drive') and len(addr) > 5:
                addr = ord(addr[5])
            elif addr.isdigit():
                addr = int(addr)
        return [addr]

    def _update_device_props(self, device, addr):
        """ Always set props """
        self._set_device_props(device, addr)

    def _set_device_props(self, device, addr):
        """ Change value to drive{A,B,...} """
        device.set_param('property', self._addr2stor(addr))


class QOldFloppyBus(QDenseBus):

    """
    Floppy bus (-drive index=n)
    """

    def __init__(self, busid, aobject=None):
        """ property <= [driveA, driveB] """
        super(QOldFloppyBus, self).__init__(None, [['index'], [2]], busid,
                                            'floppy', aobject)

    def _update_device_props(self, device, addr):
        """ Always set props """
        self._set_device_props(device, addr)

    def _set_device_props(self, device, addr):
        """ Change value to drive{A,B,...} """
        device.set_param('index', self._addr2stor(addr))

########NEW FILE########
__FILENAME__ = qcontainer
"""
Autotest qdev-structure representation.

This is the main class which represent qdev-structure. It allows to create,
interact and verify the qemu qdev structure.

:copyright: 2012-2013 Red Hat Inc.
"""

# Python imports
import logging
import re

# Autotest imports
from autotest.client.shared import utils, error
from virttest import arch, storage, data_dir, virt_vm
from utils import (DeviceError, DeviceHotplugError, DeviceInsertError,
                   DeviceRemoveError, DeviceUnplugError, none_or_int)
import os
import qbuses
import qdevices


#
# Device container (device representation of VM)
# This class represents VM by storing all devices and their connections (buses)
#
class DevContainer(object):

    """
    Device container class
    """
    # General methods

    def __init__(self, qemu_binary, vmname, strict_mode="no",
                 workaround_qemu_qmp_crash="no", allow_hotplugged_vm="yes"):
        """
        :param qemu_binary: qemu binary
        :param vm: related VM
        :param strict_mode: Use strict mode (set optional params)
        """
        def get_hmp_cmds(qemu_binary):
            """ :return: list of human monitor commands """
            _ = utils.system_output("echo -e 'help\nquit' | %s -monitor "
                                    "stdio -vnc none" % qemu_binary,
                                    timeout=10, ignore_status=True)
            _ = re.findall(r'^([^\| \[\n]+\|?\w+)', _, re.M)
            hmp_cmds = []
            for cmd in _:
                if '|' not in cmd:
                    if cmd != 'The':
                        hmp_cmds.append(cmd)
                else:
                    hmp_cmds.extend(cmd.split('|'))
            return hmp_cmds

        def get_qmp_cmds(qemu_binary, workaround_qemu_qmp_crash=False):
            """ :return: list of qmp commands """
            cmds = None
            if not workaround_qemu_qmp_crash:
                cmds = utils.system_output('echo -e \''
                                           '{ "execute": "qmp_capabilities" }\n'
                                           '{ "execute": "query-commands", "id": "RAND91" }\n'
                                           '{ "execute": "quit" }\''
                                           '| %s -qmp stdio -vnc none | grep return |'
                                           ' grep RAND91' % qemu_binary, timeout=10,
                                           ignore_status=True).splitlines()
            if not cmds:
                # Some qemu versions crashes when qmp used too early; add sleep
                cmds = utils.system_output('echo -e \''
                                           '{ "execute": "qmp_capabilities" }\n'
                                           '{ "execute": "query-commands", "id": "RAND91" }\n'
                                           '{ "execute": "quit" }\' | (sleep 1; cat )'
                                           '| %s -qmp stdio -vnc none | grep return |'
                                           ' grep RAND91' % qemu_binary, timeout=10,
                                           ignore_status=True).splitlines()
            if cmds:
                cmds = re.findall(r'{\s*"name"\s*:\s*"([^"]+)"\s*}', cmds[0])
            if cmds:    # If no mathes, return None
                return cmds

        self.__state = -1    # -1 synchronized, 0 synchronized after hotplug
        self.__qemu_help = utils.system_output("%s -help" % qemu_binary,
                                               timeout=10, ignore_status=True)
        self.__device_help = utils.system_output("%s -device ? 2>&1"
                                                 % qemu_binary, timeout=10,
                                                 ignore_status=True)
        self.__machine_types = utils.system_output("%s -M ?" % qemu_binary,
                                                   timeout=10, ignore_status=True)
        self.__hmp_cmds = get_hmp_cmds(qemu_binary)
        self.__qmp_cmds = get_qmp_cmds(qemu_binary,
                                       workaround_qemu_qmp_crash == 'always')
        self.vmname = vmname
        self.strict_mode = strict_mode == 'yes'
        self.__devices = []
        self.__buses = []
        self.__qemu_binary = qemu_binary
        self.__execute_qemu_last = None
        self.__execute_qemu_out = ""
        self.allow_hotplugged_vm = allow_hotplugged_vm == 'yes'

    def __getitem__(self, item):
        """
        :param item: autotest id or QObject-like object
        :return: First matching object defined in this QDevContainer
        :raise KeyError: In case no match was found
        """
        if isinstance(item, qdevices.QBaseDevice):
            if item in self.__devices:
                return item
        elif item:
            for device in self.__devices:
                if device.get_aid() == item:
                    return device
        raise KeyError("Device %s is not in %s" % (item, self))

    def get(self, item):
        """
        :param item: autotest id or QObject-like object
        :return: First matching object defined in this QDevContainer or None
        """
        if item in self:
            return self[item]

    def get_by_properties(self, filt):
        """
        Return list of matching devices
        :param filt: filter {'property': 'value', ...}
        :type filt: dict
        """
        out = []
        for device in self.__devices:
            for key, value in filt.iteritems():
                if not hasattr(device, key):
                    break
                if getattr(device, key) != value:
                    break
            else:
                out.append(device)
        return out

    def get_by_params(self, filt):
        """
        Return list of matching devices
        :param filt: filter {'param': 'value', ...}
        :type filt: dict
        """
        out = []
        for device in self.__devices:
            for key, value in filt.iteritems():
                if key not in device.params:
                    break
                if device.params[key] != value:
                    break
            else:
                out.append(device)
        return out

    def __delitem__(self, item):
        """
        Delete specified item from devices list
        :param item: autotest id or QObject-like object
        :raise KeyError: In case no match was found
        """
        # Remove child_buses including devices
        if self.remove(item):
            raise KeyError(item)

    def remove(self, device, recursive=True):
        """
        Remove device from this representation
        :param device: autotest id or QObject-like object
        :param recursive: remove children recursively
        :return: None on success, -1 when the device is not present
        """
        device = self[device]
        if not recursive:   # Check if there are no children
            for bus in device.child_bus:
                if len(bus) != 0:
                    raise DeviceRemoveError(device, "Child bus contains "
                                            "devices", self)
        else:               # Recursively remove all devices
            for dev in device.get_children():
                # One child might be already removed from other child's bus
                if dev in self:
                    self.remove(dev, True)
        if device in self.__devices:    # It might be removed from child bus
            for bus in self.__buses:        # Remove from parent_buses
                bus.remove(device)
            for bus in device.child_bus:    # Remove child buses from vm buses
                self.__buses.remove(bus)
            self.__devices.remove(device)   # Remove from list of devices

    def wash_the_device_out(self, device):
        """
        Removes any traces of the device from representation.
        :param device: qdevices.QBaseDevice device
        """
        # remove device from parent buses
        for bus in self.__buses:
            if device in bus:
                bus.remove(device)
        # remove child devices
        for bus in device.child_bus:
            for dev in device.get_children():
                if dev in self:
                    self.remove(dev, True)
            # remove child_buses from self.__buses
            if bus in self.__buses:
                self.__buses.remove(bus)
        # remove device from self.__devices
        if device in self.__devices:
            self.__devices.remove(device)

    def __len__(self):
        """ :return: Number of inserted devices """
        return len(self.__devices)

    def __contains__(self, item):
        """
        Is specified item defined in current devices list?
        :param item: autotest id or QObject-like object
        :return: True - yes, False - no
        """
        if isinstance(item, qdevices.QBaseDevice):
            if item in self.__devices:
                return True
        elif item:
            for device in self.__devices:
                if device.get_aid() == item:
                    return True
        return False

    def __iter__(self):
        """ Iterate over all defined devices. """
        return self.__devices.__iter__()

    def __eq__(self, qdev2):
        """ Are the VM representation alike? """
        if len(qdev2) != len(self):
            return False
        if qdev2.get_state() != self.get_state():
            if qdev2.allow_hotplugged_vm:
                if qdev2.get_state() > 0 or self.get_state() > 0:
                    return False
            else:
                return False
        for dev in self:
            if dev not in qdev2:
                return False

        # state, buses and devices are handled earlier
        qdev2 = qdev2.__dict__
        for key, value in self.__dict__.iteritems():
            if key in ("_DevContainer__devices", "_DevContainer__buses",
                       "_DevContainer__state",
                       "allow_hotplugged_vm"):
                continue
            if key not in qdev2 or qdev2[key] != value:
                return False
        return True

    def __ne__(self, qdev2):
        """ Are the VM representation different? """
        return not self.__eq__(qdev2)

    def set_dirty(self):
        """ Increase VM dirtiness (not synchronized with VM) """
        if self.__state >= 0:
            self.__state += 1
        else:
            self.__state = 1

    def set_clean(self):
        """ Decrease VM dirtiness (synchronized with VM) """
        if self.__state > 0:
            self.__state -= 1
        else:
            raise DeviceError("Trying to clean clear VM (probably calling "
                              "hotplug_clean() twice).\n%s" % self.str_long())

    def reset_state(self):
        """
        Mark representation as completely clean, without hotplugged devices.
        """
        self.__state = -1

    def get_state(self):
        """ Get the current state (0 = synchronized with VM) """
        return self.__state

    def get_by_qid(self, qid):
        """
        :param qid: qemu id
        :return: List of items with matching qemu id
        """
        ret = []
        if qid:
            for device in self:
                if device.get_qid() == qid:
                    ret.append(device)
        return ret

    def str_short(self):
        """ Short string representation of all devices """
        out = "Devices of %s" % self.vmname
        dirty = self.get_state()
        if dirty == -1:
            pass
        elif dirty == 0:
            out += "(H)"
        else:
            out += "(DIRTY%s)" % dirty
        out += ": ["
        for device in self:
            out += "%s," % device
        if out[-1] == ',':
            out = out[:-1]
        return out + "]"

    def str_long(self):
        """ Long string representation of all devices """
        out = "Devices of %s" % self.vmname
        dirty = self.get_state()
        if dirty == -1:
            pass
        elif dirty == 0:
            out += "(H)"
        else:
            out += "(DIRTY%s)" % dirty
        out += ":\n"
        for device in self:
            out += device.str_long()
        if out[-1] == '\n':
            out = out[:-1]
        return out

    def str_bus_short(self):
        """ Short representation of all buses """
        out = "Buses of %s\n  " % self.vmname
        for bus in self.__buses:
            out += str(bus)
            out += "\n  "
        return out[:-3]

    def str_bus_long(self):
        """ Long representation of all buses """
        out = "Devices of %s:\n  " % self.vmname
        for bus in self.__buses:
            out += bus.str_long().replace('\n', '\n  ')
        return out[:-3]

    def __create_unique_aid(self, qid):
        """
        Creates unique autotest id name from given qid
        :param qid: Original qemu id
        :return: aid (the format is "$qid__%d")
        """
        if qid and qid not in self:
            return qid
        i = 0
        while "%s__%d" % (qid, i) in self:
            i += 1
        return "%s__%d" % (qid, i)

    def has_option(self, option):
        """
        :param option: Desired option
        :return: Is the desired option supported by current qemu?
        """
        return bool(re.search(r"^-%s(\s|$)" % option, self.__qemu_help,
                              re.MULTILINE))

    def has_device(self, device):
        """
        :param device: Desired device
        :return: Is the desired device supported by current qemu?
        """
        return bool(re.search(r'name "%s"|alias "%s"' % (device, device),
                              self.__device_help))

    def get_help_text(self):
        """
        :return: Full output of "qemu -help"
        """
        return self.__qemu_help

    def has_hmp_cmd(self, cmd):
        """
        :param cmd: Desired command
        :return: Is the desired command supported by this qemu's human monitor?
        """
        return cmd in self.__hmp_cmds

    def has_qmp_cmd(self, cmd):
        """
        :param cmd: Desired command
        :return: Is the desired command supported by this qemu's QMP monitor?
        """
        return cmd in self.__qmp_cmds

    def execute_qemu(self, options, timeout=5):
        """
        Execute this qemu and return the stdout+stderr output.
        :param options: additional qemu options
        :type options: string
        :param timeout: execution timeout
        :type timeout: int
        :return: Output of the qemu
        :rtype: string
        """
        if self.__execute_qemu_last != options:
            cmd = "%s %s 2>&1" % (self.__qemu_binary, options)
            self.__execute_qemu_out = str(utils.run(cmd, timeout=timeout,
                                                    ignore_status=True,
                                                    verbose=False).stdout)
        return self.__execute_qemu_out

    def get_buses(self, bus_spec, type_test=False):
        """
        :param bus_spec: Bus specification (dictionary)
        :type bus_spec: dict
        :param atype: Match qemu and atype params
        :type atype: bool
        :return: All matching buses
        :rtype: List of QSparseBus
        """
        buses = []
        for bus in self.__buses:
            if bus.match_bus(bus_spec, type_test):
                buses.append(bus)
        return buses

    def get_first_free_bus(self, bus_spec, addr):
        """
        :param bus_spec: Bus specification (dictionary)
        :param addr: Desired address
        :return: First matching bus with free desired address (the latest
                 added matching bus)
        """
        buses = self.get_buses(bus_spec)
        for bus in buses:
            _ = bus.get_free_slot(addr)
            if _ is not None and _ is not False:
                return bus

    def insert(self, devices, strict_mode=None):
        """
        Inserts devices into this VM representation
        :param devices: List of qdevices.QBaseDevice devices
        :raise DeviceError: On failure. The representation remains unchanged.
        """
        def cleanup():
            """ Remove all added devices (on failure) """
            for device in added:
                self.wash_the_device_out(device)

        if not isinstance(devices, list):
            devices = [devices]

        added = []
        for device in devices:
            try:
                added.extend(self._insert(device, strict_mode))
            except DeviceError, details:
                cleanup()
                raise DeviceError("%s\nError occurred while inserting device %s"
                                  " (%s). Please check the log for details."
                                  % (details, device, devices))
        return added

    def _insert(self, device, strict_mode=None):
        """
        Inserts device into this VM representation
        :param device: qdevices.QBaseDevice device
        :raise DeviceError: On failure. The representation remains unchanged.

        1)  get list of matching parent buses
        2)  try to find matching bus+address
        2b) add bus required additional devices prior to adding this device
        3)  add child buses
        4)  append into self.devices
        """
        def clean(device, added_devices):
            """ Remove all inserted devices (on failure) """
            self.wash_the_device_out(device)
            for device in added_devices:
                self.wash_the_device_out(device)

        if strict_mode is None:
            _strict_mode = self.strict_mode
        if strict_mode is True:
            _strict_mode = True
        else:
            _strict_mode = False
        added_devices = []
        if device.parent_bus is not None and not isinstance(device.parent_bus,
                                                            (list, tuple)):
            # it have to be list of parent buses
            device.parent_bus = (device.parent_bus,)
        for parent_bus in device.parent_bus:
            # type, aobject, busid
            if parent_bus is None:
                continue
            # 1
            buses = self.get_buses(parent_bus, True)
            if not buses:
                err = "ParentBus(%s): No matching bus\n" % parent_bus
                clean(device, added_devices)
                raise DeviceInsertError(device, err, self)
            bus_returns = []
            strict_mode = _strict_mode
            for bus in buses:   # 2
                if not bus.match_bus(parent_bus, False):
                    # First available bus in qemu is not of the same type as
                    # we in autotest require. Force strict mode to get this
                    # device into the correct bus (ide-hd could go into ahci
                    # and ide hba, qemu doesn't care, autotest does).
                    strict_mode = True
                    bus_returns.append(-1)  # Don't use this bus
                    continue
                bus_returns.append(bus.insert(device, strict_mode))
                if isinstance(bus_returns[-1], list):   # we are done
                    # The bus might require additional devices plugged first
                    try:
                        added_devices.extend(self.insert(bus_returns[-1]))
                    except DeviceError, details:
                        err = ("Can't insert device %s because additional "
                               "device required by bus %s failed to be "
                               "inserted with:\n%s" % (device, bus, details))
                        clean(device, added_devices)
                        raise DeviceError(err)
                    break
            if isinstance(bus_returns[-1], list):   # we are done
                continue
            err = "ParentBus(%s): No free matching bus\n" % parent_bus
            clean(device, added_devices)
            raise DeviceInsertError(device, err, self)
        # 3
        for bus in device.child_bus:
            self.__buses.insert(0, bus)
        # 4
        if device.get_qid() and self.get_by_qid(device.get_qid()):
            err = "Devices qid %s already used in VM\n" % device.get_qid()
            clean(device, added_devices)
            raise DeviceInsertError(device, err, self)
        device.set_aid(self.__create_unique_aid(device.get_qid()))
        self.__devices.append(device)
        added_devices.append(device)
        return added_devices

    def simple_hotplug(self, device, monitor):
        """
        Function hotplug device to devices representation. If verification is
        supported by hodplugged device and result of verification is True
        then it calls set_clean. Otherwise it don't call set_clean because
        devices representatio don't know if device is added correctly.

        :param device: Device which should be unplugged.
        :type device: string, qdevices.QDevice.
        :param monitor: Monitor from vm.
        :type monitor: qemu_monitor.Monitor
        :return: tuple(monitor.cmd(), verify_hotplug output)
        """
        self.set_dirty()

        out = device.hotplug(monitor)
        ver_out = device.verify_hotplug(out, monitor)

        if ver_out is False:
            self.set_clean()
            return out, ver_out

        qdev_out = None
        try:
            qdev_out = self.insert(device)
            if not isinstance(qdev_out, list) or len(qdev_out) != 1:
                raise NotImplementedError("This device %s require to hotplug "
                                          "multiple devices %s, which is not "
                                          "supported." % (device, out))
            if ver_out is True:
                self.set_clean()
        except DeviceError, exc:
            self.set_clean()  # qdev remains consistent
            raise DeviceHotplugError(device, 'According to qemu_device: %s'
                                     % exc, self)
        out = device.hotplug(monitor)

        return out, ver_out

    def simple_unplug(self, device, monitor):
        """
        Function unplug device to devices representation. If verification is
        supported by unplugged device and result of verification is True
        then it calls set_clean. Otherwise it don't call set_clean because
        devices representatio don't know if device is added correctly.

        :param device: Device which should be unplugged.
        :type device: string, qdevices.QDevice.
        :param monitor: Monitor from vm.
        :type monitor: qemu_monitor.Monitor
        :return: tuple(monitor.cmd(), verify_unplug output)
        """
        device = self[device]
        self.set_dirty()
        # Remove all devices, which are removed together with this dev
        out = device.unplug(monitor)

        ver_out = device.verify_unplug(out, monitor)

        if ver_out is False:
            self.set_clean()
            return out, ver_out

        try:
            device.unplug_hook()
            self.remove(device, True)
            if ver_out is True:
                self.set_clean()
            elif out is False:
                raise DeviceUnplugError(device, "Device wasn't unplugged in "
                                        "qemu, but it was unplugged in device "
                                        "representation.", self)
        except (DeviceError, KeyError), exc:
            device.unplug_unhook()
            raise DeviceUnplugError(device, exc, self)

        return out, ver_out

    def hotplug_verified(self):
        """
        This function should be used after you verify, that hotplug was
        successful. For each hotplug call, hotplug_verified have to be
        executed in order to mark VM as clear.

        :warning: If you can't verify, that hotplug was successful, don't
                  use this function! You could screw-up following tests.
        """
        self.set_clean()

    def list_missing_named_buses(self, bus_pattern, bus_type, bus_count):
        """
        :param bus_pattern: Bus name pattern with 1x%s for idx or %s is
                            appended in the end. ('mybuses' or 'my%sbus').
        :param bus_type: Type of the bus.
        :param bus_count: Desired number of buses.
        :return: List of buses, which are missing in range(bus_count)
        """
        if "%s" not in bus_pattern:
            bus_pattern = bus_pattern + "%s"
        missing_buses = [bus_pattern % i for i in xrange(bus_count)]
        for bus in self.__buses:
            if bus.type == bus_type and re.match(bus_pattern % '\d+',
                                                 bus.busid):
                if bus.busid in missing_buses:
                    missing_buses.remove(bus.busid)
        return missing_buses

    def idx_of_next_named_bus(self, bus_pattern):
        """
        :param bus_pattern: Bus name prefix without %s and tailing digit
        :return: Name of the next bus (integer is appended and incremented
                 until there is no existing bus).
        """
        if "%s" not in bus_pattern:
            bus_pattern = bus_pattern + "%s"
        buses = []
        for bus in self.__buses:
            if bus.busid and re.match(bus_pattern % '\d+', bus.busid):
                buses.append(bus.busid)
        i = 0
        while True:
            if bus_pattern % i not in buses:
                return i
            i += 1

    def cmdline(self, dynamic=True):
        """
        Creates cmdline arguments for creating all defined devices
        :return: cmdline of all devices (without qemu-cmd itself)
        """
        out = ""
        for device in self.__devices:
            if dynamic:
                _out = device.cmdline()
            else:
                _out = device.cmdline_nd()
            if _out:
                out += " %s" % _out
        if out:
            return out[1:]

    def hook_fill_scsi_hbas(self, params):
        """
        This hook creates dummy scsi hba per 7 -drive 'scsi' devices.
        """
        i = 6   # We are going to divide it by 7 so 6 will result in 0
        for image_name in params.objects("images"):
            _is_oldscsi = (params.object_params(image_name).get('drive_format')
                           == 'scsi')
            _scsi_without_device = (not self.has_option('device') and
                                    params.object_params(image_name)
                                    .get('drive_format', 'virtio_blk')
                                    .startswith('scsi'))
            if _is_oldscsi or _scsi_without_device:
                i += 1

        for image_name in params.objects("cdroms"):
            _is_oldscsi = (params.object_params(image_name).get('cd_format')
                           == 'scsi')
            _scsi_without_device = (not self.has_option('device') and
                                    params.object_params(image_name)
                                    .get('cd_format', 'virtio_blk')
                                    .startswith('scsi'))
            if _is_oldscsi or _scsi_without_device:
                i += 1

        for i in xrange(i / 7):     # Autocreated lsi hba
            if arch.ARCH == 'ppc64':
                _name = 'spapr-vscsi%s' % i
                bus = qbuses.QSCSIBus("scsi.0", 'SCSI', [8, 16384],
                                      atype='spapr-vscsi')
                self.insert(qdevices.QStringDevice(_name,
                                                   parent_bus={'aobject':
                                                               params.get('pci_bus',
                                                                          'pci.0')},
                                                   child_bus=bus))
            else:
                _name = 'lsi53c895a%s' % i
                bus = qbuses.QSCSIBus("scsi.0", 'SCSI', [8, 16384], atype='lsi53c895a')
                self.insert(qdevices.QStringDevice(_name,
                                                   parent_bus={'aobject':
                                                               params.get('pci_bus',
                                                                          'pci.0')},
                                                   child_bus=bus))

    # Machine related methods
    def machine_by_params(self, params=None):
        """
        Choose the used machine and set the default devices accordingly
        :param params: VM params
        :return: List of added devices (including default buses)
        """
        def machine_q35(cmd=False):
            """
            Q35 + ICH9
            :param cmd: If set uses "-M $cmd" to force this machine type
            :return: List of added devices (including default buses)
            """
            logging.warn('Using Q35 machine which is not yet fullytested on '
                         'virt-test. False errors might occur.')
            devices = []
            bus = (qbuses.QPCIBus('pcie.0', 'PCIE', 'pci.0'),
                   qbuses.QStrictCustomBus(None, [['chassis'], [256]], '_PCI_CHASSIS',
                                           first_port=[1]),
                   qbuses.QStrictCustomBus(None, [['chassis_nr'], [256]],
                                           '_PCI_CHASSIS_NR', first_port=[1]))
            devices.append(qdevices.QStringDevice('machine', cmdline=cmd,
                                                  child_bus=bus,
                                                  aobject="pci.0"))
            devices.append(qdevices.QStringDevice('mch', {'addr': 0, 'driver': 'mch'},
                                                  parent_bus={'aobject': 'pci.0'}))
            devices.append(qdevices.QStringDevice('ICH9 LPC', {'addr': '1f.0',
                                                               'driver': 'ICH9 LPC'},
                                                  parent_bus={'aobject': 'pci.0'}))
            devices.append(qdevices.QStringDevice('ICH9 SMB', {'addr': '1f.3',
                                                               'driver': 'ICH9 SMB'},
                                                  parent_bus={'aobject': 'pci.0'}))
            devices.append(qdevices.QStringDevice('ICH9-ahci', {'addr': '1f.2',
                                                                'driver': 'ich9-ahci'},
                                                  parent_bus={'aobject': 'pci.0'},
                                                  child_bus=qbuses.QAHCIBus('ide')))
            if self.has_option('device') and self.has_option("global"):
                devices.append(qdevices.QStringDevice('fdc',
                                                      child_bus=qbuses.QFloppyBus('floppy')))
            else:
                devices.append(qdevices.QStringDevice('fdc',
                                                      child_bus=qbuses.QOldFloppyBus('floppy'))
                               )
            return devices

        def machine_i440FX(cmd=False):
            """
            i440FX + PIIX
            :param cmd: If set uses "-M $cmd" to force this machine type
            :return: List of added devices (including default buses)
            """
            devices = []
            if arch.ARCH == 'ppc64':
                pci_bus = "pci"
            else:
                pci_bus = "pci.0"
            bus = (qbuses.QPCIBus(pci_bus, 'PCI', 'pci.0'),
                   qbuses.QStrictCustomBus(None, [['chassis'], [256]], '_PCI_CHASSIS',
                                           first_port=[1]),
                   qbuses.QStrictCustomBus(None, [['chassis_nr'], [256]],
                                           '_PCI_CHASSIS_NR', first_port=[1]))
            devices.append(qdevices.QStringDevice('machine', cmdline=cmd,
                                                  child_bus=bus,
                                                  aobject="pci.0"))
            devices.append(qdevices.QStringDevice('i440FX',
                                                  {'addr': 0, 'driver': 'i440FX'},
                                                  parent_bus={'aobject': 'pci.0'}))
            devices.append(qdevices.QStringDevice('PIIX4_PM', {'addr': '01.3',
                                                               'driver': 'PIIX4_PM'},
                                                  parent_bus={'aobject': 'pci.0'}))
            devices.append(qdevices.QStringDevice('PIIX3',
                                                  {'addr': 1, 'driver': 'PIIX3'},
                                                  parent_bus={'aobject': 'pci.0'}))
            devices.append(qdevices.QStringDevice('piix3-ide', {'addr': '01.1',
                                                                'driver': 'piix3-ide'},
                                                  parent_bus={'aobject': 'pci.0'},
                                                  child_bus=qbuses.QIDEBus('ide')))
            if self.has_option('device') and self.has_option("global"):
                devices.append(qdevices.QStringDevice('fdc',
                                                      child_bus=qbuses.QFloppyBus('floppy')))
            else:
                devices.append(qdevices.QStringDevice('fdc',
                                                      child_bus=qbuses.QOldFloppyBus('floppy'))
                               )
            return devices

        def machine_other(cmd=False):
            """
            isapc or unknown machine type. This type doesn't add any default
            buses or devices, only sets the cmdline.
            :param cmd: If set uses "-M $cmd" to force this machine type
            :return: List of added devices (including default buses)
            """
            logging.warn('Machine type isa/unknown is not supported by '
                         'virt-test. False errors might occur')
            devices = []
            devices.append(qdevices.QStringDevice('machine', cmdline=cmd))
            return devices

        machine_type = params.get('machine_type')
        if machine_type:
            m_types = []
            for _ in self.__machine_types.splitlines()[1:]:
                m_types.append(_.split()[0])

            if machine_type in m_types:
                if (self.has_option('M') or self.has_option('machine')):
                    cmd = "-M %s" % machine_type
                else:
                    cmd = ""
                if 'q35' in machine_type:   # Q35 + ICH9
                    devices = machine_q35(cmd)
                elif 'isapc' not in machine_type:   # i440FX
                    devices = machine_i440FX(cmd)
                else:   # isapc (or other)
                    devices = machine_other(cmd)
            elif params.get("invalid_machine_type", "no") == "yes":
                # For negative testing pretend the unsupported machine is
                # similar to i440fx one (1 PCI bus, ..)
                devices = machine_i440FX("-M %s" % machine_type)
            else:
                raise error.TestNAError("Unsupported machine type %s." %
                                        (machine_type))
        else:
            devices = None
            for _ in self.__machine_types.splitlines()[1:]:
                if 'default' in _:
                    if 'q35' in machine_type:   # Q35 + ICH9
                        devices = machine_q35(False)
                    elif 'isapc' not in machine_type:   # i440FX
                        devices = machine_i440FX(False)
                    else:   # isapc (or other)
                        logging.warn('Machine isa/unknown is not supported by '
                                     'virt-test. False errors might occur')
                        devices = machine_other(False)
            if not devices:
                logging.warn('Unable to find the default machine type, using '
                             'i440FX')
                devices = machine_i440FX(False)

        # reserve pci.0 addresses
        pci_params = params.object_params('pci.0')
        reserved = pci_params.get('reserved_slots', '').split()
        if reserved:
            for bus in self.__buses:
                if bus.aobject == "pci.0":
                    for addr in reserved:
                        bus.reserve(hex(int(addr)))
                    break
        return devices

    # USB Controller related methods
    def usbc_by_variables(self, usb_id, usb_type, multifunction=False,
                          masterbus=None, firstport=None, freq=None,
                          max_ports=6, pci_addr=None, pci_bus='pci.0'):
        """
        Creates usb-controller devices by variables
        :param usb_id: Usb bus name
        :param usb_type: Usb bus type
        :param multifunction: Is the bus multifunction
        :param masterbus: Is this bus master?
        :param firstport: Offset of the first port
        :param freq: Bus frequency
        :param max_ports: How many ports this bus have [6]
        :param pci_addr: Desired PCI address
        :return: List of QDev devices
        """
        if not self.has_option("device"):
            # Okay, for the archaic qemu which has not device parameter,
            # just return a usb uhci controller.
            # If choose this kind of usb controller, it has no name/id,
            # and only can be created once, so give it a special name.
            usb = qdevices.QStringDevice("oldusb", cmdline="-usb",
                                         child_bus=qbuses.QUSBBus(2, 'usb.0', 'uhci', usb_id))
            return [usb]

        if not self.has_device(usb_type):
            raise error.TestNAError("usb controller %s not available"
                                    % usb_type)

        usb = qdevices.QDevice(usb_type, {}, usb_id, {'aobject': pci_bus},
                               qbuses.QUSBBus(max_ports, '%s.0' % usb_id, usb_type, usb_id))
        new_usbs = [usb]    # each usb dev might compound of multiple devs
        # TODO: Add 'bus' property (it was not in the original version)
        usb.set_param('id', usb_id)
        usb.set_param('masterbus', masterbus)
        usb.set_param('multifunction', multifunction)
        usb.set_param('firstport', firstport)
        usb.set_param('freq', freq)
        usb.set_param('addr', pci_addr)

        if usb_type == "ich9-usb-ehci1":
            usb.set_param('addr', '1d.7')
            usb.set_param('multifunction', 'on')
            for i in xrange(3):
                new_usbs.append(qdevices.QDevice('ich9-usb-uhci%d' % (i + 1), {},
                                                 usb_id))
                new_usbs[-1].parent_bus = {'aobject': pci_bus}
                new_usbs[-1].set_param('id', '%s.%d' % (usb_id, i))
                new_usbs[-1].set_param('multifunction', 'on')
                new_usbs[-1].set_param('masterbus', '%s.0' % usb_id)
                # current qdevices doesn't support x.y addr. Plug only
                # the 0th one into this representation.
                new_usbs[-1].set_param('addr', '1d.%d' % (2 * i))
                new_usbs[-1].set_param('firstport', 2 * i)
        return new_usbs

    def usbc_by_params(self, usb_name, params):
        """
        Wrapper for creating usb bus from autotest usb params.
        :param usb_name: Name of the usb bus
        :param params: USB params (params.object_params(usb_name))
        :return: List of QDev devices
        """
        return self.usbc_by_variables(usb_name,
                                      params.get('usb_type'),
                                      params.get('multifunction'),
                                      params.get('masterbus'),
                                      params.get('firstport'),
                                      params.get('freq'),
                                      params.get('max_ports', 6),
                                      params.get('pci_addr'),
                                      params.get('pci_bus', 'pci.0'))

    # USB Device related methods
    def usb_by_variables(self, usb_name, usb_type, controller_type, bus=None,
                         port=None):
        """
        Creates usb-devices by variables.
        :param usb_name: usb name
        :param usb_type: usb type (usb-tablet, usb-serial, ...)
        :param controller_type: type of the controller (uhci, ehci, xhci, ...)
        :param bus: the bus name (my_bus.0, ...)
        :param port: port specifiacation (4, 4.1.2, ...)
        :return: QDev device
        """
        if not self.has_device(usb_type):
            raise error.TestNAError("usb device %s not available"
                                    % usb_type)
        if self.has_option('device'):
            device = qdevices.QDevice(usb_type, aobject=usb_name)
            device.set_param('id', 'usb-%s' % usb_name)
            device.set_param('bus', bus)
            device.set_param('port', port)
            device.parent_bus += ({'type': controller_type},)
        else:
            if "tablet" in usb_type:
                device = qdevices.QStringDevice('usb-%s' % usb_name,
                                                cmdline='-usbdevice %s' % usb_name)
            else:
                device = qdevices.QStringDevice('missing-usb-%s' % usb_name)
                logging.error("This qemu supports only tablet device; ignoring"
                              " %s", usb_name)
        return device

    def usb_by_params(self, usb_name, params):
        """
        Wrapper for creating usb devices from autotest params.
        :param usb_name: Name of the usb
        :param params: USB device's params
        :return: QDev device
        """
        return self.usb_by_variables(usb_name,
                                     params.get("usb_type"),
                                     params.get("usb_controller"),
                                     params.get("bus"),
                                     params.get("port"))

    # Images (disk, cdrom, floppy) device related methods
    def images_define_by_variables(self, name, filename, index=None, fmt=None,
                                   cache=None, werror=None, rerror=None, serial=None,
                                   snapshot=None, boot=None, blkdebug=None, bus=None,
                                   unit=None, port=None, bootindex=None, removable=None,
                                   min_io_size=None, opt_io_size=None,
                                   physical_block_size=None, logical_block_size=None,
                                   readonly=None, scsiid=None, lun=None, aio=None,
                                   strict_mode=None, media=None, imgfmt=None,
                                   pci_addr=None, scsi_hba=None, x_data_plane=None,
                                   blk_extra_params=None, scsi=None,
                                   pci_bus='pci.0', drv_extra_params=None):
        """
        Creates related devices by variables
        :note: To skip the argument use None, to disable it use False
        :note: Strictly bool options accept "yes", "on" and True ("no"...)
        :param name: Autotest name of this disk
        :param filename: Path to the disk file
        :param index: drive index (used for generating names)
        :param fmt: drive subsystem type (ide, scsi, virtio, usb2, ...)
        :param cache: disk cache (none, writethrough, writeback)
        :param werror: What to do when write error occurs (stop, ...)
        :param rerror: What to do when read error occurs (stop, ...)
        :param serial: drive serial number ($string)
        :param snapshot: use snapshot? ($bool)
        :param boot: is bootable? ($bool)
        :param blkdebug: use blkdebug (None, blkdebug_filename)
        :param bus: 1st level of disk location (index of bus) ($int)
        :param unit: 2nd level of disk location (unit/scsiid/...) ($int)
        :param port: 3rd level of disk location (port/lun/...) ($int)
        :param bootindex: device boot priority ($int)
        :param removable: can the drive be removed? ($bool)
        :param min_io_size: Min allowed io size
        :param opt_io_size: Optimal io size
        :param physical_block_size: set physical_block_size ($int)
        :param logical_block_size: set logical_block_size ($int)
        :param readonly: set the drive readonly ($bool)
        :param scsiid: Deprecated 2nd level of disk location (&unit)
        :param lun: Deprecated 3rd level of disk location (&port)
        :param aio: set the type of async IO (native, threads, ..)
        :param strict_mode: enforce optional parameters (address, ...) ($bool)
        :param media: type of the media (disk, cdrom, ...)
        :param imgfmt: image format (qcow2, raw, ...)
        :param pci_addr: drive pci address ($int)
        :param scsi_hba: Custom scsi HBA
        """
        def define_hbas(qtype, atype, bus, unit, port, qbus, addr_spec=None,
                        pci_bus='pci.0'):
            """
            Helper for creating HBAs of certain type.
            """
            devices = []
            if qbus == qbuses.QAHCIBus:    # AHCI uses multiple ports, id is different
                _hba = 'ahci%s'
            else:
                _hba = atype.replace('-', '_') + '%s.0'  # HBA id
            _bus = bus
            if bus is None:
                bus = self.get_first_free_bus({'type': qtype, 'atype': atype},
                                              [unit, port])
                if bus is None:
                    bus = self.idx_of_next_named_bus(_hba)
                else:
                    bus = bus.busid
            if isinstance(bus, int):
                for bus_name in self.list_missing_named_buses(
                        _hba, qtype, bus + 1):
                    _bus_name = bus_name.rsplit('.')[0]
                    if addr_spec:
                        dev = qdevices.QDevice(params={'id': _bus_name,
                                                       'driver': atype},
                                               parent_bus={'aobject': pci_bus},
                                               child_bus=qbus(busid=bus_name,
                                                              bus_type=qtype,
                                                              addr_spec=addr_spec,
                                                              atype=atype))
                    else:
                        dev = qdevices.QDevice(params={'id': _bus_name,
                                                       'driver': atype},
                                               parent_bus={'aobject': pci_bus},
                                               child_bus=qbus(busid=bus_name))
                    devices.append(dev)
                bus = _hba % bus
            if qbus == qbuses.QAHCIBus and unit is not None:
                bus += ".%d" % unit
            elif _bus is None:    # If bus was not set, don't set it
                bus = None
            return devices, bus, {'type': qtype, 'atype': atype}

        #
        # Parse params
        #
        devices = []    # All related devices

        use_device = self.has_option("device")
        if fmt == "scsi":   # fmt=scsi force the old version of devices
            logging.warn("'scsi' drive_format is deprecated, please use the "
                         "new lsi_scsi type for disk %s", name)
            use_device = False
        if not fmt:
            use_device = False
        if fmt == 'floppy' and not self.has_option("global"):
            use_device = False

        if strict_mode is None:
            strict_mode = self.strict_mode
        if strict_mode:     # Force default variables
            if cache is None:
                cache = "none"
            if removable is None:
                removable = "yes"
            if aio is None:
                aio = "native"
            if media is None:
                media = "disk"
        else:       # Skip default variables
            imgfmt = None
            if media != 'cdrom':    # ignore only 'disk'
                media = None

        if "[,boot=on|off]" not in self.get_help_text():
            if boot in ('yes', 'on', True):
                bootindex = "1"
            boot = None

        bus = none_or_int(bus)     # First level
        unit = none_or_int(unit)   # Second level
        port = none_or_int(port)   # Third level
        # Compatibility with old params - scsiid, lun
        if scsiid is not None:
            logging.warn("drive_scsiid param is obsolete, use drive_unit "
                         "instead (disk %s)", name)
            unit = none_or_int(scsiid)
        if lun is not None:
            logging.warn("drive_lun param is obsolete, use drive_port instead "
                         "(disk %s)", name)
            port = none_or_int(lun)
        if pci_addr is not None and fmt == 'virtio':
            logging.warn("drive_pci_addr is obsolete, use drive_bus instead "
                         "(disk %s)", name)
            bus = none_or_int(pci_addr)

        #
        # HBA
        # fmt: ide, scsi, virtio, scsi-hd, ahci, usb1,2,3 + hba
        # device: ide-drive, usb-storage, scsi-hd, scsi-cd, virtio-blk-pci
        # bus: ahci, virtio-scsi-pci, USB
        #
        if not use_device:
            if fmt and (fmt == "scsi" or (fmt.startswith('scsi') and
                                          (scsi_hba == 'lsi53c895a' or
                                           scsi_hba == 'spapr-vscsi'))):
                if not (bus is None and unit is None and port is None):
                    logging.warn("Using scsi interface without -device "
                                 "support; ignoring bus/unit/port. (%s)", name)
                    bus, unit, port = None, None, None
                # In case we hotplug, lsi wasn't added during the startup hook
                if arch.ARCH == 'ppc64':
                    _ = define_hbas('SCSI', 'spapr-vscsi', None, None, None,
                                    qbuses.QSCSIBus, [8, 16384])
                else:
                    _ = define_hbas('SCSI', 'lsi53c895a', None, None, None,
                                    qbuses.QSCSIBus, [8, 16384])
                devices.extend(_[0])
        elif fmt == "ide":
            if bus:
                logging.warn('ide supports only 1 hba, use drive_unit to set'
                             'ide.* for disk %s', name)
            bus = unit
            dev_parent = {'type': 'IDE', 'atype': 'ide'}
        elif fmt == "ahci":
            devs, bus, dev_parent = define_hbas('IDE', 'ahci', bus, unit, port,
                                                qbuses.QAHCIBus)
            devices.extend(devs)
        elif fmt.startswith('scsi-'):
            if not scsi_hba:
                scsi_hba = "virtio-scsi-pci"
            addr_spec = None
            if scsi_hba == 'lsi53c895a' or scsi_hba == 'spapr-vscsi':
                addr_spec = [8, 16384]
            elif scsi_hba == 'virtio-scsi-pci':
                addr_spec = [256, 16384]
            _, bus, dev_parent = define_hbas('SCSI', scsi_hba, bus, unit, port,
                                             qbuses.QSCSIBus, addr_spec)
            devices.extend(_)
        elif fmt in ('usb1', 'usb2', 'usb3'):
            if bus:
                logging.warn('Manual setting of drive_bus is not yet supported'
                             ' for usb disk %s', name)
                bus = None
            if fmt == 'usb1':
                dev_parent = {'type': 'uhci'}
            elif fmt == 'usb2':
                dev_parent = {'type': 'ehci'}
            elif fmt == 'usb3':
                dev_parent = {'type': 'xhci'}
        elif fmt == 'virtio':
            dev_parent = {'aobject': pci_bus}
        else:
            dev_parent = {'type': fmt}

        #
        # Drive
        # -drive fmt or -drive fmt=none -device ...
        #
        if self.has_hmp_cmd('__com.redhat_drive_add') and use_device:
            devices.append(qdevices.QRHDrive(name))
        elif self.has_hmp_cmd('drive_add') and use_device:
            devices.append(qdevices.QHPDrive(name))
        elif self.has_option("device"):
            devices.append(qdevices.QDrive(name, use_device))
        else:       # very old qemu without 'addr' support
            devices.append(qdevices.QOldDrive(name, use_device))
        devices[-1].set_param('if', 'none')
        devices[-1].set_param('cache', cache)
        devices[-1].set_param('rerror', rerror)
        devices[-1].set_param('werror', werror)
        devices[-1].set_param('serial', serial)
        devices[-1].set_param('boot', boot, bool)
        devices[-1].set_param('snapshot', snapshot, bool)
        devices[-1].set_param('readonly', readonly, bool)
        if 'aio' in self.get_help_text():
            devices[-1].set_param('aio', aio)
        devices[-1].set_param('media', media)
        devices[-1].set_param('format', imgfmt)
        if blkdebug is not None:
            devices[-1].set_param('file', 'blkdebug:%s:%s' % (blkdebug,
                                                              filename))
        else:
            devices[-1].set_param('file', filename)
        if drv_extra_params:
            drv_extra_params = (_.split('=', 1) for _ in
                                drv_extra_params.split(',') if _)
            for key, value in drv_extra_params:
                devices[-1].set_param(key, value)
        if not use_device:
            if fmt and fmt.startswith('scsi-'):
                if scsi_hba == 'lsi53c895a' or scsi_hba == 'spapr-vscsi':
                    fmt = 'scsi'  # Compatibility with the new scsi
            if fmt and fmt not in ('ide', 'scsi', 'sd', 'mtd', 'floppy',
                                   'pflash', 'virtio'):
                raise virt_vm.VMDeviceNotSupportedError(self.vmname,
                                                        fmt)
            devices[-1].set_param('if', fmt)    # overwrite previously set None
            if not fmt:     # When fmt unspecified qemu uses ide
                fmt = 'ide'
            devices[-1].set_param('index', index)
            if fmt == 'ide':
                devices[-1].parent_bus = ({'type': fmt.upper(), 'atype': fmt},)
            elif fmt == 'scsi':
                if arch.ARCH == 'ppc64':
                    devices[-1].parent_bus = ({'atype': 'spapr-vscsi',
                                               'type': 'SCSI'},)
                else:
                    devices[-1].parent_bus = ({'atype': 'lsi53c895a',
                                               'type': 'SCSI'},)
            elif fmt == 'floppy':
                devices[-1].parent_bus = ({'type': fmt},)
            elif fmt == 'virtio':
                devices[-1].set_param('addr', pci_addr)
                devices[-1].parent_bus = ({'aobject': pci_bus},)
            if not media == 'cdrom':
                logging.warn("Using -drive fmt=xxx for %s is unsupported "
                             "method, false errors might occur.", name)
            return devices

        #
        # Device
        #
        devices.append(qdevices.QDevice(params={}, aobject=name))
        devices[-1].parent_bus += ({'busid': 'drive_%s' % name}, dev_parent)
        if fmt in ("ide", "ahci"):
            if not self.has_device('ide-hd'):
                devices[-1].set_param('driver', 'ide-drive')
            elif media == 'cdrom':
                devices[-1].set_param('driver', 'ide-cd')
            else:
                devices[-1].set_param('driver', 'ide-hd')
            devices[-1].set_param('unit', port)
        elif fmt and fmt.startswith('scsi-'):
            devices[-1].set_param('driver', fmt)
            devices[-1].set_param('scsi-id', unit)
            devices[-1].set_param('lun', port)
            devices[-1].set_param('removable', removable, bool)
            if strict_mode:
                devices[-1].set_param('channel', 0)
        elif fmt == 'virtio':
            devices[-1].set_param('driver', 'virtio-blk-pci')
            devices[-1].set_param("scsi", scsi, bool)
            if bus is not None:
                devices[-1].set_param('addr', hex(bus))
                bus = None
        elif fmt in ('usb1', 'usb2', 'usb3'):
            devices[-1].set_param('driver', 'usb-storage')
            devices[-1].set_param('port', unit)
            devices[-1].set_param('removable', removable, bool)
        elif fmt == 'floppy':
            # Overwrite qdevices.QDevice with qdevices.QFloppy
            devices[-1] = qdevices.QFloppy(unit, 'drive_%s' % name, name,
                                           ({'busid': 'drive_%s' % name}, {'type': fmt}))
        else:
            logging.warn('Using default device handling (disk %s)', name)
            devices[-1].set_param('driver', fmt)
        # Get the supported options
        options = self.execute_qemu("-device %s,?" % devices[-1]['driver'])
        devices[-1].set_param('id', name)
        devices[-1].set_param('bus', bus)
        devices[-1].set_param('drive', 'drive_%s' % name)
        devices[-1].set_param('logical_block_size', logical_block_size)
        devices[-1].set_param('physical_block_size', physical_block_size)
        devices[-1].set_param('min_io_size', min_io_size)
        devices[-1].set_param('opt_io_size', opt_io_size)
        devices[-1].set_param('bootindex', bootindex)
        devices[-1].set_param('x-data-plane', x_data_plane, bool)
        if 'serial' in options:
            devices[-1].set_param('serial', serial)
            devices[-2].set_param('serial', None)   # remove serial from drive
        if blk_extra_params:
            blk_extra_params = (_.split('=', 1) for _ in
                                blk_extra_params.split(',') if _)
            for key, value in blk_extra_params:
                devices[-1].set_param(key, value)

        return devices

    def images_define_by_params(self, name, image_params, media=None,
                                index=None, image_boot=None,
                                image_bootindex=None):
        """
        Wrapper for creating disks and related hbas from autotest image params.

        :note: To skip the argument use None, to disable it use False
        :note: Strictly bool options accept "yes", "on" and True ("no"...)
        :note: Options starting with '_' are optional and used only when
               strict_mode is True
        :param name: Name of the new disk
        :param params: Disk params (params.object_params(name))
        """
        shared_dir = os.path.join(data_dir.get_data_dir(), "shared")
        return self.images_define_by_variables(name,
                                               storage.get_image_filename(
                                                   image_params,
                                                   data_dir.get_data_dir()),
                                               index,
                                               image_params.get(
                                                   "drive_format"),
                                               image_params.get("drive_cache"),
                                               image_params.get(
                                                   "drive_werror"),
                                               image_params.get(
                                                   "drive_rerror"),
                                               image_params.get(
                                                   "drive_serial"),
                                               image_params.get(
                                                   "image_snapshot"),
                                               image_boot,
                                               storage.get_image_blkdebug_filename(
                                                   image_params,
                                                   shared_dir),
                                               image_params.get("drive_bus"),
                                               image_params.get("drive_unit"),
                                               image_params.get("drive_port"),
                                               image_bootindex,
                                               image_params.get("removable"),
                                               image_params.get("min_io_size"),
                                               image_params.get("opt_io_size"),
                                               image_params.get(
                                                   "physical_block_size"),
                                               image_params.get(
                                                   "logical_block_size"),
                                               image_params.get(
                                                   "image_readonly"),
                                               image_params.get(
                                                   "drive_scsiid"),
                                               image_params.get("drive_lun"),
                                               image_params.get("image_aio"),
                                               image_params.get(
                                                   "strict_mode") == "yes",
                                               media,
                                               image_params.get(
                                                   "image_format"),
                                               image_params.get(
                                                   "drive_pci_addr"),
                                               image_params.get("scsi_hba"),
                                               image_params.get(
                                                   "x-data-plane"),
                                               image_params.get(
                                                   "blk_extra_params"),
                                               image_params.get("virtio-blk-pci_scsi"),
                                               image_params.get('pci_bus', 'pci.0'),
                                               image_params.get("drv_extra_params"))

    def cdroms_define_by_params(self, name, image_params, media=None,
                                index=None, image_boot=None,
                                image_bootindex=None):
        """
        Wrapper for creating cdrom and related hbas from autotest image params.

        :note: To skip the argument use None, to disable it use False
        :note: Strictly bool options accept "yes", "on" and True ("no"...)
        :note: Options starting with '_' are optional and used only when
               strict_mode is True
        :param name: Name of the new disk
        :param params: Disk params (params.object_params(name))
        """
        iso = image_params.get('cdrom')
        image_params['image_name'] = ""
        if iso:
            image_params['image_name'] = os.path.join(data_dir.get_data_dir(),
                                                      image_params.get('cdrom')
                                                      )
        image_params['image_raw_device'] = 'yes'
        cd_format = image_params.get('cd_format')
        if cd_format is None or cd_format is 'ide':
            if not self.get_buses({'atype': 'ide'}):
                logging.warn("cd_format IDE not available, using AHCI "
                             "instead.")
                cd_format = 'ahci'
        shared_dir = os.path.join(data_dir.get_data_dir(), "shared")
        return self.images_define_by_variables(name,
                                               storage.get_image_filename(
                                                   image_params,
                                                   data_dir.get_data_dir()),
                                               index,
                                               cd_format,
                                               '',     # skip drive_cache
                                               image_params.get(
                                                   "drive_werror"),
                                               image_params.get(
                                                   "drive_rerror"),
                                               image_params.get(
                                                   "drive_serial"),
                                               image_params.get(
                                                   "image_snapshot"),
                                               image_boot,
                                               storage.get_image_blkdebug_filename(
                                                   image_params,
                                                   shared_dir),
                                               image_params.get("drive_bus"),
                                               image_params.get("drive_unit"),
                                               image_params.get("drive_port"),
                                               image_bootindex,
                                               image_params.get("removable"),
                                               image_params.get("min_io_size"),
                                               image_params.get("opt_io_size"),
                                               image_params.get(
                                                   "physical_block_size"),
                                               image_params.get(
                                                   "logical_block_size"),
                                               image_params.get(
                                                   "image_readonly"),
                                               image_params.get(
                                                   "drive_scsiid"),
                                               image_params.get("drive_lun"),
                                               image_params.get("image_aio"),
                                               image_params.get(
                                                   "strict_mode") == "yes",
                                               media,
                                               None,     # skip img_fmt
                                               image_params.get(
                                                   "drive_pci_addr"),
                                               image_params.get("scsi_hba"),
                                               image_params.get(
                                                   "x-data-plane"),
                                               image_params.get(
                                                   "blk_extra_params"),
                                               image_params.get("virtio-blk-pci_scsi"),
                                               image_params.get('pci_bus', 'pci.0'),
                                               image_params.get("drv_extra_params"))

    def pcic_by_params(self, name, params):
        """
        Creates pci controller/switch/... based on params

        :param name: Autotest name
        :param params: PCI controller params
        :note: x3130 creates x3130-upstream bus + xio3130-downstream port for
               each inserted device.
        :warning: x3130-upstream device creates only x3130-upstream device
                  and you are responsible for creating the downstream ports.
        """
        driver = params.get('type', 'ioh3420')
        if driver in ('ioh3420', 'x3130-upstream', 'x3130'):
            bus_type = 'PCIE'
        else:
            bus_type = 'PCI'
        parent_bus = [{'aobject': params.get('pci_bus', 'pci.0')}]
        if driver == 'x3130':
            bus = qbuses.QPCISwitchBus(name, bus_type, 'xio3130-downstream', name)
            driver = 'x3130-upstream'
        else:
            if driver == 'pci-bridge':  # addr 1-19, chasis_nr
                parent_bus.append({'busid': '_PCI_CHASSIS_NR'})
                bus_length = 20
                bus_first_port = 1
            elif driver == 'i82801b11-bridge':  # addr 1-19
                bus_length = 20
                bus_first_port = 1
            else:   # addr = 0-31
                bus_length = 32
                bus_first_port = 0
            bus = qbuses.QPCIBus(name, bus_type, name, bus_length, bus_first_port)
        for addr in params.get('reserved_slots', '').split():
            bus.reserve(addr)
        return qdevices.QDevice(driver, {'id': name}, aobject=name,
                                parent_bus=parent_bus,
                                child_bus=bus)

########NEW FILE########
__FILENAME__ = qdevices
"""
Autotest representation of qemu devices.

These classes implements various features in order to simulate, verify or
interact with qemu qdev structure.

:copyright: 2012-2013 Red Hat Inc.
"""
# Python imports
import logging
import re

# Autotest imports
from utils import DeviceError
from virttest import qemu_monitor
from virttest import utils_misc
import qbuses
import traceback

try:
    # pylint: disable=E0611
    from collections import OrderedDict
except ImportError:
    from virttest.staging.backports.collections import OrderedDict


def _convert_args(arg_dict):
    """
    Convert monitor command arguments dict into humanmonitor string.

    :param arg_dict: The dict of monitor command arguments.
    :return: A string in humanmonitor's 'key=value' format, or a empty
             '' when the dict is empty.
    """
    return ",".join("%s=%s" % (key, val) for key, val in arg_dict.iteritems())


def _build_cmd(cmd, args=None, q_id=None):
    """
    Format QMP command from cmd and args

    :param cmd: Command ('device_add', ...)
    :param q_id: queue id; True = generate random, None = None, str = use str
    """
    obj = {"execute": cmd}
    if args is not None:
        obj["arguments"] = args
    if q_id is True:
        obj["id"] = utils_misc.generate_random_string(8)
    elif q_id is not None:
        obj["id"] = q_id
    return obj


#
# Device objects
#
class QBaseDevice(object):

    """ Base class of qemu objects """

    def __init__(self, dev_type="QBaseDevice", params=None, aobject=None,
                 parent_bus=None, child_bus=None):
        """
        :param dev_type: type of this component
        :param params: component's parameters
        :param aobject: Autotest object which is associated with this device
        :param parent_bus: list of dicts specifying the parent bus
        :param child_bus: list of buses, which this device provides
        """
        self.aid = None         # unique per VM id
        self.type = dev_type    # device type
        self.aobject = aobject  # related autotest object
        if parent_bus is None:
            parent_bus = tuple()
        self.parent_bus = parent_bus   # list of buses into which this dev fits
        self.child_bus = []            # list of buses which this dev provides
        if child_bus is None:
            child_bus = []
        elif not isinstance(child_bus, (list, tuple)):
            self.add_child_bus(child_bus)
        else:
            for bus in child_bus:
                self.add_child_bus(bus)
        self.dynamic_params = []
        self.params = OrderedDict()    # various device params (id, name, ...)
        if params:
            for key, value in params.iteritems():
                self.set_param(key, value)

    def add_child_bus(self, bus):
        """
        Add child bus
        :param bus: Bus, which this device contains
        :type bus: QSparseBus-like
        """
        self.child_bus.append(bus)
        bus.set_device(self)

    def rm_child_bus(self, bus):
        """
        removes child bus
        :param bus: Bus, which this device contains
        :type bus: QSparseBus-like
        """
        self.child_bus.remove(bus)
        bus.set_device(None)

    def set_param(self, option, value, option_type=None, dynamic=False):
        """
        Set device param using qemu notation ("on", "off" instead of bool...)
        :param option: which option's value to set
        :param value: new value
        :param option_type: type of the option (bool)
        :param dynamic: if true value is changed to DYN for not_dynamic compare
        """
        if dynamic:
            if option not in self.dynamic_params:
                self.dynamic_params.append(option)
        else:
            if option in self.dynamic_params:
                self.dynamic_params.remove(option)

        if option_type is bool or isinstance(value, bool):
            if value in ['yes', 'on', True]:
                self.params[option] = "on"
            elif value in ['no', 'off', False]:
                self.params[option] = "off"
        elif value or value == 0:
            if value == "EMPTY_STRING":
                self.params[option] = '""'
            else:
                self.params[option] = value
        elif value is None and option in self.params:
            del(self.params[option])
            if option in self.dynamic_params:
                self.dynamic_params.remove(option)

    def get_param(self, option, default=None):
        """ :return: object param """
        return self.params.get(option, default)

    def __getitem__(self, option):
        """ :return: object param """
        return self.params[option]

    def __delitem__(self, option):
        """ deletes self.params[option] """
        del(self.params[option])

    def __len__(self):
        """ length of self.params """
        return len(self.params)

    def __setitem__(self, option, value):
        """ self.set_param(option, value, None) """
        return self.set_param(option, value)

    def __contains__(self, option):
        """ Is the option set? """
        return option in self.params

    def __str__(self):
        """ :return: Short string representation of this object. """
        return self.str_short()

    def __eq__(self, dev2, dynamic=True):
        """ :return: True when devs are similar, False when different. """
        check_attrs = ['cmdline_nd', 'hotplug_hmp_nd', 'hotplug_qmp_nd']
        try:
            for check_attr in check_attrs:
                try:
                    _ = getattr(self, check_attr)()
                except (DeviceError, NotImplementedError, AttributeError):
                    try:
                        getattr(dev2, check_attr)()
                    except (DeviceError, NotImplementedError, AttributeError):
                        pass
                else:
                    if _ != getattr(dev2, check_attr)():
                        return False
        except Exception:
            logging.error(traceback.format_exc())
            return False
        return True

    def __ne__(self, dev2):
        """ :return: True when devs are different, False when similar. """
        return not self.__eq__(dev2)

    def str_short(self):
        """ Short representation (aid, qid, alternative, type) """
        if self.get_qid():  # Show aid only when it's based on qid
            if self.get_aid():
                return self.get_aid()
            else:
                return "q'%s'" % self.get_qid()
        elif self._get_alternative_name():
            return "a'%s'" % self._get_alternative_name()
        else:
            return "t'%s'" % self.type

    def str_long(self):
        """ Full representation, multi-line with all params """
        out = """%s
  aid = %s
  aobject = %s
  parent_bus = %s
  child_bus = %s
  params:""" % (self.type, self.aid, self.aobject, self.parent_bus,
                self.child_bus)
        for key, value in self.params.iteritems():
            out += "\n    %s = %s" % (key, value)
        return out + '\n'

    def _get_alternative_name(self):
        """ :return: alternative object name """
        return None

    def get_qid(self):
        """ :return: qemu_id """
        return self.params.get('id', '')

    def get_aid(self):
        """ :return: per VM unique autotest_id """
        return self.aid

    def set_aid(self, aid):
        """:param aid: new autotest id for this device"""
        self.aid = aid

    def get_children(self):
        """ :return: List of all children (recursive) """
        children = []
        for bus in self.child_bus:
            children.extend(bus)
        return children

    def cmdline(self):
        """ :return: cmdline command to define this device """
        raise NotImplementedError

    def cmdline_nd(self):
        """
        Command line without dynamic params.

        :return: cmdline command to define this device
                 without dynamic parameters
        """
        self.cmdline()

    # pylint: disable=E0202
    def hotplug(self, monitor):
        """ :return: the output of monitor.cmd() hotplug command """
        if isinstance(monitor, qemu_monitor.QMPMonitor):
            try:
                cmd, args = self.hotplug_qmp()
                return monitor.cmd(cmd, args)
            except DeviceError:     # qmp command not supported
                return monitor.human_monitor_cmd(self.hotplug_hmp())
        elif isinstance(monitor, qemu_monitor.HumanMonitor):
            return monitor.cmd(self.hotplug_hmp())
        else:
            raise TypeError("Invalid monitor object: %s(%s)" % (monitor,
                                                                type(monitor)))

    def hotplug_hmp(self):
        """ :return: the hotplug monitor command """
        raise DeviceError("Hotplug is not supported by this device %s", self)

    def hotplug_qmp(self):
        """ :return: tuple(hotplug qemu command, arguments)"""
        raise DeviceError("Hotplug is not supported by this device %s", self)

    def unplug_hook(self):
        """ Modification prior to unplug can be made here """
        pass

    def unplug_unhook(self):
        """ Roll back the modification made before unplug """
        pass

    def unplug(self, monitor):
        """ :return: the output of monitor.cmd() unplug command """
        if isinstance(monitor, qemu_monitor.QMPMonitor):
            try:
                cmd, args = self.unplug_qmp()
                return monitor.cmd(cmd, args)
            except DeviceError:     # qmp command not supported
                return monitor.human_monitor_cmd(self.unplug_hmp())
        elif isinstance(monitor, qemu_monitor.HumanMonitor):
            return monitor.cmd(self.unplug_hmp())
        else:
            raise TypeError("Invalid monitor object: %s(%s)" % (monitor,
                                                                type(monitor)))

    def unplug_hmp(self):
        """ :return: the unplug monitor command """
        raise DeviceError("Unplug is not supported by this device %s", self)

    def unplug_qmp(self):
        """ :return: tuple(unplug qemu command, arguments)"""
        raise DeviceError("Unplug is not supported by this device %s", self)

    def verify_hotplug(self, out, monitor):
        """
        :param out: Output of the hotplug command
        :param monitor: Monitor used for hotplug
        :return: True when successful, False when unsuccessful, string/None
                 when can't decide.
        """
        return out

    def verify_unplug(self, out, monitor):      # pylint: disable=W0613,R0201
        """
        :param out: Output of the unplug command
        :param monitor: Monitor used for unplug
        """
        return out


class QStringDevice(QBaseDevice):

    """
    General device which allows to specify methods by fixed or parametrizable
    strings in this format:

    ::

        "%(type)s,id=%(id)s,addr=%(addr)s"

    ``params`` will be used to subst ``%()s``
    """

    def __init__(self, dev_type="dummy", params=None, aobject=None,
                 parent_bus=None, child_bus=None, cmdline="", cmdline_nd=None):
        """
        :param dev_type: type of this component
        :param params: component's parameters
        :param aobject: Autotest object which is associated with this device
        :param parent_bus: bus(es), in which this device is plugged in
        :param child_bus: bus, which this device provides
        :param cmdline: cmdline string
        """
        super(QStringDevice, self).__init__(dev_type, params, aobject,
                                            parent_bus, child_bus)
        self._cmdline = cmdline
        self._cmdline_nd = cmdline_nd
        if cmdline_nd is None:
            self._cmdline_nd = cmdline

    def cmdline(self):
        """ :return: cmdline command to define this device """
        try:
            if self._cmdline:
                return self._cmdline % self.params
        except KeyError, details:
            raise KeyError("Param %s required for cmdline is not present in %s"
                           % (details, self.str_long()))

    def cmdline_nd(self):
        """
        Command line without dynamic parameters.

        :return: cmdline command to define this device without dynamic parameters.
        """
        try:
            if self._cmdline_nd:
                return self._cmdline_nd % self.params
        except KeyError, details:
            raise KeyError("Param %s required for cmdline is not present in %s"
                           % (details, self.str_long()))


class QCustomDevice(QBaseDevice):

    """
    Representation of the '-$option $param1=$value1,$param2...' qemu object.
    This representation handles only cmdline.
    """

    def __init__(self, dev_type, params=None, aobject=None,
                 parent_bus=None, child_bus=None, backend=None):
        """
        :param dev_type: The desired -$option parameter (device, chardev, ..)
        """
        super(QCustomDevice, self).__init__(dev_type, params, aobject,
                                            parent_bus, child_bus)
        if backend:
            self.__backend = backend
        else:
            self.__backend = None

    def cmdline(self):
        """ :return: cmdline command to define this device """
        if self.__backend and self.params.get(self.__backend):
            out = "-%s %s," % (self.type, self.params.get(self.__backend))
            params = self.params.copy()
            del params[self.__backend]
        else:
            out = "-%s " % self.type
            params = self.params
        for key, value in params.iteritems():
            if value != "NO_EQUAL_STRING":
                out += "%s=%s," % (key, value)
            else:
                out += "%s," % key
        if out[-1] == ',':
            out = out[:-1]
        return out

    def cmdline_nd(self):
        """
        Command line without dynamic parameters.

        :return: cmdline command to define this device without dynamic parameters.
        """
        if self.__backend and self.params.get(self.__backend):
            out = "-%s %s," % (self.type, self.params.get(self.__backend))
            params = self.params.copy()
            del params[self.__backend]
        else:
            out = "-%s " % self.type
            params = self.params
        for key, value in params.iteritems():
            if value != "NO_EQUAL_STRING":
                if key in self.dynamic_params:
                    out += "%s=DYN," % (key,)
                else:
                    out += "%s=%s," % (key, value)
            else:
                out += "%s," % key
        if out[-1] == ',':
            out = out[:-1]
        return out


class QDrive(QCustomDevice):

    """
    Representation of the '-drive' qemu object without hotplug support.
    """

    def __init__(self, aobject, use_device=True):
        child_bus = qbuses.QDriveBus('drive_%s' % aobject, aobject)
        super(QDrive, self).__init__("drive", {}, aobject, (),
                                     child_bus)
        if use_device:
            self.params['id'] = 'drive_%s' % aobject

    def set_param(self, option, value, option_type=None):
        """
        Set device param using qemu notation ("on", "off" instead of bool...)
        It restricts setting of the 'id' param as it's automatically created.
        :param option: which option's value to set
        :param value: new value
        :param option_type: type of the option (bool)
        """
        if option == 'id':
            raise KeyError("Drive ID is automatically created from aobject. %s"
                           % self)
        elif option == 'bus':
            # Workaround inconsistency between -drive and -device
            value = re.findall(r'(\d+)', value)
            if value is not None:
                value = value[0]
        super(QDrive, self).set_param(option, value, option_type)


class QOldDrive(QDrive):

    """
    This is a variant for -drive without 'addr' support
    """

    def set_param(self, option, value, option_type=None):
        """
        Ignore addr parameters as they are not supported by old qemus
        """
        if option == 'addr':
            logging.warn("Ignoring 'addr=%s' parameter of %s due of old qemu"
                         ", PCI addresses might be messed up.", value,
                         self.str_short())
            return
        return super(QOldDrive, self).set_param(option, value, option_type)


class QHPDrive(QDrive):

    """
    Representation of the '-drive' qemu object with hotplug support.
    """

    def __init__(self, aobject):
        super(QHPDrive, self).__init__(aobject)
        self.__hook_drive_bus = None

    def verify_hotplug(self, out, monitor):
        if isinstance(monitor, qemu_monitor.QMPMonitor):
            if out.startswith('OK'):
                return True
        else:
            if out == 'OK':
                return True
        return False

    def verify_unplug(self, out, monitor):
        out = monitor.info("qtree", debug=False)
        if "unknown command" in out:       # Old qemu don't have info qtree
            return True
        dev_id_name = 'id "%s"' % self.aid
        if dev_id_name in out:
            return False
        else:
            return True

    def get_children(self):
        """ Device bus should be removed too """
        for bus in self.child_bus:
            if isinstance(bus, qbuses.QDriveBus):
                drive_bus = bus
                self.rm_child_bus(bus)
                break
        devices = super(QHPDrive, self).get_children()
        self.add_child_bus(drive_bus)
        return devices

    def unplug_hook(self):
        """
        Devices from this bus are not removed, only 'drive' is set to None.
        """
        for bus in self.child_bus:
            if isinstance(bus, qbuses.QDriveBus):
                for dev in bus:
                    self.__hook_drive_bus = dev.get_param('drive')
                    dev['drive'] = None
                break

    def unplug_unhook(self):
        """ Set back the previous 'drive' (unsafe, using the last value) """
        if self.__hook_drive_bus is not None:
            for bus in self.child_bus:
                if isinstance(bus, qbuses.QDriveBus):
                    for dev in bus:
                        dev['drive'] = self.__hook_drive_bus
                    break

    def hotplug_hmp(self):
        """ :return: the hotplug monitor command """
        args = self.params.copy()
        pci_addr = args.pop('addr', 'auto')
        args = _convert_args(args)
        return "drive_add %s %s" % (pci_addr, args)

    def unplug_hmp(self):
        """ :return: the unplug monitor command """
        if self.get_qid() is None:
            raise DeviceError("qid not set; device %s can't be unplugged"
                              % self)
        return "drive_del %s" % self.get_qid()


class QRHDrive(QDrive):

    """
    Representation of the '-drive' qemu object with RedHat hotplug support.
    """

    def __init__(self, aobject):
        super(QRHDrive, self).__init__(aobject)
        self.__hook_drive_bus = None

    def hotplug_hmp(self):
        """ :return: the hotplug monitor command """
        args = self.params.copy()
        args.pop('addr', None)    # not supported by RHDrive
        args.pop('if', None)
        args = _convert_args(args)
        return "__com.redhat_drive_add %s" % args

    def hotplug_qmp(self):
        """ :return: the hotplug monitor command """
        args = self.params.copy()
        args.pop('addr', None)    # not supported by RHDrive
        args.pop('if', None)
        return "__com.redhat_drive_add", args

    def get_children(self):
        """ Device bus should be removed too """
        for bus in self.child_bus:
            if isinstance(bus, qbuses.QDriveBus):
                drive_bus = bus
                self.rm_child_bus(bus)
                break
        devices = super(QRHDrive, self).get_children()
        self.add_child_bus(drive_bus)
        return devices

    def unplug_hook(self):
        """
        Devices from this bus are not removed, only 'drive' is set to None.
        """
        for bus in self.child_bus:
            if isinstance(bus, qbuses.QDriveBus):
                for dev in bus:
                    self.__hook_drive_bus = dev.get_param('drive')
                    dev['drive'] = None
                break

    def unplug_unhook(self):
        """ Set back the previous 'drive' (unsafe, using the last value) """
        if self.__hook_drive_bus is not None:
            for bus in self.child_bus:
                if isinstance(bus, qbuses.QDriveBus):
                    for dev in bus:
                        dev['drive'] = self.__hook_drive_bus
                    break

    def unplug_hmp(self):
        """ :return: the unplug monitor command """
        if self.get_qid() is None:
            raise DeviceError("qid not set; device %s can't be unplugged"
                              % self)
        return "__com.redhat_drive_del %s" % self.get_qid()

    def unplug_qmp(self):
        """ :return: the unplug monitor command """
        if self.get_qid() is None:
            raise DeviceError("qid not set; device %s can't be unplugged"
                              % self)
        return "__com.redhat_drive_del", {'id': self.get_qid()}


class QDevice(QCustomDevice):

    """
    Representation of the '-device' qemu object. It supports all methods.
    :note: Use driver format in full form - 'driver' = '...' (usb-ehci, ide-hd)
    """

    def __init__(self, driver=None, params=None, aobject=None,
                 parent_bus=None, child_bus=None):
        super(QDevice, self).__init__("device", params, aobject, parent_bus,
                                      child_bus, 'driver')
        if driver:
            self.set_param('driver', driver)
        self.hook_drive_bus = None

    def _get_alternative_name(self):
        """ :return: alternative object name """
        if self.params.get('driver'):
            return self.params.get('driver')

    def hotplug_hmp(self):
        """ :return: the hotplug monitor command """
        if self.params.get('driver'):
            params = self.params.copy()
            out = "device_add %s" % params.pop('driver')
            params = _convert_args(params)
            if params:
                out += ",%s" % params
        else:
            out = "device_add %s" % _convert_args(self.params)
        return out

    def hotplug_qmp(self):
        """ :return: the hotplug monitor command """
        return "device_add", self.params

    def hotplug_hmp_nd(self):
        """ :return: the hotplug monitor command without dynamic parameters"""
        if self.params.get('driver'):
            params = self.params.copy()
            out = "device_add %s" % params.pop('driver')
            for key in self.dynamic_params:
                params[key] = "DYN"
            params = _convert_args(params)
            if params:
                out += ",%s" % params
        else:
            params = self.params.copy()
            for key in self.dynamic_params:
                params[key] = "DYN"
            out = "device_add %s" % _convert_args(params)
        return out

    def hotplug_qmp_nd(self):
        """ :return: the hotplug monitor command without dynamic parameters"""
        params = self.params.copy()
        for key in self.dynamic_params:
            params[key] = "DYN"
        return "device_add", params

    def get_children(self):
        """ Device bus should be removed too """
        devices = super(QDevice, self).get_children()
        if self.hook_drive_bus:
            devices.append(self.hook_drive_bus)
        return devices

    def unplug_hmp(self):
        """ :return: the unplug monitor command """
        if self.get_qid():
            return "device_del %s" % self.get_qid()
        else:
            raise DeviceError("Device has no qemu_id.")

    def unplug_qmp(self):
        """ :return: the unplug monitor command """
        if self.get_qid():
            return "device_del", {'id': self.get_qid()}
        else:
            raise DeviceError("Device has no qemu_id.")

    def verify_unplug(self, out, monitor):
        out = monitor.info("qtree", debug=False)
        if "unknown command" in out:       # Old qemu don't have info qtree
            return out
        dev_id_name = 'id "%s"' % self.get_qid()
        if dev_id_name in out:
            return False
        else:
            return True

    # pylint: disable=E0202
    def verify_hotplug(self, out, monitor):
        out = monitor.info("qtree", debug=False)
        if "unknown command" in out:       # Old qemu don't have info qtree
            return out
        dev_id_name = 'id "%s"' % self.get_qid()
        if dev_id_name in out:
            return True
        else:
            return False


class QGlobal(QBaseDevice):

    """
    Representation of qemu global setting (-global driver.property=value)
    """

    def __init__(self, driver, prop, value, aobject=None,
                 parent_bus=None, child_bus=None):
        """
        :param driver: Which global driver to set
        :param prop: Which property to set
        :param value: What's the desired value
        :param params: component's parameters
        :param aobject: Autotest object which is associated with this device
        :param parent_bus: bus(es), in which this device is plugged in
        :param child_bus: bus, which this device provides
        """
        params = {'driver': driver, 'property': prop, 'value': value}
        super(QGlobal, self).__init__('global', params, aobject,
                                      parent_bus, child_bus)

    def cmdline(self):
        return "-global %s.%s=%s" % (self['driver'], self['property'],
                                     self['value'])


class QFloppy(QGlobal):

    """
    Imitation of qemu floppy disk defined by -global isa-fdc.drive?=$drive
    """

    def __init__(self, unit=None, drive=None, aobject=None, parent_bus=None,
                 child_bus=None):
        """
        :param unit: Floppy unit (None, 0, 1 or driveA, driveB)
        :param drive: id of drive
        :param aobject: Autotest object which is associated with this device
        :param parent_bus: bus(es), in which this device is plugged in
        :param child_bus: bus(es), which this device provides
        """
        super(QFloppy, self).__init__('isa-fdc', unit, drive, aobject,
                                      parent_bus, child_bus)

    def _get_alternative_name(self):
        return "floppy-%s" % (self.get_param('property'))

    def set_param(self, option, value, option_type=None):
        """
        drive and unit params have to be 'translated' as value and property.
        """
        if option == 'drive':
            option = 'value'
        elif option == 'unit':
            option = 'property'
        super(QFloppy, self).set_param(option, value, option_type)

########NEW FILE########
__FILENAME__ = utils
"""
Shared classes and functions (exceptions, ...)

:copyright: 2013 Red Hat Inc.
"""


#
# Exceptions
#
class DeviceError(Exception):

    """ General device exception """
    pass


class DeviceInsertError(DeviceError):

    """ Fail to insert device """

    def __init__(self, device, reason, vmdev):
        self.device = device
        self.reason = reason
        self.vmdev = vmdev
        self.issue = "insert"

    def __str__(self):
        return ("Failed to %s device:\n%s\nBecause:\n%s\nList of VM devices:\n"
                "%s\n%s" % (self.issue, self.device.str_long(), self.reason,
                            self.vmdev.str_short(), self.vmdev.str_bus_long()))


class DeviceRemoveError(DeviceInsertError):

    """ Fail to remove device """

    def __init__(self, device, reason, vmdev):
        DeviceInsertError.__init__(self, device, reason, vmdev)
        self.issue = "remove"


class DeviceHotplugError(DeviceInsertError):

    """ Fail to hotplug device """

    def __init__(self, device, reason, vmdev):
        DeviceInsertError.__init__(self, device, reason, vmdev)
        self.issue = "hotplug"


class DeviceUnplugError(DeviceHotplugError):

    """ Fail to unplug device """

    def __init__(self, device, reason, vmdev):
        DeviceHotplugError.__init__(self, device, reason, vmdev)
        self.issue = "unplug"


#
# Utilities
#
def none_or_int(value):
    """ Helper fction which returns None or int() """
    if isinstance(value, int):
        return value
    elif not value:   # "", None, False
        return None
    elif isinstance(value, str) and value.isdigit():
        return int(value)
    else:
        raise TypeError("This parameter has to be int or none")

########NEW FILE########
__FILENAME__ = qemu_devices_unittest
#!/usr/bin/python
"""
This is a unittest for qemu_devices library.

:author: Lukas Doktor <ldoktor@redhat.com>
:copyright: 2012 Red Hat, Inc.
"""
__author__ = """Lukas Doktor (ldoktor@redhat.com)"""

import re
import unittest
import os

import common
from autotest.client.shared.test_utils import mock
from qemu_devices import qdevices, qbuses, qcontainer
from qemu_devices.utils import DeviceHotplugError, DeviceRemoveError
import data_dir
import qemu_monitor

UNITTEST_DATA_DIR = os.path.join(
    data_dir.get_root_dir(), "virttest", "unittest_data")

# Dummy variables
# qemu-1.5.0 human monitor help output
QEMU_HMP = open(os.path.join(UNITTEST_DATA_DIR, "qemu-1.5.0__hmp_help")).read()
# qemu-1.5.0 QMP monitor commands output
QEMU_QMP = open(os.path.join(UNITTEST_DATA_DIR, "qemu-1.5.0__qmp_help")).read()
# qemu-1.5.0 -help
QEMU_HELP = open(os.path.join(UNITTEST_DATA_DIR, "qemu-1.5.0__help")).read()
# qemu-1.5.0 -devices ?
QEMU_DEVICES = open(
    os.path.join(UNITTEST_DATA_DIR, "qemu-1.5.0__devices_help")).read()
# qemu-1.5.0 -M ?
QEMU_MACHINE = open(
    os.path.join(UNITTEST_DATA_DIR, "qemu-1.5.0__machine_help")).read()


class ParamsDict(dict):

    """ params like dictionary """

    def objects(self, item):
        if self.get(item):
            return self.get(item).split(' ')

    def object_params(self, obj):
        ret = self.copy()
        for (param, value) in self.iteritems():
            if param.endswith('_%s' % obj):
                ret[param[:-len('_%s' % obj)]] = value
        return ret


class MockHMPMonitor(qemu_monitor.HumanMonitor):

    """ Dummy class inherited from qemu_monitor.HumanMonitor """

    def __init__(self):     # pylint: disable=W0231
        self.debug_log = False

    def __del__(self):
        pass


class Devices(unittest.TestCase):

    """ set of qemu devices tests """

    def test_q_base_device(self):
        """ QBaseDevice tests """
        qdevice = qdevices.QBaseDevice('MyType',
                                       {'ParamA': 'ValueA',
                                        'AUTOREMOVE': None},
                                       'Object1',
                                       {'type': 'pci'})
        self.assertEqual(qdevice['ParamA'], 'ValueA', 'Param added during '
                         '__init__ is corrupted %s != %s' % (qdevice['ParamA'],
                                                             'ValueA'))
        qdevice['ParamA'] = 'ValueB'
        qdevice.set_param('BoolTrue', True)
        qdevice.set_param('BoolFalse', 'off', bool)
        qdevice['Empty'] = 'EMPTY_STRING'

        out = """MyType
  aid = None
  aobject = Object1
  parent_bus = {'type': 'pci'}
  child_bus = []
  params:
    ParamA = ValueB
    BoolTrue = on
    BoolFalse = off
    Empty = ""
"""
        self.assertEqual(qdevice.str_long(), out, "Device output doesn't match"
                         "\n%s\n\n%s" % (qdevice.str_long(), out))

    def test_q_string_device(self):
        """ QStringDevice tests """
        qdevice = qdevices.QStringDevice('MyType', {'addr': '0x7'},
                                         cmdline='-qdevice ahci,addr=%(addr)s')
        self.assertEqual(qdevice.cmdline(), '-qdevice ahci,addr=0x7', "Cmdline"
                         " doesn't match expected one:\n%s\n%s"
                         % (qdevice.cmdline(), '-qdevice ahci,addr=0x7'))

    def test_q_device(self):
        """ QDevice tests """
        qdevice = qdevices.QDevice('ahci', {'addr': '0x7'})

        self.assertEqual(str(qdevice), "a'ahci'", "Alternative name error %s "
                         "!= %s" % (str(qdevice), "a'ahci'"))

        qdevice['id'] = 'ahci1'
        self.assertEqual(str(qdevice), "q'ahci1'", "Id name error %s "
                         "!= %s" % (str(qdevice), "q'ahci1'"))

        exp = "device_add ahci,addr=0x7,id=ahci1"
        out = qdevice.hotplug_hmp()
        self.assertEqual(out, exp, "HMP command corrupted:\n%s\n%s"
                         % (out, exp))

        exp = ("('device_add', OrderedDict([('addr', '0x7'), "
               "('driver', 'ahci'), ('id', 'ahci1')]))")
        out = str(qdevice.hotplug_qmp())
        self.assertEqual(out, exp, "QMP command corrupted:\n%s\n%s"
                         % (out, exp))


class Buses(unittest.TestCase):

    """ Set of bus-representation tests """

    def test_q_sparse_bus(self):
        """ Sparse bus tests (general bus testing) """
        bus = qbuses.QSparseBus('bus',
                                (['addr1', 'addr2', 'addr3'], [2, 6, 4]),
                                'my_bus',
                                'bus_type',
                                'autotest_bus')

        qdevice = qdevices.QDevice

        # Correct records
        params = {'addr1': '0', 'addr2': '0', 'addr3': '0', 'bus': 'my_bus'}
        dev = qdevice('dev1', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'addr1': '1', 'addr2': '0', 'addr3': '0', 'bus': 'my_bus'}
        dev = qdevice('dev2', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'addr1': '1', 'addr2': '1', 'addr3': '0', 'bus': 'my_bus'}
        dev = qdevice('dev3', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'addr1': '1', 'addr2': '1', 'addr3': '1', 'bus': 'my_bus'}
        dev = qdevice('dev4', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'addr1': '1', 'bus': 'my_bus'}
        dev = qdevice('dev5', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'bus': 'my_bus'}
        dev = qdevice('dev6', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {}
        dev2 = qdevice('dev7', params, parent_bus={'type': 'bus_type'})
        exp = []
        out = bus.insert(dev2, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev2.str_long(), bus.str_long()))

        # Compare short repr
        exp = ("my_bus(bus_type): {0-0-0:a'dev1',0-0-1:a'dev6',0-0-2:a'dev7',"
               "1-0-0:a'dev2',1-0-1:a'dev5',1-1-0:a'dev3',1-1-1:a'dev4'}")
        out = str(bus.str_short())
        self.assertEqual(out, exp, "Short representation corrupted:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

        # Incorrect records
        # Used address
        params = {'addr1': '0', 'addr2': '0', 'addr3': '0', 'bus': 'my_bus'}
        dev = qdevice('devI1', params, parent_bus={'type': 'bus_type'})
        exp = "UsedSlot"
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Added bad device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        # Out of range address
        params = {'addr1': '0', 'addr2': '6', 'addr3': '0', 'bus': 'my_bus'}
        dev = qdevice('devI2', params, parent_bus={'type': 'bus_type'})
        exp = "BadAddr(False)"
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Added bad device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        # Incorrect bus name
        params = {'bus': 'other_bus'}
        dev = qdevice('devI3', params, parent_bus={'type': 'bus_type'})
        exp = "BusId"
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Added bad device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        # Compare short repr
        exp = ("my_bus(bus_type): {0-0-0:a'dev1',0-0-1:a'dev6',0-0-2:a'dev7',"
               "1-0-0:a'dev2',1-0-1:a'dev5',1-1-0:a'dev3',1-1-1:a'dev4'}")
        out = str(bus.str_short())
        self.assertEqual(out, exp, "Short representation corrupted:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

        # Compare long repr
        exp = """Bus my_bus, type=bus_type
Slots:
---------------< 1-0-0 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      bus = my_bus
      addr2 = 0
      addr3 = 0
      addr1 = 1
      driver = dev2
---------------< 1-0-1 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      bus = my_bus
      addr1 = 1
      driver = dev5
---------------< 1-1-1 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      bus = my_bus
      addr2 = 1
      addr3 = 1
      addr1 = 1
      driver = dev4
---------------< 1-1-0 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      bus = my_bus
      addr2 = 1
      addr3 = 0
      addr1 = 1
      driver = dev3
---------------< 0-0-1 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      bus = my_bus
      driver = dev6
---------------< 0-0-0 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      bus = my_bus
      addr2 = 0
      addr3 = 0
      addr1 = 0
      driver = dev1
---------------< 0-0-2 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'bus_type'}
    child_bus = []
    params:
      driver = dev7
"""
        out = str(bus.str_long())
        self.assertEqual(out, exp, "Long representation corrupted:\n%s\n%s"
                         % (repr(out), exp))

        # Low level functions
        # Get device by object
        exp = dev2
        out = bus.get(dev2)
        self.assertEqual(out, exp, "Failed to get device from bus:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

        dev2.aid = 'bad_device3'
        exp = dev2
        out = bus.get('bad_device3')
        self.assertEqual(out, exp, "Failed to get device from bus:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

        exp = None
        out = bus.get('missing_bad_device')
        self.assertEqual(out, exp, "Got device while expecting None:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

        # Remove all devices
        devs = [dev for dev in bus]
        for dev in devs:
            bus.remove(dev)

        exp = 'Bus my_bus, type=bus_type\nSlots:\n'
        out = str(bus.str_long())
        self.assertEqual(out, exp, "Long representation corrupted:\n%s\n%s"
                         % (out, exp))

    def test_q_pci_bus(self):
        """ PCI bus tests """
        bus = qbuses.QPCIBus('pci.0', 'pci', 'my_pci')
        qdevice = qdevices.QDevice

        # Good devices
        params = {'addr': '0'}
        dev = qdevice('dev1', params, parent_bus={'type': 'pci'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'addr': 10, 'bus': 'pci.0'}
        dev = qdevice('dev2', params, parent_bus={'type': 'pci'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        params = {'addr': '0x1f'}
        dev = qdevice('dev3', params, parent_bus={'type': 'pci'})
        exp = []
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Failed to add device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        # Compare short repr
        exp = ("pci.0(pci): {00-00:a'dev1',0a-00:a'dev2',1f-00:a'dev3'}")
        out = str(bus.str_short())
        self.assertEqual(out, exp, "Short representation corrupted:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

        # Incorrect records
        # Used address
        params = {'addr': 0}
        dev = qdevice('devI1', params, parent_bus={'type': 'pci'})
        exp = "UsedSlot"
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Added bad device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        # Out of range address
        params = {'addr': '0xffff'}
        dev = qdevice('devI2', params, parent_bus={'type': 'pci'})
        exp = "BadAddr(False)"
        out = bus.insert(dev, False)
        self.assertEqual(out, exp, "Added bad device; %s != %s\n%s\n\n%s"
                         % (out, exp, dev.str_long(), bus.str_long()))

        # Compare short repr
        exp = ("pci.0(pci): {00-00:a'dev1',0a-00:a'dev2',1f-00:a'dev3'}")
        out = str(bus.str_short())
        self.assertEqual(out, exp, "Short representation corrupted:\n%s\n%s"
                         "\n\n%s" % (out, exp, bus.str_long()))

    def test_q_pci_bus_strict(self):
        """ PCI bus tests in strict_mode (enforce additional options) """
        bus = qbuses.QPCIBus('pci.0', 'pci', 'my_pci')
        qdevice = qdevices.QDevice

        params = {}
        bus.insert(qdevice('dev1', params, parent_bus={'type': 'pci'}), True)
        bus.insert(qdevice('dev2', params, parent_bus={'type': 'pci'}), True)
        bus.insert(qdevice('dev3', params, parent_bus={'type': 'pci'}), True)
        params = {'addr': '0x1f'}
        bus.insert(qdevice('dev1', params, parent_bus={'type': 'pci'}), True)
        params = {'addr': 30}
        bus.insert(qdevice('dev1', params, parent_bus={'type': 'pci'}), True)
        params = {'addr': 12}
        bus.insert(qdevice('dev1', params, parent_bus={'type': 'pci'}), True)

        # All devices will have 'addr' set as we are in the strict mode
        exp = """Bus pci.0, type=pci
Slots:
---------------< 1e-00 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'pci'}
    child_bus = []
    params:
      addr = 1e
      driver = dev1
      bus = pci.0
---------------< 02-00 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'pci'}
    child_bus = []
    params:
      driver = dev3
      bus = pci.0
      addr = 02
---------------< 1f-00 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'pci'}
    child_bus = []
    params:
      addr = 1f
      driver = dev1
      bus = pci.0
---------------< 00-00 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'pci'}
    child_bus = []
    params:
      driver = dev1
      bus = pci.0
      addr = 00
---------------< 0c-00 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'pci'}
    child_bus = []
    params:
      addr = 0c
      driver = dev1
      bus = pci.0
---------------< 01-00 >---------------
  device
    aid = None
    aobject = None
    parent_bus = {'type': 'pci'}
    child_bus = []
    params:
      driver = dev2
      bus = pci.0
      addr = 01
"""
        out = str(bus.str_long())
        self.assertEqual(out, exp, "Long representation corrupted:\n%s\n%s"
                         % (out, exp))

    def test_usb_bus(self):
        """ Tests the specific handlings of QUSBBus """
        usbc1 = qbuses.QUSBBus(2, 'usb1.0', 'uhci')

        # Insert device into usb controller, default port
        dev = qdevices.QDevice('usb-kbd', parent_bus={'type': 'uhci'})
        assert usbc1.insert(dev) == []

        # Insert usb-hub into usb controller, default port
        dev = qdevices.QDevice('usb-hub', parent_bus={'type': 'uhci'})
        assert usbc1.insert(dev) == []
        hub1 = dev.child_bus[-1]

        # Insert usb-hub into usb-hub, exact port
        dev = qdevices.QDevice('usb-hub', {'port': '2.4'},
                               parent_bus={'type': 'uhci'})
        assert hub1.insert(dev) == []
        hub2 = dev.child_bus[-1]

        # Insert usb-hub into usb-hub in usb-hub, exact port
        dev = qdevices.QDevice('usb-hub', {'port': '2.4.3'},
                               parent_bus={'type': 'uhci'})
        assert hub2.insert(dev) == []
        hub3 = dev.child_bus[-1]
        # verify that port is updated correctly
        self.assertEqual("2.4.3", dev.get_param("port"))

        # Insert usb-device into usb-hub in usb-hub in usb-hub, exact port
        dev = qdevices.QDevice('usb-kbd', {'port': '2.4.3.1'},
                               parent_bus={'type': 'uhci'})
        assert hub3.insert(dev) == []
        # Insert usb-device into usb-hub in usb-hub in usb-hub, default port
        dev = qdevices.QDevice('usb-kbd', parent_bus={'type': 'uhci'})
        assert hub3.insert(dev) == []

        # Try to insert device into specific port which belongs to inferior bus
        out = hub2.insert(qdevices.QDevice('usb-kbd',
                                           {'port': '2.4.3.3'},
                                           parent_bus={'type': 'uhci'}))
        assert out == "BusId"

        # Try to insert device into specific port which belongs to superior bus
        out = hub2.insert(qdevices.QDevice('usb-kbd', {'port': '2.4'},
                                           parent_bus={'type': 'uhci'}))
        assert out == "BusId"

        # Try to insert device into specific port which belongs to same level
        # but different port
        out = hub2.insert(qdevices.QDevice('usb-kbd', {'port': '2.3.4'},
                                           parent_bus={'type': 'uhci'}))
        assert out == "BusId"

        # Force insert device with port which belongs to other hub
        dev = qdevices.QDevice('usb-hub', {'port': '2.4.3.4'},
                               parent_bus={'type': 'uhci'})

        # Check the overall buses correctness
        self.assertEqual("usb1.0(uhci): {1:a'usb-kbd',2:a'usb-hub'}",
                         usbc1.str_short())
        self.assertEqual("usb1.0(uhci): {4:a'usb-hub'}",
                         hub1.str_short())
        self.assertEqual("usb1.0(uhci): {3:a'usb-hub'}",
                         hub2.str_short())
        self.assertEqual("usb1.0(uhci): {1:a'usb-kbd',2:a'usb-kbd'}",
                         hub3.str_short())


class Container(unittest.TestCase):

    """ Tests related to the abstract representation of qemu machine """

    def setUp(self):
        self.god = mock.mock_god(ut=self)
        self.god.stub_function(qcontainer.utils, "system_output")

    def tearDown(self):
        self.god.unstub_all()

    def create_qdev(self, vm_name='vm1', strict_mode="no",
                    allow_hotplugged_vm="yes"):
        """ :return: Initialized qcontainer.DevContainer object """
        qemu_cmd = '/usr/bin/qemu_kvm'
        qcontainer.utils.system_output.expect_call('%s -help' % qemu_cmd,
                                                   timeout=10, ignore_status=True
                                                   ).and_return(QEMU_HELP)
        qcontainer.utils.system_output.expect_call("%s -device ? 2>&1"
                                                   % qemu_cmd, timeout=10,
                                                   ignore_status=True
                                                   ).and_return(QEMU_DEVICES)
        qcontainer.utils.system_output.expect_call("%s -M ?" % qemu_cmd,
                                                   timeout=10, ignore_status=True
                                                   ).and_return(QEMU_MACHINE)
        cmd = "echo -e 'help\nquit' | %s -monitor stdio -vnc none" % qemu_cmd
        qcontainer.utils.system_output.expect_call(cmd, timeout=10,
                                                   ignore_status=True
                                                   ).and_return(QEMU_HMP)
        cmd = ('echo -e \'{ "execute": "qmp_capabilities" }\n'
               '{ "execute": "query-commands", "id": "RAND91" }\n'
               '{ "execute": "quit" }\''
               '| %s -qmp stdio -vnc none | grep return |'
               ' grep RAND91' % qemu_cmd)
        qcontainer.utils.system_output.expect_call(cmd, timeout=10,
                                                   ignore_status=True
                                                   ).and_return('')

        cmd = ('echo -e \'{ "execute": "qmp_capabilities" }\n'
               '{ "execute": "query-commands", "id": "RAND91" }\n'
               '{ "execute": "quit" }\' | (sleep 1; cat )'
               '| %s -qmp stdio -vnc none | grep return |'
               ' grep RAND91' % qemu_cmd)
        qcontainer.utils.system_output.expect_call(cmd, timeout=10,
                                                   ignore_status=True
                                                   ).and_return(QEMU_QMP)

        qdev = qcontainer.DevContainer(qemu_cmd, vm_name, strict_mode, 'no',
                                       allow_hotplugged_vm)

        self.god.check_playback()
        return qdev

    def test_qdev_functional(self):
        """ Test basic qdev workflow """
        qdev = self.create_qdev('vm1')

        # Add basic 'pc' devices
        out = qdev.insert(qdev.machine_by_params(ParamsDict({'machine_type':
                                                             'pc'})))
        assert isinstance(out, list)
        assert len(out) == 6, len(out)

        exp = r"""Devices of vm1:
machine
  aid = __0
  aobject = pci.0
  parent_bus = ()
  child_bus = \[.*QPCIBus.*, .*QStrictCustomBus.*\]
  params:
i440FX
  aid = __1
  aobject = None
  parent_bus = ({'aobject': 'pci.0'},)
  child_bus = \[\]
  params:
    driver = i440FX
    addr = 00
    bus = pci.0
PIIX4_PM
  aid = __2
  aobject = None
  parent_bus = ({'aobject': 'pci.0'},)
  child_bus = \[\]
  params:
    driver = PIIX4_PM
    addr = 01.3
    bus = pci.0
PIIX3
  aid = __3
  aobject = None
  parent_bus = ({'aobject': 'pci.0'},)
  child_bus = \[\]
  params:
    driver = PIIX3
    addr = 01
    bus = pci.0
piix3-ide
  aid = __4
  aobject = None
  parent_bus = ({'aobject': 'pci.0'},)
  child_bus = \[.*QIDEBus.*\]
  params:
    driver = piix3-ide
    addr = 01.1
    bus = pci.0
fdc
  aid = __5
  aobject = None
  parent_bus = \(\)
  child_bus = \[.*QFloppyBus.*\]
  params:"""
        out = qdev.str_long()
        self.assertNotEqual(re.findall(exp, out), None, 'Long representation is'
                            'corrupted:\n%s\n%s' % (out, exp))

        exp = ("Buses of vm1\n"
               "  floppy(floppy): [None,None]\n"
               "  ide(ide): [None,None,None,None]\n"
               "  _PCI_CHASSIS_NR(None): {}\n"
               "  _PCI_CHASSIS(None): {}\n"
               "  pci.0(PCI): {00-00:t'i440FX',01-00:t'PIIX3',"
               "01-01:t'piix3-ide',01-03:t'PIIX4_PM'}")
        out = qdev.str_bus_short()
        assert out == exp, "Bus representation is ocrrupted:\n%s\n%s" % (out,
                                                                         exp)

        # Insert some good devices
        qdevice = qdevices.QDevice

        # Device with child bus
        bus = qbuses.QSparseBus('bus', [['addr'], [6]], 'hba1.0', 'hba',
                                'a_hba')
        dev = qdevice('HBA', {'id': 'hba1', 'addr': 10},
                      parent_bus={'aobject': 'pci.0'}, child_bus=bus)
        out = qdev.insert(dev)
        assert isinstance(out, list), out
        assert len(out) == 1, len(out)

        # Device inside a child bus by type (most common)
        dev = qdevice('dev', {}, parent_bus={'type': 'hba'})
        out = qdev.insert(dev)
        assert isinstance(out, list), out
        assert len(out) == 1, len(out)

        # Device inside a child bus by autotest_id
        dev = qdevice('dev', {}, 'autotest_remove', {'aobject': 'a_hba'})
        out = qdev.insert(dev)
        assert isinstance(out, list), out
        assert len(out) == 1, len(out)

        # Device inside a child bus by busid
        dev = qdevice('dev', {}, 'autoremove', {'busid': 'hba1.0'})
        out = qdev.insert(dev)
        assert isinstance(out, list), out
        assert len(out) == 1, len(out)

        # Check the representation
        exp = ("Devices of vm1: [t'machine',t'i440FX',t'PIIX4_PM',t'PIIX3',"
               "t'piix3-ide',t'fdc',hba1,a'dev',a'dev',a'dev']")
        out = qdev.str_short()
        self.assertEqual(out, exp, "Short representation is corrupted:\n%s\n%s"
                         % (out, exp))
        exp = ("Buses of vm1\n"
               "  hba1.0(hba): {0:a'dev',1:a'dev',2:a'dev'}\n"
               "  floppy(floppy): [None,None]\n"
               "  ide(ide): [None,None,None,None]\n"
               "  _PCI_CHASSIS_NR(None): {}\n"
               "  _PCI_CHASSIS(None): {}\n"
               "  pci.0(PCI): {00-00:t'i440FX',01-00:t'PIIX3',"
               "01-01:t'piix3-ide',01-03:t'PIIX4_PM',0a-00:hba1}")
        out = qdev.str_bus_short()
        assert out == exp, 'Bus representation iscorrupted:\n%s\n%s' % (out,
                                                                        exp)

        # Check the representation
        exp = ("Devices of vm1: [t'machine',t'i440FX',t'PIIX4_PM',t'PIIX3',"
               "t'piix3-ide',t'fdc',hba1,a'dev',a'dev',a'dev']")
        out = qdev.str_short()
        assert out == exp, "Short representation is corrupted:\n%s\n%s" % (out,
                                                                           exp)
        exp = ("Buses of vm1\n"
               "  hba1.0(hba): {0:a'dev',1:a'dev',2:a'dev'}\n"
               "  floppy(floppy): [None,None]\n"
               "  ide(ide): [None,None,None,None]\n"
               "  _PCI_CHASSIS_NR(None): {}\n"
               "  _PCI_CHASSIS(None): {}\n"
               "  pci.0(PCI): {00-00:t'i440FX',01-00:t'PIIX3',"
               "01-01:t'piix3-ide',01-03:t'PIIX4_PM',0a-00:hba1}")
        out = qdev.str_bus_short()
        assert out == exp, 'Bus representation is corrupted:\n%s\n%s' % (out,
                                                                         exp)

        # Now representation contains some devices, play with it a bit
        # length
        out = len(qdev)
        assert out == 10, "Length of qdev is incorrect: %s != %s" % (out, 10)

        # compare
        qdev2 = self.create_qdev('vm1')
        self.assertNotEqual(qdev, qdev2, "This qdev matches empty one:"
                            "\n%s\n%s" % (qdev, qdev2))
        self.assertNotEqual(qdev2, qdev, "Empty qdev matches current one:"
                            "\n%s\n%s" % (qdev, qdev2))
        for _ in xrange(10):
            qdev2.insert(qdevice())
        self.assertNotEqual(qdev, qdev2, "This qdev matches different one:"
                            "\n%s\n%s" % (qdev, qdev2))
        self.assertNotEqual(qdev2, qdev, "Other qdev matches this one:\n%s\n%s"
                            % (qdev, qdev2))
        # cmdline
        exp = ("-M pc -device HBA,id=hba1,addr=0a,bus=pci.0 -device dev "
               "-device dev -device dev")
        out = qdev.cmdline()
        self.assertEqual(out, exp, 'Corrupted qdev.cmdline() output:\n%s\n%s'
                         % (out, exp))

        # get_by_qid (currently we have 2 devices of the same qid)
        out = qdev.get_by_qid('hba1')
        self.assertEqual(len(out), 1, 'Incorrect number of devices by qid '
                         '"hba1": %s != 1\n%s' % (len(out), qdev.str_long()))

        # Remove some devices
        # Remove based on aid
        out = qdev.remove('__6')
        self.assertEqual(out, None, 'Failed to remove device:\n%s\nRepr:\n%s'
                         % ('hba1__0', qdev.str_long()))

        # Remove device which contains other devices (without recursive)
        self.assertRaises(qcontainer.DeviceRemoveError, qdev.remove, 'hba1',
                          False)

        # Remove device which contains other devices (recursive)
        out = qdev.remove('hba1')
        self.assertEqual(out, None, 'Failed to remove device:\n%s\nRepr:\n%s'
                         % ('hba1', qdev.str_long()))

        # Check the representation
        exp = ("Devices of vm1: [t'machine',t'i440FX',t'PIIX4_PM',t'PIIX3',"
               "t'piix3-ide',t'fdc']")
        out = qdev.str_short()
        assert out == exp, "Short representation is corrupted:\n%s\n%s" % (out,
                                                                           exp)
        exp = ("Buses of vm1\n"
               "  floppy(floppy): [None,None]\n"
               "  ide(ide): [None,None,None,None]\n"
               "  _PCI_CHASSIS_NR(None): {}\n"
               "  _PCI_CHASSIS(None): {}\n"
               "  pci.0(PCI): {00-00:t'i440FX',01-00:t'PIIX3',"
               "01-01:t'piix3-ide',01-03:t'PIIX4_PM'}")
        out = qdev.str_bus_short()
        assert out == exp, 'Bus representation is corrupted:\n%s\n%s' % (out,
                                                                         exp)

    def test_qdev_hotplug(self):
        """ Test the hotplug/unplug functionality """
        qdev = self.create_qdev('vm1', False, True)
        devs = qdev.machine_by_params(ParamsDict({'machine_type': 'pc'}))
        for dev in devs:
            qdev.insert(dev)
        monitor = MockHMPMonitor()

        out = qdev.get_state()
        assert out == -1, ("Status after init is not -1"
                           " (%s)" % out)
        out = len(qdev)
        assert out == 6, "Number of devices of this VM is not 5 (%s)" % out

        dev1, dev2 = qdev.images_define_by_variables('disk', '/tmp/a',
                                                     fmt="virtio")

        out = dev1.hotplug_hmp()
        exp = "drive_add auto id=drive_disk,if=none,file=/tmp/a"
        assert out == exp, ("Hotplug command of drive is incorrect:\n%s\n%s"
                            % (exp, out))

        # hotplug of drive will return "  OK" (pass)
        dev1.hotplug = lambda _monitor: "OK"
        dev1.verify_hotplug = lambda _out, _monitor: True
        out, ver_out = qdev.simple_hotplug(dev1, monitor)
        assert out == "OK", "Return value of hotplug is not OK (%s)" % out
        assert ver_out is True, ("Return value of hotplug"
                                 " is not True (%s)" % ver_out)
        out = qdev.get_state()
        assert out == 0, ("Status after verified hotplug is not 0 (%s)" % out)

        # hotplug of virtio-blk-pci will return ""
        out = dev2.hotplug_hmp()
        exp = "device_add virtio-blk-pci,id=disk,drive=drive_disk"
        assert out == exp, ("Hotplug command of device is incorrect:\n%s\n%s"
                            % (exp, out))
        dev2.hotplug = lambda _monitor: ""
        dev2.verify_hotplug = lambda _out, _monitor: ""
        out, ver_out = qdev.simple_hotplug(dev2, monitor)
        # automatic verification is not supported, hotplug returns the original
        # monitor message ("")
        assert ver_out == "", ("Return value of hotplug is"
                               " not "" (%s)" % ver_out)
        assert out == "", 'Return value of hotplug is not "" (%s)' % out
        out = qdev.get_state()
        assert out == 1, ("Status after verified hotplug is not 1 (%s)" % out)
        qdev.hotplug_verified()
        out = qdev.get_state()
        assert out == 0, ("Status after verified hotplug is not 0 (%s)" % out)

        out = len(qdev)
        assert out == 8, "Number of devices of this VM is not 8 (%s)" % out

        # Hotplug is expected to pass but monitor reports failure
        dev3 = qdevices.QDrive('a_dev1')
        dev3.hotplug = lambda _monitor: ("could not open disk image /tmp/qqq: "
                                         "No such file or directory")

        out, ver_out = qdev.simple_hotplug(dev3, monitor)
        exp = "could not open disk image /tmp/qqq: No such file or directory"
        assert out, "Return value of hotplug is incorrect:\n%s\n%s" % (out,
                                                                       exp)
        out = qdev.get_state()
        assert out == 1, ("Status after failed hotplug is not 1 (%s)" % out)
        # device is still in qdev, but is not in qemu, we should remove it
        qdev.remove(dev3, recursive=False)
        out = qdev.get_state()
        assert out == 1, ("Status after verified hotplug is not 1 (%s)" % out)
        qdev.hotplug_verified()
        out = qdev.get_state()
        assert out == 0, ("Status after verified hotplug is not 0 (%s)" % out)

        # Hotplug is expected to fail, qdev should stay unaffected
        dev4 = qdevices.QBaseDevice("bad_dev", parent_bus={'type': "XXX"})
        dev4.hotplug = lambda _monitor: ("")
        self.assertRaises(qcontainer.DeviceHotplugError, qdev.simple_hotplug,
                          dev4, True)
        out = qdev.get_state()
        assert out == 0, "Status after impossible hotplug is not 0 (%s)" % out

        # Unplug
        # Unplug used drive (automatic verification not supported)
        out = dev1.unplug_hmp()
        exp = "drive_del drive_disk"
        assert out == exp, ("Hotplug command of device is incorrect:\n%s\n%s"
                            % (exp, out))
        dev1.unplug = lambda _monitor: ""
        dev1.verify_unplug = lambda _monitor, _out: ""
        out, ver_out = qdev.simple_unplug(dev1, monitor)
        # I verified, that device was unplugged successfully
        qdev.hotplug_verified()
        out = qdev.get_state()
        assert out == 0, ("Status after verified hotplug is not 0 (%s)" % out)
        out = len(qdev)
        assert out == 7, "Number of devices of this VM is not 7 (%s)" % out
        # Removal of drive should also set drive of the disk device to None
        out = dev2.get_param('drive')
        assert out is None, "Drive was not removed from disk device"

    # pylint: disable=W0212
    def test_qdev_low_level(self):
        """ Test low level functions """
        qdev = self.create_qdev('vm1')

        # Representation state (used for hotplug or other nasty things)
        out = qdev.get_state()
        assert out == -1, "qdev state is incorrect %s != %s" % (out, 1)

        qdev.set_dirty()
        out = qdev.get_state()
        self.assertEqual(out, 1, "qdev state is incorrect %s != %s" % (out, 1))

        qdev.set_dirty()
        out = qdev.get_state()
        self.assertEqual(out, 2, "qdev state is incorrect %s != %s" % (out, 1))

        qdev.set_clean()
        out = qdev.get_state()
        self.assertEqual(out, 1, "qdev state is incorrect %s != %s" % (out, 1))

        qdev.set_clean()
        out = qdev.get_state()
        self.assertEqual(out, 0, "qdev state is incorrect %s != %s" % (out, 1))

        qdev.reset_state()
        out = qdev.get_state()
        assert out == -1, "qdev state is incorrect %s != %s" % (out, 1)

        # __create_unique_aid
        dev = qdevices.QDevice()
        qdev.insert(dev)
        out = dev.get_aid()
        self.assertEqual(out, '__0', "incorrect aid %s != %s" % (out, '__0'))

        dev = qdevices.QDevice(None, {'id': 'qid'})
        qdev.insert(dev)
        out = dev.get_aid()
        self.assertEqual(out, 'qid', "incorrect aid %s != %s" % (out, 'qid'))

        # has_option
        out = qdev.has_option('device')
        self.assertEqual(out, True)

        out = qdev.has_option('missing_option')
        self.assertEqual(out, False)

        # has_device
        out = qdev.has_device('ide-drive')
        self.assertEqual(out, True)

        out = qdev.has_device('missing_device')
        self.assertEqual(out, False)

        # get_help_text
        out = qdev.get_help_text()
        self.assertEqual(out, QEMU_HELP)

        # has_hmp_cmd
        self.assertTrue(qdev.has_hmp_cmd('pcie_aer_inject_error'))
        self.assertTrue(qdev.has_hmp_cmd('c'))
        self.assertTrue(qdev.has_hmp_cmd('cont'))
        self.assertFalse(qdev.has_hmp_cmd('off'))
        self.assertFalse(qdev.has_hmp_cmd('\ndump-guest-memory'))
        self.assertFalse(qdev.has_hmp_cmd('The'))

        # has_qmp_cmd
        self.assertTrue(qdev.has_qmp_cmd('device_add'))
        self.assertFalse(qdev.has_qmp_cmd('RAND91'))

        # Add some buses
        bus1 = qbuses.QPCIBus('pci.0', 'pci', 'a_pci0')
        qdev.insert(qdevices.QDevice(params={'id': 'pci0'},
                                     child_bus=bus1))
        bus2 = qbuses.QPCIBus('pci.1', 'pci', 'a_pci1')
        qdev.insert(qdevices.QDevice(child_bus=bus2))
        bus3 = qbuses.QPCIBus('pci.2', 'pci', 'a_pci2')
        qdev.insert(qdevices.QDevice(child_bus=bus3))
        bus4 = qbuses.QPCIBus('pcie.0', 'pcie', 'a_pcie0')
        qdev.insert(qdevices.QDevice(child_bus=bus4))

        # get_buses (all buses of this type)
        out = qdev.get_buses({'type': 'pci'})
        self.assertEqual(len(out), 3, 'get_buses should return 3 buses but '
                         'returned %s instead:\n%s' % (len(out), out))

        # get_first_free_bus (last added bus of this type)
        out = qdev.get_first_free_bus({'type': 'pci'}, [None, None])
        self.assertEqual(bus3, out)

        # fill the first pci bus
        for _ in xrange(32):
            qdev.insert(qdevices.QDevice(parent_bus={'type': 'pci'}))

        # get_first_free_bus (last one is full, return the previous one)
        out = qdev.get_first_free_bus({'type': 'pci'}, [None, None])
        self.assertEqual(bus2, out)

        # list_named_buses
        out = qdev.list_missing_named_buses('pci.', 'pci', 5)
        self.assertEqual(len(out), 2, 'Number of missing named buses is '
                         'incorrect: %s != %s\n%s' % (len(out), 2, out))
        out = qdev.list_missing_named_buses('pci.', 'abc', 5)
        self.assertEqual(len(out), 5, 'Number of missing named buses is '
                         'incorrect: %s != %s\n%s' % (len(out), 2, out))

        # idx_of_next_named_bus
        out = qdev.idx_of_next_named_bus('pci.')
        self.assertEqual(out, 3, 'Incorrect idx of next named bus: %s !='
                         ' %s' % (out, 3))

        # get_children
        dev = qdevices.QDevice(parent_bus={'aobject': 'a_pci0'})
        bus = qbuses.QPCIBus('test1', 'test', 'a_test1')
        dev.add_child_bus(bus)
        bus = qbuses.QPCIBus('test2', 'test', 'a_test2')
        dev.add_child_bus(bus)
        qdev.insert(dev)
        qdev.insert(qdevices.QDevice(parent_bus={'aobject': 'a_test1'}))
        qdev.insert(qdevices.QDevice(parent_bus={'aobject': 'a_test2'}))
        out = dev.get_children()
        assert len(out) == 2, ("Not all children were listed %d != 2:\n%s"
                               % (len(out), out))

        out = bus.get_device()
        assert out == dev, ("bus.get_device() returned different device "
                            "than the one in which it was plugged:\n"
                            "%s\n%s\n%s" % (out.str_long(), dev.str_long(),
                                            qdev.str_long()))
    # pylint: enable=W0212

    def test_qdev_equal(self):
        qdev1 = self.create_qdev('vm1', allow_hotplugged_vm='no')
        qdev2 = self.create_qdev('vm1', allow_hotplugged_vm='no')
        qdev3 = self.create_qdev('vm1', allow_hotplugged_vm='yes')
        monitor = MockHMPMonitor()

        assert qdev1 == qdev2, ("Init qdevs are not alike\n%s\n%s"
                                % (qdev1.str_long(), qdev2.str_long()))

        # Insert a device to qdev1
        dev = qdevices.QDevice('dev1', {'id': 'dev1'})
        qdev1.insert(dev)

        assert qdev1 != qdev2, ("Different qdevs match:\n%s\n%s"
                                % (qdev1.str_long(), qdev2.str_long()))

        # Insert similar device to qdev2
        dev = qdevices.QDevice('dev1', {'id': 'dev1'})
        qdev2.insert(dev)

        assert qdev1 == qdev2, ("Similar qdevs are not alike\n%s\n%s"
                                % (qdev1.str_long(), qdev2.str_long()))

        # Hotplug similar device to qdev3
        dev = qdevices.QDevice('dev1', {'id': 'dev1'})
        dev.hotplug = lambda _monitor: ""   # override the hotplug method
        dev.verify_hotplug = lambda _out, _monitor: True
        qdev3.simple_hotplug(dev, monitor)
        assert qdev1 == qdev3, ("Similar hotplugged qdevs are not alike\n%s\n"
                                "%s" % (qdev1.str_long(), qdev2.str_long()))

        # Eq. is not symmetrical, qdev1 doesn't allow hotplugged VMs.
        assert qdev3 != qdev1, ("Similar hotplugged qdevs match even thought "
                                "qdev1 doesn't allow hotplugged VM\n%s\n%s"
                                % (qdev1.str_long(), qdev2.str_long()))

        qdev2.__qemu_help = "I support only this :-)"  # pylint: disable=W0212
        assert qdev1 == qdev2, ("qdevs of different qemu versions match:\n%s\n"
                                "%s" % (qdev1.str_long(), qdev2.str_long()))

    def test_pci(self):
        qdev = self.create_qdev('vm1')
        devs = qdev.machine_by_params(ParamsDict({'machine_type': 'pc'}))
        for dev in devs:
            qdev.insert(dev)
        # machine creates main pci (pci.0)
        # buses root.1 pci_switch pci_bridge
        # root.1: ioh3420(pci.0)
        # pci_switch: x3130(root.1)
        # pci_bridge: pci-bridge(root.1)
        devs = qdev.pcic_by_params('root.1', {'pci_bus': 'pci.0',
                                              'type': 'ioh3420'})
        qdev.insert(devs)
        devs = qdev.pcic_by_params('pci_switch', {'pci_bus': 'root.1',
                                                  'type': 'x3130'})

        qdev.insert(devs)
        devs = qdev.pcic_by_params('pci_bridge', {'pci_bus': 'root.1',
                                                  'type': 'pci-bridge'})
        qdev.insert(devs)

        qdev.insert(qdevices.QDevice("ahci", {'id': 'in_bridge'},
                                     parent_bus={'type': ('PCI', 'PCIE'),
                                                 'aobject': 'pci_bridge'}))

        qdev.insert(qdevices.QDevice("ahci", {'id': 'in_switch1'},
                                     parent_bus={'type': ('PCI', 'PCIE'),
                                                 'aobject': 'pci_switch'}))
        qdev.insert(qdevices.QDevice("ahci", {'id': 'in_switch2'},
                                     parent_bus={'type': ('PCI', 'PCIE'),
                                                 'aobject': 'pci_switch'}))
        qdev.insert(qdevices.QDevice("ahci", {'id': 'in_switch3'},
                                     parent_bus={'type': ('PCI', 'PCIE'),
                                                 'aobject': 'pci_switch'}))

        qdev.insert(qdevices.QDevice("ahci", {'id': 'in_root1'},
                                     parent_bus={'type': ('PCI', 'PCIE'),
                                                 'aobject': 'root.1'}))

        qdev.insert(qdevices.QDevice("ahci", {'id': 'in_pci.0'},
                                     parent_bus={'type': ('PCI', 'PCIE'),
                                                 'aobject': 'pci.0'}))

        exp = ("-M pc -device ioh3420,id=root.1,bus=pci.0,addr=02 "
               "-device x3130-upstream,id=pci_switch,bus=root.1,addr=00 "
               "-device pci-bridge,id=pci_bridge,bus=root.1,addr=01,"
               "chassis_nr=1 -device ahci,id=in_bridge,bus=pci_bridge,addr=01"
               " -device xio3130-downstream,bus=pci_switch,id=pci_switch.0,"
               "addr=00,chassis=1 -device ahci,id=in_switch1,bus=pci_switch.0"
               ",addr=00 "
               "-device xio3130-downstream,bus=pci_switch,id=pci_switch.1,"
               "addr=01,chassis=2 -device ahci,id=in_switch2,bus=pci_switch.1"
               ",addr=00 "
               "-device xio3130-downstream,bus=pci_switch,id=pci_switch.2,"
               "addr=02,chassis=3 -device ahci,id=in_switch3,bus=pci_switch.2"
               ",addr=00 "
               "-device ahci,id=in_root1,bus=root.1,addr=02 "
               "-device ahci,id=in_pci.0,bus=pci.0,addr=03")
        out = qdev.cmdline()
        assert out == exp, (out, exp)

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = qemu_installer
"""
Installer code that implement KVM specific bits.

See BaseInstaller class in base_installer.py for interface details.
"""

import os
import logging
from autotest.client import utils
from autotest.client.shared import error
import base_installer


__all__ = ['GitRepoInstaller', 'LocalSourceDirInstaller',
           'LocalSourceTarInstaller', 'RemoteSourceTarInstaller']


class QEMUBaseInstaller(base_installer.BaseInstaller):

    '''
    Base class for KVM installations
    '''

    #
    # Name of acceptable QEMU binaries that may be built or installed.
    # We'll look for one of these binaries when linking the QEMU binary
    # to the test directory
    #
    qemu_system = 'qemu-system-' + utils.system_output('uname -i')
    ACCEPTABLE_QEMU_BIN_NAMES = ['qemu-kvm', qemu_system]

    #
    # The default names for the binaries
    #
    QEMU_BIN = 'qemu'
    QEMU_IMG_BIN = 'qemu-img'
    QEMU_IO_BIN = 'qemu-io'
    QEMU_FS_PROXY_BIN = 'virtfs-proxy-helper'

    def _kill_qemu_processes(self):
        """
        Kills all qemu processes and all processes holding /dev/kvm down

        :return: None
        """
        logging.debug("Killing any qemu processes that might be left behind")
        utils.system("pkill qemu", ignore_status=True)
        # Let's double check to see if some other process is holding /dev/kvm
        if os.path.isfile("/dev/kvm"):
            utils.system("fuser -k /dev/kvm", ignore_status=True)

    def _cleanup_links_qemu(self):
        '''
        Removes previously created links, if they exist

        :return: None
        '''
        qemu_path = os.path.join(self.test_builddir, self.QEMU_BIN)
        qemu_img_path = os.path.join(self.test_builddir, self.QEMU_IMG_BIN)
        qemu_io_path = os.path.join(self.test_builddir, self.QEMU_IO_BIN)
        qemu_fs_proxy_path = os.path.join(self.test_builddir,
                                          self.QEMU_FS_PROXY_BIN)

        # clean up previous links, if they exist
        for path in (qemu_path, qemu_img_path, qemu_io_path,
                     qemu_fs_proxy_path):
            if os.path.lexists(path):
                os.unlink(path)

    def _cleanup_link_unittest(self):
        '''
        Removes previously created links, if they exist

        :return: None
        '''
        qemu_unittest_path = os.path.join(self.test_builddir, "unittests")

        if os.path.lexists(qemu_unittest_path):
            os.unlink(qemu_unittest_path)

    def _create_symlink_unittest(self):
        '''
        Create symbolic links for qemu and qemu-img commands on test bindir

        :return: None
        '''
        unittest_src = os.path.join(self.install_prefix,
                                    'share', 'qemu', 'tests')
        unittest_dst = os.path.join(self.test_builddir, "unittests")

        if os.path.lexists(unittest_dst):
            logging.debug("Unlinking unittest dir")
            os.unlink(unittest_dst)

        logging.debug("Linking unittest dir")
        os.symlink(unittest_src, unittest_dst)

    def _qemu_bin_exists_at_prefix(self):
        '''
        Attempts to find the QEMU binary at the installation prefix

        :return: full path of QEMU binary or None if not found
        '''
        result = None

        for name in self.ACCEPTABLE_QEMU_BIN_NAMES:
            qemu_bin_name = os.path.join(self.install_prefix, 'bin', name)
            if os.path.isfile(qemu_bin_name):
                result = qemu_bin_name
                break

        if result is not None:
            logging.debug('Found QEMU binary at %s', result)
        else:
            logging.debug('Could not find QEMU binary at prefix %s',
                          self.install_prefix)

        return result

    def _qemu_img_bin_exists_at_prefix(self):
        '''
        Attempts to find the qemu-img binary at the installation prefix

        :return: full path of qemu-img binary or None if not found
        '''
        qemu_img_bin_name = os.path.join(self.install_prefix,
                                         'bin', self.QEMU_IMG_BIN)
        if os.path.isfile(qemu_img_bin_name):
            logging.debug('Found qemu-img binary at %s', qemu_img_bin_name)
            return qemu_img_bin_name
        else:
            logging.debug('Could not find qemu-img binary at prefix %s',
                          self.install_prefix)
            return None

    def _qemu_io_bin_exists_at_prefix(self):
        '''
        Attempts to find the qemu-io binary at the installation prefix

        :return: full path of qemu-io binary or None if not found
        '''
        qemu_io_bin_name = os.path.join(self.install_prefix,
                                        'bin', self.QEMU_IO_BIN)
        if os.path.isfile(qemu_io_bin_name):
            logging.debug('Found qemu-io binary at %s', qemu_io_bin_name)
            return qemu_io_bin_name
        else:
            logging.debug('Could not find qemu-io binary at prefix %s',
                          self.install_prefix)
            return None

    def _qemu_fs_proxy_bin_exists_at_prefix(self):
        '''
        Attempts to find the qemu fs proxy binary at the installation prefix

        :return: full path of qemu fs proxy binary or None if not found
        '''
        qemu_fs_proxy_bin_name = os.path.join(self.install_prefix,
                                              'bin', self.QEMU_FS_PROXY_BIN)
        if os.path.isfile(qemu_fs_proxy_bin_name):
            logging.debug('Found qemu fs proxy binary at %s',
                          qemu_fs_proxy_bin_name)
            return qemu_fs_proxy_bin_name
        else:
            logging.debug('Could not find qemu fs proxy binary at prefix %s',
                          self.install_prefix)
            return None

    def _create_symlink_qemu(self):
        """
        Create symbolic links for qemu and qemu-img commands on test bindir

        :return: None
        """
        logging.debug("Linking QEMU binaries")

        qemu_dst = os.path.join(self.test_builddir, self.QEMU_BIN)
        qemu_img_dst = os.path.join(self.test_builddir, self.QEMU_IMG_BIN)
        qemu_io_dst = os.path.join(self.test_builddir, self.QEMU_IO_BIN)
        qemu_fs_proxy_dst = os.path.join(self.test_builddir,
                                         self.QEMU_FS_PROXY_BIN)

        qemu_bin = self._qemu_bin_exists_at_prefix()
        if qemu_bin is not None:
            os.symlink(qemu_bin, qemu_dst)
        else:
            raise error.TestError('Invalid qemu path')

        qemu_img_bin = self._qemu_img_bin_exists_at_prefix()
        if qemu_img_bin is not None:
            os.symlink(qemu_img_bin, qemu_img_dst)
        else:
            raise error.TestError('Invalid qemu-img path')

        qemu_io_bin = self._qemu_io_bin_exists_at_prefix()
        if qemu_io_bin is not None:
            os.symlink(qemu_io_bin, qemu_io_dst)
        else:
            raise error.TestError('Invalid qemu-io path')

        qemu_fs_proxy_bin = self._qemu_fs_proxy_bin_exists_at_prefix()
        if qemu_fs_proxy_bin is not None:
            os.symlink(qemu_fs_proxy_bin, qemu_fs_proxy_dst)
        else:
            logging.warning('Qemu fs proxy path %s not found on source dir')

    def _install_phase_init(self):
        '''
        Initializes the built and installed software

        This uses a simple mechanism of looking up the installer name
        for deciding what action to do.

        :return: None
        '''
        if 'unit' in self.name:
            self._cleanup_link_unittest()
            self._create_symlink_unittest()

        elif 'qemu' in self.name:
            self._cleanup_links_qemu()
            self._create_symlink_qemu()

    def uninstall(self):
        '''
        Performs the uninstallation of KVM userspace component

        :return: None
        '''
        self._kill_qemu_processes()
        self._cleanup_links()
        super(QEMUBaseInstaller, self).uninstall()


class GitRepoInstaller(QEMUBaseInstaller,
                       base_installer.GitRepoInstaller):

    '''
    Installer that deals with source code on Git repositories
    '''
    pass


class LocalSourceDirInstaller(QEMUBaseInstaller,
                              base_installer.LocalSourceDirInstaller):

    '''
    Installer that deals with source code on local directories
    '''
    pass


class LocalSourceTarInstaller(QEMUBaseInstaller,
                              base_installer.LocalSourceTarInstaller):

    '''
    Installer that deals with source code on local tarballs
    '''
    pass


class RemoteSourceTarInstaller(QEMUBaseInstaller,
                               base_installer.RemoteSourceTarInstaller):

    '''
    Installer that deals with source code on remote tarballs
    '''
    pass

########NEW FILE########
__FILENAME__ = qemu_io
import re
from autotest.client.shared import error
from autotest.client import utils
import utils_misc
import aexpect
import data_dir


class QemuIOParamError(Exception):

    """
    Parameter Error for qemu-io command
    """
    pass


class QemuIO(object):

    """
    A class for execute qemu-io command
    """

    def __init__(self, test, params, image_name, blkdebug_cfg="",
                 prompt=r"qemu-io>\s*$", log_filename=None, io_options="",
                 log_func=None):
        self.type = ""
        if log_filename:
            log_filename += "-" + utils_misc.generate_random_string(4)
            self.output_func = utils_misc.log_line
            self.output_params = (log_filename,)
        else:
            self.output_func = None
            self.output_params = ()
        self.output_prefix = ""
        self.prompt = prompt
        self.blkdebug_cfg = blkdebug_cfg

        self.qemu_io_cmd = utils_misc.get_qemu_io_binary(params)
        self.io_options = io_options
        self.run_command = False
        self.image_name = image_name
        self.blkdebug_cfg = blkdebug_cfg
        self.log_func = log_func

    def get_cmd_line(self, ignore_option=[], essential_option=[],
                     forbid_option=[]):
        """
        Generate the command line for qemu-io from the parameters
        :params ignore_option: list for the options should not in command
        :params essential_option: list for the essential options
        :params forbid_option: list for the option should not in command
        :return: qemu-io command line
        """
        essential_flag = False

        qemu_io_cmd = self.qemu_io_cmd
        if self.io_options:
            for io_option in re.split(",", self.io_options):
                if io_option in ignore_option:
                    pass
                elif io_option in forbid_option:
                    raise QemuIOParamError
                else:
                    if not essential_flag and io_option in essential_option:
                        essential_flag = True
                    if len(io_option) == 1:
                        qemu_io_cmd += " -%s" % io_option
                    else:
                        qemu_io_cmd += " --%s" % io_option
            if essential_option and not essential_flag:
                raise QemuIOParamError

        if self.image_name:
            qemu_io_cmd += " "
            if self.blkdebug_cfg:
                qemu_io_cmd += "blkdebug:%s:" % self.blkdebug_cfg
            qemu_io_cmd += self.image_name

        return qemu_io_cmd

    def cmd_output(self, command):
        """
        Run a command in qemu-io
        """
        pass

    def close(self):
        """
        Clean up
        """
        pass


class QemuIOShellSession(QemuIO):

    """
    Use a shell session to execute qemu-io command
    """

    def __init__(self, test, params, image_name, blkdebug_cfg="",
                 prompt=r"qemu+-io>\s*$", log_filename=None, io_options="",
                 log_func=None):
        QemuIO.__init__(self, test, params, image_name, blkdebug_cfg, prompt,
                        log_filename, io_options, log_func)

        self.type = "shell"
        forbid_option = ["h", "help", "V", "version", "c", "cmd"]

        self.qemu_io_cmd = self.get_cmd_line(forbid_option=forbid_option)
        self.create_session = True
        self.session = None

    @error.context_aware
    def cmd_output(self, command, timeout=60):
        """
        Get output from shell session. If the create flag is True, init the
        shell session and set the create flag to False.
        :param command: command to execute in qemu-io
        :param timeout: timeout for execute the command
        """
        qemu_io_cmd = self.qemu_io_cmd
        prompt = self.prompt
        output_func = self.output_func
        output_params = self.output_params
        output_prefix = self.output_prefix
        if self.create_session:
            error.context("Running command: %s" % qemu_io_cmd, self.log_func)
            self.session = aexpect.ShellSession(qemu_io_cmd, echo=True,
                                                prompt=prompt,
                                                output_func=output_func,
                                                output_params=output_params,
                                                output_prefix=output_prefix)
            # Record the command line in log file
            if self.output_func:
                params = self.output_params + (qemu_io_cmd, )
                self.output_func(*params)

            self.create_session = False
            # Get the reaction from session
            self.session.cmd_output("\n")

        error.context("Executing command: %s" % command, self.log_func)
        return self.session.cmd_output(command, timeout=timeout)

    def close(self):
        """
        Close the shell session for qemu-io
        """
        if not self.create_session:
            self.session.close()


class QemuIOSystem(QemuIO):

    """
    Run qemu-io with a command line which will return immediately
    """

    def __init__(self, test, params, image_name, blkdebug_cfg="",
                 prompt=r"qemu-io>\s*$", log_filename=None, io_options="",
                 log_func=None):
        QemuIO.__init__(self, test, params, image_name, blkdebug_cfg, prompt,
                        log_filename, io_options, log_func)
        ignore_option = ["c", "cmd"]
        essential_option = ["h", "help", "V", "version", "c", "cmd"]

        self.qemu_io_cmd = self.get_cmd_line(ignore_option=ignore_option,
                                             essential_option=essential_option)

    @error.context_aware
    def cmd_output(self, command, timeout=60):
        """
        Get output from system_output. Add the command to the qemu-io command
        line with -c and record the output in the log file.
        :param command: command to execute in qemu-io
        :param timeout: timeout for execute the command
        """
        qemu_io_cmd = self.qemu_io_cmd
        if command:
            qemu_io_cmd += " -c '%s'" % command

        error.context("Running command: %s" % qemu_io_cmd, self.log_func)
        output = utils.system_output(qemu_io_cmd, timeout=timeout)

        # Record command line in log file
        if self.output_func:
            params = self.output_params + (qemu_io_cmd,)
            self.output_func(*params)

            params = self.output_params + (output,)
            self.output_func(*params)

        return output

    def close(self):
        """
        To keep the the same interface with QemuIOShellSession
        """
        pass

########NEW FILE########
__FILENAME__ = qemu_monitor
"""
Interfaces to the QEMU monitor.

:copyright: 2008-2010 Red Hat Inc.
"""

import socket
import time
import threading
import logging
import select
import re
import os
import utils_misc
import passfd_setup
from autotest.client.shared import utils
try:
    import json
except ImportError:
    logging.warning("Could not import json module. "
                    "QMP monitor functionality disabled.")


class MonitorError(Exception):
    pass


class MonitorConnectError(MonitorError):

    def __init__(self, monitor_name):
        MonitorError.__init__(self)
        self.monitor_name = monitor_name

    def __str__(self):
        return "Could not connect to monitor '%s'" % self.monitor_name


class MonitorSocketError(MonitorError):

    def __init__(self, msg, e):
        Exception.__init__(self, msg, e)
        self.msg = msg
        self.e = e

    def __str__(self):
        return "%s    (%s)" % (self.msg, self.e)


class MonitorLockError(MonitorError):
    pass


class MonitorProtocolError(MonitorError):
    pass


class MonitorNotSupportedError(MonitorError):
    pass


class MonitorNotSupportedCmdError(MonitorNotSupportedError):

    def __init__(self, monitor, cmd):
        MonitorError.__init__(self)
        self.monitor = monitor
        self.cmd = cmd

    def __str__(self):
        return ("Not supported cmd '%s' in monitor '%s'" %
                (self.cmd, self.monitor))


class QMPCmdError(MonitorError):

    def __init__(self, cmd, qmp_args, data):
        MonitorError.__init__(self, cmd, qmp_args, data)
        self.cmd = cmd
        self.qmp_args = qmp_args
        self.data = data

    def __str__(self):
        return ("QMP command %r failed    (arguments: %r,    "
                "error message: %r)" % (self.cmd, self.qmp_args, self.data))


def get_monitor_filename(vm, monitor_name):
    """
    Return the filename corresponding to a given monitor name.

    :param vm: The VM object which has the monitor.
    :param monitor_name: The monitor name.
    :return: The string of socket file name for qemu monitor.
    """
    return "/tmp/monitor-%s-%s" % (monitor_name, vm.instance)


def get_monitor_filenames(vm):
    """
    Return a list of all monitor filenames (as specified in the VM's
    params).

    :param vm: The VM object which has the monitors.
    """
    return [get_monitor_filename(vm, m) for m in vm.params.objects("monitors")]


def create_monitor(vm, monitor_name, monitor_params):
    """
    Create monitor object and connect to the monitor socket.

    :param vm: The VM object which has the monitor.
    :param monitor_name: The name of this monitor object.
    :param monitor_params: The dict for creating this monitor object.
    """
    monitor_creator = HumanMonitor
    if monitor_params.get("monitor_type") == "qmp":
        monitor_creator = QMPMonitor
        if not utils_misc.qemu_has_option("qmp", vm.qemu_binary):
            # Add a "human" monitor on non-qmp version of qemu.
            logging.warn("QMP monitor is unsupported by this version of qemu,"
                         " creating human monitor instead.")
            monitor_creator = HumanMonitor

    monitor_filename = get_monitor_filename(vm, monitor_name)
    logging.info("Connecting to monitor '%s'", monitor_name)
    monitor = monitor_creator(vm, monitor_name, monitor_filename)
    monitor.verify_responsive()

    return monitor


def wait_for_create_monitor(vm, monitor_name, monitor_params, timeout):
    """
    Wait for the progress of creating monitor object. This function will
    retry to create the Monitor object until timeout.

    :param vm: The VM object which has the monitor.
    :param monitor_name: The name of this monitor object.
    :param monitor_params: The dict for creating this monitor object.
    :param timeout: Time to wait for creating this monitor object.
    """
    # Wait for monitor connection to succeed
    end_time = time.time() + timeout
    while time.time() < end_time:
        try:
            return create_monitor(vm, monitor_name, monitor_params)
        except MonitorError, e:
            logging.warn(e)
            time.sleep(1)
    else:
        raise MonitorConnectError(monitor_name)


class Monitor:

    """
    Common code for monitor classes.
    """

    ACQUIRE_LOCK_TIMEOUT = 20
    DATA_AVAILABLE_TIMEOUT = 0
    CONNECT_TIMEOUT = 30

    def __init__(self, vm, name, filename):
        """
        Initialize the instance.

        :param vm: The VM which this monitor belongs to.
        :param name: Monitor identifier (a string)
        :param filename: Monitor socket filename

        :raise MonitorConnectError: Raised if the connection fails
        """
        self.vm = vm
        self.name = name
        self.filename = filename
        self._lock = threading.RLock()
        self._socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        self._socket.settimeout(self.CONNECT_TIMEOUT)
        self._passfd = None
        self._supported_cmds = []
        self.debug_log = False
        self.log_file = os.path.basename(self.filename + ".log")

        try:
            self._socket.connect(filename)
        except socket.error, details:
            raise MonitorConnectError("Could not connect to monitor socket: %s"
                                      % details)

    def __del__(self):
        # Automatically close the connection when the instance is garbage
        # collected
        self._close_sock()
        utils_misc.close_log_file(self.log_file)

    # The following two functions are defined to make sure the state is set
    # exclusively by the constructor call as specified in __getinitargs__().
    def __getstate__(self):
        pass

    def __setstate__(self, state):
        pass

    def __getinitargs__(self):
        # Save some information when pickling -- will be passed to the
        # constructor upon unpickling
        return self.vm, self.name, self.filename, True

    def _close_sock(self):
        try:
            self._socket.shutdown(socket.SHUT_RDWR)
        except socket.error:
            pass
        self._socket.close()

    def _acquire_lock(self, timeout=ACQUIRE_LOCK_TIMEOUT):
        end_time = time.time() + timeout
        while time.time() < end_time:
            if self._lock.acquire(False):
                return True
            time.sleep(0.05)
        return False

    def _data_available(self, timeout=DATA_AVAILABLE_TIMEOUT):
        timeout = max(0, timeout)
        try:
            return bool(select.select([self._socket], [], [], timeout)[0])
        except socket.error, e:
            raise MonitorSocketError("Verifying data on monitor socket", e)

    def _recvall(self):
        s = ""
        while self._data_available():
            try:
                data = self._socket.recv(1024)
            except socket.error, e:
                raise MonitorSocketError("Could not receive data from monitor",
                                         e)
            if not data:
                break
            s += data
        return s

    def _has_command(self, cmd):
        """
        Check wheter kvm monitor support 'cmd'.

        :param cmd: command string which will be checked.

        :return: True if cmd is supported, False if not supported.
        """
        if cmd and cmd in self._supported_cmds:
            return True
        return False

    def _log_command(self, cmd, debug=True, extra_str=""):
        """
        Print log message beening sent.

        :param cmd: Command string.
        :param debug: Whether to print the commands.
        :param extra_str: Extra string would be printed in log.
        """
        if self.debug_log or debug:
            logging.debug("(monitor %s) Sending command '%s' %s",
                          self.name, cmd, extra_str)

    def _log_lines(self, log_str):
        """
        Record monitor cmd/output in log file.
        """
        try:
            for l in log_str.splitlines():
                utils_misc.log_line(self.log_file, l)
        except Exception:
            pass

    def correct(self, cmd):
        """
        Automatic conversion "-" and "_" in commands if the translate command
        is supported commands;
        """
        def translate(cmd):
            return "-".join(re.split("[_-]", cmd))

        if not self._has_command(cmd):
            for _cmd in self._supported_cmds:
                if translate(_cmd) == translate(cmd):
                    logging.info("Convert command %s -> %s", cmd, _cmd)
                    return _cmd
        return cmd

    def is_responsive(self):
        """
        Return True iff the monitor is responsive.
        """
        try:
            self.verify_responsive()
            return True
        except MonitorError:
            return False

    def verify_supported_cmd(self, cmd):
        """
        Verify whether cmd is supported by monitor. If not, raise a
        MonitorNotSupportedCmdError Exception.

        :param cmd: The cmd string need to verify.
        """
        if not self._has_command(cmd):
            raise MonitorNotSupportedCmdError(self.name, cmd)

    # Methods that may be implemented by subclasses:

    def human_monitor_cmd(self, cmd="", timeout=None,
                          debug=True, fd=None):
        """
        Send HMP command

        This method allows code to send HMP commands without the need to check
        if the monitor is QMPMonitor or HumanMonitor.

        :param cmd: human monitor command.
        :param timeout: Time duration to wait for response
        :param debug: Whether to print the commands being sent and responses
        :param fd: file object or file descriptor to pass

        :return: The response to the command
        """
        raise NotImplementedError

    # Methods that should work on both classes, as long as human_monitor_cmd()
    # works:
    re_numa_nodes = re.compile(r"^([0-9]+) nodes$", re.M)
    re_numa_node_info = re.compile(r"^node ([0-9]+) (cpus|size): (.*)$", re.M)

    @classmethod
    def parse_info_numa(cls, r):
        """
        Parse 'info numa' output

        See info_numa() for information about the return value.
        """

        nodes = cls.re_numa_nodes.search(r)
        if nodes is None:
            raise Exception(
                "Couldn't get number of nodes from 'info numa' output")
        nodes = int(nodes.group(1))

        data = [[0, set()] for i in range(nodes)]
        for nodenr, field, value in cls.re_numa_node_info.findall(r):
            nodenr = int(nodenr)
            if nodenr > nodes:
                raise Exception(
                    "Invalid node number on 'info numa' output: %d", nodenr)
            if field == 'size':
                if not value.endswith(' MB'):
                    raise Exception("Unexpected size value: %s", value)
                megabytes = int(value[:-3])
                data[nodenr][0] = megabytes
            elif field == 'cpus':
                cpus = set([int(v) for v in value.split()])
                data[nodenr][1] = cpus
        data = [tuple(i) for i in data]
        return data

    def info_numa(self):
        """
        Run 'info numa' command and parse returned information

        :return: An array of (ram, cpus) tuples, where ram is the RAM size in
                 MB and cpus is a set of CPU numbers
        """
        r = self.human_monitor_cmd("info numa")
        return self.parse_info_numa(r)

    def info(self, what, debug=True):
        """
        Request info about something and return the response.
        """
        raise NotImplementedError

    def info_block(self, debug=True):
        """
        Request info about blocks and return dict of parsed results
        :return: Dict of disk parameters
        """
        info = self.info('block', debug)
        if isinstance(info, str):
            try:
                return self._parse_info_block_old(info)
            except ValueError:
                return self._parse_info_block_1_5(info)
        else:
            return self._parse_info_block_qmp(info)

    @staticmethod
    def _parse_info_block_old(info):
        """
        Parse output of "info block" into dict of disk params (qemu < 1.5.0)
        """
        blocks = {}
        info = info.split('\n')
        for line in info:
            if not line.strip():
                continue
            line = line.split(':', 1)
            name = line[0].strip()
            blocks[name] = {}
            if line[1].endswith('[not inserted]'):
                blocks[name]['not-inserted'] = 1
                line[1] = line[1][:-14]
            for _ in line[1].strip().split(' '):
                (prop, value) = _.split('=', 1)
                if value.isdigit():
                    value = int(value)
                blocks[name][prop] = value
        return blocks

    @staticmethod
    def _parse_info_block_1_5(info):
        """
        Parse output of "info block" into dict of disk params (qemu >= 1.5.0)
        """
        blocks = {}
        info = info.split('\n')
        for line in info:
            if not line.strip():
                continue
            if not line.startswith(' '):   # new block device
                line = line.split(':', 1)
                name = line[0].strip()
                line = line[1][1:]
                blocks[name] = {}
                if line == "[not inserted]":
                    blocks[name]['not-inserted'] = 1
                    continue
                line = line.rsplit(' (', 1)
                if len(line) == 1:       # disk_name
                    blocks[name]['file'] = line
                else:       # disk_name (options)
                    blocks[name]['file'] = line[0]
                    options = (_.strip() for _ in line[1][:-1].split(','))
                    _ = False
                    for option in options:
                        if not _:   # First argument is driver (qcow2, raw, ..)
                            blocks[name]['drv'] = option
                            _ = True
                        elif option == 'read-only':
                            blocks[name]['ro'] = 1
                        elif option == 'encrypted':
                            blocks[name]['encrypted'] = 1
                        else:
                            err = ("_parse_info_block_1_5 got option '%s' "
                                   "which is not yet mapped in autotest. "
                                   "Please contact developers on github.com/"
                                   "autotest." % option)
                            raise NotImplementedError(err)
            else:
                try:
                    option, line = line.split(':', 1)
                    option, line = option.strip(), line.strip()
                    if option == "Backing file":
                        line = line.rsplit(' (chain depth: ')
                        blocks[name]['backing_file'] = line[0]
                        blocks[name]['backing_file_depth'] = int(line[1][:-1])
                    elif option == "Removable device":
                        blocks[name]['removable'] = 1
                        if 'not locked' not in line:
                            blocks[name]['locked'] = 1
                        if 'try open' in line:
                            blocks[name]['try-open'] = 1
                except ValueError:
                    continue

        return blocks

    @staticmethod
    def _parse_info_block_qmp(info):
        """
        Parse output of "query block" into dict of disk params
        """
        blocks = {}
        for item in info:
            if not item.get('device'):
                raise ValueError("Incorrect QMP respone, device not set in"
                                 "info block: %s" % info)
            name = item.pop('device')
            blocks[name] = {}
            if 'inserted' not in item:
                blocks[name]['not-inserted'] = True
            else:
                for key, value in item.pop('inserted', {}).iteritems():
                    blocks[name][key] = value
            for key, value in item.iteritems():
                blocks[name][key] = value
        return blocks

    def close(self):
        """
        Close the connection to the monitor and its log file.
        """
        self._close_sock()
        utils_misc.close_log_file(self.log_file)


class HumanMonitor(Monitor):

    """
    Wraps "human monitor" commands.
    """

    PROMPT_TIMEOUT = 60
    CMD_TIMEOUT = 120

    def __init__(self, vm, name, filename, suppress_exceptions=False):
        """
        Connect to the monitor socket and find the (qemu) prompt.

        :param vm: The VM which this monitor belongs to.
        :param name: Monitor identifier (a string)
        :param filename: Monitor socket filename

        :raise MonitorConnectError: Raised if the connection fails and
                suppress_exceptions is False
        :raise MonitorProtocolError: Raised if the initial (qemu) prompt isn't
                found and suppress_exceptions is False
        :note: Other exceptions may be raised.  See cmd()'s
                docstring.
        """
        try:
            Monitor.__init__(self, vm, name, filename)

            self.protocol = "human"

            # Find the initial (qemu) prompt
            s, o = self._read_up_to_qemu_prompt()
            if not s:
                raise MonitorProtocolError("Could not find (qemu) prompt "
                                           "after connecting to monitor. "
                                           "Output so far: %r" % o)

            self._get_supported_cmds()

        except MonitorError, e:
            self._close_sock()
            if suppress_exceptions:
                logging.warn(e)
            else:
                raise

    # Private methods
    def _read_up_to_qemu_prompt(self, timeout=PROMPT_TIMEOUT):
        s = ""
        end_time = time.time() + timeout
        while self._data_available(end_time - time.time()):
            data = self._recvall()
            if not data:
                break
            s += data
            try:
                lines = s.splitlines()
                # Sometimes the qemu monitor lacks a line break before the
                # qemu prompt, so we have to be less exigent:
                if lines[-1].split()[-1].endswith("(qemu)"):
                    self._log_lines("\n".join(lines[1:]))
                    return True, "\n".join(lines[:-1])
            except IndexError:
                continue
        if s:
            try:
                self._log_lines(s.splitlines()[1:])
            except IndexError:
                pass
        return False, "\n".join(s.splitlines())

    def _send(self, cmd):
        """
        Send a command without waiting for output.

        :param cmd: Command to send
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSocketError: Raised if a socket error occurs
        """
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to send "
                                   "monitor command '%s'" % cmd)

        try:
            try:
                self._socket.sendall(cmd + "\n")
                self._log_lines(cmd)
            except socket.error, e:
                raise MonitorSocketError("Could not send monitor command %r" %
                                         cmd, e)

        finally:
            self._lock.release()

    def _get_supported_cmds(self):
        """
        Get supported human monitor cmds list.
        """
        cmds = self.cmd("help", debug=False)
        if cmds:
            cmd_list = re.findall("^(.*?) ", cmds, re.M)
            self._supported_cmds = [c for c in cmd_list if c]

        if not self._supported_cmds:
            logging.warn("Could not get supported monitor cmds list")

    def _log_response(self, cmd, resp, debug=True):
        """
        Print log message for monitor cmd's response.

        :param cmd: Command string.
        :param resp: Response from monitor command.
        :param debug: Whether to print the commands.
        """
        if self.debug_log or debug:
            logging.debug("(monitor %s) Response to '%s'", self.name, cmd)
            for l in resp.splitlines():
                logging.debug("(monitor %s)    %s", self.name, l)

    # Public methods
    def cmd(self, cmd, timeout=CMD_TIMEOUT, debug=True, fd=None):
        """
        Send command to the monitor.

        :param cmd: Command to send to the monitor
        :param timeout: Time duration to wait for the (qemu) prompt to return
        :param debug: Whether to print the commands being sent and responses
        :return: Output received from the monitor
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSocketError: Raised if a socket error occurs
        :raise MonitorProtocolError: Raised if the (qemu) prompt cannot be
                found after sending the command
        """
        self._log_command(cmd, debug)
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to send "
                                   "monitor command '%s'" % cmd)

        try:
            # Read any data that might be available
            self._recvall()
            if fd is not None:
                if self._passfd is None:
                    self._passfd = passfd_setup.import_passfd()
                # If command includes a file descriptor, use passfd module
                self._passfd.sendfd(self._socket, fd, "%s\n" % cmd)
            else:
                # Send command
                if debug:
                    logging.debug("Send command: %s" % cmd)
                self._send(cmd)
            # Read output
            s, o = self._read_up_to_qemu_prompt(timeout)
            # Remove command echo from output
            o = "\n".join(o.splitlines()[1:])
            # Report success/failure
            if s:
                if o:
                    self._log_response(cmd, o, debug)
                return o
            else:
                msg = ("Could not find (qemu) prompt after command '%s'. "
                       "Output so far: %r" % (cmd, o))
                raise MonitorProtocolError(msg)

        finally:
            self._lock.release()

    def human_monitor_cmd(self, cmd="", timeout=CMD_TIMEOUT,
                          debug=True, fd=None):
        """
        Send human monitor command directly

        :param cmd: human monitor command.
        :param timeout: Time duration to wait for response
        :param debug: Whether to print the commands being sent and responses
        :param fd: file object or file descriptor to pass

        :return: The response to the command
        """
        return self.cmd(cmd, timeout, debug, fd)

    def verify_responsive(self):
        """
        Make sure the monitor is responsive by sending a command.
        """
        self.cmd("info status", debug=False)

    def get_status(self):
        return self.cmd("info status", debug=False)

    def verify_status(self, status):
        """
        Verify VM status

        :param status: Optional VM status, 'running' or 'paused'
        :return: return True if VM status is same as we expected
        """
        return (status in self.get_status())

    # Command wrappers
    # Notes:
    # - All of the following commands raise exceptions in a similar manner to
    #   cmd().
    # - A command wrapper should use self._has_command if it requires
    #    information about the monitor's capabilities.
    def send_args_cmd(self, cmdlines, timeout=CMD_TIMEOUT, convert=True):
        """
        Send a command with/without parameters and return its output.
        Have same effect with cmd function.
        Implemented under the same name for both the human and QMP monitors.
        Command with parameters should in following format e.g.:
        'memsave val=0 size=10240 filename=memsave'
        Command without parameter: 'sendkey ctrl-alt-f1'

        :param cmdlines: Commands send to qemu which is separated by ";". For
                         command with parameters command should send in a string
                         with this format:
                         $command $arg_name=$arg_value $arg_name=$arg_value
        :param timeout: Time duration to wait for (qemu) prompt after command
        :param convert: If command need to convert. For commands such as:
                        $command $arg_value
        :return: The output of the command
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSendError: Raised if the command cannot be sent
        :raise MonitorProtocolError: Raised if the (qemu) prompt cannot be
                found after sending the command
        """
        cmd_output = []
        for cmdline in cmdlines.split(";"):
            if not convert:
                return self.cmd(cmdline, timeout)
            if "=" in cmdline:
                command = cmdline.split()[0]
                cmdargs = " ".join(cmdline.split()[1:]).split(",")
                for arg in cmdargs:
                    value = "=".join(arg.split("=")[1:])
                    if arg.split("=")[0] == "cert-subject":
                        value = value.replace('/', ',')
                    command += " " + value
            else:
                command = cmdline
            cmd_output.append(self.cmd(command, timeout))
        if len(cmd_output) == 1:
            return cmd_output[0]
        return cmd_output

    def quit(self):
        """
        Send "quit" without waiting for output.
        """
        self._send("quit")

    def info(self, what, debug=True):
        """
        Request info about something and return the output.
        :param debug: Whether to print the commands being sent and responses
        """
        return self.cmd("info %s" % what, debug=debug)

    def query(self, what):
        """
        Alias for info.
        """
        return self.info(what)

    def screendump(self, filename, debug=True):
        """
        Request a screendump.

        :param filename: Location for the screendump
        :return: The command's output
        """
        return self.cmd(cmd="screendump %s" % filename, debug=debug)

    def set_link(self, name, up):
        """
        Set link up/down.

        :param name: Link name
        :param up: Bool value, True=set up this link, False=Set down this link
        :return: The response to the command
        """
        set_link_cmd = "set_link"

        # set_link in RHEL5 host use "up|down" instead of "on|off" which is
        # used in RHEL6 host and Fedora host. So here find out the string
        # this monitor accept.
        o = self.cmd("help %s" % set_link_cmd)
        try:
            on_str, off_str = re.findall("(\w+)\|(\w+)", o)[0]
        except IndexError:
            # take a default value if can't get on/off string from monitor.
            on_str, off_str = "on", "off"

        status = off_str
        if up:
            status = on_str
        return self.cmd("%s %s %s" % (set_link_cmd, name, status))

    def live_snapshot(self, device, snapshot_file, snapshot_format="qcow2"):
        """
        Take a live disk snapshot.

        :param device: device id of base image
        :param snapshot_file: image file name of snapshot
        :param snapshot_format: image format of snapshot

        :return: The response to the command
        """
        cmd = ("snapshot_blkdev %s %s %s" %
               (device, snapshot_file, snapshot_format))
        return self.cmd(cmd)

    def block_stream(self, device, speed=None, base=None,
                     cmd="block_stream", correct=True):
        """
        Start block-stream job;

        :param device: device ID
        :param speed: int type, lmited speed(B/s)
        :param base: base file
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        cmd += " %s" % device
        if speed is not None:
            cmd += " %sB" % speed
        if base:
            cmd += " %s" % base
        return self.cmd(cmd)

    def set_block_job_speed(self, device, speed=0,
                            cmd="block_job_set_speed", correct=True):
        """
        Set limited speed for runnig job on the device

        :param device: device ID
        :param speed: int type, limited speed(B/s)
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        cmd += " %s %sB" % (device, speed)
        return self.cmd(cmd)

    def cancel_block_job(self, device, cmd="block_job_cancel", correct=True):
        """
        Cancel running block stream/mirror job on the device

        :param device: device ID
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        cmd += " %s" % device
        return self.send_args_cmd(cmd)

    def query_block_job(self, device):
        """
        Get block job status on the device

        :param device: device ID

        :return: dict about job info, return empty dict if no active job
        """
        job = dict()
        output = str(self.info("block-jobs"))
        for line in output.split("\n"):
            if "No" in re.match("\w+", output).group(0):
                continue
            if device in line:
                if "Streaming" in re.match("\w+", output).group(0):
                    job["type"] = "stream"
                else:
                    job["type"] = "mirror"
                job["device"] = device
                job["offset"] = int(re.findall("\d+", output)[-3])
                job["len"] = int(re.findall("\d+", output)[-2])
                job["speed"] = int(re.findall("\d+", output)[-1])
                break
        return job

    def get_backingfile(self, device):
        """
        Return "backing_file" path of the device

        :param device: device ID

        :return: string, backing_file path
        """
        backing_file = None
        block_info = self.query("block")
        try:
            pattern = "%s:.*backing_file=([^\s]*)" % device
            backing_file = re.search(pattern, block_info, re.M).group(1)
        except Exception:
            pass
        return backing_file

    def block_mirror(self, device, target, speed, sync, format, mode,
                     cmd="drive_mirror", correct=True):
        """
        Start mirror type block device copy job

        :param device: device ID
        :param target: target image
        :param speed: limited speed, unit is B/s
        :param sync: full copy to target image(unsupport in human monitor)
        :param mode: target image create mode, 'absolute-paths' or 'existing'
        :param format: target image format
        :param cmd: block mirror command
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = " %s %s %s" % (device, target, format)
        info = str(self.cmd("help %s" % cmd))
        if (mode == "existing") and "-n" in info:
            args = "-n %s" % args
        if (sync == "full") and "-f" in info:
            args = "-f %s" % args
        if (speed is not None) and ("speed" in info):
            args = "%s %s" % (args, speed)
        cmd = "%s %s" % (cmd, args)
        return self.cmd(cmd)

    def block_reopen(self, device, new_image_file, image_format,
                     cmd="block_job_complete", correct=True):
        """
        Reopen new target image

        :param device: device ID
        :param new_image_file: new image file name
        :param image_format: new image file format
        :param cmd: image reopen command
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = "%s" % device
        info = str(self.cmd("help %s" % cmd))
        if "format" in info:
            args += " %s %s" % (new_image_file, image_format)
        cmd = "%s %s" % (cmd, args)
        return self.cmd(cmd)

    def migrate(self, uri, full_copy=False, incremental_copy=False, wait=False):
        """
        Migrate.

        :param uri: destination URI
        :param full_copy: If true, migrate with full disk copy
        :param incremental_copy: If true, migrate with incremental disk copy
        :param wait: If true, wait for completion
        :return: The command's output
        """
        cmd = "migrate"
        if not wait:
            cmd += " -d"
        if full_copy:
            cmd += " -b"
        if incremental_copy:
            cmd += " -i"
        cmd += " %s" % uri
        return self.cmd(cmd)

    def migrate_set_speed(self, value):
        """
        Set maximum speed (in bytes/sec) for migrations.

        :param value: Speed in bytes/sec
        :return: The command's output
        """
        return self.cmd("migrate_set_speed %s" % value)

    def migrate_set_downtime(self, value):
        """
        Set maximum tolerated downtime (in seconds) for migration.

        :param value: maximum downtime (in seconds)
        :return: The command's output
        """
        return self.cmd("migrate_set_downtime %s" % value)

    def sendkey(self, keystr, hold_time=1):
        """
        Send key combination to VM.

        :param keystr: Key combination string
        :param hold_time: Hold time in ms (should normally stay 1 ms)
        :return: The command's output
        """
        return self.cmd("sendkey %s %s" % (keystr, hold_time))

    def mouse_move(self, dx, dy):
        """
        Move mouse.

        :param dx: X amount
        :param dy: Y amount
        :return: The command's output
        """
        return self.cmd("mouse_move %s %s" % (dx, dy))

    def mouse_button(self, state):
        """
        Set mouse button state.

        :param state: Button state (1=L, 2=M, 4=R)
        :return: The command's output
        """
        return self.cmd("mouse_button %s" % state)

    def getfd(self, fd, name):
        """
        Receives a file descriptor

        :param fd: File descriptor to pass to QEMU
        :param name: File descriptor name (internal to QEMU)
        :return: The command's output
        """
        return self.cmd("getfd %s" % name, fd=fd)

    def system_wakeup(self):
        """
        Wakeup suspended guest.
        """
        cmd = "system_wakeup"
        self.verify_supported_cmd(cmd)
        return self.cmd(cmd)

    def nmi(self):
        """
        Inject a NMI on all guest's CPUs.
        """
        return self.cmd("nmi")

    def block_resize(self, device, size):
        """
        Resize the block device size

        :param device: Block device name
        :param size: Block device size need to set to. To keep the same with
                     qmp monitor will use bytes as unit for the block size
        :return: Command output
        """
        size = int(size) / 1024 / 1024
        cmd = "block_resize device=%s,size=%s" % (device, size)
        return self.send_args_cmd(cmd)

    def eject_cdrom(self, device, force=False):
        """
        Eject media of cdrom and open cdrom door;
        """
        cmd = "eject"
        self.verify_supported_cmd(cmd)
        if force:
            cmd += " -f "
        cmd += " %s" % device
        return self.cmd(cmd)

    def change_media(self, device, target):
        """
        Change media of cdrom of drive;
        """
        cmd = "change"
        self.verify_supported_cmd(cmd)
        cmd += " %s %s" % (device, target)
        return self.cmd(cmd)


class QMPMonitor(Monitor):

    """
    Wraps QMP monitor commands.
    """

    READ_OBJECTS_TIMEOUT = 5
    CMD_TIMEOUT = 120
    RESPONSE_TIMEOUT = 120
    PROMPT_TIMEOUT = 60

    def __init__(self, vm, name, filename, suppress_exceptions=False):
        """
        Connect to the monitor socket, read the greeting message and issue the
        qmp_capabilities command.  Also make sure the json module is available.

        :param vm: The VM which this monitor belongs to.
        :param name: Monitor identifier (a string)
        :param filename: Monitor socket filename

        :raise MonitorConnectError: Raised if the connection fails and
                suppress_exceptions is False
        :raise MonitorProtocolError: Raised if the no QMP greeting message is
                received and suppress_exceptions is False
        :raise MonitorNotSupportedError: Raised if json isn't available and
                suppress_exceptions is False
        :note: Other exceptions may be raised if the qmp_capabilities command
                fails.  See cmd()'s docstring.
        """
        try:
            Monitor.__init__(self, vm, name, filename)

            self.protocol = "qmp"
            self._greeting = None
            self._events = []
            self._supported_hmp_cmds = []

            # Make sure json is available
            try:
                json
            except NameError:
                raise MonitorNotSupportedError("QMP requires the json module "
                                               "(Python 2.6 and up)")

            # Read greeting message
            end_time = time.time() + 20
            output_str = ""
            while time.time() < end_time:
                for obj in self._read_objects():
                    output_str += str(obj)
                    if "QMP" in obj:
                        self._greeting = obj
                        break
                if self._greeting:
                    break
                time.sleep(0.1)
            else:
                raise MonitorProtocolError("No QMP greeting message received."
                                           " Output so far: %s" % output_str)

            # Issue qmp_capabilities
            self.cmd("qmp_capabilities")

            self._get_supported_cmds()
            self._get_supported_hmp_cmds()

        except MonitorError, e:
            self._close_sock()
            if suppress_exceptions:
                logging.warn(e)
            else:
                raise

    # Private methods
    def _build_cmd(self, cmd, args=None, q_id=None):
        obj = {"execute": cmd}
        if args is not None:
            obj["arguments"] = args
        if q_id is not None:
            obj["id"] = q_id
        return obj

    def _read_objects(self, timeout=READ_OBJECTS_TIMEOUT):
        """
        Read lines from the monitor and try to decode them.
        Stop when all available lines have been successfully decoded, or when
        timeout expires.  If any decoded objects are asynchronous events, store
        them in self._events.  Return all decoded objects.

        :param timeout: Time to wait for all lines to decode successfully
        :return: A list of objects
        """
        if not self._data_available():
            return []
        s = ""
        end_time = time.time() + timeout
        while self._data_available(end_time - time.time()):
            s += self._recvall()
            # Make sure all lines are decodable
            for line in s.splitlines():
                if line:
                    try:
                        json.loads(line)
                    except Exception:
                        # Found an incomplete or broken line -- keep reading
                        break
            else:
                # All lines are OK -- stop reading
                break
        # Decode all decodable lines
        objs = []
        for line in s.splitlines():
            try:
                objs += [json.loads(line)]
                self._log_lines(line)
            except Exception:
                pass
        # Keep track of asynchronous events
        self._events += [obj for obj in objs if "event" in obj]
        return objs

    def _send(self, data):
        """
        Send raw data without waiting for response.

        :param data: Data to send
        :raise MonitorSocketError: Raised if a socket error occurs
        """
        try:
            self._socket.sendall(data)
            self._log_lines(str(data))
        except socket.error, e:
            raise MonitorSocketError("Could not send data: %r" % data, e)

    def _get_response(self, q_id=None, timeout=RESPONSE_TIMEOUT):
        """
        Read a response from the QMP monitor.

        :param id: If not None, look for a response with this id
        :param timeout: Time duration to wait for response
        :return: The response dict, or None if none was found
        """
        end_time = time.time() + timeout
        while self._data_available(end_time - time.time()):
            for obj in self._read_objects():
                if isinstance(obj, dict):
                    if q_id is not None and obj.get("id") != q_id:
                        continue
                    if "return" in obj or "error" in obj:
                        return obj

    def _get_supported_cmds(self):
        """
        Get supported qmp cmds list.
        """
        cmds = self.cmd("query-commands", debug=False)
        if cmds:
            self._supported_cmds = [n["name"] for n in cmds if
                                    n.has_key("name")]

        if not self._supported_cmds:
            logging.warn("Could not get supported monitor cmds list")

    def _get_supported_hmp_cmds(self):
        """
        Get supported human monitor cmds list.
        """
        cmds = self.human_monitor_cmd("help", debug=False)
        if cmds:
            cmd_list = re.findall(
                r"(?:^\w+\|(\w+)\s)|(?:^(\w+?)\s)", cmds, re.M)
            self._supported_hmp_cmds = [(i + j) for i, j in cmd_list if i or j]

        if not self._supported_cmds:
            logging.warn("Could not get supported monitor cmds list")

    def _has_hmp_command(self, cmd):
        """
        Check wheter monitor support hmp 'cmd'.

        :param cmd: command string which will be checked.

        :return: True if cmd is supported, False if not supported.
        """
        if cmd and cmd in self._supported_hmp_cmds:
            return True
        return False

    def verify_supported_hmp_cmd(self, cmd):
        """
        Verify whether cmd is supported by hmp monitor.
        If not, raise a MonitorNotSupportedCmdError Exception.

        :param cmd: The cmd string need to verify.
        """
        if not self._has_hmp_command(cmd):
            raise MonitorNotSupportedCmdError(self.name, cmd)

    def _log_response(self, cmd, resp, debug=True):
        """
        Print log message for monitor cmd's response.

        :param cmd: Command string.
        :param resp: Response from monitor command.
        :param debug: Whether to print the commands.
        """
        def _log_output(o, indent=0):
            logging.debug("(monitor %s)    %s%s",
                          self.name, " " * indent, o)

        def _dump_list(li, indent=0):
            for l in li:
                if isinstance(l, dict):
                    _dump_dict(l, indent + 2)
                else:
                    _log_output(str(l), indent)

        def _dump_dict(di, indent=0):
            for k, v in di.iteritems():
                o = "%s%s: " % (" " * indent, k)
                if isinstance(v, dict):
                    _log_output(o, indent)
                    _dump_dict(v, indent + 2)
                elif isinstance(v, list):
                    _log_output(o, indent)
                    _dump_list(v, indent + 2)
                else:
                    o += str(v)
                    _log_output(o, indent)

        if self.debug_log or debug:
            logging.debug("(monitor %s) Response to '%s' "
                          "(re-formated)", self.name, cmd)
            if isinstance(resp, dict):
                _dump_dict(resp)
            elif isinstance(resp, list):
                _dump_list(resp)
            else:
                for l in str(resp).splitlines():
                    _log_output(l)

    # Public methods
    def cmd(self, cmd, args=None, timeout=CMD_TIMEOUT, debug=True, fd=None):
        """
        Send a QMP monitor command and return the response.

        Note: an id is automatically assigned to the command and the response
        is checked for the presence of the same id.

        :param cmd: Command to send
        :param args: A dict containing command arguments, or None
        :param timeout: Time duration to wait for response
        :param debug: Whether to print the commands being sent and responses
        :param fd: file object or file descriptor to pass

        :return: The response received

        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSocketError: Raised if a socket error occurs
        :raise MonitorProtocolError: Raised if no response is received
        :raise QMPCmdError: Raised if the response is an error message
                            (the exception's args are (cmd, args, data)
                            where data is the error data)
        """
        self._log_command(cmd, debug)
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to send "
                                   "QMP command '%s'" % cmd)

        try:
            # Read any data that might be available
            self._read_objects()
            # Send command
            q_id = utils_misc.generate_random_string(8)
            cmdobj = self._build_cmd(cmd, args, q_id)
            if debug:
                logging.debug("Send command: %s" % cmdobj)
            if fd is not None:
                if self._passfd is None:
                    self._passfd = passfd_setup.import_passfd()
                # If command includes a file descriptor, use passfd module
                self._passfd.sendfd(
                    self._socket, fd, json.dumps(cmdobj) + "\n")
            else:
                self._send(json.dumps(cmdobj) + "\n")
            # Read response
            r = self._get_response(q_id, timeout)
            if r is None:
                raise MonitorProtocolError("Received no response to QMP "
                                           "command '%s', or received a "
                                           "response with an incorrect id"
                                           % cmd)
            if "return" in r:
                ret = r["return"]
                if ret:
                    self._log_response(cmd, ret, debug)
                return ret
            if "error" in r:
                raise QMPCmdError(cmd, args, r["error"])

        finally:
            self._lock.release()

    def cmd_raw(self, data, timeout=CMD_TIMEOUT):
        """
        Send a raw string to the QMP monitor and return the response.
        Unlike cmd(), return the raw response dict without performing any
        checks on it.

        :param data: The data to send
        :param timeout: Time duration to wait for response
        :return: The response received
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSocketError: Raised if a socket error occurs
        :raise MonitorProtocolError: Raised if no response is received
        """
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to send "
                                   "data: %r" % data)

        try:
            self._read_objects()
            self._send(data)
            r = self._get_response(None, timeout)
            if r is None:
                raise MonitorProtocolError("Received no response to data: %r" %
                                           data)
            return r

        finally:
            self._lock.release()

    def cmd_obj(self, obj, timeout=CMD_TIMEOUT):
        """
        Transform a Python object to JSON, send the resulting string to the QMP
        monitor, and return the response.
        Unlike cmd(), return the raw response dict without performing any
        checks on it.

        :param obj: The object to send
        :param timeout: Time duration to wait for response
        :return: The response received
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSocketError: Raised if a socket error occurs
        :raise MonitorProtocolError: Raised if no response is received
        """
        return self.cmd_raw(json.dumps(obj) + "\n", timeout)

    def cmd_qmp(self, cmd, args=None, q_id=None, timeout=CMD_TIMEOUT):
        """
        Build a QMP command from the passed arguments, send it to the monitor
        and return the response.
        Unlike cmd(), return the raw response dict without performing any
        checks on it.

        :param cmd: Command to send
        :param args: A dict containing command arguments, or None
        :param id:  An id for the command, or None
        :param timeout: Time duration to wait for response
        :return: The response received
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSocketError: Raised if a socket error occurs
        :raise MonitorProtocolError: Raised if no response is received
        """
        return self.cmd_obj(self._build_cmd(cmd, args, q_id), timeout)

    def verify_responsive(self):
        """
        Make sure the monitor is responsive by sending a command.
        """
        self.cmd(cmd="query-status", debug=False)

    def get_status(self):
        """
        Get VM status.

        :return: return VM status
        """
        return self.cmd(cmd="query-status", debug=False)

    def verify_status(self, status):
        """
        Verify VM status

        :param status: Optional VM status, 'running' or 'paused'
        :return: return True if VM status is same as we expected
        """
        o = dict(self.cmd(cmd="query-status", debug=False))
        if status == 'paused':
            return (o['running'] is False)
        if status == 'running':
            return (o['running'] is True)
        if o['status'] == status:
            return True
        return False

    def get_events(self):
        """
        Return a list of the asynchronous events received since the last
        clear_events() call.

        :return: A list of events (the objects returned have an "event" key)
        :raise MonitorLockError: Raised if the lock cannot be acquired
        """
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to read "
                                   "QMP events")
        try:
            self._read_objects()
            return self._events[:]
        finally:
            self._lock.release()

    def get_event(self, name):
        """
        Look for an event with the given name in the list of events.

        :param name: The name of the event to look for (e.g. 'RESET')
        :return: An event object or None if none is found
        """
        for e in self.get_events():
            if e.get("event") == name:
                return e

    def human_monitor_cmd(self, cmd="", timeout=CMD_TIMEOUT,
                          debug=True, fd=None):
        """
        Run human monitor command in QMP through human-monitor-command

        :param cmd: human monitor command.
        :param timeout: Time duration to wait for response
        :param debug: Whether to print the commands being sent and responses
        :param fd: file object or file descriptor to pass

        :return: The response to the command
        """
        self._log_command(cmd, extra_str="(via Human Monitor)")

        args = {"command-line": cmd}
        ret = self.cmd("human-monitor-command", args, timeout, False, fd)

        if ret:
            self._log_response(cmd, ret, debug)
        return ret

    def clear_events(self):
        """
        Clear the list of asynchronous events.

        :raise MonitorLockError: Raised if the lock cannot be acquired
        """
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to clear "
                                   "QMP event list")
        self._events = []
        self._lock.release()

    def clear_event(self, name):
        """
        Clear a kinds of events in events list only.

        :raise MonitorLockError: Raised if the lock cannot be acquired
        """
        if not self._acquire_lock():
            raise MonitorLockError("Could not acquire exclusive lock to clear "
                                   "QMP event list")
        while True:
            event = self.get_event(name)
            if event:
                self._events.remove(event)
            else:
                break
        self._lock.release()

    def get_greeting(self):
        """
        Return QMP greeting message.
        """
        return self._greeting

    # Command wrappers
    # Note: all of the following functions raise exceptions in a similar manner
    # to cmd().
    def send_args_cmd(self, cmdlines, timeout=CMD_TIMEOUT, convert=True):
        """
        Send a command with/without parameters and return its output.
        Have same effect with cmd function.
        Implemented under the same name for both the human and QMP monitors.
        Command with parameters should in following format e.g.:
        'memsave val=0 size=10240 filename=memsave'
        Command without parameter: 'query-vnc'

        :param cmdlines: Commands send to qemu which is separated by ";". For
                         command with parameters command should send in a string
                         with this format:
                         $command $arg_name=$arg_value $arg_name=$arg_value
        :param timeout: Time duration to wait for (qemu) prompt after command
        :param convert: If command need to convert. For commands not in standard
                        format such as: $command $arg_value
        :return: The response to the command
        :raise MonitorLockError: Raised if the lock cannot be acquired
        :raise MonitorSendError: Raised if the command cannot be sent
        :raise MonitorProtocolError: Raised if no response is received
        """
        cmd_output = []
        for cmdline in cmdlines.split(";"):
            command = cmdline.split()[0]
            if not self._has_command(command):
                if "=" in cmdline:
                    command = cmdline.split()[0]
                    self.verify_supported_hmp_cmd(command)

                    cmdargs = " ".join(cmdline.split()[1:]).split(",")
                    for arg in cmdargs:
                        value = "=".join(arg.split("=")[1:])
                        if arg.split("=")[0] == "cert-subject":
                            value = value.replace('/', ',')

                        command += " " + value
                else:
                    command = cmdline
                cmd_output.append(self.human_monitor_cmd(command))
            else:
                cmdargs = " ".join(cmdline.split()[1:]).split(",")
                args = {}
                for arg in cmdargs:
                    opt = arg.split('=')
                    value = "=".join(opt[1:])
                    try:
                        if re.match("^[0-9]+$", value):
                            value = int(value)
                        elif re.match("^[0-9]+\.[0-9]*$", value):
                            value = float(value)
                        elif re.findall("true", value, re.I):
                            value = True
                        elif re.findall("false", value, re.I):
                            value = False
                        else:
                            value = value.strip()
                        if opt[0] == "cert-subject":
                            value = value.replace('/', ',')
                        if opt[0]:
                            args[opt[0].strip()] = value
                    except:
                        logging.debug("Fail to create args, please check cmd")
                cmd_output.append(self.cmd(command, args, timeout=timeout))
        if len(cmd_output) == 1:
            return cmd_output[0]
        return cmd_output

    def quit(self):
        """
        Send "quit" and return the response.
        """
        return self.cmd("quit")

    def info(self, what, debug=True):
        """
        Request info about something and return the response.
        """
        cmd = "query-%s" % what
        if not self._has_command(cmd):
            cmd = "info %s" % what
            return self.human_monitor_cmd(cmd, debug=debug)

        return self.cmd(cmd, debug=debug)

    def query(self, what, debug=True):
        """
        Alias for info.
        """
        return self.info(what, debug)

    def screendump(self, filename, debug=True):
        """
        Request a screendump.

        :param filename: Location for the screendump
        :param debug: Whether to print the commands being sent and responses

        :return: The response to the command
        """
        cmd = "screendump"
        if not self._has_command(cmd):
            self.verify_supported_hmp_cmd(cmd)
            cmdline = "%s %s" % (cmd, filename)
            return self.human_monitor_cmd(cmdline, debug=debug)

        args = {"filename": filename}
        return self.cmd(cmd=cmd, args=args, debug=debug)

    def sendkey(self, keystr, hold_time=1):
        """
        Send key combination to VM.

        :param keystr: Key combination string
        :param hold_time: Hold time in ms (should normally stay 1 ms)

        :return: The response to the command
        """
        return self.human_monitor_cmd("sendkey %s %s" % (keystr, hold_time))

    def migrate(self, uri, full_copy=False, incremental_copy=False, wait=False):
        """
        Migrate.

        :param uri: destination URI
        :param full_copy: If true, migrate with full disk copy
        :param incremental_copy: If true, migrate with incremental disk copy
        :param wait: If true, wait for completion
        :return: The response to the command
        """
        args = {"uri": uri,
                "blk": full_copy,
                "inc": incremental_copy}
        args['uri'] = re.sub('"', "", args['uri'])
        try:
            return self.cmd("migrate", args)
        except QMPCmdError, e:
            if e.data['class'] in ['SockConnectInprogress', 'GenericError']:
                logging.debug(
                    "Migrate socket connection still initializing...")
            else:
                raise e

    def migrate_set_speed(self, value):
        """
        Set maximum speed (in bytes/sec) for migrations.

        :param value: Speed in bytes/sec
        :return: The response to the command
        """
        value = utils.convert_data_size(value, "M")
        args = {"value": value}
        return self.cmd("migrate_set_speed", args)

    def set_link(self, name, up):
        """
        Set link up/down.

        :param name: Link name
        :param up: Bool value, True=set up this link, False=Set down this link

        :return: The response to the command
        """
        return self.send_args_cmd("set_link name=%s,up=%s" % (name, str(up)))

    def migrate_set_downtime(self, value):
        """
        Set maximum tolerated downtime (in seconds) for migration.

        :param value: maximum downtime (in seconds)

        :return: The command's output
        """
        val = value * 10 ** 9
        args = {"value": val}
        return self.cmd("migrate_set_downtime", args)

    def live_snapshot(self, device, snapshot_file, snapshot_format="qcow2"):
        """
        Take a live disk snapshot.

        :param device: device id of base image
        :param snapshot_file: image file name of snapshot
        :param snapshot_format: image format of snapshot

        :return: The response to the command
        """
        args = {"device": device,
                "snapshot-file": snapshot_file,
                "format": snapshot_format}
        return self.cmd("blockdev-snapshot-sync", args)

    def block_stream(self, device, speed=None, base=None,
                     cmd="block-stream", correct=True):
        """
        Start block-stream job;

        :param device: device ID
        :param speed: int type, limited speed(B/s)
        :param base: base file
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = {"device": device}
        if speed is not None:
            args["speed"] = speed
        if base:
            args["base"] = base
        return self.cmd(cmd, args)

    def set_block_job_speed(self, device, speed=0,
                            cmd="block-job-set-speed", correct=True):
        """
        Set limited speed for runnig job on the device

        :param device: device ID
        :param speed: int type, limited speed(B/s)
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = {"device": device,
                "speed": speed}
        return self.cmd(cmd, args)

    def cancel_block_job(self, device, cmd="block-job-cancel", correct=True):
        """
        Cancel running block stream/mirror job on the device

        :param device: device ID
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = {"device": device}
        return self.cmd(cmd, args)

    def query_block_job(self, device):
        """
        Get block job status on the device

        :param device: device ID

        :return: dict about job info, return empty dict if no active job
        """
        job = dict()
        output = str(self.info("block-jobs"))
        try:
            job = filter(lambda x: x.get("device") == device,
                         eval(output))[0]
        except Exception:
            pass
        return job

    def get_backingfile(self, device):
        """
        Return "backing_file" path of the device

        :param device: device ID

        :return: string, backing_file path
        """
        backing_file = None
        block_info = self.query("block")
        try:
            image_info = filter(lambda x: x["device"] == device, block_info)[0]
            backing_file = image_info["inserted"].get("backing_file")
        except Exception:
            pass
        return backing_file

    def block_mirror(self, device, target, speed, sync, format, mode,
                     cmd="drive-mirror", correct=True):
        """
        Start mirror type block device copy job

        :param device: device ID
        :param target: target image
        :param speed: limited speed, unit is B/s
        :param sync: what parts of the disk image should be copied to the
                     destination;
        :param mode: 'absolute-paths' or 'existing'
        :param format: target image format
        :param cmd: block mirror command
        :param correct: auto correct command, correct by default

        :return: The command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = {"device": device,
                "target": target}
        if cmd.startswith("__com.redhat"):
            args["full"] = sync
        else:
            args["sync"] = sync
        if mode:
            args["mode"] = mode
        if format:
            args["format"] = format
        if speed:
            args["speed"] = speed
        return self.cmd(cmd, args)

    def block_reopen(self, device, new_image_file, image_format,
                     cmd="block-job-complete", correct=True):
        """
        Reopen new target image;

        :param device: device ID
        :param new_image_file: new image file name
        :param image_format: new image file format
        :param cmd: image reopen command
        :param correct: auto correct command, correct by default

        :return: the command's output
        """
        if correct:
            cmd = self.correct(cmd)
        self.verify_supported_cmd(cmd)
        args = {"device": device}
        if cmd.startswith("__"):
            args["new-image-file"] = new_image_file
            args["format"] = image_format
        return self.cmd(cmd, args)

    def getfd(self, fd, name):
        """
        Receives a file descriptor

        :param fd: File descriptor to pass to QEMU
        :param name: File descriptor name (internal to QEMU)

        :return: The response to the command
        """
        args = {"fdname": name}
        return self.cmd("getfd", args, fd=fd)

    def system_wakeup(self):
        """
        Wakeup suspended guest.
        """
        cmd = "system_wakeup"
        self.verify_supported_cmd(cmd)
        return self.cmd(cmd)

    def nmi(self):
        """
        Inject a NMI on all guest's CPUs.
        """
        return self.cmd("inject-nmi")

    def block_resize(self, device, size):
        """
        Resize the block device size

        :param device: Block device name
        :param size: Block device size need to set to. Unit is bytes.
        :return: Command output
        """
        cmd = "block_resize device=%s,size=%s" % (device, size)
        return self.send_args_cmd(cmd)

    def eject_cdrom(self, device, force=False):
        """
        Eject media of cdrom and open cdrom door;
        """
        cmd = "eject"
        self.verify_supported_cmd(cmd)
        args = {"device": device, "force": force}
        return self.cmd(cmd, args)

    def change_media(self, device, target):
        """
        Change media of cdrom of drive;
        """
        cmd = "change"
        self.verify_supported_cmd(cmd)
        args = {"device": device, "target": target}
        return self.cmd(cmd, args)

########NEW FILE########
__FILENAME__ = qemu_monitor_unittest
import unittest

import common
from qemu_monitor import Monitor
import qemu_monitor


class MockMonitor(qemu_monitor.Monitor):

    """ Dummy class inherited from qemu_monitor.HumanMonitor """

    def __init__(self):     # pylint: disable=W0231
        pass

    def __del__(self):
        pass


class InfoNumaTests(unittest.TestCase):

    def testZeroNodes(self):
        d = "0 nodes\n"
        r = Monitor.parse_info_numa(d)
        self.assertEquals(r, [])

    def testTwoNodes(self):
        d = "2 nodes\n" + \
            "node 0 cpus: 0 2 4\n" + \
            "node 0 size: 12 MB\n" + \
            "node 1 cpus: 1 3 5\n" + \
            "node 1 size: 34 MB\n"
        r = Monitor.parse_info_numa(d)
        self.assertEquals(r, [(12, set([0, 2, 4])),
                              (34, set([1, 3, 5]))])


class InfoBlocks(unittest.TestCase):

    def testParseBlocks(self):
        info_1_4 = """ide0-hd0: removable=0 io-status=ok file=c.qcow2 backing_file=b.qcow2 backing_file_depth=2 ro=0 drv=qcow2 encrypted=0 bps=0 bps_rd=0 bps_wr=0 iops=0 iops_rd=0 iops_wr=0
scsi0-hd0: removable=0 io-status=ok file=a.qcow ro=1 drv=raw encrypted=0 bps=0 bps_rd=0 bps_wr=0 iops=0 iops_rd=0 iops_wr=0
scsi0-hd1: removable=0 io-status=ok file=enc.qcow2 ro=0 drv=qcow2 encrypted=1 bps=0 bps_rd=0 bps_wr=0 iops=0 iops_rd=0 iops_wr=0
ide1-cd0: removable=1 locked=0 tray-open=0 io-status=ok [not inserted]
floppy0: removable=1 locked=0 tray-open=0 [not inserted]
sd0: removable=1 locked=0 tray-open=0 [not inserted]"""
        info_1_5 = """ide0-hd0: c.qcow2 (qcow2)
    Backing file:     b.qcow2 (chain depth: 2)

scsi0-hd0: a.qcow (raw, read-only)

scsi0-hd1: enc.qcow2 (qcow2, encrypted)

ide1-cd0: [not inserted]
    Removable device: not locked, tray closed

floppy0: [not inserted]
    Removable device: not locked, tray closed

sd0: [not inserted]
    Removable device: not locked, tray closed"""
        info_qmp = [{"io-status": "ok", "device": "ide0-hd0", "locked":
                     False, "removable": False, "inserted": {"iops_rd": 0,
                                                             "iops_wr": 0, "ro": False, "backing_file_depth": 2,
                                                             "drv": "qcow2", "iops": 0, "bps_wr": 0, "backing_file":
                                                             "b.qcow2", "encrypted": False, "bps": 0, "bps_rd": 0,
                                                             "file": "c.qcow2", "encryption_key_missing": False},
                     "type": "unknown"}, {"io-status": "ok", "device":
                                          "scsi0-hd0", "locked": False, "removable": False,
                                          "inserted": {"iops_rd": 0, "iops_wr": 0, "ro": True,
                                                       "backing_file_depth": 0, "drv": "raw", "iops": 0,
                                                       "bps_wr": 0, "encrypted": False, "bps": 0, "bps_rd": 0,
                                                       "file": "a.qcow", "encryption_key_missing": False},
                                          "type": "unknown"}, {"io-status": "ok", "device":
                                                               "scsi0-hd1", "locked": False, "removable": False,
                                                               "inserted": {"iops_rd": 0, "iops_wr": 0, "ro": False,
                                                                            "backing_file_depth": 0, "drv": "qcow2", "iops": 0,
                                                                            "bps_wr": 0, "encrypted": True, "bps": 0, "bps_rd": 0,
                                                                            "file": "enc.qcow2", "encryption_key_missing": True},
                                                               "type": "unknown"}, {"io-status": "ok", "device":
                                                                                    "ide1-cd0", "locked": False, "removable": True,
                                                                                    "tray_open": False, "type": "unknown"}, {"device":
                                                                                                                             "floppy0", "locked": False, "removable": True,
                                                                                                                             "tray_open": False, "type": "unknown"}, {"device": "sd0",
                                                                                                                                                                      "locked": False, "removable": True, "tray_open": False,
                                                                                                                                                                      "type": "unknown"}]
        monitor = MockMonitor()

        # Test "info block" version 1.4
        monitor.info = lambda _what, _debug: info_1_4
        out1 = monitor.info_block()
        exp = {'sd0': {'tray-open': 0, 'locked': 0, 'not-inserted': 1,
                       'removable': 1},
               'ide0-hd0': {'bps_rd': 0, 'backing_file_depth': 2,
                            'removable': 0, 'encrypted': 0, 'bps_wr': 0,
                            'io-status': 'ok', 'drv': 'qcow2', 'bps': 0,
                            'iops': 0, 'file': 'c.qcow2', 'iops_rd': 0,
                            'ro': 0, 'backing_file': 'b.qcow2', 'iops_wr': 0},
               'floppy0': {'tray-open': 0, 'locked': 0, 'not-inserted': 1,
                           'removable': 1},
               'ide1-cd0': {'tray-open': 0, 'locked': 0, 'not-inserted': 1,
                            'io-status': 'ok', 'removable': 1},
               'scsi0-hd0': {'bps_rd': 0, 'removable': 0, 'encrypted': 0,
                             'bps_wr': 0, 'io-status': 'ok', 'drv': 'raw',
                             'bps': 0, 'iops': 0, 'file': 'a.qcow',
                             'iops_rd': 0, 'ro': 1, 'iops_wr': 0},
               'scsi0-hd1': {'bps_rd': 0, 'removable': 0, 'encrypted': 1,
                             'bps_wr': 0, 'io-status': 'ok', 'drv': 'qcow2',
                             'bps': 0, 'iops': 0, 'file': 'enc.qcow2',
                             'iops_rd': 0, 'ro': 0, 'iops_wr': 0}}
        assert out1 == exp, ("Info block of qemu 1.4 is parsed incorrectly\n%s"
                             "\n%s" % (out1, exp))

        # Test "info block" version 1.5
        monitor.info = lambda _what, _debug: info_1_5
        out2 = monitor.info_block()
        exp = {'sd0': {'not-inserted': 1, 'removable': 1},
               'ide0-hd0': {'backing_file_depth': 2, 'drv': 'qcow2',
                            'backing_file': 'b.qcow2', 'file': 'c.qcow2'},
               'floppy0': {'not-inserted': 1, 'removable': 1},
               'ide1-cd0': {'not-inserted': 1, 'removable': 1},
               'scsi0-hd0': {'drv': 'raw', 'ro': 1, 'file': 'a.qcow'},
               'scsi0-hd1': {'encrypted': 1, 'drv': 'qcow2',
                             'file': 'enc.qcow2'}}
        assert out2 == exp, ("Info block of qemu 1.5 is parsed incorrectly\n%s"
                             "\n%s" % (out2, exp))

        # verify, that booth representation gives the same results
        # (qemu-1.5 is less informative so not all params are checked)
        for name, params in out2.iteritems():
            assert name in out1, ("missing disk '%s' in info-1.5\n%s\n%s"
                                  % (name, out2, out1))
            for key, value in params.iteritems():
                assert out1[name].get(key, 0) == value, ("value of disk %s "
                                                         "mismatch in info-1.5 %s=%s (%s)\n%s\n%s"
                                                         % (name, key, value, out1[
                                                             name].get(key, 0),
                                                            out2, out1))

        # Test "query-block" qmp version
        monitor.info = lambda _what, _debug: info_qmp
        out3 = monitor.info_block()
        exp = {'sd0': {'type': 'unknown', 'tray_open': False,
                       'not-inserted': True, 'removable': True,
                       'locked': False},
               'ide0-hd0': {'bps_rd': 0, 'backing_file_depth': 2,
                            'removable': False, 'type': 'unknown',
                            'encrypted': False, 'bps_wr': 0, 'locked': False,
                            'drv': 'qcow2', 'bps': 0, 'iops': 0,
                            'io-status': 'ok', 'file': 'c.qcow2',
                            'iops_rd': 0, 'encryption_key_missing': False,
                            'ro': False, 'backing_file': 'b.qcow2',
                            'iops_wr': 0},
               'floppy0': {'type': 'unknown', 'tray_open': False,
                           'not-inserted': True, 'removable': True,
                           'locked': False},
               'ide1-cd0': {'locked': False, 'tray_open': False,
                            'io-status': 'ok', 'removable': True,
                            'not-inserted': True, 'type': 'unknown'},
               'scsi0-hd0': {'bps_rd': 0, 'backing_file_depth': 0,
                             'removable': False, 'encrypted': False,
                             'bps_wr': 0, 'locked': False, 'drv': 'raw',
                             'bps': 0, 'iops': 0, 'io-status': 'ok',
                             'file': 'a.qcow', 'iops_rd': 0,
                             'encryption_key_missing': False, 'ro': True,
                             'type': 'unknown', 'iops_wr': 0},
               'scsi0-hd1': {'bps_rd': 0, 'backing_file_depth': 0,
                             'removable': False, 'encrypted': True,
                             'bps_wr': 0, 'locked': False, 'drv': 'qcow2',
                             'bps': 0, 'iops': 0, 'io-status': 'ok',
                             'file': 'enc.qcow2', 'iops_rd': 0,
                             'encryption_key_missing': True, 'ro': False,
                             'type': 'unknown', 'iops_wr': 0}}
        assert out3 == exp, ("QMP query-block of qemu is parsed incorrectly\n"
                             "%s\n%s" % (out3, exp))

        # verify, that booth representation gives the same results
        # (qemu-1.4 is less informative so not all params are checked)
        for name, params in out1.iteritems():
            assert name in out3, ("missing disk '%s' in info-1.5\n%s\n%s"
                                  % (name, out1, out3))
            for key, value in params.iteritems():
                assert out3[name].get(key, 0) == value, ("value of disk %s "
                                                         "mismatch in QMP version %s=%s (%s)\n%s\n%s"
                                                         % (name, key, value, out3[
                                                             name].get(key, 0),
                                                            out1, out3))


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = qemu_qtree
"""
Utility classes and functions to handle KVM Qtree parsing and verification.

:author: Lukas Doktor <ldoktor@redhat.com>
:copyright: 2012 Red Hat Inc.
"""
import logging
import os
import re
import storage
import data_dir
import utils_misc
import arch


OFFSET_PER_LEVEL = 2

_RE_BLANKS = re.compile(r'^([ ]*)')
_RE_CLASS = re.compile(r'^class ([^,]*), addr (\w\w:\w\w.\w+), pci id '
                       '(\w{4}:\w{4}) \(sub (\w{4}:\w{4})\)')


class IncompatibleTypeError(TypeError):

    def __init__(self, prop, desired_type, value):
        TypeError.__init__(self)
        self.prop = prop
        self.desired = desired_type
        self.value = value

    def __str__(self):
        return "%s have to be %s, not %s" % (self.prop, type(self.desired),
                                             type(self.value))


class QtreeNode(object):

    """
    Generic Qtree node
    """

    def __init__(self):
        self.parent = None      # Parent node
        self.qtree = {}         # List of qtree attributes
        self.children = []     # List of child nodes
        self.params = {}        # generated params from qtree

    def __str__(self):
        out = self.str_short()
        if self.parent:
            out += "\n[parent]\n %s" % self.parent.str_short()
        if self.qtree:
            out += "\n[info qtree]"
        for tmp in self.qtree.iteritems():
            out += "\n %s = %s" % (tmp[0], tmp[1])
        if self.children:
            out += "\n[children]"
        for tmp in self.children:
            out += "\n %s" % tmp.str_short()
        if self.params:
            out += "\n[params]"
        for tmp in self.params.iteritems():
            out += "\n %s = %s" % (tmp[0], [tmp[1]])
        return out

    def set_parent(self, parent):
        if not isinstance(parent, QtreeNode) and parent is not None:
            raise IncompatibleTypeError('parent', QtreeNode(), parent)
        self.parent = parent

    def get_parent(self):
        return self.parent

    def add_child(self, child):
        if not isinstance(child, QtreeNode):
            raise IncompatibleTypeError('child', QtreeNode(), child)
        self.children.append(child)

    def replace_child(self, oldchild, newchild):
        if oldchild not in self.children:
            raise ValueError('child %s not in children %s' % (oldchild,
                                                              self.children))
        self.add_child(newchild)
        self.children.remove(oldchild)

    def get_children(self):
        return self.children

    def set_qtree(self, qtree):
        if not isinstance(qtree, dict):
            raise IncompatibleTypeError('qtree', {}, qtree)
        self.qtree = qtree

    def set_qtree_prop(self, prop, value):
        if prop in self.qtree:
            raise ValueError("Property %s = %s, not rewriting with %s" % (prop,
                                                                          self.qtree.get(prop), value))
        self.update_qtree_prop(prop, value)

    def update_qtree_prop(self, prop, value):
        if prop.startswith("bus-prop: "):
            prop = prop[10:]
        if prop.startswith("dev-prop: "):
            prop = prop[10:]
        self.qtree[prop] = value

    def get_qtree(self):
        return self.qtree

    def guess_type(self):
        """ Detect type of this object from qtree props """
        return QtreeNode

    def str_short(self):
        return "id: '%s', type: %s" % (self.qtree.get('id'), type(self))

    def str_qtree(self):
        out = "%s" % self.str_short()
        for child in self.children:
            for line in child.str_qtree().splitlines():
                out += "\n  %s" % line
        return out

    def generate_params(self):
        pass

    def get_params(self):
        return self.params

    def update_params(self, param, value):
        self.params[param] = value

    def verify(self):
        pass


class QtreeBus(QtreeNode):

    """ bus: qtree object """

    def __init__(self):
        super(QtreeBus, self).__init__()

    def add_child(self, child):
        if not isinstance(child, QtreeDev):
            raise IncompatibleTypeError('child', QtreeDev(), child)
        super(QtreeBus, self).add_child(child)

    def guess_type(self):
        return QtreeBus


class QtreeDev(QtreeNode):

    """ dev: qtree object """

    def __init__(self):
        super(QtreeDev, self).__init__()

    def add_child(self, child):
        if not isinstance(child, QtreeBus):
            raise IncompatibleTypeError('child', QtreeBus(), child)
        super(QtreeDev, self).add_child(child)

    def guess_type(self):
        if ('drive' in self.qtree and
                self.qtree['type'] != 'usb-storage' and
                self.qtree['type'] != 'virtio-blk-device'):
            # ^^ HOOK when usb-storage-containter is detected as disk
            return QtreeDisk
        else:
            return QtreeDev


class QtreeDisk(QtreeDev):

    """ qtree disk object """

    def __init__(self):
        super(QtreeDisk, self).__init__()
        self.block = {}     # Info from 'info block'

    def __str__(self):
        out = super(QtreeDisk, self).__str__()
        if self.block:
            out += "\n[info block]"
        for tmp in self.block.iteritems():
            out += "\n%s = %s" % (tmp[0], tmp[1])
        return out

    def set_block_prop(self, prop, value):
        if prop in self.block:
            raise ValueError("Property %s = %s, not rewriting with %s" % (prop,
                                                                          self.block.get(prop), value))
        self.update_block_prop(prop, value)

    def update_block_prop(self, prop, value):
        if prop.startswith("bus-prop: "):
            prop = prop[10:]
        if prop.startswith("dev-prop: "):
            prop = prop[10:]
        self.block[prop] = value

    def get_block(self):
        return self.block

    def generate_params(self):
        if not self.qtree or not self.block:
            raise ValueError("Node doesn't have qtree or block info yet.")
        if self.block.get('backing_file'):
            self.params['image_snapshot'] = 'yes'
            self.params['image_name'] = os.path.realpath(
                self.block.get('backing_file'))
        elif self.block.get('file'):
            self.params['image_name'] = os.path.realpath(
                self.block.get('file'))
        else:
            raise ValueError("Missing 'file' or 'backing_file' information "
                             "in self.block.")
        if self.block.get('ro') and self.block.get('ro') != '0':
            self.params['image_readonly'] = 'yes'
        self.params['drive_format'] = self.qtree.get('type')

    def get_qname(self):
        return self.qtree.get('drive')


class QtreeContainer(object):

    """ Container for Qtree """

    def __init__(self):
        self.nodes = None

    def get_qtree(self):
        """ :return: root of qtree """
        if self.nodes:
            return self.nodes[-1]

    def get_nodes(self):
        """
        :return: flat list of all qtree nodes (last one is main-system-bus)
        """
        return self.nodes

    def parse_info_qtree(self, info):
        """
        Parses 'info qtree' output. Creates list of self.nodes. Last node is
        the main-system-bus (whole qtree)
        """
        def _replace_node(old, newtype):
            if isinstance(old, newtype):
                return old
            new = newtype()
            new.set_parent(old.get_parent())
            new.get_parent().replace_child(old, new)
            new.set_qtree(old.get_qtree())
            for child in old.get_children():
                child.set_parent(new)
                new.add_child(child)
            return new

        def _hook_usb2_disk(node):
            """
            usb2 disk - from point of qtree - is scsi disk inside the
            usb-storage device.
            """
            # We're looking for scsi disk with grand-grand parent of
            # usb sorage type
            if not isinstance(node, QtreeDisk):
                return  # Not a disk
            if not node.get_qtree().get('type').startswith('scsi'):
                return  # Not scsi disk
            if not (node.get_parent() and node.get_parent().get_parent()):
                return  # Doesn't have grand-grand parent
            if not (node.get_parent().get_parent().get_qtree().get('type') ==
                    'usb-storage'):
                return  # grand-grand parent is not usb-storage
            # This disk is not scsi disk, it's virtual usb-storage drive
            node.update_qtree_prop('type', 'usb2')
        info = info.split('\n')
        current = None
        offset = 0
        self.nodes = []
        line = info.pop(0)
        while True:
            _offset = len(_RE_BLANKS.match(line).group(0))
            if not line.strip():
                if len(info) == 0:
                    break
                line = info.pop(0)
                continue
            if _offset >= offset:
                offset = _offset
                line = line[offset:]
                # Strip out all dev-prop/bus-prop/...
                # bus/dev/prop
                if line.startswith('bus: '):
                    # bus: scsi.0
                    new = QtreeBus()
                    if current:
                        current.add_child(new)
                        new.set_parent(current)
                    current = new
                    offset += OFFSET_PER_LEVEL
                    line = ['id', line[5:].strip()]
                elif line.startswith('dev: '):
                    # dev: scsi-disk, id ""
                    new = QtreeDev()
                    if current:
                        current.add_child(new)
                        new.set_parent(current)
                    current = new
                    line = line[5:].split(',')
                    line[1] = line[1].strip()
                    q_id = line[1][4:-1]
                    if len(q_id) > 0:
                        current.set_qtree_prop('id', q_id)
                    offset += OFFSET_PER_LEVEL
                    line = ['type', line[0]]
                elif _RE_CLASS.match(line):
                    # class IDE controller, addr 00:01.1, pci id 8086:7010 (..
                    line = _RE_CLASS.match(line).groups()
                    current.set_qtree_prop('class_addr', line[1])
                    current.set_qtree_prop('class_pciid', line[2])
                    current.set_qtree_prop('class_sub', line[3])
                    line = ['class_name', line[0]]
                elif '=' in line:
                    # bus-prop: addr = 02.0
                    line = line.split('=', 1)
                elif ':' in line:
                    # bar 0: i/o at 0xc280 [0xc2bf]
                    line = line.split(':', 1)
                elif ' ' in line:
                    # mmio ffffffffffffffff/0000000000100000
                    line = line.split(' ', 1)
                    # HOOK: mmio can have multiple values
                    if line[0] == 'mmio':
                        if 'mmio' not in current.qtree:
                            current.set_qtree_prop('mmio', [])
                        current.qtree['mmio'].append(line[1])
                        line = None
                else:
                    # Corrupted qtree
                    raise ValueError('qtree line not recognized:\n%s' % line)
                if line:
                    current.set_qtree_prop(line[0].strip(), line[1].strip())
                if len(info) == 0:
                    break
                line = info.pop(0)
            else:
                # Node can be of different type
                current = _replace_node(current, current.guess_type())
                self.nodes.append(current)
                current = current.get_parent()
                offset -= OFFSET_PER_LEVEL
        # Read out remaining self.nodes
        while offset > 0:
            current = _replace_node(current, current.guess_type())
            self.nodes.append(current)
            current = current.get_parent()
            offset -= OFFSET_PER_LEVEL
        # This is the place to put HOOKs for nasty qtree devices
        for i in xrange(len(self.nodes)):
            _hook_usb2_disk(self.nodes[i])


class QtreeDisksContainer(object):

    """
    Container for QtreeDisks verification.
    It's necessary because some information can be verified only from
    informations about all disks, not only from single disk.
    """

    def __init__(self, nodes):
        """ work only with QtreeDisks instances """
        self.disks = []
        for node in nodes:
            if isinstance(node, QtreeDisk):
                if node.get_qname() != '<null>':
                    self.disks.append(node)

    def parse_info_block(self, info):
        """
        Extracts all information about self.disks and fills them in.

        :param info: output of ``info block`` command
        :return: ``self.disks`` defined in qtree but not in ``info block``,
                 ``self.disks`` defined in ``block info`` but not in qtree
        """
        additional = 0
        missing = 0
        for i in xrange(len(self.disks)):
            disk = self.disks[i]
            name = disk.get_qname()
            if name not in info:
                logging.error("disk %s is in block but not in qtree", name)
                missing += 1
                continue
            for prop, value in info[name].iteritems():
                disk.set_block_prop(prop, value)
        for disk in self.disks:
            if disk.get_block() == {}:
                logging.error("disk in qtree but not in info block\n%s", disk)
                additional += 1
        return (additional, missing)

    def generate_params(self):
        """
        Generate params from current self.qtree and self.block info.
        :note: disk name is not yet the one from autotest params
        :return: number of fails
        """
        err = 0
        for disk in self.disks:
            try:
                disk.generate_params()
            except ValueError:
                logging.error("generate_params error: %s", disk)
                err += 1
        return err

    def check_guests_proc_scsi(self, info):
        """
        Check info from guest's /proc/scsi/scsi file with qtree/block info

        :note: Not tested disks are of different type (virtio_blk, ...)
        :param info: contents of guest's /proc/scsi/scsi file
        :return: Number of disks missing in guest os, disks missing in qtree,
                 disks not tested from qtree, disks not tested from guest)
        """
        # Check only channel, id and lun for now
        additional = 0
        missing = 0
        qtree_not_scsi = 0
        proc_not_scsi = 0
        # host, channel, id, lun, vendor
        _scsis = re.findall(r'Host:\s+(\w+)\s+Channel:\s+(\d+)\s+Id:\s+(\d+)'
                            '\s+Lun:\s+(\d+)\n\s+Vendor:\s+([a-zA-Z0-9_-]+)'
                            '\s+Model:.*\n.*Type:\s+([a-zA-Z0-9_-]+)', info)
        disks = set()
        # Check only scsi disks
        for disk in self.disks:
            if (disk.get_qtree()['type'].startswith('scsi') or
                    disk.get_qtree()['type'].startswith('usb2')):
                props = disk.get_qtree()
                disks.add('%d-%d-%d' % (int(props.get('channel')),
                                        int(props.get('scsi-id')),
                                        int(props.get('lun'))))
            else:
                qtree_not_scsi += 1
        scsis = set()
        for scsi in _scsis:
            # Ignore IDE disks
            if scsi[5] != 'CD-ROM':
                scsis.add("%d-%d-%d" % (int(scsi[1]), int(scsi[2]),
                                        int(scsi[3])))
            else:
                proc_not_scsi += 1
        for disk in disks.difference(scsis):
            logging.error('Disk %s is in qtree but not in /proc/scsi/scsi.',
                          disk)
            additional += 1
        for disk in scsis.difference(disks):
            logging.error('Disk %s is in /proc/scsi/scsi but not in qtree.',
                          disk)
            missing += 1
        return (additional, missing, qtree_not_scsi, proc_not_scsi)

    def check_disk_params(self, params):
        """
        Check gathered info from qtree/block with params
        :param params: autotest params
        :return: number of errors
        """
        def check_drive_format(node, params):
            """ checks the drive format according to qtree info """
            expected = params.get('drive_format')
            if expected == 'scsi':
                if arch.ARCH == 'ppc64':
                    expected = 'spapr-vscsi'
                else:
                    expected = 'lsi53c895a'
            elif expected.startswith('scsi'):
                expected = params.get('scsi_hba', 'virtio-scsi-pci')
            elif expected.startswith('usb'):
                expected = 'usb-storage'
            try:
                if expected == 'virtio':
                    actual = node.qtree['type']
                else:
                    actual = node.parent.parent.qtree.get('type')
            except AttributeError:
                logging.error("Failed to check drive format, can't get parent"
                              "of:\n%s", node)
            if actual == 'virtio-scsi-device':  # new name for virtio-scsi
                actual = 'virtio-scsi-pci'
            if expected not in actual:
                return ("drive format in qemu is %s, in autotest %s"
                        % (actual, expected))

        err = 0
        disks = {}
        for disk in self.disks:
            if isinstance(disk, QtreeDisk):
                disks[disk.get_qname()] = (disk.get_params().copy(), disk)
        # We don't have the params name so we need to map file_names instead
        qname = None
        for name in params.objects('cdroms'):
            image_name = utils_misc.get_path(data_dir.get_data_dir(),
                                             params.object_params(name).get('cdrom', ''))
            image_name = os.path.realpath(image_name)
            for (qname, disk) in disks.iteritems():
                if disk[0].get('image_name') == image_name:
                    break
            else:
                continue    # Not /proc/scsi cdrom device
            disks.pop(qname)
        for name in params.objects('images'):
            current = None
            image_params = params.object_params(name)

            base_dir = image_params.get("images_base_dir",
                                        data_dir.get_data_dir())

            image_name = os.path.realpath(
                storage.get_image_filename(image_params,
                                           base_dir))
            for (qname, disk) in disks.iteritems():
                if disk[0].get('image_name') == image_name:
                    current = disk[0]
                    current_node = disk[1]
                    # autotest params might use relative path
                    current['image_name'] = image_params.get('image_name')
                    break
            if not current:
                logging.error("Disk %s is not in qtree but is in params.",
                              name)
                err += 1
                continue
            for prop in current.iterkeys():
                handled = False
                if prop == "drive_format":
                    out = check_drive_format(current_node, image_params)
                    if out:
                        logging.error("Disk %s %s", qname, out)
                        err += 1
                    handled = True
                elif (image_params.get(prop) and
                        image_params.get(prop) == current.get(prop)):
                    handled = True
                if not handled:
                    logging.error("Disk %s property %s=%s doesn't match params"
                                  " %s", qname, prop, current.get(prop),
                                  image_params.get(prop))
                    err += 1
            disks.pop(qname)
        if disks:
            logging.error('Some disks were in qtree but not in autotest params'
                          ': %s', disks)
            err += 1
        return err

########NEW FILE########
__FILENAME__ = qemu_qtree_unittest
#!/usr/bin/python
"""
This is a unittest for qemu_qtree library.

:author: Lukas Doktor <ldoktor@redhat.com>
:copyright: 2012 Red Hat, Inc.
"""
__author__ = """Lukas Doktor (ldoktor@redhat.com)"""

import unittest

import common
from autotest.client.shared.test_utils import mock
import qemu_qtree

OFFSET_PER_LEVEL = qemu_qtree.OFFSET_PER_LEVEL


# Dummy classes and functions
class ParamsDict(dict):

    """ params like dictionary """

    def objects(self, item):
        if self.get(item):
            return self.get(item).split(' ')

    def object_params(self, obj):
        ret = self.copy()
        for (param, value) in self.iteritems():
            if param.endswith('_%s' % obj):
                ret[param[:-len('_%s' % obj)]] = value
        return ret


def combine(first, second, offset):
    """ Add string line-by-line with offset*OFFSET_PER_LEVEL """
    out = first[:]
    offset = ' ' * OFFSET_PER_LEVEL * offset
    for line in second.splitlines():
        out += '\n' + offset + line
    return out

# Dummy variables
qtree_header = """bus: main-system-bus
  type System

"""

dev_ide_disk = """dev: piix3-ide, id ""
  bus-prop: addr = 01.1
  bus-prop: romfile = <null>
  bus-prop: rombar = 1
  bus-prop: multifunction = off
  bus-prop: command_serr_enable = on
  class IDE controller, addr 00:01.1, pci id 8086:7010 (sub 1af4:1100)
  bar 4: i/o at 0xc2a0 [0xc2af]
  bus: ide.0
    type IDE
    dev: ide-hd, id ""
      dev-prop: drive = ide0-hd0
      dev-prop: logical_block_size = 512
      dev-prop: physical_block_size = 512
      dev-prop: min_io_size = 0
      dev-prop: opt_io_size = 0
      dev-prop: bootindex = -1
      dev-prop: discard_granularity = 0
      dev-prop: ver = "1.0.50"
      dev-prop: serial = "QM00001"
      bus-prop: unit = 0"""

dev_usb_disk = """dev: ich9-usb-uhci1, id "usb1"
  dev-prop: masterbus = <null>
  dev-prop: firstport = 0
  bus-prop: addr = 04.0
  bus-prop: romfile = <null>
  bus-prop: rombar = 1
  bus-prop: multifunction = off
  bus-prop: command_serr_enable = on
  class USB controller, addr 00:04.0, pci id 8086:2934 (sub 1af4:1100)
  bar 4: i/o at 0xc280 [0xc29f]
  bus: usb1.0
    type USB
    dev: usb-hub, id ""
      bus-prop: port = <null>
      addr 0.3, port 2, speed 12, name QEMU USB Hub, attached
    dev: usb-tablet, id "usb-tablet1"
      bus-prop: port = <null>
      addr 0.4, port 2.1, speed 12, name QEMU USB Tablet, attached
    dev: usb-storage, id ""
      dev-prop: drive = <null>
      dev-prop: logical_block_size = 512
      dev-prop: physical_block_size = 512
      dev-prop: min_io_size = 0
      dev-prop: opt_io_size = 0
      dev-prop: bootindex = -1
      dev-prop: discard_granularity = 0
      dev-prop: serial = <null>
      dev-prop: removable = off
      bus-prop: port = <null>
      addr 0.2, port 1, speed 12, name QEMU USB MSD, attached
      bus: scsi.0
        type SCSI
        dev: scsi-disk, id ""
          dev-prop: drive = usb2.6
          dev-prop: logical_block_size = 512
          dev-prop: physical_block_size = 512
          dev-prop: min_io_size = 0
          dev-prop: opt_io_size = 0
          dev-prop: bootindex = -1
          dev-prop: discard_granularity = 0
          dev-prop: ver = "1.0.50"
          dev-prop: serial = <null>
          dev-prop: removable = off
          bus-prop: channel = 0
          bus-prop: scsi-id = 0
          bus-prop: lun = 0"""

dev_dummy_mmio = """dev: fw_cfg, id ""
  dev-prop: ctl_iobase = 0x510
  dev-prop: data_iobase = 0x511
  irq 0
  mmio ffffffffffffffff/0000000000000002
  mmio ffffffffffffffff/0000000000000001"""

info_block = {'ide0-hd0': {'removable': 0, 'io-status': 'ok',
                           'file': '/tmp/vl.UWzrkU',
                           'backing_file': '/dummy/directory/f16-64.qcow2',
                           'ro': 1, 'drv': 'qcow2', 'encrypted': 0, 'bps': 0,
                           'bps_rd': 0, 'bps_wr': 0, 'iops': 0, 'iops_rd': 0,
                           'iops_wr': 0},
              'usb2.6': {'removable': 0, 'io-status': 'ok',
                         'file': '/tmp/stg4.qcow2', 'ro': 0, 'drv': 'qcow2',
                         'encrypted': 0, 'bps': 0, 'bps_rd': 0, 'bps_wr': 0,
                         'iops': 0, 'iops_rd': 0, 'iops_wr': 0}}

guest_proc_scsi = """Attached devices:
Host: scsi4 Channel: 00 Id: 00 Lun: 00
  Vendor: QEMU     Model: QEMU HARDDISK    Rev: 1.0.
  Type:   Direct-Access                    ANSI  SCSI revision: 05"""

params = ParamsDict({'images': 'image1 stg4',
                     'drive_format': 'ide',
                     'drive_format_stg4': 'usb2',
                     'drive_index_image1': '0',
                     'drive_index_stg4': '6',
                     'image_format': 'qcow2',
                     'image_name': '/dummy/directory/f16-64',
                     'image_name_stg4': 'stg4',
                     'image_size': '10G',
                     'image_size_stg4': '1M',
                     'image_snapshot': 'yes',
                     'image_snapshot_stg4': 'no',
                     'image_readonly_image1': 'yes',
                     'cdroms': 'cdrom1'})


class QtreeContainerTest(unittest.TestCase):

    """ QtreeContainer tests """

    def test_qtree(self):
        """ Correct workflow """
        reference_nodes = [qemu_qtree.QtreeDisk, qemu_qtree.QtreeBus,
                           qemu_qtree.QtreeDev, qemu_qtree.QtreeDev,
                           qemu_qtree.QtreeDev, qemu_qtree.QtreeDisk,
                           qemu_qtree.QtreeBus, qemu_qtree.QtreeDev,
                           qemu_qtree.QtreeBus, qemu_qtree.QtreeDev,
                           qemu_qtree.QtreeDev, qemu_qtree.QtreeBus]

        info = qtree_header
        info = combine(info, dev_ide_disk, 1)
        info = combine(info, dev_usb_disk, 1)
        info = combine(info, dev_dummy_mmio, 1)
        info += "\n"

        qtree = qemu_qtree.QtreeContainer()
        qtree.parse_info_qtree(info)
        nodes = qtree.get_nodes()

        self.assertEqual(len(nodes), len(reference_nodes), ("Number of parsed "
                                                            "nodes is not equal to the number of qtree nodes. "
                                                            "%s != %s" % (len(nodes), len(reference_nodes))))

        for i in xrange(len(nodes)):
            self.assertTrue(isinstance(nodes[i], reference_nodes[i]),
                            ("Node %d should be class %s but is %s instead" %
                             (i, reference_nodes[i], type(reference_nodes))))

        tree = qtree.get_qtree()
        self.assertTrue(isinstance(tree.str_qtree(), str),
                        "qtree.str_qtree() returns nonstring output.")

        self.assertTrue(isinstance(str(tree), str),
                        "str(qtree) returns nonstring output.")

    def test_bad_qtree(self):
        """ Incorrect qtree """
        qtree = qemu_qtree.QtreeContainer()
        info = combine(qtree_header, "Very_bad_line", 1)
        self.assertRaises(ValueError, qtree.parse_info_qtree, info)


class QtreeDiskContainerTest(unittest.TestCase):

    """ QtreeDiskContainer tests """

    def setUp(self):
        # Get rid of logging errors
        def dumm(*args, **kvargs):
            pass
        self.god = mock.mock_god(ut=self)
        self.god.stub_with(qemu_qtree.logging, 'error', dumm)

        info = qtree_header
        info = combine(info, dev_ide_disk, 1)
        info = combine(info, dev_usb_disk, 1)
        info = combine(info, dev_dummy_mmio, 1)
        info += "\n"

        self.no_disks = 2

        self.qtree = qemu_qtree.QtreeContainer()
        self.qtree.parse_info_qtree(info)

        self.disks = qemu_qtree.QtreeDisksContainer(self.qtree.get_nodes())

    def tearDown(self):
        self.god.unstub_all()

    def test_check_params(self):
        """ Correct workflow """
        disks = self.disks
        self.assertEqual(len(self.disks.disks), self.no_disks)
        self.assertEqual(disks.parse_info_block(info_block), (0, 0))
        self.assertEqual(disks.generate_params(), 0)
        self.assertEqual(disks.check_disk_params(params), 2)
        self.assertEqual(disks.check_guests_proc_scsi(guest_proc_scsi),
                         (0, 0, 1, 0))
        # Check the full disk output (including params)
        for disk in disks.disks:
            self.assertTrue(isinstance(str(disk), str),
                            "str(disk) returns nonstring output.")

    def test_check_params_bad(self):
        """ Whole workflow with bad data """
        disks = self.disks
        # missing disk in info block
        _info_block = info_block.copy()
        _info_block.pop('ide0-hd0')
        # snapshot in info qtree but not in params
        _info_block['usb2.6']['file'] = 'none.qcow2'
        _info_block['usb2.6']['backing_file'] = '/tmp/stg4.qcow2'
        # additional disk in info block
        _info_block['missing_bad_disk1'] = {}
        # additional disk in params
        _params = ParamsDict(params)
        _params['images'] += ' bad_disk2'
        # Missing disk in proc_scsi
        _guest_proc_scsi = guest_proc_scsi.replace('Channel: 00',
                                                   'Channel: 01')
        # Ignored disk in proc_scsi
        _guest_proc_scsi += """
Host: scsi1 Channel: 00 Id: 00 Lun: 00
  Vendor: ATA      Model: QEMU HARDDISK    Rev: 1.0.
  Type:   Direct-Access                    ANSI  SCSI revision: 05"""

        self.assertEqual(disks.parse_info_block(_info_block), (1, 1))
        self.assertEqual(disks.generate_params(), 1)
        self.assertEqual(disks.check_disk_params(_params), 4)
        self.assertEqual(disks.check_guests_proc_scsi(_guest_proc_scsi),
                         (0, 1, 1, 0))


class KvmQtreeClassTest(unittest.TestCase):

    """ Additional tests for qemu_qtree classes """

    def test_qtree_bus_bus(self):
        """ Bus' child can't be Bus() """
        test = qemu_qtree.QtreeBus()
        self.assertRaises(qemu_qtree.IncompatibleTypeError,
                          test.add_child, qemu_qtree.QtreeBus())

    def test_qtree_dev_dev(self):
        """ Dev's child can't be Dev() """
        test = qemu_qtree.QtreeDev()
        self.assertRaises(qemu_qtree.IncompatibleTypeError,
                          test.add_child, qemu_qtree.QtreeDev())

    def test_qtree_disk_missing_filename(self):
        """ in info_block must contain info about file or backing_file """
        test = qemu_qtree.QtreeDisk()
        test.set_qtree({'something': 'something'})
        test.set_block_prop('prop', 'value')
        self.assertRaises(ValueError, test.generate_params)


if __name__ == "__main__":
    """ Run unittest """
    unittest.main()

########NEW FILE########
__FILENAME__ = qemu_storage
"""
Classes and functions to handle block/disk images for KVM.

This exports:
  - two functions for get image/blkdebug filename
  - class for image operates and basic parameters
"""
import logging
import os
import re
from autotest.client.shared import error
from autotest.client import utils
import utils_misc
import virt_vm
import storage
import data_dir


class QemuImg(storage.QemuImg):

    """
    KVM class for handling operations of disk/block images.
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images
        """
        storage.QemuImg.__init__(self, params, root_dir, tag)
        self.image_cmd = utils_misc.get_qemu_img_binary(params)
        q_result = utils.run(self.image_cmd, ignore_status=True,
                             verbose=False)
        self.help_text = q_result.stdout

    @error.context_aware
    def create(self, params, ignore_errors=False):
        """
        Create an image using qemu_img or dd.

        :param params: Dictionary containing the test parameters.
        :param ignore_errors: Whether to ignore errors on the image creation
                              cmd.

        :note: params should contain:

               image_name
                   name of the image file, without extension
               image_format
                   format of the image (qcow2, raw etc)
               image_cluster_size (optional)
                   cluster size for the image
               image_size
                   requested size of the image (a string qemu-img can
                   understand, such as '10G')
               create_with_dd
                   use dd to create the image (raw format only)
               base_image(optional)
                   the base image name when create snapshot
               base_format(optional)
                   the format of base image
               encrypted(optional)
                   if the image is encrypted, allowed values: on and off.
                   Default is "off"
               preallocated(optional)
                   if preallocation when create image, allowed values: off,
                   metadata. Default is "off"

        :return: tuple (path to the image created, utils.CmdResult object
                 containing the result of the creation command).
        """
        if params.get("create_with_dd") == "yes" and self.image_format == "raw":
            # maps K,M,G,T => (count, bs)
            human = {'K': (1, 1),
                     'M': (1, 1024),
                     'G': (1024, 1024),
                     'T': (1024, 1048576),
                     }
            if human.has_key(self.size[-1]):
                block_size = human[self.size[-1]][1]
                size = int(self.size[:-1]) * human[self.size[-1]][0]
            qemu_img_cmd = ("dd if=/dev/zero of=%s count=%s bs=%sK"
                            % (self.image_filename, size, block_size))
        else:
            qemu_img_cmd = self.image_cmd
            qemu_img_cmd += " create"

            qemu_img_cmd += " -f %s" % self.image_format

            image_cluster_size = params.get("image_cluster_size", None)
            preallocated = params.get("preallocated", "off")
            encrypted = params.get("encrypted", "off")
            image_extra_params = params.get("image_extra_params", "")
            has_backing_file = params.get('has_backing_file')

            qemu_img_cmd += " -o "
            if preallocated != "off":
                qemu_img_cmd += "preallocation=%s," % preallocated

            if encrypted != "off":
                qemu_img_cmd += "encrypted=%s," % encrypted

            if image_cluster_size is not None:
                qemu_img_cmd += "cluster_size=%s," % image_cluster_size

            if has_backing_file == "yes":
                backing_param = params.object_params("backing_file")
                backing_file = storage.get_image_filename(backing_param,
                                                          self.root_dir)
                backing_fmt = backing_param.get("image_format")
                qemu_img_cmd += "backing_file=%s," % backing_file

                qemu_img_cmd += "backing_fmt=%s," % backing_fmt

            if image_extra_params:
                qemu_img_cmd += "%s," % image_extra_params
            qemu_img_cmd = qemu_img_cmd.rstrip(" -o")
            qemu_img_cmd = qemu_img_cmd.rstrip(",")

            if self.base_tag:
                qemu_img_cmd += " -b %s" % self.base_image_filename
                if self.base_format:
                    qemu_img_cmd += " -F %s" % self.base_format

            qemu_img_cmd += " %s" % self.image_filename

            qemu_img_cmd += " %s" % self.size

        if (params.get("image_backend", "filesystem") == "filesystem"):
            image_dirname = os.path.dirname(self.image_filename)
            if image_dirname and not os.path.isdir(image_dirname):
                e_msg = ("Parent directory of the image file %s does "
                         "not exist" % self.image_filename)
                logging.error(e_msg)
                logging.error("This usually means a serious setup error.")
                logging.error("Please verify if your data dir contains the "
                              "expected directory structure")
                logging.error("Backing data dir: %s",
                              data_dir.get_backing_data_dir())
                logging.error("Directory structure:")
                for root, _, _ in os.walk(data_dir.get_backing_data_dir()):
                    logging.error(root)

                logging.warning("We'll try to proceed by creating the dir. "
                                "Other errors may ensue")
                os.makedirs(image_dirname)

        msg = "Create image by command: %s" % qemu_img_cmd
        error.context(msg, logging.info)
        cmd_result = utils.run(qemu_img_cmd, verbose=False, ignore_status=True)
        if cmd_result.exit_status != 0 and not ignore_errors:
            raise error.TestError("Failed to create image %s" %
                                  self.image_filename)

        return self.image_filename, cmd_result

    def convert(self, params, root_dir, cache_mode=None):
        """
        Convert image

        :param params: dictionary containing the test parameters
        :param root_dir: dir for save the convert image
        :param cache_mode: The cache mode used to write the output disk image.
                           Valid options are: ``none``, ``writeback``
                           (default), ``writethrough``, ``directsync`` and
                           ``unsafe``.

        :note: params should contain:

            convert_image_tag
                the image name of the convert image
            convert_filename
                the name of the image after convert
            convert_fmt
                the format after convert
            compressed
                indicates that target image must be compressed
            encrypted
                there are two value "off" and "on", default value is "off"
        """
        convert_image_tag = params["image_convert"]
        convert_image = params["convert_name_%s" % convert_image_tag]
        convert_compressed = params.get("convert_compressed")
        convert_encrypted = params.get("convert_encrypted", "off")
        convert_format = params["convert_format_%s" % convert_image_tag]
        params_convert = {"image_name": convert_image,
                          "image_format": convert_format}

        convert_image_filename = storage.get_image_filename(params_convert,
                                                            root_dir)

        cmd = self.image_cmd
        cmd += " convert"
        if convert_compressed == "yes":
            cmd += " -c"
        if convert_encrypted != "off":
            cmd += " -o encryption=%s" % convert_encrypted
        if self.image_format:
            cmd += " -f %s" % self.image_format
        cmd += " -O %s" % convert_format
        if cache_mode:
            cmd += " -t %s" % cache_mode
        cmd += " %s %s" % (self.image_filename, convert_image_filename)

        logging.info("Convert image %s from %s to %s", self.image_filename,
                     self.image_format, convert_format)

        utils.system(cmd)

        return convert_image_tag

    def rebase(self, params, cache_mode=None):
        """
        Rebase image.

        :param params: dictionary containing the test parameters
        :param cache_mode: the cache mode used to write the output disk image,
                           the valid options are: 'none', 'writeback' (default),
                           'writethrough', 'directsync' and 'unsafe'.

        :note: params should contain:

            cmd
                qemu-img cmd
            snapshot_img
                the snapshot name
            base_img
                base image name
            base_fmt
                base image format
            snapshot_fmt
                the snapshot format
            mode
                there are two value, "safe" and "unsafe", default is "safe"
        """
        self.check_option("base_image_filename")
        self.check_option("base_format")

        rebase_mode = params.get("rebase_mode")
        cmd = self.image_cmd
        cmd += " rebase"
        if self.image_format:
            cmd += " -f %s" % self.image_format
        if cache_mode:
            cmd += " -t %s" % cache_mode
        if rebase_mode == "unsafe":
            cmd += " -u"
        if self.base_tag:
            cmd += " -b %s -F %s %s" % (self.base_image_filename,
                                        self.base_format, self.image_filename)
        else:
            raise error.TestError("Can not find the image parameters need"
                                  " for rebase.")

        logging.info("Rebase snapshot %s to %s..." % (self.image_filename,
                                                      self.base_image_filename))
        utils.system(cmd)

        return self.base_tag

    def commit(self, params={}, cache_mode=None):
        """
        Commit image to it's base file

        :param cache_mode: the cache mode used to write the output disk image,
            the valid options are: 'none', 'writeback' (default),
            'writethrough', 'directsync' and 'unsafe'.
        """
        cmd = self.image_cmd
        cmd += " commit"
        if cache_mode:
            cmd += " -t %s" % cache_mode
        cmd += " -f %s %s" % (self.image_format, self.image_filename)
        logging.info("Commit snapshot %s" % self.image_filename)
        utils.system(cmd)

        return self.image_filename

    def snapshot_create(self):
        """
        Create a snapshot image.

        :note: params should contain:
               snapshot_image_name -- the name of snapshot image file
        """

        cmd = self.image_cmd
        if self.snapshot_tag:
            cmd += " snapshot -c %s" % self.snapshot_image_filename
        else:
            raise error.TestError("Can not find the snapshot image"
                                  " parameters")
        cmd += " %s" % self.image_filename

        utils.system_output(cmd)

        return self.snapshot_tag

    def snapshot_del(self, blkdebug_cfg=""):
        """
        Delete a snapshot image.

        :param blkdebug_cfg: The configure file of blkdebug

        :note: params should contain:
               snapshot_image_name -- the name of snapshot image file
        """

        cmd = self.image_cmd
        if self.snapshot_tag:
            cmd += " snapshot -d %s" % self.snapshot_image_filename
        else:
            raise error.TestError("Can not find the snapshot image"
                                  " parameters")
        if blkdebug_cfg:
            cmd += " blkdebug:%s:%s" % (blkdebug_cfg, self.image_filename)
        else:
            cmd += " %s" % self.image_filename

        utils.system_output(cmd)

    def snapshot_list(self):
        """
        List all snapshots in the given image
        """
        cmd = self.image_cmd
        cmd += " snapshot -l %s" % self.image_filename

        return utils.system_output(cmd)

    def remove(self):
        """
        Remove an image file.
        """
        logging.debug("Removing image file %s", self.image_filename)
        if os.path.exists(self.image_filename):
            os.unlink(self.image_filename)
        else:
            logging.debug("Image file %s not found", self.image_filename)

    def info(self):
        """
        Run qemu-img info command on image file and return its output.
        """
        logging.debug("Run qemu-img info comamnd on %s", self.image_filename)
        cmd = self.image_cmd
        if os.path.exists(self.image_filename):
            cmd += " info %s" % self.image_filename
            output = utils.system_output(cmd)
        else:
            logging.debug("Image file %s not found", self.image_filename)
            output = None
        return output

    def get_format(self):
        """
        Get the fimage file format.
        """
        image_info = self.info()
        if image_info:
            image_format = re.findall("file format: (\w+)", image_info)[0]
        else:
            image_format = None
        return image_format

    def support_cmd(self, cmd):
        """
        Verifies whether qemu-img supports command cmd.

        :param cmd: Command string.
        """
        supports_cmd = True

        if cmd not in self.help_text:
            logging.error("%s does not support command '%s'", self.image_cmd,
                          cmd)
            supports_cmd = False

        return supports_cmd

    def compare_images(self, image1, image2, verbose=True):
        """
        Compare 2 images using the appropriate tools for each virt backend.

        :param image1: image path of first image
        :param image2: image path of second image
        :param verbose: Record output in debug file or not
        """
        compare_images = self.support_cmd("compare")
        if not compare_images:
            logging.debug("Skipping image comparison "
                          "(lack of support in qemu-img)")
        else:
            logging.info("Comparing images %s and %s", image1, image2)
            compare_cmd = "%s compare %s %s" % (self.image_cmd, image1, image2)
            rv = utils.run(compare_cmd, ignore_status=True)

            if verbose:
                logging.debug("Output from command: %s" % rv.stdout)

            if rv.exit_status == 0:
                logging.info("Compared images are equal")
            elif rv.exit_status == 1:
                raise error.TestFail("Compared images differ")
            else:
                raise error.TestError("Error in image comparison")

    def check_image(self, params, root_dir):
        """
        Check an image using the appropriate tools for each virt backend.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.

        :note: params should contain:
               image_name -- the name of the image file, without extension
               image_format -- the format of the image (qcow2, raw etc)

        :raise VMImageCheckError: In case qemu-img check fails on the image.
        """
        image_filename = self.image_filename
        logging.debug("Checking image file %s", image_filename)
        qemu_img_cmd = self.image_cmd
        image_is_checkable = self.image_format in ['qcow2', 'qed']

        if (storage.file_exists(params, image_filename) or
                params.get("enable_gluster", "no") == "yes") and image_is_checkable:
            check_img = self.support_cmd("check") and self.support_cmd("info")
            if not check_img:
                logging.debug("Skipping image check "
                              "(lack of support in qemu-img)")
            else:
                try:
                    utils.run("%s info %s" % (qemu_img_cmd, image_filename),
                              verbose=True)
                except error.CmdError:
                    logging.error("Error getting info from image %s",
                                  image_filename)

                cmd_result = utils.run("%s check %s" %
                                       (qemu_img_cmd, image_filename),
                                       ignore_status=True, verbose=True)
                # Error check, large chances of a non-fatal problem.
                # There are chances that bad data was skipped though
                if cmd_result.exit_status == 1:
                    for e_line in cmd_result.stdout.splitlines():
                        logging.error("[stdout] %s", e_line)
                    for e_line in cmd_result.stderr.splitlines():
                        logging.error("[stderr] %s", e_line)
                    chk = params.get("backup_image_on_check_error", "no")
                    if chk == "yes":
                        self.backup_image(params, root_dir, "backup", False)
                    raise error.TestWarn("qemu-img check error. Some bad "
                                         "data in the image may have gone"
                                         " unnoticed (%s)" % image_filename)
                # Exit status 2 is data corruption for sure,
                # so fail the test
                elif cmd_result.exit_status == 2:
                    for e_line in cmd_result.stdout.splitlines():
                        logging.error("[stdout] %s", e_line)
                    for e_line in cmd_result.stderr.splitlines():
                        logging.error("[stderr] %s", e_line)
                    chk = params.get("backup_image_on_check_error", "no")
                    if chk == "yes":
                        self.backup_image(params, root_dir, "backup", False)
                    raise virt_vm.VMImageCheckError(image_filename)
                # Leaked clusters, they are known to be harmless to data
                # integrity
                elif cmd_result.exit_status == 3:
                    raise error.TestWarn("Leaked clusters were noticed"
                                         " during image check. No data "
                                         "integrity problem was found "
                                         "though. (%s)" % image_filename)

                # Just handle normal operation
                if params.get("backup_image", "no") == "yes":
                    self.backup_image(params, root_dir, "backup", True, True)
        else:
            if not storage.file_exists(params, image_filename):
                logging.debug("Image file %s not found, skipping check",
                              image_filename)
            elif not image_is_checkable:
                logging.debug(
                    "Image format %s is not checkable, skipping check",
                    self.image_format)


class Iscsidev(storage.Iscsidev):

    """
    Class for handle iscsi devices for VM
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images
        """
        super(Iscsidev, self).__init__(params, root_dir, tag)

    def setup(self):
        """
        Access the iscsi target. And return the local raw device name.
        """
        if self.iscsidevice.logged_in():
            logging.warn("Session already present. Don't need to"
                         " login again")
        else:
            self.iscsidevice.login()

        if utils_misc.wait_for(self.iscsidevice.get_device_name,
                               self.iscsi_init_timeout):
            device_name = self.iscsidevice.get_device_name()
        else:
            raise error.TestError("Can not get iscsi device name in host"
                                  " in %ss" % self.iscsi_init_timeout)

        if self.device_id:
            device_name += self.device_id
        return device_name

    def cleanup(self):
        """
        Logout the iscsi target and clean up the config and image.
        """
        if self.exec_cleanup:
            self.iscsidevice.cleanup()
            if self.emulated_file_remove:
                logging.debug("Removing file %s", self.emulated_image)
                if os.path.exists(self.emulated_image):
                    os.unlink(self.emulated_image)
                else:
                    logging.debug("File %s not found", self.emulated_image)


class LVMdev(storage.LVMdev):

    """
    Class for handle lvm devices for VM
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images
        """
        super(LVMdev, self).__init__(params, root_dir, tag)

    def setup(self):
        """
        Get logical volume path;
        """
        return self.lvmdevice.setup()

    def cleanup(self):
        """
        Cleanup useless volumes;
        """
        return self.lvmdevice.cleanup()

########NEW FILE########
__FILENAME__ = qemu_virtio_port
"""
Interfaces and helpers for the virtio_serial ports.

:copyright: 2012 Red Hat Inc.
"""
from threading import Thread
from collections import deque
import aexpect
import logging
import os
import random
import select
import socket
import time
from autotest.client.shared import error, utils
import utils_test
import data_dir


SOCKET_SIZE = 2048


class VirtioPortException(Exception):

    """ General virtio_port exception """
    pass


class VirtioPortFatalException(VirtioPortException):

    """ Fatal virtio_port exception """
    pass


class _VirtioPort(object):

    """
    Define structure to keep information about used port.
    """

    def __init__(self, qemu_id, name, hostfile):
        """
        :param name: Name of port for guest side.
        :param hostfile: Path to port on host side.
        """
        self.qemu_id = qemu_id
        self.name = name
        self.hostfile = hostfile
        self.is_console = None  # "yes", "no"
        self.sock = None
        self.port_was_opened = None

    def __str__(self):
        """
        Convert to text.
        """
        return ("%s,%s,%s,%s,%d" % ("Socket", self.name, self.is_console,
                                    self.hostfile, self.is_open()))

    def __getstate__(self):
        """
        socket is unpickable so we need to remove it and say it's closed.
        Used by autotest env.
        """
        # TODO: add port cleanup into qemu_vm.py
        if self.is_open():
            logging.warn("Force closing virtio_port socket, FIX the code to "
                         " close the socket prior this to avoid possible err.")
            self.close()
        return self.__dict__.copy()

    def is_open(self):
        """ :return: host port status (open/closed) """
        if self.sock:
            return True
        else:
            return False

    def for_guest(self):
        """
        Format data for communication with guest side.
        """
        return [self.name, self.is_console]

    def open(self):     # @ReservedAssignment
        """
        Open port on host side.
        """
        if self.is_open():
            return
        attempt = 11
        while attempt > 0:
            try:
                self.sock = socket.socket(socket.AF_UNIX,
                                          socket.SOCK_STREAM)
                self.sock.settimeout(1)
                self.sock.connect(self.hostfile)
                self.sock.setsockopt(1, socket.SO_SNDBUF, SOCKET_SIZE)
                self.sock.settimeout(None)
                self.port_was_opened = True
                return
            except Exception:
                attempt -= 1
                time.sleep(1)
        raise error.TestFail("Can't open the %s sock (%s)" % (self.name,
                                                              self.hostfile))

    def clean_port(self):
        """
        Clean all data from opened port on host side.
        """
        if self.is_open():
            self.close()
        elif not self.port_was_opened:
            # BUG: Don't even try opening port which was never used. It
            # hangs for ever... (virtio_console bug)
            logging.debug("No need to clean port %s", self)
            return
        logging.debug("Cleaning port %s", self)
        self.open()
        ret = select.select([self.sock], [], [], 1.0)
        if ret[0]:
            buf = self.sock.recv(1024)
            logging.debug("Rest in socket: " + buf)

    def close(self):
        """
        Close port.
        """
        if self.is_open():
            self.sock.shutdown(socket.SHUT_RDWR)
            self.sock.close()
            self.sock = None

    def mark_as_clean(self):
        """
        Mark port as cleaned
        """
        self.port_was_opened = False


class VirtioSerial(_VirtioPort):

    """ Class for handling virtio-serialport """

    def __init__(self, qemu_id, name, hostfile):
        """
        :param name: Name of port for guest side.
        :param hostfile: Path to port on host side.
        """
        super(VirtioSerial, self).__init__(qemu_id, name, hostfile)
        self.is_console = "no"


class VirtioConsole(_VirtioPort):

    """ Class for handling virtio-console """

    def __init__(self, qemu_id, name, hostfile):
        """
        :param name: Name of port for guest side.
        :param hostfile: Path to port on host side.
        """
        super(VirtioConsole, self).__init__(qemu_id, name, hostfile)
        self.is_console = "yes"


class GuestWorker(object):

    """
    Class for executing "virtio_console_guest" script on guest
    """

    def __init__(self, vm):
        """ Initialize worker for use (including port init on guest) """
        self.vm = vm
        self.session = self.vm.wait_for_login()
        self.__cmd_execute_worker = None

        # Detect the OS version
        guest_script_py = "virtio_console_guest.py"
        out = self.session.cmd_output("echo on")
        if "on" in out:
            self.os_linux = True
            guest_script_path = "/tmp/%s" % guest_script_py
            cmd_guest_size = ("du -b %s | cut -f1"
                              % guest_script_path)
            cmd_already_compiled_chck = "ls %so" % guest_script_path
            cmd_compile = ("python -OO %s -c "
                           "&& echo -n 'PASS: Compile virtio_guest finished' "
                           "|| echo -n 'FAIL: Compile virtio_guest failed'"
                           % guest_script_path)
            self.__cmd_execute_worker = ("python %so"
                                         "&& echo -n 'PASS: virtio_guest finished' "
                                         "|| echo -n 'FAIL: virtio_guest failed'"
                                         % guest_script_path)
        else:
            self.os_linux = False
            guest_script_path = "C:\\%s" % guest_script_py
            cmd_guest_size = ("for %%I in (%s) do @echo %%~zI"
                              % guest_script_path)
            cmd_already_compiled_chck = "dir %so" % guest_script_path
            cmd_compile = ("%s -c "
                           "&& echo PASS: Compile virtio_guest finished "
                           "|| echo FAIL: Compile virtio_guest failed"
                           % guest_script_path)
            self.__cmd_execute_worker = ("%so "
                                         "&& echo PASS: virtio_guest finished "
                                         "|| echo FAIL: virtio_guest failed"
                                         % guest_script_path)

        # Copy, compile and run the worker
        timeout = 10
        base_path = os.path.dirname(data_dir.get_data_dir())
        guest_script_src = os.path.join(base_path, 'scripts',
                                        'virtio_console_guest.py')
        script_size = utils.system_output("du -b %s | cut -f1"
                                          % guest_script_src).strip()
        script_size_guest = self.session.cmd_output(cmd_guest_size).strip()
        if (script_size != script_size_guest
                or self.session.cmd_status(cmd_already_compiled_chck)):
            if self.os_linux:
                # Disable serial-getty@hvc0.service on systemd-like hosts
                self.session.cmd_status('systemctl mask '
                                        'serial-getty@hvc0.service')
                self.session.cmd_status('systemctl stop '
                                        'serial-getty@hvc0.service')
            # Copy virtio_console_guest.py into guests
            self.vm.copy_files_to(guest_script_src, guest_script_path)

            # set echo off (self.cmd() musn't contain C:)
            self.session.sendline("echo off")
            # Compile worker
            logging.debug("Compile %s on guest %s", guest_script_py,
                          self.vm.name)
            try:
                self.cmd(cmd_compile, timeout)
            except VirtioPortException:
                if not self.os_linux:
                    logging.error("Script execution failed, do you have python"
                                  " and pywin32 installed? Currently this "
                                  "needs to be done manually!")
                raise
            self.session.sendline()

        # set echo off (self.cmd() musn't contain C:)
        self.session.sendline("echo off")
        logging.debug("Starting %so on guest %s", guest_script_py,
                      self.vm.name)
        self._execute_worker(timeout)
        self._init_guest(timeout)

    def _execute_worker(self, timeout=10):
        """ Execute worker on guest """
        try:
            self.cmd(self.__cmd_execute_worker, timeout)
        except VirtioPortException:
            if not self.os_linux:
                logging.error("Script execution failed, do you have python"
                              " and pywin32 installed? Currently this "
                              "needs to be done manually!")
            raise
        # Let the system rest
        # FIXME: Is this always necessarily?
        time.sleep(2)

    def _init_guest(self, timeout=10):
        """ Initialize worker on guest """
        ports = []
        for port in self.vm.virtio_ports:
            ports.append(port.for_guest())
        self.cmd("virt.init(%s)" % (ports), timeout)

    def reconnect(self, vm, timeout=10):
        """
        Reconnect to guest_worker (eg. after migration)
        :param vm: New VM object
        """
        self.vm = vm
        self.session = self.vm.wait_for_login()
        self._execute_worker(timeout)

    def cmd(self, cmd, timeout=10, patterns=None):
        """
        Wrapper around the self.cmd command which executes the command on
        guest. Unlike self._cmd command when the command fails it raises the
        test error.
        :param command: Command that will be executed.
        :param timeout: Timeout used to verify expected output.
        :return: Tuple (match index, data)
        """
        match, data = self._cmd(cmd, timeout, patterns)
        if match == 1 or match is None:
            raise VirtioPortException("Failed to execute '%s' on"
                                      " virtio_console_guest.py, "
                                      "vm: %s, output:\n%s" %
                                      (cmd, self.vm.name, data))
        return (match, data)

    def _cmd(self, cmd, timeout=10, patterns=None):
        """
        Execute given command inside the script's main loop.
        :param command: Command that will be executed.
        :param timeout: Timeout used to verify expected output.
        :param patterns: Expected patterns; have to startwith ^PASS: or ^FAIL:
        :return: Tuple (match index, data)
        """
        if not patterns:
            patterns = ("^PASS:", "^FAIL:")
        logging.debug("Executing '%s' on virtio_console_guest.py,"
                      " vm: %s, timeout: %s", cmd, self.vm.name, timeout)
        self.session.sendline(cmd)
        try:
            (match, data) = self.session.read_until_any_line_matches(patterns,
                                                                     timeout=timeout)
            if patterns[match].startswith('^PASS:'):
                match = 0
            elif patterns[match].startswith('^FAIL:'):
                match = 1
            else:
                data = ("Incorrect pattern %s. Data in console:\n%s"
                        % (patterns[match], data))
                match = None
        except aexpect.ExpectError, inst:
            match = None
            data = "Cmd process timeout. Data in console:\n" + inst.output

        self.vm.verify_kernel_crash()

        return (match, data)

    def read_nonblocking(self, internal_timeout=None, timeout=None):
        """
        Reads-out all remaining output from GuestWorker.

        :param internal_timeout: Time (seconds) to wait before we give up
                                 reading from the child process, or None to
                                 use the default value.
        :param timeout: Timeout for reading child process output.
        """
        return self.session.read_nonblocking(internal_timeout, timeout)

    def _cleanup_ports(self):
        """
        Read all data from all ports, in both sides of each port.
        """
        for port in self.vm.virtio_ports:
            openned = port.is_open()
            port.clean_port()
            self.cmd("virt.clean_port('%s'),1024" % port.name, 10)
            if not openned:
                port.close()
                self.cmd("virt.close('%s'),1024" % port.name, 10)

    def safe_exit_loopback_threads(self, send_pts, recv_pts):
        """
        Safely executes on_guest("virt.exit_threads()") using workaround of
        the stuck thread in loopback in mode=virt.LOOP_NONE .
        :param send_pts: list of possible send sockets we need to work around.
        :param recv_pts: list of possible recv sockets we need to read-out.
        """
        # No need to clean ports when VM is dead
        if not self.vm or self.vm.is_dead():
            return
        # in LOOP_NONE mode it might stuck in read/write
        # This command can't fail, can only freze so wait for the correct msg
        match, tmp = self._cmd("virt.exit_threads()", 3, ("^PASS: All threads"
                                                          " finished",))
        if match is None:
            logging.warn("Workaround the stuck thread on guest")
            # Thread is stuck in read/write
            for send_pt in send_pts:
                send_pt.sock.sendall(".")
        elif match != 0:
            # Something else
            raise VirtioPortException("Unexpected fail\nMatch: %s\nData:\n%s"
                                      % (match, tmp))

        # Read-out all remaining data
        for recv_pt in recv_pts:
            while select.select([recv_pt.sock], [], [], 0.1)[0]:
                recv_pt.sock.recv(1024)

        # This will cause fail in case anything went wrong.
        match, tmp = self._cmd("print 'PASS: nothing'", 10, ('^PASS: nothing',
                                                             '^FAIL:'))
        if match is not 0:
            logging.error("Python is stuck/FAILed after read-out:\n%s", tmp)
            try:
                self.session.close()
                self.session = self.vm.wait_for_login()
                if self.os_linux:   # On windows it dies with the connection
                    self.cmd("killall -9 python "
                             "&& echo -n PASS: python killed"
                             "|| echo -n PASS: python was already dead", 10)
                self._execute_worker()
                self._init_guest()
            except Exception, inst:
                logging.error(inst)
                raise VirtioPortFatalException("virtio-console driver is "
                                               "irreparably blocked, further tests might FAIL.")

    def cleanup_ports(self):
        """
        Clean state of all ports and set port to default state.

        Default state: No data on port or in port buffer. Read mode = blocking.
        """
        # Check if python is still alive
        match, tmp = self._cmd("is_alive()", 10)
        if match is not 0:
            logging.error("Python died/is stuck/have remaining threads")
            logging.debug(tmp)
            try:
                self.vm.verify_kernel_crash()

                match, tmp = self._cmd("guest_exit()", 10, ('^FAIL:',
                                                            '^PASS: virtio_guest finished'))
                self.session.close()
                self.session = self.vm.wait_for_login()
                # On windows it dies with the connection
                if match is not 0 and self.os_linux:
                    logging.debug(tmp)
                    self.cmd("killall -9 python "
                             "&& echo -n PASS: python killed"
                             "|| echo -n PASS: python was already dead", 10)

                self._execute_worker()
                self._init_guest()
                self._cleanup_ports()

            except Exception, inst:
                logging.error(inst)
                raise VirtioPortFatalException("virtio-console driver is "
                                               "irreparably blocked, further tests might FAIL.")

    def cleanup(self):
        """ Cleanup ports and quit the worker """
        # Verify that guest works
        if self.session and self.vm and self.vm.is_alive():
            self.cleanup_ports()
        if self.vm:
            self.vm.verify_kernel_crash()
        # Quit worker
        if self.session and self.vm and self.vm.is_alive():
            match, tmp = self._cmd("guest_exit()", 10)
            self.session.close()
            # On windows it dies with the connection
            if match is not 0 and self.os_linux:
                logging.warn('guest_worker stuck during cleanup:\n%s\n,'
                             ' killing python...', tmp)
                self.session = self.vm.wait_for_login()
                self.cmd("killall -9 python "
                         "&& echo -n PASS: python killed"
                         "|| echo -n PASS: python was already dead", 10)
                self.session.close()
        self.session = None
        self.vm = None


class ThSend(Thread):

    """
    Random data sender thread.
    """

    def __init__(self, port, data, exit_event, quiet=False):
        """
        :param port: Destination port.
        :param data: The data intend to be send in a loop.
        :param exit_event: Exit event.
        :param quiet: If true don't raise event when crash.
        """
        Thread.__init__(self)
        self.port = port
        # FIXME: socket.send(data>>127998) without read blocks thread
        if len(data) > 102400:
            data = data[0:102400]
            logging.error("Data is too long, using only first %d bytes",
                          len(data))
        self.data = data
        self.exitevent = exit_event
        self.idx = 0
        self.quiet = quiet
        self.ret_code = 1    # sets to 0 when finish properly

    def run(self):
        logging.debug("ThSend %s: run", self.getName())
        try:
            while not self.exitevent.isSet():
                self.idx += self.port.send(self.data)
            logging.debug("ThSend %s: exit(%d)", self.getName(),
                          self.idx)
        except Exception, ints:
            if not self.quiet:
                raise ints
            logging.debug(ints)
        self.ret_code = 0


class ThSendCheck(Thread):

    """
    Random data sender thread.
    """

    def __init__(self, port, exit_event, queues, blocklen=1024,
                 migrate_event=None, reduced_set=False):
        """
        :param port: Destination port
        :param exit_event: Exit event
        :param queues: Queues for the control data (FIFOs)
        :param blocklen: Block length
        :param migrate_event: Event indicating port was changed and is ready.
        """
        Thread.__init__(self)
        self.port = port
        self.queues = queues
        # FIXME: socket.send(data>>127998) without read blocks thread
        if blocklen > 102400:
            blocklen = 102400
            logging.error("Data is too long, using blocklen = %d",
                          blocklen)
        self.blocklen = blocklen
        self.exitevent = exit_event
        self.migrate_event = migrate_event
        self.idx = 0
        self.ret_code = 1    # sets to 0 when finish properly
        self.reduced_set = reduced_set

    def run(self):
        logging.debug("ThSendCheck %s: run", self.getName())
        _err_msg_exception = ('ThSendCheck ' + str(self.getName()) + ': Got '
                              'exception %s, continuing')
        _err_msg_disconnect = ('ThSendCheck ' + str(self.getName()) + ': Port '
                               'disconnected, waiting for new port.')
        _err_msg_reconnect = ('ThSendCheck ' + str(self.getName()) + ': Port '
                              'reconnected, continuing.')
        too_much_data = False
        if self.reduced_set:
            rand_a = 65
            rand_b = 91
        else:
            rand_a = 0
            rand_b = 255
        while not self.exitevent.isSet():
            # FIXME: workaround the problem with qemu-kvm stall when too
            # much data is sent without receiving
            for queue in self.queues:
                while not self.exitevent.isSet() and len(queue) > 1048576:
                    too_much_data = True
                    time.sleep(0.1)
            try:
                ret = select.select([], [self.port.sock], [], 1.0)
            except Exception, inst:
                # self.port is not yet set while reconnecting
                if self.migrate_event is None:
                    raise error.TestFail("ThSendCheck %s: Broken pipe. If this"
                                         " is expected behavior set migrate_event "
                                         "to support reconnection." % self.getName())
                if self.port.sock is None:
                    logging.debug(_err_msg_disconnect)
                    while self.port.sock is None:
                        if self.exitevent.isSet():
                            break
                        time.sleep(0.1)
                    logging.debug(_err_msg_reconnect)
                else:
                    logging.debug(_err_msg_exception, inst)
                continue
            if ret[1]:
                # Generate blocklen of random data add them to the FIFO
                # and send them over virtio_console
                buf = ""
                for _ in range(self.blocklen):
                    char = "%c" % random.randrange(rand_a, rand_b)
                    buf += char
                    for queue in self.queues:
                        queue.append(char)
                target = self.idx + self.blocklen
                while not self.exitevent.isSet() and self.idx < target:
                    try:
                        idx = self.port.sock.send(buf)
                    except Exception, inst:
                        # Broken pipe
                        if not hasattr(inst, 'errno') or inst.errno != 32:
                            continue
                        if self.migrate_event is None:
                            self.exitevent.set()
                            raise error.TestFail("ThSendCheck %s: Broken "
                                                 "pipe. If this is expected behavior "
                                                 "set migrate_event to support "
                                                 "reconnection." % self.getName())
                        logging.debug("ThSendCheck %s: Broken pipe "
                                      ", reconnecting. ", self.getName())
                        attempt = 10
                        while (attempt > 1
                               and not self.exitevent.isSet()):
                            # Wait until main thread sets the new self.port
                            while not (self.exitevent.isSet()
                                       or self.migrate_event.wait(1)):
                                pass
                            if self.exitevent.isSet():
                                break
                            logging.debug("ThSendCheck %s: Broken pipe resumed"
                                          ", reconnecting...", self.getName())
                            self.port.sock = False
                            self.port.open()
                            try:
                                idx = self.port.sock.send(buf)
                            except Exception:
                                attempt -= 1
                                time.sleep(10)
                            else:
                                attempt = 0
                    buf = buf[idx:]
                    self.idx += idx
        logging.debug("ThSendCheck %s: exit(%d)", self.getName(),
                      self.idx)
        if too_much_data:
            logging.error("ThSendCheck: working around the 'too_much_data'"
                          "bug")
        self.ret_code = 0


class ThRecv(Thread):

    """
    Receives data and throws it away.
    """

    def __init__(self, port, event, blocklen=1024, quiet=False):
        """
        :param port: Data source port.
        :param event: Exit event.
        :param blocklen: Block length.
        :param quiet: If true don't raise event when crash.
        """
        Thread.__init__(self)
        self.port = port
        self._port_timeout = self.port.gettimeout()
        self.port.settimeout(0.1)
        self.exitevent = event
        self.blocklen = blocklen
        self.idx = 0
        self.quiet = quiet
        self.ret_code = 1    # sets to 0 when finish properly

    def run(self):
        logging.debug("ThRecv %s: run", self.getName())
        try:
            while not self.exitevent.isSet():
                # TODO: Workaround, it didn't work with select :-/
                try:
                    self.idx += len(self.port.recv(self.blocklen))
                except socket.timeout:
                    pass
            self.port.settimeout(self._port_timeout)
            logging.debug("ThRecv %s: exit(%d)", self.getName(), self.idx)
        except Exception, ints:
            if not self.quiet:
                raise ints
            logging.debug(ints)
        self.ret_code = 0


class ThRecvCheck(Thread):

    """
    Random data receiver/checker thread.
    """

    def __init__(self, port, buff, exit_event, blocklen=1024, sendlen=0,
                 migrate_event=None, debug=None):
        """
        :param port: Source port.
        :param buff: Control data buffer (FIFO).
        :param exit_event: Exit event.
        :param blocklen: Block length.
        :param sendlen: Block length of the send function (on guest)
        :param migrate_event: Event indicating port was changed and is ready.
        :param debug: Set the execution mode, when nothing run normal.
        """
        Thread.__init__(self)
        self.port = port
        self.buff = buff
        self.exitevent = exit_event
        self.migrate_event = migrate_event
        self.blocklen = blocklen
        self.idx = 0
        self.sendlen = sendlen + 1  # >=
        self.ret_code = 1    # sets to 0 when finish properly
        self.debug = debug      # see the self.run_* docstrings for details
        # self.sendidx is the maxiaml number of skipped/duplicated values
        # 1) autoreload when the host socket is reconnected. In this case
        #    it waits <30s for migrate_event and reloads sendidx to sendlen
        # 2) manual write to this value (eg. before you reconnect guest port).
        #    RecvThread decreases this value whenever data loss/dup occurs.
        self.sendidx = -1
        self.minsendidx = self.sendlen

    def reload_loss_idx(self):
        """
        This function reloads the acceptable loss to the original value
        (Reload the self.sendidx to self.sendlen)
        :note: This function is automatically called during port reconnection.
        """
        if self.sendidx >= 0:
            self.minsendidx = min(self.minsendidx, self.sendidx)
            logging.debug("ThRecvCheck %s: Previous data loss was %d.",
                          self.getName(), (self.sendlen - self.sendidx))
        self.sendidx = self.sendlen

    def run(self):
        """ Pick the right mode and execute it """
        if self.debug == 'debug':
            self.run_debug()
        elif self.debug == 'normal' or not self.debug:
            self.run_normal()
        else:
            logging.error('ThRecvCheck %s: Unsupported debug mode, using '
                          'normal mode.', self.getName())
            self.run_normal()

    def run_normal(self):
        """
        Receives data and verifies, whether they match the self.buff (queue).
        It allow data loss up to self.sendidx which can be manually loaded
        after host socket reconnection or you can overwrite this value from
        other thread.
        """
        logging.debug("ThRecvCheck %s: run", self.getName())
        _err_msg_missing_migrate_ev = ("ThRecvCheck %s: Broken pipe. If "
                                       "this is expected behavior set migrate_event to "
                                       "support reconnection." % self.getName())
        _err_msg_exception = ('ThRecvCheck ' + str(self.getName()) + ': Got '
                              'exception %s, continuing')
        _err_msg_disconnect = ('ThRecvCheck ' + str(self.getName()) + ': Port '
                               'disconnected, waiting for new port.')
        _err_msg_reconnect = ('ThRecvCheck ' + str(self.getName()) + ': Port '
                              'reconnected, continuing.')
        attempt = 10
        while not self.exitevent.isSet():
            try:
                ret = select.select([self.port.sock], [], [], 1.0)
            except Exception, inst:
                # self.port is not yet set while reconnecting
                if self.port.sock is None:
                    logging.debug(_err_msg_disconnect)
                    while self.port.sock is None:
                        if self.exitevent.isSet():
                            break
                        time.sleep(0.1)
                    logging.debug(_err_msg_reconnect)
                else:
                    logging.debug(_err_msg_exception, inst)
                continue
            if ret[0] and (not self.exitevent.isSet()):
                try:
                    buf = self.port.sock.recv(self.blocklen)
                except Exception, inst:
                    # self.port is not yet set while reconnecting
                    if self.port.sock is None:
                        logging.debug(_err_msg_disconnect)
                        while self.port.sock is None:
                            if self.exitevent.isSet():
                                break
                            time.sleep(0.1)
                        logging.debug(_err_msg_reconnect)
                    else:
                        logging.debug(_err_msg_exception, inst)
                    continue
                if buf:
                    # Compare the received data with the control data
                    for char in buf:
                        _char = self.buff.popleft()
                        if char == _char:
                            self.idx += 1
                        else:
                            # TODO BUG: data from the socket on host can
                            # be lost during migration
                            while char != _char:
                                if self.sendidx > 0:
                                    self.sendidx -= 1
                                    _char = self.buff.popleft()
                                else:
                                    self.exitevent.set()
                                    logging.error("ThRecvCheck %s: "
                                                  "Failed to recv %dth "
                                                  "character",
                                                  self.getName(), self.idx)
                                    logging.error("ThRecvCheck %s: "
                                                  "%s != %s",
                                                  self.getName(),
                                                  repr(char), repr(_char))
                                    logging.error("ThRecvCheck %s: "
                                                  "Recv = %s",
                                                  self.getName(), repr(buf))
                                    # sender might change the buff :-(
                                    time.sleep(1)
                                    _char = ""
                                    for buf in self.buff:
                                        _char += buf
                                        _char += ' '
                                    logging.error("ThRecvCheck %s: "
                                                  "Queue = %s",
                                                  self.getName(), repr(_char))
                                    logging.info("ThRecvCheck %s: "
                                                 "MaxSendIDX = %d",
                                                 self.getName(),
                                                 (self.sendlen - self.sendidx))
                                    raise error.TestFail("ThRecvCheck %s: "
                                                         "incorrect data" %
                                                         self.getName())
                    attempt = 10
                else:   # ! buf
                    # Broken socket
                    if attempt > 0:
                        attempt -= 1
                        if self.migrate_event is None:
                            self.exitevent.set()
                            raise error.TestFail(_err_msg_missing_migrate_ev)
                        logging.debug("ThRecvCheck %s: Broken pipe "
                                      ", reconnecting. ", self.getName())
                        self.reload_loss_idx()
                        # Wait until main thread sets the new self.port
                        while not (self.exitevent.isSet()
                                   or self.migrate_event.wait(1)):
                            pass
                        if self.exitevent.isSet():
                            break
                        logging.debug("ThRecvCheck %s: Broken pipe resumed, "
                                      "reconnecting...", self.getName())

                        self.port.sock = False
                        self.port.open()
        if self.sendidx >= 0:
            self.minsendidx = min(self.minsendidx, self.sendidx)
        if (self.sendlen - self.minsendidx):
            logging.error("ThRecvCheck %s: Data loss occurred during socket"
                          "reconnection. Maximal loss was %d per one "
                          "migration.", self.getName(),
                          (self.sendlen - self.minsendidx))
        logging.debug("ThRecvCheck %s: exit(%d)", self.getName(),
                      self.idx)
        self.ret_code = 0

    def run_debug(self):
        """
        viz run_normal.
        Additionally it stores last n verified characters and in
        case of failures it quickly receive enough data to verify failure or
        allowed loss and then analyze this data. It provides more info about
        the situation.
        Unlike normal run this one supports booth - loss and duplications.
        It's not friendly to data corruption.
        """
        logging.debug("ThRecvCheck %s: run", self.getName())
        attempt = 10
        max_loss = 0
        sum_loss = 0
        verif_buf = deque(maxlen=max(self.blocklen, self.sendlen))
        while not self.exitevent.isSet():
            ret = select.select([self.port.sock], [], [], 1.0)
            if ret[0] and (not self.exitevent.isSet()):
                buf = self.port.sock.recv(self.blocklen)
                if buf:
                    # Compare the received data with the control data
                    for idx_char in xrange(len(buf)):
                        _char = self.buff.popleft()
                        if buf[idx_char] == _char:
                            self.idx += 1
                            verif_buf.append(_char)
                        else:
                            # Detect the duplicated/lost characters.
                            logging.debug("ThRecvCheck %s: fail to receive "
                                          "%dth character.", self.getName(),
                                          self.idx)
                            buf = buf[idx_char:]
                            for i in xrange(100):
                                if len(self.buff) < self.sendidx:
                                    time.sleep(0.01)
                                else:
                                    break
                            sendidx = min(self.sendidx, len(self.buff))
                            if sendidx < self.sendidx:
                                logging.debug("ThRecvCheck %s: sendidx was "
                                              "lowered as there is not enough "
                                              "data after 1s. Using sendidx="
                                              "%s.", self.getName(), sendidx)
                            for _ in xrange(sendidx / self.blocklen):
                                if self.exitevent.isSet():
                                    break
                                buf += self.port.sock.recv(self.blocklen)
                            queue = _char
                            for _ in xrange(sendidx):
                                queue += self.buff[_]
                            offset_a = None
                            offset_b = None
                            for i in xrange(sendidx):
                                length = min(len(buf[i:]), len(queue))
                                if buf[i:] == queue[:length]:
                                    offset_a = i
                                    break
                            for i in xrange(sendidx):
                                length = min(len(queue[i:]), len(buf))
                                if queue[i:][:length] == buf[:length]:
                                    offset_b = i
                                    break

                            if (offset_b and offset_b < offset_a) or offset_a:
                                # Data duplication
                                self.sendidx -= offset_a
                                max_loss = max(max_loss, offset_a)
                                sum_loss += offset_a
                                logging.debug("ThRecvCheck %s: DUP %s (out of "
                                              "%s)", self.getName(), offset_a,
                                              sendidx)
                                buf = buf[offset_a + 1:]
                                for _ in xrange(len(buf)):
                                    self.buff.popleft()
                                verif_buf.extend(buf)
                                self.idx += len(buf)
                            elif offset_b:  # Data loss
                                max_loss = max(max_loss, offset_b)
                                sum_loss += offset_b
                                logging.debug("ThRecvCheck %s: LOST %s (out of"
                                              " %s)", self.getName(), offset_b,
                                              sendidx)
                                # Pop-out the lost characters from verif_queue
                                # (first one is already out)
                                self.sendidx -= offset_b
                                for i in xrange(offset_b - 1):
                                    self.buff.popleft()
                                for _ in xrange(len(buf)):
                                    self.buff.popleft()
                                self.idx += len(buf)
                                verif_buf.extend(buf)
                            else:   # Too big data loss or duplication
                                verif = ""
                                for _ in xrange(-min(sendidx, len(verif_buf)),
                                                0):
                                    verif += verif_buf[_]
                                logging.error("ThRecvCheck %s: mismatched data"
                                              ":\nverified: ..%s\nreceived:   "
                                              "%s\nsent:       %s",
                                              self.getName(), repr(verif),
                                              repr(buf), repr(queue))
                                raise error.TestFail("Recv and sendqueue "
                                                     "don't match with any offset.")
                            # buf was changed, break from this loop
                            attempt = 10
                            break
                    attempt = 10
                else:   # ! buf
                    # Broken socket
                    if attempt > 0:
                        attempt -= 1
                        if self.migrate_event is None:
                            self.exitevent.set()
                            raise error.TestFail("ThRecvCheck %s: Broken pipe."
                                                 " If this is expected behavior set migrate"
                                                 "_event to support reconnection." %
                                                 self.getName())
                        logging.debug("ThRecvCheck %s: Broken pipe "
                                      ", reconnecting. ", self.getName())
                        self.reload_loss_idx()
                        # Wait until main thread sets the new self.port
                        while not (self.exitevent.isSet()
                                   or self.migrate_event.wait(1)):
                            pass
                        if self.exitevent.isSet():
                            break
                        logging.debug("ThRecvCheck %s: Broken pipe resumed, "
                                      "reconnecting...", self.getName())

                        self.port.sock = False
                        self.port.open()
        if self.sendidx >= 0:
            self.minsendidx = min(self.minsendidx, self.sendidx)
        if (self.sendlen - self.minsendidx):
            logging.debug("ThRecvCheck %s: Data loss occurred during socket"
                          "reconnection. Maximal loss was %d per one "
                          "migration.", self.getName(),
                          (self.sendlen - self.minsendidx))
        if sum_loss > 0:
            logging.debug("ThRecvCheck %s: Data offset detected, cumulative "
                          "err: %d, max err: %d(%d)", self.getName(), sum_loss,
                          max_loss, float(max_loss) / self.blocklen)
        logging.debug("ThRecvCheck %s: exit(%d)", self.getName(),
                      self.idx)
        self.ret_code = 0

########NEW FILE########
__FILENAME__ = qemu_vm
"""
Utility classes and functions to handle Virtual Machine creation using qemu.

:copyright: 2008-2009 Red Hat Inc.
"""

import time
import os
import logging
import fcntl
import re
import commands
from autotest.client.shared import error
from autotest.client import utils
from virttest.qemu_devices import qdevices, qcontainer
import utils_misc
import virt_vm
import test_setup
import storage
import qemu_monitor
import aexpect
import qemu_virtio_port
import remote
import data_dir
import utils_net


class QemuSegFaultError(virt_vm.VMError):

    def __init__(self, crash_message):
        virt_vm.VMError.__init__(self, crash_message)
        self.crash_message = crash_message

    def __str__(self):
        return ("Qemu crashed: %s" % self.crash_message)


class VMMigrateProtoUnsupportedError(virt_vm.VMMigrateProtoUnknownError):

    """
    When QEMU tells us it doesn't know about a given migration protocol.

    This usually happens when we're testing older QEMU. It makes sense to
    skip the test in this situation.
    """

    def __init__(self, protocol, output):
        self.protocol = protocol
        self.output = output

    def __str__(self):
        return ("QEMU reports it doesn't know migration protocol '%s'. "
                "QEMU output: %s" % (self.protocol, self.output))


class KVMInternalError(virt_vm.VMError):
    pass


class ImageUnbootableError(virt_vm.VMError):

    def __init__(self, name):
        virt_vm.VMError.__init__(self, name)
        self.name = name

    def __str__(self):
        return ("VM '%s' can't bootup from image,"
                " check your boot disk image file." % self.name)


def clean_tmp_files():
    if os.path.isfile(CREATE_LOCK_FILENAME):
        os.unlink(CREATE_LOCK_FILENAME)

CREATE_LOCK_FILENAME = os.path.join('/tmp', 'virt-test-vm-create.lock')


class VM(virt_vm.BaseVM):

    """
    This class handles all basic VM operations.
    """

    MIGRATION_PROTOS = ['rdma', 'x-rdma', 'tcp', 'unix', 'exec', 'fd']

    # By default we inherit all timeouts from the base VM class except...
    CLOSE_SESSION_TIMEOUT = 30

    # Because we've seen qemu taking longer than 5 seconds to initialize
    # itself completely, including creating the monitor sockets files
    # which are used on create(), this timeout is considerably larger
    # than the one on the base vm class
    CREATE_TIMEOUT = 20

    def __init__(self, name, params, root_dir, address_cache, state=None):
        """
        Initialize the object and set a few attributes.

        :param name: The name of the object
        :param params: A dict containing VM params
                (see method make_qemu_command for a full description)
        :param root_dir: Base directory for relative filenames
        :param address_cache: A dict that maps MAC addresses to IP addresses
        :param state: If provided, use this as self.__dict__
        """

        if state:
            self.__dict__ = state
        else:
            self.process = None
            self.serial_ports = []
            self.serial_console = None
            self.redirs = {}
            self.spice_options = {}
            self.vnc_port = 5900
            self.monitors = []
            self.virtio_ports = []      # virtio_console / virtio_serialport
            self.pci_assignable = None
            self.uuid = None
            self.vcpu_threads = []
            self.vhost_threads = []
            self.devices = None
            self.logs = {}
            self.remote_sessions = []
            self.logsessions = {}

        self.name = name
        self.params = params
        self.root_dir = root_dir
        self.ip_version = self.params.get("ip_version", "ipv4")
        self.address_cache = address_cache
        self.index_in_use = {}
        # This usb_dev_dict member stores usb controller and device info,
        # It's dict, each key is an id of usb controller,
        # and key's value is a list, contains usb devices' ids which
        # attach to this controller.
        # A filled usb_dev_dict may look like:
        # { "usb1" : ["stg1", "stg2", "stg3", "stg4", "stg5", "stg6"],
        #   "usb2" : ["stg7", "stg8"],
        #   ...
        # }
        # This structure can used in usb hotplug/unplug test.
        self.usb_dev_dict = {}
        self.driver_type = 'qemu'
        self.params['driver_type_' + self.name] = self.driver_type
        # virtnet init depends on vm_type/driver_type being set w/in params
        super(VM, self).__init__(name, params)
        # un-overwrite instance attribute, virtnet db lookups depend on this
        if state:
            self.instance = state['instance']
        self.qemu_command = ''
        self.start_time = 0.0
        self.start_monotonic_time = 0.0
        self.last_boot_index = 0
        self.last_driver_index = 0

    def verify_alive(self):
        """
        Make sure the VM is alive and that the main monitor is responsive.

        :raise VMDeadError: If the VM is dead
        :raise: Various monitor exceptions if the monitor is unresponsive
        """
        self.verify_disk_image_bootable()
        self.verify_userspace_crash()
        self.verify_kernel_crash()
        self.verify_illegal_instruction()
        self.verify_kvm_internal_error()
        try:
            virt_vm.BaseVM.verify_alive(self)
            if self.monitor:
                self.monitor.verify_responsive()
        except virt_vm.VMDeadError:
            raise virt_vm.VMDeadError(self.process.get_status(),
                                      self.process.get_output())

    def is_alive(self):
        """
        Return True if the VM is alive and its monitor is responsive.
        """
        return not self.is_dead() and (not self.monitor or
                                       self.monitor.is_responsive())

    def is_dead(self):
        """
        Return True if the qemu process is dead.
        """
        return not self.process or not self.process.is_alive()

    def is_paused(self):
        """
        Return True if the qemu process is paused ('stop'ed)
        """
        if self.is_dead():
            return False
        try:
            self.verify_status("paused")
            return True
        except virt_vm.VMStatusError:
            return False

    def verify_status(self, status):
        """
        Check VM status

        :param status: Optional VM status, 'running' or 'paused'
        :raise VMStatusError: If the VM status is not same as parameter
        """
        if not self.monitor.verify_status(status):
            raise virt_vm.VMStatusError('Unexpected VM status: "%s"' %
                                        self.monitor.get_status())

    def verify_userspace_crash(self):
        """
        Verify if the userspace component (qemu) crashed.
        """
        if "(core dumped)" in self.process.get_output():
            for line in self.process.get_output().splitlines():
                if "(core dumped)" in line:
                    raise QemuSegFaultError(line)

    def verify_kvm_internal_error(self):
        """
        Verify KVM internal error.
        """
        if "KVM internal error." in self.process.get_output():
            out = self.process.get_output()
            out = out[out.find("KVM internal error."):]
            raise KVMInternalError(out)

    def verify_disk_image_bootable(self):
        if self.params.get("image_verify_bootable") == "yes":
            pattern = self.params.get("image_unbootable_pattern")
            if not pattern:
                raise virt_vm.VMConfigMissingError(self.name,
                                                   "image_unbootable_pattern")
            try:
                seabios_log = self.logsessions['seabios'].get_output()
                if re.search(pattern, seabios_log, re.S):
                    logging.error("Can't boot guest from image.")
                    # Set 'shutdown_command' to None to force autotest
                    # shuts down guest with monitor.
                    self.params["shutdown_command"] = None
                    raise ImageUnbootableError(self.name)
            except KeyError:
                pass

    def clone(self, name=None, params=None, root_dir=None, address_cache=None,
              copy_state=False):
        """
        Return a clone of the VM object with optionally modified parameters.
        The clone is initially not alive and needs to be started using create().
        Any parameters not passed to this function are copied from the source
        VM.

        :param name: Optional new VM name
        :param params: Optional new VM creation parameters
        :param root_dir: Optional new base directory for relative filenames
        :param address_cache: A dict that maps MAC addresses to IP addresses
        :param copy_state: If True, copy the original VM's state to the clone.
                Mainly useful for make_qemu_command().
        """
        if name is None:
            name = self.name
        if params is None:
            params = self.params.copy()
        if root_dir is None:
            root_dir = self.root_dir
        if address_cache is None:
            address_cache = self.address_cache
        if copy_state:
            state = self.__dict__.copy()
        else:
            state = None
        return VM(name, params, root_dir, address_cache, state)

    def get_serial_console_filename(self, name=None):
        """
        Return the serial console filename.

        :param name: The serial port name.
        """
        if name:
            return "/tmp/serial-%s-%s" % (name, self.instance)
        return "/tmp/serial-%s" % self.instance

    def get_serial_console_filenames(self):
        """
        Return a list of all serial console filenames
        (as specified in the VM's params).
        """
        return [self.get_serial_console_filename(_) for _ in
                self.params.objects("isa_serials")]

    def cleanup_serial_console(self):
        """
        Close serial console and associated log file
        """
        if self.serial_console is not None:
            self.serial_console.close()
            self.serial_console = None
        if hasattr(self, "migration_file"):
            try:
                os.unlink(self.migration_file)
            except OSError:
                pass

    def make_create_command(self, name=None, params=None, root_dir=None):
        """
        Generate a qemu command line. All parameters are optional. If a
        parameter is not supplied, the corresponding value stored in the
        class attributes is used.

        :param name: The name of the object
        :param params: A dict containing VM params
        :param root_dir: Base directory for relative filenames

        :note: The params dict should contain:
               mem -- memory size in MBs
               cdrom -- ISO filename to use with the qemu -cdrom parameter
               extra_params -- a string to append to the qemu command
               shell_port -- port of the remote shell daemon on the guest
               (SSH, Telnet or the home-made Remote Shell Server)
               shell_client -- client program to use for connecting to the
               remote shell daemon on the guest (ssh, telnet or nc)
               x11_display -- if specified, the DISPLAY environment variable
               will be be set to this value for the qemu process (useful for
               SDL rendering)
               images -- a list of image object names, separated by spaces
               nics -- a list of NIC object names, separated by spaces

               For each image in images:
               drive_format -- string to pass as 'if' parameter for this
               image (e.g. ide, scsi)
               image_snapshot -- if yes, pass 'snapshot=on' to qemu for
               this image
               image_boot -- if yes, pass 'boot=on' to qemu for this image
               In addition, all parameters required by get_image_filename.

               For each NIC in nics:
               nic_model -- string to pass as 'model' parameter for this
               NIC (e.g. e1000)
        """
        # Helper function for command line option wrappers
        def _add_option(option, value, option_type=None, first=False):
            """
            Add option to qemu parameters.
            """
            if first:
                fmt = " %s=%s"
            else:
                fmt = ",%s=%s"
            if option_type is bool:
                # Decode value for bool parameter (supports True, False, None)
                if value in ['yes', 'on', True]:
                    return fmt % (option, "on")
                elif value in ['no', 'off', False]:
                    return fmt % (option, "off")
            elif value and isinstance(value, bool):
                return fmt % (option, "on")
            elif value and isinstance(value, str):
                # "EMPTY_STRING" and "NULL_STRING" is used for testing illegal
                # foramt of option.
                # "EMPTY_STRING": set option as a empty string "".
                # "NO_EQUAL_STRING": set option as a option string only,
                #                    even without "=".
                #      (In most case, qemu-kvm should recognize it as "<null>")
                if value == "NO_EQUAL_STRING":
                    return ",%s" % option
                if value == "EMPTY_STRING":
                    value = '""'
                return fmt % (option, str(value))
            return ""

        # Wrappers for all supported qemu command line parameters.
        # This is meant to allow support for multiple qemu versions.
        # Each of these functions receives the output of 'qemu -help'
        # as a parameter, and should add the requested command line
        # option accordingly.
        def add_name(devices, name):
            return " -name '%s'" % name

        def process_sandbox(devices, action):
            if action == "add":
                if devices.has_option("sandbox"):
                    return " -sandbox on "
            elif action == "rem":
                if devices.has_option("sandbox"):
                    return " -sandbox off "

        def add_human_monitor(devices, monitor_name, filename):
            if not devices.has_option("chardev"):
                return " -monitor unix:'%s',server,nowait" % filename

            monitor_id = "hmp_id_%s" % monitor_name
            cmd = " -chardev socket"
            cmd += _add_option("id", monitor_id)
            cmd += _add_option("path", filename)
            cmd += _add_option("server", "NO_EQUAL_STRING")
            cmd += _add_option("nowait", "NO_EQUAL_STRING")
            cmd += " -mon chardev=%s" % monitor_id
            cmd += _add_option("mode", "readline")
            return cmd

        def add_qmp_monitor(devices, monitor_name, filename):
            if not devices.has_option("qmp"):
                logging.warn("Fallback to human monitor since qmp is"
                             " unsupported")
                return add_human_monitor(devices, monitor_name, filename)

            if not devices.has_option("chardev"):
                return " -qmp unix:'%s',server,nowait" % filename

            monitor_id = "qmp_id_%s" % monitor_name
            cmd = " -chardev socket"
            cmd += _add_option("id", monitor_id)
            cmd += _add_option("path", filename)
            cmd += _add_option("server", "NO_EQUAL_STRING")
            cmd += _add_option("nowait", "NO_EQUAL_STRING")
            cmd += " -mon chardev=%s" % monitor_id
            cmd += _add_option("mode", "control")
            return cmd

        def add_serial(devices, name, filename):
            if not devices.has_option("chardev"):
                return " -serial unix:'%s',server,nowait" % filename

            serial_id = "serial_id_%s" % name
            cmd = " -chardev socket"
            cmd += _add_option("id", serial_id)
            cmd += _add_option("path", filename)
            cmd += _add_option("server", "NO_EQUAL_STRING")
            cmd += _add_option("nowait", "NO_EQUAL_STRING")
            cmd += " -device isa-serial"
            cmd += _add_option("chardev", serial_id)
            return cmd

        def add_virtio_port(devices, name, bus, filename, porttype, chardev,
                            name_prefix=None, index=None, extra_params=""):
            """
            Appends virtio_serialport or virtio_console device to cmdline.
            :param help: qemu -h output
            :param name: Name of the port
            :param bus: Which virtio-serial-pci device use
            :param filename: Path to chardev filename
            :param porttype: Type of the port (*serialport, console)
            :param chardev: Which chardev to use (*socket, spicevmc)
            :param name_prefix: Custom name prefix (port index is appended)
            :param index: Index of the current virtio_port
            :param extra_params: Space sepparated chardev params
            """
            cmd = ''
            # host chardev
            if chardev == "spicevmc":   # SPICE
                cmd += " -chardev spicevmc,id=dev%s,name=%s" % (name, name)
            else:   # SOCKET
                cmd = (" -chardev socket,id=dev%s,path=%s,server,nowait"
                       % (name, filename))
            # virtport device
            if porttype in ("console", "virtio_console"):
                cmd += " -device virtconsole"
            else:
                cmd += " -device virtserialport"
            if name_prefix:     # used by spiceagent (com.redhat.spice.*)
                port_name = "%s%d" % (name_prefix, index)
            else:
                port_name = name
            cmd += ",chardev=dev%s,name=%s,id=%s" % (name, port_name, name)
            cmd += _add_option("bus", bus)
            # Space sepparated chardev params
            _params = ""
            for parm in extra_params.split():
                _params += ',' + parm
            cmd += _params
            return cmd

        def add_log_seabios(devices):
            if not devices.has_device("isa-debugcon"):
                return ""

            default_id = "seabioslog_id_%s" % self.instance
            filename = "/tmp/seabios-%s" % self.instance
            self.logs["seabios"] = filename
            cmd = " -chardev socket"
            cmd += _add_option("id", default_id)
            cmd += _add_option("path", filename)
            cmd += _add_option("server", "NO_EQUAL_STRING")
            cmd += _add_option("nowait", "NO_EQUAL_STRING")
            cmd += " -device isa-debugcon"
            cmd += _add_option("chardev", default_id)
            cmd += _add_option("iobase", "0x402")
            return cmd

        def add_log_anaconda(devices, pci_bus='pci.0'):
            chardev_id = "anacondalog_chardev_%s" % self.instance
            vioser_id = "anacondalog_vioser_%s" % self.instance
            filename = "/tmp/anaconda-%s" % self.instance
            self.logs["anaconda"] = filename
            dev = qdevices.QCustomDevice('chardev', backend='backend')
            dev.set_param('backend', 'socket')
            dev.set_param('id', chardev_id)
            dev.set_param("path", filename)
            dev.set_param("server", 'NO_EQUAL_STRING')
            dev.set_param("nowait", 'NO_EQUAL_STRING')
            devices.insert(dev)
            dev = QDevice('virtio-serial-pci', parent_bus=pci_bus)
            dev.set_param("id", vioser_id)
            devices.insert(dev)
            dev = QDevice('virtserialport')
            dev.set_param("bus", "%s.0" % vioser_id)
            dev.set_param("chardev", chardev_id)
            dev.set_param("name", "org.fedoraproject.anaconda.log.0")
            devices.insert(dev)

        def add_mem(devices, mem):
            return " -m %s" % mem

        def add_smp(devices):
            smp_str = " -smp %d" % self.cpuinfo.smp
            smp_pattern = "smp .*n\[,maxcpus=cpus\].*"
            if devices.has_option(smp_pattern):
                smp_str += ",maxcpus=%d" % self.cpuinfo.maxcpus
            smp_str += ",cores=%d" % self.cpuinfo.cores
            smp_str += ",threads=%d" % self.cpuinfo.threads
            smp_str += ",sockets=%d" % self.cpuinfo.sockets
            return smp_str

        def add_nic(devices, vlan, model=None, mac=None, device_id=None,
                    netdev_id=None, nic_extra_params=None, pci_addr=None,
                    bootindex=None, queues=1, vectors=None, pci_bus='pci.0'):
            if model == 'none':
                return
            if devices.has_option("device"):
                if not model:
                    model = "rtl8139"
                elif model == "virtio":
                    model = "virtio-net-pci"
                dev = QDevice(model)
                dev.set_param('mac', mac, dynamic=True)
                # only pci domain=0,bus=0,function=0 is supported for now.
                #
                # libvirt gains the pci_slot, free_pci_addr here,
                # value by parsing the xml file, i.e. counting all the
                # pci devices and store the number.
                if model != 'spapr-vlan':
                    dev.parent_bus = pci_bus
                    dev.set_param('addr', pci_addr)
                if nic_extra_params:
                    nic_extra_params = (_.split('=', 1) for _ in
                                        nic_extra_params.split(',') if _)
                    for key, val in nic_extra_params:
                        dev.set_param(key, val)
                dev.set_param("bootindex", bootindex)
            else:
                dev = qdevices.QCustomDevice('net', backend='type')
                dev.set_param('type', 'nic')
                dev.set_param('model', model)
                dev.set_param('macaddr', mac, 'NEED_QUOTE', True)
            dev.set_param('id', device_id, 'NEED_QUOTE')
            if "virtio" in model:
                if int(queues) > 1:
                    dev.set_param('mq', 'on')
                if vectors:
                    dev.set_param('vectors', vectors)
            if devices.has_option("netdev"):
                dev.set_param('netdev', netdev_id)
            else:
                dev.set_param('vlan', vlan)
            devices.insert(dev)

        def add_net(devices, vlan, nettype, ifname=None, tftp=None,
                    bootfile=None, hostfwd=[], netdev_id=None,
                    netdev_extra_params=None, tapfds=None, script=None,
                    downscript=None, vhost=None, queues=None, vhostfds=None,
                    add_queues=None, helper=None, add_tapfd=None,
                    add_vhostfd=None):
            mode = None
            if nettype in ['bridge', 'network', 'macvtap']:
                mode = 'tap'
            elif nettype == 'user':
                mode = 'user'
            else:
                logging.warning("Unknown/unsupported nettype %s" % nettype)
                return ''

            if devices.has_option("netdev"):
                cmd = " -netdev %s,id=%s" % (mode, netdev_id)
                cmd_nd = cmd
                if vhost:
                    if vhost in ["on", "off"]:
                        cmd += ",vhost=%s" % vhost
                    elif vhost == "vhost=on":  # Keeps compatibility with old.
                        cmd += ",%s" % vhost
                    cmd_nd = cmd
                    if vhostfds:
                        if (int(queues) > 1 and
                                'vhostfds=' in devices.get_help_text()):
                            cmd += ",vhostfds=%(vhostfds)s"
                            cmd_nd += ",vhostfds=DYN"
                        else:
                            txt = ""
                            if int(queues) > 1:
                                txt = "qemu do not support vhost multiqueue,"
                                txt += " Fall back to single queue."
                            if 'vhostfd=' in devices.get_help_text():
                                cmd += ",vhostfd=%(vhostfd)s"
                                cmd_nd += ",vhostfd=DYN"
                            else:
                                txt += " qemu do not support vhostfd."
                            if txt:
                                logging.warn(txt)
                        # For negative test
                        if add_vhostfd:
                            cmd += ",vhostfd=%(vhostfd)s"
                            cmd_nd += ",vhostfd=%(vhostfd)s"
                if netdev_extra_params:
                    cmd += "%s" % netdev_extra_params
                    cmd_nd += "%s" % netdev_extra_params
            else:
                cmd = " -net %s,vlan=%d" % (mode, vlan)
                cmd_nd = cmd
            if mode == "tap":
                if script:
                    cmd += ",script='%s'" % script
                    cmd += ",downscript='%s'" % (downscript or "no")
                    cmd_nd = cmd
                    if ifname:
                        cmd += ",ifname='%s'" % ifname
                        cmd_nd = cmd
                elif tapfds:
                    if (int(queues) > 1 and
                            ',fds=' in devices.get_help_text()):
                        cmd += ",fds=%(tapfds)s"
                        cmd_nd += ",fds=DYN"
                    else:
                        cmd += ",fd=%(tapfd)s"
                        cmd_nd += ",fd=DYN"
                    # For negative test
                    if add_tapfd:
                        cmd += ",fd=%(tapfd)s"
                        cmd_nd += ",fd=%(tapfd)s"
            elif mode == "user":
                if tftp and "[,tftp=" in devices.get_help_text():
                    cmd += ",tftp='%s'" % tftp
                    cmd_nd = cmd
                if bootfile and "[,bootfile=" in devices.get_help_text():
                    cmd += ",bootfile='%s'" % bootfile
                    cmd_nd = cmd
                if "[,hostfwd=" in devices.get_help_text():
                    for i in xrange(len(hostfwd)):
                        cmd += (",hostfwd=tcp::%%(host_port%d)s"
                                "-:%%(guest_port%d)s" % (i, i))
                        cmd_nd += ",hostfwd=tcp::DYN-:%%(guest_port)ds"

            if add_queues and queues:
                cmd += ",queues=%s" % queues
                cmd_nd += ",queues=%s" % queues

            if helper:
                cmd += ",helper=%s" % helper
                cmd_nd += ",helper=%s" % helper

            return cmd, cmd_nd

        def add_floppy(devices, filename, index):
            cmd_list = [" -fda '%s'", " -fdb '%s'"]
            return cmd_list[index] % filename

        def add_tftp(devices, filename):
            # If the new syntax is supported, don't add -tftp
            if "[,tftp=" in devices.get_help_text():
                return ""
            else:
                return " -tftp '%s'" % filename

        def add_bootp(devices, filename):
            # If the new syntax is supported, don't add -bootp
            if "[,bootfile=" in devices.get_help_text():
                return ""
            else:
                return " -bootp '%s'" % filename

        def add_tcp_redir(devices, host_port, guest_port):
            # If the new syntax is supported, don't add -redir
            if "[,hostfwd=" in devices.get_help_text():
                return ""
            else:
                return " -redir tcp:%s::%s" % (host_port, guest_port)

        def add_vnc(devices, vnc_port, vnc_password='no', extra_params=None):
            vnc_cmd = " -vnc :%d" % (vnc_port - 5900)
            if vnc_password == "yes":
                vnc_cmd += ",password"
            if extra_params:
                vnc_cmd += ",%s" % extra_params
            return vnc_cmd

        def add_sdl(devices):
            if devices.has_option("sdl"):
                return " -sdl"
            else:
                return ""

        def add_nographic(devices):
            return " -nographic"

        def add_uuid(devices, uuid):
            return " -uuid '%s'" % uuid

        def add_pcidevice(devices, host, params, device_driver="pci-assign",
                          pci_bus='pci.0'):
            if devices.has_device(device_driver):
                dev = QDevice(device_driver, parent_bus=pci_bus)
            else:
                dev = qdevices.QCustomDevice('pcidevice', parent_bus=pci_bus)
            help_cmd = "%s -device %s,\\? 2>&1" % (qemu_binary, device_driver)
            pcidevice_help = utils.system_output(help_cmd)
            dev.set_param('host', host)
            dev.set_param('id', 'id_%s' % host.replace(":", "."))
            fail_param = []
            for param in params.get("pci-assign_params", "").split():
                value = params.get(param)
                if value:
                    if param in pcidevice_help:
                        dev.set_param(param, value)
                    else:
                        fail_param.append(param)
            if fail_param:
                msg = ("parameter %s is not support in device pci-assign."
                       " It only support following parameter:\n %s" %
                       (", ".join(fail_param), pcidevice_help))
                logging.warn(msg)
            devices.insert(dev)

        def add_spice_rhel5(devices, spice_params, port_range=(3100, 3199)):
            """
            processes spice parameters on rhel5 host.

            :param spice_options - dict with spice keys/values
            :param port_range - tuple with port range, default: (3000, 3199)
            """

            if devices.has_option("spice"):
                cmd = " -spice"
            else:
                return ""
            spice_help = ""
            if devices.has_option("spice-help"):
                spice_help = commands.getoutput("%s -device \\?" % qemu_binary)
            s_port = str(utils_misc.find_free_port(*port_range))
            self.spice_options['spice_port'] = s_port
            cmd += " port=%s" % s_port
            for param in spice_params.split():
                value = params.get(param)
                if value:
                    if bool(re.search(param, spice_help, re.M)):
                        cmd += ",%s=%s" % (param, value)
                    else:
                        msg = ("parameter %s is not supported in spice. It "
                               "only supports the following parameters:\n %s"
                               % (param, spice_help))
                        logging.warn(msg)
                else:
                    cmd += ",%s" % param
            if devices.has_option("qxl"):
                qxl_dev_nr = params.get("qxl_dev_nr", 1)
                cmd += " -qxl %s" % qxl_dev_nr
            return cmd

        def add_spice(port_range=(3000, 3199),
                      tls_port_range=(3200, 3399)):
            """
            processes spice parameters
            :param port_range - tuple with port range, default: (3000, 3199)
            :param tls_port_range - tuple with tls port range,
                                    default: (3200, 3399)
            """
            spice_opts = []  # will be used for ",".join()
            tmp = None

            def optget(opt):
                """a helper function"""
                return self.spice_options.get(opt)

            def set_yes_no_value(key, yes_value=None, no_value=None):
                """just a helper function"""
                tmp = optget(key)
                if tmp == "no" and no_value:
                    spice_opts.append(no_value)

                elif tmp == "yes" and yes_value:
                    spice_opts.append(yes_value)

            def set_value(opt_string, key, fallback=None):
                """just a helper function"""
                tmp = optget(key)
                if tmp:
                    spice_opts.append(opt_string % tmp)
                elif fallback:
                    spice_opts.append(fallback)
            s_port = str(utils_misc.find_free_port(*port_range))
            if optget("spice_port") == "generate":
                if not self.is_alive():
                    self.spice_options['spice_port'] = s_port
                    spice_opts.append("port=%s" % s_port)
                    self.spice_port = s_port
                else:
                    self.spice_options['spice_port'] = self.spice_port
                    spice_opts.append("port=%s" % self.spice_port)
            else:
                set_value("port=%s", "spice_port")

            set_value("password=%s", "spice_password", "disable-ticketing")
            if optget("listening_addr") == "ipv4":
                host_ip = utils_net.get_host_ip_address(self.params)
                self.spice_options['listening_addr'] = "ipv4"
                spice_opts.append("addr=%s" % host_ip)
                # set_value("addr=%s", "listening_addr", )
            elif optget("listening_addr") == "ipv6":
                host_ip = utils_net.get_host_ip_address(self.params)
                host_ip_ipv6 = utils_misc.convert_ipv4_to_ipv6(host_ip)
                self.spice_options['listening_addr'] = "ipv6"
                spice_opts.append("addr=%s" % host_ip_ipv6)

            set_yes_no_value(
                "disable_copy_paste", yes_value="disable-copy-paste")
            set_value("addr=%s", "spice_addr")

            if optget("spice_ssl") == "yes":
                # SSL only part
                t_port = str(utils_misc.find_free_port(*tls_port_range))
                if optget("spice_tls_port") == "generate":
                    if not self.is_alive():
                        self.spice_options['spice_tls_port'] = t_port
                        spice_opts.append("tls-port=%s" % t_port)
                        self.spice_tls_port = t_port
                    else:
                        self.spice_options[
                            'spice_tls_port'] = self.spice_tls_port
                        spice_opts.append("tls-port=%s" % self.spice_tls_port)
                else:
                    set_value("tls-port=%s", "spice_tls_port")

                prefix = optget("spice_x509_prefix")
                if ((prefix is None or not os.path.exists(prefix)) and
                        (optget("spice_gen_x509") == "yes")):
                    # Generate spice_x509_* is not always necessary,
                    # Regenerate them will make your existing VM
                    # not longer accessiable via encrypted spice.
                    c_subj = optget("spice_x509_cacert_subj")
                    s_subj = optget("spice_x509_server_subj")
                    # If CN is not specified, add IP of host
                    if s_subj[-3:] == "CN=":
                        s_subj += utils_net.get_host_ip_address(self.params)
                    passwd = optget("spice_x509_key_password")
                    secure = optget("spice_x509_secure")

                    utils_misc.create_x509_dir(prefix, c_subj, s_subj, passwd,
                                               secure)

                tmp = optget("spice_x509_dir")
                if tmp == "yes":
                    spice_opts.append("x509-dir=%s" % (prefix))

                elif tmp == "no":
                    cacert = optget("spice_x509_cacert_file")
                    server_key = optget("spice_x509_key_file")
                    server_cert = optget("spice_x509_cert_file")
                    keyfile_str = ("x509-key-file=%s,x509-cacert-file=%s,"
                                   "x509-cert-file=%s" %
                                   (os.path.join(prefix, server_key),
                                    os.path.join(prefix, cacert),
                                    os.path.join(prefix, server_cert)))
                    spice_opts.append(keyfile_str)

                set_yes_no_value("spice_x509_secure",
                                 yes_value="x509-key-password=%s" %
                                 (optget("spice_x509_key_password")))

                tmp = optget("spice_secure_channels")
                if tmp:
                    for item in tmp.split(","):
                        spice_opts.append("tls-channel=%s" % (item.strip()))

            # Less common options
            set_value("seamless-migration=%s", "spice_seamless_migration")
            set_value("image-compression=%s", "spice_image_compression")
            set_value("jpeg-wan-compression=%s", "spice_jpeg_wan_compression")
            set_value("zlib-glz-wan-compression=%s",
                      "spice_zlib_glz_wan_compression")
            set_value("streaming-video=%s", "spice_streaming_video")
            set_value("agent-mouse=%s", "spice_agent_mouse")
            set_value("playback-compression=%s", "spice_playback_compression")

            set_yes_no_value("spice_ipv4", yes_value="ipv4")
            set_yes_no_value("spice_ipv6", yes_value="ipv6")

            return " -spice %s" % (",".join(spice_opts))

        def add_qxl(qxl_nr, qxl_memory=None):
            """
            adds extra qxl devices + sets memory to -vga qxl and extra qxls
            :param qxl_nr total number of qxl devices
            :param qxl_memory sets memory to individual devices
            """
            qxl_str = ""
            vram_help = ""

            if qxl_memory:
                vram_help = "vram_size=%d" % qxl_memory
                qxl_str += " -global qxl-vga.%s" % (vram_help)

            for index in range(1, qxl_nr):
                qxl_str += " -device qxl,id=video%d,%s"\
                    % (index, vram_help)
            return qxl_str

        def add_vga(vga):
            return " -vga %s" % vga

        def add_kernel(devices, filename):
            return " -kernel '%s'" % filename

        def add_initrd(devices, filename):
            return " -initrd '%s'" % filename

        def add_rtc(devices):
            # Pay attention that rtc-td-hack is for early version
            # if "rtc " in help:
            if devices.has_option("rtc"):
                cmd = " -rtc base=%s" % params.get("rtc_base", "utc")
                cmd += _add_option("clock", params.get("rtc_clock", "host"))
                cmd += _add_option("driftfix", params.get("rtc_drift", "none"))
                return cmd
            elif devices.has_option("rtc-td-hack"):
                return " -rtc-td-hack"
            else:
                return ""

        def add_kernel_cmdline(devices, cmdline):
            return " -append '%s'" % cmdline

        def add_testdev(devices, filename=None):
            if devices.has_device("testdev"):
                return (" -chardev file,id=testlog,path=%s"
                        " -device testdev,chardev=testlog" % filename)
            elif devices.has_device("pc-testdev"):
                return " -device pc-testdev"
            else:
                return ""

        def add_isa_debug_exit(devices, iobase=0xf4, iosize=0x04):
            if devices.has_device("isa-debug-exit"):
                return (" -device isa-debug-exit,iobase=%s,iosize=%s" %
                        (iobase, iosize))
            else:
                return ""

        def add_no_hpet(devices):
            if devices.has_option("no-hpet"):
                return " -no-hpet"
            else:
                return ""

        def add_cpu_flags(devices, cpu_model, flags=None, vendor_id=None,
                          family=None):
            if devices.has_option('cpu'):
                cmd = " -cpu '%s'" % cpu_model

                if vendor_id:
                    cmd += ",vendor=\"%s\"" % vendor_id
                if flags:
                    if not flags.startswith(","):
                        cmd += ","
                    cmd += "%s" % flags
                if family is not None:
                    cmd += ",family=%s" % family
                return cmd
            else:
                return ""

        def add_boot(devices, boot_order, boot_once, boot_menu):
            cmd = " -boot"
            pattern = "boot \[order=drives\]\[,once=drives\]\[,menu=on\|off\]"
            if devices.has_option("boot \[a\|c\|d\|n\]"):
                cmd += " %s" % boot_once
            elif devices.has_option(pattern):
                cmd += (" order=%s,once=%s,menu=%s" %
                        (boot_order, boot_once, boot_menu))
            else:
                cmd = ""
            return cmd

        def get_index(index):
            while self.index_in_use.get(str(index)):
                index += 1
            return index

        def add_sga(devices):
            if not devices.has_option("device"):
                return ""

            return " -device sga"

        def add_watchdog(devices, device_type=None, action="reset"):
            watchdog_cmd = ""
            if devices.has_option("watchdog"):
                if device_type:
                    watchdog_cmd += " -watchdog %s" % device_type
                watchdog_cmd += " -watchdog-action %s" % action

            return watchdog_cmd

        def add_option_rom(devices, opt_rom):
            if not devices.has_option("option-rom"):
                return ""

            return " -option-rom %s" % opt_rom

        def add_smartcard(devices, sc_chardev, sc_id):
            sc_cmd = " -device usb-ccid,id=ccid0"
            sc_cmd += " -chardev " + sc_chardev
            sc_cmd += ",id=" + sc_id + ",name=smartcard"
            sc_cmd += " -device ccid-card-passthru,chardev=" + sc_id

            return sc_cmd

        def add_numa_node(devices, mem=None, cpus=None, nodeid=None):
            """
            This function used to add numa node to guest command line
            """
            if not devices.has_option("numa"):
                return ""
            numa_cmd = " -numa node"
            if mem is not None:
                numa_cmd += ",mem=%s" % mem
            if cpus is not None:
                numa_cmd += ",cpus=%s" % cpus
            if nodeid is not None:
                numa_cmd += ",nodeid=%s" % nodeid
            return numa_cmd

        # End of command line option wrappers

        # If nothing changed and devices exists, return imediatelly
        if (name is None and params is None and root_dir is None
                and self.devices is not None):
            return self.devices

        if name is None:
            name = self.name
        if params is None:
            params = self.params
        if root_dir is None:
            root_dir = self.root_dir

        have_ahci = False
        have_virtio_scsi = False
        virtio_scsi_pcis = []
        pci_bus = {'aobject': params.get('pci_bus', 'pci.0')}

        # init value by default.
        # PCI addr 0,1,2 are taken by PCI/ISA/IDE bridge and the GPU.
        self.pci_addr_list = [0, 1, 2]

        # Clone this VM using the new params
        vm = self.clone(name, params, root_dir, copy_state=True)

        # global counters
        ide_bus = 0
        ide_unit = 0
        vdisk = 0
        scsi_disk = 0
        self.last_boot_index = 0
        if params.get("kernel"):
            self.last_boot_index = 1

        qemu_binary = utils_misc.get_qemu_binary(params)

        self.qemu_binary = qemu_binary
        support_cpu_model = commands.getoutput("%s -cpu \\?" % qemu_binary)

        self.last_driver_index = 0
        # init the dict index_in_use
        for key in params.keys():
            if 'drive_index' in key:
                self.index_in_use[params.get(key)] = True

        cmd = ""
        # Enable the use of glibc's malloc_perturb feature
        if params.get("malloc_perturb", "no") == "yes":
            cmd += "MALLOC_PERTURB_=1 "
        # Set the X11 display parameter if requested
        if params.get("x11_display"):
            cmd += "DISPLAY=%s " % params.get("x11_display")
        if params.get("qemu_audio_drv"):
            cmd += "QEMU_AUDIO_DRV=%s " % params.get("qemu_audio_drv")
        # Add command prefix for qemu-kvm. like taskset, valgrind and so on
        if params.get("qemu_command_prefix"):
            qemu_command_prefix = params.get("qemu_command_prefix")
            cmd += "%s " % qemu_command_prefix
        # Add numa memory cmd to pin guest memory to numa node
        if params.get("numa_node"):
            numa_node = int(params.get("numa_node"))
            if len(utils_misc.get_node_cpus()) < int(params.get("smp", 1)):
                logging.info("Skip pinning, no enough nodes")
            elif numa_node < 0:
                n = utils_misc.NumaNode(numa_node)
                cmd += "numactl -m %s " % n.node_id
            else:
                n = numa_node - 1
                cmd += "numactl -m %s " % n

        # Start constructing devices representation
        devices = qcontainer.DevContainer(qemu_binary, self.name,
                                          params.get('strict_mode'),
                                          params.get('workaround_qemu_qmp_crash'),
                                          params.get('allow_hotplugged_vm'))
        StrDev = qdevices.QStringDevice
        QDevice = qdevices.QDevice

        devices.insert(StrDev('PREFIX', cmdline=cmd))
        # Add the qemu binary
        devices.insert(StrDev('qemu', cmdline=qemu_binary))
        devices.insert(StrDev('-S', cmdline="-S"))
        # Add the VM's name
        devices.insert(StrDev('vmname', cmdline=add_name(devices, name)))

        if params.get("qemu_sandbox", "on") == "on":
            devices.insert(StrDev('sandbox', cmdline=process_sandbox(devices, "add")))
        elif params.get("sandbox", "off") == "off":
            devices.insert(StrDev('qemu_sandbox', cmdline=process_sandbox(devices, "rem")))

        devs = devices.machine_by_params(params)
        for dev in devs:
            devices.insert(dev)

        # no automagic devices please
        defaults = params.get("defaults", "no")
        if devices.has_option("nodefaults") and defaults != "yes":
            devices.insert(StrDev('nodefaults', cmdline=" -nodefaults"))

        vga = params.get("vga")
        if vga:
            if vga != 'none':
                devices.insert(StrDev('VGA-%s' % vga,
                                      cmdline=add_vga(vga),
                                      parent_bus={'aobject': 'pci.0'}))
            else:
                devices.insert(StrDev('VGA-none', cmdline=add_vga(vga)))

            if vga == "qxl":
                qxl_dev_memory = int(params.get("qxl_dev_memory", 0))
                qxl_dev_nr = int(params.get("qxl_dev_nr", 1))
                devices.insert(StrDev('qxl',
                                      cmdline=add_qxl(qxl_dev_nr, qxl_dev_memory)))
        elif params.get('defaults', 'no') != 'no':  # by default add cirrus
            devices.insert(StrDev('VGA-cirrus',
                                  cmdline=add_vga(vga),
                                  parent_bus={'aobject': 'pci.0'}))

        # When old scsi fmt is used, new device with lowest pci_addr is created
        devices.hook_fill_scsi_hbas(params)

        # Additional PCI RC/switch/bridges
        for pcic in params.objects("pci_controllers"):
            devs = devices.pcic_by_params(pcic, params.object_params(pcic))
            devices.insert(devs)

        # -soundhw addresses are always the lowest after scsi
        soundhw = params.get("soundcards")
        if soundhw:
            if not devices.has_option('device') or soundhw == "all":
                for sndcard in ('AC97', 'ES1370', 'intel-hda'):
                    # Add all dummy PCI devices and the actuall command below
                    devices.insert(StrDev("SND-%s" % sndcard,
                                          parent_bus=pci_bus))
                devices.insert(StrDev('SoundHW',
                                      cmdline="-soundhw %s" % soundhw))
            else:
                # TODO: Use QDevices for this and set the addresses properly
                for sound_device in soundhw.split(","):
                    if "hda" in sound_device:
                        devices.insert(QDevice('intel-hda',
                                               parent_bus=pci_bus))
                        devices.insert(QDevice('hda-duplex'))
                    elif sound_device in ["es1370", "ac97"]:
                        devices.insert(QDevice(sound_device.upper(),
                                               parent_bus=pci_bus))
                    else:
                        devices.insert(QDevice(sound_device,
                                               parent_bus=pci_bus))

        # Add monitors
        for monitor_name in params.objects("monitors"):
            monitor_params = params.object_params(monitor_name)
            monitor_filename = qemu_monitor.get_monitor_filename(vm,
                                                                 monitor_name)
            if monitor_params.get("monitor_type") == "qmp":
                cmd = add_qmp_monitor(devices, monitor_name,
                                      monitor_filename)
                devices.insert(StrDev('QMP-%s' % monitor_name, cmdline=cmd))
            else:
                cmd = add_human_monitor(devices, monitor_name,
                                        monitor_filename)
                devices.insert(StrDev('HMP-%s' % monitor_name, cmdline=cmd))

        # Add serial console redirection
        for serial in params.objects("isa_serials"):
            serial_filename = vm.get_serial_console_filename(serial)
            cmd = add_serial(devices, serial, serial_filename)
            devices.insert(StrDev('SER-%s' % serial, cmdline=cmd))

        # Add virtio_serial ports
        no_virtio_serial_pcis = 0
        no_virtio_ports = 0
        virtio_port_spread = int(params.get('virtio_port_spread', 2))
        for port_name in params.objects("virtio_ports"):
            port_params = params.object_params(port_name)
            bus = params.get('virtio_port_bus', False)
            if bus is not False:     # Manually set bus
                bus = int(bus)
            elif not virtio_port_spread:
                # bus not specified, let qemu decide
                pass
            elif not no_virtio_ports % virtio_port_spread:
                # Add new vio-pci every n-th port. (Spread ports)
                bus = no_virtio_serial_pcis
            else:  # Port not overriden, use last vio-pci
                bus = no_virtio_serial_pcis - 1
                if bus < 0:     # First bus
                    bus = 0
            # Add virtio_serial_pcis
            # Multiple virtio console devices can't share a
            # single virtio-serial-pci bus. So add a virtio-serial-pci bus
            # when the port is a virtio console.
            if (port_params.get('virtio_port_type') == 'console'
                    and params.get('virtio_port_bus') is None):
                dev = QDevice('virtio-serial-pci', parent_bus=pci_bus)
                dev.set_param('id',
                              'virtio_serial_pci%d' % no_virtio_serial_pcis)
                devices.insert(dev)
                no_virtio_serial_pcis += 1
            for i in range(no_virtio_serial_pcis, bus + 1):
                dev = QDevice('virtio-serial-pci', parent_bus=pci_bus)
                dev.set_param('id', 'virtio_serial_pci%d' % i)
                devices.insert(dev)
                no_virtio_serial_pcis += 1
            if bus is not False:
                bus = "virtio_serial_pci%d.0" % bus
            # Add actual ports
            cmd = add_virtio_port(devices, port_name, bus,
                                  self.get_virtio_port_filename(port_name),
                                  port_params.get('virtio_port_type'),
                                  port_params.get('virtio_port_chardev'),
                                  port_params.get('virtio_port_name_prefix'),
                                  no_virtio_ports,
                                  port_params.get('virtio_port_params', ''))
            devices.insert(StrDev('VIO-%s' % port_name, cmdline=cmd))
            no_virtio_ports += 1

        # Add logging
        devices.insert(StrDev('isa-log', cmdline=add_log_seabios(devices)))
        if params.get("anaconda_log", "no") == "yes":
            add_log_anaconda(devices, pci_bus)

        # Add USB controllers
        usbs = params.objects("usbs")
        if not devices.has_option("device"):
            usbs = ("oldusb",)  # Old qemu, add only one controller '-usb'
        for usb_name in usbs:
            usb_params = params.object_params(usb_name)
            for dev in devices.usbc_by_params(usb_name, usb_params):
                devices.insert(dev)

        # Add images (harddrives)
        for image_name in params.objects("images"):
            # FIXME: Use qemu_devices for handling indexes
            image_params = params.object_params(image_name)
            if image_params.get("boot_drive") == "no":
                continue
            if params.get("index_enable") == "yes":
                drive_index = image_params.get("drive_index")
                if drive_index:
                    index = drive_index
                else:
                    self.last_driver_index = get_index(self.last_driver_index)
                    index = str(self.last_driver_index)
                    self.last_driver_index += 1
            else:
                index = None
            image_bootindex = None
            image_boot = image_params.get("image_boot")
            if not re.search("boot=on\|off", devices.get_help_text(),
                             re.MULTILINE):
                if image_boot in ['yes', 'on', True]:
                    image_bootindex = str(self.last_boot_index)
                    self.last_boot_index += 1
                image_boot = "unused"
                image_bootindex = image_params.get('bootindex',
                                                   image_bootindex)
            else:
                if image_boot in ['yes', 'on', True]:
                    if self.last_boot_index > 0:
                        image_boot = False
                    self.last_boot_index += 1
            image_params = params.object_params(image_name)
            if image_params.get("boot_drive") == "no":
                continue
            devs = devices.images_define_by_params(image_name, image_params,
                                                   'disk', index, image_boot,
                                                   image_bootindex)
            for _ in devs:
                devices.insert(_)

        # Networking
        redirs = []
        for redir_name in params.objects("redirs"):
            redir_params = params.object_params(redir_name)
            guest_port = int(redir_params.get("guest_port"))
            host_port = vm.redirs.get(guest_port)
            redirs += [(host_port, guest_port)]

        iov = 0
        for nic in vm.virtnet:
            nic_params = params.object_params(nic.nic_name)
            if nic_params.get('pci_assignable') == "no":
                script = nic_params.get("nic_script")
                downscript = nic_params.get("nic_downscript")
                vhost = nic_params.get("vhost")
                script_dir = data_dir.get_data_dir()
                if script:
                    script = utils_misc.get_path(script_dir, script)
                if downscript:
                    downscript = utils_misc.get_path(script_dir, downscript)
                # setup nic parameters as needed
                # add_netdev if netdev_id not set
                nic = vm.add_nic(**dict(nic))
                # gather set values or None if unset
                vlan = int(nic.get('vlan'))
                netdev_id = nic.get('netdev_id')
                device_id = nic.get('device_id')
                mac = nic.get('mac')
                nic_model = nic.get("nic_model")
                nic_extra = nic.get("nic_extra_params")
                bootindex = nic_params.get("bootindex")
                netdev_extra = nic.get("netdev_extra_params")
                bootp = nic.get("bootp")
                add_queues = nic_params.get("add_queues", "no") == "yes"
                add_tapfd = nic_params.get("add_tapfd", "no") == "yes"
                add_vhostfd = nic_params.get("add_vhostfd", "no") == "yes"
                helper = nic_params.get("helper")
                tapfds_len = int(nic_params.get("tapfds_len", -1))
                vhostfds_len = int(nic_params.get("vhostfds_len", -1))
                if nic.get("tftp"):
                    tftp = utils_misc.get_path(root_dir, nic.get("tftp"))
                else:
                    tftp = None
                nettype = nic.get("nettype", "bridge")
                # don't force conversion add_nic()/add_net() optional parameter
                if 'tapfds' in nic:
                    tapfds = nic.tapfds
                else:
                    tapfds = None
                if 'vhostfds' in nic:
                    vhostfds = nic.vhostfds
                else:
                    vhostfds = None
                ifname = nic.get('ifname')
                queues = nic.get("queues", 1)
                # specify the number of MSI-X vectors that the card should have;
                # this option currently only affects virtio cards
                if nic_params.get("enable_msix_vectors") == "yes":
                    if "vectors" in nic:
                        vectors = nic.vectors
                    else:
                        vectors = 2 * int(queues) + 2
                else:
                    vectors = None

                # Setup some exclusive parameters if we are not running a
                # negative test.
                if nic_params.get("run_invalid_cmd_nic") != "yes":
                    if vhostfds or tapfds or add_queues:
                        helper = None
                    if vhostfds or tapfds:
                        add_queues = None
                    add_vhostfd = None
                    add_tapfd = None
                else:
                    if vhostfds and vhostfds_len > -1:
                        vhostfd_list = re.split(":", vhostfds)
                        if vhostfds_len < len(vhostfd_list):
                            vhostfds = ":".join(vhostfd_list[:vhostfds_len])
                    if tapfds and tapfds_len > -1:
                        tapfd_list = re.split(":", tapfds)
                        if tapfds_len < len(tapfd_list):
                            tapfds = ":".join(tapfd_list[:tapfds_len])

                # Handle the '-net nic' part
                add_nic(devices, vlan, nic_model, mac,
                        device_id, netdev_id, nic_extra,
                        nic_params.get("nic_pci_addr"),
                        bootindex, queues, vectors, pci_bus)

                # Handle the '-net tap' or '-net user' or '-netdev' part
                cmd, cmd_nd = add_net(devices, vlan, nettype, ifname, tftp,
                                      bootp, redirs, netdev_id, netdev_extra,
                                      tapfds, script, downscript, vhost,
                                      queues, vhostfds, add_queues, helper,
                                      add_tapfd, add_vhostfd)

                if vhostfds is None:
                    vhostfds = ""

                if tapfds is None:
                    tapfds = ""

                net_params = {'netdev_id': netdev_id,
                              'vhostfd': vhostfds.split(":")[0],
                              'vhostfds': vhostfds,
                              'tapfd': tapfds.split(":")[0],
                              'tapfds': tapfds,
                              'ifname': ifname,
                              }

                for i, (host_port, guest_port) in enumerate(redirs):
                    net_params["host_port%d" % i] = host_port
                    net_params["guest_port%d" % i] = guest_port

                # TODO: Is every NIC a PCI device?
                devices.insert(StrDev("NET-%s" % nettype, cmdline=cmd,
                                      params=net_params, cmdline_nd=cmd_nd))
            else:
                device_driver = nic_params.get("device_driver", "pci-assign")
                pci_id = vm.pa_pci_ids[iov]
                pci_id = ":".join(pci_id.split(":")[1:])
                add_pcidevice(devices, pci_id, params=nic_params,
                              device_driver=device_driver,
                              pci_bus=pci_bus)
                iov += 1

        mem = params.get("mem")
        if mem:
            devices.insert(StrDev('mem', cmdline=add_mem(devices, mem)))

        smp = int(params.get("smp", 0))
        vcpu_maxcpus = int(params.get("vcpu_maxcpus", 0))
        vcpu_sockets = int(params.get("vcpu_sockets", 0))
        vcpu_cores = int(params.get("vcpu_cores", 0))
        vcpu_threads = int(params.get("vcpu_threads", 0))

        # Force CPU threads to 2 when smp > 8.
        if smp > 8 and vcpu_threads <= 1:
            vcpu_threads = 2

        # Some versions of windows don't support more than 2 sockets of cpu,
        # here is a workaround to make all windows use only 2 sockets.
        if (vcpu_sockets and vcpu_sockets > 2
                and params.get("os_type") == 'windows'):
            vcpu_sockets = 2

        if smp == 0 or vcpu_sockets == 0:
            vcpu_cores = vcpu_cores or 1
            vcpu_threads = vcpu_threads or 1
            if smp and vcpu_sockets == 0:
                vcpu_sockets = int(smp / (vcpu_cores * vcpu_threads)) or 1
            else:
                vcpu_sockets = vcpu_sockets or 1
            if smp == 0:
                smp = vcpu_cores * vcpu_threads * vcpu_sockets
        else:
            if vcpu_cores == 0:
                vcpu_threads = vcpu_threads or 1
                vcpu_cores = int(smp / (vcpu_sockets * vcpu_threads)) or 1
            else:
                vcpu_threads = int(smp / (vcpu_cores * vcpu_sockets)) or 1

        self.cpuinfo.smp = smp
        self.cpuinfo.maxcpus = vcpu_maxcpus or smp
        self.cpuinfo.cores = vcpu_cores
        self.cpuinfo.threads = vcpu_threads
        self.cpuinfo.sockets = vcpu_sockets
        devices.insert(StrDev('smp', cmdline=add_smp(devices)))

        numa_total_cpus = 0
        numa_total_mem = 0
        for numa_node in params.objects("guest_numa_nodes"):
            numa_params = params.object_params(numa_node)
            numa_mem = numa_params.get("numa_mem")
            numa_cpus = numa_params.get("numa_cpus")
            numa_nodeid = numa_params.get("numa_nodeid")
            if numa_mem is not None:
                numa_total_mem += int(numa_mem)
            if numa_cpus is not None:
                numa_total_cpus += len(utils_misc.cpu_str_to_list(numa_cpus))
            devices.insert(StrDev('numa', cmdline=add_numa_node(devices)))

        if params.get("numa_consistency_check_cpu_mem", "no") == "yes":
            if (numa_total_cpus > int(smp) or numa_total_mem > int(mem)
                    or len(params.objects("guest_numa_nodes")) > int(smp)):
                logging.debug("-numa need %s vcpu and %s memory. It is not "
                              "matched the -smp and -mem. The vcpu number "
                              "from -smp is %s, and memory size from -mem is"
                              " %s" % (numa_total_cpus, numa_total_mem, smp,
                                       mem))
                raise virt_vm.VMDeviceError("The numa node cfg can not fit"
                                            " smp and memory cfg.")

        cpu_model = params.get("cpu_model")
        use_default_cpu_model = True
        if cpu_model:
            use_default_cpu_model = False
            for model in re.split(",", cpu_model):
                model = model.strip()
                if model not in support_cpu_model:
                    continue
                cpu_model = model
                break
            else:
                cpu_model = model
                logging.error("Non existing CPU model %s will be passed "
                              "to qemu (wrong config or negative test)", model)

        if use_default_cpu_model:
            cpu_model = params.get("default_cpu_model")

        if cpu_model:
            vendor = params.get("cpu_model_vendor")
            flags = params.get("cpu_model_flags")
            family = params.get("cpu_family")
            self.cpuinfo.model = cpu_model
            self.cpuinfo.vendor = vendor
            self.cpuinfo.flags = flags
            self.cpuinfo.family = family
            cmd = add_cpu_flags(devices, cpu_model, flags, vendor, family)
            devices.insert(StrDev('cpu', cmdline=cmd))

        # Add cdroms
        for cdrom in params.objects("cdroms"):
            image_params = params.object_params(cdrom)
            # FIXME: Use qemu_devices for handling indexes
            if image_params.get("boot_drive") == "no":
                continue
            if params.get("index_enable") == "yes":
                drive_index = image_params.get("drive_index")
                if drive_index:
                    index = drive_index
                else:
                    self.last_driver_index = get_index(self.last_driver_index)
                    index = str(self.last_driver_index)
                    self.last_driver_index += 1
            else:
                index = None
            image_bootindex = None
            image_boot = image_params.get("image_boot")
            if not re.search("boot=on\|off", devices.get_help_text(),
                             re.MULTILINE):
                if image_boot in ['yes', 'on', True]:
                    image_bootindex = str(self.last_boot_index)
                    self.last_boot_index += 1
                image_boot = "unused"
                image_bootindex = image_params.get(
                    'bootindex', image_bootindex)
            else:
                if image_boot in ['yes', 'on', True]:
                    if self.last_boot_index > 0:
                        image_boot = False
                    self.last_boot_index += 1
            iso = image_params.get("cdrom")
            if iso or image_params.get("cdrom_without_file") == "yes":
                devs = devices.cdroms_define_by_params(cdrom, image_params,
                                                       'cdrom', index,
                                                       image_boot,
                                                       image_bootindex)
                for _ in devs:
                    devices.insert(_)

        # We may want to add {floppy_otps} parameter for -fda, -fdb
        # {fat:floppy:}/path/. However vvfat is not usually recommended.
        for floppy_name in params.objects('floppies'):
            image_params = params.object_params(floppy_name)
            # TODO: Unify image, cdrom, floppy params
            image_params['drive_format'] = 'floppy'
            image_params[
                'image_readonly'] = image_params.get("floppy_readonly",
                                                     "no")
            # Use the absolute patch with floppies (pure *.vfd)
            image_params['image_raw_device'] = 'yes'
            image_params['image_name'] = utils_misc.get_path(
                data_dir.get_data_dir(),
                image_params["floppy_name"])
            image_params['image_format'] = None
            devs = devices.images_define_by_params(floppy_name, image_params,
                                                   media='')
            for _ in devs:
                devices.insert(_)

        # Add usb devices
        for usb_dev in params.objects("usb_devices"):
            usb_dev_params = params.object_params(usb_dev)
            devices.insert(devices.usb_by_params(usb_dev, usb_dev_params))

        tftp = params.get("tftp")
        if tftp:
            tftp = utils_misc.get_path(data_dir.get_data_dir(), tftp)
            devices.insert(StrDev('tftp', cmdline=add_tftp(devices, tftp)))

        bootp = params.get("bootp")
        if bootp:
            devices.insert(StrDev('bootp',
                                  cmdline=add_bootp(devices, bootp)))

        kernel = params.get("kernel")
        if kernel:
            kernel = utils_misc.get_path(data_dir.get_data_dir(), kernel)
            devices.insert(StrDev('kernel',
                                  cmdline=add_kernel(devices, kernel)))

        kernel_params = params.get("kernel_params")
        if kernel_params:
            cmd = add_kernel_cmdline(devices, kernel_params)
            devices.insert(StrDev('kernel-params', cmdline=cmd))

        initrd = params.get("initrd")
        if initrd:
            initrd = utils_misc.get_path(data_dir.get_data_dir(), initrd)
            devices.insert(StrDev('initrd',
                                  cmdline=add_initrd(devices, initrd)))

        for host_port, guest_port in redirs:
            cmd = add_tcp_redir(devices, host_port, guest_port)
            devices.insert(StrDev('tcp-redir', cmdline=cmd))

        cmd = ""
        if params.get("display") == "vnc":
            vnc_extra_params = params.get("vnc_extra_params")
            vnc_password = params.get("vnc_password", "no")
            cmd += add_vnc(devices, self.vnc_port, vnc_password,
                           vnc_extra_params)
        elif params.get("display") == "sdl":
            cmd += add_sdl(devices)
        elif params.get("display") == "nographic":
            cmd += add_nographic(devices)
        elif params.get("display") == "spice":
            if params.get("rhel5_spice"):
                spice_params = params.get("spice_params")
                cmd += add_spice_rhel5(devices, spice_params)
            else:
                spice_keys = (
                    "spice_port", "spice_password", "spice_addr", "spice_ssl",
                    "spice_tls_port", "spice_tls_ciphers", "spice_gen_x509",
                    "spice_x509_dir", "spice_x509_prefix",
                    "spice_x509_key_file", "spice_x509_cacert_file",
                    "spice_x509_key_password", "spice_x509_secure",
                    "spice_x509_cacert_subj", "spice_x509_server_subj",
                    "spice_secure_channels", "spice_image_compression",
                    "spice_jpeg_wan_compression",
                    "spice_zlib_glz_wan_compression", "spice_streaming_video",
                    "spice_agent_mouse", "spice_playback_compression",
                    "spice_ipv4", "spice_ipv6", "spice_x509_cert_file",
                    "disable_copy_paste", "spice_seamless_migration",
                    "listening_addr"
                )

                for skey in spice_keys:
                    value = params.get(skey, None)
                    if value:
                        self.spice_options[skey] = value

                cmd += add_spice()
        if cmd:
            devices.insert(StrDev('display', cmdline=cmd))

        if params.get("uuid") == "random":
            cmd = add_uuid(devices, vm.uuid)
            devices.insert(StrDev('uuid', cmdline=cmd))
        elif params.get("uuid"):
            cmd = add_uuid(devices, params.get("uuid"))
            devices.insert(StrDev('uuid', cmdline=cmd))

        if params.get("testdev") == "yes":
            cmd = add_testdev(devices, vm.get_testlog_filename())
            devices.insert(StrDev('testdev', cmdline=cmd))

        if params.get("isa_debugexit") == "yes":
            iobase = params.get("isa_debugexit_iobase")
            iosize = params.get("isa_debugexit_iosize")
            cmd = add_isa_debug_exit(devices, iobase, iosize)
            devices.insert(StrDev('isa_debugexit', cmdline=cmd))

        if params.get("disable_hpet") == "yes":
            devices.insert(StrDev('nohpet', cmdline=add_no_hpet(devices)))

        devices.insert(StrDev('rtc', cmdline=add_rtc(devices)))

        if devices.has_option("boot"):
            boot_order = params.get("boot_order", "cdn")
            boot_once = params.get("boot_once", "c")
            boot_menu = params.get("boot_menu", "off")
            cmd = add_boot(devices, boot_order, boot_once, boot_menu)
            devices.insert(StrDev('bootmenu', cmdline=cmd))

        p9_export_dir = params.get("9p_export_dir")
        if p9_export_dir:
            cmd = " -fsdev"
            p9_fs_driver = params.get("9p_fs_driver")
            if p9_fs_driver == "handle":
                cmd += " handle,id=local1,path=" + p9_export_dir
            elif p9_fs_driver == "proxy":
                cmd += " proxy,id=local1,socket="
            else:
                p9_fs_driver = "local"
                cmd += " local,id=local1,path=" + p9_export_dir

            # security model is needed only for local fs driver
            if p9_fs_driver == "local":
                p9_security_model = params.get("9p_security_model")
                if not p9_security_model:
                    p9_security_model = "none"
                cmd += ",security_model=" + p9_security_model
            elif p9_fs_driver == "proxy":
                p9_socket_name = params.get("9p_socket_name")
                if not p9_socket_name:
                    raise virt_vm.VMImageMissingError("Socket name not "
                                                      "defined")
                cmd += p9_socket_name

            p9_immediate_writeout = params.get("9p_immediate_writeout")
            if p9_immediate_writeout == "yes":
                cmd += ",writeout=immediate"

            p9_readonly = params.get("9p_readonly")
            if p9_readonly == "yes":
                cmd += ",readonly"

            devices.insert(StrDev('fsdev', cmdline=cmd))

            dev = QDevice('virtio-9p-pci', parent_bus=pci_bus)
            dev.set_param('fsdev', 'local1')
            dev.set_param('mount_tag', 'autotest_tag')
            devices.insert(dev)

        extra_params = params.get("extra_params")
        if extra_params:
            devices.insert(StrDev('extra', cmdline=extra_params))

        bios_path = params.get("bios_path")
        if bios_path:
            devices.insert(StrDev('bios', cmdline="-bios %s" % bios_path))

        disable_kvm_option = ""
        if (devices.has_option("no-kvm")):
            disable_kvm_option = "-no-kvm"

        enable_kvm_option = ""
        if (devices.has_option("enable-kvm")):
            enable_kvm_option = "-enable-kvm"

        if (params.get("disable_kvm", "no") == "yes"):
            params["enable_kvm"] = "no"

        if (params.get("enable_kvm", "yes") == "no"):
            devices.insert(StrDev('nokvm', cmdline=disable_kvm_option))
            logging.debug("qemu will run in TCG mode")
        else:
            devices.insert(StrDev('kvm', cmdline=enable_kvm_option))
            logging.debug("qemu will run in KVM mode")

        self.no_shutdown = (devices.has_option("no-shutdown") and
                            params.get("disable_shutdown", "no") == "yes")
        if self.no_shutdown:
            devices.insert(StrDev('noshutdown', cmdline="-no-shutdown"))

        user_runas = params.get("user_runas")
        if devices.has_option("runas") and user_runas:
            devices.insert(StrDev('runas', cmdline="-runas %s" % user_runas))

        if params.get("enable_sga") == "yes":
            devices.insert(StrDev('sga', cmdline=add_sga(devices)))

        if params.get("smartcard", "no") == "yes":
            sc_chardev = params.get("smartcard_chardev")
            sc_id = params.get("smartcard_id")
            devices.insert(StrDev('smartcard',
                                  cmdline=add_smartcard(devices, sc_chardev, sc_id)))

        if params.get("enable_watchdog", "no") == "yes":
            cmd = add_watchdog(devices,
                               params.get("watchdog_device_type", None),
                               params.get("watchdog_action", "reset"))
            devices.insert(StrDev('watchdog', cmdline=cmd))

        option_roms = params.get("option_roms")
        if option_roms:
            cmd = ""
            for opt_rom in option_roms.split():
                cmd += add_option_rom(devices, opt_rom)
            if cmd:
                devices.insert(StrDev('ROM', cmdline=cmd))

        return devices

    def _nic_tap_add_helper(self, nic):
        if nic.nettype == 'macvtap':
            macvtap_mode = self.params.get("macvtap_mode", "vepa")
            nic.tapfds = utils_net.create_and_open_macvtap(nic.ifname,
                                                           macvtap_mode, nic.queues, nic.netdst, nic.mac)
        else:
            nic.tapfds = utils_net.open_tap("/dev/net/tun", nic.ifname,
                                            queues=nic.queues, vnet_hdr=True)
            logging.debug("Adding VM %s NIC ifname %s to bridge %s",
                          self.name, nic.ifname, nic.netdst)
            if nic.nettype == 'bridge':
                utils_net.add_to_bridge(nic.ifname, nic.netdst)
        utils_net.bring_up_ifname(nic.ifname)

    def _nic_tap_remove_helper(self, nic):
        try:
            if nic.nettype == 'macvtap':
                logging.info("Remove macvtap ifname %s", nic.ifname)
                tap = utils_net.Macvtap(nic.ifname)
                tap.delete()
            else:
                logging.debug("Removing VM %s NIC ifname %s from bridge %s",
                              self.name, nic.ifname, nic.netdst)
                if nic.tapfds:
                    for i in nic.tapfds.split(':'):
                        os.close(int(i))
                if nic.vhostfds:
                    for i in nic.vhostfds.split(':'):
                        os.close(int(i))
                if nic.ifname and nic.ifname not in utils_net.get_net_if():
                    _, br_name = utils_net.find_current_bridge(nic.ifname)
                    if br_name == nic.netdst:
                        utils_net.del_from_bridge(nic.ifname, nic.netdst)
        except TypeError:
            pass

    def create_serial_console(self):
        """
        Establish a session with the serial console.

        Let's consider the first serial port as serial console.
        Note: requires a version of netcat that supports -U
        """
        try:
            tmp_serial = self.serial_ports[0]
        except IndexError:
            raise virt_vm.VMConfigMissingError(self.name, "isa_serial")

        self.serial_console = aexpect.ShellSession(
            "nc -U %s" % self.get_serial_console_filename(tmp_serial),
            auto_close=False,
            output_func=utils_misc.log_line,
            output_params=("serial-%s-%s.log" % (tmp_serial, self.name),),
            prompt=self.params.get("shell_prompt", "[\#\$]"))
        del tmp_serial

    def update_system_dependent_devs(self):
        # Networking
        devices = self.devices
        params = self.params
        redirs = []
        for redir_name in params.objects("redirs"):
            redir_params = params.object_params(redir_name)
            guest_port = int(redir_params.get("guest_port"))
            host_port = self.redirs.get(guest_port)
            redirs += [(host_port, guest_port)]

        for nic in self.virtnet:
            nic_params = params.object_params(nic.nic_name)
            if nic_params.get('pci_assignable') == "no":
                script = nic_params.get("nic_script")
                downscript = nic_params.get("nic_downscript")
                script_dir = data_dir.get_data_dir()
                if script:
                    script = utils_misc.get_path(script_dir, script)
                if downscript:
                    downscript = utils_misc.get_path(script_dir,
                                                     downscript)
                # setup nic parameters as needed
                # add_netdev if netdev_id not set
                nic = self.add_nic(**dict(nic))
                # gather set values or None if unset
                netdev_id = nic.get('netdev_id')
                # don't force conversion add_nic()/add_net() optional
                # parameter
                if 'tapfds' in nic:
                    tapfds = nic.tapfds
                else:
                    tapfds = ""
                if 'vhostfds' in nic:
                    vhostfds = nic.vhostfds
                else:
                    vhostfds = ""
                ifname = nic.get('ifname')
                # specify the number of MSI-X vectors that the card should
                # have this option currently only affects virtio cards

                net_params = {'netdev_id': netdev_id,
                              'vhostfd': vhostfds.split(":")[0],
                              'vhostfds': vhostfds,
                              'tapfd': tapfds.split(":")[0],
                              'tapfds': tapfds,
                              'ifname': ifname,
                              }

                for i, (host_port, guest_port) in enumerate(redirs):
                    net_params["host_port%d" % i] = host_port
                    net_params["guest_port%d" % i] = guest_port

                # TODO: Is every NIC a PCI device?
                devs = devices.get_by_params({'netdev_id': netdev_id})
                # TODO: Is every NIC a PCI device?
                if len(devs) > 1:
                    logging.error("There are %d devices with netdev_id %s."
                                  " This shouldn't happens." % (len(devs),
                                                                netdev_id))
                devs[0].params.update(net_params)

    @error.context_aware
    def create(self, name=None, params=None, root_dir=None,
               timeout=CREATE_TIMEOUT, migration_mode=None,
               migration_exec_cmd=None, migration_fd=None,
               mac_source=None):
        """
        Start the VM by running a qemu command.
        All parameters are optional. If name, params or root_dir are not
        supplied, the respective values stored as class attributes are used.

        :param name: The name of the object
        :param params: A dict containing VM params
        :param root_dir: Base directory for relative filenames
        :param migration_mode: If supplied, start VM for incoming migration
                using this protocol (either 'rdma', 'x-rdma', 'rdma', 'tcp', 'unix' or 'exec')
        :param migration_exec_cmd: Command to embed in '-incoming "exec: ..."'
                (e.g. 'gzip -c -d filename') if migration_mode is 'exec'
                default to listening on a random TCP port
        :param migration_fd: Open descriptor from machine should migrate.
        :param mac_source: A VM object from which to copy MAC addresses. If not
                specified, new addresses will be generated.

        :raise VMCreateError: If qemu terminates unexpectedly
        :raise VMKVMInitError: If KVM initialization fails
        :raise VMHugePageError: If hugepage initialization fails
        :raise VMImageMissingError: If a CD image is missing
        :raise VMHashMismatchError: If a CD image hash has doesn't match the
                expected hash
        :raise VMBadPATypeError: If an unsupported PCI assignment type is
                requested
        :raise VMPAError: If no PCI assignable devices could be assigned
        :raise TAPCreationError: If fail to create tap fd
        :raise BRAddIfError: If fail to add a tap to a bridge
        :raise TAPBringUpError: If fail to bring up a tap
        :raise PrivateBridgeError: If fail to bring the private bridge
        """
        error.context("creating '%s'" % self.name)
        self.destroy(free_mac_addresses=False)

        if name is not None:
            self.name = name
            self.devices = None     # Representation changed
        if params is not None:
            self.params = params
            self.devices = None     # Representation changed
        if root_dir is not None:
            self.root_dir = root_dir
            self.devices = None     # Representation changed
        name = self.name
        params = self.params
        root_dir = self.root_dir

        # Verify the md5sum of the ISO images
        for cdrom in params.objects("cdroms"):
            cdrom_params = params.object_params(cdrom)
            iso = cdrom_params.get("cdrom")
            if iso:
                iso = utils_misc.get_path(data_dir.get_data_dir(), iso)
                if not os.path.exists(iso):
                    raise virt_vm.VMImageMissingError(iso)
                compare = False
                if cdrom_params.get("skip_hash"):
                    logging.debug("Skipping hash comparison")
                elif cdrom_params.get("md5sum_1m"):
                    logging.debug("Comparing expected MD5 sum with MD5 sum of "
                                  "first MB of ISO file...")
                    actual_hash = utils.hash_file(iso, 1048576, method="md5")
                    expected_hash = cdrom_params.get("md5sum_1m")
                    compare = True
                elif cdrom_params.get("md5sum"):
                    logging.debug("Comparing expected MD5 sum with MD5 sum of "
                                  "ISO file...")
                    actual_hash = utils.hash_file(iso, method="md5")
                    expected_hash = cdrom_params.get("md5sum")
                    compare = True
                elif cdrom_params.get("sha1sum"):
                    logging.debug("Comparing expected SHA1 sum with SHA1 sum "
                                  "of ISO file...")
                    actual_hash = utils.hash_file(iso, method="sha1")
                    expected_hash = cdrom_params.get("sha1sum")
                    compare = True
                if compare:
                    if actual_hash == expected_hash:
                        logging.debug("Hashes match")
                    else:
                        raise virt_vm.VMHashMismatchError(actual_hash,
                                                          expected_hash)

        # Make sure the following code is not executed by more than one thread
        # at the same time
        lockfile = open(CREATE_LOCK_FILENAME, "w+")
        fcntl.lockf(lockfile, fcntl.LOCK_EX)

        try:
            # Handle port redirections
            redir_names = params.objects("redirs")
            host_ports = utils_misc.find_free_ports(
                5000, 6000, len(redir_names))

            old_redirs = None
            if self.redirs:
                old_redirs = self.redirs

            self.redirs = {}
            for i in range(len(redir_names)):
                redir_params = params.object_params(redir_names[i])
                guest_port = int(redir_params.get("guest_port"))
                self.redirs[guest_port] = host_ports[i]

            if self.redirs != old_redirs:
                self.devices = None

            # Update the network related parameters as well to conform to
            # expected behavior on VM creation
            getattr(self, 'virtnet').__init__(self.params,
                                              self.name,
                                              self.instance)

            # Generate basic parameter values for all NICs and create TAP fd
            for nic in self.virtnet:
                nic_params = params.object_params(nic.nic_name)
                pa_type = nic_params.get("pci_assignable")
                if pa_type and pa_type != "no":
                    device_driver = nic_params.get("device_driver",
                                                   "pci-assign")
                    if "mac" not in nic:
                        self.virtnet.generate_mac_address(nic["nic_name"])
                    mac = nic["mac"]
                    if self.pci_assignable is None:
                        self.pci_assignable = test_setup.PciAssignable(
                            driver=params.get("driver"),
                            driver_option=params.get("driver_option"),
                            host_set_flag=params.get("host_setup_flag"),
                            kvm_params=params.get("kvm_default"),
                            vf_filter_re=params.get("vf_filter_re"),
                            pf_filter_re=params.get("pf_filter_re"),
                            device_driver=device_driver)
                    # Virtual Functions (VF) assignable devices
                    if pa_type == "vf":
                        self.pci_assignable.add_device(device_type=pa_type,
                                                       mac=mac,
                                                       name=nic_params.get("device_name"))
                    # Physical NIC (PF) assignable devices
                    elif pa_type == "pf":
                        self.pci_assignable.add_device(device_type=pa_type,
                                                       name=nic_params.get("device_name"))
                    else:
                        raise virt_vm.VMBadPATypeError(pa_type)
                else:
                    # fill in key values, validate nettype
                    # note: make_create_command() calls vm.add_nic (i.e. on a
                    # copy)
                    if nic_params.get('netdst') == 'private':
                        nic.netdst = (test_setup.
                                      PrivateBridgeConfig(nic_params).brname)

                    nic = self.add_nic(**dict(nic))  # implied add_netdev

                    if mac_source:
                        # Will raise exception if source doesn't
                        # have cooresponding nic
                        logging.debug("Copying mac for nic %s from VM %s"
                                      % (nic.nic_name, mac_source.name))
                        nic.mac = mac_source.get_mac_address(nic.nic_name)

                    if nic.ifname in utils_net.get_net_if():
                        self.virtnet.generate_ifname(nic.nic_name)
                    elif (utils_net.find_current_bridge(nic.ifname)[1] ==
                          nic.netdst):
                        utils_net.del_from_bridge(nic.ifname, nic.netdst)

                    if nic.nettype in ['bridge', 'network', 'macvtap']:
                        self._nic_tap_add_helper(nic)

                    if ((nic_params.get("vhost") in ['on',
                                                     'force',
                                                     'vhost=on']) and
                            (nic_params.get("enable_vhostfd", "yes") == "yes")):
                        vhostfds = []
                        for i in xrange(int(nic.queues)):
                            vhostfds.append(str(os.open("/dev/vhost-net",
                                                        os.O_RDWR)))
                        nic.vhostfds = ':'.join(vhostfds)
                    elif nic.nettype == 'user':
                        logging.info("Assuming dependencies met for "
                                     "user mode nic %s, and ready to go"
                                     % nic.nic_name)

                    self.virtnet.update_db()

            # Find available VNC port, if needed
            if params.get("display") == "vnc":
                self.vnc_port = utils_misc.find_free_port(5900, 6100)

            # Find random UUID if specified 'uuid = random' in config file
            if params.get("uuid") == "random":
                f = open("/proc/sys/kernel/random/uuid")
                self.uuid = f.read().strip()
                f.close()

            if self.pci_assignable is not None:
                self.pa_pci_ids = self.pci_assignable.request_devs()

                if self.pa_pci_ids:
                    logging.debug("Successfully assigned devices: %s",
                                  self.pa_pci_ids)
                else:
                    raise virt_vm.VMPAError(pa_type)

            if (name is None and params is None and root_dir is None
                    and self.devices is not None):
                self.update_system_dependent_devs()
            # Make qemu command
            try:
                self.devices = self.make_create_command()
                logging.debug(self.devices.str_short())
                logging.debug(self.devices.str_bus_short())
                qemu_command = self.devices.cmdline()
            except error.TestNAError:
                # TestNAErrors should be kept as-is so we generate SKIP
                # results instead of bogus FAIL results
                raise
            except Exception:
                for nic in self.virtnet:
                    self._nic_tap_remove_helper(nic)
                # TODO: log_last_traceback is being moved into autotest.
                # use autotest.client.shared.base_utils when it's completed.
                if 'log_last_traceback' in utils.__dict__:
                    utils.log_last_traceback('Fail to create qemu command:')
                else:
                    utils_misc.log_last_traceback('Fail to create qemu'
                                                  'command:')
                raise virt_vm.VMStartError(self.name, 'Error occurred while '
                                           'executing make_create_command(). '
                                           'Check the log for traceback.')

            # Add migration parameters if required
            if migration_mode in ["tcp", "rdma", "x-rdma"]:
                self.migration_port = utils_misc.find_free_port(5200, 6000)
                qemu_command += (" -incoming " + migration_mode +
                                 ":0:%d" % self.migration_port)
            elif migration_mode == "unix":
                self.migration_file = "/tmp/migration-unix-%s" % self.instance
                qemu_command += " -incoming unix:%s" % self.migration_file
            elif migration_mode == "exec":
                if migration_exec_cmd is None:
                    self.migration_port = utils_misc.find_free_port(5200, 6000)
                    qemu_command += (' -incoming "exec:nc -l %s"' %
                                     self.migration_port)
                else:
                    qemu_command += (' -incoming "exec:%s"' %
                                     migration_exec_cmd)
            elif migration_mode == "fd":
                qemu_command += ' -incoming "fd:%d"' % (migration_fd)

            p9_fs_driver = params.get("9p_fs_driver")
            if p9_fs_driver == "proxy":
                proxy_helper_name = params.get("9p_proxy_binary",
                                               "virtfs-proxy-helper")
                proxy_helper_cmd = utils_misc.get_path(root_dir,
                                                       proxy_helper_name)
                if not proxy_helper_cmd:
                    raise virt_vm.VMConfigMissingError(self.name,
                                                       "9p_proxy_binary")

                p9_export_dir = params.get("9p_export_dir")
                if not p9_export_dir:
                    raise virt_vm.VMConfigMissingError(self.name,
                                                       "9p_export_dir")

                proxy_helper_cmd += " -p " + p9_export_dir
                proxy_helper_cmd += " -u 0 -g 0"
                p9_socket_name = params.get("9p_socket_name")
                proxy_helper_cmd += " -s " + p9_socket_name
                proxy_helper_cmd += " -n"

                logging.info("Running Proxy Helper:\n%s", proxy_helper_cmd)
                self.process = aexpect.run_tail(proxy_helper_cmd,
                                                None,
                                                logging.info,
                                                "[9p proxy helper]",
                                                auto_close=False)
            else:
                logging.info("Running qemu command (reformatted):\n%s",
                             qemu_command.replace(" -", " \\\n    -"))
                self.qemu_command = qemu_command
                self.process = aexpect.run_tail(qemu_command,
                                                None,
                                                logging.info,
                                                "[qemu output] ",
                                                auto_close=False)

            logging.info("Created qemu process with parent PID %d",
                         self.process.get_pid())
            self.start_time = time.time()
            self.start_monotonic_time = utils_misc.monotonic_time()

            # test doesn't need to hold tapfd's open
            for nic in self.virtnet:
                if 'tapfds' in nic:  # implies bridge/tap
                    try:
                        for i in nic.tapfds.split(':'):
                            os.close(int(i))
                        # qemu process retains access via open file
                        # remove this attribute from virtnet because
                        # fd numbers are not always predictable and
                        # vm instance must support cloning.
                        del nic['tapfds']
                    # File descriptor is already closed
                    except OSError:
                        pass
                if 'vhostfds' in nic:
                    try:
                        for i in nic.vhostfds.split(':'):
                            os.close(int(i))
                        del nic['vhostfds']
                    except OSError:
                        pass

            # Make sure qemu is not defunct
            if self.process.is_defunct():
                logging.error("Bad things happened, qemu process is defunct")
                err = ("Qemu is defunct.\nQemu output:\n%s"
                       % self.process.get_output())
                self.destroy()
                raise virt_vm.VMStartError(self.name, err)

            # Make sure the process was started successfully
            if not self.process.is_alive():
                status = self.process.get_status()
                output = self.process.get_output().strip()
                migration_in_course = migration_mode is not None
                unknown_protocol = "unknown migration protocol" in output
                if migration_in_course and unknown_protocol:
                    e = VMMigrateProtoUnsupportedError(migration_mode, output)
                else:
                    e = virt_vm.VMCreateError(qemu_command, status, output)
                self.destroy()
                raise e

            # Establish monitor connections
            self.monitors = []
            for monitor_name in params.objects("monitors"):
                monitor_params = params.object_params(monitor_name)
                try:
                    monitor = qemu_monitor.wait_for_create_monitor(self,
                                                                   monitor_name, monitor_params, timeout)
                except qemu_monitor.MonitorConnectError, detail:
                    logging.error(detail)
                    self.destroy()
                    raise

                # Add this monitor to the list
                self.monitors += [monitor]

            # Create isa serial ports.
            for serial in params.objects("isa_serials"):
                self.serial_ports.append(serial)

            # Create virtio_ports (virtio_serialports and virtio_consoles)
            i = 0
            self.virtio_ports = []
            for port in params.objects("virtio_ports"):
                port_params = params.object_params(port)
                if port_params.get('virtio_port_chardev') == "spicevmc":
                    filename = 'dev%s' % port
                else:
                    filename = self.get_virtio_port_filename(port)
                port_name = port_params.get('virtio_port_name_prefix', None)
                if port_name:   # If port_name_prefix was used
                    port_name = port_name + str(i)
                else:           # Implicit name - port
                    port_name = port
                if port_params.get('virtio_port_type') in ("console",
                                                           "virtio_console"):
                    self.virtio_ports.append(
                        qemu_virtio_port.VirtioConsole(port, port_name,
                                                       filename))
                else:
                    self.virtio_ports.append(
                        qemu_virtio_port.VirtioSerial(port, port_name,
                                                      filename))
                i += 1

            # Get the output so far, to see if we have any problems with
            # KVM modules or with hugepage setup.
            output = self.process.get_output()

            if re.search("Could not initialize KVM", output, re.IGNORECASE):
                e = virt_vm.VMKVMInitError(
                    qemu_command, self.process.get_output())
                self.destroy()
                raise e

            if "alloc_mem_area" in output:
                e = virt_vm.VMHugePageError(
                    qemu_command, self.process.get_output())
                self.destroy()
                raise e

            logging.debug("VM appears to be alive with PID %s", self.get_pid())
            vcpu_thread_pattern = self.params.get("vcpu_thread_pattern",
                                                  r"thread_id.?[:|=]\s*(\d+)")
            self.vcpu_threads = self.get_vcpu_pids(vcpu_thread_pattern)

            vhost_thread_pattern = params.get("vhost_thread_pattern",
                                              r"\w+\s+(\d+)\s.*\[vhost-%s\]")
            self.vhost_threads = self.get_vhost_threads(vhost_thread_pattern)

            self.create_serial_console()

            for key, value in self.logs.items():
                outfile = "%s-%s.log" % (key, name)
                self.logsessions[key] = aexpect.Tail(
                    "nc -U %s" % value,
                    auto_close=False,
                    output_func=utils_misc.log_line,
                    output_params=(outfile,))
                self.logsessions[key].set_log_file(outfile)

            if params.get("paused_after_start_vm") != "yes":
                # start guest
                if self.monitor.verify_status("paused"):
                    try:
                        self.monitor.cmd("cont")
                    except qemu_monitor.QMPCmdError, e:
                        if ((e.data['class'] == "MigrationExpected") and
                                (migration_mode is not None)):
                            logging.debug("Migration did not start yet...")
                        else:
                            raise e

            # Update mac and IP info for assigned device
            # NeedFix: Can we find another way to get guest ip?
            if params.get("mac_changeable") == "yes":
                utils_net.update_mac_ip_address(self, params)

        finally:
            fcntl.lockf(lockfile, fcntl.LOCK_UN)
            lockfile.close()

    def wait_for_status(self, status, timeout, first=0.0, step=1.0, text=None):
        """
        Wait until the VM status changes to specified status

        :param timeout: Timeout in seconds
        :param first: Time to sleep before first attempt
        :param steps: Time to sleep between attempts in seconds
        :param text: Text to print while waiting, for debug purposes

        :return: True in case the status has changed before timeout, otherwise
                 return None.
        """
        return utils_misc.wait_for(lambda: self.monitor.verify_status(status),
                                   timeout, first, step, text)

    def wait_until_paused(self, timeout):
        """
        Wait until the VM is paused.

        :param timeout: Timeout in seconds.

        :return: True in case the VM is paused before timeout, otherwise
                 return None.
        """
        return self.wait_for_status("paused", timeout)

    def wait_until_dead(self, timeout, first=0.0, step=1.0):
        """
        Wait until VM is dead.

        :return: True if VM is dead before timeout, otherwise returns None.

        :param timeout: Timeout in seconds
        :param first: Time to sleep before first attempt
        :param steps: Time to sleep between attempts in seconds
        """
        return utils_misc.wait_for(self.is_dead, timeout, first, step)

    def wait_for_shutdown(self, timeout=60):
        """
        Wait until guest shuts down.

        Helps until the VM is shut down by the guest.

        :return: True in case the VM was shut down, None otherwise.

        Note that the VM is not necessarily dead when this function returns
        True. If QEMU is running in -no-shutdown mode, the QEMU process
        may be still alive.
        """
        if self.no_shutdown:
            return self.wait_until_paused(timeout)
        else:
            return self.wait_until_dead(timeout, 1, 1)

    def graceful_shutdown(self, timeout=60):
        """
        Try to gracefully shut down the VM.

        :return: True if VM was successfully shut down, None otherwise.

        Note that the VM is not necessarily dead when this function returns
        True. If QEMU is running in -no-shutdown mode, the QEMU process
        may be still alive.
        """
        if self.params.get("shutdown_command"):
            # Try to destroy with shell command
            logging.debug("Shutting down VM %s (shell)", self.name)
            try:
                if len(self.virtnet) > 0:
                    session = self.login()
                else:
                    session = self.serial_login()
            except (IndexError), e:
                try:
                    session = self.serial_login()
                except (remote.LoginError, virt_vm.VMError), e:
                    logging.debug(e)
            except (remote.LoginError, virt_vm.VMError), e:
                logging.debug(e)
            else:
                try:
                    # Send the shutdown command
                    session.sendline(self.params.get("shutdown_command"))
                    if self.wait_for_shutdown(timeout):
                        return True
                finally:
                    session.close()

    def _cleanup(self, free_mac_addresses):
        """
        Do cleanup works
            .removes VM monitor files.
            .process close
            .serial_console close
            .logsessions close
            .delete tmp files
            .free_mac_addresses, if needed
            .delete macvtap, if needed

        :param free_mac_addresses: Whether to release the VM's NICs back
                to the address pool.
        """
        self.monitors = []
        if self.pci_assignable:
            self.pci_assignable.release_devs()
            self.pci_assignable = None
        if self.process:
            self.process.close()
        if self.serial_console:
            self.serial_console.close()
        if self.logsessions:
            for key in self.logsessions:
                self.logsessions[key].close()

        # Generate the tmp file which should be deleted.
        file_list = [self.get_testlog_filename()]
        file_list += qemu_monitor.get_monitor_filenames(self)
        file_list += self.get_virtio_port_filenames()
        file_list += self.get_serial_console_filenames()
        file_list += self.logs.values()

        for f in file_list:
            try:
                os.unlink(f)
            except OSError:
                pass

        if hasattr(self, "migration_file"):
            try:
                os.unlink(self.migration_file)
            except OSError:
                pass

        if free_mac_addresses:
            for nic_index in xrange(0, len(self.virtnet)):
                self.free_mac_address(nic_index)

        for nic in self.virtnet:
            if nic.nettype == 'macvtap':
                tap = utils_net.Macvtap(nic.ifname)
                tap.delete()
            elif nic.ifname and nic.ifname not in utils_net.get_net_if():
                _, br_name = utils_net.find_current_bridge(nic.ifname)
                if br_name == nic.netdst:
                    utils_net.del_from_bridge(nic.ifname, nic.netdst)

    def destroy(self, gracefully=True, free_mac_addresses=True):
        """
        Destroy the VM.

        If gracefully is True, first attempt to shutdown the VM with a shell
        command.  Then, attempt to destroy the VM via the monitor with a 'quit'
        command.  If that fails, send SIGKILL to the qemu process.

        :param gracefully: If True, an attempt will be made to end the VM
                using a shell command before trying to end the qemu process
                with a 'quit' or a kill signal.
        :param free_mac_addresses: If True, the MAC addresses used by the VM
                will be freed.
        """
        try:
            # Is it already dead?
            if self.is_dead():
                return

            logging.debug("Destroying VM %s (PID %s)", self.name,
                          self.get_pid())

            kill_timeout = int(self.params.get("kill_timeout", "60"))

            if gracefully:
                self.graceful_shutdown(kill_timeout)
                if self.is_dead():
                    logging.debug("VM %s down (shell)", self.name)
                    return
                else:
                    logging.debug("VM %s failed to go down (shell)", self.name)

            if self.monitor:
                # Try to finish process with a monitor command
                logging.debug("Ending VM %s process (monitor)", self.name)
                try:
                    self.monitor.quit()
                except Exception, e:
                    logging.warn(e)
                    if self.is_dead():
                        logging.warn("VM %s down during try to kill it "
                                     "by monitor", self.name)
                        return
                else:
                    # Wait for the VM to be really dead
                    if self.wait_until_dead(5, 0.5, 0.5):
                        logging.debug("VM %s down (monitor)", self.name)
                        return
                    else:
                        logging.debug("VM %s failed to go down (monitor)",
                                      self.name)

            # If the VM isn't dead yet...
            pid = self.process.get_pid()
            logging.debug("Ending VM %s process (killing PID %s)",
                          self.name, pid)
            utils_misc.kill_process_tree(pid, 9)

            # Wait for the VM to be really dead
            if utils_misc.wait_for(self.is_dead, 5, 0.5, 0.5):
                logging.debug("VM %s down (process killed)", self.name)
                return

            # If all else fails, we've got a zombie...
            logging.error("VM %s (PID %s) is a zombie!", self.name,
                          self.process.get_pid())

        finally:
            self._cleanup(free_mac_addresses)

    @property
    def monitor(self):
        """
        Return the main monitor object, selected by the parameter main_monitor.
        If main_monitor isn't defined, return the first monitor.
        If no monitors exist, or if main_monitor refers to a nonexistent
        monitor, return None.
        """
        for m in self.monitors:
            if m.name == self.params.get("main_monitor"):
                return m
        if self.monitors and not self.params.get("main_monitor"):
            return self.monitors[0]
        return None

    def get_monitors_by_type(self, mon_type):
        """
        Return list of monitors of mon_type type.
        :param mon_type: desired monitor type (qmp, human)
        """
        return [_ for _ in self.monitors if _.protocol == mon_type]

    def get_peer(self, netid):
        """
        Return the peer of netdev or network deivce.

        :param netid: id of netdev or device
        :return: id of the peer device otherwise None
        """
        o = self.monitor.info("network")
        network_info = o
        if isinstance(o, dict):
            network_info = o.get["return"]

        netdev_peer_re = self.params.get("netdev_peer_re")
        if not netdev_peer_re:
            default_netdev_peer_re = "\s{2,}(.*?): .*?\\\s(.*?):"
            logging.warning("Missing config netdev_peer_re for VM %s, "
                            "using default %s", self.name,
                            default_netdev_peer_re)
            netdev_peer_re = default_netdev_peer_re

        pairs = re.findall(netdev_peer_re, network_info, re.S)
        for nic, tap in pairs:
            if nic == netid:
                return tap
            if tap == netid:
                return nic

        return None

    def get_ifname(self, nic_index=0):
        """
        Return the ifname of a bridge/tap device associated with a NIC.

        :param nic_index: Index of the NIC
        """
        return self.virtnet[nic_index].ifname

    def get_pid(self):
        """
        Return the VM's PID.  If the VM is dead return None.

        :note: This works under the assumption that self.process.get_pid()
        :return: the PID of the parent shell process.
        """
        try:
            children = commands.getoutput("ps --ppid=%d -o pid=" %
                                          self.process.get_pid()).split()
            return int(children[0])
        except (TypeError, IndexError, ValueError):
            return None

    def get_shell_pid(self):
        """
        Return the PID of the parent shell process.

        :note: This works under the assumption that self.process.get_pid()
        :return: the PID of the parent shell process.
        """
        return self.process.get_pid()

    def get_vnc_port(self):
        """
        Return self.vnc_port.
        """

        return self.vnc_port

    def get_vcpu_pids(self, vcpu_thread_pattern):
        """
        Return the list of vcpu PIDs

        :return: the list of vcpu PIDs
        """
        return [int(_) for _ in re.findall(vcpu_thread_pattern,
                                           str(self.monitor.info("cpus")))]

    def get_vhost_threads(self, vhost_thread_pattern):
        """
        Return the list of vhost threads PIDs

        :param vhost_thread_pattern: a regex to match the vhost threads
        :type vhost_thread_pattern: string
        :return: a list of vhost threads PIDs
        :rtype: list of integer
        """
        return [int(_) for _ in re.findall(vhost_thread_pattern %
                                           self.get_pid(),
                                           utils.system_output("ps aux"))]

    def get_shared_meminfo(self):
        """
        Returns the VM's shared memory information.

        :return: Shared memory used by VM (MB)
        """
        if self.is_dead():
            logging.error("Could not get shared memory info from dead VM.")
            return None

        filename = "/proc/%d/statm" % self.get_pid()
        shm = int(open(filename).read().split()[2])
        # statm stores informations in pages, translate it to MB
        return shm * 4.0 / 1024

    def get_spice_var(self, spice_var):
        """
        Returns string value of spice variable of choice or None
        :param spice_var - spice related variable 'spice_port', ...
        """
        return self.spice_options.get(spice_var, None)

    @error.context_aware
    def hotplug_vcpu(self, cpu_id=None, plug_command=""):
        """
        Hotplug a vcpu, if not assign the cpu_id, will use the minimum unused.
        the function will use the plug_command if you assigned it, else the
        function will use the command automatically generated based on the
        type of monitor

        :param cpu_id  the cpu_id you want hotplug.
        """
        vcpu_threads_count = len(self.vcpu_threads)
        plug_cpu_id = cpu_id
        if plug_cpu_id is None:
            plug_cpu_id = vcpu_threads_count
        if plug_command:
            vcpu_add_cmd = plug_command % plug_cpu_id
        else:
            if self.monitor.protocol == 'human':
                vcpu_add_cmd = "cpu_set %s online" % plug_cpu_id
            elif self.monitor.protocol == 'qmp':
                vcpu_add_cmd = "cpu-add id=%s" % plug_cpu_id

        try:
            self.monitor.verify_supported_cmd(vcpu_add_cmd.split()[0])
        except qemu_monitor.MonitorNotSupportedCmdError:
            raise error.TestNAError("%s monitor not support cmd '%s'" %
                                    (self.monitor.protocol, vcpu_add_cmd))
        try:
            cmd_output = self.monitor.send_args_cmd(vcpu_add_cmd)
        except qemu_monitor.QMPCmdError, e:
            return (False, str(e))

        vcpu_thread_pattern = self.params.get("vcpu_thread_pattern",
                                              r"thread_id.?[:|=]\s*(\d+)")
        self.vcpu_threads = self.get_vcpu_pids(vcpu_thread_pattern)
        if len(self.vcpu_threads) == vcpu_threads_count + 1:
            return(True, plug_cpu_id)
        else:
            return(False, cmd_output)

    @error.context_aware
    def hotplug_nic(self, **params):
        """
        Convenience method wrapper for add_nic() and add_netdev().

        :return: dict-like object containing nic's details
        """
        nic_name = self.add_nic(**params)["nic_name"]
        self.activate_netdev(nic_name)
        self.activate_nic(nic_name)
        return self.virtnet[nic_name]

    @error.context_aware
    def hotunplug_nic(self, nic_index_or_name):
        """
        Convenience method wrapper for del/deactivate nic and netdev.
        """
        # make sure we got a name
        nic_name = self.virtnet[nic_index_or_name].nic_name
        self.deactivate_nic(nic_name)
        self.deactivate_netdev(nic_name)
        self.del_nic(nic_name)

    @error.context_aware
    def add_netdev(self, **params):
        """
        Hotplug a netdev device.

        :param params: NIC info. dict.
        :return: netdev_id
        """
        nic_name = params['nic_name']
        nic = self.virtnet[nic_name]
        nic_index = self.virtnet.nic_name_index(nic_name)
        nic.set_if_none('netdev_id', utils_misc.generate_random_id())
        nic.set_if_none('ifname', self.virtnet.generate_ifname(nic_index))
        nic.set_if_none('netdev_extra_params',
                        params.get('netdev_extra_params'))
        nic.set_if_none('nettype', 'bridge')
        if nic.nettype in ['bridge', 'macvtap']:  # implies tap
            # destination is required, hard-code reasonable default if unset
            # nic.set_if_none('netdst', 'virbr0')
            # tapfd allocated/set in activate because requires system resources
            nic.set_if_none('queues', '1')
            ids = []
            for i in range(int(nic.queues)):
                ids.append(utils_misc.generate_random_id())
            nic.set_if_none('tapfd_ids', ids)

        elif nic.nettype == 'user':
            pass  # nothing to do
        else:  # unsupported nettype
            raise virt_vm.VMUnknownNetTypeError(self.name, nic_name,
                                                nic.nettype)
        return nic.netdev_id

    @error.context_aware
    def del_netdev(self, nic_index_or_name):
        """
        Remove netdev info. from nic on VM, does not deactivate.

        :param: nic_index_or_name: name or index number for existing NIC
        """
        nic = self.virtnet[nic_index_or_name]
        error.context("removing netdev info from nic %s from vm %s" % (
                      nic, self.name))
        for propertea in ['netdev_id', 'ifname', 'queues',
                          'tapfds', 'tapfd_ids', 'vectors']:
            if nic.has_key(propertea):
                del nic[propertea]

    def add_nic(self, **params):
        """
        Add new or setup existing NIC, optionally creating netdev if None

        :param params: Parameters to set
        :param nic_name: Name for existing or new device
        :param nic_model: Model name to emulate
        :param netdev_id: Existing qemu net device ID name, None to create new
        :param mac: Optional MAC address, None to randomly generate.
        """
        # returns existing or new nic object
        nic = super(VM, self).add_nic(**params)
        nic_index = self.virtnet.nic_name_index(nic.nic_name)
        nic.set_if_none('vlan', str(nic_index))
        nic.set_if_none('device_id', utils_misc.generate_random_id())
        nic.set_if_none('queues', '1')
        if not nic.has_key('netdev_id'):
            # virtnet items are lists that act like dicts
            nic.netdev_id = self.add_netdev(**dict(nic))
        nic.set_if_none('nic_model', params['nic_model'])
        nic.set_if_none('queues', params.get('queues', '1'))
        if params.get("enable_msix_vectors") == "yes":
            nic.set_if_none('vectors', 2 * int(nic.queues) + 2)
        return nic

    @error.context_aware
    def activate_netdev(self, nic_index_or_name):
        """
        Activate an inactive host-side networking device

        :raise: IndexError if nic doesn't exist
        :raise: VMUnknownNetTypeError: if nettype is unset/unsupported
        :raise: IOError if TAP device node cannot be opened
        :raise: VMAddNetDevError: if operation failed
        """
        nic = self.virtnet[nic_index_or_name]
        error.context("Activating netdev for %s based on %s" %
                      (self.name, nic))
        msg_sfx = ("nic %s on vm %s with attach_cmd " %
                   (self.virtnet[nic_index_or_name], self.name))

        attach_cmd = "netdev_add"
        if nic.nettype in ['bridge', 'macvtap']:
            error.context("Opening tap device node for %s " % nic.ifname,
                          logging.debug)
            if nic.nettype == "bridge":
                tun_tap_dev = "/dev/net/tun"
                python_tapfds = utils_net.open_tap(tun_tap_dev,
                                                   nic.ifname,
                                                   queues=nic.queues,
                                                   vnet_hdr=False)
            elif nic.nettype == "macvtap":
                macvtap_mode = self.params.get("macvtap_mode", "vepa")
                o_macvtap = utils_net.create_macvtap(nic.ifname, macvtap_mode,
                                                     nic.netdst, nic.mac)
                tun_tap_dev = o_macvtap.get_device()
                python_tapfds = utils_net.open_macvtap(o_macvtap, nic.queues)

            qemu_fds = "/proc/%s/fd" % self.get_pid()
            openfd_list = os.listdir(qemu_fds)
            for i in range(int(nic.queues)):
                error.context("Assigning tap %s to qemu by fd" %
                              nic.tapfd_ids[i], logging.info)
                self.monitor.getfd(int(python_tapfds.split(':')[i]),
                                   nic.tapfd_ids[i])
            n_openfd_list = os.listdir(qemu_fds)
            new_fds = list(set(n_openfd_list) - set(openfd_list))

            if not new_fds:
                err_msg = "Can't get the fd that qemu process opened!"
                raise virt_vm.VMAddNetDevError(err_msg)
            qemu_tapfds = [fd for fd in new_fds if os.readlink(
                           os.path.join(qemu_fds, fd)) == tun_tap_dev]
            if not qemu_tapfds or len(qemu_tapfds) != int(nic.queues):
                err_msg = "Can't get the tap fd in qemu process!"
                raise virt_vm.VMAddNetDevError(err_msg)
            nic.set_if_none("tapfds", ":".join(qemu_tapfds))

            if not self.devices:
                err_msg = "Can't add nic for VM which is not running."
                raise virt_vm.VMAddNetDevError(err_msg)
            if ((int(nic.queues)) > 1 and
                    ',fds=' in self.devices.get_help_text()):
                attach_cmd += " type=tap,id=%s,fds=%s" % (nic.device_id,
                                                          nic.tapfds)
            else:
                attach_cmd += " type=tap,id=%s,fd=%s" % (nic.device_id,
                                                         nic.tapfds)
            error.context("Raising interface for " + msg_sfx + attach_cmd,
                          logging.debug)
            utils_net.bring_up_ifname(nic.ifname)
            # assume this will puke if netdst unset
            if nic.netdst is not None and nic.nettype == "bridge":
                error.context("Raising bridge for " + msg_sfx + attach_cmd,
                              logging.debug)
                utils_net.add_to_bridge(nic.ifname, nic.netdst)
        elif nic.nettype == 'user':
            attach_cmd += " user,id=%s" % nic.device_id
        elif nic.nettype == 'none':
            attach_cmd += " none"
        else:  # unsupported nettype
            raise virt_vm.VMUnknownNetTypeError(self.name, nic_index_or_name,
                                                nic.nettype)
        if nic.has_key('netdev_extra_params') and nic.netdev_extra_params:
            attach_cmd += nic.netdev_extra_params
        error.context("Hotplugging " + msg_sfx + attach_cmd, logging.debug)

        if self.monitor.protocol == 'qmp':
            self.monitor.send_args_cmd(attach_cmd)
        else:
            self.monitor.send_args_cmd(attach_cmd, convert=False)

        network_info = self.monitor.info("network")
        if nic.device_id not in network_info:
            # Don't leave resources dangling
            self.deactivate_netdev(nic_index_or_name)
            raise virt_vm.VMAddNetDevError(("Failed to add netdev: %s for " %
                                            nic.device_id) + msg_sfx +
                                           attach_cmd)

    @error.context_aware
    def activate_nic(self, nic_index_or_name):
        """
        Activate an VM's inactive NIC device and verify state

        :param nic_index_or_name: name or index number for existing NIC
        """
        error.context("Retrieving info for NIC %s on VM %s" % (
                      nic_index_or_name, self.name))
        nic = self.virtnet[nic_index_or_name]
        device_add_cmd = "device_add"
        if nic.has_key('nic_model'):
            device_add_cmd += ' driver=%s' % nic.nic_model
        device_add_cmd += ",netdev=%s" % nic.device_id
        if nic.has_key('mac'):
            device_add_cmd += ",mac=%s" % nic.mac
        device_add_cmd += ",id=%s" % nic.nic_name
        if nic['nic_model'] == 'virtio-net-pci':
            if int(nic['queues']) > 1:
                device_add_cmd += ",mq=on"
            if nic.has_key('vectors'):
                device_add_cmd += ",vectors=%s" % nic.vectors
        device_add_cmd += nic.get('nic_extra_params', '')
        if nic.has_key('romfile'):
            device_add_cmd += ",romfile=%s" % nic.romfile
        error.context("Activating nic on VM %s with monitor command %s" % (
            self.name, device_add_cmd))

        if self.monitor.protocol == 'qmp':
            self.monitor.send_args_cmd(device_add_cmd)
        else:
            self.monitor.send_args_cmd(device_add_cmd, convert=False)

        error.context("Verifying nic %s shows in qtree" % nic.nic_name)
        qtree = self.monitor.info("qtree")
        if nic.nic_name not in qtree:
            logging.error(qtree)
            raise virt_vm.VMAddNicError("Device %s was not plugged into qdev"
                                        "tree" % nic.nic_name)

    @error.context_aware
    def deactivate_nic(self, nic_index_or_name, wait=20):
        """
        Reverses what activate_nic did

        :param nic_index_or_name: name or index number for existing NIC
        :param wait: Time test will wait for the guest to unplug the device
        """
        nic = self.virtnet[nic_index_or_name]
        error.context("Removing nic %s from VM %s" % (nic_index_or_name,
                                                      self.name))
        nic_del_cmd = "device_del id=%s" % (nic.nic_name)

        if self.monitor.protocol == 'qmp':
            self.monitor.send_args_cmd(nic_del_cmd)
        else:
            self.monitor.send_args_cmd(nic_del_cmd, convert=True)

        if wait:
            logging.info("waiting for the guest to finish the unplug")
            nic_eigenvalue = r'dev:\s+%s,\s+id\s+"%s"' % (nic.nic_model,
                                                          nic.nic_name)
            if not utils_misc.wait_for(lambda: nic_eigenvalue not in
                                       self.monitor.info("qtree"),
                                       wait, 5, 1):
                raise virt_vm.VMDelNicError("Device is not unplugged by "
                                            "guest, please check whether the "
                                            "hotplug module was loaded in "
                                            "guest")

    @error.context_aware
    def deactivate_netdev(self, nic_index_or_name):
        """
        Reverses what activate_netdev() did

        :param: nic_index_or_name: name or index number for existing NIC
        """
        # FIXME: Need to down interface & remove from bridge????
        nic = self.virtnet[nic_index_or_name]
        netdev_id = nic.device_id
        error.context("removing netdev id %s from vm %s" %
                      (netdev_id, self.name))
        nic_del_cmd = "netdev_del id=%s" % netdev_id

        if self.monitor.protocol == 'qmp':
            self.monitor.send_args_cmd(nic_del_cmd)
        else:
            self.monitor.send_args_cmd(nic_del_cmd, convert=True)

        network_info = self.monitor.info("network")
        netdev_eigenvalue = r'netdev\s+=\s+%s' % netdev_id
        if netdev_eigenvalue in network_info:
            raise virt_vm.VMDelNetDevError("Fail to remove netdev %s" %
                                           netdev_id)
        if nic.nettype == 'macvtap':
            tap = utils_net.Macvtap(nic.ifname)
            tap.delete()

    @error.context_aware
    def del_nic(self, nic_index_or_name):
        """
        Undefine nic prameters, reverses what add_nic did.

        :param nic_index_or_name: name or index number for existing NIC
        :param wait: Time test will wait for the guest to unplug the device
        """
        super(VM, self).del_nic(nic_index_or_name)

    @error.context_aware
    def send_fd(self, fd, fd_name="migfd"):
        """
        Send file descriptor over unix socket to VM.

        :param fd: File descriptor.
        :param fd_name: File descriptor identificator in VM.
        """
        error.context("Send fd %d like %s to VM %s" % (fd, fd_name, self.name))

        logging.debug("Send file descriptor %s to source VM.", fd_name)
        if self.monitor.protocol == 'human':
            self.monitor.cmd("getfd %s" % (fd_name), fd=fd)
        elif self.monitor.protocol == 'qmp':
            self.monitor.cmd("getfd", args={'fdname': fd_name}, fd=fd)
        error.context()

    def mig_finished(self):
        ret = True
        if (self.params["display"] == "spice" and
                self.get_spice_var("spice_seamless_migration") == "on"):
            s = self.monitor.info("spice")
            if isinstance(s, str):
                ret = "migrated: true" in s
            else:
                ret = s.get("migrated") == "true"
        o = self.monitor.info("migrate")
        if isinstance(o, str):
            return ret and ("status: active" not in o)
        else:
            return ret and (o.get("status") != "active")

    def mig_succeeded(self):
        o = self.monitor.info("migrate")
        if isinstance(o, str):
            return "status: completed" in o
        else:
            return o.get("status") == "completed"

    def mig_failed(self):
        o = self.monitor.info("migrate")
        if isinstance(o, str):
            return "status: failed" in o
        else:
            return o.get("status") == "failed"

    def mig_cancelled(self):
        if self.mig_succeeded():
            raise virt_vm.VMMigrateCancelError(
                "Migration completed successfully")
        elif self.mig_failed():
            raise virt_vm.VMMigrateFailedError("Migration failed")
        o = self.monitor.info("migrate")
        if isinstance(o, str):
            return ("Migration status: cancelled" in o or
                    "Migration status: canceled" in o)
        else:
            return (o.get("status") == "cancelled" or
                    o.get("status") == "canceled")

    def wait_for_migration(self, timeout):
        if not utils_misc.wait_for(self.mig_finished, timeout, 2, 2,
                                   "Waiting for migration to complete"):
            raise virt_vm.VMMigrateTimeoutError("Timeout expired while waiting"
                                                " for migration to finish")

    @error.context_aware
    def migrate(self, timeout=virt_vm.BaseVM.MIGRATE_TIMEOUT, protocol="tcp",
                cancel_delay=None, offline=False, stable_check=False,
                clean=True, save_path="/tmp", dest_host="localhost",
                remote_port=None, not_wait_for_migration=False,
                fd_src=None, fd_dst=None, migration_exec_cmd_src=None,
                migration_exec_cmd_dst=None, env=None):
        """
        Migrate the VM.

        If the migration is local, the VM object's state is switched with that
        of the destination VM.  Otherwise, the state is switched with that of
        a dead VM (returned by self.clone()).

        :param timeout: Time to wait for migration to complete.
        :param protocol: Migration protocol (as defined in MIGRATION_PROTOS)
        :param cancel_delay: If provided, specifies a time duration after which
                migration will be canceled.  Used for testing migrate_cancel.
        :param offline: If True, pause the source VM before migration.
        :param stable_check: If True, compare the VM's state after migration to
                its state before migration and raise an exception if they
                differ.
        :param clean: If True, delete the saved state files (relevant only if
                stable_check is also True).
        :param save_path: The path for state files.
        :param dest_host: Destination host (defaults to 'localhost').
        :param remote_port: Port to use for remote migration.
        :param not_wait_for_migration: If True migration start but not wait till
                the end of migration.
        :param fd_s: File descriptor for migration to which source
                     VM write data. Descriptor is closed during the migration.
        :param fd_d: File descriptor for migration from which destination
                     VM read data.
        :param migration_exec_cmd_src: Command to embed in '-incoming "exec: "'
                (e.g. 'exec:gzip -c > filename') if migration_mode is 'exec'
                default to listening on a random TCP port
        :param migration_exec_cmd_dst: Command to embed in '-incoming "exec: "'
                (e.g. 'gzip -c -d filename') if migration_mode is 'exec'
                default to listening on a random TCP port
        :param env: Dictionary with test environment
        """
        if protocol not in self.MIGRATION_PROTOS:
            raise virt_vm.VMMigrateProtoUnknownError(protocol)

        error.base_context("migrating '%s'" % self.name)

        local = dest_host == "localhost"
        mig_fd_name = None

        if protocol == "fd":
            # Check if descriptors aren't None for local migration.
            if local and (fd_dst is None or fd_src is None):
                (fd_dst, fd_src) = os.pipe()

            mig_fd_name = "migfd_%d_%d" % (fd_src, time.time())
            self.send_fd(fd_src, mig_fd_name)
            os.close(fd_src)

        clone = self.clone()
        if self.params.get('qemu_dst_binary', None) is not None:
            clone.params['qemu_binary'] = utils_misc.get_qemu_dst_binary(self.params)
        if env:
            env.register_vm("%s_clone" % clone.name, clone)
        if (local and not (migration_exec_cmd_src
                           and "gzip" in migration_exec_cmd_src)):
            error.context("creating destination VM")
            if stable_check:
                # Pause the dest vm after creation
                extra_params = clone.params.get("extra_params", "") + " -S"
                clone.params["extra_params"] = extra_params

            clone.create(migration_mode=protocol, mac_source=self,
                         migration_fd=fd_dst,
                         migration_exec_cmd=migration_exec_cmd_dst)
            if fd_dst:
                os.close(fd_dst)
            error.context()

        try:
            if (self.params["display"] == "spice" and local and
                not (protocol == "exec" and
                     (migration_exec_cmd_src and "gzip" in migration_exec_cmd_src))):
                host_ip = utils_net.get_host_ip_address(self.params)
                dest_port = clone.spice_options.get('spice_port', '')
                if self.params.get("spice_ssl") == "yes":
                    dest_tls_port = clone.spice_options.get("spice_tls_port",
                                                            "")
                    cert_s = clone.spice_options.get("spice_x509_server_subj",
                                                     "")
                    cert_subj = "%s" % cert_s[1:]
                    cert_subj += host_ip
                    cert_subj = "\"%s\"" % cert_subj
                else:
                    dest_tls_port = ""
                    cert_subj = ""
                logging.debug("Informing migration to spice client")
                commands = ["__com.redhat_spice_migrate_info",
                            "spice_migrate_info",
                            "client_migrate_info"]

                cmdline = ""
                for command in commands:
                    try:
                        self.monitor.verify_supported_cmd(command)
                    except qemu_monitor.MonitorNotSupportedCmdError:
                        continue
                    # spice_migrate_info requires host_ip, dest_port
                    # client_migrate_info also requires protocol
                    cmdline = "%s hostname=%s" % (command, host_ip)
                    if command == "client_migrate_info":
                        cmdline += " ,protocol=%s" % self.params['display']
                    if dest_port:
                        cmdline += ",port=%s" % dest_port
                    if dest_tls_port:
                        cmdline += ",tls-port=%s" % dest_tls_port
                    if cert_subj:
                        cmdline += ",cert-subject=%s" % cert_subj
                    break
                if cmdline:
                    self.monitor.send_args_cmd(cmdline)

            if protocol in ["tcp", "rdma", "x-rdma"]:
                if local:
                    uri = protocol + ":localhost:%d" % clone.migration_port
                else:
                    uri = protocol + ":%s:%d" % (dest_host, remote_port)
            elif protocol == "unix":
                uri = "unix:%s" % clone.migration_file
            elif protocol == "exec":
                if local:
                    if not migration_exec_cmd_src:
                        uri = '"exec:nc localhost %s"' % clone.migration_port
                    else:
                        uri = '"exec:%s"' % (migration_exec_cmd_src)
                else:
                    uri = '"exec:%s"' % (migration_exec_cmd_src)
            elif protocol == "fd":
                uri = "fd:%s" % mig_fd_name

            if offline is True:
                self.monitor.cmd("stop")

            logging.info("Migrating to %s", uri)
            self.monitor.migrate(uri)
            if not_wait_for_migration:
                return clone

            if cancel_delay:
                time.sleep(cancel_delay)
                self.monitor.cmd("migrate_cancel")
                if not utils_misc.wait_for(self.mig_cancelled, 60, 2, 2,
                                           "Waiting for migration "
                                           "cancellation"):
                    raise virt_vm.VMMigrateCancelError(
                        "Cannot cancel migration")
                return

            self.wait_for_migration(timeout)

            if (local and (migration_exec_cmd_src
                           and "gzip" in migration_exec_cmd_src)):
                error.context("creating destination VM")
                if stable_check:
                    # Pause the dest vm after creation
                    extra_params = clone.params.get("extra_params", "") + " -S"
                    clone.params["extra_params"] = extra_params
                clone.create(migration_mode=protocol, mac_source=self,
                             migration_fd=fd_dst,
                             migration_exec_cmd=migration_exec_cmd_dst)

            self.verify_alive()

            # Report migration status
            if self.mig_succeeded():
                logging.info("Migration completed successfully")
            elif self.mig_failed():
                raise virt_vm.VMMigrateFailedError("Migration failed")
            else:
                raise virt_vm.VMMigrateFailedError("Migration ended with "
                                                   "unknown status")

            # Switch self <-> clone
            temp = self.clone(copy_state=True)
            self.__dict__ = clone.__dict__
            clone = temp

            # From now on, clone is the source VM that will soon be destroyed
            # and self is the destination VM that will remain alive.  If this
            # is remote migration, self is a dead VM object.

            error.context("after migration")
            if local:
                time.sleep(1)
                self.verify_kernel_crash()
                self.verify_alive()

            if local and stable_check:
                try:
                    save1 = os.path.join(save_path, "src-" + clone.instance)
                    save2 = os.path.join(save_path, "dst-" + self.instance)
                    clone.save_to_file(save1)
                    self.save_to_file(save2)
                    # Fail if we see deltas
                    md5_save1 = utils.hash_file(save1)
                    md5_save2 = utils.hash_file(save2)
                    if md5_save1 != md5_save2:
                        raise virt_vm.VMMigrateStateMismatchError()
                finally:
                    if clean:
                        if os.path.isfile(save1):
                            os.remove(save1)
                        if os.path.isfile(save2):
                            os.remove(save2)

        finally:
            # If we're doing remote migration and it's completed successfully,
            # self points to a dead VM object
            if not not_wait_for_migration:
                if self.is_alive():
                    self.monitor.cmd("cont")
                clone.destroy(gracefully=False)
                if env:
                    env.unregister_vm("%s_clone" % self.name)

    @error.context_aware
    def reboot(self, session=None, method="shell", nic_index=0,
               timeout=virt_vm.BaseVM.REBOOT_TIMEOUT):
        """
        Reboot the VM and wait for it to come back up by trying to log in until
        timeout expires.

        :param session: A shell session object or None.
        :param method: Reboot method.  Can be "shell" (send a shell reboot
                command) or "system_reset" (send a system_reset monitor command).
        :param nic_index: Index of NIC to access in the VM, when logging in
                after rebooting.
        :param timeout: Time to wait for login to succeed (after rebooting).
        :return: A new shell session object.
        """
        error.base_context("rebooting '%s'" % self.name, logging.info)
        error.context("before reboot")
        error.context()

        if method == "shell":
            session = session or self.login()
            session.sendline(self.params.get("reboot_command"))
            error.context("waiting for guest to go down", logging.info)
            if not utils_misc.wait_for(
                lambda:
                    not session.is_responsive(
                        timeout=self.CLOSE_SESSION_TIMEOUT),
                    timeout / 2, 0, 1):
                raise virt_vm.VMRebootError("Guest refuses to go down")
            session.close()

        elif method == "system_reset":
            # Clear the event list of all QMP monitors
            qmp_monitors = [m for m in self.monitors if m.protocol == "qmp"]
            for m in qmp_monitors:
                m.clear_events()
            # Send a system_reset monitor command
            self.monitor.cmd("system_reset")
            # Look for RESET QMP events
            time.sleep(1)
            for m in qmp_monitors:
                if m.get_event("RESET"):
                    logging.info("RESET QMP event received")
                else:
                    raise virt_vm.VMRebootError("RESET QMP event not received "
                                                "after system_reset "
                                                "(monitor '%s')" % m.name)
        else:
            raise virt_vm.VMRebootError("Unknown reboot method: %s" % method)

        if self.params.get("mac_changeable") == "yes":
            utils_net.update_mac_ip_address(self, self.params)

        error.context("logging in after reboot", logging.info)
        return self.wait_for_login(nic_index, timeout=timeout)

    def send_key(self, keystr):
        """
        Send a key event to the VM.

        :param keystr: A key event string (e.g. "ctrl-alt-delete")
        """
        # For compatibility with versions of QEMU that do not recognize all
        # key names: replace keyname with the hex value from the dict, which
        # QEMU will definitely accept
        key_mapping = {"semicolon": "0x27",
                       "comma": "0x33",
                       "dot": "0x34",
                       "slash": "0x35"}
        for key, value in key_mapping.items():
            keystr = keystr.replace(key, value)
        self.monitor.sendkey(keystr)
        time.sleep(0.2)

    # should this really be expected from VMs of all hypervisor types?
    def screendump(self, filename, debug=True):
        try:
            if self.monitor:
                self.monitor.screendump(filename=filename, debug=debug)
        except qemu_monitor.MonitorError, e:
            logging.warn(e)

    def save_to_file(self, path):
        """
        Override BaseVM save_to_file method
        """
        self.verify_status('paused')  # Throws exception if not
        # Set high speed 1TB/S
        self.monitor.migrate_set_speed(str(2 << 39))
        self.monitor.migrate_set_downtime(self.MIGRATE_TIMEOUT)
        logging.debug("Saving VM %s to %s" % (self.name, path))
        # Can only check status if background migration
        self.monitor.migrate("exec:cat>%s" % path, wait=False)
        utils_misc.wait_for(
            # no monitor.migrate-status method
            lambda:
            re.search("(status.*completed)",
                      str(self.monitor.info("migrate")), re.M),
            self.MIGRATE_TIMEOUT, 2, 2,
            "Waiting for save to %s to complete" % path)
        # Restore the speed and downtime to default values
        self.monitor.migrate_set_speed(str(32 << 20))
        self.monitor.migrate_set_downtime(0.03)
        # Base class defines VM must be off after a save
        self.monitor.cmd("system_reset")
        self.verify_status('paused')  # Throws exception if not

    def restore_from_file(self, path):
        """
        Override BaseVM restore_from_file method
        """
        self.verify_status('paused')  # Throws exception if not
        logging.debug("Restoring VM %s from %s" % (self.name, path))
        # Rely on create() in incoming migration mode to do the 'right thing'
        self.create(name=self.name, params=self.params, root_dir=self.root_dir,
                    timeout=self.MIGRATE_TIMEOUT, migration_mode="exec",
                    migration_exec_cmd="cat " + path, mac_source=self)
        self.verify_status('running')  # Throws exception if not

    def savevm(self, tag_name):
        """
        Override BaseVM savevm method
        """
        self.verify_status('paused')  # Throws exception if not
        logging.debug("Saving VM %s to %s" % (self.name, tag_name))
        self.monitor.send_args_cmd("savevm id=%s" % tag_name)
        self.monitor.cmd("system_reset")
        self.verify_status('paused')  # Throws exception if not

    def loadvm(self, tag_name):
        """
        Override BaseVM loadvm method
        """
        self.verify_status('paused')  # Throws exception if not
        logging.debug("Loading VM %s from %s" % (self.name, tag_name))
        self.monitor.send_args_cmd("loadvm id=%s" % tag_name)
        self.verify_status('paused')  # Throws exception if not

    def pause(self):
        """
        Pause the VM operation.
        """
        self.monitor.cmd("stop")

    def resume(self):
        """
        Resume the VM operation in case it's stopped.
        """
        self.monitor.cmd("cont")

    def set_link(self, netdev_name, up):
        """
        Set link up/down.

        :param name: Link name
        :param up: Bool value, True=set up this link, False=Set down this link
        """
        self.monitor.set_link(netdev_name, up)

    def get_block_old(self, blocks_info, p_dict={}):
        """
        Get specified block device from monitor's info block command.
        The block device is defined by parameter in p_dict.

        :param p_dict: Dictionary that contains parameters and its value used
                       to define specified block device.

        :param blocks_info: the results of monitor command 'info block'

        :return: Matched block device name, None when not find any device.
        """
        if isinstance(blocks_info, str):
            for block in blocks_info.splitlines():
                match = True
                for key, value in p_dict.iteritems():
                    if value is True:
                        check_str = "%s=1" % key
                    elif value is False:
                        check_str = "%s=0" % key
                    else:
                        check_str = "%s=%s" % (key, value)
                    if check_str not in block:
                        match = False
                        break
                if match:
                    return block.split(":")[0]
        else:
            for block in blocks_info:
                match = True
                for key, value in p_dict.iteritems():
                    if isinstance(value, bool):
                        check_str = "u'%s': %s" % (key, value)
                    else:
                        check_str = "u'%s': u'%s'" % (key, value)
                    if check_str not in str(block):
                        match = False
                        break
                if match:
                    return block['device']
        return None

    def process_info_block(self, blocks_info):
        """
        Process the info block, so that can deal with the new and old
        qemu format.

        :param blocks_info: the output of qemu command
                            'info block'
        """
        block_list = []
        block_entry = []
        for block in blocks_info.splitlines():
            if block:
                block_entry.append(block.strip())
            else:
                block_list.append(' '.join(block_entry))
                block_entry = []
        # don't forget the last one
        block_list.append(' '.join(block_entry))
        return block_list

    def get_block(self, p_dict={}):
        """
        Get specified block device from monitor's info block command.
        The block device is defined by parameter in p_dict.

        :param p_dict: Dictionary that contains parameters and its value used
                       to define specified block device.

        :return: Matched block device name, None when not find any device.
        """
        blocks_info = self.monitor.info("block")
        block = self.get_block_old(blocks_info, p_dict)
        if block:
            return block

        block_list = self.process_info_block(blocks_info)
        for block in block_list:
            for key, value in p_dict.iteritems():
                    # for new qemu we just deal with key = [removable,
                    # file,backing_file], for other types key, we should
                    # fixup later
                logging.info("block = %s" % block)
                if key == 'removable':
                    if value is False:
                        if 'Removable device' not in block:
                            return block.split(":")[0]
                    elif value is True:
                        if 'Removable device' in block:
                            return block.split(":")[0]
                # file in key means both file and backing_file
                if ('file' in key) and (value in block):
                    return block.split(":")[0]

        return None

    def check_block_locked(self, value):
        """
        Check whether specified block device is locked or not.
        Return True, if device is locked, else False.

        :param vm: VM object
        :param value: Parameter that can specify block device.
                      Can be any possible identification of a device,
                      Such as device name/image file name/...

        :return: True if device is locked, False if device is unlocked.
        """
        assert value, "Device identification not specified"

        blocks_info = self.monitor.info("block")

        assert value in str(blocks_info), \
            "Device %s not listed in monitor's output" % value

        if isinstance(blocks_info, str):
            lock_str = "locked=1"
            lock_str_new = "locked"
            no_lock_str = "not locked"
            for block in blocks_info.splitlines():
                if (value in block) and (lock_str in block):
                    return True
            # deal with new qemu
            block_list = self.process_info_block(blocks_info)
            for block_new in block_list:
                if (value in block_new) and ("Removable device" in block_new):
                    if no_lock_str in block_new:
                        return False
                    elif lock_str_new in block_new:
                        return True
        else:
            for block in blocks_info:
                if value in str(block):
                    return block['locked']
        return False

    def live_snapshot(self, base_file, snapshot_file,
                      snapshot_format="qcow2"):
        """
        Take a live disk snapshot.

        :param base_file: base file name
        :param snapshot_file: snapshot file name
        :param snapshot_format: snapshot file format

        :return: File name of disk snapshot.
        """
        device = self.get_block({"file": base_file})

        output = self.monitor.live_snapshot(device, snapshot_file,
                                            snapshot_format)
        logging.debug(output)
        device = self.get_block({"file": snapshot_file})
        if device:
            current_file = device
        else:
            current_file = None

        return current_file

    def block_stream(self, device, speed, base=None, correct=True):
        """
        start to stream block device, aka merge snapshot;

        :param device: device ID;
        :param speed: limited speed, default unit B/s;
        :param base: base file;
        :param correct: auto correct cmd, correct by default
        """
        cmd = self.params.get("block_stream_cmd", "block-stream")
        return self.monitor.block_stream(device, speed, base,
                                         cmd, correct=correct)

    def block_mirror(self, device, target, speed, sync,
                     format, mode="absolute-paths", correct=True):
        """
        Mirror block device to target file;

        :param device: device ID
        :param target: destination image file name;
        :param speed: max limited speed, default unit is B/s;
        :param sync: what parts of the disk image should be copied to the
                     destination;
        :param mode: new image open mode
        :param format: target image format
        :param correct: auto correct cmd, correct by default
        """
        cmd = self.params.get("block_mirror_cmd", "drive-mirror")
        return self.monitor.block_mirror(device, target, speed, sync,
                                         format, mode, cmd, correct=correct)

    def block_reopen(self, device, new_image, format="qcow2", correct=True):
        """
        Reopen a new image, no need to do this step in rhel7 host

        :param device: device ID
        :param new_image: new image filename
        :param format: new image format
        :param correct: auto correct cmd, correct by default
        """
        cmd = self.params.get("block_reopen_cmd", "block-job-complete")
        return self.monitor.block_reopen(device, new_image,
                                         format, cmd, correct=correct)

    def cancel_block_job(self, device, correct=True):
        """
        cancel active job on the image_file

        :param device: device ID
        :param correct: auto correct cmd, correct by default
        """
        cmd = self.params.get("block_job_cancel_cmd", "block-job-cancel")
        return self.monitor.cancel_block_job(device, cmd, correct=correct)

    def set_job_speed(self, device, speed="0", correct=True):
        """
        set max speed of block job;

        :param device: device ID
        :param speed: max speed of block job
        :param correct: auto correct cmd, correct by default
        """
        cmd = self.params.get("set_block_job_speed", "block-job-set-speed")
        return self.monitor.set_block_job_speed(device, speed,
                                                cmd, correct=correct)

    def get_job_status(self, device):
        """
        get block job info;

        :param device: device ID
        """
        return self.monitor.query_block_job(device)

    def eject_cdrom(self, device, force=False):
        """
        Eject cdrom and open door of the CDROM;

        :param device: device ID;
        :param force: force eject or not;
        """
        return self.monitor.eject_cdrom(device, force)

    def change_media(self, device, target):
        """
        Change media of cdrom;

        :param device: Device ID;
        :param target: new media file;
        """
        return self.monitor.change_media(device, target)

########NEW FILE########
__FILENAME__ = remote
"""
Functions and classes used for logging into guests and transferring files.
"""
import logging
import time
import re
import os
import shutil
import tempfile
import aexpect
import utils_misc
import rss_client
import base64

from remote_commander import remote_master
from remote_commander import messenger

from autotest.client.shared import error
from autotest.client import utils
import data_dir


class LoginError(Exception):

    def __init__(self, msg, output):
        Exception.__init__(self, msg, output)
        self.msg = msg
        self.output = output

    def __str__(self):
        return "%s    (output: %r)" % (self.msg, self.output)


class LoginAuthenticationError(LoginError):
    pass


class LoginTimeoutError(LoginError):

    def __init__(self, output):
        LoginError.__init__(self, "Login timeout expired", output)


class LoginProcessTerminatedError(LoginError):

    def __init__(self, status, output):
        LoginError.__init__(self, None, output)
        self.status = status

    def __str__(self):
        return ("Client process terminated    (status: %s,    output: %r)" %
                (self.status, self.output))


class LoginBadClientError(LoginError):

    def __init__(self, client):
        LoginError.__init__(self, None, None)
        self.client = client

    def __str__(self):
        return "Unknown remote shell client: %r" % self.client


class SCPError(Exception):

    def __init__(self, msg, output):
        Exception.__init__(self, msg, output)
        self.msg = msg
        self.output = output

    def __str__(self):
        return "%s    (output: %r)" % (self.msg, self.output)


class SCPAuthenticationError(SCPError):
    pass


class SCPAuthenticationTimeoutError(SCPAuthenticationError):

    def __init__(self, output):
        SCPAuthenticationError.__init__(self, "Authentication timeout expired",
                                        output)


class SCPTransferTimeoutError(SCPError):

    def __init__(self, output):
        SCPError.__init__(self, "Transfer timeout expired", output)


class SCPTransferFailedError(SCPError):

    def __init__(self, status, output):
        SCPError.__init__(self, None, output)
        self.status = status

    def __str__(self):
        return ("SCP transfer failed    (status: %s,    output: %r)" %
                (self.status, self.output))


def handle_prompts(session, username, password, prompt, timeout=10,
                   debug=False):
    """
    Connect to a remote host (guest) using SSH or Telnet or else.

    Wait for questions and provide answers.  If timeout expires while
    waiting for output from the child (e.g. a password prompt or
    a shell prompt) -- fail.

    :param session: An Expect or ShellSession instance to operate on
    :param username: The username to send in reply to a login prompt
    :param password: The password to send in reply to a password prompt
    :param prompt: The shell prompt that indicates a successful login
    :param timeout: The maximal time duration (in seconds) to wait for each
            step of the login procedure (i.e. the "Are you sure" prompt, the
            password prompt, the shell prompt, etc)
    :raise LoginTimeoutError: If timeout expires
    :raise LoginAuthenticationError: If authentication fails
    :raise LoginProcessTerminatedError: If the client terminates during login
    :raise LoginError: If some other error occurs
    """
    password_prompt_count = 0
    login_prompt_count = 0

    while True:
        try:
            match, text = session.read_until_last_line_matches(
                [r"[Aa]re you sure", r"[Pp]assword:\s*",
                 r"\(or (press|type) Control-D to continue\):\s*$",  # Prompt of rescue mode for Red Hat.
                 r"[Gg]ive.*[Ll]ogin:\s*$",  # Prompt of rescue mode for SUSE.
                 r"(?<![Ll]ast).*[Ll]ogin:\s*$",  # Don't match "Last Login:"
                 r"[Cc]onnection.*closed", r"[Cc]onnection.*refused",
                 r"[Pp]lease wait", r"[Ww]arning", r"[Ee]nter.*username",
                 r"[Ee]nter.*password", prompt],
                timeout=timeout, internal_timeout=0.5)
            if match == 0:  # "Are you sure you want to continue connecting"
                if debug:
                    logging.debug("Got 'Are you sure...', sending 'yes'")
                session.sendline("yes")
                continue
            elif match in [1, 2, 3, 10]:  # "password:"
                if password_prompt_count == 0:
                    if debug:
                        logging.debug("Got password prompt, sending '%s'",
                                      password)
                    session.sendline(password)
                    password_prompt_count += 1
                    continue
                else:
                    raise LoginAuthenticationError("Got password prompt twice",
                                                   text)
            elif match == 4 or match == 9:  # "login:"
                if login_prompt_count == 0 and password_prompt_count == 0:
                    if debug:
                        logging.debug("Got username prompt; sending '%s'",
                                      username)
                    session.sendline(username)
                    login_prompt_count += 1
                    continue
                else:
                    if login_prompt_count > 0:
                        msg = "Got username prompt twice"
                    else:
                        msg = "Got username prompt after password prompt"
                    raise LoginAuthenticationError(msg, text)
            elif match == 5:  # "Connection closed"
                raise LoginError("Client said 'connection closed'", text)
            elif match == 6:  # "Connection refused"
                raise LoginError("Client said 'connection refused'", text)
            elif match == 7:  # "Please wait"
                if debug:
                    logging.debug("Got 'Please wait'")
                timeout = 30
                continue
            elif match == 8:  # "Warning added RSA"
                if debug:
                    logging.debug("Got 'Warning added RSA to known host list")
                continue
            elif match == 11:  # prompt
                if debug:
                    logging.debug("Got shell prompt -- logged in")
                break
        except aexpect.ExpectTimeoutError, e:
            raise LoginTimeoutError(e.output)
        except aexpect.ExpectProcessTerminatedError, e:
            raise LoginProcessTerminatedError(e.status, e.output)


def remote_login(client, host, port, username, password, prompt, linesep="\n",
                 log_filename=None, timeout=10, interface=None):
    """
    Log into a remote host (guest) using SSH/Telnet/Netcat.

    :param client: The client to use ('ssh', 'telnet' or 'nc')
    :param host: Hostname or IP address
    :param port: Port to connect to
    :param username: Username (if required)
    :param password: Password (if required)
    :param prompt: Shell prompt (regular expression)
    :param linesep: The line separator to use when sending lines
            (e.g. '\\n' or '\\r\\n')
    :param log_filename: If specified, log all output to this file
    :param timeout: The maximal time duration (in seconds) to wait for
            each step of the login procedure (i.e. the "Are you sure" prompt
            or the password prompt)
    :interface: The interface the neighbours attach to (only use when using ipv6
                linklocal address.)
    :raise LoginError: If using ipv6 linklocal but not assign a interface that
                       the neighbour attache
    :raise LoginBadClientError: If an unknown client is requested
    :raise: Whatever handle_prompts() raises
    :return: A ShellSession object.
    """
    if host and host.lower().startswith("fe80"):
        if not interface:
            raise LoginError("When using ipv6 linklocal an interface must "
                             "be assigned")
        host = "%s%%%s" % (host, interface)
    if client == "ssh":
        cmd = ("ssh -o UserKnownHostsFile=/dev/null "
               "-o StrictHostKeyChecking=no "
               "-o PreferredAuthentications=password -p %s %s@%s" %
               (port, username, host))
    elif client == "telnet":
        cmd = "telnet -l %s %s %s" % (username, host, port)
    elif client == "nc":
        cmd = "nc %s %s" % (host, port)
    else:
        raise LoginBadClientError(client)

    logging.debug("Login command: '%s'", cmd)
    session = aexpect.ShellSession(cmd, linesep=linesep, prompt=prompt)
    try:
        handle_prompts(session, username, password, prompt, timeout)
    except Exception:
        session.close()
        raise
    if log_filename:
        session.set_output_func(utils_misc.log_line)
        session.set_output_params((log_filename,))
        session.set_log_file(log_filename)
    return session


class AexpectIOWrapperOut(messenger.StdIOWrapperOutBase64):

    """
    Basic implementation of IOWrapper for stdout
    """

    def close(self):
        self._obj.close()

    def fileno(self):
        return os.open(self._obj, os.O_RDWR)

    def write(self, data):
        self._obj.send(data)


def remote_commander(client, host, port, username, password, prompt,
                     linesep="\n", log_filename=None, timeout=10, path=None):
    """
    Log into a remote host (guest) using SSH/Telnet/Netcat.

    :param client: The client to use ('ssh', 'telnet' or 'nc')
    :param host: Hostname or IP address
    :param port: Port to connect to
    :param username: Username (if required)
    :param password: Password (if required)
    :param prompt: Shell prompt (regular expression)
    :param linesep: The line separator to use when sending lines
            (e.g. '\\n' or '\\r\\n')
    :param log_filename: If specified, log all output to this file
    :param timeout: The maximal time duration (in seconds) to wait for
            each step of the login procedure (i.e. the "Are you sure" prompt
            or the password prompt)
    :param path: The path to place where remote_runner.py is placed.
    :raise LoginBadClientError: If an unknown client is requested
    :raise: Whatever handle_prompts() raises
    :return: A ShellSession object.
    """
    if path is None:
        path = "/tmp"
    if client == "ssh":
        cmd = ("ssh -o UserKnownHostsFile=/dev/null "
               "-o PreferredAuthentications=password "
               "-p %s %s@%s %s agent_base64" %
               (port, username, host, os.path.join(path, "remote_runner.py")))
    elif client == "telnet":
        cmd = "telnet -l %s %s %s" % (username, host, port)
    elif client == "nc":
        cmd = "nc %s %s" % (host, port)
    else:
        raise LoginBadClientError(client)

    logging.debug("Login command: '%s'", cmd)
    session = aexpect.Expect(cmd, linesep=linesep)
    try:
        handle_prompts(session, username, password, prompt, timeout)
    except Exception:
        session.close()
        raise
    if log_filename:
        session.set_output_func(utils_misc.log_line)
        session.set_output_params((log_filename,))
        session.set_log_file(log_filename)

    session.send_ctrl("raw")
    # Wrap io interfaces.
    inw = messenger.StdIOWrapperInBase64(session._get_fd("tail"))
    outw = AexpectIOWrapperOut(session)
    # Create commander

    cmd = remote_master.CommanderMaster(inw, outw, False)
    return cmd


def wait_for_login(client, host, port, username, password, prompt,
                   linesep="\n", log_filename=None, timeout=240,
                   internal_timeout=10, interface=None):
    """
    Make multiple attempts to log into a guest until one succeeds or timeouts.

    :param timeout: Total time duration to wait for a successful login
    :param internal_timeout: The maximum time duration (in seconds) to wait for
                             each step of the login procedure (e.g. the
                             "Are you sure" prompt or the password prompt)
    :interface: The interface the neighbours attach to (only use when using ipv6
                linklocal address.)
    :see: remote_login()
    :raise: Whatever remote_login() raises
    :return: A ShellSession object.
    """
    logging.debug("Attempting to log into %s:%s using %s (timeout %ds)",
                  host, port, client, timeout)
    end_time = time.time() + timeout
    while time.time() < end_time:
        try:
            return remote_login(client, host, port, username, password, prompt,
                                linesep, log_filename, internal_timeout,
                                interface)
        except LoginError, e:
            logging.debug(e)
        time.sleep(2)
    # Timeout expired; try one more time but don't catch exceptions
    return remote_login(client, host, port, username, password, prompt,
                        linesep, log_filename, internal_timeout, interface)


def _remote_scp(session, password_list, transfer_timeout=600, login_timeout=20):
    """
    Transfer files using SCP, given a command line.

    Transfer file(s) to a remote host (guest) using SCP.  Wait for questions
    and provide answers.  If login_timeout expires while waiting for output
    from the child (e.g. a password prompt), fail.  If transfer_timeout expires
    while waiting for the transfer to complete, fail.

    :param session: An Expect or ShellSession instance to operate on
    :param password_list: Password list to send in reply to the password prompt
    :param transfer_timeout: The time duration (in seconds) to wait for the
            transfer to complete.
    :param login_timeout: The maximal time duration (in seconds) to wait for
            each step of the login procedure (i.e. the "Are you sure" prompt or
            the password prompt)
    :raise SCPAuthenticationError: If authentication fails
    :raise SCPTransferTimeoutError: If the transfer fails to complete in time
    :raise SCPTransferFailedError: If the process terminates with a nonzero
            exit code
    :raise SCPError: If some other error occurs
    """
    password_prompt_count = 0
    timeout = login_timeout
    authentication_done = False

    scp_type = len(password_list)

    while True:
        try:
            match, text = session.read_until_last_line_matches(
                [r"[Aa]re you sure", r"[Pp]assword:\s*$", r"lost connection"],
                timeout=timeout, internal_timeout=0.5)
            if match == 0:  # "Are you sure you want to continue connecting"
                logging.debug("Got 'Are you sure...', sending 'yes'")
                session.sendline("yes")
                continue
            elif match == 1:  # "password:"
                if password_prompt_count == 0:
                    logging.debug("Got password prompt, sending '%s'" %
                                  password_list[password_prompt_count])
                    session.sendline(password_list[password_prompt_count])
                    password_prompt_count += 1
                    timeout = transfer_timeout
                    if scp_type == 1:
                        authentication_done = True
                    continue
                elif password_prompt_count == 1 and scp_type == 2:
                    logging.debug("Got password prompt, sending '%s'" %
                                  password_list[password_prompt_count])
                    session.sendline(password_list[password_prompt_count])
                    password_prompt_count += 1
                    timeout = transfer_timeout
                    authentication_done = True
                    continue
                else:
                    raise SCPAuthenticationError("Got password prompt twice",
                                                 text)
            elif match == 2:  # "lost connection"
                raise SCPError("SCP client said 'lost connection'", text)
        except aexpect.ExpectTimeoutError, e:
            if authentication_done:
                raise SCPTransferTimeoutError(e.output)
            else:
                raise SCPAuthenticationTimeoutError(e.output)
        except aexpect.ExpectProcessTerminatedError, e:
            if e.status == 0:
                logging.debug("SCP process terminated with status 0")
                break
            else:
                raise SCPTransferFailedError(e.status, e.output)


def remote_scp(command, password_list, log_filename=None, transfer_timeout=600,
               login_timeout=20):
    """
    Transfer files using SCP, given a command line.

    :param command: The command to execute
        (e.g. "scp -r foobar root@localhost:/tmp/").
    :param password_list: Password list to send in reply to a password prompt.
    :param log_filename: If specified, log all output to this file
    :param transfer_timeout: The time duration (in seconds) to wait for the
            transfer to complete.
    :param login_timeout: The maximal time duration (in seconds) to wait for
            each step of the login procedure (i.e. the "Are you sure" prompt
            or the password prompt)
    :raise: Whatever _remote_scp() raises
    """
    logging.debug("Trying to SCP with command '%s', timeout %ss",
                  command, transfer_timeout)
    if log_filename:
        output_func = utils_misc.log_line
        output_params = (log_filename,)
    else:
        output_func = None
        output_params = ()
    session = aexpect.Expect(command,
                             output_func=output_func,
                             output_params=output_params)
    try:
        _remote_scp(session, password_list, transfer_timeout, login_timeout)
    finally:
        session.close()


def scp_to_remote(host, port, username, password, local_path, remote_path,
                  limit="", log_filename=None, timeout=600, interface=None):
    """
    Copy files to a remote host (guest) through scp.

    :param host: Hostname or IP address
    :param username: Username (if required)
    :param password: Password (if required)
    :param local_path: Path on the local machine where we are copying from
    :param remote_path: Path on the remote machine where we are copying to
    :param limit: Speed limit of file transfer.
    :param log_filename: If specified, log all output to this file
    :param timeout: The time duration (in seconds) to wait for the transfer
            to complete.
    :interface: The interface the neighbours attach to (only use when using ipv6
                linklocal address.)
    :raise: Whatever remote_scp() raises
    """
    if (limit):
        limit = "-l %s" % (limit)

    if host and host.lower().startswith("fe80"):
        if not interface:
            raise SCPError("When using ipv6 linklocal address must assign",
                           "the interface the neighbour attache")
        host = "%s%%%s" % (host, interface)

    command = ("scp -v -o UserKnownHostsFile=/dev/null "
               "-o StrictHostKeyChecking=no "
               "-o PreferredAuthentications=password -r %s "
               "-P %s %s %s@\[%s\]:%s" %
               (limit, port, local_path, username, host, remote_path))
    password_list = []
    password_list.append(password)
    return remote_scp(command, password_list, log_filename, timeout)


def scp_from_remote(host, port, username, password, remote_path, local_path,
                    limit="", log_filename=None, timeout=600, interface=None):
    """
    Copy files from a remote host (guest).

    :param host: Hostname or IP address
    :param username: Username (if required)
    :param password: Password (if required)
    :param local_path: Path on the local machine where we are copying from
    :param remote_path: Path on the remote machine where we are copying to
    :param limit: Speed limit of file transfer.
    :param log_filename: If specified, log all output to this file
    :param timeout: The time duration (in seconds) to wait for the transfer
            to complete.
    :interface: The interface the neighbours attach to (only use when using ipv6
                linklocal address.)
    :raise: Whatever remote_scp() raises
    """
    if (limit):
        limit = "-l %s" % (limit)
    if host and host.lower().startswith("fe80"):
        if not interface:
            raise SCPError("When using ipv6 linklocal address must assign, ",
                           "the interface the neighbour attache")
        host = "%s%%%s" % (host, interface)

    command = ("scp -v -o UserKnownHostsFile=/dev/null "
               "-o StrictHostKeyChecking=no "
               "-o PreferredAuthentications=password -r %s "
               "-P %s %s@\[%s\]:%s %s" %
               (limit, port, username, host, remote_path, local_path))
    password_list = []
    password_list.append(password)
    remote_scp(command, password_list, log_filename, timeout)


def scp_between_remotes(src, dst, port, s_passwd, d_passwd, s_name, d_name,
                        s_path, d_path, limit="", log_filename=None,
                        timeout=600, src_inter=None, dst_inter=None):
    """
    Copy files from a remote host (guest) to another remote host (guest).

    :param src/dst: Hostname or IP address of src and dst
    :param s_name/d_name: Username (if required)
    :param s_passwd/d_passwd: Password (if required)
    :param s_path/d_path: Path on the remote machine where we are copying
                         from/to
    :param limit: Speed limit of file transfer.
    :param log_filename: If specified, log all output to this file
    :param timeout: The time duration (in seconds) to wait for the transfer
            to complete.
    :src_inter: The interface on local that the src neighbour attache
    :dst_inter: The interface on the src that the dst neighbour attache

    :return: True on success and False on failure.
    """
    if (limit):
        limit = "-l %s" % (limit)
    if src and src.lower().startswith("fe80"):
        if not src_inter:
            raise SCPError("When using ipv6 linklocal address must assign ",
                           "the interface the neighbour attache")
        src = "%s%%%s" % (src, src_inter)
    if dst and dst.lower().startswith("fe80"):
        if not dst_inter:
            raise SCPError("When using ipv6 linklocal address must assign ",
                           "the interface the neighbour attache")
        dst = "%s%%%s" % (dst, dst_inter)

    command = ("scp -v -o UserKnownHostsFile=/dev/null "
               "-o StrictHostKeyChecking=no "
               "-o PreferredAuthentications=password -r %s -P %s"
               " %s@\[%s\]:%s %s@\[%s\]:%s" %
               (limit, port, s_name, src, s_path, d_name, dst, d_path))
    password_list = []
    password_list.append(s_passwd)
    password_list.append(d_passwd)
    return remote_scp(command, password_list, log_filename, timeout)


def nc_copy_between_remotes(src, dst, s_port, s_passwd, d_passwd,
                            s_name, d_name, s_path, d_path,
                            c_type="ssh", c_prompt="\n",
                            d_port="8888", d_protocol="udp", timeout=10,
                            check_sum=True):
    """
    Copy files from guest to guest using netcat.

    This method only supports linux guest OS.

    :param src/dst: Hostname or IP address of src and dst
    :param s_name/d_name: Username (if required)
    :param s_passwd/d_passwd: Password (if required)
    :param s_path/d_path: Path on the remote machine where we are copying
    :param c_type: Login method to remote host(guest).
    :param c_prompt: command line prompt of remote host(guest)
    :param d_port:  the port data transfer
    :param d_protocol: nc protocol use (tcp or udp)
    :param timeout: If a connection and stdin are idle for more than timeout
                    seconds, then the connection is silently closed.

    :return: True on success and False on failure.
    """
    s_session = remote_login(c_type, src, s_port, s_name, s_passwd, c_prompt)
    d_session = remote_login(c_type, dst, s_port, d_name, d_passwd, c_prompt)

    s_session.cmd("iptables -I INPUT -p %s -j ACCEPT" % d_protocol)
    d_session.cmd("iptables -I OUTPUT -p %s -j ACCEPT" % d_protocol)

    logging.info("Transfer data using netcat from %s to %s" % (src, dst))
    cmd = "nc"
    if d_protocol == "udp":
        cmd += " -u"
        cmd += " -w %s" % timeout
    s_session.sendline("%s -l %s < %s" % (cmd, d_port, s_path))
    d_session.sendline("echo a | %s %s %s > %s" % (cmd, src, d_port, d_path))

    if check_sum:
        if (s_session.cmd("md5sum %s" % s_path).split()[0] !=
                d_session.cmd("md5sum %s" % d_path).split()[0]):
            return False
    return True


def udp_copy_between_remotes(src, dst, s_port, s_passwd, d_passwd,
                             s_name, d_name, s_path, d_path,
                             c_type="ssh", c_prompt="\n",
                             d_port="9000", timeout=600):
    """
    Copy files from guest to guest using udp.

    :param src/dst: Hostname or IP address of src and dst
    :param s_name/d_name: Username (if required)
    :param s_passwd/d_passwd: Password (if required)
    :param s_path/d_path: Path on the remote machine where we are copying
    :param c_type: Login method to remote host(guest).
    :param c_prompt: command line prompt of remote host(guest)
    :param d_port:  the port data transfer
    :param timeout: data transfer timeout
    """
    s_session = remote_login(c_type, src, s_port, s_name, s_passwd, c_prompt)
    d_session = remote_login(c_type, dst, s_port, d_name, d_passwd, c_prompt)

    def get_abs_path(session, filename, extension):
        """
        return file path drive+path
        """
        cmd_tmp = "wmic datafile where \"Filename='%s' and "
        cmd_tmp += "extension='%s'\" get drive^,path"
        cmd = cmd_tmp % (filename, extension)
        info = session.cmd_output(cmd, timeout=360).strip()
        drive_path = re.search(r'(\w):\s+(\S+)', info, re.M)
        if not drive_path:
            raise error.TestError("Not found file %s.%s in your guest"
                                  % (filename, extension))
        return ":".join(drive_path.groups())

    def get_file_md5(session, file_path):
        """
        Get files md5sums
        """
        if c_type == "ssh":
            md5_cmd = "md5sum %s" % file_path
            md5_reg = r"(\w+)\s+%s.*" % file_path
        else:
            drive_path = get_abs_path(session, "md5sums", "exe")
            filename = file_path.split("\\")[-1]
            md5_reg = r"%s\s+(\w+)" % filename
            md5_cmd = '%smd5sums.exe %s | find "%s"' % (drive_path, file_path,
                                                        filename)
        o = session.cmd_output(md5_cmd)
        file_md5 = re.findall(md5_reg, o)
        if not o:
            raise error.TestError("Get file %s md5sum error" % file_path)
        return file_md5

    def server_alive(session):
        if c_type == "ssh":
            check_cmd = "ps aux"
        else:
            check_cmd = "tasklist"
        o = session.cmd_output(check_cmd)
        if not o:
            raise error.TestError("Can not get the server status")
        if "sendfile" in o.lower():
            return True
        return False

    def start_server(session):
        if c_type == "ssh":
            start_cmd = "sendfile %s &" % d_port
        else:
            drive_path = get_abs_path(session, "sendfile", "exe")
            start_cmd = "start /b %ssendfile.exe %s" % (drive_path,
                                                        d_port)
        session.cmd_output_safe(start_cmd)
        if not server_alive(session):
            raise error.TestError("Start udt server failed")

    def start_client(session):
        if c_type == "ssh":
            client_cmd = "recvfile %s %s %s %s" % (src, d_port,
                                                   s_path, d_path)
        else:
            drive_path = get_abs_path(session, "recvfile", "exe")
            client_cmd_tmp = "%srecvfile.exe %s %s %s %s"
            client_cmd = client_cmd_tmp % (drive_path, src, d_port,
                                           s_path.split("\\")[-1],
                                           d_path.split("\\")[-1])
        session.cmd_output_safe(client_cmd, timeout)

    def stop_server(session):
        if c_type == "ssh":
            stop_cmd = "killall sendfile"
        else:
            stop_cmd = "taskkill /F /IM sendfile.exe"
        if server_alive(session):
            session.cmd_output_safe(stop_cmd)

    try:
        src_md5 = get_file_md5(s_session, s_path)
        if not server_alive(s_session):
            start_server(s_session)
        start_client(d_session)
        dst_md5 = get_file_md5(d_session, d_path)
        if src_md5 != dst_md5:
            err_msg = "Files md5sum mismatch, file %s md5sum is '%s', "
            err_msg = "but the file %s md5sum is %s"
            raise error.TestError(err_msg % (s_path, src_md5,
                                             d_path, dst_md5))
    finally:
        stop_server(s_session)
        s_session.close()
        d_session.close()


def copy_files_to(address, client, username, password, port, local_path,
                  remote_path, limit="", log_filename=None,
                  verbose=False, timeout=600, interface=None):
    """
    Copy files to a remote host (guest) using the selected client.

    :param client: Type of transfer client
    :param username: Username (if required)
    :param password: Password (if requried)
    :param local_path: Path on the local machine where we are copying from
    :param remote_path: Path on the remote machine where we are copying to
    :param address: Address of remote host(guest)
    :param limit: Speed limit of file transfer.
    :param log_filename: If specified, log all output to this file (SCP only)
    :param verbose: If True, log some stats using logging.debug (RSS only)
    :param timeout: The time duration (in seconds) to wait for the transfer to
            complete.
    :interface: The interface the neighbours attach to (only use when using ipv6
                linklocal address.)
    :raise: Whatever remote_scp() raises
    """
    if client == "scp":
        scp_to_remote(address, port, username, password, local_path,
                      remote_path, limit, log_filename, timeout,
                      interface=interface)
    elif client == "rss":
        log_func = None
        if verbose:
            log_func = logging.debug
        c = rss_client.FileUploadClient(address, port, log_func)
        c.upload(local_path, remote_path, timeout)
        c.close()
    else:
        raise error.TestError("No such file copy client: '%s', valid values"
                              "are scp and rss" % client)


def copy_files_from(address, client, username, password, port, remote_path,
                    local_path, limit="", log_filename=None,
                    verbose=False, timeout=600, interface=None):
    """
    Copy files from a remote host (guest) using the selected client.

    :param client: Type of transfer client
    :param username: Username (if required)
    :param password: Password (if requried)
    :param remote_path: Path on the remote machine where we are copying from
    :param local_path: Path on the local machine where we are copying to
    :param address: Address of remote host(guest)
    :param limit: Speed limit of file transfer.
    :param log_filename: If specified, log all output to this file (SCP only)
    :param verbose: If True, log some stats using ``logging.debug`` (RSS only)
    :param timeout: The time duration (in seconds) to wait for the transfer to
                    complete.
    :interface: The interface the neighbours attach to (only use when using ipv6
                linklocal address.)
    :raise: Whatever ``remote_scp()`` raises
    """
    if client == "scp":
        scp_from_remote(address, port, username, password, remote_path,
                        local_path, limit, log_filename, timeout,
                        interface=interface)
    elif client == "rss":
        log_func = None
        if verbose:
            log_func = logging.debug
        c = rss_client.FileDownloadClient(address, port, log_func)
        c.download(remote_path, local_path, timeout)
        c.close()
    else:
        raise error.TestError("No such file copy client: '%s', valid values"
                              "are scp and rss" % client)


class Remote_Package(object):

    def __init__(self, address, client, username, password, port, remote_path):
        """
        Initialization of Remote Package class.

        :param address: Address of remote host(guest)
        :param client: The client to use ('ssh', 'telnet' or 'nc')
        :param username: Username (if required)
        :param password: Password (if requried)
        :param port: Port to connect to
        :param remote_path: Rmote package path
        """
        self.address = address
        self.client = client
        self.port = port
        self.username = username
        self.password = password
        self.remote_path = remote_path

        if self.client == "nc":
            self.cp_client = "rss"
            self.cp_port = 10023
        elif self.client == "ssh":
            self.cp_client = "scp"
            self.cp_port = 22
        else:
            raise LoginBadClientError(client)

    def pull_file(self, local_path, timeout=600):
        """
        Copy file from remote to local.
        """
        logging.debug("Pull remote: '%s' to local: '%s'." % (self.remote_path,
                                                             local_path))
        copy_files_from(self.address, self.cp_client, self.username,
                        self.password, self.cp_port, self.remote_path,
                        local_path, timeout=timeout)

    def push_file(self, local_path, timeout=600):
        """
        Copy file from local to remote.
        """
        logging.debug("Push local: '%s' to remote: '%s'." % (local_path,
                                                             self.remote_path))
        copy_files_to(self.address, self.cp_client, self.username,
                      self.password, self.cp_port, local_path,
                      self.remote_path, timeout=timeout)


class RemoteFile(object):

    """
    Class to handle the operations of file on remote host or guest.
    """

    def __init__(self, address, client, username, password, port,
                 remote_path, limit="", log_filename=None,
                 verbose=False, timeout=600):
        """
        Initialization of RemoteFile class.

        :param address: Address of remote host(guest)
        :param client: Type of transfer client
        :param username: Username (if required)
        :param password: Password (if requried)
        :param remote_path: Path of file which we want to edit on remote.
        :param limit: Speed limit of file transfer.
        :param log_filename: If specified, log all output to this file(SCP only)
        :param verbose: If True, log some stats using logging.debug (RSS only)
        :param timeout: The time duration (in seconds) to wait for the
                        transfer tocomplete.
        """
        self.address = address
        self.client = client
        self.username = username
        self.password = password
        self.port = port
        self.remote_path = remote_path
        self.limit = limit
        self.log_filename = log_filename
        self.verbose = verbose
        self.timeout = timeout

        # Get a local_path and all actions is taken on it.
        filename = os.path.basename(self.remote_path)

        # Get a local_path.
        tmp_dir = data_dir.get_tmp_dir()
        local_file = tempfile.NamedTemporaryFile(prefix=("%s_" % filename),
                                                 dir=tmp_dir)
        self.local_path = local_file.name
        local_file.close()

        # Get a backup_path.
        backup_file = tempfile.NamedTemporaryFile(prefix=("%s_" % filename),
                                                  dir=tmp_dir)
        self.backup_path = backup_file.name
        backup_file.close()

        # Get file from remote.
        self._pull_file()
        # Save a backup.
        shutil.copy(self.local_path, self.backup_path)

    def __del__(self):
        """
        Called when the instance is about to be destroyed.
        """
        self._reset_file()
        if os.path.exists(self.backup_path):
            os.remove(self.backup_path)
        if os.path.exists(self.local_path):
            os.remove(self.local_path)

    def _pull_file(self):
        """
        Copy file from remote to local.
        """
        if self.client == "test":
            shutil.copy(self.remote_path, self.local_path)
        else:
            copy_files_from(self.address, self.client, self.username,
                            self.password, self.port, self.remote_path,
                            self.local_path, self.limit, self.log_filename,
                            self.verbose, self.timeout)

    def _push_file(self):
        """
        Copy file from local to remote.
        """
        if self.client == "test":
            shutil.copy(self.local_path, self.remote_path)
        else:
            copy_files_to(self.address, self.client, self.username,
                          self.password, self.port, self.local_path,
                          self.remote_path, self.limit, self.log_filename,
                          self.verbose, self.timeout)

    def _reset_file(self):
        """
        Copy backup from local to remote.
        """
        if self.client == "test":
            shutil.copy(self.backup_path, self.remote_path)
        else:
            copy_files_to(self.address, self.client, self.username,
                          self.password, self.port, self.backup_path,
                          self.remote_path, self.limit, self.log_filename,
                          self.verbose, self.timeout)

    def _read_local(self):
        """
        Read file on local_path.

        :return: string list got from readlines().
        """
        local_file = open(self.local_path, "r")
        lines = local_file.readlines()
        local_file.close()
        return lines

    def _write_local(self, lines):
        """
        Write file on local_path. Call writelines method of File.
        """
        local_file = open(self.local_path, "w")
        local_file.writelines(lines)
        local_file.close()

    def add(self, line_list):
        """
        Append lines in line_list into file on remote.
        """
        lines = self._read_local()
        for line in line_list:
            lines.append("\n%s" % line)
        self._write_local(lines)
        self._push_file()

    def sub(self, pattern2repl_dict):
        """
        Replace the string which match the pattern
        to the value contained in pattern2repl_dict.
        """
        lines = self._read_local()
        for pattern, repl in pattern2repl_dict.items():
            for index in range(len(lines)):
                line = lines[index]
                lines[index] = re.sub(pattern, repl, line)
        self._write_local(lines)
        self._push_file()

    def remove(self, pattern_list):
        """
        Remove the lines in remote file which matchs a pattern
        in pattern_list.
        """
        lines = self._read_local()
        for pattern in pattern_list:
            for index in range(len(lines)):
                line = lines[index]
                if re.match(pattern, line):
                    lines.remove(line)
                    # Check this line is the last one or not.
                    if (not line.endswith('\n') and (index > 0)):
                        lines[index - 1] = lines[index - 1].rstrip("\n")
        self._write_local(lines)
        self._push_file()

    def sub_else_add(self, pattern2repl_dict):
        """
        Replace the string which match the pattern.
        If no match in the all lines, append the value
        to the end of file.
        """
        lines = self._read_local()
        for pattern, repl in pattern2repl_dict.items():
            no_line_match = True
            for index in range(len(lines)):
                line = lines[index]
                if re.match(pattern, line):
                    no_line_match = False
                    lines[index] = re.sub(pattern, repl, line)
            if no_line_match:
                lines.append("\n%s" % repl)
        self._write_local(lines)
        self._push_file()


class RemoteRunner(object):

    """
    Class to provide a utils.run-like method to execute command on
    remote host or guest. Provide a similar interface with utils.run
    on local.
    """

    def __init__(self, client="ssh", host=None, port="22", username="root",
                 password=None, prompt=r"[\#\$]\s*$", linesep="\n",
                 log_filename=None, timeout=240, internal_timeout=10,
                 session=None):
        """
        Initialization of RemoteRunner. Init a session login to remote host or
        guest.

        :param client: The client to use ('ssh', 'telnet' or 'nc')
        :param host: Hostname or IP address
        :param port: Port to connect to
        :param username: Username (if required)
        :param password: Password (if required)
        :param prompt: Shell prompt (regular expression)
        :param linesep: The line separator to use when sending lines
                (e.g. '\\n' or '\\r\\n')
        :param log_filename: If specified, log all output to this file
        :param timeout: Total time duration to wait for a successful login
        :param internal_timeout: The maximal time duration (in seconds) to wait
                for each step of the login procedure (e.g. the "Are you sure"
                prompt or the password prompt)
        :param session: An existing session
        :see: wait_for_login()
        :raise: Whatever wait_for_login() raises
        """
        if session is None:
            if host is None:
                raise error.TestError("Neither host, nor session was defined!")
            self.session = wait_for_login(client, host, port, username,
                                          password, prompt, linesep,
                                          log_filename, timeout,
                                          internal_timeout)
        else:
            self.session = session
        # Init stdout pipe and stderr pipe.
        self.stdout_pipe = tempfile.mktemp()
        self.stderr_pipe = tempfile.mktemp()

    def run(self, command, timeout=60, ignore_status=False):
        """
        Method to provide a utils.run-like interface to execute command on
        remote host or guest.

        :param timeout: Total time duration to wait for command return.
        :param ignore_status: If ignore_status=True, do not raise an exception,
                              no matter what the exit code of the command is.
                              Else, raise CmdError if exit code of command is not
                              zero.
        """
        # Redirect the stdout and stderr to file, Deviding error message
        # from output, and taking off the color of output. To return the same
        # result with utils.run() function.
        command = "%s 1>%s 2>%s" % (command, self.stdout_pipe, self.stderr_pipe)
        status, _ = self.session.cmd_status_output(command, timeout=timeout)
        output = self.session.cmd_output("cat %s;rm -f %s" %
                                         (self.stdout_pipe, self.stdout_pipe))
        errput = self.session.cmd_output("cat %s;rm -f %s" %
                                         (self.stderr_pipe, self.stderr_pipe))
        cmd_result = utils.CmdResult(command=command, exit_status=status,
                                     stdout=output, stderr=errput)
        if (status and (not ignore_status)):
            raise error.CmdError(command, cmd_result)
        return cmd_result

########NEW FILE########
__FILENAME__ = remote_build
import os
import re
from autotest.client import utils
import remote
import aexpect
import data_dir
import hashlib
import logging


class BuildError(Exception):

    def __init__(self, error_info):
        super(BuildError, self).__init__(error_info)
        self.error_info = error_info

    def __str__(self):
        e_msg = "Build Error: %s" % self.error_info
        return e_msg


class Builder(object):

    def __init__(self, params, address, source, shell_client=None,
                 shell_port=None, file_transfer_client=None,
                 file_transfer_port=None, username=None, password=None,
                 make_flags="", build_dir=None, build_dir_prefix=None,
                 shell_linesep=None, shell_prompt=None):
        """
        :param params: Dictionary with test parameters, used to get the default
                       values of all named parameters.
        :param address: Remote host or guest address
        :param source: Directory containing the source on the machine
                       where this script is running
        :param shell_client: The client to use ('ssh', 'telnet' or 'nc')
        :param shell_port: Port to connect to for the shell client
        :param file_transfer_client: The file transfer client to use ('scp' or
                                     'rss')
        :param file_transfer_port: Port to connect to for the file transfer
                                   client
        :param username: Username (if required)
        :param password: Password (if required)
        :param make_flags: Flags to pass to the make process, default: ""
        :param build_dir: Where to copy and build the files on target. If None,
                          use params['tmp_dir']
        :param build_dir_prefix: What to name the build directory on target
                                 If None, use the name of the source directory.
        :param shell_linesep: Line separator in the shell
        :param shell_prompt: Regexp that matches the prompt in the shell.
        """

        def full_build_path(build_dir, directory_prefix, make_flags):
            """
            Generates the full path for the build using the make flags and
            supplied build location.
            :return: The full path as a string
            """
            extra_flags_hash = hashlib.sha1()
            extra_flags_hash.update(make_flags)
            directory_name = "%s-%s" % (directory_prefix,
                                        (extra_flags_hash.hexdigest())[:8])
            return os.path.join(build_dir, directory_name)

        def def_helper(arg, param, default):
            if arg is None:
                return params.get(param, default)
            else:
                return arg

        self.address = address
        self.source = os.path.normpath(source)
        self.client = def_helper(shell_client, "shell_client", "ssh")
        self.port = def_helper(shell_port, "shell_port", "22")
        self.file_transfer_client = def_helper(file_transfer_client,
                                               "file_transfer_client", "scp")
        self.file_transfer_port = def_helper(file_transfer_port,
                                             "file_transfer_port", "22")
        self.username = def_helper(username, "username", "root")
        self.password = def_helper(password, "password", "redhat")
        self.make_flags = make_flags
        self.build_dir = def_helper(build_dir, "tmp_dir", "/tmp")
        if build_dir_prefix is None:
            build_dir_prefix = os.path.basename(source)
        self.full_build_path = full_build_path(self.build_dir,
                                               build_dir_prefix, make_flags)
        self.linesep = def_helper(shell_linesep, "shell_linesep", "\n")
        self.prompt = def_helper(shell_prompt, "shell_prompt",
                                 "^\[.*\][\#\$]\s*)$")

        self.session = remote.remote_login(self.client, self.address,
                                           self.port, self.username,
                                           self.password, self.prompt,
                                           self.linesep, timeout=360)

    def sync_directories(self):
        """
        Synchronize the directories between the local and remote machines
        :returns: True if any files needed to be copied; False otherwise. Does
        not support symlinks.
        """

        def get_local_hashes(path):
            """
            Create a dict of the hashes of all files in path on the local
            machine.
            :param path: Path to search
            """
            def hash_file(file_name):
                """
                Calculate hex-encoded hash of a file
                :param file_name: File to hash
                """
                f = open(file_name, mode='rb')
                h = hashlib.sha1()
                while True:
                    buf = f.read(4096)
                    if not buf:
                        break
                    h.update(buf)
                return h.hexdigest()

            def visit(arg, dir_name, file_names):
                """
                Callback function to calculate and store hashes
                :param arg: Tuple with base path and the hash that will contain
                            the results.
                :param dir_name: Current directory
                :param file_names: File names in the current directory
                """
                (base_path, result) = arg
                for file_name in file_names:
                    path = os.path.join(dir_name, file_name)
                    if os.path.isfile(path):
                        result[os.path.relpath(path, base_path)] = hash_file(path)

            result = {}
            os.path.walk(path, visit, (path, result))

            return result

        def get_remote_hashes(path, session, linesep):
            """
            Create a dict of the hashes of all files in path on the remote
            machine.
            :param path: Path to search
            :param session: Session object to use
            :param linesep: Line separation string for the remote system
            """

            cmd = 'test \! -d %s || find %s -type f | xargs sha1sum' % (path,
                                                                        path)
            status, output = session.cmd_status_output(cmd)
            if not status == 0:
                raise BuildError("Unable to get hashes of remote files: '%s'"
                                 % output)
            result = {}
            # Output is "<sum>  <filename><linesep><sum>  <filename>..."
            for line in output.split(linesep):
                if re.match("^[a-f0-9]{32,}  [^ ].*$", line):
                    (h, f) = line.split(None, 1)
                    result[os.path.relpath(f, path)] = h

            return result

        def list_recursive_dirnames(path):
            """
            List all directories that exist in path on the local machine
            :param path: Path to search
            """
            def visit(arg, dir_name, file_names):
                """
                Callback function list alla directories
                :param arg: Tuple with base path and the list that will contain
                            the results.
                :param dir_name: Current directory
                :param file_names: File names in the current directory
                """
                (base_path, result) = arg
                for file_name in file_names:
                    path = os.path.join(dir_name, file_name)
                    if os.path.isdir(path):
                        result.append(os.path.relpath(path, base_path))

            result = []
            os.path.walk(path, visit, (path, result))

            return result

        remote_hashes = get_remote_hashes(self.full_build_path, self.session,
                                          self.linesep)
        local_hashes = get_local_hashes(self.source)

        to_transfer = []
        for rel_path in local_hashes.keys():
            rhash = remote_hashes.get(rel_path)
            if rhash is None or not rhash == local_hashes[rel_path]:
                to_transfer.append(rel_path)

        need_build = False
        if to_transfer:
            logging.info("Need to copy files to %s on target" %
                         self.full_build_path)
            need_build = True

            # Create all directories
            dirs = list_recursive_dirnames(self.source)
            if dirs:
                dirs_text = " ".join(dirs)
                fmt_arg = (self.full_build_path, self.full_build_path,
                           dirs_text)
                cmd = 'mkdir -p %s && cd %s && mkdir -p %s' % fmt_arg
            else:
                cmd = 'mkdir -p %s' % self.full_build_path
            status, output = self.session.cmd_status_output(cmd)
            if not status == 0:
                raise BuildError("Unable to create remote directories: '%s'"
                                 % output)

            # Copy files
            for file_name in to_transfer:
                local_path = os.path.join(self.source, file_name)
                remote_path = os.path.join(self.full_build_path, file_name)
                remote.copy_files_to(self.address, self.file_transfer_client,
                                     self.username, self.password,
                                     self.file_transfer_port, local_path,
                                     remote_path)

        else:
            logging.info("Directory %s on target already up-to-date" %
                         self.full_build_path)

        return need_build

    def make(self):
        """
        Execute make on the remote system
        """
        logging.info("Building in %s on target" % self.full_build_path)
        cmd = 'make -C %s %s' % (self.full_build_path, self.make_flags)
        status, output = self.session.cmd_status_output(cmd)
        if not status == 0:
            raise BuildError("Unable to make: '%s'" % output)

    def build(self):
        """
        Synchronize all files and execute 'make' on the remote system if
        needed.
        :returns: The path to the build directory on the remote machine
        """
        if self.sync_directories():
            self.make()

        return self.full_build_path

########NEW FILE########
__FILENAME__ = messenger
#!/usr/bin/env python

'''
Created on Dec 6, 2013

:author: jzupka
'''

import os
import logging
import select
import cPickle
import time
import remote_interface
import cStringIO
import base64


class IOWrapper(object):

    """
    Class encaptulates io opearation to be more consist in different
    implementations. (stdio, sockets, etc..)
    """

    def __init__(self, obj):
        """
        :param obj: IO obj for example file decriptor.
        """
        self._obj = obj

    def close(self):
        raise NotImplementedError()

    def read(self, max_len, timeout=None):
        """
        Read function should be reinmplemented as blocking reading from data
        source when timeout is None and nonblocking for timeout is not None.
        Implementation example StdIWrapper.

        :params max_len: Max len of readed data.
        :type max_len: int
        :param timeout: Timeout of reading operation.
        :type timeout: float
        :return: Readed data.
        """
        raise NotImplementedError()

    def write(self, data):
        """
        Write funciton should be implemented for object uded for writing.

        :param data: Data to write.
        :type data: str.
        """
        raise NotImplementedError()

    def fileno(self):
        """
        Function should return file descriptor number. If object should be used
        for standard io operation.

        :return: File number.
        """
        raise NotImplementedError()

    def _wait_for_data(self, max_len, timeout):
        """
        Wait for data for time == timeout.

        :params max_len: Max len of readed data.
        :type max_len: int
        :param timeout: Timeout of reading operation.
        :type timeout: float
        :return: Readed data.
        """
        r, _, _ = select.select([self.fileno()], [], [], timeout)
        if r:
            return self.read(max_len, None)
        return None


class DataWrapper(object):

    """
    Basic implementation of IOWrapper for stdio.
    """

    def decode(self, data):
        """
        Decodes the data which was read.

        :return: decoded data.
        """
        return data

    def encode(self, data):
        """
        Encode data.

        :return: encoded data.
        """
        return data


class DataWrapperBase64(DataWrapper):

    """
    Basic implementation of IOWrapper for stdio.
    """

    def decode(self, data):
        return base64.b64decode(data)

    def encode(self, data):
        return base64.b64encode(data)


class StdIOWrapper(IOWrapper, DataWrapper):

    """
    Basic implementation of IOWrapper for stdio.
    """

    def close(self):
        os.close(self._obj)

    def fileno(self):
        return self._obj


class StdIOWrapperIn(StdIOWrapper):

    """
    Basic implementation of IOWrapper for stdin
    """

    def read(self, max_len, timeout=None):
        if timeout is not None:
            return self._wait_for_data(max_len, timeout)
        else:
            return os.read(self._obj, max_len)


class StdIOWrapperOut(StdIOWrapper):

    """
    Basic implementation of IOWrapper for stdout
    """

    def write(self, data):
        os.write(self._obj, data)


class StdIOWrapperInBase64(StdIOWrapperIn, DataWrapperBase64):

    """
    Basic implementation of IOWrapper for stdin
    """


class StdIOWrapperOutBase64(StdIOWrapperOut, DataWrapperBase64):

    """
    Basic implementation of IOWrapper for stdout
    """


class MessengerError(Exception):

    def __init__(self, msg):
        super(MessengerError, self).__init__(msg)
        self.msg = msg

    def __str__(self):
        return "Messenger ERROR %s" % (self.msg)


def _map_path(mod_name, kls_name):
    if mod_name.endswith('remote_interface'):  # catch all old module names
        mod = remote_interface
        return getattr(mod, kls_name)
    else:
        mod = __import__(mod_name)
        return getattr(mod, kls_name)


class Messenger(object):

    """
    Class could be used for communication between two python process connected
    by communication canal wrapped by IOWrapper class. Pickling is used
    for communication and thus it is possible to communicate every picleable
    object.
    """

    def __init__(self, stdin, stdout):
        """
        :params stdin: Object for read data from communication interface.
        :type stdin: IOWrapper
        :params stdout: Object for write data to communication interface.
        :type stdout: IOWrapper
        """
        self.stdin = stdin
        self.stdout = stdout

        # Unfortunately only static length of data length is supported.
        self.enc_len_length = len(stdout.encode("0" * 10))

    def close(self):
        self.stdin.close()
        self.stdout.close()

    def format_msg(self, data):
        """
        Format message where first 10 char is length of message and rest is
        piclked message.
        """
        pdata = cPickle.dumps(data, cPickle.HIGHEST_PROTOCOL)
        pdata = self.stdout.encode(pdata)
        len_enc = self.stdout.encode("%10d" % len(pdata))
        return "%s%s" % (len_enc, pdata)

    def flush_stdin(self):
        """
        Flush all input data from communication interface.
        """
        const = 16384
        r, _, _ = select.select([self.stdin.fileno()], [], [], 1)
        while r:
            if len(self.stdin.read(const)) < const:
                break
            r, _, _ = select.select([self.stdin.fileno()], [], [], 1)

    def write_msg(self, data):
        """
        Write formated message to communication interface.
        """
        self.stdout.write(self.format_msg(data))

    def _read_until_len(self, timeout=None):
        """
        Deal with terminal interfaces... Read input until gets string
        contains " " and digits len(string) == 10

        :param timeout: timeout of reading.
        """
        data = ""

        endtime = None
        if timeout is not None:
            endtime = time.time() + timeout

        while (len(data) < self.enc_len_length and
               (endtime is None or time.time() < endtime)):
            d = self.stdin.read(1, timeout)
            if d is None:
                return None
            if len(d) == 0:
                return d
            data += d
        if len(data) < self.enc_len_length:
            return None

        return self.stdout.decode(data)

    def read_msg(self, timeout=None):
        """
        Read data from com interface.

        :param timeout: timeout for reading data.
        :type timeout: float
        :return: (True, data) when reading is successful.
                 (False, None) when other side is closed.
                 (None, None) when reading is timeouted.
        """
        data = self._read_until_len(timeout)
        if data is None:
            return (None, None)
        if len(data) == 0:
            return (False, None)
        rdata = None
        try:
            cmd_len = int(data)
            rdata = ""
            rdata_len = 0
            while (rdata_len < cmd_len):
                rdata += self.stdin.read(cmd_len - rdata_len)
                rdata_len = len(rdata)
            rdataIO = cStringIO.StringIO(self.stdin.decode(rdata))
            unp = cPickle.Unpickler(rdataIO)
            unp.find_global = _map_path
            data = unp.load()
        except Exception, e:
            logging.error("ERROR data:%s rdata:%s" % (data, rdata))
            try:
                self.write_msg(remote_interface.MessengerError("Communication "
                                                               "failed.%s" % (e)))
            except OSError:
                pass
            self.flush_stdin()
            raise
        # Debugging commands.
        # if (isinstance(data, remote_interface.BaseCmd)):
        #    print data.func
        return (True, data)

########NEW FILE########
__FILENAME__ = remote_interface
'''
Created on Dec 11, 2013

:author: jzupka
'''
import copy


class MessengerError(Exception):

    """
    Represented error in messanger.
    """

    def __init__(self, msg):
        super(MessengerError, self).__init__(msg)
        self.msg = msg

    def __str__(self):
        return "Messenger ERROR %s" % (self.msg)


class CommanderError(MessengerError):

    """
    Represent error in Commnader
    """

    def __init__(self, msg):
        super(CommanderError, self).__init__(msg)

    def __str__(self):
        return "Commander ERROR %s" % (self.msg)


class CmdTraceBack(Exception):

    """
    Represent back-trace used for error tracing on remote side.
    """

    def __init__(self, msg):
        super(CmdTraceBack, self).__init__(msg)
        self.msg = msg

    def __str__(self):
        return "Cmd ERROR %s" % (self.msg)


class CmdMessage(object):

    """
    Base cmd message class
    """
    __slots__ = ["cmd_id"]

    def __init__(self, cmd_id):
        self.cmd_id = cmd_id

    def __getstate__(self):
        return (self.cmd_id)

    def __setstate__(self, state):
        self.cmd_id = state[0]

    def isCmdMsg(self):
        return self.cmd_id is not None

    def __eq__(self, other):
        return self.cmd_id == other.cmd_id


class StdStream(CmdMessage):

    """
    Represent message string data from remote client
    """
    __slots__ = ["msg"]

    def __init__(self, msg, cmd_id=None):
        super(StdStream, self).__init__(cmd_id)
        self.msg = msg

    def __str__(self):
        return (self.msg)

    def __getstate__(self):
        return (self.cmd_id, self.msg)

    def __setstate__(self, state):
        self.cmd_id = state[0]
        self.msg = state[1]


class StdOut(StdStream):

    """
    Represent message from stdout string data from remote client
    """
    __slots__ = []

    def __init__(self, msg, cmd_id=None):
        super(StdOut, self).__init__(msg, cmd_id)

    def __getstate__(self):
        return (self.cmd_id, self.msg)

    def __setstate__(self, state):
        self.cmd_id = state[0]
        self.msg = state[1]


class StdErr(StdStream):

    """
    Represent message from stderr string data from remote client
    """
    __slots__ = []

    def __init__(self, msg, cmd_id=None):
        super(StdErr, self).__init__(msg, cmd_id)

    def __getstate__(self):
        return (self.cmd_id, self.msg)

    def __setstate__(self, state):
        self.cmd_id = state[0]
        self.msg = state[1]


class BaseCmd(CmdMessage):

    """
    Class used for moveing information about commands between master and slave.
    """
    __slots__ = ["func", "args", "kargs", "results", "_async", "_finished",
                 "nh_stdin", "nh_stdout", "nh_stderr", "cmd_hash"]

    single_cmd_id = 0

    def __init__(self, func_cmd, *args, **kargs):
        self.cmd_id = BaseCmd.single_cmd_id
        BaseCmd.single_cmd_id += 1
        super(BaseCmd, self).__init__(self.cmd_id)

        self.func = func_cmd
        self.args = copy.deepcopy(args)
        self.kargs = copy.deepcopy(kargs)
        self.results = None
        self._async = False
        self._finished = False
        self.nh_stdin = None
        self.nh_stdout = None
        self.nh_stderr = None
        self.cmd_hash = None

    def __getstate__(self):
        return (self.cmd_id, self.func, self.args, self.kargs, self.results,
                self._async, self._finished, self.nh_stdin, self.nh_stdout,
                self.nh_stderr, self.cmd_hash)

    def __setstate__(self, state):
        self.cmd_id = state[0]
        self.func = state[1]
        self.args = state[2]
        self.kargs = state[3]
        self.results = state[4]
        self._async = state[5]
        self._finished = state[6]
        self.nh_stdin = state[7]
        self.nh_stdout = state[8]
        self.nh_stderr = state[9]
        self.cmd_hash = state[10]

    def __str__(self):
        str_args = []
        for a in self.args:  # Format str value in args to "val"
            if type(a) is str:
                str_args.append("\"%s\"" % a)
            else:
                str_args.append(a)

        str_kargs = {}
        for key, val in self.kargs:   # Format str value in kargs to "val"
            if type(val) is str:
                str_kargs[key] = "\"%s\"" % val
            else:
                str_kargs[key] = val

        return ("base_cmd: %s(%s)" % (".".join(self.func),
                                      ", ".join(str_args) +
                                      ",".join(str_kargs.items())))

    def is_async(self):
        """
        :return: True if command is async else False
        """
        return self._async

    def is_finished(self):
        """
        :return: True if command is finished else False
        """
        return self._finished

    def update(self, basecmd):
        """
        Sync local class with class moved over the messanger.

        :param basecmd: basecmd from which should be sync data to this instance
        :type basecmd: BaseCmd
        """
        self.results = basecmd.results
        self._finished = basecmd._finished
        self._async = basecmd._async

    def update_cmd_hash(self, basecmd):
        if basecmd.cmd_hash is not None:
            self.cmd_hash = basecmd.cmd_hash

########NEW FILE########
__FILENAME__ = remote_master
#!/usr/bin/env python

'''
Created on Dec 6, 2013

:author: jzupka
'''
import sys
import time
import inspect
import remote_interface
import messenger


def getsource(obj):
    return inspect.getsource(obj)


def wait_timeout(timeout):
    if timeout is None:
        while 1:
            yield True
    else:
        end_time = time.time() + timeout
        while time.time() < end_time:
            yield True


class CmdMaster(object):

    """
    Representation of BaseCmd on master side.
    """

    def __init__(self, commander, name, *args, **kargs):
        """
        :params commander: Commander from which was command started.
        :params name: Name parsed to string representation
        :type name: [str, str, str]
        :parmas args: list to arguments to cmd.
        :type args: []
        :params kargs: {}
        """
        self._basecmd = remote_interface.BaseCmd(name, *args, **kargs)
        self.commander = commander
        self._stdout = ""
        self._stderr = ""
        self._results_cnt = 0
        self._stdout_cnt = 0
        self._stderr_cnt = 0

    def getbasecmd(self):
        """
        Property basecmd getter
        """
        self._results_cnt = 0
        return self._basecmd

    def setbasecmd(self, value):
        """
        Property basecmd setter _resuls_cnt identify if value was change from
        last reading.
        """

        self._basecmd = value
        self._results_cnt += 1

    basecmd = property(getbasecmd, setbasecmd)

    def getstdout(self):
        """
        Property stdout getter
        """
        self._stdout_cnt = 0
        return self._stdout

    def setstdout(self, value):
        """
        Property stdout setter _stdout_cnt identify if value was change from
        last reading.
        """
        self._stdout = value
        self._stdout_cnt += 1

    stdout = property(getstdout, setstdout)

    def getstderr(self):
        """
        Property stderr getter
        """
        self._stderr_cnt = 0
        return self._stderr

    def setstderr(self, value):
        """
        Property stderr setter _stderr_cnt identify if value was change from
        last reading.
        """
        self._stderr = value
        self._stderr_cnt += 1

    stderr = property(getstderr, setstderr)

    def send_stdin(self, msg):
        """
        Send data to stdin
        """
        self.commander.manage.send_msg(msg, self.basecmd.cmd_id)

    def wait(self):
        """
        Wait until command return results.
        """
        return self.commander.wait(self)

    def wait_response(self, timeout=None):
        """
        Wait until command return any cmd.
        """
        self.commander.wait_response(self, timeout)

    def __getattr__(self, name):
        """
        Shortcut to encapsulated basecmd.
        """
        if name in ["__getstate__", "__setstate__", "__slots__"]:
            raise AttributeError()
        return getattr(self.basecmd, name)

    def set_commander(self, commander):
        """
        For nohup commands it allows connect cmd to new created commander.
        """
        self.commander = commander
        if self not in commander.cmds:
            commander.cmds[self.cmd_id] = self
        self.commander.manage.register_cmd(self.basecmd,
                                           remote_interface.BaseCmd.single_cmd_id)


class CmdEncapsulation(object):

    """
    Class parse command name   cmd.nohup.shell -> ["nohup", "shell"]
    """

    def __init__(self, master, obj_name, name):
        self.master = master
        if obj_name is None:
            self.name = [name]
        else:
            self.name = obj_name + [name]
        self.cmd = None

    def __getattr__(self, name):
        return CmdEncapsulation(self.master, self.name, name)

    def __call__(self, *args, **kargs):
        """
        Call commander with specific command.
        """
        self.cmd = CmdMaster(self.master, self.name, *args, **kargs)
        return self.master.cmd(self.cmd)


class CmdTimeout(remote_interface.MessengerError):

    """
    Raised when waiting for cmd exceeds time define by timeout.
    """

    def __init__(self, msg):
        super(CmdTimeout, self).__init__(msg)

    def __str__(self):
        return "Commander Timeout %s" % (self.msg)


class Commander(object):

    """
    Commander representation for transfer over network.
    """
    __slots__ = []


class CommanderMaster(messenger.Messenger):

    """
    Class commander master is responsible for communication with commander
    slave. It invoke commands to slave part and receive messages from them.
    For communication is used only stdin and stdout which are streams from
    slave part.
    """

    def __init__(self, stdin, stdout, debug=False):
        """
        :type stdin: IOWrapper with implemented write function.
        :type stout: IOWrapper with implemented read function.
        """
        super(CommanderMaster, self).__init__(stdin, stdout)
        self.cmds = {}
        self.debug = debug

        self.flush_stdin()
        self.write_msg("start")
        succ, msg = self.read_msg()
        if not succ or msg != "Started":
            raise remote_interface.CommanderError("Remote commander"
                                                  " not started.")

    def close(self):
        try:
            self.manage.exit()
        except Exception:
            pass
        super(CommanderMaster, self).close()

    def __getattr__(self, name):
        """
        Start parsing unknown attribute in cmd.
        """
        if name in ["__getstate__", "__setstate__", "__slots__"]:
            raise AttributeError()
        return CmdEncapsulation(self, None, name)

    def __deepcopy__(self, memo):
        """
        Replace deepcopy by substituting by network Commander version.
        """
        result = Commander.__new__(Commander)
        memo[id(self)] = result
        return result

    def listen_streams(self, cmd):
        """
        Listen on all streams included in Commander commands.
        """
        if isinstance(cmd, remote_interface.StdStream):
            if (self.debug):
                print cmd.msg
            if cmd.isCmdMsg():
                if isinstance(cmd, remote_interface.StdOut):
                    self.cmds[cmd.cmd_id].stdout += cmd.msg
                elif isinstance(cmd, remote_interface.StdErr):
                    self.cmds[cmd.cmd_id].stderr += cmd.msg
            else:
                if isinstance(cmd, remote_interface.StdOut):
                    sys.stdout.write(cmd.msg)
                elif isinstance(cmd, remote_interface.StdErr):
                    sys.stderr.write(cmd.msg)

    def listen_errors(self, cmd):
        """
        Listen for errors raised from slave part of commander.
        """
        if isinstance(cmd, (Exception, remote_interface.CommanderError,
                            remote_interface.MessengerError)):
            raise cmd

    def listen_cmds(self, cmd):
        """
        Manage basecmds from slave side.
        """
        if isinstance(cmd, remote_interface.BaseCmd):
            if (self.debug):
                print cmd.func, cmd.results, cmd._finished

            if isinstance(cmd.results, Exception):
                raise cmd.results
            if cmd.cmd_id in self.cmds:
                self.cmds[cmd.cmd_id].basecmd.update(cmd)
                self.cmds[cmd.cmd_id].basecmd.update_cmd_hash(cmd)

    def listen_messenger(self, timeout=60):
        """
        Wait for msg from slave side and take care about them.
        """
        succ, r_cmd = self.read_msg(timeout)
        if succ is None:
            return r_cmd
        if not succ:
            raise remote_interface.CommanderError("Remote process died.")

        self.listen_errors(r_cmd)
        self.listen_streams(r_cmd)
        self.listen_cmds(r_cmd)
        return r_cmd

    def cmd(self, cmd, timeout=60):
        """
        Invoke command on client side.
        """
        self.cmds[cmd.basecmd.cmd_id] = cmd
        self.write_msg(cmd.basecmd)
        while (1):
            if cmd.basecmd.func[0] not in ["async", "nohup"]:
                # If not async wait for finish.
                self.wait(cmd, timeout)
            else:
                ancmd = self.wait_response(cmd, timeout)
                cmd.update_cmd_hash(ancmd)
            return cmd

    def wait(self, cmd, timeout=60):
        """
        Wait until command return results.
        """
        if cmd.cmd_id not in self.cmds:
            return cmd
        m_cmd = self.cmds[cmd.cmd_id]
        if m_cmd.is_finished():
            return m_cmd

        r_cmd = None

        time_step = None
        if timeout is not None:
            time_step = timeout / 10.0
        w = wait_timeout(timeout)
        for _ in w:
            r_cmd = self.listen_messenger(time_step)
            if isinstance(r_cmd, remote_interface.BaseCmd):
                if (self.debug):
                    print m_cmd._stdout
                if r_cmd is not None and r_cmd == m_cmd.basecmd:
                    # If command which we waiting for.
                    if r_cmd.is_finished():
                        del self.cmds[m_cmd.basecmd.cmd_id]
                        m_cmd.basecmd.update(r_cmd)
                        return m_cmd
                    m_cmd.basecmd.update(r_cmd)
                    m_cmd.basecmd.update_cmd_hash(r_cmd)

        if r_cmd is None:
            raise CmdTimeout("%ss during %s" % (timeout, str(cmd)))

    def wait_response(self, cmd, timeout=60):
        """
        Wait until command return any cmd.
        """
        if cmd.cmd_id not in self.cmds:
            return cmd
        if cmd.is_finished() or cmd._stdout_cnt or cmd._stderr_cnt:
            return cmd
        m_cmd = self.cmds[cmd.cmd_id]

        r_cmd = None

        time_step = None
        if timeout is not None:
            time_step = timeout / 10.0
        w = wait_timeout(timeout)
        while (w.next()):
            r_cmd = self.listen_messenger(time_step)
            if r_cmd is not None and r_cmd == m_cmd.basecmd:
                return m_cmd

        if r_cmd is None:
            raise CmdTimeout(timeout)

########NEW FILE########
__FILENAME__ = remote_runner
#!/usr/bin/env python

'''
Created on Dec 6, 2013

:author: jzupka
'''

import os
import sys
import select
import time
import stat
import gc
import logging
import traceback
import subprocess
import string
import random
import shutil
import signal

import remote_interface
import messenger as ms


def daemonize(pipe_root_path="/tmp"):
    """
    Init daemon.

    :param pipe_root_path: path to directory for pipe.
    :return: [True if child, stdin_path, stdou_path, stderr_path]
    """
    def is_file_open(path):
        """
        Determine process which open file.

        :param path: Path to file.
        :return: [[pid,mode], ... ].
        """
        opens = []
        pids = os.listdir('/proc')
        for pid in sorted(pids):
            try:
                int(pid)
            except ValueError:
                continue
            fd_dir = os.path.join('/proc', pid, 'fd')
            try:
                for filepath in os.listdir(fd_dir):
                    try:
                        p = os.path.join(fd_dir, filepath)
                        link = os.readlink(os.path.join(fd_dir, filepath))
                        if link == path:
                            mode = os.lstat(p).st_mode
                            opens.append([pid, mode])
                    except OSError:
                        continue
            except OSError, e:
                if e.errno == 2:
                    continue
                raise
        return opens

    def daemonize():
        """
        Run guest as a daemon.
        """
        gc_was_enabled = gc.isenabled()
        # Disable gc to avoid bug where gc -> file_dealloc ->
        # write to stderr -> hang.  http://bugs.python.org/issue1336
        gc.disable()
        try:
            pid = os.fork()
            if gc_was_enabled:
                gc.enable()
            if pid > 0:  # If parent return False
                os.waitpid(pid, 0)
                return 0
        except OSError, e:
            sys.stderr.write("Daemonize failed: %s\n" % (e))
            sys.exit(1)

        os.chdir("/")
        os.setsid()
        os.umask(0)

        try:
            pid = os.fork()
            if gc_was_enabled:
                gc.enable()
            if pid > 0:  # If parent Exit
                sys.exit(0)
        except OSError, e:
            sys.stderr.write("Daemonize failed: %s\n" % (e))
            sys.exit(1)

        if gc_was_enabled:
            gc.enable()

        sys.stdout.flush()
        sys.stderr.flush()
        return 1

    stdin_path = os.path.join(pipe_root_path, "stdin")
    stdout_path = os.path.join(pipe_root_path, "stdout")
    stderr_path = os.path.join(pipe_root_path, "stderr")
    results_path = os.path.join(pipe_root_path, "results")
    inputs_path = os.path.join(pipe_root_path, "inputs")

    for f in [stdin_path, stdout_path, stderr_path, results_path, inputs_path]:
        try:
            os.mkfifo(f)
        except OSError, e:
            if e.errno == 17:
                pass

    # Check for a pidfile to see if the daemon already runs
    openers = is_file_open(stdout_path)
    rundaemon = False
    if len(openers) > 0:
        for i in openers:
            if i[1] & stat.S_IWUSR:
                rundaemon = True
                openers.remove(i)
        if len(openers) > 0:
            for i in openers:
                os.kill(int(i[0]), 9)
    time.sleep(0.3)

    # Start the daemon
    child = False
    if not rundaemon:
        child = daemonize()

    if child == 0:
        return (child,
                inputs_path,
                results_path,
                stdin_path,
                stdout_path,
                stderr_path)
    else:
        signal.signal(signal.SIGIO, signal.SIG_DFL)
        return (child,
                results_path,
                inputs_path,
                stdin_path,
                stdout_path,
                stderr_path)


def create_process_cmd():
    """
    Create child process without clean process data thanks that it is possible
    call function and classes from child process.
    """
    r_c, w_p = os.pipe()
    r_p, w_c = os.pipe()
    r_si, w_si = os.pipe()
    r_so, w_so = os.pipe()
    r_se, w_se = os.pipe()
    gc_was_enabled = gc.isenabled()
    # Disable gc to avoid bug where gc -> file_dealloc ->
    # write to stderr -> hang.  http://bugs.python.org/issue1336
    gc.disable()
    pid = os.fork()
    if pid == 0:  # Child process
        os.close(r_p)
        os.close(w_p)
        os.close(w_si)
        os.close(r_so)
        os.close(r_se)
        sys.stdin.close()
        sys.stdout.close()
        sys.stderr.close()
        sys.stdin = os.fdopen(r_si, 'r', 0)
        sys.stdout = os.fdopen(w_so, 'w', 0)
        sys.stderr = os.fdopen(w_se, 'w', 0)
        if gc_was_enabled:
            gc.enable()
        return (0, r_c, w_c, None, None, None)
    else:
        os.close(r_c)
        os.close(w_c)
        os.close(r_si)
        os.close(w_so)
        os.close(w_se)
        if gc_was_enabled:
            gc.enable()
        return (pid, r_p, w_p, w_si, r_so, r_se)


def gen_tmp_dir(root_path):
    """
    Try to create tmp dir with special name.
    """
    path = None
    while (path is None or os.path.exists(path)):
        rname = "runner" + "".join(random.sample(string.letters, 4))
        path = os.path.join(root_path, rname)
        try:
            if not os.path.exists(path):
                os.mkdir(path)
                return path
        except:
            continue


def clean_tmp_dir(path):
    """
    Clean up directory.
    """
    shutil.rmtree(path, True)


def sort_fds_event(fds):
    hup = [x[0] for x in fds if x[1] & select.POLLHUP]
    read = [x[0] for x in fds if x[1] & select.POLLIN]
    write = [x[0] for x in fds if x[1] & select.POLLOUT]
    return hup, read, write


def close_unused_fds(fds):
    """
    Close all file descriptors which are not necessary anymore.

    :param fds: file descriptors
    :type fds: list []
    """
    for fd in fds:
        os.close(fd)


class CmdFinish(object):

    """
    Class used for communication with child process. This class
    """
    __slots__ = ["pid"]

    def __init__(self, parent=False):
        if not parent:
            self.pid = os.getpid()
        else:
            self.pid = os.getppid()
        self.pid = self.pid


class CmdSlave(object):

    """
    Representation of BaseCmd on slave side.
    """

    def __init__(self, baseCmd):
        """
        :param baseCmd: basecmd for encapsulation.
        """
        self.basecmd = baseCmd
        self.cmd_id = baseCmd.cmd_id
        self.obj = None
        self.pid = None
        self.r_pipe = None
        self.w_pipe = None
        self.stdin_pipe = None
        self.stdout_pipe = None
        self.stderr_pipe = None
        self.async = False
        self.nohup = False
        self.manage = False
        self.msg = None

    def close_pipes(self):
        """
        Close command communication pipe.
        """
        if self.r_pipe is not None:
            os.close(self.r_pipe)
        if self.w_pipe is not None:
            os.close(self.w_pipe)
        if self.stdin_pipe is not None:
            os.close(self.stdin_pipe)
        if self.stdout_pipe is not None:
            os.close(self.stdout_pipe)
        if self.stderr_pipe is not None:
            os.close(self.stderr_pipe)

    def parse_func_name(self, func_name, commander):
        """
        Parse name sended from master.

        format: ``["manage|async|nohup| ", "fnname1", "fnname2", ...]``

        :param func_name: Function name
        :param commander: Where to execute the command (remote or local)
        """
        if func_name[0] == "manage":  # start command in main process.
            self.manage = True
            func_name = func_name[1:]
        if func_name[0] == "async":  # start command in new process.
            self.async = True
            func_name = func_name[1:]
        if func_name[0] == "nohup":  # start command in new daemon process.
            self.nohup = True
            func_name = func_name[1:]
        if hasattr(commander, func_name[0]):
            obj = getattr(commander, func_name[0])
        elif func_name[0] in commander.globals:
            obj = commander.globals[func_name[0]]
        elif func_name[0] in commander.locals:
            obj = commander.locals[func_name[0]]
        else:
            obj = globals()[func_name[0]]
        if len(func_name) > 1:
            for name in func_name[1:]:
                obj = getattr(obj, name)
        return obj

    def __call__(self, commander):
        """
        Call command cmd(*args, **kargs)
        """
        self.obj = self.parse_func_name(self.basecmd.func, commander)
        if self.manage:  # start command in main process
            self.basecmd.results = self.obj(*self.basecmd.args,
                                            **self.basecmd.kargs)
            self.basecmd._finished = True
            self.finish(commander)
        elif self.async:  # start command in new process
            self.basecmd.results = self.__call_async__(commander)
            self.basecmd._async = True
        elif self.nohup:   # start command in new daemon process
            if self.basecmd.cmd_hash is None:
                self.basecmd.cmd_hash = gen_tmp_dir("/tmp")
            self.basecmd.results = self.__call_nohup__(commander)
            self.basecmd._async = True
        else:  # start command in new process but wait for input.
            self.basecmd.results = self.__call_async__(commander)

    def __call_async__(self, commander):
        (self.pid, self.r_pipe, self.w_pipe, self.stdin_pipe,
         self.stdout_pipe, self.stderr_pipe) = create_process_cmd()
        if self.pid == 0:  # Child process make commands
            commander._close_cmds_stdios(self)
            self.msg = ms.Messenger(ms.StdIOWrapperIn(self.r_pipe),
                                    ms.StdIOWrapperOut(self.w_pipe))
            try:
                self.basecmd.results = self.obj(*self.basecmd.args,
                                                **self.basecmd.kargs)
            except Exception:
                err_msg = traceback.format_exc()
                self.msg.write_msg(remote_interface.CmdTraceBack(err_msg))
                sys.exit(-1)
            finally:
                self.msg.write_msg(self.basecmd.results)
                self.msg.write_msg(CmdFinish())
            sys.exit(0)
        else:  # Parent process create communication interface to child process
            self.msg = ms.Messenger(ms.StdIOWrapperIn(self.r_pipe),
                                    ms.StdIOWrapperOut(self.w_pipe))

    def __call_nohup__(self, commander):
        (pid, self.r_path, self.w_path, self.stdin_path, self.stdout_path,
         self.stderr_path) = daemonize(self.basecmd.cmd_hash)
        if pid == 1:  # Child process make commands
            commander._close_cmds_stdios(self)
            (self.pid, r_pipe, w_pipe, stdin_pipe,
             stdout_pipe, stderr_pipe) = create_process_cmd()
            if self.pid == 0:  # Child process make commands
                self.msg = ms.Messenger(ms.StdIOWrapperIn(r_pipe),
                                        ms.StdIOWrapperOut(w_pipe))
                try:
                    self.basecmd.results = self.obj(*self.basecmd.args,
                                                    **self.basecmd.kargs)
                except Exception:
                    err_msg = traceback.format_exc()
                    self.msg.write_msg(remote_interface.CmdTraceBack(err_msg))
                    sys.exit(-1)
                finally:
                    self.msg.write_msg(self.basecmd.results)
                sys.exit(0)
            else:
                # helper child process open communication pipes.
                # This process is able to manage problem with connection width
                # main parent process. It allows start unchanged child process.
                self.r_pipe = os.open(self.r_path, os.O_RDONLY)
                self.w_pipe = os.open(self.w_path, os.O_WRONLY)
                sys.stdout = os.fdopen(os.open(self.stdout_path, os.O_WRONLY),
                                       "w",
                                       0)
                sys.stderr = os.fdopen(os.open(self.stderr_path, os.O_WRONLY),
                                       "w",
                                       0)
                sys.stdin = os.fdopen(os.open(self.stdin_path, os.O_RDONLY),
                                      "r",
                                      0)

                w_fds = [r_pipe, w_pipe, stdin_pipe, stdout_pipe, stderr_pipe]
                m_fds = [self.r_pipe,
                         self.w_pipe,
                         sys.stdin.fileno(),
                         sys.stdout.fileno(),
                         sys.stderr.fileno()]
                p = select.poll()
                p.register(r_pipe)
                p.register(w_pipe)
                # p.register(stdin_pipe)
                p.register(stdout_pipe)
                p.register(stderr_pipe)
                p.register(self.r_pipe)
                # p.register(self.w_pipe)
                p.register(sys.stdin.fileno())
                # p.register(sys.stdout.fileno())
                # p.register(sys.stderr.fileno())
                io_map = {r_pipe: self.w_pipe,
                          self.r_pipe: w_pipe,
                          sys.stdin.fileno(): stdin_pipe,
                          stdout_pipe: sys.stdout.fileno(),
                          stderr_pipe: sys.stderr.fileno()}
                while 1:
                    d = p.poll()
                    w_ev = [x for x in d if x[0] in w_fds]
                    m_ev = [x for x in d if x[0] in m_fds]
                    w_hup, w_read, _ = sort_fds_event(w_ev)
                    m_hup, m_read, _ = sort_fds_event(m_ev)
                    if m_hup:
                        time.sleep(0.1)
                    if w_hup:  # child process finished
                        for r in w_read:
                            data = os.read(r, 16384)
                            os.write(io_map[r], data)
                        break
                    for r in w_read:
                        data = os.read(r, 16384)
                        os.write(io_map[r], data)
                    for r in m_read:
                        data = os.read(r, 16384)
                        os.write(io_map[r], data)
                self.msg = ms.Messenger(ms.StdIOWrapperIn(self.r_pipe),
                                        ms.StdIOWrapperOut(self.w_pipe))
                self.msg.write_msg(CmdFinish())
                exit(0)
        else:  # main process open communication named pipes.
            self.w_pipe = os.open(self.w_path, os.O_WRONLY)
            self.r_pipe = os.open(self.r_path, os.O_RDONLY)
            self.stdout_pipe = os.open(self.stdout_path, os.O_RDONLY)
            self.stderr_pipe = os.open(self.stderr_path, os.O_RDONLY)
            self.stdin_pipe = os.open(self.stdin_path, os.O_WRONLY)
            self.msg = ms.Messenger(ms.StdIOWrapperIn(self.r_pipe),
                                    ms.StdIOWrapperOut(self.w_pipe))

    def work(self):
        """
        Wait for message from running child process
        """
        succ, msg = self.msg.read_msg()
        if isinstance(msg, CmdFinish):
            try:
                pid, _ = os.waitpid(msg.pid, 0)
            except OSError:
                pid = msg.pid
            if (succ is False or pid == msg.pid):
                self.basecmd._finished = True
                return True
            else:
                return False
        else:
            self.basecmd.results = msg

    def recover_paths(self):
        """
        Helper function for reconnect to daemon/nohup process.
        """
        self.stdin_path = os.path.join(self.basecmd.cmd_hash, "stdin")
        self.stdout_path = os.path.join(self.basecmd.cmd_hash, "stdout")
        self.stderr_path = os.path.join(self.basecmd.cmd_hash, "stderr")
        self.w_path = os.path.join(self.basecmd.cmd_hash, "results")
        self.r_path = os.path.join(self.basecmd.cmd_hash, "inputs")

    def recover_fds(self):
        """
        Helper function for reconnect to daemon/nohup process.
        """
        if self.r_pipe is None:
            self.recover_paths()
            self.w_pipe = os.open(self.w_path, os.O_WRONLY)
            self.r_pipe = os.open(self.r_path, os.O_RDONLY)
            self.stdin_pipe = os.open(self.stdin_path, os.O_WRONLY)
            self.stdout_pipe = os.open(self.stdout_path, os.O_RDONLY)
            self.stderr_pipe = os.open(self.stderr_path, os.O_RDONLY)
            self.msg = ms.Messenger(ms.StdIOWrapperIn(self.r_pipe),
                                    ms.StdIOWrapperOut(self.w_pipe))

    def finish(self, commander):
        """
        Remove cmd from commander commands on finish of process.
        """
        self.close_pipes()
        if self.basecmd.cmd_hash:
            clean_tmp_dir(self.basecmd.cmd_hash)
            self.basecmd.cmd_hash = None
        del commander.cmds[self.cmd_id]


class CommanderSlave(ms.Messenger):

    """
    Class commander slace is responsible for communication with commander
    master. It invoke commands to slave part and receive messages from them.
    For communication is used only stdin and stdout which are streams from
    slave part.
    """

    def __init__(self, stdin, stdout, o_stdout, o_stderr):
        super(CommanderSlave, self).__init__(stdin, stdout)
        self._exit = False
        self.cmds = {}
        self.globals = {}
        self.locals = {}
        self.o_stdout = o_stdout
        self.o_stderr = o_stderr

    def cmd_loop(self):
        """
        Wait for commands from master and receive results and outputs from
        commands.
        """
        try:
            while (not self._exit):
                stdios = [self.stdin, self.o_stdout, self.o_stderr]
                r_pipes = [cmd.r_pipe for cmd in self.cmds.values()
                           if cmd.r_pipe is not None]
                stdouts = [cmd.stdout_pipe for cmd in self.cmds.values()
                           if cmd.stdout_pipe is not None]
                stderrs = [cmd.stderr_pipe for cmd in self.cmds.values()
                           if cmd.stderr_pipe is not None]

                r, _, _ = select.select(stdios + r_pipes + stdouts + stderrs, [], [])

                if self.stdin in r:  # command from controller
                    cmd = CmdSlave(self.read_msg()[1])
                    self.cmds[cmd.cmd_id] = cmd
                    try:
                        cmd(self)
                        self.write_msg(cmd.basecmd)
                    except Exception:
                        err_msg = traceback.format_exc()
                        self.write_msg(remote_interface.CommanderError(err_msg))

                if self.o_stdout in r:  # Send message from stdout
                    msg = os.read(self.o_stdout, 16384)
                    self.write_msg(remote_interface.StdOut(msg))
                if self.o_stderr in r:  # Send message from stdout
                    msg = os.read(self.o_stderr, 16384)
                    self.write_msg(remote_interface.StdErr(msg))

                # test all commands for io
                for cmd in self.cmds.values():
                    if cmd.stdout_pipe in r:  # command stdout
                        data = os.read(cmd.stdout_pipe, 16384)
                        if data != "":  # pipe is not closed on another side.
                            self.write_msg(remote_interface.StdOut(data,
                                                                   cmd.cmd_id))
                        else:
                            os.close(cmd.stdout_pipe)
                            cmd.stdout_pipe = None
                    if cmd.stderr_pipe in r:  # command stderr
                        data = os.read(cmd.stderr_pipe, 16384)
                        if data != "":  # pipe is not closed on another side.
                            self.write_msg(remote_interface.StdErr(data,
                                                                   cmd.cmd_id))
                        else:
                            os.close(cmd.stderr_pipe)
                            cmd.stderr_pipe = None
                    if cmd.r_pipe in r:  # command results
                        if cmd.work():
                            cmd.finish(self)
                        self.write_msg(cmd.basecmd)
        except Exception:
            err_msg = traceback.format_exc()
            self.write_msg(remote_interface.CommanderError(err_msg))

    def _close_cmds_stdios(self, exclude_cmd):
        for cmd in self.cmds.values():
            if cmd is not exclude_cmd:
                cmd.close_pipes()


class CommanderSlaveCmds(CommanderSlave):

    """
    Class extends CommanderSlave and adds to them special commands like
    shell process, interactive python, send_msg to cmd.
    """

    def __init__(self, stdin, stdout, o_stdout, o_stderr):
        super(CommanderSlaveCmds, self).__init__(stdin, stdout,
                                                 o_stdout, o_stderr)

        while (1):
            succ, data = self.read_msg()
            if succ and data == "start":
                break
        self.write_msg("Started")

    def shell(self, cmd):
        """
        Starts shell process. Stdout is automatically copyed to basecmd.stdout

        :param cmd: Command which should be started.
        :return: basecmd with return code of cmd.
        """
        process = subprocess.Popen(cmd,
                                   shell=True,
                                   stdin=sys.stdin,
                                   stdout=sys.stdout,
                                   stderr=sys.stderr)

        return process.wait()

    def interactive(self):
        """
        Starts interactive python.
        """
        while 1:
            out = raw_input()
            if out == "":
                return
            try:
                exec out
            except Exception:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                print "On Guest exception from: \n" + "".join(
                    traceback.format_exception(exc_type,
                                               exc_value,
                                               exc_traceback))
                print "FAIL: Guest command exception."

    def send_msg(self, msg, cmd_id):
        """
        Send msg to cmd with id == cmd_id

        :param msg: message passed to cmd over the stdin
        :type msg: str
        :param cmd_id: id of cmd.
        """
        os.write(self.cmds[cmd_id].stdin_pipe, msg)

    def register_cmd(self, basecmd, basecmd_cmd_id):
        """
        Second side of set_commander cmd from master. It register existing
        cmd to CommandSlave dict.

        :param basecmd: cmd which should be added to CommandSlave dict
        :type basecmd: BaseCmd
        :param basecmd_cmd_id: number under which should be stored
        :type basecmd_cmd_id: int
        """
        remote_interface.BaseCmd.single_cmd_id = basecmd_cmd_id
        cmd = CmdSlave(basecmd)
        self.cmds[basecmd.cmd_id] = cmd
        if cmd.basecmd.cmd_hash is not None:
            cmd.recover_fds()
        return basecmd

    def add_function(self, f_code):
        """
        Adds function to client code.

        :param f_code: Code of function.
        :type f_code: str.
        """
        exec(f_code, globals(), globals())

    def copy_file(self, name, path, content):
        """
        Really naive implementation of copping files. Should be used only for
        short files.
        """
        f = open(os.path.join(path, name), "w")
        f.write(content)
        f.close()

    def import_src(self, name, path=None):
        """
        Import file to running python session.
        """
        if path:
            if path not in sys.path:
                sys.path.append(path)
        mod = __import__(name, globals(), locals())
        globals()[name] = mod
        sys.modules[name] = mod

    def exit(self):
        """
        Method for killing command slave.
        """
        self._exit = True
        return "bye"


def remote_agent(in_stream_cls, out_stream_cls):
    """
    Connect file descriptors to right pipe and start slave command loop.
    When something happend it raise exception which could be caught by cmd
    master.

    :params in_stream_cls: Class encapsulated input stream.
    :params out_stream_cls: Class encapsulated output stream.
    """
    try:
        fd_stdout = sys.stdout.fileno()
        fd_stderr = sys.stderr.fileno()
        fd_stdin = sys.stdin.fileno()
        soutr, soutw = os.pipe()
        serrr, serrw = os.pipe()
        sys.stdout = os.fdopen(soutw, 'w', 0)
        sys.stderr = os.fdopen(serrw, 'w', 0)
        os.write(fd_stdout, "#")

        logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)

        w_stdin = None
        w_stdout = out_stream_cls(fd_stdout)
        w_stdin = in_stream_cls(fd_stdin)

        cmd = CommanderSlaveCmds(w_stdin,
                                 w_stdout,
                                 soutr,
                                 serrr)

        cmd.cmd_loop()
    except SystemExit:
        pass
    except:
        e = traceback.format_exc()
        sys.stderr.write(e)
        # traceback.print_exc()

if __name__ == '__main__':
    if len(sys.argv) > 1:
        if sys.argv[1] == "agent":
            remote_agent(ms.StdIOWrapperIn, ms.StdIOWrapperOut)
        elif sys.argv[1] == "agent_base64":
            remote_agent(ms.StdIOWrapperInBase64, ms.StdIOWrapperOutBase64)

########NEW FILE########
__FILENAME__ = remote_unittest
#!/usr/bin/python

import unittest
import os

import common
import remote
import data_dir


class RemoteFileTest(unittest.TestCase):
    tmp_dir = data_dir.get_tmp_dir()
    test_file_path = os.path.join(tmp_dir, "remote_file")
    default_data = ["RemoteFile Test.\n", "Pattern Line."]

    def __del__(self):
        if os.path.exists(self.test_file_path):
            os.remove(self.test_file_path)

    def _new_remote_file(self):
        if os.path.exists(self.test_file_path):
            os.remove(self.test_file_path)
        test_file = open(self.test_file_path, "w")
        test_file.writelines(self.default_data)
        test_file.close()
        remote_file = remote.RemoteFile(None, "test", None, None, None,
                                        self.test_file_path)
        return remote_file

    def _read_test_file(self):
        test_file = open(self.test_file_path, "r")
        test_data = test_file.readlines()
        test_file.close()
        return test_data

    def testAdd(self):
        remote_file = self._new_remote_file()
        _add_list = ["add_line_1", "add_line_2", "add_line_3"]
        remote_file.add(_add_list)
        test_data = self._read_test_file()
        except_data = ["RemoteFile Test.\n",
                       "Pattern Line.\n",
                       "add_line_1\n",
                       "add_line_2\n",
                       "add_line_3"]
        for index in range(len(except_data)):
            self.assertEqual(except_data[index], test_data[index])
        del remote_file
        test_data = self._read_test_file()
        self.assertEqual(test_data, self.default_data)

    def testSub(self):
        remote_file = self._new_remote_file()
        _pattern2repl = {r"Remote": "Local", r"^Pat.*$": "Replace Line"}
        remote_file.sub(_pattern2repl)
        test_data = self._read_test_file()
        except_data = ["LocalFile Test.\n",
                       "Replace Line"]
        for index in range(len(except_data)):
            self.assertEqual(except_data[index], test_data[index])
        del remote_file
        test_data = self._read_test_file()
        self.assertEqual(test_data, self.default_data)

    def testRemove(self):
        remote_file = self._new_remote_file()
        _pattern_list = [r"^Pattern"]
        remote_file.remove(_pattern_list)
        test_data = self._read_test_file()
        except_data = ["RemoteFile Test."]
        for index in range(len(except_data)):
            self.assertEqual(except_data[index], test_data[index])
        del remote_file
        test_data = self._read_test_file()
        self.assertEqual(test_data, self.default_data)

    def testSEEA(self):
        remote_file = self._new_remote_file()
        _pattern2repl = {r"Remote": "Local", r"NoMatch": "ADD line."}
        remote_file.sub_else_add(_pattern2repl)
        test_data = self._read_test_file()
        except_data = ["LocalFile Test.\n",
                       "Pattern Line.\n",
                       "ADD line."]
        for index in range(len(except_data)):
            self.assertEqual(except_data[index], test_data[index])
        del remote_file
        test_data = self._read_test_file()
        self.assertEqual(test_data, self.default_data)

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = RFBDes
from virttest import utils_misc


class Des(object):

    """
    Base Data Encryption Standard class.
    For details, please refer to:
    http://en.wikipedia.org/wiki/Data_Encryption_Standard
    """
    # Permutation and translation tables for DES
    PC1 = [
        56, 48, 40, 32, 24, 16, 8,
        0, 57, 49, 41, 33, 25, 17,
        9, 1, 58, 50, 42, 34, 26,
        18, 10, 2, 59, 51, 43, 35,
        62, 54, 46, 38, 30, 22, 14,
        6, 61, 53, 45, 37, 29, 21,
        13, 5, 60, 52, 44, 36, 28,
        20, 12, 4, 27, 19, 11, 3
    ]

    # Number left rotations of pc1
    left_rotations = [
        1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1
    ]

    # get_sub_listd choice key (table 2)
    PC2 = [
        13, 16, 10, 23, 0, 4,
        2, 27, 14, 5, 20, 9,
        22, 18, 11, 3, 25, 7,
        15, 6, 26, 19, 12, 1,
        40, 51, 30, 36, 46, 54,
        29, 39, 50, 44, 32, 47,
        43, 48, 38, 55, 33, 52,
        45, 41, 49, 35, 28, 31
    ]

    # Initial permutation IP
    IP = [
        57, 49, 41, 33, 25, 17, 9, 1,
        59, 51, 43, 35, 27, 19, 11, 3,
        61, 53, 45, 37, 29, 21, 13, 5,
        63, 55, 47, 39, 31, 23, 15, 7,
        56, 48, 40, 32, 24, 16, 8, 0,
        58, 50, 42, 34, 26, 18, 10, 2,
        60, 52, 44, 36, 28, 20, 12, 4,
        62, 54, 46, 38, 30, 22, 14, 6
    ]

    # Expansion table for turning 32 bit blocks into 48 bits
    E = [
        31, 0, 1, 2, 3, 4,
        3, 4, 5, 6, 7, 8,
        7, 8, 9, 10, 11, 12,
        11, 12, 13, 14, 15, 16,
        15, 16, 17, 18, 19, 20,
        19, 20, 21, 22, 23, 24,
        23, 24, 25, 26, 27, 28,
        27, 28, 29, 30, 31, 0
    ]

    # The (in)famous S-boxes
    sbox = [
        # S1
        [14, 4, 13, 1, 2, 15, 11, 8, 3, 10, 6, 12, 5, 9, 0, 7,
         0, 15, 7, 4, 14, 2, 13, 1, 10, 6, 12, 11, 9, 5, 3, 8,
         4, 1, 14, 8, 13, 6, 2, 11, 15, 12, 9, 7, 3, 10, 5, 0,
         15, 12, 8, 2, 4, 9, 1, 7, 5, 11, 3, 14, 10, 0, 6, 13],

        # S2
        [15, 1, 8, 14, 6, 11, 3, 4, 9, 7, 2, 13, 12, 0, 5, 10,
         3, 13, 4, 7, 15, 2, 8, 14, 12, 0, 1, 10, 6, 9, 11, 5,
         0, 14, 7, 11, 10, 4, 13, 1, 5, 8, 12, 6, 9, 3, 2, 15,
         13, 8, 10, 1, 3, 15, 4, 2, 11, 6, 7, 12, 0, 5, 14, 9],

        # S3
        [10, 0, 9, 14, 6, 3, 15, 5, 1, 13, 12, 7, 11, 4, 2, 8,
         13, 7, 0, 9, 3, 4, 6, 10, 2, 8, 5, 14, 12, 11, 15, 1,
         13, 6, 4, 9, 8, 15, 3, 0, 11, 1, 2, 12, 5, 10, 14, 7,
         1, 10, 13, 0, 6, 9, 8, 7, 4, 15, 14, 3, 11, 5, 2, 12],

        # S4
        [7, 13, 14, 3, 0, 6, 9, 10, 1, 2, 8, 5, 11, 12, 4, 15,
         13, 8, 11, 5, 6, 15, 0, 3, 4, 7, 2, 12, 1, 10, 14, 9,
         10, 6, 9, 0, 12, 11, 7, 13, 15, 1, 3, 14, 5, 2, 8, 4,
         3, 15, 0, 6, 10, 1, 13, 8, 9, 4, 5, 11, 12, 7, 2, 14],

        # S5
        [2, 12, 4, 1, 7, 10, 11, 6, 8, 5, 3, 15, 13, 0, 14, 9,
         14, 11, 2, 12, 4, 7, 13, 1, 5, 0, 15, 10, 3, 9, 8, 6,
         4, 2, 1, 11, 10, 13, 7, 8, 15, 9, 12, 5, 6, 3, 0, 14,
         11, 8, 12, 7, 1, 14, 2, 13, 6, 15, 0, 9, 10, 4, 5, 3],

        # S6
        [12, 1, 10, 15, 9, 2, 6, 8, 0, 13, 3, 4, 14, 7, 5, 11,
         10, 15, 4, 2, 7, 12, 9, 5, 6, 1, 13, 14, 0, 11, 3, 8,
         9, 14, 15, 5, 2, 8, 12, 3, 7, 0, 4, 10, 1, 13, 11, 6,
         4, 3, 2, 12, 9, 5, 15, 10, 11, 14, 1, 7, 6, 0, 8, 13],

        # S7
        [4, 11, 2, 14, 15, 0, 8, 13, 3, 12, 9, 7, 5, 10, 6, 1,
         13, 0, 11, 7, 4, 9, 1, 10, 14, 3, 5, 12, 2, 15, 8, 6,
         1, 4, 11, 13, 12, 3, 7, 14, 10, 15, 6, 8, 0, 5, 9, 2,
         6, 11, 13, 8, 1, 4, 10, 7, 9, 5, 0, 15, 14, 2, 3, 12],

        # S8
        [13, 2, 8, 4, 6, 15, 11, 1, 10, 9, 3, 14, 5, 0, 12, 7,
         1, 15, 13, 8, 10, 3, 7, 4, 12, 5, 6, 11, 0, 14, 9, 2,
         7, 11, 4, 1, 9, 12, 14, 2, 0, 6, 10, 13, 15, 3, 5, 8,
         2, 1, 14, 7, 4, 10, 8, 13, 15, 12, 9, 0, 3, 5, 6, 11],
    ]

    # 32-bit permutation function P used on the output of the S-boxes
    P = [
        15, 6, 19, 20, 28, 11,
        27, 16, 0, 14, 22, 25,
        4, 17, 30, 9, 1, 7,
        23, 13, 31, 26, 2, 8,
        18, 12, 29, 5, 21, 10,
        3, 24
    ]

    # Final permutation IP^-1
    FP = [
        39, 7, 47, 15, 55, 23, 63, 31,
        38, 6, 46, 14, 54, 22, 62, 30,
        37, 5, 45, 13, 53, 21, 61, 29,
        36, 4, 44, 12, 52, 20, 60, 28,
        35, 3, 43, 11, 51, 19, 59, 27,
        34, 2, 42, 10, 50, 18, 58, 26,
        33, 1, 41, 9, 49, 17, 57, 25,
        32, 0, 40, 8, 48, 16, 56, 24
    ]

    # Initialisation
    def __init__(self, key):
        """
        Initialize the instance.

        :param key: Original used in DES.
        """
        if len(key) != 8:
            key = (key + '\0' * 8)[:8]

        self.L = []
        self.R = []
        self.Kn = [[0] * 48] * 16    # 16 48-bit keys (K1 - K16)

        self.setKey(key)

    def getKey(self):
        """
        Just get the crypting key.
        """
        return self.key

    def setKey(self, key):
        """
        Will set the crypting key for this object.
        RFB protocol for authentication requires client to encrypt
        challenge sent by server with password using DES method. However,
        bits in each byte of the password are put in reverse order before
        using it as encryption key.

        :param key: Original used in DES.
        """
        newkey = []
        for ki in range(len(key)):
            bsrc = ord(key[ki])
            btgt = 0
            for i in range(8):
                if bsrc & (1 << i):
                    btgt = btgt | (1 << 7 - i)

            newkey.append(chr(btgt))
        self.key = newkey
        self.create_Kn()

    def get_sub_list(self, table, block):
        """
        Return sub list of block according to index in table.

        :param table: Index list.
        :param block: bit list used to get sub list.
        """
        block_list = []
        for x in table:
            block_list.append(block[x])
        return block_list

    def create_Kn(self):
        """
        Create the 16 subkeys,from K[0] to K[15], from the given key
        """
        key = self.get_sub_list(
            self.PC1, utils_misc.string_to_bitlist(self.getKey()))
        self.L = key[:28]
        self.R = key[28:]
        for i in range(16):
            # Perform circular left shifts
            for j in range(self.left_rotations[i]):
                self.L.append(self.L[0])
                del self.L[0]
                self.R.append(self.R[0])
                del self.R[0]
            # Create one of the 16 subkeys through pc2 permutation
            self.Kn[i] = self.get_sub_list(self.PC2, self.L + self.R)

    def f(self, K):
        """
        The Feistel function (F-function) of DES, operates on half a block
        (32 bits) at a time and consists of four stages:
        1. Expansion
        2. Key mixing
        3. Substitution
        4. Permutation

        :param K: One of sixteen 48-bit subkeys are derived from the main key.
        """
        # Expansion:
        # The 32-bit half-block is expanded to 48 bits using E.
        self.R = self.get_sub_list(self.E, self.R)

        # Key mixing: The result is combined with a subkey using an XOR
        # operation. Sixteen 48-bit subkeys are derived from the main key.
        self.R = list(map(lambda x, y: x ^ y, self.R, K))

        # The block is divided into eight 6-bit pieces
        B = [self.R[:6], self.R[6:12], self.R[12:18], self.R[18:24],
             self.R[24:30], self.R[30:36], self.R[36:42], self.R[42:]]

        # Substitution:
        Bn = [0] * 32
        pos = 0
        for j in range(8):
            # Work out the offsets
            m = (B[j][0] << 1) + B[j][5]
            n = (B[j][1] << 3) + (B[j][2] << 2) + (B[j][3] << 1) + B[j][4]

            # Find the permutation value
            v = self.sbox[j][(m << 4) + n]

            # Turn value into bits, add it to result: Bn
            Bn[pos] = (v & 8) >> 3
            Bn[pos + 1] = (v & 4) >> 2
            Bn[pos + 2] = (v & 2) >> 1
            Bn[pos + 3] = v & 1

            pos += 4

        # Permutation:
        # Bn are rearranged according to a fixed permutation, the P-box.
        self.R = self.get_sub_list(self.P, Bn)

    def des_crypt(self, data, crypt_type=0):
        """
        Crypt the block of data through DES bit-manipulation

        :param data: data need to crypt.
        :param crypt_type: crypt type. 0 means encrypt, and 1 means decrypt.
        """
        # Get new block by using Ip.
        block = self.get_sub_list(self.IP, data)
        self.L = block[:32]
        self.R = block[32:]

        if crypt_type == 0:
            des_i = 0
            des_adj = 1
        else:
            des_i = 15
            des_adj = -1

        i = 0
        while i < 16:
            tempR = self.R
            self.f(self.Kn[des_i])

            # Xor with L[i - 1]
            self.R = list(map(lambda x, y: x ^ y, self.R, self.L))
            # Optimization: This now replaces the below commented code
            self.L = tempR

            i += 1
            des_i += des_adj

        # Final permutation of R[16]L[16]
        final = self.get_sub_list(self.FP, self.R + self.L)
        return final

    def crypt(self, data, crypt_type=0):
        """
        Crypt the data in blocks, running it through des_crypt()

        :param data: Data to be encrypted/decrypted.
        :param crypt_type: crypt type. 0 means encrypt, and 1 means decrypt.
        """

        # Split the data into list, crypting each one separately
        i = 0
        result = []
        while i < len(data):
            # Test code for caching encryption results
            block = utils_misc.string_to_bitlist(data[i:i + 8])
            pro_block = self.des_crypt(block, crypt_type)

            # Add the resulting block to our list
            result.append(utils_misc.bitlist_to_string(pro_block))
            i += 8

        # Return the full encrypted/decrypted string
        return ''.join(result)

########NEW FILE########
__FILENAME__ = rss_client
#!/usr/bin/python
"""
Client for file transfer services offered by RSS (Remote Shell Server).

:author: Michael Goldish (mgoldish@redhat.com)
:copyright: 2008-2010 Red Hat Inc.
"""

import socket
import struct
import time
import sys
import os
import glob

# Globals
CHUNKSIZE = 65536

# Protocol message constants
RSS_MAGIC = 0x525353
RSS_OK = 1
RSS_ERROR = 2
RSS_UPLOAD = 3
RSS_DOWNLOAD = 4
RSS_SET_PATH = 5
RSS_CREATE_FILE = 6
RSS_CREATE_DIR = 7
RSS_LEAVE_DIR = 8
RSS_DONE = 9

# See rss.cpp for protocol details.


class FileTransferError(Exception):

    def __init__(self, msg, e=None, filename=None):
        Exception.__init__(self, msg, e, filename)
        self.msg = msg
        self.e = e
        self.filename = filename

    def __str__(self):
        s = self.msg
        if self.e and self.filename:
            s += "    (error: %s,    filename: %s)" % (self.e, self.filename)
        elif self.e:
            s += "    (%s)" % self.e
        elif self.filename:
            s += "    (filename: %s)" % self.filename
        return s


class FileTransferConnectError(FileTransferError):
    pass


class FileTransferTimeoutError(FileTransferError):
    pass


class FileTransferProtocolError(FileTransferError):
    pass


class FileTransferSocketError(FileTransferError):
    pass


class FileTransferServerError(FileTransferError):

    def __init__(self, errmsg):
        FileTransferError.__init__(self, None, errmsg)

    def __str__(self):
        s = "Server said: %r" % self.e
        if self.filename:
            s += "    (filename: %s)" % self.filename
        return s


class FileTransferNotFoundError(FileTransferError):
    pass


class FileTransferClient(object):

    """
    Connect to a RSS (remote shell server) and transfer files.
    """

    def __init__(self, address, port, log_func=None, timeout=20):
        """
        Connect to a server.

        :param address: The server's address
        :param port: The server's port
        :param log_func: If provided, transfer stats will be passed to this
                function during the transfer
        :param timeout: Time duration to wait for connection to succeed
        :raise FileTransferConnectError: Raised if the connection fails
        """
        self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self._socket.settimeout(timeout)
        try:
            self._socket.connect((address, port))
        except socket.error, e:
            raise FileTransferConnectError("Cannot connect to server at "
                                           "%s:%s" % (address, port), e)
        try:
            if self._receive_msg(timeout) != RSS_MAGIC:
                raise FileTransferConnectError("Received wrong magic number")
        except FileTransferTimeoutError:
            raise FileTransferConnectError("Timeout expired while waiting to "
                                           "receive magic number")
        self._send(struct.pack("=i", CHUNKSIZE))
        self._log_func = log_func
        self._last_time = time.time()
        self._last_transferred = 0
        self.transferred = 0

    def __del__(self):
        self.close()

    def close(self):
        """
        Close the connection.
        """
        self._socket.close()

    def _send(self, sr, timeout=60):
        try:
            if timeout <= 0:
                raise socket.timeout
            self._socket.settimeout(timeout)
            self._socket.sendall(sr)
        except socket.timeout:
            raise FileTransferTimeoutError("Timeout expired while sending "
                                           "data to server")
        except socket.error, e:
            raise FileTransferSocketError("Could not send data to server", e)

    def _receive(self, size, timeout=60):
        strs = []
        end_time = time.time() + timeout
        try:
            while size > 0:
                timeout = end_time - time.time()
                if timeout <= 0:
                    raise socket.timeout
                self._socket.settimeout(timeout)
                data = self._socket.recv(size)
                if not data:
                    raise FileTransferProtocolError("Connection closed "
                                                    "unexpectedly while "
                                                    "receiving data from "
                                                    "server")
                strs.append(data)
                size -= len(data)
        except socket.timeout:
            raise FileTransferTimeoutError("Timeout expired while receiving "
                                           "data from server")
        except socket.error, e:
            raise FileTransferSocketError("Error receiving data from server",
                                          e)
        return "".join(strs)

    def _report_stats(self, sr):
        if self._log_func:
            dt = time.time() - self._last_time
            if dt >= 1:
                transferred = self.transferred / 1048576.
                speed = (self.transferred - self._last_transferred) / dt
                speed /= 1048576.
                self._log_func("%s %.3f MB (%.3f MB/sec)" %
                               (sr, transferred, speed))
                self._last_time = time.time()
                self._last_transferred = self.transferred

    def _send_packet(self, sr, timeout=60):
        self._send(struct.pack("=I", len(sr)))
        self._send(sr, timeout)
        self.transferred += len(sr) + 4
        self._report_stats("Sent")

    def _receive_packet(self, timeout=60):
        size = struct.unpack("=I", self._receive(4))[0]
        sr = self._receive(size, timeout)
        self.transferred += len(sr) + 4
        self._report_stats("Received")
        return sr

    def _send_file_chunks(self, filename, timeout=60):
        if self._log_func:
            self._log_func("Sending file %s" % filename)
        f = open(filename, "rb")
        try:
            try:
                end_time = time.time() + timeout
                while True:
                    data = f.read(CHUNKSIZE)
                    self._send_packet(data, end_time - time.time())
                    if len(data) < CHUNKSIZE:
                        break
            except FileTransferError, e:
                e.filename = filename
                raise
        finally:
            f.close()

    def _receive_file_chunks(self, filename, timeout=60):
        if self._log_func:
            self._log_func("Receiving file %s" % filename)
        f = open(filename, "wb")
        try:
            try:
                end_time = time.time() + timeout
                while True:
                    data = self._receive_packet(end_time - time.time())
                    f.write(data)
                    if len(data) < CHUNKSIZE:
                        break
            except FileTransferError, e:
                e.filename = filename
                raise
        finally:
            f.close()

    def _send_msg(self, msg, timeout=60):
        self._send(struct.pack("=I", msg))

    def _receive_msg(self, timeout=60):
        s = self._receive(4, timeout)
        return struct.unpack("=I", s)[0]

    def _handle_transfer_error(self):
        # Save original exception
        e = sys.exc_info()
        try:
            # See if we can get an error message
            msg = self._receive_msg()
        except FileTransferError:
            # No error message -- re-raise original exception
            raise e[0], e[1], e[2]
        if msg == RSS_ERROR:
            errmsg = self._receive_packet()
            raise FileTransferServerError(errmsg)
        raise e[0], e[1], e[2]


class FileUploadClient(FileTransferClient):

    """
    Connect to a RSS (remote shell server) and upload files or directory trees.
    """

    def __init__(self, address, port, log_func=None, timeout=20):
        """
        Connect to a server.

        :param address: The server's address
        :param port: The server's port
        :param log_func: If provided, transfer stats will be passed to this
                function during the transfer
        :param timeout: Time duration to wait for connection to succeed
        :raise FileTransferConnectError: Raised if the connection fails
        :raise FileTransferProtocolError: Raised if an incorrect magic number
                is received
        :raise FileTransferSocketError: Raised if the RSS_UPLOAD message cannot
                be sent to the server
        """
        super(FileUploadClient, self).__init__(
            address, port, log_func, timeout)
        self._send_msg(RSS_UPLOAD)

    def _upload_file(self, path, end_time):
        if os.path.isfile(path):
            self._send_msg(RSS_CREATE_FILE)
            self._send_packet(os.path.basename(path))
            self._send_file_chunks(path, end_time - time.time())
        elif os.path.isdir(path):
            self._send_msg(RSS_CREATE_DIR)
            self._send_packet(os.path.basename(path))
            for filename in os.listdir(path):
                self._upload_file(os.path.join(path, filename), end_time)
            self._send_msg(RSS_LEAVE_DIR)

    def upload(self, src_pattern, dst_path, timeout=600):
        """
        Send files or directory trees to the server.

        The semantics of src_pattern and dst_path are similar to those of scp.
        For example, the following are OK:

        ::

            src_pattern='/tmp/foo.txt', dst_path='C:\\'
                (uploads a single file)
            src_pattern='/usr/', dst_path='C:\\Windows\\'
                (uploads a directory tree recursively)
            src_pattern='/usr/*', dst_path='C:\\Windows\\'
                (uploads all files and directory trees under /usr/)

        The following is not OK:

        ::

            src_pattern='/tmp/foo.txt', dst_path='C:\\Windows\\*'
                (wildcards are only allowed in src_pattern)

        :param src_pattern: A path or wildcard pattern specifying the files or
                            directories to send to the server
        :param dst_path: A path in the server's filesystem where the files will
                         be saved
        :param timeout: Time duration in seconds to wait for the transfer to
                        complete
        :raise FileTransferTimeoutError: Raised if timeout expires
        :raise FileTransferServerError: Raised if something goes wrong and the
                                        server sends an informative error
                                        message to the client
        :note: Other exceptions can be raised.
        """
        end_time = time.time() + timeout
        try:
            try:
                self._send_msg(RSS_SET_PATH)
                self._send_packet(dst_path)
                matches = glob.glob(src_pattern)
                for filename in matches:
                    self._upload_file(os.path.abspath(filename), end_time)
                self._send_msg(RSS_DONE)
            except FileTransferTimeoutError:
                raise
            except FileTransferError:
                self._handle_transfer_error()
            else:
                # If nothing was transferred, raise an exception
                if not matches:
                    raise FileTransferNotFoundError("Pattern %s does not "
                                                    "match any files or "
                                                    "directories" %
                                                    src_pattern)
                # Look for RSS_OK or RSS_ERROR
                msg = self._receive_msg(end_time - time.time())
                if msg == RSS_OK:
                    return
                elif msg == RSS_ERROR:
                    errmsg = self._receive_packet()
                    raise FileTransferServerError(errmsg)
                else:
                    # Neither RSS_OK nor RSS_ERROR found
                    raise FileTransferProtocolError("Received unexpected msg")
        except Exception:
            # In any case, if the transfer failed, close the connection
            self.close()
            raise


class FileDownloadClient(FileTransferClient):

    """
    Connect to a RSS (remote shell server) and download files or directory trees.
    """

    def __init__(self, address, port, log_func=None, timeout=20):
        """
        Connect to a server.

        :param address: The server's address
        :param port: The server's port
        :param log_func: If provided, transfer stats will be passed to this
                function during the transfer
        :param timeout: Time duration to wait for connection to succeed
        :raise FileTransferConnectError: Raised if the connection fails
        :raise FileTransferProtocolError: Raised if an incorrect magic number
                is received
        :raise FileTransferSendError: Raised if the RSS_UPLOAD message cannot
                be sent to the server
        """
        super(FileDownloadClient, self).__init__(
            address, port, log_func, timeout)
        self._send_msg(RSS_DOWNLOAD)

    def download(self, src_pattern, dst_path, timeout=600):
        """
        Receive files or directory trees from the server.
        The semantics of src_pattern and dst_path are similar to those of scp.

        For example, the following are OK:

        ::

            src_pattern='C:\\foo.txt', dst_path='/tmp'
                (downloads a single file)
            src_pattern='C:\\Windows', dst_path='/tmp'
                (downloads a directory tree recursively)
            src_pattern='C:\\Windows\\*', dst_path='/tmp'
                (downloads all files and directory trees under C:\\Windows)

        The following is not OK:

        ::

            src_pattern='C:\\Windows', dst_path='/tmp/*'
                (wildcards are only allowed in src_pattern)

        :param src_pattern: A path or wildcard pattern specifying the files or
                            directories, in the server's filesystem, that will
                            be sent to the client
        :param dst_path: A path in the local filesystem where the files will
                         be saved
        :param timeout: Time duration in seconds to wait for the transfer to
                        complete
        :raise FileTransferTimeoutError: Raised if timeout expires
        :raise FileTransferServerError: Raised if something goes wrong and the
                                        server sends an informative error
                                        message to the client
        :note: Other exceptions can be raised.
        """
        dst_path = os.path.abspath(dst_path)
        end_time = time.time() + timeout
        file_count = 0
        dir_count = 0
        try:
            try:
                self._send_msg(RSS_SET_PATH)
                self._send_packet(src_pattern)
            except FileTransferError:
                self._handle_transfer_error()
            while True:
                msg = self._receive_msg()
                if msg == RSS_CREATE_FILE:
                    # Receive filename and file contents
                    filename = self._receive_packet()
                    if os.path.isdir(dst_path):
                        dst_path = os.path.join(dst_path, filename)
                    self._receive_file_chunks(dst_path, end_time - time.time())
                    dst_path = os.path.dirname(dst_path)
                    file_count += 1
                elif msg == RSS_CREATE_DIR:
                    # Receive dirname and create the directory
                    dirname = self._receive_packet()
                    if os.path.isdir(dst_path):
                        dst_path = os.path.join(dst_path, dirname)
                    if not os.path.isdir(dst_path):
                        os.mkdir(dst_path)
                    dir_count += 1
                elif msg == RSS_LEAVE_DIR:
                    # Return to parent dir
                    dst_path = os.path.dirname(dst_path)
                elif msg == RSS_DONE:
                    # Transfer complete
                    if not file_count and not dir_count:
                        raise FileTransferNotFoundError("Pattern %s does not "
                                                        "match any files or "
                                                        "directories that "
                                                        "could be downloaded" %
                                                        src_pattern)
                    break
                elif msg == RSS_ERROR:
                    # Receive error message and abort
                    errmsg = self._receive_packet()
                    raise FileTransferServerError(errmsg)
                else:
                    # Unexpected msg
                    raise FileTransferProtocolError("Received unexpected msg")
        except Exception:
            # In any case, if the transfer failed, close the connection
            self.close()
            raise


def upload(address, port, src_pattern, dst_path, log_func=None, timeout=60,
           connect_timeout=20):
    """
    Connect to server and upload files.

    :see:: FileUploadClient
    """
    client = FileUploadClient(address, port, log_func, connect_timeout)
    client.upload(src_pattern, dst_path, timeout)
    client.close()


def download(address, port, src_pattern, dst_path, log_func=None, timeout=60,
             connect_timeout=20):
    """
    Connect to server and upload files.

    :see:: FileDownloadClient
    """
    client = FileDownloadClient(address, port, log_func, connect_timeout)
    client.download(src_pattern, dst_path, timeout)
    client.close()


def main():
    import optparse

    usage = "usage: %prog [options] address port src_pattern dst_path"
    parser = optparse.OptionParser(usage=usage)
    parser.add_option("-d", "--download",
                      action="store_true", dest="download",
                      help="download files from server")
    parser.add_option("-u", "--upload",
                      action="store_true", dest="upload",
                      help="upload files to server")
    parser.add_option("-v", "--verbose",
                      action="store_true", dest="verbose",
                      help="be verbose")
    parser.add_option("-t", "--timeout",
                      type="int", dest="timeout", default=3600,
                      help="transfer timeout")
    options, args = parser.parse_args()
    if options.download == options.upload:
        parser.error("you must specify either -d or -u")
    if len(args) != 4:
        parser.error("incorrect number of arguments")
    address, port, src_pattern, dst_path = args
    port = int(port)

    logger = None
    if options.verbose:
        def p(s):
            print s
        logger = p

    if options.download:
        download(address, port, src_pattern, dst_path, logger, options.timeout)
    elif options.upload:
        upload(address, port, src_pattern, dst_path, logger, options.timeout)


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = scheduler
import os
import select
import utils_env
import virt_vm
import aexpect


class scheduler:

    """
    A scheduler that manages several parallel test execution pipelines on a
    single host.
    """

    def __init__(self, tests, num_workers, total_cpus, total_mem, bindir):
        """
        Initialize the class.

        :param tests: A list of test dictionaries.
        :param num_workers: The number of workers (pipelines).
        :param total_cpus: The total number of CPUs to dedicate to tests.
        :param total_mem: The total amount of memory to dedicate to tests.
        :param bindir: The directory where environment files reside.
        """
        self.tests = tests
        self.num_workers = num_workers
        self.total_cpus = total_cpus
        self.total_mem = total_mem
        self.bindir = bindir
        # Pipes -- s stands for scheduler, w stands for worker
        self.s2w = [os.pipe() for _ in range(num_workers)]
        self.w2s = [os.pipe() for _ in range(num_workers)]
        self.s2w_r = [os.fdopen(r, "r", 0) for r, _ in self.s2w]
        self.s2w_w = [os.fdopen(w, "w", 0) for _, w in self.s2w]
        self.w2s_r = [os.fdopen(r, "r", 0) for r, _ in self.w2s]
        self.w2s_w = [os.fdopen(w, "w", 0) for _, w in self.w2s]
        # "Personal" worker dicts contain modifications that are applied
        # specifically to each worker.  For example, each worker must use a
        # different environment file and a different MAC address pool.
        self.worker_dicts = [{"env": "env%d" % i} for i in range(num_workers)]

    def worker(self, index, run_test_func):
        """
        The worker function.

        Waits for commands from the scheduler and processes them.

        :param index: The index of this worker (in the range 0..num_workers-1).
        :param run_test_func: A function to be called to run a test
                (e.g. job.run_test).
        """
        r = self.s2w_r[index]
        w = self.w2s_w[index]
        self_dict = self.worker_dicts[index]

        # Inform the scheduler this worker is ready
        w.write("ready\n")

        while True:
            cmd = r.readline().split()
            if not cmd:
                continue

            # The scheduler wants this worker to run a test
            if cmd[0] == "run":
                test_index = int(cmd[1])
                test = self.tests[test_index].copy()
                test.update(self_dict)
                test_iterations = int(test.get("iterations", 1))
                status = run_test_func("kvm", params=test,
                                       tag=test.get("shortname"),
                                       iterations=test_iterations)
                w.write("done %s %s\n" % (test_index, status))
                w.write("ready\n")

            # The scheduler wants this worker to free its used resources
            elif cmd[0] == "cleanup":
                env_filename = os.path.join(self.bindir, self_dict["env"])
                env = utils_env.Env(env_filename)
                for obj in env.values():
                    if isinstance(obj, virt_vm.BaseVM):
                        obj.destroy()
                    elif isinstance(obj, aexpect.Spawn):
                        obj.close()
                env.save()
                w.write("cleanup_done\n")
                w.write("ready\n")

            # There's no more work for this worker
            elif cmd[0] == "terminate":
                break

    def scheduler(self):
        """
        The scheduler function.

        Sends commands to workers, telling them to run tests, clean up or
        terminate execution.
        """
        idle_workers = []
        closing_workers = []
        test_status = ["waiting"] * len(self.tests)
        test_worker = [None] * len(self.tests)
        used_cpus = [0] * self.num_workers
        used_mem = [0] * self.num_workers

        while True:
            # Wait for a message from a worker
            r, _, _ = select.select(self.w2s_r, [], [])

            someone_is_ready = False

            for pipe in r:
                worker_index = self.w2s_r.index(pipe)
                msg = pipe.readline().split()
                if not msg:
                    continue

                # A worker is ready -- add it to the idle_workers list
                if msg[0] == "ready":
                    idle_workers.append(worker_index)
                    someone_is_ready = True

                # A worker completed a test
                elif msg[0] == "done":
                    test_index = int(msg[1])
                    test = self.tests[test_index]
                    status = int(eval(msg[2]))
                    test_status[test_index] = ("fail", "pass")[status]
                    # If the test failed, mark all dependent tests as "failed"
                    # too
                    if not status:
                        for i, other_test in enumerate(self.tests):
                            for dep in other_test.get("dep", []):
                                if dep in test["name"]:
                                    test_status[i] = "fail"

                # A worker is done shutting down its VMs and other processes
                elif msg[0] == "cleanup_done":
                    used_cpus[worker_index] = 0
                    used_mem[worker_index] = 0
                    closing_workers.remove(worker_index)

            if not someone_is_ready:
                continue

            for worker in idle_workers[:]:
                # Find a test for this worker
                test_found = False
                for i, test in enumerate(self.tests):
                    # We only want "waiting" tests
                    if test_status[i] != "waiting":
                        continue
                    # Make sure the test isn't assigned to another worker
                    if test_worker[i] is not None and test_worker[i] != worker:
                        continue
                    # Make sure the test's dependencies are satisfied
                    dependencies_satisfied = True
                    for dep in test["dep"]:
                        dependencies = [j for j, t in enumerate(self.tests)
                                        if dep in t["name"]]
                        bad_status_deps = [j for j in dependencies
                                           if test_status[j] != "pass"]
                        if bad_status_deps:
                            dependencies_satisfied = False
                            break
                    if not dependencies_satisfied:
                        continue
                    # Make sure we have enough resources to run the test
                    test_used_cpus = int(test.get("used_cpus", 1))
                    test_used_mem = int(test.get("used_mem", 128))
                    # First make sure the other workers aren't using too many
                    # CPUs (not including the workers currently shutting down)
                    uc = (sum(used_cpus) - used_cpus[worker] -
                          sum(used_cpus[i] for i in closing_workers))
                    if uc and uc + test_used_cpus > self.total_cpus:
                        continue
                    # ... or too much memory
                    um = (sum(used_mem) - used_mem[worker] -
                          sum(used_mem[i] for i in closing_workers))
                    if um and um + test_used_mem > self.total_mem:
                        continue
                    # If we reached this point it means there are, or will
                    # soon be, enough resources to run the test
                    test_found = True
                    # Now check if the test can be run right now, i.e. if the
                    # other workers, including the ones currently shutting
                    # down, aren't using too many CPUs
                    uc = (sum(used_cpus) - used_cpus[worker])
                    if uc and uc + test_used_cpus > self.total_cpus:
                        continue
                    # ... or too much memory
                    um = (sum(used_mem) - used_mem[worker])
                    if um and um + test_used_mem > self.total_mem:
                        continue
                    # Everything is OK -- run the test
                    test_status[i] = "running"
                    test_worker[i] = worker
                    idle_workers.remove(worker)
                    # Update used_cpus and used_mem
                    used_cpus[worker] = test_used_cpus
                    used_mem[worker] = test_used_mem
                    # Assign all related tests to this worker
                    for j, other_test in enumerate(self.tests):
                        for other_dep in other_test["dep"]:
                            # All tests that depend on this test
                            if other_dep in test["name"]:
                                test_worker[j] = worker
                                break
                            # ... and all tests that share a dependency
                            # with this test
                            for dep in test["dep"]:
                                if dep in other_dep or other_dep in dep:
                                    test_worker[j] = worker
                                    break
                    # Tell the worker to run the test
                    self.s2w_w[worker].write("run %s\n" % i)
                    break

                # If there won't be any tests for this worker to run soon, tell
                # the worker to free its used resources
                if not test_found and (used_cpus[worker] or used_mem[worker]):
                    self.s2w_w[worker].write("cleanup\n")
                    idle_workers.remove(worker)
                    closing_workers.append(worker)

            # If there are no more new tests to run, terminate the workers and
            # the scheduler
            if len(idle_workers) == self.num_workers:
                for worker in idle_workers:
                    self.s2w_w[worker].write("terminate\n")
                break

########NEW FILE########
__FILENAME__ = defaultdict
'''
Backport of the defaultdict module, obtained from:
http://code.activestate.com/recipes/523034-emulate-collectionsdefaultdict/
'''

# pylint: disable=I0011,C0103


class defaultdict(dict):

    """
    collections.defaultdict is a handy shortcut added in Python 2.5 which can
    be emulated in older versions of Python. This recipe tries to backport
    defaultdict exactly and aims to be safe to subclass and extend without
    worrying if the base class is in C or is being emulated.

    http://code.activestate.com/recipes/523034-emulate-collectionsdefaultdict/
    :codeauthor: Jason Kirtland
    :license: PSF

    Changes:
    * replaced self.items() with self.iteritems() to fix Pickle bug as
    recommended by Aaron Lav
    * reformated with autopep8
    """

    def __init__(self, default_factory=None, *a, **kw):
        if (default_factory is not None and
                not hasattr(default_factory, '__call__')):
            raise TypeError('first argument must be callable')
        dict.__init__(self, *a, **kw)
        self.default_factory = default_factory

    def __getitem__(self, key):
        try:
            return dict.__getitem__(self, key)
        except KeyError:
            return self.__missing__(key)

    def __missing__(self, key):
        if self.default_factory is None:
            raise KeyError(key)
        self[key] = value = self.default_factory()
        return value

    def __reduce__(self):
        if self.default_factory is None:
            args = tuple()
        else:
            args = self.default_factory,
        return type(self), args, None, None, self.iteritems()

    def copy(self):
        return self.__copy__()

    def __copy__(self):
        return type(self)(self.default_factory, self)

    # pylint: disable=I0011,W0613
    def __deepcopy__(self, memo):
        import copy
        return type(self)(self.default_factory,
                          copy.deepcopy(self.iteritems()))

    def __repr__(self):
        return 'defaultdict(%s, %s)' % (self.default_factory,
                                        dict.__repr__(self))

########NEW FILE########
__FILENAME__ = namedtuple
"""
This module contains a backport for collections.namedtuple obtained from
http://code.activestate.com/recipes/500261-named-tuples/
"""

from operator import itemgetter as _itemgetter
from keyword import iskeyword as _iskeyword
import sys as _sys


# pylint: disable=I0011,R0914,W0141,W0122,W0612,C0103,W0212,R0912
def namedtuple(typename, field_names, verbose=False, rename=False):
    """
    Returns a new subclass of tuple with named fields.

    >>> Point = namedtuple('Point', 'x y')
    >>> Point.__doc__                   # docstring for the new class
    'Point(x, y)'
    >>> p = Point(11, y=22)             # instantiate with positional args or keywords
    >>> p[0] + p[1]                     # indexable like a plain tuple
    33
    >>> x, y = p                        # unpack like a regular tuple
    >>> x, y
    (11, 22)
    >>> p.x + p.y                       # fields also accessible by name
    33
    >>> d = p._asdict()                 # convert to a dictionary
    >>> d['x']
    11
    >>> Point(**d)                      # convert from a dictionary
    Point(x=11, y=22)
    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields
    Point(x=100, y=22)

    http://code.activestate.com/recipes/500261-named-tuples/
    :codeauthor: Raymond Hettinger
    :license: PSF

    Changes:
    * autopep8 reformatting
    """

    # Parse and validate the field names.  Validation serves two purposes,
    # generating informative error messages and preventing template injection
    # attacks.
    if isinstance(field_names, basestring):
        field_names = field_names.replace(
            ',', ' ').split()  # names separated by whitespace and/or commas
    field_names = tuple(map(str, field_names))
    if rename:
        names = list(field_names)
        seen = set()
        for i, name in enumerate(names):
            if (not min(c.isalnum() or c == '_' for c in name)
                or _iskeyword(name)
                or not name
                or name[0].isdigit()
                or name.startswith('_')
                    or name in seen):
                names[i] = '_%d' % i
            seen.add(name)
        field_names = tuple(names)
    for name in (typename,) + field_names:
        if not min(c.isalnum() or c == '_' for c in name):
            raise ValueError(
                'Type names and field names can only contain alphanumeric '
                'characters and underscores: %r' % name)
        if _iskeyword(name):
            raise ValueError(
                'Type names and field names cannot be a keyword: %r' % name)
        if name[0].isdigit():
            raise ValueError(
                'Type names and field names cannot start with a '
                'number: %r' % name)
    seen_names = set()
    for name in field_names:
        if name.startswith('_') and not rename:
            raise ValueError(
                'Field names cannot start with an underscore: %r' % name)
        if name in seen_names:
            raise ValueError('Encountered duplicate field name: %r' % name)
        seen_names.add(name)

    # Create and fill-in the class template
    numfields = len(field_names)
    argtxt = repr(field_names).replace("'", "")[
        1:-1]   # tuple repr without parens or quotes
    reprtxt = ', '.join('%s=%%r' % name for name in field_names)
    template = '''class %(typename)s(tuple):
        '%(typename)s(%(argtxt)s)' \n
        __slots__ = () \n
        _fields = %(field_names)r \n
        def __new__(_cls, %(argtxt)s):
            return _tuple.__new__(_cls, (%(argtxt)s)) \n
        @classmethod
        def _make(cls, iterable, new=tuple.__new__, len=len):
            'Make a new %(typename)s object from a sequence or iterable'
            result = new(cls, iterable)
            if len(result) != %(numfields)d:
                raise TypeError('Expected %(numfields)d arguments, got %%d' %% len(result))
            return result \n
        def __repr__(self):
            return '%(typename)s(%(reprtxt)s)' %% self \n
        def _asdict(self):
            'Return a new dict which maps field names to their values'
            return dict(zip(self._fields, self)) \n
        def _replace(_self, **kwds):
            'Return a new %(typename)s object replacing specified fields with new values'
            result = _self._make(map(kwds.pop, %(field_names)r, _self))
            if kwds:
                raise ValueError('Got unexpected field names: %%r' %% kwds.keys())
            return result \n
        def __getnewargs__(self):
            return tuple(self) \n\n''' % locals()
    for i, name in enumerate(field_names):
        template += '        %s = _property(_itemgetter(%d))\n' % (name, i)
    if verbose:
        print template

    # Execute the template string in a temporary namespace
    namespace = dict(
        _itemgetter=_itemgetter, __name__='namedtuple_%s' % typename,
        _property=property, _tuple=tuple)
    try:
        exec template in namespace
    except SyntaxError, e:
        raise SyntaxError(e.message + ':\n' + template)
    result = namespace[typename]

    # For pickling to work, the __module__ variable needs to be set to the frame
    # where the named tuple is created.  Bypass this step in environments where
    # sys._getframe is not defined (Jython for example) or sys._getframe is not
    # defined for arguments greater than 0 (IronPython).
    try:
        result.__module__ = _sys._getframe(
            1).f_globals.get('__name__', '__main__')
    except (AttributeError, ValueError):
        pass

    return result

########NEW FILE########
__FILENAME__ = OrderedDict
'''
Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and
pypy. Passes Python2.7's test suite and incorporates all the latest updates.

Obtained from:
http://code.activestate.com/recipes/576693-ordered-dictionary-for-py24/
'''

try:
    from thread import get_ident as _get_ident
except ImportError:
    from dummy_thread import get_ident as _get_ident

try:
    from _abcoll import KeysView, ValuesView, ItemsView
except ImportError:
    pass


class OrderedDict(dict):

    """
    Dictionary that remembers insertion order

    http://code.activestate.com/recipes/576693-ordered-dictionary-for-py24/
    :codeauthor: Raymond Hettinger
    :license: MIT

    """
    # An inherited dict maps keys to values.
    # The inherited dict provides __getitem__, __len__, __contains__, and get.
    # The remaining methods are order-aware.
    # Big-O running times for all methods are the same as for regular
    # dictionaries.

    # The internal self.__map dictionary maps keys to links in a doubly linked
    # list.
    # The circular doubly linked list starts and ends with a sentinel element.
    # The sentinel element never gets deleted (this simplifies the algorithm).
    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].
    # pylint: disable=I0011,W0231

    def __init__(self, *args, **kwds):
        '''
        Initialize an ordered dictionary.

        Signature is the same as for regular dictionaries, but keyword
        arguments are not recommended because their insertion order is
        arbitrary.
        '''
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))
        try:
            self.__root
        except AttributeError:
            self.__root = root = []                     # sentinel node
            root[:] = [root, root, None]
            self.__map = {}
        self.__update(*args, **kwds)

    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
        'od.__setitem__(i, y) <==> od[i]=y'
        # Setting a new item creates a new link which goes at the end of the
        # linked list, and the inherited dictionary is updated with the new
        # key/value pair.
        if key not in self:
            root = self.__root
            last = root[0]
            last[1] = root[0] = self.__map[key] = [last, root, key]
        dict_setitem(self, key, value)

    def __delitem__(self, key, dict_delitem=dict.__delitem__):
        'od.__delitem__(y) <==> del od[y]'
        # Deleting an existing item uses self.__map to find the link which is
        # then removed by updating the links in the predecessor and successor
        # nodes
        dict_delitem(self, key)
        link_prev, link_next, key = self.__map.pop(key)
        link_prev[1] = link_next
        link_next[0] = link_prev

    def __iter__(self):
        'od.__iter__() <==> iter(od)'
        root = self.__root
        curr = root[1]
        while curr is not root:
            yield curr[2]
            curr = curr[1]

    def __reversed__(self):
        'od.__reversed__() <==> reversed(od)'
        root = self.__root
        curr = root[0]
        while curr is not root:
            yield curr[2]
            curr = curr[0]

    def clear(self):
        'od.clear() -> None.  Remove all items from od.'
        try:
            for node in self.__map.itervalues():
                del node[:]
            root = self.__root
            root[:] = [root, root, None]
            self.__map.clear()
        except AttributeError:
            pass
        dict.clear(self)

    def popitem(self, last=True):
        '''od.popitem() -> (k, v), return and remove a (key, value) pair.
        Pairs are returned in LIFO order if last is true or FIFO order if false.

        '''
        if not self:
            raise KeyError('dictionary is empty')
        root = self.__root
        if last:
            link = root[0]
            link_prev = link[0]
            link_prev[1] = root
            root[0] = link_prev
        else:
            link = root[1]
            link_next = link[1]
            root[1] = link_next
            link_next[0] = root
        key = link[2]
        del self.__map[key]
        value = dict.pop(self, key)
        return key, value

    # -- the following methods do not depend on the internal structure --

    def keys(self):
        'od.keys() -> list of keys in od'
        return list(self)

    def values(self):
        'od.values() -> list of values in od'
        return [self[key] for key in self]

    def items(self):
        'od.items() -> list of (key, value) pairs in od'
        return [(key, self[key]) for key in self]

    def iterkeys(self):
        'od.iterkeys() -> an iterator over the keys in od'
        return iter(self)

    def itervalues(self):
        'od.itervalues -> an iterator over the values in od'
        for k in self:
            yield self[k]

    def iteritems(self):
        'od.iteritems -> an iterator over the (key, value) items in od'
        for k in self:
            yield (k, self[k])

    # pylint: disable=I0011,E0211,E1103
    def update(*args, **kwds):
        '''od.update(E, **F) -> None.  Update od from dict/iterable E and F.

        If E is a dict instance, does:           for k in E: od[k] = E[k]
        If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
        Or if E is an iterable of items, does:   for k, v in E: od[k] = v
        In either case, this is followed by:     for k, v in F.items(): od[k] = v

        '''
        if len(args) > 2:
            raise TypeError('update() takes at most 2 positional '
                            'arguments (%d given)' % (len(args),))
        elif not args:
            raise TypeError('update() takes at least 1 argument (0 given)')
        self = args[0]
        # Make progressively weaker assumptions about "other"
        other = ()
        if len(args) == 2:
            other = args[1]
        if isinstance(other, dict):
            for key in other:
                self[key] = other[key]
        elif hasattr(other, 'keys'):
            for key in other.keys():
                self[key] = other[key]
        else:
            for key, value in other:
                self[key] = value
        for key, value in kwds.items():
            self[key] = value

    # let subclasses override update without breaking __init__
    __update = update

    __marker = object()

    def pop(self, key, default=__marker):
        '''
        od.pop(k[,d]) -> v, remove specified key and return the corresponding
        value.

        If key is not found, d is returned if given, otherwise KeyError is
        raised.
        '''
        if key in self:
            result = self[key]
            del self[key]
            return result
        if default is self.__marker:
            raise KeyError(key)
        return default

    def setdefault(self, key, default=None):
        'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
        if key in self:
            return self[key]
        self[key] = default
        return default

    # pylint: disable=I0011,W0102
    def __repr__(self, _repr_running={}):
        'od.__repr__() <==> repr(od)'
        call_key = id(self), _get_ident()
        if call_key in _repr_running:
            return '...'
        _repr_running[call_key] = 1
        try:
            if not self:
                return '%s()' % (self.__class__.__name__,)
            return '%s(%r)' % (self.__class__.__name__, self.items())
        finally:
            del _repr_running[call_key]

    def __reduce__(self):
        'Return state information for pickling'
        items = [[k, self[k]] for k in self]
        inst_dict = vars(self).copy()
        for k in vars(OrderedDict()):
            inst_dict.pop(k, None)
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def copy(self):
        'od.copy() -> a shallow copy of od'
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
        and values equal to v (which defaults to None).

        '''
        dict_instance = cls()
        for key in iterable:
            dict_instance[key] = value
        return dict_instance

    def __eq__(self, other):
        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
        while comparison to a regular mapping is order-insensitive.

        '''
        if isinstance(other, OrderedDict):
            return len(self) == len(other) and self.items() == other.items()
        return dict.__eq__(self, other)

    def __ne__(self, other):
        return not self == other

    # -- the following methods are only used in Python 2.7 --

    def viewkeys(self):
        "od.viewkeys() -> a set-like object providing a view on od's keys"
        return KeysView(self)

    def viewvalues(self):
        "od.viewvalues() -> an object providing a view on od's values"
        return ValuesView(self)

    def viewitems(self):
        "od.viewitems() -> a set-like object providing a view on od's items"
        return ItemsView(self)

########NEW FILE########
__FILENAME__ = decoder
"""Implementation of JSONDecoder
"""
import re
import sys
import struct

from scanner import make_scanner


def _import_c_scanstring():
    try:
        from _speedups import scanstring
        return scanstring
    except ImportError:
        return None
c_scanstring = _import_c_scanstring()

__all__ = ['JSONDecoder']

FLAGS = re.VERBOSE | re.MULTILINE | re.DOTALL


def _floatconstants():
    _BYTES = '7FF80000000000007FF0000000000000'.decode('hex')
    # The struct module in Python 2.4 would get frexp() out of range here
    # when an endian is specified in the format string. Fixed in Python 2.5+
    if sys.byteorder != 'big':
        _BYTES = _BYTES[:8][::-1] + _BYTES[8:][::-1]
    nan, inf = struct.unpack('dd', _BYTES)
    return nan, inf, -inf

NaN, PosInf, NegInf = _floatconstants()


class JSONDecodeError(ValueError):

    """Subclass of ValueError with the following additional properties:

    msg: The unformatted error message
    doc: The JSON document being parsed
    pos: The start index of doc where parsing failed
    end: The end index of doc where parsing failed (may be None)
    lineno: The line corresponding to pos
    colno: The column corresponding to pos
    endlineno: The line corresponding to end (may be None)
    endcolno: The column corresponding to end (may be None)

    """

    def __init__(self, msg, doc, pos, end=None):
        ValueError.__init__(self, errmsg(msg, doc, pos, end=end))
        self.msg = msg
        self.doc = doc
        self.pos = pos
        self.end = end
        self.lineno, self.colno = linecol(doc, pos)
        if end is not None:
            self.endlineno, self.endcolno = linecol(doc, pos)
        else:
            self.endlineno, self.endcolno = None, None


def linecol(doc, pos):
    lineno = doc.count('\n', 0, pos) + 1
    if lineno == 1:
        colno = pos
    else:
        colno = pos - doc.rindex('\n', 0, pos)
    return lineno, colno


def errmsg(msg, doc, pos, end=None):
    # Note that this function is called from _speedups
    lineno, colno = linecol(doc, pos)
    if end is None:
        #fmt = '{0}: line {1} column {2} (char {3})'
        # return fmt.format(msg, lineno, colno, pos)
        fmt = '%s: line %d column %d (char %d)'
        return fmt % (msg, lineno, colno, pos)
    endlineno, endcolno = linecol(doc, end)
    #fmt = '{0}: line {1} column {2} - line {3} column {4} (char {5} - {6})'
    # return fmt.format(msg, lineno, colno, endlineno, endcolno, pos, end)
    fmt = '%s: line %d column %d - line %d column %d (char %d - %d)'
    return fmt % (msg, lineno, colno, endlineno, endcolno, pos, end)


_CONSTANTS = {
    '-Infinity': NegInf,
    'Infinity': PosInf,
    'NaN': NaN,
}

STRINGCHUNK = re.compile(r'(.*?)(["\\\x00-\x1f])', FLAGS)
BACKSLASH = {
    '"': u'"', '\\': u'\\', '/': u'/',
    'b': u'\b', 'f': u'\f', 'n': u'\n', 'r': u'\r', 't': u'\t',
}

DEFAULT_ENCODING = "utf-8"


def py_scanstring(s, end, encoding=None, strict=True,
                  _b=BACKSLASH, _m=STRINGCHUNK.match):
    """Scan the string s for a JSON string. End is the index of the
    character in s after the quote that started the JSON string.
    Unescapes all valid JSON string escape sequences and raises ValueError
    on attempt to decode an invalid string. If strict is False then literal
    control characters are allowed in the string.

    Returns a tuple of the decoded string and the index of the character in s
    after the end quote."""
    if encoding is None:
        encoding = DEFAULT_ENCODING
    chunks = []
    _append = chunks.append
    begin = end - 1
    while 1:
        chunk = _m(s, end)
        if chunk is None:
            raise JSONDecodeError(
                "Unterminated string starting at", s, begin)
        end = chunk.end()
        content, terminator = chunk.groups()
        # Content is contains zero or more unescaped string characters
        if content:
            if not isinstance(content, unicode):
                content = unicode(content, encoding)
            _append(content)
        # Terminator is the end of string, a literal control character,
        # or a backslash denoting that an escape sequence follows
        if terminator == '"':
            break
        elif terminator != '\\':
            if strict:
                msg = "Invalid control character %r at" % (terminator,)
                #msg = "Invalid control character {0!r} at".format(terminator)
                raise JSONDecodeError(msg, s, end)
            else:
                _append(terminator)
                continue
        try:
            esc = s[end]
        except IndexError:
            raise JSONDecodeError(
                "Unterminated string starting at", s, begin)
        # If not a unicode escape sequence, must be in the lookup table
        if esc != 'u':
            try:
                char = _b[esc]
            except KeyError:
                msg = "Invalid \\escape: " + repr(esc)
                raise JSONDecodeError(msg, s, end)
            end += 1
        else:
            # Unicode escape sequence
            esc = s[end + 1:end + 5]
            next_end = end + 5
            if len(esc) != 4:
                msg = "Invalid \\uXXXX escape"
                raise JSONDecodeError(msg, s, end)
            uni = int(esc, 16)
            # Check for surrogate pair on UCS-4 systems
            if 0xd800 <= uni <= 0xdbff and sys.maxunicode > 65535:
                msg = "Invalid \\uXXXX\\uXXXX surrogate pair"
                if not s[end + 5:end + 7] == '\\u':
                    raise JSONDecodeError(msg, s, end)
                esc2 = s[end + 7:end + 11]
                if len(esc2) != 4:
                    raise JSONDecodeError(msg, s, end)
                uni2 = int(esc2, 16)
                uni = 0x10000 + (((uni - 0xd800) << 10) | (uni2 - 0xdc00))
                next_end += 6
            char = unichr(uni)
            end = next_end
        # Append the unescaped character
        _append(char)
    return u''.join(chunks), end


# Use speedup if available
scanstring = c_scanstring or py_scanstring

WHITESPACE = re.compile(r'[ \t\n\r]*', FLAGS)
WHITESPACE_STR = ' \t\n\r'


def JSONObject((s, end), encoding, strict, scan_once, object_hook,
               object_pairs_hook, memo=None,
               _w=WHITESPACE.match, _ws=WHITESPACE_STR):
    # Backwards compatibility
    if memo is None:
        memo = {}
    memo_get = memo.setdefault
    pairs = []
    # Use a slice to prevent IndexError from being raised, the following
    # check will raise a more specific ValueError if the string is empty
    nextchar = s[end:end + 1]
    # Normally we expect nextchar == '"'
    if nextchar != '"':
        if nextchar in _ws:
            end = _w(s, end).end()
            nextchar = s[end:end + 1]
        # Trivial empty object
        if nextchar == '}':
            if object_pairs_hook is not None:
                result = object_pairs_hook(pairs)
                return result, end
            pairs = {}
            if object_hook is not None:
                pairs = object_hook(pairs)
            return pairs, end + 1
        elif nextchar != '"':
            raise JSONDecodeError("Expecting property name", s, end)
    end += 1
    while True:
        key, end = scanstring(s, end, encoding, strict)
        key = memo_get(key, key)

        # To skip some function call overhead we optimize the fast paths where
        # the JSON key separator is ": " or just ":".
        if s[end:end + 1] != ':':
            end = _w(s, end).end()
            if s[end:end + 1] != ':':
                raise JSONDecodeError("Expecting : delimiter", s, end)

        end += 1

        try:
            if s[end] in _ws:
                end += 1
                if s[end] in _ws:
                    end = _w(s, end + 1).end()
        except IndexError:
            pass

        try:
            value, end = scan_once(s, end)
        except StopIteration:
            raise JSONDecodeError("Expecting object", s, end)
        pairs.append((key, value))

        try:
            nextchar = s[end]
            if nextchar in _ws:
                end = _w(s, end + 1).end()
                nextchar = s[end]
        except IndexError:
            nextchar = ''
        end += 1

        if nextchar == '}':
            break
        elif nextchar != ',':
            raise JSONDecodeError("Expecting , delimiter", s, end - 1)

        try:
            nextchar = s[end]
            if nextchar in _ws:
                end += 1
                nextchar = s[end]
                if nextchar in _ws:
                    end = _w(s, end + 1).end()
                    nextchar = s[end]
        except IndexError:
            nextchar = ''

        end += 1
        if nextchar != '"':
            raise JSONDecodeError("Expecting property name", s, end - 1)

    if object_pairs_hook is not None:
        result = object_pairs_hook(pairs)
        return result, end
    pairs = dict(pairs)
    if object_hook is not None:
        pairs = object_hook(pairs)
    return pairs, end


def JSONArray((s, end), scan_once, _w=WHITESPACE.match, _ws=WHITESPACE_STR):
    values = []
    nextchar = s[end:end + 1]
    if nextchar in _ws:
        end = _w(s, end + 1).end()
        nextchar = s[end:end + 1]
    # Look-ahead for trivial empty array
    if nextchar == ']':
        return values, end + 1
    _append = values.append
    while True:
        try:
            value, end = scan_once(s, end)
        except StopIteration:
            raise JSONDecodeError("Expecting object", s, end)
        _append(value)
        nextchar = s[end:end + 1]
        if nextchar in _ws:
            end = _w(s, end + 1).end()
            nextchar = s[end:end + 1]
        end += 1
        if nextchar == ']':
            break
        elif nextchar != ',':
            raise JSONDecodeError("Expecting , delimiter", s, end)

        try:
            if s[end] in _ws:
                end += 1
                if s[end] in _ws:
                    end = _w(s, end + 1).end()
        except IndexError:
            pass

    return values, end


class JSONDecoder(object):

    """Simple JSON <http://json.org> decoder

    Performs the following translations in decoding by default:

    +---------------+-------------------+
    | JSON          | Python            |
    +===============+===================+
    | object        | dict              |
    +---------------+-------------------+
    | array         | list              |
    +---------------+-------------------+
    | string        | unicode           |
    +---------------+-------------------+
    | number (int)  | int, long         |
    +---------------+-------------------+
    | number (real) | float             |
    +---------------+-------------------+
    | true          | True              |
    +---------------+-------------------+
    | false         | False             |
    +---------------+-------------------+
    | null          | None              |
    +---------------+-------------------+

    It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as
    their corresponding ``float`` values, which is outside the JSON spec.

    """

    def __init__(self, encoding=None, object_hook=None, parse_float=None,
                 parse_int=None, parse_constant=None, strict=True,
                 object_pairs_hook=None):
        """
        *encoding* determines the encoding used to interpret any
        :class:`str` objects decoded by this instance (``'utf-8'`` by
        default).  It has no effect when decoding :class:`unicode` objects.

        Note that currently only encodings that are a superset of ASCII work,
        strings of other encodings should be passed in as :class:`unicode`.

        *object_hook*, if specified, will be called with the result of every
        JSON object decoded and its return value will be used in place of the
        given :class:`dict`.  This can be used to provide custom
        deserializations (e.g. to support JSON-RPC class hinting).

        *object_pairs_hook* is an optional function that will be called with
        the result of any object literal decode with an ordered list of pairs.
        The return value of *object_pairs_hook* will be used instead of the
        :class:`dict`.  This feature can be used to implement custom decoders
        that rely on the order that the key and value pairs are decoded (for
        example, :func:`collections.OrderedDict` will remember the order of
        insertion). If *object_hook* is also defined, the *object_pairs_hook*
        takes priority.

        *parse_float*, if specified, will be called with the string of every
        JSON float to be decoded.  By default, this is equivalent to
        ``float(num_str)``. This can be used to use another datatype or parser
        for JSON floats (e.g. :class:`decimal.Decimal`).

        *parse_int*, if specified, will be called with the string of every
        JSON int to be decoded.  By default, this is equivalent to
        ``int(num_str)``.  This can be used to use another datatype or parser
        for JSON integers (e.g. :class:`float`).

        *parse_constant*, if specified, will be called with one of the
        following strings: ``'-Infinity'``, ``'Infinity'``, ``'NaN'``.  This
        can be used to raise an exception if invalid JSON numbers are
        encountered.

        *strict* controls the parser's behavior when it encounters an
        invalid control character in a string. The default setting of
        ``True`` means that unescaped control characters are parse errors, if
        ``False`` then control characters will be allowed in strings.

        """
        self.encoding = encoding
        self.object_hook = object_hook
        self.object_pairs_hook = object_pairs_hook
        self.parse_float = parse_float or float
        self.parse_int = parse_int or int
        self.parse_constant = parse_constant or _CONSTANTS.__getitem__
        self.strict = strict
        self.parse_object = JSONObject
        self.parse_array = JSONArray
        self.parse_string = scanstring
        self.memo = {}
        self.scan_once = make_scanner(self)

    def decode(self, s, _w=WHITESPACE.match):
        """Return the Python representation of ``s`` (a ``str`` or ``unicode``
        instance containing a JSON document)

        """
        obj, end = self.raw_decode(s, idx=_w(s, 0).end())
        end = _w(s, end).end()
        if end != len(s):
            raise JSONDecodeError("Extra data", s, end, len(s))
        return obj

    def raw_decode(self, s, idx=0):
        """Decode a JSON document from ``s`` (a ``str`` or ``unicode``
        beginning with a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.

        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.

        """
        try:
            obj, end = self.scan_once(s, idx)
        except StopIteration:
            raise JSONDecodeError("No JSON object could be decoded", s, idx)
        return obj, end

########NEW FILE########
__FILENAME__ = encoder
"""Implementation of JSONEncoder
"""
import re
from decimal import Decimal


def _import_speedups():
    try:
        from simplejson import _speedups
        return _speedups.encode_basestring_ascii, _speedups.make_encoder
    except ImportError:
        return None, None
c_encode_basestring_ascii, c_make_encoder = _import_speedups()

from decoder import PosInf

ESCAPE = re.compile(r'[\x00-\x1f\\"\b\f\n\r\t]')
ESCAPE_ASCII = re.compile(r'([\\"]|[^\ -~])')
HAS_UTF8 = re.compile(r'[\x80-\xff]')
ESCAPE_DCT = {
    '\\': '\\\\',
    '"': '\\"',
    '\b': '\\b',
    '\f': '\\f',
    '\n': '\\n',
    '\r': '\\r',
    '\t': '\\t',
}
for i in range(0x20):
    #ESCAPE_DCT.setdefault(chr(i), '\\u{0:04x}'.format(i))
    ESCAPE_DCT.setdefault(chr(i), '\\u%04x' % (i,))

FLOAT_REPR = repr


def encode_basestring(s):
    """Return a JSON representation of a Python string

    """
    if isinstance(s, str) and HAS_UTF8.search(s) is not None:
        s = s.decode('utf-8')

    def replace(match):
        return ESCAPE_DCT[match.group(0)]
    return u'"' + ESCAPE.sub(replace, s) + u'"'


def py_encode_basestring_ascii(s):
    """Return an ASCII-only JSON representation of a Python string

    """
    if isinstance(s, str) and HAS_UTF8.search(s) is not None:
        s = s.decode('utf-8')

    def replace(match):
        s = match.group(0)
        try:
            return ESCAPE_DCT[s]
        except KeyError:
            n = ord(s)
            if n < 0x10000:
                # return '\\u{0:04x}'.format(n)
                return '\\u%04x' % (n,)
            else:
                # surrogate pair
                n -= 0x10000
                s1 = 0xd800 | ((n >> 10) & 0x3ff)
                s2 = 0xdc00 | (n & 0x3ff)
                # return '\\u{0:04x}\\u{1:04x}'.format(s1, s2)
                return '\\u%04x\\u%04x' % (s1, s2)
    return '"' + str(ESCAPE_ASCII.sub(replace, s)) + '"'


encode_basestring_ascii = (
    c_encode_basestring_ascii or py_encode_basestring_ascii)


class JSONEncoder(object):

    """Extensible JSON <http://json.org> encoder for Python data structures.

    Supports the following objects and types by default:

    +-------------------+---------------+
    | Python            | JSON          |
    +===================+===============+
    | dict              | object        |
    +-------------------+---------------+
    | list, tuple       | array         |
    +-------------------+---------------+
    | str, unicode      | string        |
    +-------------------+---------------+
    | int, long, float  | number        |
    +-------------------+---------------+
    | True              | true          |
    +-------------------+---------------+
    | False             | false         |
    +-------------------+---------------+
    | None              | null          |
    +-------------------+---------------+

    To extend this to recognize other objects, subclass and implement a
    ``.default()`` method with another method that returns a serializable
    object for ``o`` if possible, otherwise it should call the superclass
    implementation (to raise ``TypeError``).

    """
    item_separator = ', '
    key_separator = ': '

    def __init__(self, skipkeys=False, ensure_ascii=True,
                 check_circular=True, allow_nan=True, sort_keys=False,
                 indent=None, separators=None, encoding='utf-8', default=None,
                 use_decimal=False):
        """Constructor for JSONEncoder, with sensible defaults.

        If skipkeys is false, then it is a TypeError to attempt
        encoding of keys that are not str, int, long, float or None.  If
        skipkeys is True, such items are simply skipped.

        If ensure_ascii is true, the output is guaranteed to be str
        objects with all incoming unicode characters escaped.  If
        ensure_ascii is false, the output will be unicode object.

        If check_circular is true, then lists, dicts, and custom encoded
        objects will be checked for circular references during encoding to
        prevent an infinite recursion (which would cause an OverflowError).
        Otherwise, no such check takes place.

        If allow_nan is true, then NaN, Infinity, and -Infinity will be
        encoded as such.  This behavior is not JSON specification compliant,
        but is consistent with most JavaScript based encoders and decoders.
        Otherwise, it will be a ValueError to encode such floats.

        If sort_keys is true, then the output of dictionaries will be
        sorted by key; this is useful for regression tests to ensure
        that JSON serializations can be compared on a day-to-day basis.

        If indent is a string, then JSON array elements and object members
        will be pretty-printed with a newline followed by that string repeated
        for each level of nesting. ``None`` (the default) selects the most compact
        representation without any newlines. For backwards compatibility with
        versions of simplejson earlier than 2.1.0, an integer is also accepted
        and is converted to a string with that many spaces.

        If specified, separators should be a (item_separator, key_separator)
        tuple.  The default is (', ', ': ').  To get the most compact JSON
        representation you should specify (',', ':') to eliminate whitespace.

        If specified, default is a function that gets called for objects
        that can't otherwise be serialized.  It should return a JSON encodable
        version of the object or raise a ``TypeError``.

        If encoding is not None, then all input strings will be
        transformed into unicode using that encoding prior to JSON-encoding.
        The default is UTF-8.

        If use_decimal is true (not the default), ``decimal.Decimal`` will
        be supported directly by the encoder. For the inverse, decode JSON
        with ``parse_float=decimal.Decimal``.

        """

        self.skipkeys = skipkeys
        self.ensure_ascii = ensure_ascii
        self.check_circular = check_circular
        self.allow_nan = allow_nan
        self.sort_keys = sort_keys
        self.use_decimal = use_decimal
        if isinstance(indent, (int, long)):
            indent = ' ' * indent
        self.indent = indent
        if separators is not None:
            self.item_separator, self.key_separator = separators
        if default is not None:
            self.default = default
        self.encoding = encoding

    # pylint: disable=E0202
    def default(self, o):
        """Implement this method in a subclass such that it returns
        a serializable object for ``o``, or calls the base implementation
        (to raise a ``TypeError``).

        For example, to support arbitrary iterators, you could
        implement default like this::

            def default(self, o):
                try:
                    iterable = iter(o)
                except TypeError:
                    pass
                else:
                    return list(iterable)
                return JSONEncoder.default(self, o)

        """
        raise TypeError(repr(o) + " is not JSON serializable")

    def encode(self, o):
        """Return a JSON string representation of a Python data structure.

        >>> from simplejson import JSONEncoder
        >>> JSONEncoder().encode({"foo": ["bar", "baz"]})
        '{"foo": ["bar", "baz"]}'

        """
        # This is for extremely simple cases and benchmarks.
        if isinstance(o, basestring):
            if isinstance(o, str):
                _encoding = self.encoding
                if (_encoding is not None
                        and not (_encoding == 'utf-8')):
                    o = o.decode(_encoding)
            if self.ensure_ascii:
                return encode_basestring_ascii(o)
            else:
                return encode_basestring(o)
        # This doesn't pass the iterator directly to ''.join() because the
        # exceptions aren't as detailed.  The list call should be roughly
        # equivalent to the PySequence_Fast that ''.join() would do.
        chunks = self.iterencode(o, _one_shot=True)
        if not isinstance(chunks, (list, tuple)):
            chunks = list(chunks)
        if self.ensure_ascii:
            return ''.join(chunks)
        else:
            return u''.join(chunks)

    def iterencode(self, o, _one_shot=False):
        """Encode the given object and yield each string
        representation as available.

        For example::

            for chunk in JSONEncoder().iterencode(bigobject):
                mysocket.write(chunk)

        """
        if self.check_circular:
            markers = {}
        else:
            markers = None
        if self.ensure_ascii:
            _encoder = encode_basestring_ascii
        else:
            _encoder = encode_basestring
        if self.encoding != 'utf-8':
            # pylint: disable=E0102
            def _encoder(o, _orig_encoder=_encoder, _encoding=self.encoding):
                if isinstance(o, str):
                    o = o.decode(_encoding)
                return _orig_encoder(o)

        def floatstr(o, allow_nan=self.allow_nan,
                     _repr=FLOAT_REPR, _inf=PosInf, _neginf=-PosInf):
            # Check for specials. Note that this type of test is processor
            # and/or platform-specific, so do tests which don't depend on
            # the internals.

            if o != o:
                text = 'NaN'
            elif o == _inf:
                text = 'Infinity'
            elif o == _neginf:
                text = '-Infinity'
            else:
                return _repr(o)

            if not allow_nan:
                raise ValueError(
                    "Out of range float values are not JSON compliant: " +
                    repr(o))

            return text

        key_memo = {}
        if (_one_shot and c_make_encoder is not None
                and not self.indent and not self.sort_keys):
            _iterencode = c_make_encoder(
                markers, self.default, _encoder, self.indent,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, self.allow_nan, key_memo, self.use_decimal)
        else:
            _iterencode = _make_iterencode(
                markers, self.default, _encoder, self.indent, floatstr,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, _one_shot, self.use_decimal)
        try:
            return _iterencode(o, 0)
        finally:
            key_memo.clear()


class JSONEncoderForHTML(JSONEncoder):

    """An encoder that produces JSON safe to embed in HTML.

    To embed JSON content in, say, a script tag on a web page, the
    characters &, < and > should be escaped. They cannot be escaped
    with the usual entities (e.g. &amp;) because they are not expanded
    within <script> tags.
    """

    def encode(self, o):
        # Override JSONEncoder.encode because it has hacks for
        # performance that make things more complicated.
        chunks = self.iterencode(o, True)
        if self.ensure_ascii:
            return ''.join(chunks)
        else:
            return u''.join(chunks)

    def iterencode(self, o, _one_shot=False):
        chunks = super(JSONEncoderForHTML, self).iterencode(o, _one_shot)
        for chunk in chunks:
            chunk = chunk.replace('&', '\\u0026')
            chunk = chunk.replace('<', '\\u003c')
            chunk = chunk.replace('>', '\\u003e')
            yield chunk


def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,
                     _key_separator, _item_separator, _sort_keys, _skipkeys, _one_shot,
                     _use_decimal,
                     # HACK: hand-optimized bytecode; turn globals into locals
                     False=False,
                     True=True,
                     ValueError=ValueError,
                     basestring=basestring,
                     Decimal=Decimal,
                     dict=dict,
                     float=float,
                     id=id,
                     int=int,
                     isinstance=isinstance,
                     list=list,
                     long=long,
                     str=str,
                     tuple=tuple,
                     ):

    def _iterencode_list(lst, _current_indent_level):
        if not lst:
            yield '[]'
            return
        if markers is not None:
            markerid = id(lst)
            if markerid in markers:
                raise ValueError("Circular reference detected")
            markers[markerid] = lst
        buf = '['
        if _indent is not None:
            _current_indent_level += 1
            newline_indent = '\n' + (_indent * _current_indent_level)
            separator = _item_separator + newline_indent
            buf += newline_indent
        else:
            newline_indent = None
            separator = _item_separator
        first = True
        for value in lst:
            if first:
                first = False
            else:
                buf = separator
            if isinstance(value, basestring):
                yield buf + _encoder(value)
            elif value is None:
                yield buf + 'null'
            elif value is True:
                yield buf + 'true'
            elif value is False:
                yield buf + 'false'
            elif isinstance(value, (int, long)):
                yield buf + str(value)
            elif isinstance(value, float):
                yield buf + _floatstr(value)
            elif _use_decimal and isinstance(value, Decimal):
                yield buf + str(value)
            else:
                yield buf
                if isinstance(value, (list, tuple)):
                    chunks = _iterencode_list(value, _current_indent_level)
                elif isinstance(value, dict):
                    chunks = _iterencode_dict(value, _current_indent_level)
                else:
                    chunks = _iterencode(value, _current_indent_level)
                for chunk in chunks:
                    yield chunk
        if newline_indent is not None:
            _current_indent_level -= 1
            yield '\n' + (_indent * _current_indent_level)
        yield ']'
        if markers is not None:
            del markers[markerid]

    def _iterencode_dict(dct, _current_indent_level):
        if not dct:
            yield '{}'
            return
        if markers is not None:
            markerid = id(dct)
            if markerid in markers:
                raise ValueError("Circular reference detected")
            markers[markerid] = dct
        yield '{'
        if _indent is not None:
            _current_indent_level += 1
            newline_indent = '\n' + (_indent * _current_indent_level)
            item_separator = _item_separator + newline_indent
            yield newline_indent
        else:
            newline_indent = None
            item_separator = _item_separator
        first = True
        if _sort_keys:
            items = dct.items()
            items.sort(key=lambda kv: kv[0])
        else:
            items = dct.iteritems()
        for key, value in items:
            if isinstance(key, basestring):
                pass
            # JavaScript is weakly typed for these, so it makes sense to
            # also allow them.  Many encoders seem to do something like this.
            elif isinstance(key, float):
                key = _floatstr(key)
            elif key is True:
                key = 'true'
            elif key is False:
                key = 'false'
            elif key is None:
                key = 'null'
            elif isinstance(key, (int, long)):
                key = str(key)
            elif _skipkeys:
                continue
            else:
                raise TypeError("key " + repr(key) + " is not a string")
            if first:
                first = False
            else:
                yield item_separator
            yield _encoder(key)
            yield _key_separator
            if isinstance(value, basestring):
                yield _encoder(value)
            elif value is None:
                yield 'null'
            elif value is True:
                yield 'true'
            elif value is False:
                yield 'false'
            elif isinstance(value, (int, long)):
                yield str(value)
            elif isinstance(value, float):
                yield _floatstr(value)
            elif _use_decimal and isinstance(value, Decimal):
                yield str(value)
            else:
                if isinstance(value, (list, tuple)):
                    chunks = _iterencode_list(value, _current_indent_level)
                elif isinstance(value, dict):
                    chunks = _iterencode_dict(value, _current_indent_level)
                else:
                    chunks = _iterencode(value, _current_indent_level)
                for chunk in chunks:
                    yield chunk
        if newline_indent is not None:
            _current_indent_level -= 1
            yield '\n' + (_indent * _current_indent_level)
        yield '}'
        if markers is not None:
            del markers[markerid]

    def _iterencode(o, _current_indent_level):
        if isinstance(o, basestring):
            yield _encoder(o)
        elif o is None:
            yield 'null'
        elif o is True:
            yield 'true'
        elif o is False:
            yield 'false'
        elif isinstance(o, (int, long)):
            yield str(o)
        elif isinstance(o, float):
            yield _floatstr(o)
        elif isinstance(o, (list, tuple)):
            for chunk in _iterencode_list(o, _current_indent_level):
                yield chunk
        elif isinstance(o, dict):
            for chunk in _iterencode_dict(o, _current_indent_level):
                yield chunk
        elif _use_decimal and isinstance(o, Decimal):
            yield str(o)
        else:
            if markers is not None:
                markerid = id(o)
                if markerid in markers:
                    raise ValueError("Circular reference detected")
                markers[markerid] = o
            o = _default(o)
            for chunk in _iterencode(o, _current_indent_level):
                yield chunk
            if markers is not None:
                del markers[markerid]

    return _iterencode

########NEW FILE########
__FILENAME__ = ordered_dict
"""Drop-in replacement for collections.OrderedDict by Raymond Hettinger

http://code.activestate.com/recipes/576693/

"""
from UserDict import DictMixin

# Modified from original to support Python 2.4, see
# http://code.google.com/p/simplejson/issues/detail?id=53
try:
    all
except NameError:
    def all(seq):
        for elem in seq:
            if not elem:
                return False
        return True


class OrderedDict(dict, DictMixin):

    def __init__(self, *args, **kwds):
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))
        try:
            self.__end
        except AttributeError:
            self.clear()
        self.update(*args, **kwds)

    def clear(self):
        self.__end = end = []
        end += [None, end, end]         # sentinel node for doubly linked list
        self.__map = {}                 # key --> [key, prev, next]
        dict.clear(self)

    def __setitem__(self, key, value):
        if key not in self:
            end = self.__end
            curr = end[1]
            curr[2] = end[1] = self.__map[key] = [key, curr, end]
        dict.__setitem__(self, key, value)

    def __delitem__(self, key):
        dict.__delitem__(self, key)
        key, prev, next = self.__map.pop(key)
        prev[2] = next
        next[1] = prev

    def __iter__(self):
        end = self.__end
        curr = end[2]
        while curr is not end:
            yield curr[0]
            curr = curr[2]

    def __reversed__(self):
        end = self.__end
        curr = end[1]
        while curr is not end:
            yield curr[0]
            curr = curr[1]

    def popitem(self, last=True):
        if not self:
            raise KeyError('dictionary is empty')
        # Modified from original to support Python 2.4, see
        # http://code.google.com/p/simplejson/issues/detail?id=53
        if last:
            # pylint: disable=E0111
            key = reversed(self).next()
        else:
            key = iter(self).next()
        value = self.pop(key)
        return key, value

    def __reduce__(self):
        items = [[k, self[k]] for k in self]
        tmp = self.__map, self.__end
        del self.__map, self.__end
        inst_dict = vars(self).copy()
        self.__map, self.__end = tmp
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def keys(self):
        return list(self)

    setdefault = DictMixin.setdefault
    update = DictMixin.update
    pop = DictMixin.pop
    values = DictMixin.values
    items = DictMixin.items
    iterkeys = DictMixin.iterkeys
    itervalues = DictMixin.itervalues
    iteritems = DictMixin.iteritems

    def __repr__(self):
        if not self:
            return '%s()' % (self.__class__.__name__,)
        return '%s(%r)' % (self.__class__.__name__, self.items())

    def copy(self):
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        d = cls()
        for key in iterable:
            d[key] = value
        return d

    def __eq__(self, other):
        if isinstance(other, OrderedDict):
            return len(self) == len(other) and \
                all(p == q for p, q in zip(self.items(), other.items()))
        return dict.__eq__(self, other)

    def __ne__(self, other):
        return not self == other

########NEW FILE########
__FILENAME__ = scanner
"""JSON token scanner
"""
import re


def _import_c_make_scanner():
    try:
        from _speedups import make_scanner
        return make_scanner
    except ImportError:
        return None
c_make_scanner = _import_c_make_scanner()

__all__ = ['make_scanner']

NUMBER_RE = re.compile(
    r'(-?(?:0|[1-9]\d*))(\.\d+)?([eE][-+]?\d+)?',
    (re.VERBOSE | re.MULTILINE | re.DOTALL))


def py_make_scanner(context):
    parse_object = context.parse_object
    parse_array = context.parse_array
    parse_string = context.parse_string
    match_number = NUMBER_RE.match
    encoding = context.encoding
    strict = context.strict
    parse_float = context.parse_float
    parse_int = context.parse_int
    parse_constant = context.parse_constant
    object_hook = context.object_hook
    object_pairs_hook = context.object_pairs_hook
    memo = context.memo

    def _scan_once(string, idx):
        try:
            nextchar = string[idx]
        except IndexError:
            raise StopIteration

        if nextchar == '"':
            return parse_string(string, idx + 1, encoding, strict)
        elif nextchar == '{':
            return parse_object((string, idx + 1), encoding, strict,
                                _scan_once, object_hook, object_pairs_hook, memo)
        elif nextchar == '[':
            return parse_array((string, idx + 1), _scan_once)
        elif nextchar == 'n' and string[idx:idx + 4] == 'null':
            return None, idx + 4
        elif nextchar == 't' and string[idx:idx + 4] == 'true':
            return True, idx + 4
        elif nextchar == 'f' and string[idx:idx + 5] == 'false':
            return False, idx + 5

        m = match_number(string, idx)
        if m is not None:
            integer, frac, exp = m.groups()
            if frac or exp:
                res = parse_float(integer + (frac or '') + (exp or ''))
            else:
                res = parse_int(integer)
            return res, m.end()
        elif nextchar == 'N' and string[idx:idx + 3] == 'NaN':
            return parse_constant('NaN'), idx + 3
        elif nextchar == 'I' and string[idx:idx + 8] == 'Infinity':
            return parse_constant('Infinity'), idx + 8
        elif nextchar == '-' and string[idx:idx + 9] == '-Infinity':
            return parse_constant('-Infinity'), idx + 9
        else:
            raise StopIteration

    def scan_once(string, idx):
        try:
            return _scan_once(string, idx)
        finally:
            memo.clear()

    return scan_once

make_scanner = c_make_scanner or py_make_scanner

########NEW FILE########
__FILENAME__ = tool
r"""Command-line tool to validate and pretty-print JSON

Usage::

    $ echo '{"json":"obj"}' | python -m simplejson.tool
    {
        "json": "obj"
    }
    $ echo '{ 1.2:3.4}' | python -m simplejson.tool
    Expecting property name: line 1 column 2 (char 2)

"""
import sys
import simplejson as json


def main():
    if len(sys.argv) == 1:
        infile = sys.stdin
        outfile = sys.stdout
    elif len(sys.argv) == 2:
        infile = open(sys.argv[1], 'rb')
        outfile = sys.stdout
    elif len(sys.argv) == 3:
        infile = open(sys.argv[1], 'rb')
        outfile = open(sys.argv[2], 'wb')
    else:
        raise SystemExit(sys.argv[0] + " [infile [outfile]]")
    try:
        obj = json.load(infile,
                        object_pairs_hook=json.OrderedDict,
                        use_decimal=True)
    except ValueError, e:
        raise SystemExit(e)
    json.dump(obj, outfile, sort_keys=True, indent='    ', use_decimal=True)
    outfile.write('\n')


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = _itertools
"""
This module contains some itertools functions people have been using in
virt-test that are not present in python 2.4, the minimum supported version.
"""


def product(*args, **kwds):
    """
    (virt-test backport)
    Cartesian product of input iterables. Equivalent to nested for-loops.

    For example, product(A, B) returns the same as:  ((x,y) for x in A for y in B).
    The leftmost iterators are in the outermost for-loop, so the output tuples
    cycle in a manner similar to an odometer (with the rightmost element changing
    on every iteration).

    To compute the product of an iterable with itself, specify the number
    of repetitions with the optional repeat keyword argument. For example,
    product(A, repeat=4) means the same as product(A, A, A, A).

    product('ab', range(3)) --> ('a',0) ('a',1) ('a',2) ('b',0) ('b',1) ('b',2)
    product((0,1), (0,1), (0,1)) --> (0,0,0) (0,0,1) (0,1,0) (0,1,1) (1,0,0) ...
    """
    # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
    pools = map(tuple, args) * kwds.get('repeat', 1)
    result = [[]]
    for pool in pools:
        result = [x + [y] for x in result for y in pool]
    for prod in result:
        yield tuple(prod)

########NEW FILE########
__FILENAME__ = lv_utils
"""
Utilities to create logical volumes or take snapshots of existing ones.

:author: Plamen Dimitrov
:copyright: Intra2net AG 2012
:license: GPL v2

:param vg_name: Name of the volume group.
:param lv_name: Name of the logical volume.
:param lv_size: Size of the logical volume as string in the form "#G"
                (for example 30G).
:param lv_snapshot_name: Name of the snapshot with origin the logical
                         volume.
:param lv_snapshot_size: Size of the snapshot with origin the logical
                         volume also as "#G".
:param ramdisk_vg_size: Size of the ramdisk virtual group.
:param ramdisk_basedir: Base directory for the ramdisk sparse file.
:param ramdisk_sparse_filename: Name of the ramdisk sparse file.

Sample ramdisk params:

::

    ramdisk_vg_size = "40000"
    ramdisk_basedir = "/tmp"
    ramdisk_sparse_filename = "virtual_hdd"

Sample general params:

::

    vg_name='autotest_vg',
    lv_name='autotest_lv',
    lv_size='1G',
    lv_snapshot_name='autotest_sn',
    lv_snapshot_size='1G'

The ramdisk volume group size is in MB.
"""

import logging
import re
import os
import shutil
import time

from autotest.client import utils
from autotest.client.shared import error


@error.context_aware
def vg_ramdisk(vg_name, ramdisk_vg_size,
               ramdisk_basedir, ramdisk_sparse_filename):
    """
    Create vg on top of ram memory to speed up lv performance.
    """
    error.context("Creating virtual group on top of ram memory",
                  logging.info)
    vg_size = ramdisk_vg_size
    vg_ramdisk_dir = os.path.join(ramdisk_basedir, vg_name)
    ramdisk_filename = os.path.join(vg_ramdisk_dir,
                                    ramdisk_sparse_filename)

    vg_ramdisk_cleanup(ramdisk_filename,
                       vg_ramdisk_dir, vg_name, "")
    result = ""
    if not os.path.exists(vg_ramdisk_dir):
        os.mkdir(vg_ramdisk_dir)
    try:
        logging.info("Mounting tmpfs")
        result = utils.run("mount -t tmpfs tmpfs " + vg_ramdisk_dir)

        logging.info("Converting and copying /dev/zero")
        cmd = ("dd if=/dev/zero of=" + ramdisk_filename +
               " bs=1M count=1 seek=" + vg_size)
        result = utils.run(cmd, verbose=True)

        logging.info("Finding free loop device")
        result = utils.run("losetup --find", verbose=True)
    except error.CmdError, ex:
        logging.error(ex)
        vg_ramdisk_cleanup(ramdisk_filename,
                           vg_ramdisk_dir, vg_name, "")
        raise ex

    loop_device = result.stdout.rstrip()

    try:
        logging.info("Creating loop device")
        result = utils.run("losetup " + loop_device + " " + ramdisk_filename)
        logging.info("Creating physical volume %s", loop_device)
        result = utils.run("pvcreate " + loop_device)
        logging.info("Creating volume group %s", vg_name)
        result = utils.run("vgcreate " + vg_name + " " + loop_device)
    except error.CmdError, ex:
        logging.error(ex)
        vg_ramdisk_cleanup(ramdisk_filename, vg_ramdisk_dir, vg_name,
                           loop_device)
        raise ex

    logging.info(result.stdout.rstrip())


def vg_ramdisk_cleanup(ramdisk_filename, vg_ramdisk_dir,
                       vg_name, loop_device):
    """
    Inline cleanup function in case of test error.
    """
    result = utils.run("vgremove " + vg_name, ignore_status=True)
    if result.exit_status == 0:
        logging.info(result.stdout.rstrip())
    else:
        logging.debug("%s -> %s", result.command, result.stderr)

    result = utils.run("pvremove " + loop_device, ignore_status=True)
    if result.exit_status == 0:
        logging.info(result.stdout.rstrip())
    else:
        logging.debug("%s -> %s", result.command, result.stderr)

    for _ in range(10):
        time.sleep(0.1)
        result = utils.run("losetup -d " + loop_device, ignore_status=True)
        if "resource busy" not in result.stderr:
            if result.exit_status != 0:
                logging.debug("%s -> %s", result.command, result.stderr)
            else:
                logging.info("Loop device %s deleted", loop_device)
            break

    if os.path.exists(ramdisk_filename):
        os.unlink(ramdisk_filename)
        logging.info("Ramdisk filename %s deleted", ramdisk_filename)

    utils.run("umount " + vg_ramdisk_dir, ignore_status=True)
    if result.exit_status == 0:
        if loop_device != "":
            logging.info("Loop device %s unmounted", loop_device)
    else:
        logging.debug("%s -> %s", result.command, result.stderr)

    if os.path.exists(vg_ramdisk_dir):
        try:
            shutil.rmtree(vg_ramdisk_dir)
            logging.info("Ramdisk directory %s deleted", vg_ramdisk_dir)
        except OSError:
            pass


def vg_check(vg_name):
    """
    Check whether provided volume group exists.
    """
    cmd = "vgdisplay " + vg_name
    try:
        utils.run(cmd)
        logging.debug("Provided volume group exists: " + vg_name)
        return True
    except error.CmdError:
        return False


def vg_list():
    """
    List available volume groups.
    """
    cmd = "vgs --all"
    vgroups = {}
    result = utils.run(cmd)

    lines = result.stdout.strip().splitlines()
    if len(lines) > 1:
        columns = lines[0].split()
        lines = lines[1:]
    else:
        return vgroups

    for line in lines:
        details = line.split()
        details_dict = {}
        index = 0
        for column in columns:
            if re.search("VG", column):
                vg_name = details[index]
            else:
                details_dict[column] = details[index]
            index += 1
        vgroups[vg_name] = details_dict
    return vgroups


@error.context_aware
def vg_create(vg_name, pv_list):
    """
    Create a volume group by using the block special devices
    """
    error.context(
        "Creating volume group '%s' by using '%s'" %
        (vg_name, pv_list), logging.info)

    if vg_check(vg_name):
        raise error.TestError("Volume group '%s' already exist" % vg_name)
    cmd = "vgcreate %s %s" % (vg_name, pv_list)
    result = utils.run(cmd)
    logging.info(result.stdout.rstrip())


@error.context_aware
def vg_remove(vg_name):
    """
    Remove a volume group.
    """
    error.context("Removing volume '%s'" % vg_name, logging.info)

    if not vg_check(vg_name):
        raise error.TestError("Volume group '%s' could not be found" % vg_name)
    cmd = "vgremove -f %s" % vg_name
    result = utils.run(cmd)
    logging.info(result.stdout.rstrip())


def lv_check(vg_name, lv_name):
    """
    Check whether provided logical volume exists.
    """
    cmd = "lvdisplay"
    result = utils.run(cmd, ignore_status=True)

    # unstable approach but currently works
    lvpattern = r"LV Path\s+/dev/" + vg_name + r"/" + lv_name + "\s+"
    match = re.search(lvpattern, result.stdout.rstrip())
    if match:
        logging.debug("Provided logical volume exists: /dev/" +
                      vg_name + "/" + lv_name)
        return True
    else:
        return False


@error.context_aware
def lv_remove(vg_name, lv_name):
    """
    Remove a logical volume.
    """
    error.context("Removing volume /dev/%s/%s" %
                  (vg_name, lv_name), logging.info)

    if not vg_check(vg_name):
        raise error.TestError("Volume group could not be found")
    if not lv_check(vg_name, lv_name):
        raise error.TestError("Logical volume could not be found")

    cmd = "lvremove -f " + vg_name + "/" + lv_name
    result = utils.run(cmd)
    logging.info(result.stdout.rstrip())


@error.context_aware
def lv_create(vg_name, lv_name, lv_size, force_flag=True):
    """
    Create a logical volume in a volume group.

    The volume group must already exist.
    """
    error.context("Creating original lv to take a snapshot from",
                  logging.info)

    if not vg_check(vg_name):
        raise error.TestError("Volume group could not be found")
    if lv_check(vg_name, lv_name) and not force_flag:
        raise error.TestError("Logical volume already exists")
    elif lv_check(vg_name, lv_name) and force_flag:
        lv_remove(vg_name, lv_name)

    cmd = ("lvcreate --size " + lv_size + " --name " + lv_name + " " + vg_name)
    result = utils.run(cmd)
    logging.info(result.stdout.rstrip())


@error.context_aware
def lv_take_snapshot(vg_name, lv_name,
                     lv_snapshot_name, lv_snapshot_size):
    """
    Take a snapshot of the original logical volume.
    """
    error.context("Taking snapshot from original logical volume",
                  logging.info)

    if not vg_check(vg_name):
        raise error.TestError("Volume group could not be found")
    if lv_check(vg_name, lv_snapshot_name):
        raise error.TestError("Snapshot already exists")
    if not lv_check(vg_name, lv_name):
        raise error.TestError("Snapshot's origin could not be found")

    cmd = ("lvcreate --size " + lv_snapshot_size + " --snapshot " +
           " --name " + lv_snapshot_name + " /dev/" + vg_name + "/" + lv_name)
    try:
        result = utils.run(cmd)
    except error.CmdError, ex:
        if ('Logical volume "%s" already exists in volume group "%s"' %
            (lv_snapshot_name, vg_name) in ex.result_obj.stderr and
            re.search(re.escape(lv_snapshot_name + " [active]"),
                      utils.run("lvdisplay").stdout)):
            # the above conditions detect if merge of snapshot was postponed
            logging.warning(("Logical volume %s is still active! " +
                             "Attempting to deactivate..."), lv_name)
            lv_reactivate(vg_name, lv_name)
            result = utils.run(cmd)
        else:
            raise ex
    logging.info(result.stdout.rstrip())


@error.context_aware
def lv_revert(vg_name, lv_name, lv_snapshot_name):
    """
    Revert the origin to a snapshot.
    """
    error.context("Reverting original logical volume to snapshot",
                  logging.info)
    try:
        if not vg_check(vg_name):
            raise error.TestError("Volume group could not be found")
        if not lv_check(vg_name, lv_snapshot_name):
            raise error.TestError("Snapshot could not be found")
        if (not lv_check(vg_name, lv_snapshot_name)
                and not lv_check(vg_name, lv_name)):
            raise error.TestError("Snapshot and its origin could not be found")
        if (lv_check(vg_name, lv_snapshot_name)
                and not lv_check(vg_name, lv_name)):
            raise error.TestError("Snapshot origin could not be found")

        cmd = ("lvconvert --merge /dev/%s/%s" % (vg_name, lv_snapshot_name))
        result = utils.run(cmd)
        if ("Merging of snapshot %s will start next activation." %
                lv_snapshot_name) in result.stdout:
            raise error.TestError("The logical volume %s is still active" %
                                  lv_name)
        result = result.stdout.rstrip()

    except error.TestError, ex:
        # detect if merge of snapshot was postponed
        # and attempt to reactivate the volume.
        if (('Snapshot could not be found' in ex and
             re.search(re.escape(lv_snapshot_name + " [active]"),
                       utils.run("lvdisplay").stdout))
                or ("The logical volume %s is still active" % lv_name) in ex):
            logging.warning(("Logical volume %s is still active! " +
                             "Attempting to deactivate..."), lv_name)
            lv_reactivate(vg_name, lv_name)
            result = "Continuing after reactivation"
        elif 'Snapshot could not be found' in ex:
            logging.error(ex)
            result = "Could not revert to snapshot"
        else:
            raise ex
    logging.info(result)


@error.context_aware
def lv_revert_with_snapshot(vg_name, lv_name,
                            lv_snapshot_name, lv_snapshot_size):
    """
    Perform logical volume merge with snapshot and take a new snapshot.

    """
    error.context("Reverting to snapshot and taking a new one",
                  logging.info)

    lv_revert(vg_name, lv_name, lv_snapshot_name)
    lv_take_snapshot(vg_name, lv_name, lv_snapshot_name, lv_snapshot_size)


@error.context_aware
def lv_reactivate(vg_name, lv_name, timeout=10):
    """
    In case of unclean shutdowns some of the lvs is still active and merging
    is postponed. Use this function to attempt to deactivate and reactivate
    all of them to cause the merge to happen.
    """
    try:
        utils.run("lvchange -an /dev/%s/%s" % (vg_name, lv_name))
        time.sleep(timeout)
        utils.run("lvchange -ay /dev/%s/%s" % (vg_name, lv_name))
        time.sleep(timeout)
    except error.CmdError:
        logging.error(("Failed to reactivate %s - please, " +
                       "nuke the process that uses it first."), lv_name)
        raise error.TestError("The logical volume %s is still active" % lv_name)

########NEW FILE########
__FILENAME__ = service
#  Copyright(c) 2013 Intel Corporation.
#
#  This program is free software; you can redistribute it and/or modify it
#  under the terms and conditions of the GNU General Public License,
#  version 2, as published by the Free Software Foundation.
#
#  This program is distributed in the hope it will be useful, but WITHOUT
#  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
#  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
#  more details.
#
#  You should have received a copy of the GNU General Public License along with
#  this program; if not, write to the Free Software Foundation, Inc.,
#  51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
#
#  The full GNU General Public License is included in this distribution in
#  the file called "COPYING".

import os
import re
import logging

from autotest.client.shared import error
from tempfile import mktemp
from autotest.client import utils


_COMMAND_TABLE_DOC = """

Taken from http://fedoraproject.org/wiki/SysVinit_to_Systemd_Cheatsheet

service frobozz start
systemctl start frobozz.service
 Used to start a service (not reboot persistent)

service frobozz stop
systemctl stop frobozz.service
 Used to stop a service (not reboot persistent)

service frobozz restart
systemctl restart frobozz.service
 Used to stop and then start a service

service frobozz reload
systemctl reload frobozz.service
 When supported, reloads the config file without interrupting pending operations.

service frobozz condrestart
systemctl condrestart frobozz.service
 Restarts if the service is already running.

service frobozz status
systemctl status frobozz.service
 Tells whether a service is currently running.

ls /etc/rc.d/init.d/
systemctl list-unit-files --type=service (preferred)
 Used to list the services that can be started or stopped
ls /lib/systemd/system/*.service /etc/systemd/system/*.service
 Used to list all the services and other units

chkconfig frobozz on
systemctl enable frobozz.service
 Turn the service on, for start at next boot, or other trigger.

chkconfig frobozz off
systemctl disable frobozz.service
 Turn the service off for the next reboot, or any other trigger.

chkconfig frobozz
systemctl is-enabled frobozz.service
 Used to check whether a service is configured to start or not in the current environment.

chkconfig --list
systemctl list-unit-files --type=service(preferred)
ls /etc/systemd/system/*.wants/
 Print a table of services that lists which runlevels each is configured on or off

chkconfig frobozz --list
ls /etc/systemd/system/*.wants/frobozz.service
 Used to list what levels this service is configured on or off

chkconfig frobozz --add
systemctl daemon-reload
 Used when you create a new service file or modify any configuration


"""


def sys_v_init_result_parser(command):
    """
    Parse results from sys_v style commands.

    Valid commands:
        status:
            return true if service is running.
        is_enabled:
            return true if service is enabled.
        list:
            return a dict from service name to status.
        others:
            return true if operate success.

    :param command: command.
    :type command: str.
    :return: different from the command.
    """
    if command == "status":
        def method(cmdResult):
            """
            Parse method for service XXX status.

            Returns True if XXX is running.
            Returns False if XXX is stopped.
            Returns None if XXX is unrecognized.
            """
            # If service is stopped, exit_status is also not zero.
            # So, we can't use exit_status to check result.
            output = cmdResult.stdout.lower()
            # Returns None if XXX is unrecognized.
            if re.search(r"unrecognized", output):
                return None
            # Returns False if XXX is stopped.
            dead_flags = [r"stopped", r"not running", r"dead"]
            for flag in dead_flags:
                if re.search(flag, output):
                    return False
            # If output does not contain a dead flag, check it with "running".
            return bool(re.search(r"running", output))
        return method
    elif command == "list":
        def method(cmdResult):
            """
            Parse method for service XXX list.

            Return dict from service name to status.

            e.g:
                {"sshd": {0: 'off', 1: 'off', 2: 'off', 3: 'off', 4: 'off', 5: 'off', 6: 'off'},
                 "vsftpd": {0: 'off', 1: 'off', 2: 'off', 3: 'off', 4: 'off', 5: 'off', 6: 'off'},
                 "xinetd": {'discard-dgram:': 'off', 'rsync:': 'off'...'chargen-stream:': 'off'},
                 ...
                 }
            """
            if cmdResult.exit_status:
                raise error.CmdError(cmdResult.command, cmdResult)
            # The final dict to return.
            _service2statusOnTarget_dict = {}
            # Dict to store status on every target for each service.
            _status_on_target = {}
            # Dict to store the status for service based on xinetd.
            _service2statusOnXinet_dict = {}
            lines = cmdResult.stdout.strip().splitlines()
            for line in lines:
                sublines = line.strip().split()
                if len(sublines) == 8:
                    # Service and status on each target.
                    service_name = sublines[0]
                    # Store the status of each target in _status_on_target.
                    for target in range(7):
                        status = sublines[target + 1].split(":")[-1]
                        _status_on_target[target] = status
                    _service2statusOnTarget_dict[
                        service_name] = _status_on_target.copy()

                elif len(sublines) == 2:
                    # Service based on xinetd.
                    service_name = sublines[0].strip(":")
                    status = sublines[-1]
                    _service2statusOnXinet_dict[service_name] = status

                else:
                    # Header or some lines useless.
                    continue
            # Add xinetd based service in the main dict.
            _service2statusOnTarget_dict[
                "xinetd"] = _service2statusOnXinet_dict
            return _service2statusOnTarget_dict
        return method
    else:
        return _ServiceResultParser.default_method


def systemd_result_parser(command):
    """
    Parse results from systemd style commands.

    Valid commands:
        status:
            return true if service is running.
        is_enabled:
            return true if service is enabled.
        list:
            return a dict from service name to status.
        others:
            return true if operate success.

    :param command: command.
    :type command: str.
    :return: different from the command.
    """
    if command == "status":
        def method(cmdResult):
            """
            Parse method for systemctl status XXX.service.

            Returns True if XXX.service is running.
            Returns False if XXX.service is stopped.
            Returns None if XXX.service is not loaded.
            """
            # If service is stopped, exit_status is also not zero.
            # So, we can't use exit_status to check result.
            output = cmdResult.stdout
            # Returns None if XXX is not loaded.
            if not re.search(r"Loaded: loaded", output):
                return None
            # Check it with Active status.
            return (output.count("Active: active") > 0)
        return method
    elif command == "list":
        def method(cmdResult):
            """
            Parse method for systemctl list XXX.service.

            Return a dict from service name to status.

            e.g:
                {"sshd": "enabled",
                 "vsftpd": "disabled",
                 "systemd-sysctl": "static",
                 ...
                 }
            """
            if cmdResult.exit_status:
                raise error.CmdError(cmdResult.command, cmdResult)
            # Dict to store service name to status.
            _service2status_dict = {}
            lines = cmdResult.stdout.strip().splitlines()
            for line in lines:
                sublines = line.strip().split()
                if (not len(sublines) == 2) or (not sublines[0].endswith("service")):
                    # Some lines useless.
                    continue
                service_name = sublines[0].rstrip(".service")
                status = sublines[-1]
                _service2status_dict[service_name] = status
            return _service2status_dict
        return method
    else:
        return _ServiceResultParser.default_method


def sys_v_init_command_generator(command):
    """
    Generate lists of command arguments for sys_v style inits.

    :param command: start,stop,restart, etc.
    :type command: str
    :return: list of commands to pass to utils.run or similar function
    :rtype: list
    """
    command_name = "service"
    if command == "is_enabled":
        command_name = "chkconfig"
        command = ""
    elif command == 'enable':
        command_name = "chkconfig"
        command = "on"
    elif command == 'disable':
        command_name = "chkconfig"
        command = "off"
    elif command == 'list':
        # noinspection PyUnusedLocal
        def list_command(service_name):
            return ["chkconfig", "--list"]
        return list_command
    elif command == "set_target":
        def set_target_command(target):
            target = convert_systemd_target_to_runlevel(target)
            return ["telinit", target]
        return set_target_command

    def method(service_name):
        return [command_name, service_name, command]
    return method


def systemd_command_generator(command):
    """
    Generate list of command line argument strings for systemctl.
    One argument per string for compatibility Popen

    WARNING: If systemctl detects that it is running on a tty it will use color,
    pipe to $PAGER, change column sizes and not truncate unit names.
    Use --no-pager to suppress pager output, or set PAGER=cat in the environment.
    You may need to take other steps to suppress color output.
    See https://bugzilla.redhat.com/show_bug.cgi?id=713567

    :param command: start,stop,restart, etc.
    :type command: str
    :return: list of command and arguments to pass to utils.run or similar functions
    :rtype: list
    """
    command_name = "systemctl"
    if command == "is_enabled":
        command = "is-enabled"
    elif command == "list":
        # noinspection PyUnusedLocal
        def list_command(service_name):
            # systemctl pipes to `less` or $PAGER by default. Workaround this
            # add '--full' to avoid systemctl truncates service names.
            return [command_name, "list-unit-files",
                    "--type=service", "--no-pager", "--full"]
        return list_command
    elif command == "set_target":
        def set_target_command(target):
            return [command_name, "isolate", target]
        return set_target_command

    def method(service_name):
        return [command_name, command, "%s.service" % service_name]
    return method


COMMANDS = (
    "start",
    "stop",
    "reload",
    "restart",
    "condrestart",
    "status",
    "enable",
    "disable",
    "is_enabled",
    "list",
    "set_target",
)


class _ServiceResultParser(object):

    """
    A class that contains staticmethods to parse the result of service command.
    """

    def __init__(self, result_parser, command_list=COMMANDS):
        """
            Create staticmethods for each command in command_list using setattr and the
            result_parser

            :param result_parser: function that generates functions that parse the result of command.
            :type result_parser: function
            :param command_list: list of all the commands, e.g. start, stop, restart, etc.
            :type command_list: list
        """
        self.commands = command_list
        for command in self.commands:
            setattr(self, command, result_parser(command))

    @staticmethod
    def default_method(cmdResult):
        """
        Default method to parse result from command which is not 'list' nor 'status'.

        Returns True if command was executed successfully.
        """
        if cmdResult.exit_status:
            logging.debug(cmdResult)
            return False
        else:
            return True


class _ServiceCommandGenerator(object):

    """
    A class that contains staticmethods that generate partial functions that
    generate command lists for starting/stopping services.
    """

    def __init__(self, command_generator, command_list=COMMANDS):
        """
            Create staticmethods for each command in command_list using setattr and the
            command_generator

            :param command_generator: function that generates functions that generate lists of command strings
            :type command_generator: function
            :param command_list: list of all the commands, e.g. start, stop, restart, etc.
            :type command_list: list
        """
        self.commands = command_list
        for command in self.commands:
            setattr(self, command, command_generator(command))


class _SpecificServiceManager(object):

    def __init__(self, service_name, service_command_generator, service_result_parser, run=utils.run):
        """
        Create staticmethods that call utils.run with the given service_name
        for each command in service_command_generator.

        lldpad = SpecificServiceManager("lldpad",
                                        auto_create_specific_service_command_generator())
        lldpad.start()
        lldpad.stop()

        :param service_name: init service name or systemd unit name
        :type service_name: str
        :param service_command_generator: a sys_v_init or systemd command generator
        :type service_command_generator: _ServiceCommandGenerator
        :param run: function that executes the commands and return CmdResult object, default utils.run
        :type run: function
        """
        for cmd in service_command_generator.commands:
            setattr(self, cmd,
                    self.generate_run_function(run,
                                               getattr(
                                                   service_result_parser, cmd),
                                               getattr(
                                                   service_command_generator, cmd),
                                               service_name))

    @staticmethod
    def generate_run_function(run_func, parse_func, command, service_name):
        """
        Generate the wrapped call to utils.run for the given service_name.

        :param run_func:  function to execute command and return CmdResult object.
        :type run_func:  function
        :param parse_func: function to parse the result from run.
        :type parse_func: function
        :param command: partial function that generates the command list
        :type command: function
        :param service_name: init service name or systemd unit name
        :type service_name: str
        :return: wrapped utils.run function.
        :rtype: function
        """
        def run(**kwargs):
            """
            Wrapped utils.run invocation that will start, stop, restart, etc. a service.

            :param kwargs: extra arguments to utils.run, .e.g. timeout. But not for ignore_status.
                           We need a CmdResult to parse and raise a error.TestError if command failed.
                           We will not let the CmdError out.
            :return: result of parse_func.
            """
            # If run_func is utils.run by default, we need to set
            # ignore_status = True. Otherwise, skip this setting.
            if run_func is utils.run:
                logging.debug("Setting ignore_status to True.")
                kwargs["ignore_status"] = True
            result = run_func(" ".join(command(service_name)), **kwargs)
            return parse_func(result)
        return run


class _GenericServiceManager(object):

    """
    Base class for SysVInitServiceManager and SystemdServiceManager.
    """

    def __init__(self, service_command_generator, service_result_parser, run=utils.run):
        """
        Create staticmethods for each service command, e.g. start, stop, restart.
        These staticmethods take as an argument the service to be started or stopped.

        systemd = SpecificServiceManager(auto_create_specific_service_command_generator())
        systemd.start("lldpad")
        systemd.stop("lldpad")

        :param service_command_generator: a sys_v_init or systemd command generator
        :type service_command_generator: _ServiceCommandGenerator
        :param run: function to call the run the commands, default utils.run
        :type run: function
        """
        # create staticmethods in class attributes (not used)
        # for cmd in service_command_generator.commands:
        #     setattr(self.__class__, cmd,
        #             staticmethod(self.generate_run_function(run, getattr(service_command_generator, cmd))))
        # create functions in instance attributes
        for cmd in service_command_generator.commands:
            setattr(self, cmd,
                    self.generate_run_function(run,
                                               getattr(
                                                   service_result_parser, cmd),
                                               getattr(service_command_generator, cmd)))

    @staticmethod
    def generate_run_function(run_func, parse_func, command):
        """
        Generate the wrapped call to utils.run for the service command, "service" or "systemctl"

        :param run_func:  utils.run
        :type run_func:  function
        :param command: partial function that generates the command list
        :type command: function
        :return: wrapped utils.run function.
        :rtype: function
        """
        def run(service="", **kwargs):
            """
            Wrapped utils.run invocation that will start, stop, restart, etc. a service.

            :param service: service name, e.g. crond, dbus, etc.
            :param kwargs: extra arguments to utils.run, .e.g. timeout. But not for ignore_status.
                           We need a CmdResult to parse and raise a error.TestError if command failed.
                           We will not let the CmdError out.
            :return: result of parse_func.
            """
            # If run_func is utils.run by default, we need to set
            # ignore_status = True. Otherwise, skip this setting.
            if run_func is utils.run:
                logging.debug("Setting ignore_status to True.")
                kwargs["ignore_status"] = True
            result = run_func(" ".join(command(service)), **kwargs)
            return parse_func(result)
        return run


class _SysVInitServiceManager(_GenericServiceManager):

    """
    Concrete class that implements the SysVInitServiceManager
    """

    def __init__(self, service_command_generator, service_result_parser, run=utils.run):
        """
        Create the GenericServiceManager for SysV services.

        :param service_command_generator:
        :type service_command_generator: _ServiceCommandGenerator
        :param run: function to call to run the commands, default utils.run
        :type run: function
        """
        super(
            _SysVInitServiceManager, self).__init__(service_command_generator,
                                                    service_result_parser, run)

    # @staticmethod
    # def change_default_runlevel(runlevel='3'):
    #     """
    #     Set the default sys_v runlevel
    #
    #     :param runlevel: sys_v runlevel to set as default in inittab
    #     :type runlevel: str
    #     """
    #     raise NotImplemented


def convert_sysv_runlevel(level):
    """
    Convert runlevel to systemd target.

    :param level: sys_v runlevel
    :type level: str or int
    :return: systemd target
    :rtype: str
    :raise ValueError: when runlevel is unknown
    """
    runlevel = str(level)
    if runlevel == '0':
        target = "poweroff.target"
    elif runlevel in ['1', "s", "single"]:
        target = "rescue.target"
    elif runlevel in ['2', '3', '4']:
        target = "multi-user.target"
    elif runlevel == '5':
        target = "graphical.target"
    elif runlevel == '6':
        target = "reboot.target"
    else:
        raise ValueError("unknown runlevel %s" % level)
    return target


def convert_systemd_target_to_runlevel(target):
    """
    Convert systemd target to runlevel.

    :param target: systemd target
    :type target: str
    :return: sys_v runlevel
    :rtype: str
    :raise ValueError: when systemd target is unknown
    """
    if target == "poweroff.target":
        runlevel = '0'
    elif target == "rescue.target":
        runlevel = 's'
    elif target == "multi-user.target":
        runlevel = '3'
    elif target == "graphical.target":
        runlevel = '5'
    elif target == "reboot.target":
        runlevel = '6'
    else:
        raise ValueError("unknown target %s" % target)
    return runlevel


class _SystemdServiceManager(_GenericServiceManager):

    """
    Concrete class that implements the SystemdServiceManager
    """

    def __init__(self, service_command_generator, service_result_parser, run=utils.run):
        """
        Create the GenericServiceManager for systemd services.

        :param service_command_generator:
        :type service_command_generator: _ServiceCommandGenerator
        :param run: function to call to run the commands, default utils.run
        :type run: function
        """
        super(_SystemdServiceManager, self).__init__(service_command_generator,
                                                     service_result_parser, run)

    @staticmethod
    def change_default_runlevel(runlevel='multi-user.target'):
        # atomic symlinking, symlink and then rename
        """
        Set the default systemd target.
        Create the symlink in a temp directory and then use
        atomic rename to move the symlink into place.

        :param runlevel: default systemd target
        :type runlevel: str
        """
        tmp_symlink = mktemp(dir="/etc/systemd/system")
        os.symlink("/usr/lib/systemd/system/%s" % runlevel, tmp_symlink)
        os.rename(tmp_symlink, "/etc/systemd/system/default.target")


class Factory(object):

    """
    Class to create different kinds of ServiceManager.
    The all interfaces to create manager are staticmethod,
    so we do not have to create an instance of factory
    when create manager.

    * GenericServiceManager:
        * Interface: create_generic_service()
        * Description: Object to manage the all services(lldp, sshd and so on).
                You can list the all services by GenericServiceManager.list().
                And you can operate any service by passing the service name,
                such as GenericServiceManager.start("sshd").

                Example:
                # Get the system service manager
                service_manager = Factory.create_generic_service()

                # Stating service/unit "sshd"
                service_manager.start("sshd")

                # Getting a list of available units
                units = service_manager.list()

    * SpecificServiceManager:
        * interface: create_specific_service(service_name)
        * description: Object to manage specific service(such as sshd). You can
                not operate the other services nor list the all information on
                this host.

                # Get the specific service manager for sshd
                sshd = Factory.create_specific_service("sshd")
                sshd.start()
                sshd.stop()

    After all, there is an unified interface to create both of them,
    create_service(service_name=None).

    If we pass a service_name to it, it will return a SpecificServiceManager,
    otherwise, it will return GenericServiceManager.
    """

    class FactoryHelper(object):

        """
        Internal class to help create service manager.

        Provide some functions to auto detect system type.
        And auto create command_generator and result_parser.
        """
        _command_generators = {"init": sys_v_init_command_generator,
                               "systemd": systemd_command_generator}

        _result_parsers = {"init": sys_v_init_result_parser,
                           "systemd": systemd_result_parser}

        _service_managers = {"init": _SysVInitServiceManager,
                             "systemd": _SystemdServiceManager}

        def __init__(self, run=utils.run):
            """
            Init a helper to create service manager.

            :param run: Funtion to run command.
            :type: utils.run-like function.
            """
            result = run("true")
            if not isinstance(result, utils.CmdResult):
                raise ValueError("Param run is a/an %s, "
                                 "but not an instance of utils.CmdResult."
                                 % (type(result)))
            self.run = run
            self.init_name = self.get_name_of_init()

        def get_name_of_init(self):
            """
            Internal function to determine what executable is PID 1,
            :return: executable name for PID 1, aka init
            :rtype:  str
            """
            output = self.run("ps -o comm 1").stdout
            return output.splitlines()[-1].strip()

        def get_generic_service_manager_type(self):
            """
            Get the ServiceManager type using the auto-detect init command.

            :return: Subclass type of _GenericServiceManager from the current init command.
            :rtype: _SysVInitServiceManager or _SystemdServiceManager.
            """
            return self._service_managers[self.init_name]

        def get_generic_service_result_parser(self):
            """
            Get the ServiceResultParser using the auto-detect init command.

            :return: ServiceResultParser fro the current init command.
            :rtype: _ServiceResultParser
            """
            result_parser = self._result_parsers[self.init_name]
            return _ServiceResultParser(result_parser)

        def get_generic_service_command_generator(self):
            """
            Lazy initializer for ServiceCommandGenerator using the auto-detect init command.

            :return: ServiceCommandGenerator for the current init command.
            :rtype: _ServiceCommandGenerator
            """
            command_generator = self._command_generators[self.init_name]
            return _ServiceCommandGenerator(command_generator)

        def get_specific_service_result_parser(self):
            """
            Create a class that will create partial functions that generate result_parser
            for the current init command.

            :return: A ServiceResultParser for the auto-detected init command.
            :rtype: _ServiceResultParser
            """
            result_parser = self._result_parsers[self.init_name]
            # remove list method
            command_list = [
                c for c in COMMANDS if c not in ["list", "set_target"]]
            return _ServiceResultParser(result_parser, command_list)

        def get_specific_service_command_generator(self):
            """
            Create a class that will create partial functions that generate commands
            for the current init command.

            ::

                lldpad = SpecificServiceManager("lldpad",
                             auto_create_specific_service_command_generator())
                lldpad.start()
                lldpad.stop()

            :return: A ServiceCommandGenerator for the auto-detected init command.
            :rtype: _ServiceCommandGenerator
            """
            command_generator = self._command_generators[self.init_name]
            # remove list method
            command_list = [
                c for c in COMMANDS if c not in ["list", "set_target"]]
            return _ServiceCommandGenerator(command_generator, command_list)

    @staticmethod
    def create_generic_service(run=utils.run):
        """
        Detect which init program is being used, init or systemd and return a
        class with methods to start/stop services.

        ::

            # Get the system service manager
            service_manager = Factory.create_generic_service()

            # Stating service/unit "sshd"
            service_manager.start("sshd")

            # Getting a list of available units
            units = service_manager.list()

            # Disabling and stopping a list of services
            services_to_disable = ['ntpd', 'httpd']
            for s in services_to_disable:
                service_manager.disable(s)
                service_manager.stop(s)

        :return: SysVInitServiceManager or SystemdServiceManager
        :rtype: _GenericServiceManager
        """
        helper = Factory.FactoryHelper(run)
        service_manager = helper.get_generic_service_manager_type()
        command_generator = helper.get_generic_service_command_generator()
        result_parser = helper.get_generic_service_result_parser()
        return service_manager(command_generator, result_parser, run)

    @staticmethod
    def create_specific_service(service_name, run=utils.run):
        """

        # Get the specific service manager for sshd
        sshd = Factory.create_specific_service("sshd")
        sshd.start()
        sshd.stop()
        sshd.reload()
        sshd.restart()
        sshd.condrestart()
        sshd.status()
        sshd.enable()
        sshd.disable()
        sshd.is_enabled()

        :param service_name: systemd unit or init.d service to manager
        :type service_name: str
        :return: SpecificServiceManager that has start/stop methods
        :rtype: _SpecificServiceManager
        """
        helper = Factory.FactoryHelper(run)
        command_generator = helper.get_specific_service_command_generator()
        result_parser = helper.get_specific_service_result_parser()

        return _SpecificServiceManager(service_name,
                                       command_generator,
                                       result_parser,
                                       run)

    @staticmethod
    def create_service(service_name=None, run=utils.run):
        """
        # Unified interface for generic and specific service manager.

        :return: _SpecificServiceManager if service_name is not None,
                _GenericServiceManager if service_name is None.
        """
        if service_name:
            return Factory.create_specific_service(service_name, run)
        return Factory.create_generic_service(run)

########NEW FILE########
__FILENAME__ = utils_cgroup
#!/usr/bin/python
# -*- coding: utf-8 -*-
"""
Helpers for cgroup testing.

:copyright: 2011 Red Hat Inc.
:author: Lukas Doktor <ldoktor@redhat.com>
"""
import logging
import os
import shutil
import subprocess
import time
import re
import random
import commands
from tempfile import mkdtemp
from autotest.client import utils
from autotest.client.shared import error

import service


class Cgroup(object):

    """
    Cgroup handling class.
    """

    def __init__(self, module, _client):
        """
        Constructor
        :param module: Name of the cgroup module
        :param _client: Test script pwd + name
        """
        self.module = module
        self._client = _client
        self.root = None
        self.cgroups = []

    def __del__(self):
        """
        Destructor
        """
        self.cgroups.sort(reverse=True)
        for pwd in self.cgroups[:]:
            for task in self.get_property("tasks", pwd):
                if task:
                    self.set_root_cgroup(int(task))
            self.rm_cgroup(pwd)

    def initialize(self, modules):
        """
        Initializes object for use.

        :param modules: Array of all available cgroup modules.
        """
        self.root = modules.get_pwd(self.module)
        if not self.root:
            raise error.TestError("cg.initialize(): Module %s not found"
                                  % self.module)

    def __get_cgroup_pwd(self, cgroup):
        """
        Get cgroup's full path

        :param cgroup: cgroup name
        :return: cgroup's full path
        """
        if not isinstance(cgroup, str):
            raise error.TestError("cgroup type isn't string!")
        return os.path.join(self.root, cgroup) + '/'

    def get_cgroup_name(self, pwd=None):
        """
        Get cgroup's name

        :param pwd: cgroup name
        :return: cgroup's name
        """
        if pwd is None:
            # root cgroup
            return None
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        # self.root is "/cgroup/blkio," not "/cgroup/blkio/"
        # cgroup is "/cgroup/blkio/test" or "/cgroup/blkio/test/test"
        # expected cgroup name is test/ or test/test/
        if pwd.startswith(self.root + '/'):
            return pwd[len(self.root) + 1:]
        return None

    def get_cgroup_index(self, cgroup):
        """
        Get cgroup's index in cgroups

        :param cgroup: cgroup name
        :return: index of cgroup
        """
        try:
            if self.__get_cgroup_pwd(cgroup) not in self.cgroups:
                raise error.TestFail("%s not exists!" % cgroup)
            cgroup_pwd = self.__get_cgroup_pwd(cgroup)
            return self.cgroups.index(cgroup_pwd)
        except error.CmdError:
            raise error.TestFail("Find index failed!")

    def mk_cgroup_cgcreate(self, pwd=None, cgroup=None):
        """
        Make a cgroup by executing the cgcreate command

        :params: cgroup: name of the cgroup to be created
        :return: last cgroup index
        """
        try:
            parent_cgroup = self.get_cgroup_name(pwd)
            if cgroup is None:
                range = "abcdefghijklmnopqrstuvwxyz0123456789"
                sub_cgroup = "cgroup-" + "".join(random.sample(range +
                                                               range.upper(), 6))
            else:
                sub_cgroup = cgroup
            if parent_cgroup is None:
                cgroup = sub_cgroup
            else:
                # Parent cgroup:test. Created cgroup:test1.
                # Whole cgroup name is "test/test1"
                cgroup = os.path.join(parent_cgroup, sub_cgroup)
            if self.__get_cgroup_pwd(cgroup) in self.cgroups:
                raise error.TestFail("%s exists!" % cgroup)
            cgcreate_cmd = "cgcreate -g %s:%s" % (self.module, cgroup)
            utils.run(cgcreate_cmd, ignore_status=False)
            pwd = self.__get_cgroup_pwd(cgroup)
            self.cgroups.append(pwd)
            return len(self.cgroups) - 1
        except error.CmdError:
            raise error.TestFail("Make cgroup by cgcreate failed!")

    def mk_cgroup(self, pwd=None, cgroup=None):
        """
        Creates new temporary cgroup
        :param pwd: where to create this cgroup (default: self.root)
        :param cgroup: desired cgroup name
        :return: last cgroup index
        """
        if pwd is None:
            pwd = self.root
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            if cgroup and self.__get_cgroup_pwd(cgroup) in self.cgroups:
                raise error.TestFail("%s exists!" % cgroup)
            if not cgroup:
                pwd = mkdtemp(prefix='cgroup-', dir=pwd) + '/'
            else:
                pwd = os.path.join(pwd, cgroup) + '/'
                if not os.path.exists(pwd):
                    os.mkdir(pwd)
        except Exception, inst:
            raise error.TestError("cg.mk_cgroup(): %s" % inst)
        self.cgroups.append(pwd)
        return len(self.cgroups) - 1

    def cgexec(self, cgroup, cmd, args=""):
        """
        Execute command in desired cgroup

        :param cgroup: Desired cgroup
        :param cmd: Executed command
        :param args: Executed command's parameters
        """
        try:
            args_str = ""
            if len(args):
                args_str = " ".join(args)
            cgexec_cmd = ("cgexec -g %s:%s %s %s" %
                          (self.module, cgroup, cmd, args_str))
            status, output = commands.getstatusoutput(cgexec_cmd)
            return status, output
        except error.CmdError, detail:
            raise error.TestFail("Execute %s in cgroup failed!\n%s" %
                                 (cmd, detail))

    def rm_cgroup(self, pwd):
        """
        Removes cgroup.

        :param pwd: cgroup directory.
        """
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            os.rmdir(pwd)
            self.cgroups.remove(pwd)
        except ValueError:
            logging.warn("cg.rm_cgroup(): Removed cgroup which wasn't created"
                         "using this Cgroup")
        except Exception, inst:
            raise error.TestError("cg.rm_cgroup(): %s" % inst)

    def cgdelete_all_cgroups(self):
        """
        Delete all cgroups in the module
        """
        try:
            for cgroup_pwd in self.cgroups:
                # Ignore sub cgroup
                cgroup = self.get_cgroup_name(cgroup_pwd)
                if cgroup.count("/") > 0:
                    continue
                self.cgdelete_cgroup(cgroup, True)
        except error.CmdError:
            raise error.TestFail("cgdelete all cgroups in %s failed!"
                                 % self.module)

    def cgdelete_cgroup(self, cgroup, recursive=False):
        """
        Delete desired cgroup.

        :params cgroup: desired cgroup
        :params force: If true, sub cgroup can be deleted with parent cgroup
        """
        try:
            cgroup_pwd = self.__get_cgroup_pwd(cgroup)
            if cgroup_pwd not in self.cgroups:
                raise error.TestError("%s doesn't exist!" % cgroup)
            cmd = "cgdelete %s:%s" % (self.module, cgroup)
            if recursive:
                cmd += " -r"
            utils.run(cmd, ignore_status=False)
            self.cgroups.remove(cgroup_pwd)
        except error.CmdError, detail:
            raise error.TestFail("cgdelete %s failed!\n%s" %
                                 (cgroup, detail))

    def cgclassify_cgroup(self, pid, cgroup):
        """
        Classify pid into cgroup

        :param pid: pid of the process
        :param cgroup: cgroup name
        """
        try:
            cgroup_pwd = self.__get_cgroup_pwd(cgroup)
            if cgroup_pwd not in self.cgroups:
                raise error.TestError("%s doesn't exist!" % cgroup)
            cgclassify_cmd = ("cgclassify -g %s:%s %d" %
                              (self.module, cgroup, pid))
            utils.run(cgclassify_cmd, ignore_status=False)
        except error.CmdError, detail:
            raise error.TestFail("Classify process to tasks file failed!:%s" %
                                 detail)

    def get_pids(self, pwd=None):
        """
        Get all pids in cgroup

        :params: pwd: cgroup directory
        :return: all pids(list)
        """
        if pwd is None:
            pwd = self.root
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            return [_.strip() for _ in open(os.path.join(pwd, 'tasks'), 'r')]
        except Exception, inst:
            raise error.TestError("cg.get_pids(): %s" % inst)

    def test(self, cmd):
        """
        Executes cgroup_client.py with cmd parameter.

        :param cmd: command to be executed
        :return: subprocess.Popen() process
        """
        logging.debug("cg.test(): executing parallel process '%s'", cmd)
        cmd = self._client + ' ' + cmd
        process = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE,
                                   stdout=subprocess.PIPE,
                                   stderr=subprocess.PIPE, close_fds=True)
        return process

    def is_cgroup(self, pid, pwd):
        """
        Checks if the 'pid' process is in 'pwd' cgroup
        :param pid: pid of the process
        :param pwd: cgroup directory
        :return: 0 when is 'pwd' member
        """
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        if open(os.path.join(pwd, 'tasks')).readlines().count("%d\n" % pid) > 0:
            return 0
        else:
            return -1

    def is_root_cgroup(self, pid):
        """
        Checks if the 'pid' process is in root cgroup (WO cgroup)
        :param pid: pid of the process
        :return: 0 when is 'root' member
        """
        return self.is_cgroup(pid, self.root)

    def set_cgroup(self, pid, pwd=None):
        """
        Sets cgroup membership
        :param pid: pid of the process
        :param pwd: cgroup directory
        """
        if pwd is None:
            pwd = self.root
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            open(os.path.join(pwd, 'tasks'), 'w').write(str(pid))
        except Exception, inst:
            raise error.TestError("cg.set_cgroup(): %s" % inst)
        if self.is_cgroup(pid, pwd):
            raise error.TestError("cg.set_cgroup(): Setting %d pid into %s "
                                  "cgroup failed" % (pid, pwd))

    def set_root_cgroup(self, pid):
        """
        Resets the cgroup membership (sets to root)
        :param pid: pid of the process
        :return: 0 when PASSED
        """
        return self.set_cgroup(pid, self.root)

    def get_property(self, prop, pwd=None):
        """
        Gets the property value
        :param prop: property name (file)
        :param pwd: cgroup directory
        :return: [] values or None when FAILED
        """
        if pwd is None:
            pwd = self.root
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            # Remove tailing '\n' from each line
            file_link = os.path.join(pwd, prop)
            ret = [_[:-1].replace("\t", " ") for _ in open(file_link, 'r')]
            if ret:
                return ret
            else:
                return [""]
        except Exception, inst:
            raise error.TestError("cg.get_property(): %s" % inst)

    def set_property_h(self, prop, value, pwd=None, check=True, checkprop=None):
        """
        Sets the one-line property value concerning the K,M,G postfix
        :param prop: property name (file)
        :param value: desired value
        :param pwd: cgroup directory
        :param check: check the value after setup / override checking value
        :param checkprop: override prop when checking the value
        """
        _value = value
        try:
            value = str(value)
            human = {'B': 1,
                     'K': 1024,
                     'M': 1048576,
                     'G': 1073741824,
                     'T': 1099511627776
                     }
            if human.has_key(value[-1]):
                value = int(value[:-1]) * human[value[-1]]
        except Exception:
            logging.warn("cg.set_prop() fallback into cg.set_property.")
            value = _value
        self.set_property(prop, value, pwd, check, checkprop)

    def set_property(self, prop, value, pwd=None, check=True, checkprop=None):
        """
        Sets the property value
        :param prop: property name (file)
        :param value: desired value
        :param pwd: cgroup directory
        :param check: check the value after setup / override checking value
        :param checkprop: override prop when checking the value
        """
        value = str(value)
        if pwd is None:
            pwd = self.root
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            open(os.path.join(pwd, prop), 'w').write(value)
        except Exception, inst:
            raise error.TestError("cg.set_property(): %s" % inst)

        if check is not False:
            if check is True:
                check = value
            if checkprop is None:
                checkprop = prop
            _values = self.get_property(checkprop, pwd)
            # Sanitize non printable characters before check
            check = " ".join(check.split())
            if check not in _values:
                raise error.TestError("cg.set_property(): Setting failed: "
                                      "desired = %s, real values = %s"
                                      % (repr(check), repr(_values)))

    def cgset_property(self, prop, value, pwd=None, check=True, checkprop=None):
        """
        Sets the property value by cgset command

        :param prop: property name (file)
        :param value: desired value
        :param pwd: cgroup directory
        :param check: check the value after setup / override checking value
        :param checkprop: override prop when checking the value
        """
        if pwd is None:
            pwd = self.root
        if isinstance(pwd, int):
            pwd = self.cgroups[pwd]
        try:
            cgroup = self.get_cgroup_name(pwd)
            cgset_cmd = "cgset -r %s='%s' %s" % (prop, value, cgroup)
            utils.run(cgset_cmd, ignore_status=False)
        except error.CmdError, detail:
            raise error.TestFail("Modify %s failed!:\n%s" % (prop, detail))

        if check is not False:
            if check is True:
                check = value
            if checkprop is None:
                checkprop = prop
            _values = self.get_property(checkprop,
                                        self.get_cgroup_index(cgroup))
            # Sanitize non printable characters before check
            check = " ".join(check.split())
            if check not in _values:
                raise error.TestError("cg.set_property(): Setting failed: "
                                      "desired = %s, real values = %s"
                                      % (repr(check), repr(_values)))

    def smoke_test(self):
        """
        Smoke test
        Module independent basic tests
        """
        pwd = self.mk_cgroup()

        ps = self.test("smoke")
        if ps is None:
            raise error.TestError("cg.smoke_test: Couldn't create process")

        if (ps.poll() is not None):
            raise error.TestError("cg.smoke_test: Process died unexpectidly")

        # New process should be a root member
        if self.is_root_cgroup(ps.pid):
            raise error.TestError(
                "cg.smoke_test: Process is not a root member")

        # Change the cgroup
        self.set_cgroup(ps.pid, pwd)

        # Try to remove used cgroup
        try:
            self.rm_cgroup(pwd)
        except error.TestError:
            pass
        else:
            raise error.TestError("cg.smoke_test: Unexpected successful"
                                  " deletion of the used cgroup")

        # Return the process into the root cgroup
        self.set_root_cgroup(ps.pid)

        # It should be safe to remove the cgroup now
        self.rm_cgroup(pwd)

        # Finish the process
        ps.stdin.write('\n')
        time.sleep(2)
        if (ps.poll() is None):
            raise error.TestError("cg.smoke_test: Process is not finished")


class CgroupModules(object):

    """
    Handles the list of different cgroup filesystems.
    """

    def __init__(self, mountdir=None):
        self.modules = []
        self.modules.append([])
        self.modules.append([])
        self.modules.append([])
        if mountdir is None:
            self.mountdir = mkdtemp(prefix='cgroup-') + '/'
            self.rm_mountdir = True
        else:
            self.mountdir = mountdir
            self.rm_mountdir = False

    def __del__(self):
        """
        Unmount all cgroups and remove the mountdir
        """
        for i in range(len(self.modules[0])):
            if self.modules[2][i]:
                try:
                    utils.system('umount %s -l' % self.modules[1][i])
                except Exception, failure_detail:
                    logging.warn("CGM: Couldn't unmount %s directory: %s",
                                 self.modules[1][i], failure_detail)
        try:
            if self.rm_mountdir:
                # If delete /cgroup/, this action will break cgroup service.
                shutil.rmtree(self.mountdir)
        except Exception:
            logging.warn(
                "CGM: Couldn't remove the %s directory", self.mountdir)

    def init(self, _modules):
        """
        Checks the mounted modules and if necessary mounts them into tmp
        mountdir.

        :param _modules: Desired modules.'memory','cpu,cpuset'...
        :return: Number of initialized modules.
        """
        logging.debug("Desired cgroup modules: %s", _modules)
        mounts = []
        proc_mounts = open('/proc/mounts', 'r')
        line = proc_mounts.readline().split()
        while line:
            if line[2] == 'cgroup':
                mounts.append(line)
            line = proc_mounts.readline().split()
        proc_mounts.close()

        for module in _modules:
            # Is it already mounted?
            i = False
            _module = set(module.split(','))
            for mount in mounts:
                # 'memory' or 'memory,cpuset'
                if _module.issubset(mount[3].split(',')):
                    self.modules[0].append(module)
                    self.modules[1].append(mount[1] + '/')
                    self.modules[2].append(False)
                    i = True
                    break
            if not i:
                # Not yet mounted
                module_path = os.path.join(self.mountdir, module)
                if not os.path.exists(module_path):
                    os.mkdir(module_path)
                cmd = ('mount -t cgroup -o %s %s %s' %
                       (module, module, module_path))
                try:
                    utils.run(cmd)
                    self.modules[0].append(module)
                    self.modules[1].append(module_path)
                    self.modules[2].append(True)
                except error.CmdError:
                    logging.info("Cgroup module '%s' not available", module)

        logging.debug("Initialized cgroup modules: %s", self.modules[0])
        return len(self.modules[0])

    def get_pwd(self, module):
        """
        Returns the mount directory of 'module'
        :param module: desired module (memory, ...)
        :return: mount directory of 'module' or None
        """
        try:
            i = self.modules[0].index(module)
        except Exception, inst:
            logging.error("module %s not found: %s", module, inst)
            return None
        return self.modules[1][i]


def get_load_per_cpu(_stats=None):
    """
    Gather load per cpu from /proc/stat
    :param _stats: previous values
    :return: list of diff/absolute values of CPU times [SUM, CPU1, CPU2, ...]
    """
    stats = []
    f_stat = open('/proc/stat', 'r')
    if _stats:
        for i in range(len(_stats)):
            stats.append(int(f_stat.readline().split()[1]) - _stats[i])
    else:
        line = f_stat.readline()
        while line:
            if line.startswith('cpu'):
                stats.append(int(line.split()[1]))
            else:
                break
            line = f_stat.readline()
    return stats


def get_cgroup_mountpoint(controller, mount_file="/proc/mounts"):
    """
    Get desired controller's mountpoint

    :param controller: Desired controller
    :param mount_file: Name of file contains mounting information, in most
                       cases this are not need to be set.
    :return: controller's mountpoint
    :raise: TestError when contoller doesn't exist in mount table
    """
    f_cgcon = open(mount_file, "rU")
    cgconf_txt = f_cgcon.read()
    f_cgcon.close()
    mntpt = re.findall(r"\s(\S*cgroup/\S*%s(?=[,\ ])\S*)" % controller, cgconf_txt)
    if len(mntpt) == 0:
        # Controller is not supported if not found in mount table.
        raise error.TestError("Doesn't support controller <%s>" % controller)
    return mntpt[0]


def get_all_controllers():
    """
    Get all controllers used in system

    :return: all used controllers(controller_list)
    """
    try:
        result = utils.run("lssubsys", ignore_status=False)
        controllers_str = result.stdout.strip()
        controller_list = []
        for controller in controllers_str.splitlines():
            controller_sub_list = controller.split(",")
            controller_list += controller_sub_list
    except error.CmdError:
        controller_list = ['cpuacct', 'cpu', 'memory', 'cpuset',
                           'devices', 'freezer', 'blkio', 'netcls']
    return controller_list


def resolve_task_cgroup_path(pid, controller):
    """
    Resolving cgroup mount path of a particular task

    :params: pid : process id of a task for which the cgroup path required
    :params: controller: takes one of the controller names in controller list

    :return: resolved path for cgroup controllers of a given pid
    """
    root_path = get_cgroup_mountpoint(controller)

    proc_cgroup = "/proc/%d/cgroup" % pid
    if not os.path.isfile(proc_cgroup):
        raise NameError('File %s does not exist\n Check whether cgroup \
                                    installed in the system' % proc_cgroup)

    try:
        proc_file = open(proc_cgroup, 'r')
        proc_cgroup_txt = proc_file.read()
    finally:
        proc_file.close()

    mount_path = re.findall(r":\S*%s(?=[,:])\S*:(\S*)\n" % controller, proc_cgroup_txt)
    return os.path.join(root_path, mount_path[0].strip("/"))


class CgconfigService(object):

    """
    Cgconfig service class.
    """

    def __init__(self):
        self._service_manager = service.Factory.create_service("cgconfig")

    def _service_cgconfig_control(self, action):
        """
        Cgconfig control by action.

        If cmd executes successfully, return True, otherwise return False.
        If the action is status, return True when it's running, otherwise return
        False.

        :param action: cgconfig service action
        """
        if not hasattr(self._service_manager, action):
            raise error.TestError("Unknown action: %s" % action)
        return getattr(self._service_manager, action)()

    def cgconfig_start(self):
        """
        Sart cgconfig service
        """
        return self._service_cgconfig_control("start")

    def cgconfig_stop(self):
        """
        Sop cgconfig service
        """
        return self._service_cgconfig_control("stop")

    def cgconfig_restart(self):
        """
        Restart cgconfig service
        """
        return self._service_cgconfig_control("restart")

    def cgconfig_condrestart(self):
        """
        Condrestart cgconfig service
        """
        return self._service_cgconfig_control("condrestart")

    def cgconfig_is_running(self):
        """
        Check cgconfig service status
        """
        return self._service_cgconfig_control("status")


def all_cgroup_delete():
    """
    Clear all cgroups in system
    """
    try:
        utils.run("cgclear", ignore_status=False)
    except error.CmdError, detail:
        raise error.TestFail("Clear all cgroup failed!:\n%s" % detail)

########NEW FILE########
__FILENAME__ = utils_koji
import HTMLParser
import ConfigParser
import os
import time
import logging
import urllib
from autotest.client import os_dep, utils

try:
    import koji
    KOJI_INSTALLED = True
except ImportError:
    KOJI_INSTALLED = False

DEFAULT_KOJI_TAG = None


class KojiDownloadError(IOError):

    def __init__(self, url, timeout, last_error):
        self.url = url
        self.timeout = timeout
        self.last_error = last_error

    def __str__(self):
        return ("Koji/Brew download of file %s failed. "
                "Timeout: %s s "
                "Last error: %s" % (self.url, self.timeout, self.last_error))


class KojiDirIndexParser(HTMLParser.HTMLParser):

    '''
    Parser for HTML directory index pages, specialized to look for RPM links
    '''

    def __init__(self):
        '''
        Initializes a new KojiDirListParser instance
        '''
        HTMLParser.HTMLParser.__init__(self)
        self.package_file_names = []

    def handle_starttag(self, tag, attrs):
        '''
        Handle tags during the parsing

        This just looks for links ('a' tags) for files ending in .rpm
        '''
        if tag == 'a':
            for k, v in attrs:
                if k == 'href' and v.endswith('.rpm'):
                    self.package_file_names.append(v)


class RPMFileNameInfo:

    '''
    Simple parser for RPM based on information present on the filename itself
    '''

    def __init__(self, filename):
        '''
        Initializes a new RpmInfo instance based on a filename
        '''
        self.filename = filename

    def get_filename_without_suffix(self):
        '''
        Returns the filename without the default RPM suffix
        '''
        assert self.filename.endswith('.rpm')
        return self.filename[0:-4]

    def get_filename_without_arch(self):
        '''
        Returns the filename without the architecture

        This also excludes the RPM suffix, that is, removes the leading arch
        and RPM suffix.
        '''
        wo_suffix = self.get_filename_without_suffix()
        arch_sep = wo_suffix.rfind('.')
        return wo_suffix[:arch_sep]

    def get_arch(self):
        '''
        Returns just the architecture as present on the RPM filename
        '''
        wo_suffix = self.get_filename_without_suffix()
        arch_sep = wo_suffix.rfind('.')
        return wo_suffix[arch_sep + 1:]

    def get_nvr_info(self):
        '''
        Returns a dictionary with the name, version and release components

        If koji is not installed, this returns None
        '''
        if not KOJI_INSTALLED:
            return None
        return koji.util.koji.parse_NVR(self.get_filename_without_arch())


class KojiClient(object):

    """
    Stablishes a connection with the build system, either koji or brew.

    This class provides convenience methods to retrieve information on packages
    and the packages themselves hosted on the build system. Packages should be
    specified in the KojiPgkSpec syntax.
    """

    CMD_LOOKUP_ORDER = ['/usr/bin/brew', '/usr/bin/koji']

    CONFIG_MAP = {'/usr/bin/brew': '/etc/brewkoji.conf',
                  '/usr/bin/koji': '/etc/koji.conf'}

    # Time to keep trying to download a package
    RETRY_TIMEOUT = 30
    # Time to wait until the next retry
    RETRY_STEP = 3

    def __init__(self, cmd=None):
        """
        Verifies whether the system has koji or brew installed, then loads
        the configuration file that will be used to download the files.

        :type cmd: string
        :param cmd: Optional command name, either 'brew' or 'koji'. If not
                set, get_default_command() is used and to look for
                one of them.
        :raise: ValueError
        """
        if not KOJI_INSTALLED:
            raise ValueError('No koji/brew installed on the machine')

        # Instance variables used by many methods
        self.command = None
        self.config = None
        self.config_options = {}
        self.session = None

        # Set koji command or get default
        if cmd is None:
            self.command = self.get_default_command()
        else:
            self.command = cmd

        # Check koji command
        if not self.is_command_valid():
            raise ValueError('Koji command "%s" is not valid' % self.command)

        # Assuming command is valid, set configuration file and read it
        self.config = self.CONFIG_MAP[self.command]
        self.read_config()

        # Setup koji session
        server_url = self.config_options['server']
        session_options = self.get_session_options()
        self.session = koji.ClientSession(server_url,
                                          session_options)

    def _get(self, url, dst):
        '''
        Download a given file to a destination path.

        This is a wrapper to utils.get_file(), that will keep trying to
        download the file from the URL for the time defined in the
        RETRY_TIMEOUT class attribute, in step intervals defined in the
        RETRY_STEP class attribute.

        :param url: Universal Resource Location of the source file
        :param dst: Destination path
        :raise: class `KojiDownloadError`
        '''
        success = False
        last_error = ""
        end_time = time.time() + self.RETRY_TIMEOUT

        while time.time() < end_time:
            try:
                utils.get_file(url, dst)
                success = True
                break
            except Exception, e:
                last_error = str(e)
                logging.error("Download failed: %s", last_error)
                logging.error("Retrying after %s seconds...",
                              self.RETRY_STEP)
                if os.path.isfile(dst):
                    os.unlink(dst)
                time.sleep(self.RETRY_STEP)

        if not success:
            raise KojiDownloadError(url, self.RETRY_TIMEOUT, last_error)

    def read_config(self, check_is_valid=True):
        '''
        Reads options from the Koji configuration file

        By default it checks if the koji configuration is valid

        :type check_valid: boolean
        :param check_valid: whether to include a check on the configuration
        :raise: ValueError
        :return: None
        '''
        if check_is_valid:
            if not self.is_config_valid():
                raise ValueError('Koji config "%s" is not valid' % self.config)

        config = ConfigParser.ConfigParser()
        config.read(self.config)

        basename = os.path.basename(self.command)
        for name, value in config.items(basename):
            self.config_options[name] = value

    def get_session_options(self):
        '''
        Filter only options necessary for setting up a cobbler client session

        :return: only the options used for session setup
        '''
        session_options = {}
        for name, value in self.config_options.items():
            if name in ('user', 'password', 'debug_xmlrpc', 'debug'):
                session_options[name] = value
        return session_options

    def is_command_valid(self):
        '''
        Checks if the currently set koji command is valid

        :return: True or False
        '''
        koji_command_ok = True

        if not os.path.isfile(self.command):
            logging.error('Koji command "%s" is not a regular file',
                          self.command)
            koji_command_ok = False

        if not os.access(self.command, os.X_OK):
            logging.warn('Koji command "%s" is not executable: this is '
                         'not fatal but indicates an unexpected situation',
                         self.command)

        if self.command not in self.CONFIG_MAP.keys():
            logging.error('Koji command "%s" does not have a configuration '
                          'file associated to it', self.command)
            koji_command_ok = False

        return koji_command_ok

    def is_config_valid(self):
        '''
        Checks if the currently set koji configuration is valid

        :return: True or False
        '''
        koji_config_ok = True

        if not os.path.isfile(self.config):
            logging.error(
                'Koji config "%s" is not a regular file', self.config)
            koji_config_ok = False

        if not os.access(self.config, os.R_OK):
            logging.error('Koji config "%s" is not readable', self.config)
            koji_config_ok = False

        config = ConfigParser.ConfigParser()
        config.read(self.config)
        basename = os.path.basename(self.command)
        if not config.has_section(basename):
            logging.error('Koji configuration file "%s" does not have a '
                          'section "%s", named after the base name of the '
                          'currently set koji command "%s"', self.config,
                          basename, self.command)
            koji_config_ok = False

        return koji_config_ok

    def get_default_command(self):
        '''
        Looks up for koji or brew "binaries" on the system

        Systems with plain koji usually don't have a brew cmd, while systems
        with koji, have *both* koji and brew utilities. So we look for brew
        first, and if found, we consider that the system is configured for
        brew. If not, we consider this is a system with plain koji.

        :return: either koji or brew command line executable path, or None
        '''
        koji_command = None
        for command in self.CMD_LOOKUP_ORDER:
            if os.path.isfile(command):
                koji_command = command
                break
            else:
                koji_command_basename = os.path.basename(command)
                try:
                    koji_command = os_dep.command(koji_command_basename)
                    break
                except ValueError:
                    pass
        return koji_command

    def get_pkg_info(self, pkg):
        '''
        Returns information from Koji on the package

        :type pkg: KojiPkgSpec
        :param pkg: information about the package, as a KojiPkgSpec instance

        :return: information from Koji about the specified package
        '''
        info = {}
        if pkg.build is not None:
            info = self.session.getBuild(int(pkg.build))
        elif pkg.tag is not None and pkg.package is not None:
            builds = self.session.listTagged(pkg.tag,
                                             latest=True,
                                             inherit=True,
                                             package=pkg.package)
            if builds:
                info = builds[0]
        return info

    def is_pkg_valid(self, pkg):
        '''
        Checks if this package is altogether valid on Koji

        This verifies if the build or tag specified in the package
        specification actually exist on the Koji server

        :return: True or False
        '''
        valid = True
        if pkg.build:
            if not self.is_pkg_spec_build_valid(pkg):
                valid = False
        elif pkg.tag:
            if not self.is_pkg_spec_tag_valid(pkg):
                valid = False
        else:
            valid = False
        return valid

    def is_pkg_spec_build_valid(self, pkg):
        '''
        Checks if build is valid on Koji

        :param pkg: a Pkg instance
        '''
        if pkg.build is not None:
            info = self.session.getBuild(int(pkg.build))
            if info:
                return True
        return False

    def is_pkg_spec_tag_valid(self, pkg):
        '''
        Checks if tag is valid on Koji

        :type pkg: KojiPkgSpec
        :param pkg: a package specification
        '''
        if pkg.tag is not None:
            tag = self.session.getTag(pkg.tag)
            if tag:
                return True
        return False

    def get_pkg_rpm_info(self, pkg, arch=None):
        '''
        Returns a list of information on the RPM packages found on koji

        :type pkg: KojiPkgSpec
        :param pkg: a package specification
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        if arch is None:
            arch = utils.get_arch()
        rpms = []
        info = self.get_pkg_info(pkg)
        if info:
            rpms = self.session.listRPMs(buildID=info['id'],
                                         arches=[arch, 'noarch'])
            if pkg.subpackages:
                rpms = [d for d in rpms if d['name'] in pkg.subpackages]
        return rpms

    def get_pkg_rpm_names(self, pkg, arch=None):
        '''
        Gets the names for the RPM packages specified in pkg

        :type pkg: KojiPkgSpec
        :param pkg: a package specification
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        if arch is None:
            arch = utils.get_arch()
        rpms = self.get_pkg_rpm_info(pkg, arch)
        return [rpm['name'] for rpm in rpms]

    def get_pkg_rpm_file_names(self, pkg, arch=None):
        '''
        Gets the file names for the RPM packages specified in pkg

        :type pkg: KojiPkgSpec
        :param pkg: a package specification
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        if arch is None:
            arch = utils.get_arch()
        rpm_names = []
        rpms = self.get_pkg_rpm_info(pkg, arch)
        for rpm in rpms:
            arch_rpm_name = koji.pathinfo.rpm(rpm)
            rpm_name = os.path.basename(arch_rpm_name)
            rpm_names.append(rpm_name)
        return rpm_names

    def get_pkg_base_url(self):
        '''
        Gets the base url for packages in Koji
        '''
        if self.config_options.has_key('pkgurl'):
            return self.config_options['pkgurl']
        else:
            return "%s/%s" % (self.config_options['topurl'],
                              'packages')

    def get_scratch_base_url(self):
        '''
        Gets the base url for scratch builds in Koji
        '''
        one_level_up = os.path.dirname(self.get_pkg_base_url())
        return "%s/%s" % (one_level_up, 'scratch')

    def get_pkg_urls(self, pkg, arch=None):
        '''
        Gets the urls for the packages specified in pkg

        :type pkg: KojiPkgSpec
        :param pkg: a package specification
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        info = self.get_pkg_info(pkg)
        rpms = self.get_pkg_rpm_info(pkg, arch)
        rpm_urls = []
        base_url = self.get_pkg_base_url()

        for rpm in rpms:
            rpm_name = koji.pathinfo.rpm(rpm)
            url = ("%s/%s/%s/%s/%s" % (base_url,
                                       info['package_name'],
                                       info['version'], info['release'],
                                       rpm_name))
            rpm_urls.append(url)
        return rpm_urls

    def get_pkgs(self, pkg, dst_dir, arch=None):
        '''
        Download the packages

        :type pkg: KojiPkgSpec
        :param pkg: a package specification
        :type dst_dir: string
        :param dst_dir: the destination directory, where the downloaded
                packages will be saved on
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        rpm_urls = self.get_pkg_urls(pkg, arch)
        for url in rpm_urls:
            dst = os.path.join(dst_dir, os.path.basename(url))
            self._get(url, dst)

    def get_scratch_pkg_urls(self, pkg, arch=None):
        '''
        Gets the urls for the scratch packages specified in pkg

        :type pkg: KojiScratchPkgSpec
        :param pkg: a scratch package specification
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        rpm_urls = []

        if arch is None:
            arch = utils.get_arch()
        arches = [arch, 'noarch']

        index_url = "%s/%s/task_%s" % (self.get_scratch_base_url(),
                                       pkg.user,
                                       pkg.task)
        index_parser = KojiDirIndexParser()
        index_parser.feed(urllib.urlopen(index_url).read())

        if pkg.subpackages:
            for p in pkg.subpackages:
                for pfn in index_parser.package_file_names:
                    r = RPMFileNameInfo(pfn)
                    info = r.get_nvr_info()
                    if (p == info['name'] and
                            r.get_arch() in arches):
                        rpm_urls.append("%s/%s" % (index_url, pfn))
        else:
            for pfn in index_parser.package_file_names:
                if (RPMFileNameInfo(pfn).get_arch() in arches):
                    rpm_urls.append("%s/%s" % (index_url, pfn))

        return rpm_urls

    def get_scratch_pkgs(self, pkg, dst_dir, arch=None):
        '''
        Download the packages from a scratch build

        :type pkg: KojiScratchPkgSpec
        :param pkg: a scratch package specification
        :type dst_dir: string
        :param dst_dir: the destination directory, where the downloaded
                packages will be saved on
        :type arch: string
        :param arch: packages built for this architecture, but also including
                architecture independent (noarch) packages
        '''
        rpm_urls = self.get_scratch_pkg_urls(pkg, arch)
        for url in rpm_urls:
            dst = os.path.join(dst_dir, os.path.basename(url))
            self._get(url, dst)


def set_default_koji_tag(tag):
    '''
    Sets the default tag that will be used
    '''
    global DEFAULT_KOJI_TAG
    DEFAULT_KOJI_TAG = tag


def get_default_koji_tag():
    return DEFAULT_KOJI_TAG


class KojiPkgSpec(object):

    '''
    A package specification syntax parser for Koji

    This holds information on either tag or build, and packages to be fetched
    from koji and possibly installed (features external do this class).

    New objects can be created either by providing information in the textual
    format or by using the actual parameters for tag, build, package and sub-
    packages. The textual format is useful for command line interfaces and
    configuration files, while using parameters is better for using this in
    a programatic fashion.

    The following sets of examples are interchangeable. Specifying all packages
    part of build number 1000:

        >>> from kvm_utils import KojiPkgSpec
        >>> pkg = KojiPkgSpec('1000')

        >>> pkg = KojiPkgSpec(build=1000)

    Specifying only a subset of packages of build number 1000:

        >>> pkg = KojiPkgSpec('1000:kernel,kernel-devel')

        >>> pkg = KojiPkgSpec(build=1000,
                              subpackages=['kernel', 'kernel-devel'])

    Specifying the latest build for the 'kernel' package tagged with 'dist-f14':

        >>> pkg = KojiPkgSpec('dist-f14:kernel')

        >>> pkg = KojiPkgSpec(tag='dist-f14', package='kernel')

    Specifying the 'kernel' package using the default tag:

        >>> kvm_utils.set_default_koji_tag('dist-f14')
        >>> pkg = KojiPkgSpec('kernel')

        >>> pkg = KojiPkgSpec(package='kernel')

    Specifying the 'kernel' package using the default tag:

        >>> kvm_utils.set_default_koji_tag('dist-f14')
        >>> pkg = KojiPkgSpec('kernel')

        >>> pkg = KojiPkgSpec(package='kernel')

    If you do not specify a default tag, and give a package name without an
    explicit tag, your package specification is considered invalid:

        >>> print kvm_utils.get_default_koji_tag()
        None
        >>> print kvm_utils.KojiPkgSpec('kernel').is_valid()
        False

        >>> print kvm_utils.KojiPkgSpec(package='kernel').is_valid()
        False
    '''

    SEP = ':'

    def __init__(self, text='', tag=None, build=None,
                 package=None, subpackages=[]):
        '''
        Instantiates a new KojiPkgSpec object

        :type text: string
        :param text: a textual representation of a package on Koji that
                will be parsed
        :type tag: string
        :param tag: a koji tag, example: Fedora-14-RELEASE
                (see U{http://fedoraproject.org/wiki/Koji#Tags_and_Targets})
        :type build: number
        :param build: a koji build, example: 1001
                (see U{http://fedoraproject.org/wiki/Koji#Koji_Architecture})
        :type package: string
        :param package: a koji package, example: python
                (see U{http://fedoraproject.org/wiki/Koji#Koji_Architecture})
        :type subpackages: list of strings
        :param subpackages: a list of package names, usually a subset of
                the RPM packages generated by a given build
        '''

        # Set to None to indicate 'not set' (and be able to use 'is')
        self.tag = None
        self.build = None
        self.package = None
        self.subpackages = []

        self.default_tag = None

        # Textual representation takes precedence (most common use case)
        if text:
            self.parse(text)
        else:
            self.tag = tag
            self.build = build
            self.package = package
            self.subpackages = subpackages

        # Set the default tag, if set, as a fallback
        if not self.build and not self.tag:
            default_tag = get_default_koji_tag()
            if default_tag is not None:
                self.tag = default_tag

    def parse(self, text):
        '''
        Parses a textual representation of a package specification

        :type text: string
        :param text: textual representation of a package in koji
        '''
        parts = text.count(self.SEP) + 1
        if parts == 1:
            if text.isdigit():
                self.build = text
            else:
                self.package = text
        elif parts == 2:
            part1, part2 = text.split(self.SEP)
            if part1.isdigit():
                self.build = part1
                self.subpackages = part2.split(',')
            else:
                self.tag = part1
                self.package = part2
        elif parts >= 3:
            # Instead of erroring on more arguments, we simply ignore them
            # This makes the parser suitable for future syntax additions, such
            # as specifying the package architecture
            part1, part2, part3 = text.split(self.SEP)[0:3]
            self.tag = part1
            self.package = part2
            self.subpackages = part3.split(',')

    def _is_invalid_neither_tag_or_build(self):
        '''
        Checks if this package is invalid due to not having either a valid
        tag or build set, that is, both are empty.

        :return: True if this is invalid and False if it's valid
        '''
        return (self.tag is None and self.build is None)

    def _is_invalid_package_but_no_tag(self):
        '''
        Checks if this package is invalid due to having a package name set
        but tag or build set, that is, both are empty.

        :return: True if this is invalid and False if it's valid
        '''
        return (self.package and not self.tag)

    def _is_invalid_subpackages_but_no_main_package(self):
        '''
        Checks if this package is invalid due to having a tag set (this is Ok)
        but specifying subpackage names without specifying the main package
        name.

        Specifying subpackages without a main package name is only valid when
        a build is used instead of a tag.

        :return: True if this is invalid and False if it's valid
        '''
        return (self.tag and self.subpackages and not self.package)

    def is_valid(self):
        '''
        Checks if this package specification is valid.

        Being valid means that it has enough and not conflicting information.
        It does not validate that the packages specified actually existe on
        the Koji server.

        :return: True or False
        '''
        if self._is_invalid_neither_tag_or_build():
            return False
        elif self._is_invalid_package_but_no_tag():
            return False
        elif self._is_invalid_subpackages_but_no_main_package():
            return False

        return True

    def describe_invalid(self):
        '''
        Describes why this is not valid, in a human friendly way
        '''
        if self._is_invalid_neither_tag_or_build():
            return ('neither a tag nor a build were set, one of them '
                    'must be set')
        elif self._is_invalid_package_but_no_tag():
            return 'package name specified but no tag is set'
        elif self._is_invalid_subpackages_but_no_main_package():
            return 'subpackages specified but no main package is set'

        return 'unkwown reason, seems to be valid'

    def describe(self):
        '''
        Describe this package specification, in a human friendly way

        :return: package specification description
        '''
        if self.is_valid():
            description = ''
            if not self.subpackages:
                description += 'all subpackages from %s ' % self.package
            else:
                description += ('only subpackage(s) %s from package %s ' %
                                (', '.join(self.subpackages), self.package))

            if self.build:
                description += 'from build %s' % self.build
            elif self.tag:
                description += 'tagged with %s' % self.tag
            else:
                raise ValueError('neither build or tag is set')

            return description
        else:
            return ('Invalid package specification: %s' %
                    self.describe_invalid())

    def to_text(self):
        '''
        Return the textual representation of this package spec

        The output should be consumable by parse() and produce the same
        package specification.

        We find that it's acceptable to put the currently set default tag
        as the package explicit tag in the textual definition for completeness.

        :return: package specification in a textual representation
        '''
        default_tag = get_default_koji_tag()

        if self.build:
            if self.subpackages:
                return "%s:%s" % (self.build, ",".join(self.subpackages))
            else:
                return "%s" % self.build

        elif self.tag:
            if self.subpackages:
                return "%s:%s:%s" % (self.tag, self.package,
                                     ",".join(self.subpackages))
            else:
                return "%s:%s" % (self.tag, self.package)

        elif default_tag is not None:
            # neither build or tag is set, try default_tag as a fallback
            if self.subpackages:
                return "%s:%s:%s" % (default_tag, self.package,
                                     ",".join(self.subpackages))
            else:
                return "%s:%s" % (default_tag, self.package)
        else:
            raise ValueError('neither build or tag is set')

    def __repr__(self):
        return ("<KojiPkgSpec tag=%s build=%s pkg=%s subpkgs=%s>" %
                (self.tag, self.build, self.package,
                 ", ".join(self.subpackages)))


class KojiScratchPkgSpec(object):

    '''
    A package specification syntax parser for Koji scratch builds

    This holds information on user, task and subpackages to be fetched
    from koji and possibly installed (features external do this class).

    New objects can be created either by providing information in the textual
    format or by using the actual parameters for user, task and subpackages.
    The textual format is useful for command line interfaces and configuration
    files, while using parameters is better for using this in a programatic
    fashion.

    This package definition has a special behaviour: if no subpackages are
    specified, all packages of the chosen architecture (plus noarch packages)
    will match.

    The following sets of examples are interchangeable. Specifying all packages
    from a scratch build (whose task id is 1000) sent by user jdoe:

        >>> from kvm_utils import KojiScratchPkgSpec
        >>> pkg = KojiScratchPkgSpec('jdoe:1000')

        >>> pkg = KojiScratchPkgSpec(user=jdoe, task=1000)

    Specifying some packages from a scratch build whose task id is 1000, sent
    by user jdoe:

        >>> pkg = KojiScratchPkgSpec('jdoe:1000:kernel,kernel-devel')

        >>> pkg = KojiScratchPkgSpec(user=jdoe, task=1000,
                                     subpackages=['kernel', 'kernel-devel'])
    '''

    SEP = ':'

    def __init__(self, text='', user=None, task=None, subpackages=[]):
        '''
        Instantiates a new KojiScratchPkgSpec object

        :type text: string
        :param text: a textual representation of a scratch build on Koji that
                will be parsed
        :type task: number
        :param task: a koji task id, example: 1001
        :type subpackages: list of strings
        :param subpackages: a list of package names, usually a subset of
                the RPM packages generated by a given build
        '''
        # Set to None to indicate 'not set' (and be able to use 'is')
        self.user = None
        self.task = None
        self.subpackages = []

        # Textual representation takes precedence (most common use case)
        if text:
            self.parse(text)
        else:
            self.user = user
            self.task = task
            self.subpackages = subpackages

    def parse(self, text):
        '''
        Parses a textual representation of a package specification

        :type text: string
        :param text: textual representation of a package in koji
        '''
        parts = text.count(self.SEP) + 1
        if parts == 1:
            raise ValueError('KojiScratchPkgSpec requires a user and task id')
        elif parts == 2:
            self.user, self.task = text.split(self.SEP)
        elif parts >= 3:
            # Instead of erroring on more arguments, we simply ignore them
            # This makes the parser suitable for future syntax additions, such
            # as specifying the package architecture
            part1, part2, part3 = text.split(self.SEP)[0:3]
            self.user = part1
            self.task = part2
            self.subpackages = part3.split(',')

    def __repr__(self):
        return ("<KojiScratchPkgSpec user=%s task=%s subpkgs=%s>" %
                (self.user, self.task, ", ".join(self.subpackages)))

########NEW FILE########
__FILENAME__ = utils_memory
import re
import glob
import math
import logging
from autotest.client import utils


# Returns total memory in kb
def read_from_meminfo(key):
    cmd_result = utils.run('grep %s /proc/meminfo' % key, verbose=False)
    meminfo = cmd_result.stdout
    return int(re.search(r'\d+', meminfo).group(0))


def memtotal():
    return read_from_meminfo('MemTotal')


def freememtotal():
    return read_from_meminfo('MemFree')


def rounded_memtotal():
    # Get total of all physical mem, in kbytes
    usable_kbytes = memtotal()
    # usable_kbytes is system's usable DRAM in kbytes,
    #   as reported by memtotal() from device /proc/meminfo memtotal
    #   after Linux deducts 1.5% to 5.1% for system table overhead
    # Undo the unknown actual deduction by rounding up
    #   to next small multiple of a big power-of-two
    #   eg  12GB - 5.1% gets rounded back up to 12GB
    mindeduct = 0.015  # 1.5 percent
    maxdeduct = 0.055  # 5.5 percent
    # deduction range 1.5% .. 5.5% supports physical mem sizes
    #    6GB .. 12GB in steps of .5GB
    #   12GB .. 24GB in steps of 1 GB
    #   24GB .. 48GB in steps of 2 GB ...
    # Finer granularity in physical mem sizes would require
    #   tighter spread between min and max possible deductions

    # increase mem size by at least min deduction, without rounding
    min_kbytes = int(usable_kbytes / (1.0 - mindeduct))
    # increase mem size further by 2**n rounding, by 0..roundKb or more
    round_kbytes = int(usable_kbytes / (1.0 - maxdeduct)) - min_kbytes
    # find least binary roundup 2**n that covers worst-cast roundKb
    mod2n = 1 << int(math.ceil(math.log(round_kbytes, 2)))
    # have round_kbytes <= mod2n < round_kbytes*2
    # round min_kbytes up to next multiple of mod2n
    phys_kbytes = min_kbytes + mod2n - 1
    phys_kbytes = phys_kbytes - (phys_kbytes % mod2n)  # clear low bits
    return phys_kbytes


def numa_nodes():
    node_paths = glob.glob('/sys/devices/system/node/node*')
    nodes = [int(re.sub(r'.*node(\d+)', r'\1', x)) for x in node_paths]
    return (sorted(nodes))


def node_size():
    nodes = max(len(numa_nodes()), 1)
    return ((memtotal() * 1024) / nodes)


def get_huge_page_size():
    output = utils.system_output('grep Hugepagesize /proc/meminfo')
    return int(output.split()[1])  # Assumes units always in kB. :(


def get_num_huge_pages():
    raw_hugepages = utils.system_output('/sbin/sysctl vm.nr_hugepages')
    return int(raw_hugepages.split()[2])


def set_num_huge_pages(num):
    utils.system('/sbin/sysctl vm.nr_hugepages=%d' % num)


def drop_caches():
    """Writes back all dirty pages to disk and clears all the caches."""
    utils.run("sync", verbose=False)
    # We ignore failures here as this will fail on 2.6.11 kernels.
    utils.run("echo 3 > /proc/sys/vm/drop_caches", ignore_status=True,
              verbose=False)


def read_from_vmstat(key):
    """
    Get specific item value from vmstat

    :param key: The item you want to check from vmstat
    :type key: String
    :return: The value of the item
    :rtype: int
    """
    vmstat = open("/proc/vmstat")
    vmstat_info = vmstat.read()
    vmstat.close()
    return int(re.findall("%s\s+(\d+)" % key, vmstat_info)[0])


def read_from_smaps(pid, key):
    """
    Get specific item value from the smaps of a process include all sections.

    :param pid: Process id
    :type pid: String
    :param key: The item you want to check from smaps
    :type key: String
    :return: The value of the item in kb
    :rtype: int
    """
    smaps = open("/proc/%s/smaps" % pid)
    smaps_info = smaps.read()
    smaps.close()

    memory_size = 0
    for each_number in re.findall("%s:\s+(\d+)" % key, smaps_info):
        memory_size += int(each_number)

    return memory_size


def read_from_numa_maps(pid, key):
    """
    Get the process numa related info from numa_maps. This function
    only use to get the numbers like anon=1.

    :param pid: Process id
    :type pid: String
    :param key: The item you want to check from numa_maps
    :type key: String
    :return: A dict using the address as the keys
    :rtype: dict
    """
    numa_maps = open("/proc/%s/numa_maps" % pid)
    numa_map_info = numa_maps.read()
    numa_maps.close()

    numa_maps_dict = {}
    numa_pattern = r"(^[\dabcdfe]+)\s+.*%s[=:](\d+)" % key
    for address, number in re.findall(numa_pattern, numa_map_info, re.M):
        numa_maps_dict[address] = number

    return numa_maps_dict


def get_buddy_info(chunk_sizes, nodes="all", zones="all"):
    """
    Get the fragement status of the host. It use the same method
    to get the page size in buddyinfo.
    2^chunk_size * page_size
    The chunk_sizes can be string make up by all orders that you want to check
    splited with blank or a mathematical expression with '>', '<' or '='.
    For example:
    The input of chunk_size could be: "0 2 4"
    And the return  will be: {'0': 3, '2': 286, '4': 687}
    if you are using expression: ">=9"
    the return will be: {'9': 63, '10': 225}

    :param chunk_size: The order number shows in buddyinfo. This is not
                       the real page size.
    :type chunk_size: string
    :param nodes: The numa node that you want to check. Default value is all
    :type nodes: string
    :param zones: The memory zone that you want to check. Default value is all
    :type zones: string
    :return: A dict using the chunk_size as the keys
    :rtype: dict
    """
    buddy_info = open("/proc/buddyinfo")
    buddy_info_content = buddy_info.read()
    buddy_info.close()

    re_buddyinfo = "Node\s+"
    if nodes == "all":
        re_buddyinfo += "(\d+)"
    else:
        re_buddyinfo += "(%s)" % "|".join(nodes.split())

    if not re.findall(re_buddyinfo, buddy_info_content):
        logging.warn("Can not find Nodes %s" % nodes)
        return None
    re_buddyinfo += ".*?zone\s+"
    if zones == "all":
        re_buddyinfo += "(\w+)"
    else:
        re_buddyinfo += "(%s)" % "|".join(zones.split())
    if not re.findall(re_buddyinfo, buddy_info_content):
        logging.warn("Can not find zones %s" % zones)
        return None
    re_buddyinfo += "\s+([\s\d]+)"

    buddy_list = re.findall(re_buddyinfo, buddy_info_content)

    if re.findall("[<>=]", chunk_sizes) and buddy_list:
        size_list = range(len(buddy_list[-1][-1].strip().split()))
        chunk_sizes = [str(_) for _ in size_list if eval("%s %s" % (_,
                                                                    chunk_sizes))]

        chunk_sizes = ' '.join(chunk_sizes)

    buddyinfo_dict = {}
    for chunk_size in chunk_sizes.split():
        buddyinfo_dict[chunk_size] = 0
        for _, _, chunk_info in buddy_list:
            chunk_info = chunk_info.strip().split()[int(chunk_size)]
            buddyinfo_dict[chunk_size] += int(chunk_info)

    return buddyinfo_dict

########NEW FILE########
__FILENAME__ = standalone_test
import os
import logging
import imp
import sys
import time
import traceback
import Queue
import glob
import shutil
from autotest.client.shared import error
from autotest.client import utils
import aexpect
import asset
import utils_misc
import utils_params
import utils_env
import utils_net
import env_process
import data_dir
import bootstrap
import storage
import cartesian_config
import arch
import funcatexit
import version
import qemu_vm
import defaults

global GUEST_NAME_LIST
GUEST_NAME_LIST = None
global TAG_INDEX
TAG_INDEX = {}


class Test(object):

    """
    Mininal test class used to run a virt test.
    """

    env_version = utils_env.get_env_version()

    def __init__(self, params, options):
        self.params = utils_params.Params(params)
        self.bindir = data_dir.get_root_dir()
        self.virtdir = os.path.join(self.bindir, 'shared')
        self.builddir = os.path.join(self.bindir, 'backends', params.get("vm_type"))

        self.srcdir = os.path.join(self.builddir, 'src')
        if not os.path.isdir(self.srcdir):
            os.makedirs(self.srcdir)

        self.tmpdir = os.path.join(self.bindir, 'tmp')
        if not os.path.isdir(self.tmpdir):
            os.makedirs(self.tmpdir)

        self.iteration = 0
        if options.config:
            self.tag = params.get("shortname")
        else:
            self.tag = params.get("_short_name_map_file")["subtests.cfg"]
        self.debugdir = None
        self.outputdir = None
        self.resultsdir = None
        self.logfile = None
        self.file_handler = None
        self.background_errors = Queue.Queue()

    def set_debugdir(self, debugdir):
        self.debugdir = os.path.join(debugdir, self.tag)
        self.outputdir = self.debugdir
        if not os.path.isdir(self.debugdir):
            os.makedirs(self.debugdir)
        self.resultsdir = os.path.join(self.debugdir, 'results')
        if not os.path.isdir(self.resultsdir):
            os.makedirs(self.resultsdir)
        self.profdir = os.path.join(self.resultsdir, 'profiling')
        if not os.path.isdir(self.profdir):
            os.makedirs(self.profdir)
        utils_misc.set_log_file_dir(self.debugdir)
        self.logfile = os.path.join(self.debugdir, 'debug.log')

    def write_test_keyval(self, d):
        utils.write_keyval(self.debugdir, d)

    def start_file_logging(self):
        self.file_handler = configure_file_logging(self.logfile)

    def stop_file_logging(self):
        logger = logging.getLogger()
        logger.removeHandler(self.file_handler)
        self.file_handler.close()

    def verify_background_errors(self):
        """
        Verify if there are any errors that happened on background threads.

        :raise Exception: Any exception stored on the background_errors queue.
        """
        try:
            exc = self.background_errors.get(block=False)
        except Queue.Empty:
            pass
        else:
            raise exc[1], None, exc[2]

    def run_once(self):
        params = self.params

        # If a dependency test prior to this test has failed, let's fail
        # it right away as TestNA.
        if params.get("dependency_failed") == 'yes':
            raise error.TestNAError("Test dependency failed")

        # Report virt test version
        logging.info(version.get_pretty_version_info())
        # Report the parameters we've received and write them as keyvals
        logging.info("Starting test %s", self.tag)
        logging.debug("Test parameters:")
        keys = params.keys()
        keys.sort()
        for key in keys:
            logging.debug("    %s = %s", key, params[key])

        # Warn of this special condition in related location in output & logs
        if os.getuid() == 0 and params.get('nettype', 'user') == 'user':
            logging.warning("")
            logging.warning("Testing with nettype='user' while running "
                            "as root may produce unexpected results!!!")
            logging.warning("")

        # Open the environment file
        env_filename = os.path.join(
            data_dir.get_backend_dir(params.get("vm_type")),
            params.get("env", "env"))
        env = utils_env.Env(env_filename, self.env_version)

        test_passed = False
        t_types = None
        t_type = None

        try:
            try:
                try:
                    subtest_dirs = []

                    other_subtests_dirs = params.get("other_tests_dirs", "")
                    for d in other_subtests_dirs.split():
                        d = os.path.join(*d.split("/"))
                        subtestdir = os.path.join(self.bindir, d, "tests")
                        if not os.path.isdir(subtestdir):
                            raise error.TestError("Directory %s does not "
                                                  "exist" % (subtestdir))
                        subtest_dirs += data_dir.SubdirList(subtestdir,
                                                            bootstrap.test_filter)

                    provider = params.get("provider", None)

                    if provider is None:
                        # Verify if we have the correspondent source file for it
                        for generic_subdir in asset.get_test_provider_subdirs('generic'):
                            subtest_dirs += data_dir.SubdirList(generic_subdir,
                                                                bootstrap.test_filter)

                        for specific_subdir in asset.get_test_provider_subdirs(params.get("vm_type")):
                            subtest_dirs += data_dir.SubdirList(specific_subdir,
                                                                bootstrap.test_filter)
                    else:
                        provider_info = asset.get_test_provider_info(provider)
                        for key in provider_info['backends']:
                            subtest_dirs += data_dir.SubdirList(
                                provider_info['backends'][key]['path'],
                                bootstrap.test_filter)

                    subtest_dir = None

                    # Get the test routine corresponding to the specified
                    # test type
                    logging.debug("Searching for test modules that match "
                                  "'type = %s' and 'provider = %s' "
                                  "on this cartesian dict",
                                  params.get("type"), params.get("provider", None))

                    t_types = params.get("type").split()
                    # Make sure we can load provider_lib in tests
                    for s in subtest_dirs:
                        if os.path.dirname(s) not in sys.path:
                            sys.path.insert(0, os.path.dirname(s))

                    test_modules = {}
                    for t_type in t_types:
                        for d in subtest_dirs:
                            module_path = os.path.join(d, "%s.py" % t_type)
                            if os.path.isfile(module_path):
                                logging.debug("Found subtest module %s",
                                              module_path)
                                subtest_dir = d
                                break
                        if subtest_dir is None:
                            msg = ("Could not find test file %s.py on test"
                                   "dirs %s" % (t_type, subtest_dirs))
                            raise error.TestError(msg)
                        # Load the test module
                        f, p, d = imp.find_module(t_type, [subtest_dir])
                        test_modules[t_type] = imp.load_module(t_type, f, p, d)
                        f.close()

                    # Preprocess
                    try:
                        params = env_process.preprocess(self, params, env)
                    finally:
                        env.save()

                    # Run the test function
                    for t_type, test_module in test_modules.items():
                        run_func = utils_misc.get_test_entrypoint_func(
                            t_type, test_module)
                        try:
                            run_func(self, params, env)
                            self.verify_background_errors()
                        finally:
                            env.save()
                    test_passed = True
                    error_message = funcatexit.run_exitfuncs(env, t_type)
                    if error_message:
                        raise error.TestWarn("funcatexit failed with: %s"
                                             % error_message)

                except Exception, e:
                    if (t_type is not None):
                        error_message = funcatexit.run_exitfuncs(env, t_type)
                        if error_message:
                            logging.error(error_message)
                    try:
                        env_process.postprocess_on_error(self, params, env)
                    finally:
                        env.save()
                    raise

            finally:
                # Postprocess
                try:
                    try:
                        env_process.postprocess(self, params, env)
                    except Exception, e:
                        if test_passed:
                            raise
                        logging.error("Exception raised during "
                                      "postprocessing: %s", e)
                finally:
                    env.save()

        except Exception, e:
            if params.get("abort_on_error") != "yes":
                raise
            # Abort on error
            logging.info("Aborting job (%s)", e)
            if params.get("vm_type") == "qemu":
                for vm in env.get_all_vms():
                    if vm.is_dead():
                        continue
                    logging.info("VM '%s' is alive.", vm.name)
                    for m in vm.monitors:
                        logging.info("It has a %s monitor unix socket at: %s",
                                     m.protocol, m.filename)
                    logging.info("The command line used to start it was:\n%s",
                                 vm.make_qemu_command())
                raise error.JobError("Abort requested (%s)" % e)

        return test_passed


def print_stdout(sr, end=True):
    try:
        sys.stdout.restore()
    except AttributeError:
        pass
    if end:
        print(sr)
    else:
        print(sr),
    try:
        sys.stdout.redirect()
    except AttributeError:
        pass


class Bcolors(object):

    """
    Very simple class with color support.
    """

    def __init__(self):
        self.blue = '\033[94m'
        self.green = '\033[92m'
        self.yellow = '\033[93m'
        self.red = '\033[91m'
        self.end = '\033[0m'
        self.HEADER = self.blue
        self.PASS = self.green
        self.SKIP = self.yellow
        self.FAIL = self.red
        self.ERROR = self.red
        self.WARN = self.yellow
        self.ENDC = self.end
        allowed_terms = ['linux', 'xterm', 'xterm-256color', 'vt100',
                         'screen', 'screen-256color']
        term = os.environ.get("TERM")
        if (not os.isatty(1)) or (term not in allowed_terms):
            self.disable()

    def disable(self):
        self.blue = ''
        self.green = ''
        self.yellow = ''
        self.red = ''
        self.end = ''
        self.HEADER = ''
        self.PASS = ''
        self.SKIP = ''
        self.FAIL = ''
        self.ERROR = ''
        self.WARN = ''
        self.ENDC = ''

# Instantiate bcolors to be used in the functions below.
bcolors = Bcolors()


def print_header(sr):
    """
    Print a string to stdout with HEADER (blue) color.
    """
    print_stdout(bcolors.HEADER + sr + bcolors.ENDC)


def print_skip(open_fd=False):
    """
    Print SKIP to stdout with SKIP (yellow) color.
    """
    normal_skip_msg = bcolors.SKIP + "SKIP" + bcolors.ENDC
    fd_skip_msg = (bcolors.SKIP +
                   "SKIP (%s fd)" % utils_misc.get_virt_test_open_fds() +
                   bcolors.ENDC)
    if open_fd:
        msg = fd_skip_msg
    else:
        msg = normal_skip_msg

    print_stdout(msg)


def print_error(t_elapsed, open_fd=False):
    """
    Print ERROR to stdout with ERROR (red) color.
    """
    normal_error_msg = (bcolors.ERROR + "ERROR" +
                        bcolors.ENDC + " (%.2f s)" % t_elapsed)
    fd_error_msg = (bcolors.ERROR + "ERROR" +
                    bcolors.ENDC + " (%.2f s) (%s fd)" %
                    (t_elapsed, utils_misc.get_virt_test_open_fds()))
    if open_fd:
        msg = fd_error_msg
    else:
        msg = normal_error_msg

    print_stdout(msg)


def print_pass(t_elapsed, open_fd=False):
    """
    Print PASS to stdout with PASS (green) color.
    """
    normal_pass_msg = (bcolors.PASS + "PASS" +
                       bcolors.ENDC + " (%.2f s)" % t_elapsed)
    fd_pass_msg = (bcolors.PASS + "PASS" +
                   bcolors.ENDC + " (%.2f s) (%s fd)" %
                   (t_elapsed, utils_misc.get_virt_test_open_fds()))
    if open_fd:
        msg = fd_pass_msg
    else:
        msg = normal_pass_msg

    print_stdout(msg)


def print_fail(t_elapsed, open_fd=False):
    """
    Print FAIL to stdout with FAIL (red) color.
    """
    normal_fail_msg = (bcolors.FAIL + "FAIL" +
                       bcolors.ENDC + " (%.2f s)" % t_elapsed)
    fd_fail_msg = (bcolors.FAIL + "FAIL" +
                   bcolors.ENDC + " (%.2f s) (%s fd)" %
                   (t_elapsed, utils_misc.get_virt_test_open_fds()))
    if open_fd:
        msg = fd_fail_msg
    else:
        msg = normal_fail_msg

    print_stdout(msg)


def print_warn(t_elapsed, open_fd=False):
    """
    Print WARN to stdout with WARN (yellow) color.
    """
    normal_warn_msg = (bcolors.WARN + "WARN" +
                       bcolors.ENDC + " (%.2f s)" % t_elapsed)
    fd_warn_msg = (bcolors.WARN + "WARN" +
                   bcolors.ENDC + " (%.2f s) (%s fd)" %
                   (t_elapsed, utils_misc.get_virt_test_open_fds()))
    if open_fd:
        msg = fd_warn_msg
    else:
        msg = normal_warn_msg

    print_stdout(msg)


def reset_logging():
    """
    Remove all the handlers and unset the log level on the root logger.
    """
    logger = logging.getLogger()
    for hdlr in logger.handlers:
        logger.removeHandler(hdlr)
    logger.setLevel(logging.NOTSET)


def configure_console_logging(loglevel=logging.DEBUG):
    """
    Simple helper for adding a file logger to the root logger.
    """
    logger = logging.getLogger()
    stream_handler = logging.StreamHandler()
    stream_handler.setLevel(loglevel)

    fmt = '%(asctime)s %(levelname)-5.5s| %(message)s'
    formatter = logging.Formatter(fmt=fmt, datefmt='%H:%M:%S')

    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)

    return stream_handler


def configure_file_logging(logfile, loglevel=logging.DEBUG):
    """
    Simple helper for adding a file logger to the root logger.
    """
    logger = logging.getLogger()
    file_handler = logging.FileHandler(filename=logfile)
    file_handler.setLevel(loglevel)

    fmt = '%(asctime)s %(levelname)-5.5s| %(message)s'
    formatter = logging.Formatter(fmt=fmt, datefmt='%H:%M:%S')

    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    return file_handler


def create_config_files(options):
    """
    Check if the appropriate configuration files are present.

    If the files are not present, create them.

    :param options: OptParser object with options.
    """
    shared_dir = os.path.dirname(data_dir.get_data_dir())
    test_dir = os.path.dirname(shared_dir)

    if (options.type and options.config):
        test_dir = data_dir.get_backend_dir(options.type)
    elif options.type:
        test_dir = data_dir.get_backend_dir(options.type)
    elif options.config:
        parent_config_dir = os.path.dirname(options.config)
        parent_config_dir = os.path.dirname(parent_config_dir)
        options.type = parent_config_dir
        test_dir = os.path.join(test_dir, parent_config_dir)

    if not os.path.exists(os.path.join(test_dir, "cfg")):
        print_stdout("Setup error: %s does not exist" %
                     os.path.join(test_dir, "cfg"))
        print_stdout("Perhaps you have not specified -t?")
        sys.exit(1)
    # lvsb test doesn't use shared configs
    if options.type != 'lvsb':
        bootstrap.create_config_files(test_dir, shared_dir, interactive=False)
        bootstrap.create_guest_os_cfg(options.type)
    bootstrap.create_subtests_cfg(options.type)


def get_paginator():
    try:
        less_cmd = utils_misc.find_command('less')
        return os.popen('%s -FRSX' % less_cmd, 'w')
    except ValueError:
        return sys.stdout


def get_cartesian_parser_details(cartesian_parser):
    """
    Print detailed information about filters applied to the cartesian cfg.

    :param cartesian_parser: Cartesian parser object.
    """
    details = ""
    details += ("Tests produced by config file %s\n\n" %
                cartesian_parser.filename)

    details += "The full test list was modified by the following:\n\n"

    if cartesian_parser.only_filters:
        details += "Filters applied:\n"
        for flt in cartesian_parser.only_filters:
            details += "    %s\n" % flt

    if cartesian_parser.no_filters:
        for flt in cartesian_parser.no_filters:
            details += "    %s\n" % flt

    details += "\n"
    details += "Different guest OS have different test lists\n"
    details += "\n"

    if cartesian_parser.assignments:
        details += "Assignments applied:\n"
        for flt in cartesian_parser.assignments:
            details += "    %s\n" % flt

    details += "\n"
    details += "Assignments override values previously set in the config file\n"
    details += "\n"

    return details


def print_test_list(options, cartesian_parser):
    """
    Helper function to pretty print the test list.

    This function uses a paginator, if possible (inspired on git).

    :param options: OptParse object with cmdline options.
    :param cartesian_parser: Cartesian parser object with test options.
    """
    pipe = get_paginator()
    index = 0

    pipe.write(get_cartesian_parser_details(cartesian_parser))
    for params in cartesian_parser.get_dicts():
        virt_test_type = params.get('virt_test_type', "")
        supported_virt_backends = virt_test_type.split(" ")
        if options.type in supported_virt_backends:
            index += 1
            shortname = params.get("_short_name_map_file")["subtests.cfg"]
            needs_root = ((params.get('requires_root', 'no') == 'yes')
                          or (params.get('vm_type') != 'qemu'))
            basic_out = (bcolors.blue + str(index) + bcolors.end + " " +
                         shortname)
            if needs_root:
                out = (basic_out + bcolors.yellow + " (requires root)" +
                       bcolors.end + "\n")
            else:
                out = basic_out + "\n"
            try:
                pipe.write(out)
            except IOError:
                return


def get_guest_name_parser(options):
    cartesian_parser = cartesian_config.Parser()
    machines_cfg_path = data_dir.get_backend_cfg_path(options.type,
                                                      'machines.cfg')
    guest_os_cfg_path = data_dir.get_backend_cfg_path(options.type,
                                                      'guest-os.cfg')
    cartesian_parser.parse_file(machines_cfg_path)
    cartesian_parser.parse_file(guest_os_cfg_path)
    if options.arch:
        cartesian_parser.only_filter(options.arch)
    if options.machine_type:
        cartesian_parser.only_filter(options.machine_type)
    if options.guest_os:
        cartesian_parser.only_filter(options.guest_os)
    return cartesian_parser


def get_guest_name_list(options):
    global GUEST_NAME_LIST
    if GUEST_NAME_LIST is None:
        guest_name_list = []
        for params in get_guest_name_parser(options).get_dicts():
            shortname = ".".join(params['name'].split(".")[1:])
            guest_name_list.append(shortname)

        GUEST_NAME_LIST = guest_name_list

    return GUEST_NAME_LIST


def print_guest_list(options):
    """
    Helper function to pretty print the guest list.

    This function uses a paginator, if possible (inspired on git).

    :param options: OptParse object with cmdline options.
    :param cartesian_parser: Cartesian parser object with test options.
    """
    pipe = get_paginator()
    # lvsb testing has no concept of guests
    if options.type == 'lvsb':
        pipe.write("No guest types available for lvsb testing")
        return
    index = 0
    pipe.write("Searched %s for guest images\n" %
               os.path.join(data_dir.get_data_dir(), 'images'))
    pipe.write("Available guests:")
    pipe.write("\n\n")
    for params in get_guest_name_parser(options).get_dicts():
        index += 1
        base_dir = params.get("images_base_dir", data_dir.get_data_dir())
        image_name = storage.get_image_filename(params, base_dir)
        name = params['name']
        if os.path.isfile(image_name):
            out = (bcolors.blue + str(index) + bcolors.end + " " +
                   name + "\n")
        else:
            out = (bcolors.blue + str(index) + bcolors.end + " " +
                   name + " " + bcolors.yellow +
                   "(missing %s)" % os.path.basename(image_name) +
                   bcolors.end + "\n")
        pipe.write(out)


def bootstrap_tests(options):
    """
    Bootstrap process (download the appropriate JeOS file to data dir).

    This function will check whether the JeOS is in the right location of the
    data dir, if not, it will download it non interactively.

    :param options: OptParse object with program command line options.
    """
    if options.type:
        test_dir = data_dir.get_backend_dir(options.type)
    elif options.config:
        parent_config_dir = os.path.dirname(os.path.dirname(options.config))
        parent_config_dir = os.path.dirname(parent_config_dir)
        options.type = parent_config_dir
        test_dir = os.path.abspath(parent_config_dir)

    if options.type == 'qemu':
        check_modules = arch.get_kvm_module_list()
    else:
        check_modules = None
    online_docs_url = "https://github.com/autotest/virt-test/wiki"

    if not options.config:
        restore_image = not options.keep_image
    else:
        restore_image = False

    os_info = defaults.get_default_guest_os_info()

    kwargs = {'test_name': options.type,
              'test_dir': test_dir,
              'base_dir': data_dir.get_data_dir(),
              'default_userspace_paths': None,
              'check_modules': check_modules,
              'online_docs_url': online_docs_url,
              'download_image': not options.no_downloads,
              'selinux': options.selinux_setup,
              'restore_image': restore_image,
              'interactive': False,
              'update_providers': options.update_providers,
              'guest_os': options.guest_os or os_info['variant']}

    # Tolerance we have without printing a message for the user to wait (3 s)
    tolerance = 3
    failed = False
    wait_message_printed = False

    bg = utils.InterruptedThread(bootstrap.bootstrap, kwargs=kwargs)
    t_begin = time.time()
    bg.start()

    while bg.isAlive():
        t_elapsed = time.time() - t_begin
        if t_elapsed > tolerance and not wait_message_printed:
            print_stdout("Running setup. Please wait...")
            wait_message_printed = True
            # if bootstrap takes too long, we temporarily make stdout verbose
            # again, so the user can see what's taking so long
            sys.stdout.restore()
        time.sleep(0.1)

    # in case stdout was restored above, redirect it again
    sys.stdout.redirect()

    reason = None
    try:
        bg.join()
    except Exception, e:
        failed = True
        reason = e

    t_end = time.time()
    t_elapsed = t_end - t_begin

    print_stdout(bcolors.HEADER + "SETUP:" + bcolors.ENDC, end=False)

    if not failed:
        print_pass(t_elapsed, open_fd=options.show_open_fd)
    else:
        print_fail(t_elapsed, open_fd=options.show_open_fd)
        print_stdout("Setup error: %s" % reason)
        sys.exit(-1)

    return True


def cleanup_env(parser, options):
    """
    Clean up virt-test temporary files.

    :param parser: Cartesian parser with run parameters.
    :param options: Test runner options object.
    """
    if options.no_cleanup:
        logging.info("Option --no-cleanup requested, not cleaning temporary "
                     "files and VM processes...")
        logging.info("")
    else:
        logging.info("Cleaning tmp files and VM processes...")
        d = parser.get_dicts().next()
        env_filename = os.path.join(data_dir.get_root_dir(),
                                    options.type, d.get("env", "env"))
        env = utils_env.Env(filename=env_filename, version=Test.env_version)
        env.destroy()
        # Kill all tail_threads which env constructor recreate.
        aexpect.kill_tail_threads()
        aexpect.clean_tmp_files()
        utils_net.clean_tmp_files()
        data_dir.clean_tmp_files()
        qemu_vm.clean_tmp_files()
        logging.info("")


def _job_report(job_elapsed_time, n_tests, n_tests_skipped, n_tests_failed):
    """
    Print to stdout and run log stats of our test job.

    :param job_elapsed_time: Time it took for the tests to execute.
    :param n_tests: Total Number of tests executed.
    :param n_tests_skipped: Total Number of tests skipped.
    :param n_tests_passed: Number of tests that passed.
    """
    minutes, seconds = divmod(job_elapsed_time, 60)
    hours, minutes = divmod(minutes, 60)

    pretty_time = ""
    if hours:
        pretty_time += "%02d:" % hours
    if hours or minutes:
        pretty_time += "%02d:" % minutes
    pretty_time += "%02d" % seconds

    total_time_str = "TOTAL TIME: %.2f s" % job_elapsed_time
    if hours or minutes:
        total_time_str += " (%s)" % pretty_time

    print_header(total_time_str)
    logging.info("Job total elapsed time: %.2f s", job_elapsed_time)

    n_tests_passed = n_tests - n_tests_skipped - n_tests_failed
    success_rate = 0
    if (n_tests - n_tests_skipped > 0):
        success_rate = ((float(n_tests_passed) /
                         float(n_tests - n_tests_skipped)) * 100)

    print_header("TESTS PASSED: %d" % n_tests_passed)
    print_header("TESTS FAILED: %d" % n_tests_failed)
    if n_tests_skipped:
        print_header("TESTS SKIPPED: %d" % n_tests_skipped)
    print_header("SUCCESS RATE: %.2f %%" % success_rate)

    logging.info("Tests passed: %d", n_tests_passed)
    logging.info("Tests failed: %d", n_tests_failed)
    if n_tests_skipped:
        logging.info("Tests skipped: %d", n_tests_skipped)
    logging.info("Success rate: %.2f %%", success_rate)


def run_tests(parser, options):
    """
    Runs the sequence of KVM tests based on the list of dctionaries
    generated by the configuration system, handling dependencies.

    :param parser: Config parser object.
    :param options: Test runner options object.
    :return: True, if all tests ran passed, False if any of them failed.
    """
    test_start_time = time.strftime('%Y-%m-%d-%H.%M.%S')
    logdir = options.logdir or os.path.join(data_dir.get_root_dir(), 'logs')
    debugbase = 'run-%s' % test_start_time
    debugdir = os.path.join(logdir, debugbase)
    latestdir = os.path.join(logdir, "latest")
    if not os.path.isdir(debugdir):
        os.makedirs(debugdir)
    try:
        os.unlink(latestdir)
    except OSError, detail:
        pass
    os.symlink(debugbase, latestdir)

    debuglog = os.path.join(debugdir, "debug.log")
    loglevel = options.log_level
    configure_file_logging(debuglog, loglevel)

    print_stdout(bcolors.HEADER +
                 "DATA DIR: %s" % data_dir.get_backing_data_dir() +
                 bcolors.ENDC)

    print_header("DEBUG LOG: %s" % debuglog)

    last_index = -1

    logging.info("Starting test job at %s", test_start_time)
    logging.info("")

    logging.info(version.get_pretty_version_info())
    logging.info("")

    cleanup_env(parser, options)

    d = parser.get_dicts().next()

    if not options.config:
        if not options.keep_image_between_tests:
            logging.debug("Creating first backup of guest image")
            qemu_img = storage.QemuImg(d, data_dir.get_data_dir(), "image")
            qemu_img.backup_image(d, data_dir.get_data_dir(), 'backup', True)
            logging.debug("")

    for line in get_cartesian_parser_details(parser).splitlines():
        logging.info(line)

    logging.info("Defined test set:")
    for i, d in enumerate(parser.get_dicts()):
        shortname = d.get("_name_map_file")["subtests.cfg"]

        logging.info("Test %4d:  %s", i + 1, shortname)
        last_index += 1

    if last_index == -1:
        print_stdout("No tests generated by config file %s" % parser.filename)
        print_stdout("Please check the file for errors (bad variable names, "
                     "wrong indentation)")
        sys.exit(-1)
    logging.info("")

    n_tests = last_index + 1
    n_tests_failed = 0
    n_tests_skipped = 0
    print_header("TESTS: %s" % n_tests)

    status_dct = {}
    failed = False
    # Add the parameter decide if setup host env in the test case
    # For some special tests we only setup host in the first and last case
    # When we need to setup host env we need the host_setup_flag as following:
    #    0(00): do nothing
    #    1(01): setup env
    #    2(10): cleanup env
    #    3(11): setup and cleanup env
    index = 0
    setup_flag = 1
    cleanup_flag = 2
    job_start_time = time.time()

    for dct in parser.get_dicts():
        shortname = d.get("_short_name_map_file")["subtests.cfg"]

        if index == 0:
            if dct.get("host_setup_flag", None) is not None:
                flag = int(dct["host_setup_flag"])
                dct["host_setup_flag"] = flag | setup_flag
            else:
                dct["host_setup_flag"] = setup_flag
        if index == last_index:
            if dct.get("host_setup_flag", None) is not None:
                flag = int(dct["host_setup_flag"])
                dct["host_setup_flag"] = flag | cleanup_flag
            else:
                dct["host_setup_flag"] = cleanup_flag
        index += 1

        # Add kvm module status
        dct["kvm_default"] = utils_misc.get_module_params(
            dct.get("sysfs_dir", "/sys"), "kvm")

        if dct.get("skip") == "yes":
            continue

        dependencies_satisfied = True
        for dep in dct.get("dep"):
            for test_name in status_dct.keys():
                if dep not in test_name:
                    continue

                if not status_dct[test_name]:
                    dependencies_satisfied = False
                    break

        current_status = False

        pretty_index = "(%d/%d)" % (index, n_tests)

        t = Test(dct, options)
        print_stdout("%s %s:" % (pretty_index, t.tag), end=False)

        if dependencies_satisfied:
            t.set_debugdir(debugdir)
            try:
                try:
                    t_begin = time.time()
                    t.start_file_logging()
                    current_status = t.run_once()
                    if current_status:
                        logging.info("PASS %s", t.tag)
                    else:
                        logging.info("FAIL %s", t.tag)
                    logging.info("")
                    t.stop_file_logging()
                finally:
                    t_end = time.time()
                    t_elapsed = t_end - t_begin
            except error.TestError, reason:
                n_tests_failed += 1
                logging.info("ERROR %s -> %s: %s", t.tag,
                             reason.__class__.__name__, reason)
                logging.info("")
                t.stop_file_logging()
                print_error(t_elapsed, open_fd=options.show_open_fd)
                status_dct[dct.get("name")] = False
                continue
            except error.TestNAError, reason:
                n_tests_skipped += 1
                logging.info("SKIP %s -> %s: %s", t.tag,
                             reason.__class__.__name__, reason)
                logging.info("")
                t.stop_file_logging()
                print_skip(open_fd=options.show_open_fd)
                status_dct[dct.get("name")] = False
                continue
            except error.TestWarn, reason:
                logging.info("WARN %s -> %s: %s", t.tag,
                             reason.__class__.__name__,
                             reason)
                logging.info("")
                t.stop_file_logging()
                print_warn(t_elapsed, open_fd=options.show_open_fd)
                status_dct[dct.get("name")] = True
                continue
            except Exception, reason:
                n_tests_failed += 1
                exc_type, exc_value, exc_traceback = sys.exc_info()
                logging.error("")
                tb_info = traceback.format_exception(exc_type, exc_value,
                                                     exc_traceback.tb_next)
                tb_info = "".join(tb_info)
                for e_line in tb_info.splitlines():
                    logging.error(e_line)
                logging.error("")
                logging.error("FAIL %s -> %s: %s", t.tag,
                              reason.__class__.__name__,
                              reason)
                logging.info("")
                t.stop_file_logging()
                current_status = False
        else:
            print_skip(open_fd=options.show_open_fd)
            status_dct[dct.get("name")] = False
            continue

        if not current_status:
            failed = True
            print_fail(t_elapsed, open_fd=options.show_open_fd)

        else:
            print_pass(t_elapsed, open_fd=options.show_open_fd)

        status_dct[dct.get("name")] = current_status

    cleanup_env(parser, options)

    job_end_time = time.time()
    job_elapsed_time = job_end_time - job_start_time
    _job_report(job_elapsed_time, n_tests, n_tests_skipped, n_tests_failed)

    return not failed

########NEW FILE########
__FILENAME__ = step_editor
#!/usr/bin/python
"""
Step file creator/editor.

:copyright: Red Hat Inc 2009
:author: mgoldish@redhat.com (Michael Goldish)
"""

import pygtk
import gtk
import os
import glob
import shutil
import sys
import logging
import ppm_utils
pygtk.require('2.0')


# General utilities

def corner_and_size_clipped(startpoint, endpoint, limits):
    c0 = startpoint[:]
    c1 = endpoint[:]
    if c0[0] < 0:
        c0[0] = 0
    if c0[1] < 0:
        c0[1] = 0
    if c1[0] < 0:
        c1[0] = 0
    if c1[1] < 0:
        c1[1] = 0
    if c0[0] > limits[0] - 1:
        c0[0] = limits[0] - 1
    if c0[1] > limits[1] - 1:
        c0[1] = limits[1] - 1
    if c1[0] > limits[0] - 1:
        c1[0] = limits[0] - 1
    if c1[1] > limits[1] - 1:
        c1[1] = limits[1] - 1
    return ([min(c0[0], c1[0]),
             min(c0[1], c1[1])],
            [abs(c1[0] - c0[0]) + 1,
             abs(c1[1] - c0[1]) + 1])


def key_event_to_qemu_string(event):
    keymap = gtk.gdk.keymap_get_default()
    keyvals = keymap.get_entries_for_keycode(event.hardware_keycode)
    keyval = keyvals[0][0]
    keyname = gtk.gdk.keyval_name(keyval)

    keymap = {"Return": "ret",
              "Tab": "tab",
              "space": "spc",
              "Left": "left",
              "Right": "right",
              "Up": "up",
              "Down": "down",
              "F1": "f1",
              "F2": "f2",
              "F3": "f3",
              "F4": "f4",
              "F5": "f5",
              "F6": "f6",
              "F7": "f7",
              "F8": "f8",
              "F9": "f9",
              "F10": "f10",
              "F11": "f11",
              "F12": "f12",
              "Escape": "esc",
              "minus": "minus",
              "equal": "equal",
              "BackSpace": "backspace",
              "comma": "comma",
              "period": "dot",
              "slash": "slash",
              "Insert": "insert",
              "Delete": "delete",
              "Home": "home",
              "End": "end",
              "Page_Up": "pgup",
              "Page_Down": "pgdn",
              "Menu": "menu",
              "semicolon": "0x27",
              "backslash": "0x2b",
              "apostrophe": "0x28",
              "grave": "0x29",
              "less": "0x2b",
              "bracketleft": "0x1a",
              "bracketright": "0x1b",
              "Super_L": "0xdc",
              "Super_R": "0xdb",
              }

    if ord('a') <= keyval <= ord('z') or ord('0') <= keyval <= ord('9'):
        sr = keyname
    elif keyname in keymap.keys():
        sr = keymap[keyname]
    else:
        return ""

    if event.state & gtk.gdk.CONTROL_MASK:
        sr = "ctrl-" + str
    if event.state & gtk.gdk.MOD1_MASK:
        sr = "alt-" + str
    if event.state & gtk.gdk.SHIFT_MASK:
        sr = "shift-" + str

    return sr


class StepMakerWindow(object):

    def __init__(self):
        # Window
        self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
        self.window.set_title("Step Maker Window")
        self.window.connect("delete-event", self.delete_event)
        self.window.connect("destroy", self.destroy)
        self.window.set_default_size(600, 800)

        # Main box (inside a frame which is inside a VBox)
        self.menu_vbox = gtk.VBox()
        self.window.add(self.menu_vbox)
        self.menu_vbox.show()

        frame = gtk.Frame()
        frame.set_border_width(10)
        frame.set_shadow_type(gtk.SHADOW_NONE)
        self.menu_vbox.pack_end(frame)
        frame.show()

        self.main_vbox = gtk.VBox(spacing=10)
        frame.add(self.main_vbox)
        self.main_vbox.show()

        # EventBox
        self.scrolledwindow = gtk.ScrolledWindow()
        self.scrolledwindow.set_policy(gtk.POLICY_AUTOMATIC,
                                       gtk.POLICY_AUTOMATIC)
        self.scrolledwindow.set_shadow_type(gtk.SHADOW_NONE)
        self.main_vbox.pack_start(self.scrolledwindow)
        self.scrolledwindow.show()

        table = gtk.Table(1, 1)
        self.scrolledwindow.add_with_viewport(table)
        table.show()
        table.realize()

        self.event_box = gtk.EventBox()
        table.attach(self.event_box, 0, 1, 0, 1, gtk.EXPAND, gtk.EXPAND)
        self.event_box.show()
        self.event_box.realize()

        # Image
        self.image = gtk.Image()
        self.event_box.add(self.image)
        self.image.show()

        # Data VBox
        self.data_vbox = gtk.VBox(spacing=10)
        self.main_vbox.pack_start(self.data_vbox, expand=False)
        self.data_vbox.show()

        # User VBox
        self.user_vbox = gtk.VBox(spacing=10)
        self.main_vbox.pack_start(self.user_vbox, expand=False)
        self.user_vbox.show()

        # Screendump ID HBox
        box = gtk.HBox(spacing=10)
        self.data_vbox.pack_start(box)
        box.show()

        label = gtk.Label("Screendump ID:")
        box.pack_start(label, False)
        label.show()

        self.entry_screendump = gtk.Entry()
        self.entry_screendump.set_editable(False)
        box.pack_start(self.entry_screendump)
        self.entry_screendump.show()

        label = gtk.Label("Time:")
        box.pack_start(label, False)
        label.show()

        self.entry_time = gtk.Entry()
        self.entry_time.set_editable(False)
        self.entry_time.set_width_chars(10)
        box.pack_start(self.entry_time, False)
        self.entry_time.show()

        # Comment HBox
        box = gtk.HBox(spacing=10)
        self.data_vbox.pack_start(box)
        box.show()

        label = gtk.Label("Comment:")
        box.pack_start(label, False)
        label.show()

        self.entry_comment = gtk.Entry()
        box.pack_start(self.entry_comment)
        self.entry_comment.show()

        # Sleep HBox
        box = gtk.HBox(spacing=10)
        self.data_vbox.pack_start(box)
        box.show()

        self.check_sleep = gtk.CheckButton("Sleep:")
        self.check_sleep.connect("toggled", self.event_check_sleep_toggled)
        box.pack_start(self.check_sleep, False)
        self.check_sleep.show()

        self.spin_sleep = gtk.SpinButton(gtk.Adjustment(0, 0, 50000, 1, 10, 0),
                                         climb_rate=0.0)
        box.pack_start(self.spin_sleep, False)
        self.spin_sleep.show()

        # Barrier HBox
        box = gtk.HBox(spacing=10)
        self.data_vbox.pack_start(box)
        box.show()

        self.check_barrier = gtk.CheckButton("Barrier:")
        self.check_barrier.connect("toggled", self.event_check_barrier_toggled)
        box.pack_start(self.check_barrier, False)
        self.check_barrier.show()

        vbox = gtk.VBox()
        box.pack_start(vbox)
        vbox.show()

        self.label_barrier_region = gtk.Label("Region:")
        self.label_barrier_region.set_alignment(0, 0.5)
        vbox.pack_start(self.label_barrier_region)
        self.label_barrier_region.show()

        self.label_barrier_md5sum = gtk.Label("MD5:")
        self.label_barrier_md5sum.set_alignment(0, 0.5)
        vbox.pack_start(self.label_barrier_md5sum)
        self.label_barrier_md5sum.show()

        self.label_barrier_timeout = gtk.Label("Timeout:")
        box.pack_start(self.label_barrier_timeout, False)
        self.label_barrier_timeout.show()

        self.spin_barrier_timeout = gtk.SpinButton(gtk.Adjustment(0, 0, 50000,
                                                                  1, 10, 0),
                                                   climb_rate=0.0)
        box.pack_start(self.spin_barrier_timeout, False)
        self.spin_barrier_timeout.show()

        self.check_barrier_optional = gtk.CheckButton("Optional")
        box.pack_start(self.check_barrier_optional, False)
        self.check_barrier_optional.show()

        # Keystrokes HBox
        box = gtk.HBox(spacing=10)
        self.data_vbox.pack_start(box)
        box.show()

        label = gtk.Label("Keystrokes:")
        box.pack_start(label, False)
        label.show()

        frame = gtk.Frame()
        frame.set_shadow_type(gtk.SHADOW_IN)
        box.pack_start(frame)
        frame.show()

        self.text_buffer = gtk.TextBuffer()
        self.entry_keys = gtk.TextView(self.text_buffer)
        self.entry_keys.set_wrap_mode(gtk.WRAP_WORD)
        self.entry_keys.connect("key-press-event", self.event_key_press)
        frame.add(self.entry_keys)
        self.entry_keys.show()

        self.check_manual = gtk.CheckButton("Manual")
        self.check_manual.connect("toggled", self.event_manual_toggled)
        box.pack_start(self.check_manual, False)
        self.check_manual.show()

        button = gtk.Button("Clear")
        button.connect("clicked", self.event_clear_clicked)
        box.pack_start(button, False)
        button.show()

        # Mouse click HBox
        box = gtk.HBox(spacing=10)
        self.data_vbox.pack_start(box)
        box.show()

        label = gtk.Label("Mouse action:")
        box.pack_start(label, False)
        label.show()

        self.button_capture = gtk.Button("Capture")
        box.pack_start(self.button_capture, False)
        self.button_capture.show()

        self.check_mousemove = gtk.CheckButton("Move: ...")
        box.pack_start(self.check_mousemove, False)
        self.check_mousemove.show()

        self.check_mouseclick = gtk.CheckButton("Click: ...")
        box.pack_start(self.check_mouseclick, False)
        self.check_mouseclick.show()

        self.spin_sensitivity = gtk.SpinButton(gtk.Adjustment(1, 1, 100, 1, 10,
                                                              0),
                                               climb_rate=0.0)
        box.pack_end(self.spin_sensitivity, False)
        self.spin_sensitivity.show()

        label = gtk.Label("Sensitivity:")
        box.pack_end(label, False)
        label.show()

        self.spin_latency = gtk.SpinButton(
            gtk.Adjustment(10, 1, 500, 1, 10, 0),
            climb_rate=0.0)
        box.pack_end(self.spin_latency, False)
        self.spin_latency.show()

        label = gtk.Label("Latency:")
        box.pack_end(label, False)
        label.show()

        self.handler_event_box_press = None
        self.handler_event_box_release = None
        self.handler_event_box_scroll = None
        self.handler_event_box_motion = None
        self.handler_event_box_expose = None

        self.window.realize()
        self.window.show()

        self.clear_state()

    # Utilities

    def message(self, text, title):
        dlg = gtk.MessageDialog(self.window,
                                gtk.DIALOG_MODAL | gtk.DIALOG_DESTROY_WITH_PARENT,
                                gtk.MESSAGE_INFO,
                                gtk.BUTTONS_CLOSE,
                                title)
        dlg.set_title(title)
        dlg.format_secondary_text(text)
        dlg.run()
        dlg.destroy()

    def question_yes_no(self, text, title):
        dlg = gtk.MessageDialog(self.window,
                                gtk.DIALOG_MODAL | gtk.DIALOG_DESTROY_WITH_PARENT,
                                gtk.MESSAGE_QUESTION,
                                gtk.BUTTONS_YES_NO,
                                title)
        dlg.set_title(title)
        dlg.format_secondary_text(text)
        response = dlg.run()
        dlg.destroy()
        if response == gtk.RESPONSE_YES:
            return True
        return False

    def inputdialog(self, text, title, default_response=""):
        # Define a little helper function
        def inputdialog_entry_activated(entry):
            dlg.response(gtk.RESPONSE_OK)

        # Create the dialog
        dlg = gtk.MessageDialog(self.window,
                                gtk.DIALOG_MODAL | gtk.DIALOG_DESTROY_WITH_PARENT,
                                gtk.MESSAGE_QUESTION,
                                gtk.BUTTONS_OK_CANCEL,
                                title)
        dlg.set_title(title)
        dlg.format_secondary_text(text)

        # Create an entry widget
        entry = gtk.Entry()
        entry.set_text(default_response)
        entry.connect("activate", inputdialog_entry_activated)
        dlg.vbox.pack_start(entry)
        entry.show()

        # Run the dialog
        response = dlg.run()
        dlg.destroy()
        if response == gtk.RESPONSE_OK:
            return entry.get_text()
        return None

    def filedialog(self, title=None, default_filename=None):
        chooser = gtk.FileChooserDialog(title=title, parent=self.window,
                                        action=gtk.FILE_CHOOSER_ACTION_OPEN,
                                        buttons=(
                                            gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL, gtk.STOCK_OPEN,
                                            gtk.RESPONSE_OK))
        chooser.resize(700, 500)
        if default_filename:
            chooser.set_filename(os.path.abspath(default_filename))
        filename = None
        response = chooser.run()
        if response == gtk.RESPONSE_OK:
            filename = chooser.get_filename()
        chooser.destroy()
        return filename

    def redirect_event_box_input(self, press=None, release=None, scroll=None,
                                 motion=None, expose=None):
        if self.handler_event_box_press is not None:
            self.event_box.disconnect(self.handler_event_box_press)
        if self.handler_event_box_release is not None:
            self.event_box.disconnect(self.handler_event_box_release)
        if self.handler_event_box_scroll is not None:
            self.event_box.disconnect(self.handler_event_box_scroll)
        if self.handler_event_box_motion is not None:
            self.event_box.disconnect(self.handler_event_box_motion)
        if self.handler_event_box_expose is not None:
            self.event_box.disconnect(self.handler_event_box_expose)
        self.handler_event_box_press = None
        self.handler_event_box_release = None
        self.handler_event_box_scroll = None
        self.handler_event_box_motion = None
        self.handler_event_box_expose = None
        if press is not None:
            self.handler_event_box_press = (
                self.event_box.connect("button-press-event", press))
        if release is not None:
            self.handler_event_box_release = (
                self.event_box.connect("button-release-event", release))
        if scroll is not None:
            self.handler_event_box_scroll = (
                self.event_box.connect("scroll-event", scroll))
        if motion is not None:
            self.handler_event_box_motion = (
                self.event_box.connect("motion-notify-event", motion))
        if expose is not None:
            self.handler_event_box_expose = (
                self.event_box.connect_after("expose-event", expose))

    def get_keys(self):
        return self.text_buffer.get_text(
            self.text_buffer.get_start_iter(),
            self.text_buffer.get_end_iter())

    def add_key(self, key):
        text = self.get_keys()
        if len(text) > 0 and text[-1] != ' ':
            text += " "
        text += key
        self.text_buffer.set_text(text)

    def clear_keys(self):
        self.text_buffer.set_text("")

    def update_barrier_info(self):
        if self.barrier_selected:
            self.label_barrier_region.set_text("Selected region: Corner: " +
                                               str(tuple(self.barrier_corner)) +
                                               " Size: " +
                                               str(tuple(self.barrier_size)))
        else:
            self.label_barrier_region.set_text("No region selected.")
        self.label_barrier_md5sum.set_text("MD5: " + self.barrier_md5sum)

    def update_mouse_click_info(self):
        if self.mouse_click_captured:
            self.check_mousemove.set_label("Move: " +
                                           str(tuple(self.mouse_click_coords)))
            self.check_mouseclick.set_label("Click: button %d" %
                                            self.mouse_click_button)
        else:
            self.check_mousemove.set_label("Move: ...")
            self.check_mouseclick.set_label("Click: ...")

    def clear_state(self, clear_screendump=True):
        # Recording time
        self.entry_time.set_text("unknown")
        if clear_screendump:
            # Screendump
            self.clear_image()
        # Screendump ID
        self.entry_screendump.set_text("")
        # Comment
        self.entry_comment.set_text("")
        # Sleep
        self.check_sleep.set_active(True)
        self.check_sleep.set_active(False)
        self.spin_sleep.set_value(10)
        # Barrier
        self.clear_barrier_state()
        # Keystrokes
        self.check_manual.set_active(False)
        self.clear_keys()
        # Mouse actions
        self.check_mousemove.set_sensitive(False)
        self.check_mouseclick.set_sensitive(False)
        self.check_mousemove.set_active(False)
        self.check_mouseclick.set_active(False)
        self.mouse_click_captured = False
        self.mouse_click_coords = [0, 0]
        self.mouse_click_button = 0
        self.update_mouse_click_info()

    def clear_barrier_state(self):
        self.check_barrier.set_active(True)
        self.check_barrier.set_active(False)
        self.check_barrier_optional.set_active(False)
        self.spin_barrier_timeout.set_value(10)
        self.barrier_selection_started = False
        self.barrier_selected = False
        self.barrier_corner0 = [0, 0]
        self.barrier_corner1 = [0, 0]
        self.barrier_corner = [0, 0]
        self.barrier_size = [0, 0]
        self.barrier_md5sum = ""
        self.update_barrier_info()

    def set_image(self, w, h, data):
        (self.image_width, self.image_height, self.image_data) = (w, h, data)
        self.image.set_from_pixbuf(gtk.gdk.pixbuf_new_from_data(
            data, gtk.gdk.COLORSPACE_RGB, False, 8,
            w, h, w * 3))
        hscrollbar = self.scrolledwindow.get_hscrollbar()
        hscrollbar.set_range(0, w)
        vscrollbar = self.scrolledwindow.get_vscrollbar()
        vscrollbar.set_range(0, h)

    def set_image_from_file(self, filename):
        if not ppm_utils.image_verify_ppm_file(filename):
            logging.warning("set_image_from_file: Warning: received invalid"
                            "screendump file")
            return self.clear_image()
        (w, h, data) = ppm_utils.image_read_from_ppm_file(filename)
        self.set_image(w, h, data)

    def clear_image(self):
        self.image.clear()
        self.image_width = 0
        self.image_height = 0
        self.image_data = ""

    def update_screendump_id(self, data_dir):
        if not self.image_data:
            return
        # Find a proper ID for the screendump
        scrdump_md5sum = ppm_utils.image_md5sum(self.image_width,
                                                self.image_height,
                                                self.image_data)
        scrdump_id = ppm_utils.find_id_for_screendump(scrdump_md5sum, data_dir)
        if not scrdump_id:
            # Not found; generate one
            scrdump_id = ppm_utils.generate_id_for_screendump(scrdump_md5sum,
                                                              data_dir)
        self.entry_screendump.set_text(scrdump_id)

    def get_step_lines(self, data_dir=None):
        if self.check_barrier.get_active() and not self.barrier_selected:
            self.message("No barrier region selected.", "Error")
            return

        sr = "step"

        # Add step recording time
        if self.entry_time.get_text():
            sr += " " + self.entry_time.get_text()

        sr += "\n"

        # Add screendump line
        if self.image_data:
            sr += "screendump %s\n" % self.entry_screendump.get_text()

        # Add comment
        if self.entry_comment.get_text():
            sr += "# %s\n" % self.entry_comment.get_text()

        # Add sleep line
        if self.check_sleep.get_active():
            sr += "sleep %d\n" % self.spin_sleep.get_value()

        # Add barrier_2 line
        if self.check_barrier.get_active():
            sr += "barrier_2 %d %d %d %d %s %d" % (
                self.barrier_size[0], self.barrier_size[1],
                self.barrier_corner[0], self.barrier_corner[1],
                self.barrier_md5sum, self.spin_barrier_timeout.get_value())
            if self.check_barrier_optional.get_active():
                sr += " optional"
            sr += "\n"

        # Add "Sending keys" comment
        keys_to_send = self.get_keys().split()
        if keys_to_send:
            sr += "# Sending keys: %s\n" % self.get_keys()

        # Add key and var lines
        for key in keys_to_send:
            if key.startswith("$"):
                varname = key[1:]
                sr += "var %s\n" % varname
            else:
                sr += "key %s\n" % key

        # Add mousemove line
        if self.check_mousemove.get_active():
            sr += "mousemove %d %d\n" % (self.mouse_click_coords[0],
                                         self.mouse_click_coords[1])

        # Add mouseclick line
        if self.check_mouseclick.get_active():
            mapping = {1: 1,
                       2: 2,
                       3: 4}
            sr += "mouseclick %d\n" % mapping[self.mouse_click_button]

        # Write screendump and cropped screendump image files
        if data_dir and self.image_data:
            # Create the data dir if it doesn't exist
            if not os.path.exists(data_dir):
                os.makedirs(data_dir)
            # Get the full screendump filename
            scrdump_filename = os.path.join(data_dir,
                                            self.entry_screendump.get_text())
            # Write screendump file if it doesn't exist
            if not os.path.exists(scrdump_filename):
                try:
                    ppm_utils.image_write_to_ppm_file(scrdump_filename,
                                                      self.image_width,
                                                      self.image_height,
                                                      self.image_data)
                except IOError:
                    self.message("Could not write screendump file.", "Error")

        return sr

    def set_state_from_step_lines(self, sr, data_dir, warn=True):
        self.clear_state()

        for line in sr.splitlines():
            words = line.split()
            if not words:
                continue

            if (line.startswith("#") and not
                self.entry_comment.get_text() and not
                line.startswith("# Sending keys:") and not
                    line.startswith("# ----")):

                self.entry_comment.set_text(line.strip("#").strip())

            elif words[0] == "step":
                if len(words) >= 2:
                    self.entry_time.set_text(words[1])

            elif words[0] == "screendump":
                self.entry_screendump.set_text(words[1])
                self.set_image_from_file(os.path.join(data_dir, words[1]))

            elif words[0] == "sleep":
                self.spin_sleep.set_value(int(words[1]))
                self.check_sleep.set_active(True)

            elif words[0] == "key":
                self.add_key(words[1])

            elif words[0] == "var":
                self.add_key("$%s" % words[1])

            elif words[0] == "mousemove":
                self.mouse_click_captured = True
                self.mouse_click_coords = [int(words[1]), int(words[2])]
                self.update_mouse_click_info()

            elif words[0] == "mouseclick":
                self.mouse_click_captured = True
                self.mouse_click_button = int(words[1])
                self.update_mouse_click_info()

            elif words[0] == "barrier_2":
                # Get region corner and size from step lines
                self.barrier_corner = [int(words[3]), int(words[4])]
                self.barrier_size = [int(words[1]), int(words[2])]
                # Get corner0 and corner1 from step lines
                self.barrier_corner0 = self.barrier_corner
                self.barrier_corner1 = [self.barrier_corner[0] +
                                        self.barrier_size[0] - 1,
                                        self.barrier_corner[1] +
                                        self.barrier_size[1] - 1]
                # Get the md5sum
                self.barrier_md5sum = words[5]
                # Pretend the user selected the region with the mouse
                self.barrier_selection_started = True
                self.barrier_selected = True
                # Update label widgets according to region information
                self.update_barrier_info()
                # Check the barrier checkbutton
                self.check_barrier.set_active(True)
                # Set timeout value
                self.spin_barrier_timeout.set_value(int(words[6]))
                # Set 'optional' checkbutton state
                self.check_barrier_optional.set_active(words[-1] == "optional")
                # Update the image widget
                self.event_box.queue_draw()

                if warn:
                    # See if the computed md5sum matches the one recorded in
                    # the file
                    computed_md5sum = ppm_utils.get_region_md5sum(
                        self.image_width, self.image_height,
                        self.image_data, self.barrier_corner[0],
                        self.barrier_corner[1], self.barrier_size[0],
                        self.barrier_size[1])
                    if computed_md5sum != self.barrier_md5sum:
                        self.message("Computed MD5 sum (%s) differs from MD5"
                                     " sum recorded in steps file (%s)" %
                                     (computed_md5sum, self.barrier_md5sum),
                                     "Warning")

    # Events

    def delete_event(self, widget, event):
        pass

    def destroy(self, widget):
        gtk.main_quit()

    def event_check_barrier_toggled(self, widget):
        if self.check_barrier.get_active():
            self.redirect_event_box_input(
                self.event_button_press,
                self.event_button_release,
                None,
                None,
                self.event_expose)
            self.event_box.queue_draw()
            self.event_box.window.set_cursor(gtk.gdk.Cursor(gtk.gdk.CROSSHAIR))
            self.label_barrier_region.set_sensitive(True)
            self.label_barrier_md5sum.set_sensitive(True)
            self.label_barrier_timeout.set_sensitive(True)
            self.spin_barrier_timeout.set_sensitive(True)
            self.check_barrier_optional.set_sensitive(True)
        else:
            self.redirect_event_box_input()
            self.event_box.queue_draw()
            self.event_box.window.set_cursor(None)
            self.label_barrier_region.set_sensitive(False)
            self.label_barrier_md5sum.set_sensitive(False)
            self.label_barrier_timeout.set_sensitive(False)
            self.spin_barrier_timeout.set_sensitive(False)
            self.check_barrier_optional.set_sensitive(False)

    def event_check_sleep_toggled(self, widget):
        if self.check_sleep.get_active():
            self.spin_sleep.set_sensitive(True)
        else:
            self.spin_sleep.set_sensitive(False)

    def event_manual_toggled(self, widget):
        self.entry_keys.grab_focus()

    def event_clear_clicked(self, widget):
        self.clear_keys()
        self.entry_keys.grab_focus()

    def event_expose(self, widget, event):
        if not self.barrier_selection_started:
            return
        (corner, size) = corner_and_size_clipped(self.barrier_corner0,
                                                 self.barrier_corner1,
                                                 self.event_box.size_request())
        gc = self.event_box.window.new_gc(line_style=gtk.gdk.LINE_DOUBLE_DASH,
                                          line_width=1)
        gc.set_foreground(gc.get_colormap().alloc_color("red"))
        gc.set_background(gc.get_colormap().alloc_color("dark red"))
        gc.set_dashes(0, (4, 4))
        self.event_box.window.draw_rectangle(
            gc, False,
            corner[0], corner[1],
            size[0] - 1, size[1] - 1)

    def event_drag_motion(self, widget, event):
        old_corner1 = self.barrier_corner1
        self.barrier_corner1 = [int(event.x), int(event.y)]
        (corner, size) = corner_and_size_clipped(self.barrier_corner0,
                                                 self.barrier_corner1,
                                                 self.event_box.size_request())
        (old_corner, old_size) = corner_and_size_clipped(self.barrier_corner0,
                                                         old_corner1,
                                                         self.event_box.size_request())
        corner0 = [
            min(corner[0], old_corner[0]), min(corner[1], old_corner[1])]
        corner1 = [max(corner[0] + size[0], old_corner[0] + old_size[0]),
                   max(corner[1] + size[1], old_corner[1] + old_size[1])]
        size = [corner1[0] - corner0[0] + 1,
                corner1[1] - corner0[1] + 1]
        self.event_box.queue_draw_area(
            corner0[0], corner0[1], size[0], size[1])

    def event_button_press(self, widget, event):
        (corner, size) = corner_and_size_clipped(self.barrier_corner0,
                                                 self.barrier_corner1,
                                                 self.event_box.size_request())
        self.event_box.queue_draw_area(corner[0], corner[1], size[0], size[1])
        self.barrier_corner0 = [int(event.x), int(event.y)]
        self.barrier_corner1 = [int(event.x), int(event.y)]
        self.redirect_event_box_input(
            self.event_button_press,
            self.event_button_release,
            None,
            self.event_drag_motion,
            self.event_expose)
        self.barrier_selection_started = True

    def event_button_release(self, widget, event):
        self.redirect_event_box_input(
            self.event_button_press,
            self.event_button_release,
            None,
            None,
            self.event_expose)
        (self.barrier_corner, self.barrier_size) = \
            corner_and_size_clipped(self.barrier_corner0, self.barrier_corner1,
                                    self.event_box.size_request())
        self.barrier_md5sum = ppm_utils.get_region_md5sum(
            self.image_width, self.image_height, self.image_data,
            self.barrier_corner[0], self.barrier_corner[1],
            self.barrier_size[0], self.barrier_size[1])
        self.barrier_selected = True
        self.update_barrier_info()

    def event_key_press(self, widget, event):
        if self.check_manual.get_active():
            return False
        sr = key_event_to_qemu_string(event)
        self.add_key(sr)
        return True


class StepEditor(StepMakerWindow):
    ui = '''<ui>
    <menubar name="MenuBar">
        <menu action="File">
            <menuitem action="Open"/>
            <separator/>
            <menuitem action="Quit"/>
        </menu>
        <menu action="Edit">
            <menuitem action="CopyStep"/>
            <menuitem action="DeleteStep"/>
        </menu>
        <menu action="Insert">
            <menuitem action="InsertNewBefore"/>
            <menuitem action="InsertNewAfter"/>
            <separator/>
            <menuitem action="InsertStepsBefore"/>
            <menuitem action="InsertStepsAfter"/>
        </menu>
        <menu action="Tools">
            <menuitem action="CleanUp"/>
        </menu>
    </menubar>
</ui>'''

    # Constructor

    def __init__(self, filename=None):
        StepMakerWindow.__init__(self)

        self.steps_filename = None
        self.steps = []

        # Create a UIManager instance
        uimanager = gtk.UIManager()

        # Add the accelerator group to the toplevel window
        accelgroup = uimanager.get_accel_group()
        self.window.add_accel_group(accelgroup)

        # Create an ActionGroup
        actiongroup = gtk.ActionGroup('StepEditor')

        # Create actions
        actiongroup.add_actions([
            ('Quit', gtk.STOCK_QUIT, '_Quit', None, 'Quit the Program',
             self.quit),
            ('Open', gtk.STOCK_OPEN, '_Open', None, 'Open steps file',
             self.open_steps_file),
            ('CopyStep', gtk.STOCK_COPY, '_Copy current step...', "",
             'Copy current step to user specified position', self.copy_step),
            ('DeleteStep', gtk.STOCK_DELETE, '_Delete current step', "",
             'Delete current step', self.event_remove_clicked),
            ('InsertNewBefore', gtk.STOCK_ADD, '_New step before current', "",
             'Insert new step before current step', self.insert_before),
            ('InsertNewAfter', gtk.STOCK_ADD, 'N_ew step after current', "",
             'Insert new step after current step', self.insert_after),
            ('InsertStepsBefore', gtk.STOCK_ADD, '_Steps before current...',
             "", 'Insert steps (from file) before current step',
             self.insert_steps_before),
            ('InsertStepsAfter', gtk.STOCK_ADD, 'Steps _after current...', "",
             'Insert steps (from file) after current step',
             self.insert_steps_after),
            ('CleanUp', gtk.STOCK_DELETE, '_Clean up data directory', "",
             'Move unused PPM files to a backup directory', self.cleanup),
            ('File', None, '_File'),
            ('Edit', None, '_Edit'),
            ('Insert', None, '_Insert'),
            ('Tools', None, '_Tools')
        ])

        def create_shortcut(name, callback, keyname):
            # Create an action
            action = gtk.Action(name, None, None, None)
            # Connect a callback to the action
            action.connect("activate", callback)
            actiongroup.add_action_with_accel(action, keyname)
            # Have the action use accelgroup
            action.set_accel_group(accelgroup)
            # Connect the accelerator to the action
            action.connect_accelerator()

        create_shortcut("Next", self.event_next_clicked, "Page_Down")
        create_shortcut("Previous", self.event_prev_clicked, "Page_Up")

        # Add the actiongroup to the uimanager
        uimanager.insert_action_group(actiongroup, 0)

        # Add a UI description
        uimanager.add_ui_from_string(self.ui)

        # Create a MenuBar
        menubar = uimanager.get_widget('/MenuBar')
        self.menu_vbox.pack_start(menubar, False)

        # Remember the Edit menu bar for future reference
        self.menu_edit = uimanager.get_widget('/MenuBar/Edit')
        self.menu_edit.set_sensitive(False)

        # Remember the Insert menu bar for future reference
        self.menu_insert = uimanager.get_widget('/MenuBar/Insert')
        self.menu_insert.set_sensitive(False)

        # Remember the Tools menu bar for future reference
        self.menu_tools = uimanager.get_widget('/MenuBar/Tools')
        self.menu_tools.set_sensitive(False)

        # Next/Previous HBox
        hbox = gtk.HBox(spacing=10)
        self.user_vbox.pack_start(hbox)
        hbox.show()

        self.button_first = gtk.Button(stock=gtk.STOCK_GOTO_FIRST)
        self.button_first.connect("clicked", self.event_first_clicked)
        hbox.pack_start(self.button_first)
        self.button_first.show()

        #self.button_prev = gtk.Button("<< Previous")
        self.button_prev = gtk.Button(stock=gtk.STOCK_GO_BACK)
        self.button_prev.connect("clicked", self.event_prev_clicked)
        hbox.pack_start(self.button_prev)
        self.button_prev.show()

        self.label_step = gtk.Label("Step:")
        hbox.pack_start(self.label_step, False)
        self.label_step.show()

        self.entry_step_num = gtk.Entry()
        self.entry_step_num.connect(
            "activate", self.event_entry_step_activated)
        self.entry_step_num.set_width_chars(3)
        hbox.pack_start(self.entry_step_num, False)
        self.entry_step_num.show()

        #self.button_next = gtk.Button("Next >>")
        self.button_next = gtk.Button(stock=gtk.STOCK_GO_FORWARD)
        self.button_next.connect("clicked", self.event_next_clicked)
        hbox.pack_start(self.button_next)
        self.button_next.show()

        self.button_last = gtk.Button(stock=gtk.STOCK_GOTO_LAST)
        self.button_last.connect("clicked", self.event_last_clicked)
        hbox.pack_start(self.button_last)
        self.button_last.show()

        # Save HBox
        hbox = gtk.HBox(spacing=10)
        self.user_vbox.pack_start(hbox)
        hbox.show()

        self.button_save = gtk.Button("_Save current step")
        self.button_save.connect("clicked", self.event_save_clicked)
        hbox.pack_start(self.button_save)
        self.button_save.show()

        self.button_remove = gtk.Button("_Delete current step")
        self.button_remove.connect("clicked", self.event_remove_clicked)
        hbox.pack_start(self.button_remove)
        self.button_remove.show()

        self.button_replace = gtk.Button("_Replace screendump")
        self.button_replace.connect("clicked", self.event_replace_clicked)
        hbox.pack_start(self.button_replace)
        self.button_replace.show()

        # Disable unused widgets
        self.button_capture.set_sensitive(False)
        self.spin_latency.set_sensitive(False)
        self.spin_sensitivity.set_sensitive(False)

        # Disable main vbox because no steps file is loaded
        self.main_vbox.set_sensitive(False)

        # Set title
        self.window.set_title("Step Editor")

    # Events

    def delete_event(self, widget, event):
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()

    def event_first_clicked(self, widget):
        if not self.steps:
            return
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()
        # Go to first step
        self.set_step(0)

    def event_last_clicked(self, widget):
        if not self.steps:
            return
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()
        # Go to last step
        self.set_step(len(self.steps) - 1)

    def event_prev_clicked(self, widget):
        if not self.steps:
            return
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()
        # Go to previous step
        index = self.current_step_index - 1
        if self.steps:
            index = index % len(self.steps)
        self.set_step(index)

    def event_next_clicked(self, widget):
        if not self.steps:
            return
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()
        # Go to next step
        index = self.current_step_index + 1
        if self.steps:
            index = index % len(self.steps)
        self.set_step(index)

    def event_entry_step_activated(self, widget):
        if not self.steps:
            return
        step_index = self.entry_step_num.get_text()
        if not step_index.isdigit():
            return
        step_index = int(step_index) - 1
        if step_index == self.current_step_index:
            return
        self.verify_save()
        self.set_step(step_index)

    def event_save_clicked(self, widget):
        if not self.steps:
            return
        self.save_step()

    def event_remove_clicked(self, widget):
        if not self.steps:
            return
        if not self.question_yes_no("This will modify the steps file."
                                    " Are you sure?", "Remove step?"):
            return
        # Remove step
        del self.steps[self.current_step_index]
        # Write changes to file
        self.write_steps_file(self.steps_filename)
        # Move to previous step
        self.set_step(self.current_step_index)

    def event_replace_clicked(self, widget):
        if not self.steps:
            return
        # Let the user choose a screendump file
        current_filename = os.path.join(self.steps_data_dir,
                                        self.entry_screendump.get_text())
        filename = self.filedialog("Choose PPM image file",
                                   default_filename=current_filename)
        if not filename:
            return
        if not ppm_utils.image_verify_ppm_file(filename):
            self.message("Not a valid PPM image file.", "Error")
            return
        self.clear_image()
        self.clear_barrier_state()
        self.set_image_from_file(filename)
        self.update_screendump_id(self.steps_data_dir)

    # Menu actions

    def open_steps_file(self, action):
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()
        # Let the user choose a steps file
        current_filename = self.steps_filename
        filename = self.filedialog("Open steps file",
                                   default_filename=current_filename)
        if not filename:
            return
        self.set_steps_file(filename)

    def quit(self, action):
        # Make sure the step is saved (if the user wants it to be)
        self.verify_save()
        # Quit
        gtk.main_quit()

    def copy_step(self, action):
        if not self.steps:
            return
        self.verify_save()
        self.set_step(self.current_step_index)
        # Get the desired position
        step_index = self.inputdialog("Copy step to position:",
                                      "Copy step",
                                      str(self.current_step_index + 2))
        if not step_index:
            return
        step_index = int(step_index) - 1
        # Get the lines of the current step
        step = self.steps[self.current_step_index]
        # Insert new step at position step_index
        self.steps.insert(step_index, step)
        # Go to new step
        self.set_step(step_index)
        # Write changes to disk
        self.write_steps_file(self.steps_filename)

    def insert_before(self, action):
        if not self.steps_filename:
            return
        if not self.question_yes_no("This will modify the steps file."
                                    " Are you sure?", "Insert new step?"):
            return
        self.verify_save()
        step_index = self.current_step_index
        # Get the lines of a blank step
        self.clear_state()
        step = self.get_step_lines()
        # Insert new step at position step_index
        self.steps.insert(step_index, step)
        # Go to new step
        self.set_step(step_index)
        # Write changes to disk
        self.write_steps_file(self.steps_filename)

    def insert_after(self, action):
        if not self.steps_filename:
            return
        if not self.question_yes_no("This will modify the steps file."
                                    " Are you sure?", "Insert new step?"):
            return
        self.verify_save()
        step_index = self.current_step_index + 1
        # Get the lines of a blank step
        self.clear_state()
        step = self.get_step_lines()
        # Insert new step at position step_index
        self.steps.insert(step_index, step)
        # Go to new step
        self.set_step(step_index)
        # Write changes to disk
        self.write_steps_file(self.steps_filename)

    def insert_steps(self, filename, index):
        # Read the steps file
        (steps, _) = self.read_steps_file(filename)

        data_dir = ppm_utils.get_data_dir(filename)
        for step in steps:
            self.set_state_from_step_lines(step, data_dir, warn=False)
            step = self.get_step_lines(self.steps_data_dir)

        # Insert steps into self.steps
        self.steps[index:index] = steps
        # Write changes to disk
        self.write_steps_file(self.steps_filename)

    def insert_steps_before(self, action):
        if not self.steps_filename:
            return
        # Let the user choose a steps file
        current_filename = self.steps_filename
        filename = self.filedialog("Choose steps file",
                                   default_filename=current_filename)
        if not filename:
            return
        self.verify_save()

        step_index = self.current_step_index
        # Insert steps at position step_index
        self.insert_steps(filename, step_index)
        # Go to new steps
        self.set_step(step_index)

    def insert_steps_after(self, action):
        if not self.steps_filename:
            return
        # Let the user choose a steps file
        current_filename = self.steps_filename
        filename = self.filedialog("Choose steps file",
                                   default_filename=current_filename)
        if not filename:
            return
        self.verify_save()

        step_index = self.current_step_index + 1
        # Insert new steps at position step_index
        self.insert_steps(filename, step_index)
        # Go to new steps
        self.set_step(step_index)

    def cleanup(self, action):
        if not self.steps_filename:
            return
        if not self.question_yes_no("All unused PPM files will be moved to a"
                                    " backup directory. Are you sure?",
                                    "Clean up data directory?"):
            return
        # Remember the current step index
        current_step_index = self.current_step_index
        # Get the backup dir
        backup_dir = os.path.join(self.steps_data_dir, "backup")
        # Create it if it doesn't exist
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        # Move all files to the backup dir
        for filename in glob.glob(os.path.join(self.steps_data_dir,
                                               "*.[Pp][Pp][Mm]")):
            shutil.move(filename, backup_dir)
        # Get the used files back
        for step in self.steps:
            self.set_state_from_step_lines(step, backup_dir, warn=False)
            self.get_step_lines(self.steps_data_dir)
        # Remove the used files from the backup dir
        used_files = os.listdir(self.steps_data_dir)
        for filename in os.listdir(backup_dir):
            if filename in used_files:
                os.unlink(os.path.join(backup_dir, filename))
        # Restore step index
        self.set_step(current_step_index)
        # Inform the user
        self.message("All unused PPM files may be found at %s." %
                     os.path.abspath(backup_dir),
                     "Clean up data directory")

    # Methods

    def read_steps_file(self, filename):
        steps = []
        header = ""

        fileobj = open(filename, "r")
        for line in fileobj.readlines():
            words = line.split()
            if not words:
                continue
            if line.startswith("# ----"):
                continue
            if words[0] == "step":
                steps.append("")
            if steps:
                steps[-1] += line
            else:
                header += line
        fileobj.close()

        return (steps, header)

    def set_steps_file(self, filename):
        try:
            (self.steps, self.header) = self.read_steps_file(filename)
        except (TypeError, IOError):
            self.message("Cannot read file %s." % filename, "Error")
            return

        self.steps_filename = filename
        self.steps_data_dir = ppm_utils.get_data_dir(filename)
        # Go to step 0
        self.set_step(0)

    def set_step(self, index):
        # Limit index to legal boundaries
        if index < 0:
            index = 0
        if index > len(self.steps) - 1:
            index = len(self.steps) - 1

        # Enable the menus
        self.menu_edit.set_sensitive(True)
        self.menu_insert.set_sensitive(True)
        self.menu_tools.set_sensitive(True)

        # If no steps exist...
        if self.steps == []:
            self.current_step_index = index
            self.current_step = None
            # Set window title
            self.window.set_title("Step Editor -- %s" %
                                  os.path.basename(self.steps_filename))
            # Set step entry widget text
            self.entry_step_num.set_text("")
            # Clear the state of all widgets
            self.clear_state()
            # Disable the main vbox
            self.main_vbox.set_sensitive(False)
            return

        self.current_step_index = index
        self.current_step = self.steps[index]
        # Set window title
        self.window.set_title("Step Editor -- %s -- step %d" %
                              (os.path.basename(self.steps_filename),
                               index + 1))
        # Set step entry widget text
        self.entry_step_num.set_text(str(self.current_step_index + 1))
        # Load the state from the step lines
        self.set_state_from_step_lines(self.current_step, self.steps_data_dir)
        # Enable the main vbox
        self.main_vbox.set_sensitive(True)
        # Make sure the step lines in self.current_step are identical to the
        # output of self.get_step_lines
        self.current_step = self.get_step_lines()

    def verify_save(self):
        if not self.steps:
            return
        # See if the user changed anything
        if self.get_step_lines() != self.current_step:
            if self.question_yes_no("Step contents have been modified."
                                    " Save step?", "Save changes?"):
                self.save_step()

    def save_step(self):
        lines = self.get_step_lines(self.steps_data_dir)
        if lines is not None:
            self.steps[self.current_step_index] = lines
            self.current_step = lines
            self.write_steps_file(self.steps_filename)

    def write_steps_file(self, filename):
        fileobj = open(filename, "w")
        fileobj.write(self.header)
        for step in self.steps:
            fileobj.write("# " + "-" * 32 + "\n")
            fileobj.write(step)
        fileobj.close()


if __name__ == "__main__":
    se = StepEditor()
    if len(sys.argv) > 1:
        se.set_steps_file(sys.argv[1])
    gtk.main()

########NEW FILE########
__FILENAME__ = storage
"""
Classes and functions to handle storage devices.

This exports:
  - two functions for get image/blkdebug filename
  - class for image operates and basic parameters
"""
import logging
import os
import shutil
import re
from autotest.client import utils
try:
    from virttest import iscsi
except ImportError:
    from autotest.client.shared import iscsi

import utils_misc
import virt_vm
import gluster
import lvm


def preprocess_images(bindir, params, env):
    # Clone master image form vms.
    for vm_name in params.get("vms").split():
        vm = env.get_vm(vm_name)
        if vm:
            vm.destroy(free_mac_addresses=False)
        vm_params = params.object_params(vm_name)
        for image in vm_params.get("master_images_clone").split():
            image_obj = QemuImg(params, bindir, image)
            image_obj.clone_image(params, vm_name, image, bindir)


def preprocess_image_backend(bindir, params, env):
    enable_gluster = params.get("enable_gluster")
    gluster_image = params.get("gluster_brick")
    if enable_gluster and gluster_image:
        return gluster.create_gluster_vol(params)

    return True


def postprocess_images(bindir, params):
    for vm in params.get("vms").split():
        vm_params = params.object_params(vm)
        for image in vm_params.get("master_images_clone").split():
            image_obj = QemuImg(params, bindir, image)
            image_obj.rm_cloned_image(params, vm, image, bindir)


def file_exists(params, filename_path):
    """
    Check if image_filename exists.

    :param params: Dictionary containing the test parameters.
    :param filename_path: path to file
    :type filename_path: str
    :param root_dir: Base directory for relative filenames.
    :type root_dir: str

    :return: True if image file exists else False
    """
    gluster_image = params.get("gluster_brick")
    if gluster_image:
        return gluster.file_exists(params, filename_path)

    return os.path.exists(filename_path)


def get_image_blkdebug_filename(params, root_dir):
    """
    Generate an blkdebug file path from params and root_dir.

    blkdebug files allow error injection in the block subsystem.

    :param params: Dictionary containing the test parameters.
    :param root_dir: Base directory for relative filenames.

    :note: params should contain:
           blkdebug -- the name of the debug file.
    """
    blkdebug_name = params.get("drive_blkdebug", None)
    if blkdebug_name is not None:
        blkdebug_filename = utils_misc.get_path(root_dir, blkdebug_name)
    else:
        blkdebug_filename = None
    return blkdebug_filename


def get_image_filename(params, root_dir):
    """
    Generate an image path from params and root_dir.

    :param params: Dictionary containing the test parameters.
    :param root_dir: Base directory for relative filenames.
    :param image_name: Force name of image.
    :param image_format: Format for image.

    :note: params should contain:
           image_name -- the name of the image file, without extension
           image_format -- the format of the image (qcow2, raw etc)
    :raise VMDeviceError: When no matching disk found (in indirect method).
    """
    enable_gluster = params.get("enable_gluster", "no") == "yes"
    if enable_gluster:
        image_name = params.get("image_name", "image")
        image_format = params.get("image_format", "qcow2")
        return gluster.get_image_filename(params, image_name, image_format)

    return get_image_filename_filesytem(params, root_dir)


def get_image_filename_filesytem(params, root_dir):
    """
    Generate an image path from params and root_dir.

    :param params: Dictionary containing the test parameters.
    :param root_dir: Base directory for relative filenames.

    :note: params should contain:
           image_name -- the name of the image file, without extension
           image_format -- the format of the image (qcow2, raw etc)
    :raise VMDeviceError: When no matching disk found (in indirect method).
    """
    def sort_cmp(first, second):
        """
        This function used for sort to suit for this test, first sort by len
        then by value.
        """
        first_contains_digit = re.findall(r'[vhs]d[a-z]*[\d]+', first)
        second_contains_digit = re.findall(r'[vhs]d[a-z]*[\d]+', second)

        if not first_contains_digit and not second_contains_digit:
            if len(first) > len(second):
                return 1
            elif len(first) < len(second):
                return -1
        if len(first) == len(second):
            if first_contains_digit and second_contains_digit:
                return cmp(first, second)
            elif first_contains_digit:
                return -1
            elif second_contains_digit:
                return 1
        return cmp(first, second)

    image_name = params.get("image_name", "image")
    indirect_image_select = params.get("indirect_image_select")
    if indirect_image_select:
        re_name = image_name
        indirect_image_select = int(indirect_image_select)
        matching_images = utils.system_output("ls -1d %s" % re_name)
        matching_images = sorted(matching_images.split('\n'), cmp=sort_cmp)
        if matching_images[-1] == '':
            matching_images = matching_images[:-1]
        try:
            image_name = matching_images[indirect_image_select]
        except IndexError:
            raise virt_vm.VMDeviceError("No matching disk found for "
                                        "name = '%s', matching = '%s' and "
                                        "selector = '%s'" %
                                        (re_name, matching_images,
                                         indirect_image_select))
        for protected in params.get('indirect_image_blacklist', '').split(' '):
            match_image = re.match(protected, image_name)
            if match_image and match_image.group(0) == image_name:
                # We just need raise an error if it is totally match, such as
                # sda sda1 and so on, but sdaa should not raise an error.
                raise virt_vm.VMDeviceError("Matching disk is in blacklist. "
                                            "name = '%s', matching = '%s' and "
                                            "selector = '%s'" %
                                            (re_name, matching_images,
                                             indirect_image_select))

    image_format = params.get("image_format", "qcow2")
    if params.get("image_raw_device") == "yes":
        return image_name
    if image_format:
        image_filename = "%s.%s" % (image_name, image_format)
    else:
        image_filename = image_name

    image_filename = utils_misc.get_path(root_dir, image_filename)
    return image_filename


class OptionMissing(Exception):

    """
    Option not found in the odbject
    """

    def __init__(self, option):
        self.option = option

    def __str__(self):
        return "%s is missing. Please check your parameters" % self.option


class QemuImg(object):

    """
    A basic class for handling operations of disk/block images.
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images.
        """
        self.image_filename = get_image_filename(params, root_dir)
        self.image_format = params.get("image_format", "qcow2")
        self.size = params.get("image_size", "10G")
        self.check_output = params.get("check_output") == "yes"
        self.image_blkdebug_filename = get_image_blkdebug_filename(params,
                                                                   root_dir)
        image_chain = params.get("image_chain")
        self.root_dir = root_dir
        self.base_tag = None
        self.snapshot_tag = None
        if image_chain:
            image_chain = re.split(r"\s+", image_chain)
            if tag in image_chain:
                index = image_chain.index(tag)
                if index < len(image_chain) - 1:
                    self.snapshot_tag = image_chain[index + 1]
                if index > 0:
                    self.base_tag = image_chain[index - 1]
        if self.base_tag:
            base_params = params.object_params(self.base_tag)
            self.base_image_filename = get_image_filename(base_params,
                                                          root_dir)
            self.base_format = base_params.get("image_format")
        if self.snapshot_tag:
            ss_params = params.object_params(self.snapshot_tag)
            self.snapshot_image_filename = get_image_filename(ss_params,
                                                              root_dir)
            self.snapshot_format = ss_params.get("image_format")

    def check_option(self, option):
        """
        Check if object has the option required.

        :param option: option should be checked
        """
        if option not in self.__dict__:
            raise OptionMissing(option)

    def backup_image(self, params, root_dir, action, good=True,
                     skip_existing=False):
        """
        Backup or restore a disk image, depending on the action chosen.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param action: Whether we want to backup or restore the image.
        :param good: If we are backing up a good image(we want to restore it)
            or a bad image (we are saving a bad image for posterior analysis).

        :note: params should contain:
               image_name -- the name of the image file, without extension
               image_format -- the format of the image (qcow2, raw etc)
        """
        def backup_raw_device(src, dst):
            if os.path.exists(src):
                utils.system("dd if=%s of=%s bs=4k conv=sync" % (src, dst))
            else:
                logging.info("No source %s, skipping dd...", src)

        def backup_image_file(src, dst):
            logging.debug("Copying %s -> %s", src, dst)
            if os.path.isfile(dst) and os.path.isfile(src):
                os.unlink(dst)
            if os.path.isfile(src):
                shutil.copy(src, dst)
            else:
                logging.info("No source file %s, skipping copy...", src)

        def get_backup_set(filename, backup_dir, action, good):
            """
            Get all sources and destinations required for each backup.
            """
            if not os.path.isdir(backup_dir):
                os.makedirs(backup_dir)
            basename = os.path.basename(filename)
            bkp_set = []
            if good:
                src = filename
                dst = os.path.join(backup_dir, "%s.backup" % basename)
                if action == 'backup':
                    bkp_set = [[src, dst]]
                elif action == 'restore':
                    bkp_set = [[dst, src]]
            else:
                # We have to make 2 backups, one of the bad image, another one
                # of the good image
                src_bad = filename
                src_good = os.path.join(backup_dir, "%s.backup" % basename)
                hsh = utils_misc.generate_random_string(4)
                dst_bad = (os.path.join(backup_dir, "%s.bad.%s" %
                                        (basename, hsh)))
                dst_good = (os.path.join(backup_dir, "%s.good.%s" %
                                         (basename, hsh)))
                if action == 'backup':
                    bkp_set = [[src_bad, dst_bad], [src_good, dst_good]]
                elif action == 'restore':
                    bkp_set = [[src_good, src_bad]]

            if not bkp_set:
                logging.error("No backup sets for action: %s, state: %s",
                              action, good)

            return bkp_set

        image_filename = self.image_filename
        backup_dir = params.get("backup_dir", "")
        if not os.path.isabs(backup_dir):
            backup_dir = os.path.join(root_dir, backup_dir)
        if params.get('image_raw_device') == 'yes':
            iname = "raw_device"
            iformat = params.get("image_format", "qcow2")
            ifilename = "%s.%s" % (iname, iformat)
            ifilename = utils_misc.get_path(root_dir, ifilename)
            backup_set = get_backup_set(ifilename, backup_dir, action, good)
            backup_func = backup_raw_device
        else:
            backup_set = get_backup_set(image_filename, backup_dir, action,
                                        good)
            backup_func = backup_image_file

        if action == 'backup':
            image_dir = os.path.dirname(image_filename)
            image_dir_disk_free = utils.freespace(image_dir)

            backup_size = 0
            for src, dst in backup_set:
                if os.path.isfile(src):
                    backup_size += os.path.getsize(src)

            minimum_disk_free = 1.2 * backup_size
            if image_dir_disk_free < minimum_disk_free:
                image_dir_disk_free_gb = float(image_dir_disk_free) / 10 ** 9
                backup_size_gb = float(backup_size) / 10 ** 9
                minimum_disk_free_gb = float(minimum_disk_free) / 10 ** 9
                logging.error("Free space on %s: %.1f GB", image_dir,
                              image_dir_disk_free_gb)
                logging.error("Backup size: %.1f GB", backup_size_gb)
                logging.error("Minimum free space acceptable: %.1f GB",
                              minimum_disk_free_gb)
                logging.error("Available disk space is not sufficient for a"
                              "full backup. Skipping backup...")
                return

        for src, dst in backup_set:
            if action == 'backup' and skip_existing and os.path.exists(dst):
                continue
            backup_func(src, dst)

    @staticmethod
    def clone_image(params, vm_name, image_name, root_dir):
        """
        Clone master image to vm specific file.

        :param params: Dictionary containing the test parameters.
        :param vm_name: Vm name.
        :param image_name: Master image name.
        :param root_dir: Base directory for relative filenames.
        """
        if not params.get("image_name_%s_%s" % (image_name, vm_name)):
            m_image_name = params.get("image_name", "image")
            vm_image_name = "%s_%s" % (m_image_name, vm_name)
            if params.get("clone_master", "yes") == "yes":
                image_params = params.object_params(image_name)
                image_params["image_name"] = vm_image_name

                m_image_fn = get_image_filename(params, root_dir)
                image_fn = get_image_filename(image_params, root_dir)

                force_clone = params.get("force_image_clone", "no")
                if not os.path.exists(image_fn) or force_clone == "yes":
                    logging.info("Clone master image for vms.")
                    utils.run(params.get("image_clone_command") % (m_image_fn,
                                                                   image_fn))

            params["image_name_%s_%s" % (image_name, vm_name)] = vm_image_name

    @staticmethod
    def rm_cloned_image(params, vm_name, image_name, root_dir):
        """
        Remove vm specific file.

        :param params: Dictionary containing the test parameters.
        :param vm_name: Vm name.
        :param image_name: Master image name.
        :param root_dir: Base directory for relative filenames.
        """
        if params.get("image_name_%s_%s" % (image_name, vm_name)):
            m_image_name = params.get("image_name", "image")
            vm_image_name = "%s_%s" % (m_image_name, vm_name)
            if params.get("clone_master", "yes") == "yes":
                image_params = params.object_params(image_name)
                image_params["image_name"] = vm_image_name

                image_fn = get_image_filename(image_params, root_dir)

                logging.debug("Removing vm specific image file %s", image_fn)
                if os.path.exists(image_fn):
                    utils.run(params.get("image_remove_command") % (image_fn))
                else:
                    logging.debug("Image file %s not found", image_fn)


class Rawdev(object):

    """
    Base class for raw storage devices such as iscsi and local disks
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images
        """
        host_set_flag = params.get("host_setup_flag")
        if host_set_flag is not None:
            self.exec_cleanup = host_set_flag & 2 == 2
        else:
            self.exec_cleanup = False
        if params.get("force_cleanup") == "yes":
            self.exec_cleanup = True
        self.image_name = tag


class Iscsidev(Rawdev):

    """
    Class for handle iscsi devices for VM
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images
        """
        Rawdev.__init__(self, params, root_dir, tag)
        self.emulated_file_remove = False
        self.emulated_image = params.get("emulated_image")
        if self.emulated_image:
            if params.get("emulated_file_remove", "no") == "yes":
                self.emulated_file_remove = True
        params["iscsi_thread_id"] = self.image_name
        self.iscsidevice = iscsi.Iscsi(params, root_dir=root_dir)
        self.device_id = params.get("device_id")
        self.iscsi_init_timeout = int(params.get("iscsi_init_timeout", 10))


class LVMdev(Rawdev):

    """
    Class for handle LVM devices for VM
    """

    def __init__(self, params, root_dir, tag):
        """
        Init the default value for image object.

        :param params: Dictionary containing the test parameters.
        :param root_dir: Base directory for relative filenames.
        :param tag: Image tag defined in parameter images
        """
        super(LVMdev, self).__init__(params, root_dir, tag)
        if params.get("emulational_device", "yes") == "yes":
            self.lvmdevice = lvm.EmulatedLVM(params, root_dir=root_dir)
        else:
            self.lvmdevice = lvm.LVM(params)

########NEW FILE########
__FILENAME__ = syslog_server
import re
import logging
import SocketServer


SYSLOG_PORT = 514
DEFAULT_FORMAT = '[AutotestSyslog (%s.%s)] %s'


def set_default_format(message_format):
    '''
    Changes the default message format

    :type message_format: string
    :param message_format: a message format string with 3 placeholders:
                           facility, priority and message.
    '''
    global DEFAULT_FORMAT
    DEFAULT_FORMAT = message_format


def get_default_format():
    '''
    Returns the current default message format
    '''
    return DEFAULT_FORMAT


class RequestHandler(SocketServer.BaseRequestHandler):

    '''
    A request handler that relays all received messages as DEBUG
    '''

    RECORD_RE = re.compile('\<(\d+)\>(.*)')

    (LOG_EMERG,
     LOG_ALERT,
     LOG_CRIT,
     LOG_ERR,
     LOG_WARNING,
     LOG_NOTICE,
     LOG_INFO,
     LOG_DEBUG) = range(8)

    (LOG_KERN,
     LOG_USER,
     LOG_MAIL,
     LOG_DAEMON,
     LOG_AUTH,
     LOG_SYSLOG,
     LOG_LPR,
     LOG_NEWS,
     LOG_UUCP,
     LOG_CRON,
     LOG_AUTHPRIV,
     LOG_FTP) = range(12)

    (LOG_LOCAL0,
     LOG_LOCAL1,
     LOG_LOCAL2,
     LOG_LOCAL3,
     LOG_LOCAL4,
     LOG_LOCAL5,
     LOG_LOCAL6,
     LOG_LOCAL7) = range(16, 24)

    PRIORITY_NAMES = {
        LOG_ALERT: "alert",
        LOG_CRIT: "critical",
        LOG_DEBUG: "debug",
        LOG_EMERG: "emerg",
        LOG_ERR: "err",
        LOG_INFO: "info",
        LOG_NOTICE: "notice",
        LOG_WARNING: "warning"
    }

    FACILITY_NAMES = {
        LOG_AUTH: "auth",
        LOG_AUTHPRIV: "authpriv",
        LOG_CRON: "cron",
        LOG_DAEMON: "daemon",
        LOG_FTP: "ftp",
        LOG_KERN: "kern",
        LOG_LPR: "lpr",
        LOG_MAIL: "mail",
        LOG_NEWS: "news",
        LOG_AUTH: "security",
        LOG_SYSLOG: "syslog",
        LOG_USER: "user",
        LOG_UUCP: "uucp",
        LOG_LOCAL0: "local0",
        LOG_LOCAL1: "local1",
        LOG_LOCAL2: "local2",
        LOG_LOCAL3: "local3",
        LOG_LOCAL4: "local4",
        LOG_LOCAL5: "local5",
        LOG_LOCAL6: "local6",
        LOG_LOCAL7: "local7",
    }

    def decodeFacilityPriority(self, priority):
        '''
        Decode both the facility and priority embedded in a syslog message

        :type priority: integer
        :param priority: an integer with facility and priority encoded
        :return: a tuple with two strings
        '''
        f = priority >> 3
        p = priority & 7
        return (self.FACILITY_NAMES.get(f, 'unknown'),
                self.PRIORITY_NAMES.get(p, 'unknown'))

    def log(self, data, message_format=None):
        '''
        Logs the received message as a DEBUG message
        '''
        match = self.RECORD_RE.match(data)
        if match:
            if message_format is None:
                message_format = get_default_format()
            pri = int(match.groups()[0])
            msg = match.groups()[1]
            (facility_name, priority_name) = self.decodeFacilityPriority(pri)
            logging.debug(message_format, facility_name, priority_name, msg)


class RequestHandlerTcp(RequestHandler):

    def handle(self):
        '''
        Handles a single request
        '''
        data = self.request.recv(4096)
        self.log(data)


class RequestHandlerUdp(RequestHandler):

    def handle(self):
        '''
        Handles a single request
        '''
        data = self.request[0]
        self.log(data)


class SysLogServerUdp(SocketServer.UDPServer):

    def __init__(self, address):
        SocketServer.UDPServer.__init__(self, address, RequestHandlerUdp)


class SysLogServerTcp(SocketServer.TCPServer):

    def __init__(self, address):
        SocketServer.TCPServer.__init__(self, address, RequestHandlerTcp)


def syslog_server(address='', port=SYSLOG_PORT,
                  tcp=True, terminate_callable=None):
    if tcp:
        klass = SysLogServerTcp
    else:
        klass = SysLogServerUdp
    syslog = klass((address, port))

    while True:
        if terminate_callable is not None:
            terminate = terminate_callable()
        else:
            terminate = False

        if not terminate:
            syslog.handle_request()


if __name__ == '__main__':
    logging.basicConfig(level=logging.DEBUG)
    syslog_server()

########NEW FILE########
__FILENAME__ = unattended_install
import logging
import time
import re
import os
import tempfile
import ConfigParser
import threading
import shutil
import xml.dom.minidom
from autotest.client.shared import error, iso9660
from autotest.client import utils
from virttest import virt_vm, utils_misc, utils_disk
from virttest import qemu_monitor, remote, syslog_server
from virttest import http_server, data_dir, utils_net, utils_test
from virttest import funcatexit


# Whether to print all shell commands called
DEBUG = False

_url_auto_content_server_thread = None
_url_auto_content_server_thread_event = None

_unattended_server_thread = None
_unattended_server_thread_event = None

_syslog_server_thread = None
_syslog_server_thread_event = None


def start_auto_content_server_thread(port, path):
    global _url_auto_content_server_thread
    global _url_auto_content_server_thread_event

    if _url_auto_content_server_thread is None:
        _url_auto_content_server_thread_event = threading.Event()
        _url_auto_content_server_thread = threading.Thread(
            target=http_server.http_server,
            args=(port, path, terminate_auto_content_server_thread))
        _url_auto_content_server_thread.start()


def start_unattended_server_thread(port, path):
    global _unattended_server_thread
    global _unattended_server_thread_event

    if _unattended_server_thread is None:
        _unattended_server_thread_event = threading.Event()
        _unattended_server_thread = threading.Thread(
            target=http_server.http_server,
            args=(port, path, terminate_unattended_server_thread))
        _unattended_server_thread.start()


def terminate_auto_content_server_thread():
    global _url_auto_content_server_thread
    global _url_auto_content_server_thread_event

    if _url_auto_content_server_thread is None:
        return False
    if _url_auto_content_server_thread_event is None:
        return False

    if _url_auto_content_server_thread_event.isSet():
        return True

    return False


def terminate_unattended_server_thread():
    global _unattended_server_thread, _unattended_server_thread_event

    if _unattended_server_thread is None:
        return False
    if _unattended_server_thread_event is None:
        return False

    if _unattended_server_thread_event.isSet():
        return True

    return False


class RemoteInstall(object):

    """
    Represents a install http server that we can master according to our needs.
    """

    def __init__(self, path, ip, port, filename):
        self.path = path
        utils_disk.cleanup(self.path)
        os.makedirs(self.path)
        self.ip = ip
        self.port = port
        self.filename = filename

        start_unattended_server_thread(self.port, self.path)

    def get_url(self):
        return 'http://%s:%s/%s' % (self.ip, self.port, self.filename)

    def get_answer_file_path(self, filename):
        return os.path.join(self.path, filename)

    def close(self):
        os.chmod(self.path, 0755)
        logging.debug("unattended http server %s successfully created",
                      self.get_url())


class UnattendedInstallConfig(object):

    """
    Creates a floppy disk image that will contain a config file for unattended
    OS install. The parameters to the script are retrieved from environment
    variables.
    """

    def __init__(self, test, params, vm):
        """
        Sets class attributes from test parameters.

        :param test: QEMU test object.
        :param params: Dictionary with test parameters.
        """
        root_dir = data_dir.get_data_dir()
        self.deps_dir = os.path.join(test.virtdir, 'deps')
        self.unattended_dir = os.path.join(test.virtdir, 'unattended')
        self.results_dir = test.debugdir
        self.params = params

        self.attributes = ['kernel_args', 'finish_program', 'cdrom_cd1',
                           'unattended_file', 'medium', 'url', 'kernel',
                           'initrd', 'nfs_server', 'nfs_dir', 'install_virtio',
                           'floppy_name', 'cdrom_unattended', 'boot_path',
                           'kernel_params', 'extra_params', 'qemu_img_binary',
                           'cdkey', 'finish_program', 'vm_type',
                           'process_check', 'vfd_size', 'cdrom_mount_point',
                           'floppy_mount_point', 'cdrom_virtio',
                           'virtio_floppy', 're_driver_match',
                           're_hardware_id', 'driver_in_floppy']

        for a in self.attributes:
            setattr(self, a, params.get(a, ''))

        # Will setup the virtio attributes
        v_attributes = ['virtio_floppy', 'virtio_scsi_path', 'virtio_storage_path',
                        'virtio_network_path', 'virtio_oemsetup_id',
                        'virtio_network_installer_path',
                        'virtio_balloon_installer_path',
                        'virtio_qxl_installer_path']

        for va in v_attributes:
            setattr(self, va, params.get(va, ''))

        self.tmpdir = test.tmpdir
        self.qemu_img_binary = utils_misc.get_qemu_img_binary(params)

        if getattr(self, 'unattended_file'):
            self.unattended_file = os.path.join(test.virtdir,
                                                self.unattended_file)

        if getattr(self, 'finish_program'):
            self.finish_program = os.path.join(test.virtdir,
                                               self.finish_program)

        if getattr(self, 'cdrom_cd1'):
            self.cdrom_cd1 = os.path.join(root_dir, self.cdrom_cd1)
        self.cdrom_cd1_mount = tempfile.mkdtemp(prefix='cdrom_cd1_',
                                                dir=self.tmpdir)
        if getattr(self, 'cdrom_unattended'):
            self.cdrom_unattended = os.path.join(root_dir,
                                                 self.cdrom_unattended)

        if getattr(self, 'virtio_floppy'):
            self.virtio_floppy = os.path.join(root_dir, self.virtio_floppy)

        if getattr(self, 'cdrom_virtio'):
            self.cdrom_virtio = os.path.join(root_dir, self.cdrom_virtio)

        if getattr(self, 'kernel'):
            self.kernel = os.path.join(root_dir, self.kernel)
        if getattr(self, 'initrd'):
            self.initrd = os.path.join(root_dir, self.initrd)

        if self.medium == 'nfs':
            self.nfs_mount = tempfile.mkdtemp(prefix='nfs_',
                                              dir=self.tmpdir)

        setattr(self, 'floppy', self.floppy_name)
        if getattr(self, 'floppy'):
            self.floppy = os.path.join(root_dir, self.floppy)
            if not os.path.isdir(os.path.dirname(self.floppy)):
                os.makedirs(os.path.dirname(self.floppy))

        self.image_path = os.path.dirname(self.kernel)

        # Content server params
        # lookup host ip address for first nic by interface name
        try:
            auto_ip = utils_net.get_ip_address_by_interface(
                vm.virtnet[0].netdst)
        except utils_net.NetError:
            auto_ip = None

        self.url_auto_content_ip = params.get('url_auto_ip', auto_ip)
        self.url_auto_content_port = None

        # Kickstart server params
        # use the same IP as url_auto_content_ip, but a different port
        self.unattended_server_port = None

        # Embedded Syslog Server
        self.syslog_server_enabled = params.get('syslog_server_enabled', 'no')
        self.syslog_server_ip = params.get('syslog_server_ip', auto_ip)
        self.syslog_server_port = int(params.get('syslog_server_port', 5140))
        self.syslog_server_tcp = params.get('syslog_server_proto',
                                            'tcp') == 'tcp'

        self.vm = vm

    @error.context_aware
    def get_driver_hardware_id(self, driver, run_cmd=True):
        """
        Get windows driver's hardware id from inf files.

        :param dirver: Configurable driver name.
        :param run_cmd:  Use hardware id in windows cmd command or not.
        :return: Windows driver's hardware id
        """
        if not os.path.exists(self.cdrom_mount_point):
            os.mkdir(self.cdrom_mount_point)
        if not os.path.exists(self.floppy_mount_point):
            os.mkdir(self.floppy_mount_point)
        if not os.path.ismount(self.cdrom_mount_point):
            utils.system("mount %s %s -o loop" % (self.cdrom_virtio,
                                                  self.cdrom_mount_point), timeout=60)
        if not os.path.ismount(self.floppy_mount_point):
            utils.system("mount %s %s -o loop" % (self.virtio_floppy,
                                                  self.floppy_mount_point), timeout=60)
        drivers_d = []
        driver_link = None
        if self.driver_in_floppy is not None:
            driver_in_floppy = self.driver_in_floppy
            drivers_d = driver_in_floppy.split()
        else:
            drivers_d.append('qxl.inf')
        for driver_d in drivers_d:
            if driver_d in driver:
                driver_link = os.path.join(self.floppy_mount_point, driver)
        if driver_link is None:
            driver_link = os.path.join(self.cdrom_mount_point, driver)
        try:
            txt = open(driver_link, "r").read()
            hwid = re.findall(self.re_hardware_id, txt)[-1].rstrip()
            if run_cmd:
                hwid = '^&'.join(hwid.split('&'))
            return hwid
        except Exception, e:
            logging.error("Fail to get hardware id with exception: %s" % e)

    @error.context_aware
    def update_driver_hardware_id(self, driver):
        """
        Update driver string with the hardware id get from inf files

        @driver: driver string
        :return: new driver string
        """
        if 'hwid' in driver:
            if 'hwidcmd' in driver:
                run_cmd = True
            else:
                run_cmd = False
            if self.re_driver_match is not None:
                d_str = self.re_driver_match
            else:
                d_str = "(\S+)\s*hwid"

            drivers_in_floppy = []
            if self.driver_in_floppy is not None:
                drivers_in_floppy = self.driver_in_floppy.split()

            mount_point = self.cdrom_mount_point
            storage_path = self.cdrom_virtio
            for driver_in_floppy in drivers_in_floppy:
                if driver_in_floppy in driver:
                    mount_point = self.floppy_mount_point
                    storage_path = self.virtio_floppy
                    break

            d_link = re.findall(d_str, driver)[0].split(":")[1]
            d_link = "/".join(d_link.split("\\\\")[1:])
            hwid = utils_test.get_driver_hardware_id(d_link, mount_point,
                                                     storage_path,
                                                     run_cmd=run_cmd)
            if hwid:
                driver = driver.replace("hwidcmd", hwid.strip())
            else:
                raise error.TestError("Can not find hwid from the driver"
                                      " inf file")
        return driver

    def answer_kickstart(self, answer_path):
        """
        Replace KVM_TEST_CDKEY (in the unattended file) with the cdkey
        provided for this test and replace the KVM_TEST_MEDIUM with
        the tree url or nfs address provided for this test.

        :return: Answer file contents
        """
        contents = open(self.unattended_file).read()

        dummy_cdkey_re = r'\bKVM_TEST_CDKEY\b'
        if re.search(dummy_cdkey_re, contents):
            if self.cdkey:
                contents = re.sub(dummy_cdkey_re, self.cdkey, contents)

        dummy_medium_re = r'\bKVM_TEST_MEDIUM\b'
        if self.medium in ["cdrom", "kernel_initrd"]:
            content = "cdrom"

        elif self.medium == "url":
            content = "url --url %s" % self.url

        elif self.medium == "nfs":
            content = "nfs --server=%s --dir=%s" % (self.nfs_server,
                                                    self.nfs_dir)
        else:
            raise ValueError("Unexpected installation medium %s" % self.url)

        contents = re.sub(dummy_medium_re, content, contents)

        dummy_logging_re = r'\bKVM_TEST_LOGGING\b'
        if re.search(dummy_logging_re, contents):
            if self.syslog_server_enabled == 'yes':
                l = 'logging --host=%s --port=%s --level=debug'
                l = l % (self.syslog_server_ip, self.syslog_server_port)
            else:
                l = ''
            contents = re.sub(dummy_logging_re, l, contents)

        logging.debug("Unattended install contents:")
        for line in contents.splitlines():
            logging.debug(line)

        utils.open_write_close(answer_path, contents)

    def answer_windows_ini(self, answer_path):
        parser = ConfigParser.ConfigParser()
        parser.read(self.unattended_file)
        # First, replacing the CDKEY
        if self.cdkey:
            parser.set('UserData', 'ProductKey', self.cdkey)
        else:
            logging.error("Param 'cdkey' required but not specified for "
                          "this unattended installation")

        # Now, replacing the virtio network driver path, under double quotes
        if self.install_virtio == 'yes':
            parser.set('Unattended', 'OemPnPDriversPath',
                       '"%s"' % self.virtio_network_path)
        else:
            parser.remove_option('Unattended', 'OemPnPDriversPath')

        dummy_re_dirver = {'KVM_TEST_VIRTIO_NETWORK_INSTALLER':
                           'virtio_network_installer_path',
                           'KVM_TEST_VIRTIO_BALLOON_INSTALLER':
                           'virtio_balloon_installer_path',
                           'KVM_TEST_VIRTIO_QXL_INSTALLER':
                           'virtio_qxl_installer_path'}
        dummy_re = ""
        for dummy in dummy_re_dirver:
            if dummy_re:
                dummy_re += "|%s" % dummy
            else:
                dummy_re = dummy

        # Replace the process check in finish command
        dummy_process_re = r'\bPROCESS_CHECK\b'
        for opt in parser.options('GuiRunOnce'):
            check = parser.get('GuiRunOnce', opt)
            if re.search(dummy_process_re, check):
                process_check = re.sub(dummy_process_re,
                                       "%s" % self.process_check,
                                       check)
                parser.set('GuiRunOnce', opt, process_check)
            elif re.findall(dummy_re, check):
                dummy = re.findall(dummy_re, check)[0]
                driver = getattr(self, dummy_re_dirver[dummy])
                if driver.endswith("msi"):
                    driver = 'msiexec /passive /package ' + driver
                elif 'INSTALLER' in dummy:
                    driver = self.update_driver_hardware_id(driver)
                elif driver is None:
                    driver = 'dir'
                check = re.sub(dummy, driver, check)
                parser.set('GuiRunOnce', opt, check)
        # Now, writing the in memory config state to the unattended file
        fp = open(answer_path, 'w')
        parser.write(fp)
        fp.close()

        # Let's read it so we can debug print the contents
        fp = open(answer_path, 'r')
        contents = fp.read()
        fp.close()
        logging.debug("Unattended install contents:")
        for line in contents.splitlines():
            logging.debug(line)

    def answer_windows_xml(self, answer_path):
        doc = xml.dom.minidom.parse(self.unattended_file)

        if self.cdkey:
            # First, replacing the CDKEY
            product_key = doc.getElementsByTagName('ProductKey')[0]
            if product_key.getElementsByTagName('Key'):
                key = product_key.getElementsByTagName('Key')[0]
                key_text = key.childNodes[0]
            else:
                key_text = product_key.childNodes[0]

            assert key_text.nodeType == doc.TEXT_NODE
            key_text.data = self.cdkey
        else:
            logging.error("Param 'cdkey' required but not specified for "
                          "this unattended installation")

        # Now, replacing the virtio driver paths or removing the entire
        # component PnpCustomizationsWinPE Element Node
        if self.install_virtio == 'yes':
            paths = doc.getElementsByTagName("Path")
            values = [self.virtio_scsi_path, self.virtio_storage_path, self.virtio_network_path]
            for path, value in zip(paths, values):
                path_text = path.childNodes[0]
                assert path_text.nodeType == doc.TEXT_NODE
                path_text.data = value
        else:
            settings = doc.getElementsByTagName("settings")
            for s in settings:
                for c in s.getElementsByTagName("component"):
                    if (c.getAttribute('name') ==
                            "Microsoft-Windows-PnpCustomizationsWinPE"):
                        s.removeChild(c)

        # Last but not least important, replacing the virtio installer command
        # And process check in finish command
        command_lines = doc.getElementsByTagName("CommandLine")
        dummy_re_dirver = {'KVM_TEST_VIRTIO_NETWORK_INSTALLER':
                           'virtio_network_installer_path',
                           'KVM_TEST_VIRTIO_BALLOON_INSTALLER':
                           'virtio_balloon_installer_path',
                           'KVM_TEST_VIRTIO_QXL_INSTALLER':
                           'virtio_qxl_installer_path'}
        process_check_re = 'PROCESS_CHECK'
        dummy_re = ""
        for dummy in dummy_re_dirver:
            if dummy_re:
                dummy_re += "|%s" % dummy
            else:
                dummy_re = dummy

        for command_line in command_lines:
            command_line_text = command_line.childNodes[0]
            assert command_line_text.nodeType == doc.TEXT_NODE

            if re.findall(dummy_re, command_line_text.data):
                dummy = re.findall(dummy_re, command_line_text.data)[0]
                driver = getattr(self, dummy_re_dirver[dummy])

                if driver.endswith("msi"):
                    driver = 'msiexec /passive /package ' + driver
                elif 'INSTALLER' in dummy:
                    driver = self.update_driver_hardware_id(driver)
                t = command_line_text.data
                t = re.sub(dummy_re, driver, t)
                command_line_text.data = t

            if process_check_re in command_line_text.data:
                t = command_line_text.data
                t = re.sub(process_check_re, self.process_check, t)
                command_line_text.data = t

        contents = doc.toxml()
        logging.debug("Unattended install contents:")
        for line in contents.splitlines():
            logging.debug(line)

        fp = open(answer_path, 'w')
        doc.writexml(fp)
        fp.close()

    def answer_suse_xml(self, answer_path):
        # There's nothing to replace on SUSE files to date. Yay!
        doc = xml.dom.minidom.parse(self.unattended_file)

        contents = doc.toxml()
        logging.debug("Unattended install contents:")
        for line in contents.splitlines():
            logging.debug(line)

        fp = open(answer_path, 'w')
        doc.writexml(fp)
        fp.close()

    def preseed_initrd(self):
        """
        Puts a preseed file inside a gz compressed initrd file.

        Debian and Ubuntu use preseed as the OEM install mechanism. The only
        way to get fully automated setup without resorting to kernel params
        is to add a preseed.cfg file at the root of the initrd image.
        """
        logging.debug("Remastering initrd.gz file with preseed file")
        dest_fname = 'preseed.cfg'
        remaster_path = os.path.join(self.image_path, "initrd_remaster")
        if not os.path.isdir(remaster_path):
            os.makedirs(remaster_path)

        base_initrd = os.path.basename(self.initrd)
        os.chdir(remaster_path)
        utils.run("gzip -d < ../%s | fakeroot cpio --extract --make-directories "
                  "--no-absolute-filenames" % base_initrd, verbose=DEBUG)
        utils.run("cp %s %s" % (self.unattended_file, dest_fname),
                  verbose=DEBUG)

        # For libvirt initrd.gz will be renamed to initrd.img in setup_cdrom()
        utils.run("find . | fakeroot cpio -H newc --create | gzip -9 > ../%s" %
                  base_initrd, verbose=DEBUG)

        os.chdir(self.image_path)
        utils.run("rm -rf initrd_remaster", verbose=DEBUG)
        contents = open(self.unattended_file).read()

        logging.debug("Unattended install contents:")
        for line in contents.splitlines():
            logging.debug(line)

    def setup_unattended_http_server(self):
        '''
        Setup a builtin http server for serving the kickstart file

        Does nothing if unattended file is not a kickstart file
        '''
        if self.unattended_file.endswith('.ks'):
            # Red Hat kickstart install
            dest_fname = 'ks.cfg'

            answer_path = os.path.join(self.tmpdir, dest_fname)
            self.answer_kickstart(answer_path)

            if self.unattended_server_port is None:
                self.unattended_server_port = utils_misc.find_free_port(
                    8000,
                    8099,
                    self.url_auto_content_ip)

            start_unattended_server_thread(self.unattended_server_port,
                                           self.tmpdir)

        # Point installation to this kickstart url
        ks_param = 'ks=http://%s:%s/%s' % (self.url_auto_content_ip,
                                           self.unattended_server_port,
                                           dest_fname)
        if 'ks=' in self.kernel_params:
            kernel_params = re.sub('ks\=[\w\d\:\.\/]+',
                                   ks_param,
                                   self.kernel_params)
        else:
            kernel_params = '%s %s' % (self.kernel_params, ks_param)

        # reflect change on params
        self.kernel_params = kernel_params

    def setup_boot_disk(self):
        if self.unattended_file.endswith('.sif'):
            dest_fname = 'winnt.sif'
            setup_file = 'winnt.bat'
            boot_disk = utils_disk.FloppyDisk(self.floppy,
                                              self.qemu_img_binary,
                                              self.tmpdir, self.vfd_size)
            answer_path = boot_disk.get_answer_file_path(dest_fname)
            self.answer_windows_ini(answer_path)
            setup_file_path = os.path.join(self.unattended_dir, setup_file)
            boot_disk.copy_to(setup_file_path)
            if self.install_virtio == "yes":
                boot_disk.setup_virtio_win2003(self.virtio_floppy,
                                               self.virtio_oemsetup_id)
            boot_disk.copy_to(self.finish_program)

        elif self.unattended_file.endswith('.ks'):
            # Red Hat kickstart install
            dest_fname = 'ks.cfg'
            if self.params.get('unattended_delivery_method') == 'integrated':
                ks_param = 'ks=cdrom:/dev/sr0:/isolinux/%s' % dest_fname
                kernel_params = self.kernel_params
                if 'ks=' in kernel_params:
                    kernel_params = re.sub('ks\=[\w\d\:\.\/]+',
                                           ks_param,
                                           kernel_params)
                else:
                    kernel_params = '%s %s' % (kernel_params, ks_param)

                # Standard setting is kickstart disk in /dev/sr0 and
                # install cdrom in /dev/sr1. As we merge them together,
                # we need to change repo configuration to /dev/sr0
                if 'repo=cdrom' in kernel_params:
                    kernel_params = re.sub('repo\=cdrom[\:\w\d\/]*',
                                           'repo=cdrom:/dev/sr0',
                                           kernel_params)

                self.kernel_params = None
                boot_disk = utils_disk.CdromInstallDisk(
                    self.cdrom_unattended,
                    self.tmpdir,
                    self.cdrom_cd1_mount,
                    kernel_params)
            elif self.params.get('unattended_delivery_method') == 'url':
                if self.unattended_server_port is None:
                    self.unattended_server_port = utils_misc.find_free_port(
                        8000,
                        8099,
                        self.url_auto_content_ip)
                path = os.path.join(os.path.dirname(self.cdrom_unattended),
                                    'ks')
                boot_disk = RemoteInstall(path, self.url_auto_content_ip,
                                          self.unattended_server_port,
                                          dest_fname)
                ks_param = 'ks=%s' % boot_disk.get_url()
                kernel_params = self.kernel_params
                if 'ks=' in kernel_params:
                    kernel_params = re.sub('ks\=[\w\d\:\.\/]+',
                                           ks_param,
                                           kernel_params)
                else:
                    kernel_params = '%s %s' % (kernel_params, ks_param)

                # Standard setting is kickstart disk in /dev/sr0 and
                # install cdrom in /dev/sr1. When we get ks via http,
                # we need to change repo configuration to /dev/sr0
                kernel_params = re.sub('repo\=cdrom[\:\w\d\/]*',
                                       'repo=cdrom:/dev/sr0',
                                       kernel_params)

                self.kernel_params = kernel_params
            elif self.params.get('unattended_delivery_method') == 'cdrom':
                boot_disk = utils_disk.CdromDisk(self.cdrom_unattended,
                                                 self.tmpdir)
            elif self.params.get('unattended_delivery_method') == 'floppy':
                boot_disk = utils_disk.FloppyDisk(self.floppy,
                                                  self.qemu_img_binary,
                                                  self.tmpdir, self.vfd_size)
                ks_param = 'ks=floppy'
                kernel_params = self.kernel_params
                if 'ks=' in kernel_params:
                    # Reading ks from floppy directly doesn't work in some OS,
                    # options 'ks=hd:/dev/fd0' can reading ks from mounted
                    # floppy, so skip repace it;
                    if not re.search("fd\d+", kernel_params):
                        kernel_params = re.sub('ks\=[\w\d\:\.\/]+',
                                               ks_param,
                                               kernel_params)
                else:
                    kernel_params = '%s %s' % (kernel_params, ks_param)

                kernel_params = re.sub('repo\=cdrom[\:\w\d\/]*',
                                       'repo=cdrom:/dev/sr0',
                                       kernel_params)

                self.kernel_params = kernel_params
            else:
                raise ValueError("Neither cdrom_unattended nor floppy set "
                                 "on the config file, please verify")
            answer_path = boot_disk.get_answer_file_path(dest_fname)
            self.answer_kickstart(answer_path)

        elif self.unattended_file.endswith('.xml'):
            if "autoyast" in self.kernel_params:
                # SUSE autoyast install
                dest_fname = "autoinst.xml"
                if (self.cdrom_unattended and
                        self.params.get('unattended_delivery_method') == 'cdrom'):
                    boot_disk = utils_disk.CdromDisk(self.cdrom_unattended,
                                                     self.tmpdir)
                elif self.floppy:
                    autoyast_param = 'autoyast=device://fd0/autoinst.xml'
                    kernel_params = self.kernel_params
                    if 'autoyast=' in kernel_params:
                        kernel_params = re.sub('autoyast\=[\w\d\:\.\/]+',
                                               autoyast_param,
                                               kernel_params)
                    else:
                        kernel_params = '%s %s' % (
                            kernel_params, autoyast_param)

                    self.kernel_params = kernel_params
                    boot_disk = utils_disk.FloppyDisk(self.floppy,
                                                      self.qemu_img_binary,
                                                      self.tmpdir,
                                                      self.vfd_size)
                else:
                    raise ValueError("Neither cdrom_unattended nor floppy set "
                                     "on the config file, please verify")
                answer_path = boot_disk.get_answer_file_path(dest_fname)
                self.answer_suse_xml(answer_path)

            else:
                # Windows unattended install
                dest_fname = "autounattend.xml"
                if self.params.get('unattended_delivery_method') == 'cdrom':
                    boot_disk = utils_disk.CdromDisk(self.cdrom_unattended,
                                                     self.tmpdir)
                    if self.install_virtio == "yes":
                        boot_disk.setup_virtio_win2008(self.virtio_floppy,
                                                       self.cdrom_virtio)
                    self.cdrom_virtio = None
                else:
                    boot_disk = utils_disk.FloppyDisk(self.floppy,
                                                      self.qemu_img_binary,
                                                      self.tmpdir,
                                                      self.vfd_size)
                    if self.install_virtio == "yes":
                        boot_disk.setup_virtio_win2008(self.virtio_floppy)
                answer_path = boot_disk.get_answer_file_path(dest_fname)
                self.answer_windows_xml(answer_path)

                boot_disk.copy_to(self.finish_program)

        else:
            raise ValueError('Unknown answer file type: %s' %
                             self.unattended_file)

        boot_disk.close()

    @error.context_aware
    def setup_cdrom(self):
        """
        Mount cdrom and copy vmlinuz and initrd.img.
        """
        error.context("Copying vmlinuz and initrd.img from install cdrom %s" %
                      self.cdrom_cd1)
        if not os.path.isdir(self.image_path):
            os.makedirs(self.image_path)

        if (self.params.get('unattended_delivery_method') in
                ['integrated', 'url']):
            i = iso9660.Iso9660Mount(self.cdrom_cd1)
            self.cdrom_cd1_mount = i.mnt_dir
        else:
            i = iso9660.iso9660(self.cdrom_cd1)

        if i is None:
            raise error.TestFail("Could not instantiate an iso9660 class")

        i.copy(os.path.join(self.boot_path, os.path.basename(self.kernel)),
               self.kernel)
        assert(os.path.getsize(self.kernel) > 0)
        i.copy(os.path.join(self.boot_path, os.path.basename(self.initrd)),
               self.initrd)
        assert(os.path.getsize(self.initrd) > 0)

        if self.unattended_file.endswith('.preseed'):
            self.preseed_initrd()

        if self.params.get("vm_type") == "libvirt":
            if self.vm.driver_type == 'qemu':
                # Virtinstall command needs files "vmlinuz" and "initrd.img"
                os.chdir(self.image_path)
                base_kernel = os.path.basename(self.kernel)
                base_initrd = os.path.basename(self.initrd)
                if base_kernel != 'vmlinuz':
                    utils.run("mv %s vmlinuz" % base_kernel, verbose=DEBUG)
                if base_initrd != 'initrd.img':
                    utils.run("mv %s initrd.img" % base_initrd, verbose=DEBUG)
                if (self.params.get('unattended_delivery_method') !=
                        'integrated'):
                    i.close()
                    utils_disk.cleanup(self.cdrom_cd1_mount)
            elif ((self.vm.driver_type == 'xen') and
                  (self.params.get('hvm_or_pv') == 'pv')):
                logging.debug("starting unattended content web server")

                self.url_auto_content_port = utils_misc.find_free_port(8100,
                                                                       8199,
                                                                       self.url_auto_content_ip)

                start_auto_content_server_thread(self.url_auto_content_port,
                                                 self.cdrom_cd1_mount)

                self.medium = 'url'
                self.url = ('http://%s:%s' % (self.url_auto_content_ip,
                                              self.url_auto_content_port))

                pxe_path = os.path.join(
                    os.path.dirname(self.image_path), 'xen')
                if not os.path.isdir(pxe_path):
                    os.makedirs(pxe_path)

                pxe_kernel = os.path.join(pxe_path,
                                          os.path.basename(self.kernel))
                pxe_initrd = os.path.join(pxe_path,
                                          os.path.basename(self.initrd))
                utils.run("cp %s %s" % (self.kernel, pxe_kernel))
                utils.run("cp %s %s" % (self.initrd, pxe_initrd))

                if 'repo=cdrom' in self.kernel_params:
                    # Red Hat
                    self.kernel_params = re.sub('repo\=[\:\w\d\/]*',
                                                'repo=http://%s:%s' %
                                                (self.url_auto_content_ip,
                                                 self.url_auto_content_port),
                                                self.kernel_params)

    @error.context_aware
    def setup_url_auto(self):
        """
        Configures the builtin web server for serving content
        """
        auto_content_url = 'http://%s:%s' % (self.url_auto_content_ip,
                                             self.url_auto_content_port)
        self.params['auto_content_url'] = auto_content_url

    @error.context_aware
    def setup_url(self):
        """
        Download the vmlinuz and initrd.img from URL.
        """
        # it's only necessary to download kernel/initrd if running bare qemu
        if self.vm_type == 'qemu':
            error.context("downloading vmlinuz/initrd.img from %s" % self.url)
            if not os.path.exists(self.image_path):
                os.mkdir(self.image_path)
            os.chdir(self.image_path)
            kernel_cmd = "wget -q %s/%s/%s" % (self.url,
                                               self.boot_path,
                                               os.path.basename(self.kernel))
            initrd_cmd = "wget -q %s/%s/%s" % (self.url,
                                               self.boot_path,
                                               os.path.basename(self.initrd))

            if os.path.exists(self.kernel):
                os.remove(self.kernel)
            if os.path.exists(self.initrd):
                os.remove(self.initrd)

            utils.run(kernel_cmd, verbose=DEBUG)
            utils.run(initrd_cmd, verbose=DEBUG)

            if 'repo=cdrom' in self.kernel_params:
                # Red Hat
                self.kernel_params = re.sub('repo\=[\:\w\d\/]*',
                                            'repo=%s' % self.url,
                                            self.kernel_params)
            elif 'autoyast=' in self.kernel_params:
                # SUSE
                self.kernel_params = (self.kernel_params + " ip=dhcp install=" + self.url)

        elif self.vm_type == 'libvirt':
            logging.info("Not downloading vmlinuz/initrd.img from %s, "
                         "letting virt-install do it instead")

        else:
            logging.info("No action defined/needed for the current virt "
                         "type: '%s'" % self.vm_type)

    def setup_nfs(self):
        """
        Copy the vmlinuz and initrd.img from nfs.
        """
        error.context("copying the vmlinuz and initrd.img from NFS share")

        m_cmd = ("mount %s:%s %s -o ro" %
                 (self.nfs_server, self.nfs_dir, self.nfs_mount))
        utils.run(m_cmd, verbose=DEBUG)

        try:
            kernel_fetch_cmd = ("cp %s/%s/%s %s" %
                                (self.nfs_mount, self.boot_path,
                                 os.path.basename(self.kernel), self.image_path))
            utils.run(kernel_fetch_cmd, verbose=DEBUG)
            initrd_fetch_cmd = ("cp %s/%s/%s %s" %
                                (self.nfs_mount, self.boot_path,
                                 os.path.basename(self.initrd), self.image_path))
            utils.run(initrd_fetch_cmd, verbose=DEBUG)
        finally:
            utils_disk.cleanup(self.nfs_mount)

        if 'autoyast=' in self.kernel_params:
            # SUSE
            self.kernel_params = (self.kernel_params + " ip=dhcp "
                                  "install=nfs://" + self.nfs_server + ":" + self.nfs_dir)

    def setup_import(self):
        self.unattended_file = None
        self.kernel_params = None

    def setup(self):
        """
        Configure the environment for unattended install.

        Uses an appropriate strategy according to each install model.
        """
        logging.info("Starting unattended install setup")
        if DEBUG:
            utils_misc.display_attributes(self)

        if self.syslog_server_enabled == 'yes':
            start_syslog_server_thread(self.syslog_server_ip,
                                       self.syslog_server_port,
                                       self.syslog_server_tcp)

        if self.medium in ["cdrom", "kernel_initrd"]:
            if self.kernel and self.initrd:
                self.setup_cdrom()
        elif self.medium == "url":
            self.setup_url()
        elif self.medium == "nfs":
            self.setup_nfs()
        elif self.medium == "import":
            self.setup_import()
        else:
            raise ValueError("Unexpected installation method %s" %
                             self.medium)
        if self.unattended_file and (self.floppy or self.cdrom_unattended):
            self.setup_boot_disk()
            if self.params.get("store_boot_disk") == "yes":
                logging.info("Sotre the boot disk to result directory for"
                             " further debug")
                src_dir = self.floppy or self.cdrom_unattended
                dst_dir = self.results_dir
                shutil.copy(src_dir, dst_dir)

        # Update params dictionary as some of the values could be updated
        for a in self.attributes:
            self.params[a] = getattr(self, a)


def start_syslog_server_thread(address, port, tcp):
    global _syslog_server_thread
    global _syslog_server_thread_event

    syslog_server.set_default_format('[UnattendedSyslog '
                                     '(%s.%s)] %s')

    if _syslog_server_thread is None:
        _syslog_server_thread_event = threading.Event()
        _syslog_server_thread = threading.Thread(
            target=syslog_server.syslog_server,
            args=(address, port, tcp, terminate_syslog_server_thread))
        _syslog_server_thread.start()


def terminate_syslog_server_thread():
    global _syslog_server_thread, _syslog_server_thread_event

    if _syslog_server_thread is None:
        return False
    if _syslog_server_thread_event is None:
        return False

    if _syslog_server_thread_event.isSet():
        return True

    return False


def copy_file_from_nfs(src, dst, mount_point, image_name):
    logging.info("Test failed before the install process start."
                 " So just copy a good image from nfs for following tests.")
    utils_misc.mount(src, mount_point, "nfs", perm="ro")
    image_src = utils_misc.get_path(mount_point, image_name)
    shutil.copy(image_src, dst)
    utils_misc.umount(src, mount_point, "nfs")


@error.context_aware
def run(test, params, env):
    """
    Unattended install test:
    1) Starts a VM with an appropriated setup to start an unattended OS install.
    2) Wait until the install reports to the install watcher its end.

    :param test: QEMU test object.
    :param params: Dictionary with the test parameters.
    :param env: Dictionary with test environment.
    """
    @error.context_aware
    def copy_images():
        error.base_context("Copy image from NFS after installation failure")
        image_copy_on_error = params.get("image_copy_on_error", "no")
        if image_copy_on_error == "yes":
            logging.info("Running image_copy to copy pristine image from NFS.")
            try:
                error.context("Quit qemu-kvm before copying guest image")
                vm.monitor.quit()
            except Exception, e:
                logging.warn(e)
            from virttest import utils_test
            error.context("Copy image from NFS Server")
            utils_test.run_image_copy(test, params, env)

    image = '%s.%s' % (params['image_name'], params['image_format'])
    image_name = os.path.basename(image)
    src = params.get('images_good')
    dst = '%s/%s' % (data_dir.get_data_dir(), image)
    mount_point = params.get("dst_dir")
    if mount_point and src:
        funcatexit.register(env, params.get("type"), copy_file_from_nfs, src,
                            dst, mount_point, image_name)

    vm = env.get_vm(params["main_vm"])
    local_dir = params.get("local_dir")
    if local_dir:
        local_dir = utils_misc.get_path(test.bindir, local_dir)
    else:
        local_dir = test.bindir
    if params.get("copy_to_local"):
        for param in params.get("copy_to_local").split():
            l_value = params.get(param)
            if l_value:
                need_copy = True
                nfs_link = utils_misc.get_path(test.bindir, l_value)
                i_name = os.path.basename(l_value)
                local_link = os.path.join(local_dir, i_name)
                if os.path.isfile(local_link):
                    file_hash = utils.hash_file(local_link, "md5")
                    expected_hash = utils.hash_file(nfs_link, "md5")
                    if file_hash == expected_hash:
                        need_copy = False
                if need_copy:
                    msg = "Copy %s to %s in local host." % (i_name, local_link)
                    error.context(msg, logging.info)
                    utils.get_file(nfs_link, local_link)
                    params[param] = local_link

    unattended_install_config = UnattendedInstallConfig(test, params, vm)
    unattended_install_config.setup()

    # params passed explicitly, because they may have been updated by
    # unattended install config code, such as when params['url'] == auto
    vm.create(params=params)

    post_finish_str = params.get("post_finish_str",
                                 "Post set up finished")
    install_timeout = int(params.get("install_timeout", 3000))

    migrate_background = params.get("migrate_background") == "yes"
    if migrate_background:
        mig_timeout = float(params.get("mig_timeout", "3600"))
        mig_protocol = params.get("migration_protocol", "tcp")

    logging.info("Waiting for installation to finish. Timeout set to %d s "
                 "(%d min)", install_timeout, install_timeout / 60)
    error.context("waiting for installation to finish")

    start_time = time.time()

    try:
        serial_name = vm.serial_ports[0]
    except IndexError:
        raise virt_vm.VMConfigMissingError(vm.name, "isa_serial")

    log_file = utils_misc.get_path(test.debugdir,
                                   "serial-%s-%s.log" % (serial_name,
                                                         vm.name))
    logging.debug("Monitoring serial console log for completion message: %s",
                  log_file)
    serial_log_msg = ""
    serial_read_fails = 0

    # As the the install process start. We may need collect informations from
    # the image. So use the test case instead this simple function in the
    # following code.
    if mount_point and src:
        funcatexit.unregister(env, params.get("type"), copy_file_from_nfs,
                              src, dst, mount_point, image_name)

    while (time.time() - start_time) < install_timeout:
        try:
            vm.verify_alive()
        # Due to a race condition, sometimes we might get a MonitorError
        # before the VM gracefully shuts down, so let's capture MonitorErrors.
        except (virt_vm.VMDeadError, qemu_monitor.MonitorError), e:
            if params.get("wait_no_ack", "no") == "yes":
                break
            else:
                # Print out the original exception before copying images.
                logging.error(e)
                copy_images()
                raise e

        try:
            test.verify_background_errors()
        except Exception, e:
            copy_images()
            raise e

        # To ignore the try:except:finally problem in old version of python
        try:
            serial_log_msg = open(log_file, 'r').read()
        except IOError:
            # Only make noise after several failed reads
            serial_read_fails += 1
            if serial_read_fails > 10:
                logging.warn("Can not read from serial log file after %d tries",
                             serial_read_fails)

        if (params.get("wait_no_ack", "no") == "no" and
                (post_finish_str in serial_log_msg)):
            break

        # Due to libvirt automatically start guest after import
        # we only need to wait for successful login.
        if params.get("medium") == "import":
            try:
                vm.login()
                break
            except (remote.LoginError, Exception), e:
                pass

        if migrate_background:
            vm.migrate(timeout=mig_timeout, protocol=mig_protocol)
        else:
            time.sleep(1)
    else:
        logging.warn("Timeout elapsed while waiting for install to finish ")
        copy_images()
        raise error.TestFail("Timeout elapsed while waiting for install to "
                             "finish")

    logging.debug('cleaning up threads and mounts that may be active')
    global _url_auto_content_server_thread
    global _url_auto_content_server_thread_event
    if _url_auto_content_server_thread is not None:
        _url_auto_content_server_thread_event.set()
        _url_auto_content_server_thread.join(3)
        _url_auto_content_server_thread = None
        utils_disk.cleanup(unattended_install_config.cdrom_cd1_mount)

    global _unattended_server_thread
    global _unattended_server_thread_event
    if _unattended_server_thread is not None:
        _unattended_server_thread_event.set()
        _unattended_server_thread.join(3)
        _unattended_server_thread = None

    global _syslog_server_thread
    global _syslog_server_thread_event
    if _syslog_server_thread is not None:
        _syslog_server_thread_event.set()
        _syslog_server_thread.join(3)
        _syslog_server_thread = None

    time_elapsed = time.time() - start_time
    logging.info("Guest reported successful installation after %d s (%d min)",
                 time_elapsed, time_elapsed / 60)

    if params.get("shutdown_cleanly", "yes") == "yes":
        shutdown_cleanly_timeout = int(params.get("shutdown_cleanly_timeout",
                                                  120))
        logging.info("Wait for guest to shutdown cleanly")
        if params.get("medium", "cdrom") == "import":
            vm.shutdown()
        try:
            if utils_misc.wait_for(vm.is_dead, shutdown_cleanly_timeout, 1, 1):
                logging.info("Guest managed to shutdown cleanly")
        except qemu_monitor.MonitorError, e:
            logging.warning("Guest apparently shut down, but got a "
                            "monitor error: %s", e)

########NEW FILE########
__FILENAME__ = utils_cgroup_unittest
#!/usr/bin/env python

import os
import unittest
import tempfile
import common
from staging import utils_cgroup
from autotest.client.shared import error

# Mount file content, Controllers and mount points from RHEL-6
mount_1 = """rootfs / rootfs rw 0 0
proc /proc proc rw,relatime 0 0
sysfs /sys sysfs rw,seclabel,relatime 0 0
devtmpfs /dev devtmpfs rw,seclabel,relatime,size=3955196k,nr_inodes=988799,mode=755 0 0
devpts /dev/pts devpts rw,seclabel,relatime,gid=5,mode=620,ptmxmode=000 0 0
tmpfs /dev/shm tmpfs rw,seclabel,relatime 0 0
/dev/sda1 / ext4 rw,seclabel,relatime,barrier=1,data=ordered 0 0
none /selinux selinuxfs rw,relatime 0 0
devtmpfs /dev devtmpfs rw,seclabel,relatime,size=3955196k,nr_inodes=988799,mode=755 0 0
/proc/bus/usb /proc/bus/usb usbfs rw,relatime 0 0
/dev/sda3 /data ext4 rw,seclabel,relatime,barrier=1,data=ordered 0 0
none /proc/sys/fs/binfmt_misc binfmt_misc rw,relatime 0 0
sunrpc /var/lib/nfs/rpc_pipefs rpc_pipefs rw,relatime 0 0
nfsd /proc/fs/nfsd nfsd rw,relatime 0 0
cgroup /cgroup/cpuset cgroup rw,relatime,cpuset 0 0
cgroup /cgroup/cpu cgroup rw,relatime,cpu 0 0
cgroup /cgroup/cpuacct cgroup rw,relatime,cpuacct 0 0
cgroup /cgroup/memory cgroup rw,relatime,memory 0 0
cgroup /cgroup/devices cgroup rw,relatime,devices 0 0
cgroup /cgroup/freezer cgroup rw,relatime,freezer 0 0
cgroup /cgroup/net_cls cgroup rw,relatime,net_cls 0 0
cgroup /cgroup/blkio cgroup rw,relatime,blkio 0 0
"""
controllers_1 = [
    "cpuset",
    "cpu",
    "cpuacct",
    "memory",
    "devices",
    "freezer",
    "net_cls",
    "blkio",
]
mount_points_1 = [
    "/cgroup/cpuset",
    "/cgroup/cpu",
    "/cgroup/cpuacct",
    "/cgroup/memory",
    "/cgroup/devices",
    "/cgroup/freezer",
    "/cgroup/net_cls",
    "/cgroup/blkio",
]

# Mount file content, Controllers and mount points from RHEL-7
mount_2 = """rootfs / rootfs rw 0 0
proc /proc proc rw,nosuid,nodev,noexec,relatime 0 0
sysfs /sys sysfs rw,seclabel,nosuid,nodev,noexec,relatime 0 0
devtmpfs /dev devtmpfs rw,seclabel,nosuid,size=3886908k,nr_inodes=971727,mode=755 0 0
securityfs /sys/kernel/security securityfs rw,nosuid,nodev,noexec,relatime 0 0
selinuxfs /sys/fs/selinux selinuxfs rw,relatime 0 0
tmpfs /dev/shm tmpfs rw,seclabel,nosuid,nodev 0 0
devpts /dev/pts devpts rw,seclabel,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000 0 0
tmpfs /run tmpfs rw,seclabel,nosuid,nodev,mode=755 0 0
tmpfs /sys/fs/cgroup tmpfs rw,seclabel,nosuid,nodev,noexec,mode=755 0 0
cgroup /sys/fs/cgroup/systemd cgroup rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd 0 0
pstore /sys/fs/pstore pstore rw,nosuid,nodev,noexec,relatime 0 0
cgroup /sys/fs/cgroup/cpuset cgroup rw,nosuid,nodev,noexec,relatime,cpuset 0 0
cgroup /sys/fs/cgroup/cpu,cpuacct cgroup rw,nosuid,nodev,noexec,relatime,cpuacct,cpu 0 0
cgroup /sys/fs/cgroup/memory cgroup rw,nosuid,nodev,noexec,relatime,memory 0 0
cgroup /sys/fs/cgroup/devices cgroup rw,nosuid,nodev,noexec,relatime,devices 0 0
cgroup /sys/fs/cgroup/freezer cgroup rw,nosuid,nodev,noexec,relatime,freezer 0 0
cgroup /sys/fs/cgroup/net_cls cgroup rw,nosuid,nodev,noexec,relatime,net_cls 0 0
cgroup /sys/fs/cgroup/blkio cgroup rw,nosuid,nodev,noexec,relatime,blkio 0 0
cgroup /sys/fs/cgroup/perf_event cgroup rw,nosuid,nodev,noexec,relatime,perf_event 0 0
cgroup /sys/fs/cgroup/hugetlb cgroup rw,nosuid,nodev,noexec,relatime,hugetlb 0 0
/dev/mapper/rhel-root / xfs rw,seclabel,relatime,attr2,inode64,noquota 0 0
systemd-1 /proc/sys/fs/binfmt_misc autofs rw,relatime,fd=35,pgrp=1,timeout=300,minproto=5,maxproto=5,direct 0 0
debugfs /sys/kernel/debug debugfs rw,relatime 0 0
mqueue /dev/mqueue mqueue rw,seclabel,relatime 0 0
hugetlbfs /dev/hugepages hugetlbfs rw,seclabel,relatime 0 0
configfs /sys/kernel/config configfs rw,relatime 0 0
sunrpc /var/lib/nfs/rpc_pipefs rpc_pipefs rw,relatime 0 0
sunrpc /proc/fs/nfsd nfsd rw,relatime 0 0
/dev/sda1 /boot xfs rw,seclabel,relatime,attr2,inode64,noquota 0 0
/dev/mapper/rhel-home /home xfs rw,seclabel,relatime,attr2,inode64,noquota 0 0
binfmt_misc /proc/sys/fs/binfmt_misc binfmt_misc rw,relatime 0 0
"""
controllers_2 = [
    "systemd",
    "cpuset",
    "cpu",
    "cpuacct",
    "memory",
    "devices",
    "freezer",
    "net_cls",
    "blkio",
    "perf_event",
    "hugetlb",
]
mount_points_2 = [
    "/sys/fs/cgroup/systemd",
    "/sys/fs/cgroup/cpuset",
    "/sys/fs/cgroup/cpu,cpuacct",
    "/sys/fs/cgroup/cpu,cpuacct",
    "/sys/fs/cgroup/memory",
    "/sys/fs/cgroup/devices",
    "/sys/fs/cgroup/freezer",
    "/sys/fs/cgroup/net_cls",
    "/sys/fs/cgroup/blkio",
    "/sys/fs/cgroup/perf_event",
    "/sys/fs/cgroup/hugetlb",
]

mount_cases = [
    {"mount_txt": mount_1,
     "controllers": controllers_1,
     "mount_points": mount_points_1,
     },
    {"mount_txt": mount_2,
     "controllers": controllers_2,
     "mount_points": mount_points_2,
     },
]


class CgroupTest(unittest.TestCase):

    def test_get_cgroup_mountpoint(self):
        for case in mount_cases:
            # Let's work around the fact that NamedTemporaryFile
            # on py 2.4 doesn't have the delete param
            mount_file = tempfile.NamedTemporaryFile()
            mount_file_path = mount_file.name
            mount_file.close()

            # Now let's do our own management of the file
            mount_file = open(mount_file_path, 'w')
            mount_file.write(case["mount_txt"])
            mount_file.close()

            try:
                for idx, controller in enumerate(case["controllers"]):
                    res = utils_cgroup.get_cgroup_mountpoint(
                        controller, mount_file_path)
                    self.assertEqual(case["mount_points"][idx], res)
                self.assertRaises(
                    error.TestError,
                    utils_cgroup.get_cgroup_mountpoint,
                    "non_exit_ctlr",
                    mount_file_path)
            finally:
                os.remove(mount_file_path)

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = utils_conn
"""
connection tools to manage kinds of connection.
"""

import logging
import os
import shutil
import tempfile

from autotest.client import utils, os_dep
from virttest import propcan, remote, utils_libvirtd
from virttest import data_dir, aexpect


class ConnectionError(Exception):

    """
    The base error in connection.
    """
    pass


class ConnForbiddenError(ConnectionError):

    """
    Error in forbidden operation.
    """

    def __init__(self, detail):
        ConnectionError.__init__(self)
        self.detail = detail

    def __str__(self):
        return ('Operation is forbidden.\n'
                'Message: %s' % self.detail)


class ConnCopyError(ConnectionError):

    """
    Error in coping file.
    """

    def __init__(self, src_path, dest_path):
        ConnectionError.__init__(self)
        self.src_path = src_path
        self.dest_path = dest_path

    def __str__(self):
        return ('Copy file from %s to %s failed.'
                % (self.src_path, self.dest_path))


class ConnNotImplementedError(ConnectionError):

    """
    Error in calling unimplemented method
    """

    def __init__(self, method_type, class_type):
        ConnectionError.__init__(self)
        self.method_type = method_type
        self.class_type = class_type

    def __str__(self):
        return ('Method %s is not implemented in class %s\n'
                % (self.method_type, self.class_type))


class ConnLoginError(ConnectionError):

    """
    Error in login.
    """

    def __init__(self, dest, detail):
        ConnectionError.__init__(self)
        self.dest = dest
        self.detail = detail

    def __str__(self):
        return ("Got a error when login to %s.\n"
                "Error: %s\n" % (self.dest, self.detail))


class ConnToolNotFoundError(ConnectionError):

    """
    Error in not found tools.
    """

    def __init__(self, tool, detail):
        ConnectionError.__init__(self)
        self.tool = tool
        self.detail = detail

    def __str__(self):
        return ("Got a error when access the tool (%s).\n"
                "Error: %s\n" % (self.tool, self.detail))


class ConnSCPError(ConnectionError):

    """
    Error in SCP.
    """

    def __init__(self, src_ip, src_path, dest_ip, dest_path, detail):
        ConnectionError.__init__(self)
        self.src_ip = src_ip
        self.src_path = src_path
        self.dest_ip = dest_ip
        self.dest_path = dest_path
        self.detail = detail

    def __str__(self):
        return ("Failed scp from %s on %s to %s on %s.\n"
                "error: %s.\n" %
                (self.src_path, self.src_ip, self.dest_path,
                 self.dest_ip, self.detail))


class SSHCheckError(ConnectionError):

    """
    Base Error in check of SSH connection.
    """

    def __init__(self, server_ip, output):
        ConnectionError.__init__(self)
        self.server_ip = server_ip
        self.output = output

    def __str__(self):
        return ("SSH to %s failed.\n"
                "output: %s " % (self.server_ip, self.output))


class ConnCmdClientError(ConnectionError):

    """
    Error in executing cmd on client.
    """

    def __init__(self, cmd, output):
        ConnectionError.__init__(self)
        self.cmd = cmd
        self.output = output

    def __str__(self):
        return ("Execute command '%s' on client failed.\n"
                "output: %s" % (self.cmd, self.output))


class ConnPrivKeyError(ConnectionError):

    """
    Error in building private key with certtool command.
    """

    def __init__(self, key, output):
        ConnectionError.__init__(self)
        self.key = key
        self.output = output

    def __str__(self):
        return ("Failed to build private key file (%s).\n"
                "output: %s .\n" % (self.key, self.output))


class ConnCertError(ConnectionError):

    """
    Error in building certificate file with certtool command.
    """

    def __init__(self, cert, output):
        ConnectionError.__init__(self)
        self.cert = cert
        self.output = output

    def __str__(self):
        return ("Failed to build certificate file (%s).\n"
                "output: %s .\n" % (self.cert, self.output))


class ConnMkdirError(ConnectionError):

    """
    Error in making directory.
    """

    def __init__(self, directory, output):
        ConnectionError.__init__(self)
        self.directory = directory
        self.output = output

    def __str__(self):
        return ("Failed to make directory %s \n"
                "output: %s.\n" % (self.directory, self.output))


class ConnServerRestartError(ConnectionError):

    """
    Error in restarting libvirtd on server.
    """

    def __init__(self, output):
        ConnectionError.__init__(self)
        self.output = output

    def __str__(self):
        return ("Failed to restart libvirtd service on server.\n"
                "output: %s.\n" % (self.output))


class ConnectionBase(propcan.PropCanBase):

    """
    Base class of a connection between server and client.

    Connection is build to from client to server. And there are
    some information for server and client in ConnectionBase.
    """
    __slots__ = ('server_ip', 'server_user', 'server_pwd',
                 'client_ip', 'client_user', 'client_pwd',
                 'server_session', 'client_session',
                 'tmp_dir', 'auto_recover')

    def __init__(self, *args, **dargs):
        """
        Initialize instance with server info and client info.

        :param server_ip: Ip of server.
        :param server_user: Username to login server.
        :param server_pwd: Password for server_user.
        :param client_ip: IP of client.
        :param client_user: Username to login client.
        :param client_pwd: Password for client_user.
        :param server_session: Session to server and execute command on
                               server.
        :param client_session: Session to client and execute command on
                               client.
        :param tmp_dir: A tmp dir to store some tmp file.
        :param auto_recover: If it is False same as the default,
                             conn_recover() will not called by __del__()
                             If it is True, Connection class will call
                             conn_recover() in __del__(), then user need not
                             call it manully. But the errors in conn_recover()
                             will be ignored.

        Example:

        ::

          connection = ConnectionBase(server_ip=server_ip,
                                      server_user=server_user,
                                      server_pwd=server_pwd,
                                      client_ip=client_ip,
                                      client_user=client_user,
                                      client_pwd=client_pwd)
          connection.conn_setup()
          virsh.connect(URI)
          connection.conn_recover()

        We sugguest *not* to pass auto_recover=True to __init__(),
        and call conn_recover() manually when you don't need this
        connection any more.
        """
        init_dict = dict(*args, **dargs)
        init_dict['server_ip'] = init_dict.get('server_ip', 'SERVER.IP')
        init_dict['server_user'] = init_dict.get('server_user', 'root')
        init_dict['server_pwd'] = init_dict.get('server_pwd', None)
        init_dict['client_ip'] = init_dict.get('client_ip', 'CLIENT.IP')
        init_dict['client_user'] = init_dict.get('client_user', 'root')
        init_dict['client_pwd'] = init_dict.get('client_pwd', None)
        init_dict['auto_recover'] = init_dict.get('auto_recover', False)
        super(ConnectionBase, self).__init__(init_dict)

        self.__dict_set__('client_session', None)
        self.__dict_set__('server_session', None)

        # make a tmp dir as a workspace
        tmp_dir = tempfile.mkdtemp(dir=data_dir.get_tmp_dir())
        if not os.path.isdir(tmp_dir):
            os.makedirs(tmp_dir)
        self.tmp_dir = tmp_dir

    def __del__(self):
        """
        Clean up any leftover sessions and tmp_dir.
        """
        self.close_session()
        if self.auto_recover:
            try:
                self.conn_recover()
            except ConnNotImplementedError:
                pass
        tmp_dir = self.tmp_dir
        if (tmp_dir is not None) and (os.path.exists(tmp_dir)):
            shutil.rmtree(tmp_dir)

    def close_session(self):
        """
        If some session exists, close it down.
        """
        session_list = ['client_session', 'server_session']
        for session_name in session_list:
            session = self.__dict_get__(session_name)
            if session is not None:
                session.close()
            else:
                continue

    def conn_setup(self):
        """
        waiting for implemented by subclass.
        """
        raise ConnNotImplementedError('conn_setup', self.__class__)

    def conn_check(self):
        """
        waiting for implemented by subclass.
        """
        raise ConnNotImplementedError('conn_check', self.__class__)

    def conn_recover(self):
        """
        waiting for implemented by subclass.
        """
        raise ConnNotImplementedError('conn_recover', self.__class__)

    def _new_client_session(self):
        """
        Build a new client session.
        """
        transport = 'ssh'
        host = self.client_ip
        port = 22
        username = self.client_user
        password = self.client_pwd
        prompt = r"[\#\$]\s*$"
        try:
            client_session = remote.wait_for_login(transport, host, port,
                                                   username, password, prompt)
        except remote.LoginTimeoutError:
            raise ConnLoginError("Got a timeout error when login to client.")
        except remote.LoginAuthenticationError:
            raise ConnLoginError("Authentication failed to login to client.")
        except remote.LoginProcessTerminatedError:
            raise ConnLoginError("Host terminates during login to client.")
        except remote.LoginError:
            raise ConnLoginError("Some error occurs login to client failed.")

        return client_session

    def get_client_session(self):
        """
        If the client session exists,return it.
        else create a session to client and set client_session.
        """
        client_session = self.__dict_get__('client_session')

        if (client_session is not None) and (client_session.is_alive()):
            return client_session
        else:
            client_session = self._new_client_session()

        self.__dict_set__('client_session', client_session)
        return client_session

    def set_client_session(self, value):
        """
        Set client session to value.
        """
        if value:
            message = "Forbide to set client_session to %s." % value
        else:
            message = "Forbide to set client_session."

        raise ConnForbiddenError(message)

    def del_client_session(self):
        """
        Delete client session.
        """
        raise ConnForbiddenError('Forbide to del client_session')

    def _new_server_session(self):
        """
        Build a new server session.
        """
        transport = 'ssh'
        host = self.server_ip
        port = 22
        username = self.server_user
        password = self.server_pwd
        prompt = r"[\#\$]\s*$"
        try:
            server_session = remote.wait_for_login(transport, host, port,
                                                   username, password, prompt)
        except remote.LoginTimeoutError:
            raise ConnLoginError("Got a timeout error when login to server.")
        except remote.LoginAuthenticationError:
            raise ConnLoginError("Authentication failed to login to server.")
        except remote.LoginProcessTerminatedError:
            raise ConnLoginError("Host terminates during login to server.")
        except remote.LoginError:
            raise ConnLoginError("Some error occurs login to client server.")

        return server_session

    def get_server_session(self):
        """
        If the server session exists,return it.
        else create a session to server and set server_session.
        """
        server_session = self.__dict_get__('server_session')

        if (server_session is not None) and (server_session.is_alive()):
            return server_session
        else:
            server_session = self._new_server_session()

        self.__dict_set__('server_session', server_session)
        return server_session

    def set_server_session(self, value=None):
        """
        Set server session to value.
        """
        if value:
            message = "Forbide to set server_session to %s." % value
        else:
            message = "Forbide to set server_session."

        raise ConnForbiddenError(message)

    def del_server_session(self):
        """
        Delete server session.
        """
        raise ConnForbiddenError('Forbide to del server_session')


class SSHConnection(ConnectionBase):

    """
    Connection of SSH transport.

    Some specific varaibles in SSHConnection class.

    ssh_rsa_pub_path: Path of id_rsa.pub, default is /root/.ssh/id_rsa.pub.
    ssh_id_rsa_path: Path of id_rsa, default is /root/.ssh/id_rsa.
    SSH_KEYGEN, SSH_ADD, SSH_COPY_ID, SSH_AGENT, SHELL, SSH: tools to build
    a non-pwd connection.
    """
    __slots__ = ('ssh_rsa_pub_path', 'ssh_id_rsa_path', 'SSH_KEYGEN',
                 'SSH_ADD', 'SSH_COPY_ID', 'SSH_AGENT', 'SHELL', 'SSH')

    def __init__(self, *args, **dargs):
        """
        Initialization of SSH connection.

        (1). Call __init__ of class ConnectionBase.
        (2). Initialize tools will be used in conn setup.
        """
        init_dict = dict(*args, **dargs)
        init_dict['ssh_rsa_pub_path'] = init_dict.get('ssh_rsa_pub_path',
                                                      '/root/.ssh/id_rsa.pub')
        init_dict['ssh_id_rsa_path'] = init_dict.get('ssh_id_rsa_path',
                                                     '/root/.ssh/id_rsa')
        super(SSHConnection, self).__init__(init_dict)
        # set the tool for ssh setup.
        tool_dict = {'SSH_KEYGEN': 'ssh-keygen',
                     'SSH_ADD': 'ssh-add',
                     'SSH_COPY_ID': 'ssh-copy-id',
                     'SSH_AGENT': 'ssh-agent',
                     'SHELL': 'sh',
                     'SSH': 'ssh'}

        for key in tool_dict:
            toolName = tool_dict[key]
            try:
                tool = os_dep.command(toolName)
            except ValueError:
                logging.debug("%s executable not set or found on path,"
                              "some function of connection will fail.",
                              toolName)
                tool = '/bin/true'
            self.__dict_set__(key, tool)

    def conn_check(self):
        """
        Check the SSH connection.

        (1).Initialize some variables.
        (2).execute ssh command to check conn.
        """
        client_session = self.client_session
        server_user = self.server_user
        server_ip = self.server_ip
        ssh = self.SSH
        if ssh is '/bin/true':
            raise ConnToolNotFoundError('ssh',
                                        "executable not set or found on path, ")

        cmd = "%s %s@%s exit 0" % (ssh, server_user, server_ip)
        try:
            client_session.cmd(cmd, timeout=5)
        except aexpect.ShellError, detail:
            client_session.close()
            raise SSHCheckError(server_ip, detail)
        logging.debug("Check the SSH to %s OK.", server_ip)

    def conn_recover(self):
        """
        It's ok to ignore finish work for ssh connection.
        """
        pass

    def conn_setup(self):
        """
        Setup of SSH connection.

        (1).Initialization of some variables.
        (2).Check tools.
        (3).Initialization of id_rsa.
        (4).set a ssh_agent.
        (5).copy pub key to server.
        """
        client_session = self.client_session
        ssh_rsa_pub_path = self.ssh_rsa_pub_path
        ssh_id_rsa_path = self.ssh_id_rsa_path
        server_user = self.server_user
        server_ip = self.server_ip
        server_pwd = self.server_pwd
        ssh_keygen = self.SSH_KEYGEN
        ssh_add = self.SSH_ADD
        ssh_copy_id = self.SSH_COPY_ID
        ssh_agent = self.SSH_AGENT
        shell = self.SHELL

        tool_dict = {'ssh_keygen': ssh_keygen,
                     'ssh_add': ssh_add,
                     'ssh_copy_id': ssh_copy_id,
                     'ssh_agent': ssh_agent,
                     'shell': shell}
        for tool_name in tool_dict:
            tool = tool_dict[tool_name]
            if tool is '/bin/true':
                raise ConnToolNotFoundError(tool_name,
                                            "executable not set or found on path,")

        if os.path.exists("/root/.ssh/id_rsa"):
            pass
        else:
            cmd = "%s -t rsa -f /root/.ssh/id_rsa -N '' " % (ssh_keygen)
            status, output = client_session.cmd_status_output(cmd)
            if status:
                raise ConnCmdClientError(cmd, output)

        cmd = "%s %s" % (ssh_agent, shell)
        status, output = client_session.cmd_status_output(cmd)
        if status:
            raise ConnCmdClientError(cmd, output)

        cmd = "%s %s" % (ssh_add, ssh_id_rsa_path)
        status, output = client_session.cmd_status_output(cmd)
        if status:
            raise ConnCmdClientError(cmd, output)

        cmd = "%s -i %s %s@%s" % (ssh_copy_id, ssh_rsa_pub_path,
                                  server_user, server_ip)
        client_session.sendline(cmd)
        try:
            remote.handle_prompts(client_session, server_user,
                                  server_pwd, prompt=r"[\#\$]\s*$")
        except remote.LoginError, detail:
            raise ConnCmdClientError(cmd, detail)

        client_session.close()
        logging.debug("SSH connection setup successfully.")


class TCPConnection(ConnectionBase):

    """
    Connection class for TCP transport.

    Some specific varaibles for TCPConnection class.
    """
    __slots__ = ('tcp_port', 'remote_syslibvirtd', 'remote_libvirtdconf')

    def __init__(self, *args, **dargs):
        """
        init params for TCP connection and init tmp_dir.

        param tcp_port: Port of tcp connection, default is 16509.
        param sysconfig_libvirtd_path: Path of libvirtd file, default is
                                       ``/etc/sysconfig/libvirtd``.
        param libvirtd_conf_path: Path of libvirtd.conf, default is
                                  ``/etc/libvirt/libvirtd.conf``.
        """
        init_dict = dict(*args, **dargs)
        init_dict['tcp_port'] = init_dict.get('tcp_port', '16509')
        super(TCPConnection, self).__init__(init_dict)

        self.remote_syslibvirtd = remote.RemoteFile(
            address=self.server_ip,
            client='scp',
            username=self.server_user,
            password=self.server_pwd,
            port='22',
            remote_path='/etc/sysconfig/libvirtd')

        self.remote_libvirtdconf = remote.RemoteFile(
            address=self.server_ip,
            client='scp',
            username=self.server_user,
            password=self.server_pwd,
            port='22',
            remote_path='/etc/libvirt/libvirtd.conf')

    def conn_recover(self):
        """
        Clean up for TCP connection.

        (1).initialize variables.
        (2).Delete the RemoteFile.
        (3).restart libvirtd on server.
        """
        # initialize variables
        server_ip = self.server_ip
        server_user = self.server_user
        server_pwd = self.server_pwd
        # delete the RemoteFile object to recover remote file.
        del self.remote_syslibvirtd
        del self.remote_libvirtdconf
        # restart libvirtd service on server
        try:
            session = remote.wait_for_login('ssh', server_ip, '22',
                                            server_user, server_pwd,
                                            r"[\#\$]\s*$")
            libvirtd_service = utils_libvirtd.Libvirtd(session=session)
            libvirtd_service.restart()
        except (remote.LoginError, aexpect.ShellError), detail:
            raise ConnServerRestartError(detail)

        logging.debug("TCP connection recover successfully.")

    def conn_setup(self):
        """
        Enable tcp connect of libvirtd on server.

        (1).initialization for variables.
        (2).edit /etc/sysconfig/libvirtd on server.
        (3).edit /etc/libvirt/libvirtd.conf on server.
        (4).restart libvirtd service on server.
        """
        # initialize variables
        server_ip = self.server_ip
        server_user = self.server_user
        server_pwd = self.server_pwd
        tcp_port = self.tcp_port

        # edit the /etc/sysconfig/libvirtd to add --listen args in libvirtd
        pattern2repl = {r".*LIBVIRTD_ARGS\s*=\s*\"\s*--listen\s*\".*":
                        "LIBVIRTD_ARGS=\"--listen\""}
        self.remote_syslibvirtd.sub_else_add(pattern2repl)

        # edit the /etc/libvirt/libvirtd.conf
        # listen_tcp=1, tcp_port=$tcp_port, auth_tcp="none"
        pattern2repl = {r".*listen_tls\s*=.*": 'listen_tls=0',
                        r".*listen_tcp\s*=.*": 'listen_tcp=1',
                        r".*tcp_port\s*=.*": 'tcp_port="%s"' % (tcp_port),
                        r'.*auth_tcp\s*=.*': 'auth_tcp="none"'}
        self.remote_libvirtdconf.sub_else_add(pattern2repl)

        # restart libvirtd service on server
        try:
            session = remote.wait_for_login('ssh', server_ip, '22',
                                            server_user, server_pwd,
                                            r"[\#\$]\s*$")
            libvirtd_service = utils_libvirtd.Libvirtd(session=session)
            libvirtd_service.restart()
        except (remote.LoginError, aexpect.ShellError), detail:
            raise ConnServerRestartError(detail)

        logging.debug("TCP connection setup successfully.")


class TLSConnection(ConnectionBase):

    """
    Connection of TLS transport.

    Some specific varaibles for TLSConnection class.

    server_cn, client_cn: Info to build pki key.
    CERTOOL: tool to build key for TLS connection.
    pki_CA_dir: Dir to store CA key.
    libvirt_pki_dir, libvirt_pki_private_dir: Dir to store pki in libvirt.
    sysconfig_libvirtd_path, libvirtd_conf_path: Path of libvirt config file.
    hosts_path: /etc/hosts
    """
    __slots__ = ('server_cn', 'client_cn', 'CERTTOOL', 'pki_CA_dir',
                 'libvirt_pki_dir', 'libvirt_pki_private_dir', 'client_hosts',
                 'server_libvirtdconf', 'server_syslibvirtd')

    def __init__(self, *args, **dargs):
        """
        Initialization of TLSConnection.

        (1).call the init func in ConnectionBase.
        (2).check and set CERTTOOL.
        (3).make a tmp directory as a workspace.
        (4).set values of pki related.
        """
        init_dict = dict(*args, **dargs)
        init_dict['server_cn'] = init_dict.get('server_cn', 'TLSServer')
        init_dict['client_cn'] = init_dict.get('client_cn', 'TLSClient')
        super(TLSConnection, self).__init__(init_dict)
        # check and set CERTTOOL in slots
        try:
            CERTTOOL = os_dep.command("certtool")
        except ValueError:
            logging.warning("certtool executable not set or found on path, "
                            "TLS connection will not setup normally")
            CERTTOOL = '/bin/true'
        self.CERTTOOL = CERTTOOL
        # set some pki related dir values
        self.pki_CA_dir = ('/etc/pki/CA/')
        self.libvirt_pki_dir = ('/etc/pki/libvirt/')
        self.libvirt_pki_private_dir = ('/etc/pki/libvirt/private/')

        self.client_hosts = remote.RemoteFile(address=self.client_ip,
                                              client='scp',
                                              username=self.client_user,
                                              password=self.client_pwd,
                                              port='22',
                                              remote_path='/etc/hosts')

        self.server_syslibvirtd = remote.RemoteFile(
            address=self.server_ip,
            client='scp',
            username=self.server_user,
            password=self.server_pwd,
            port='22',
            remote_path='/etc/sysconfig/libvirtd')

        self.server_libvirtdconf = remote.RemoteFile(
            address=self.server_ip,
            client='scp',
            username=self.server_user,
            password=self.server_pwd,
            port='22',
            remote_path='/etc/libvirt/libvirtd.conf')

    def conn_recover(self):
        """
        Do the clean up work.

        (1).initialize variables.
        (2).Delete remote file.
        (3).Restart libvirtd on server.
        """
        # initialize variables
        server_ip = self.server_ip
        server_user = self.server_user
        server_pwd = self.server_pwd

        del self.client_hosts
        del self.server_syslibvirtd
        del self.server_libvirtdconf
        # restart libvirtd service on server
        try:
            session = remote.wait_for_login('ssh', server_ip, '22',
                                            server_user, server_pwd,
                                            r"[\#\$]\s*$")
            libvirtd_service = utils_libvirtd.Libvirtd(session=session)
            libvirtd_service.restart()
        except (remote.LoginError, aexpect.ShellError), detail:
            raise ConnServerRestartError(detail)
        logging.debug("TLS connection recover successfully.")

    def conn_setup(self):
        """
        setup a TLS connection between server and client.
        At first check the certtool needed to setup.
        Then call some setup functions to complete connection setup.
        """
        if self.CERTTOOL == '/bin/true':
            raise ConnToolNotFoundError('certtool',
                                        "certtool executable not set or found on path.")

        build_CA(self.tmp_dir, self.CERTTOOL)
        self.server_setup()
        self.client_setup()

        logging.debug("TLS connection setup successfully.")

    def server_setup(self):
        """
        setup private key and certificate file for server.

        (1).initialization for variables.
        (2).build server key.
        (3).copy files to server.
        (4).edit /etc/sysconfig/libvirtd on server.
        (5).edit /etc/libvirt/libvirtd.conf on server.
        (6).restart libvirtd service on server.
        """
        # initialize variables
        tmp_dir = self.tmp_dir
        cacert_path = '%s/cacert.pem' % tmp_dir
        serverkey_path = '%s/serverkey.pem' % tmp_dir
        servercert_path = '%s/servercert.pem' % tmp_dir
        server_ip = self.server_ip
        server_user = self.server_user
        server_pwd = self.server_pwd

        # build a server key.
        build_server_key(tmp_dir, self.server_cn, self.CERTTOOL)

        # scp cacert.pem, servercert.pem and serverkey.pem to server.
        server_session = self.server_session
        cmd = "mkdir -p %s" % self.libvirt_pki_private_dir
        status, output = server_session.cmd_status_output(cmd)
        if status:
            raise ConnMkdirError(self.libvirt_pki_private_dir, output)

        scp_dict = {cacert_path: self.pki_CA_dir,
                    servercert_path: self.libvirt_pki_dir,
                    serverkey_path: self.libvirt_pki_private_dir}

        for key in scp_dict:
            local_path = key
            remote_path = scp_dict[key]
            try:
                remote.copy_files_to(server_ip, 'scp', server_user,
                                     server_pwd, '22', local_path, remote_path)
            except remote.SCPError, detail:
                raise ConnSCPError('AdminHost', local_path,
                                   server_ip, remote_path, detail)

        # edit the /etc/sysconfig/libvirtd to add --listen args in libvirtd
        pattern2repl = {r".*LIBVIRTD_ARGS\s*=\s*\"\s*--listen\s*\".*":
                        "LIBVIRTD_ARGS=\"--listen\""}
        self.server_syslibvirtd.sub_else_add(pattern2repl)

        # edit the /etc/libvirt/libvirtd.conf to add listen_tls=1
        pattern2repl = {r".*listen_tls\s*=\s*.*": "listen_tls=1"}
        self.server_libvirtdconf.sub_else_add(pattern2repl)

        # restart libvirtd service on server
        try:
            session = remote.wait_for_login('ssh', server_ip, '22',
                                            server_user, server_pwd,
                                            r"[\#\$]\s*$")
            libvirtd_service = utils_libvirtd.Libvirtd(session=session)
            libvirtd_service.restart()
        except (remote.LoginError, aexpect.ShellError), detail:
            raise ConnServerRestartError(detail)

    def client_setup(self):
        """
        setup private key and certificate file for client.

        (1).initialization for variables.
        (2).build a key for client.
        (3).copy files to client.
        (4).edit /etc/hosts on client.
        """
        # initialize variables
        tmp_dir = self.tmp_dir
        cacert_path = '%s/cacert.pem' % tmp_dir
        clientkey_path = '%s/clientkey.pem' % tmp_dir
        clientcert_path = '%s/clientcert.pem' % tmp_dir
        client_ip = self.client_ip
        client_user = self.client_user
        client_pwd = self.client_pwd

        # build a client key.
        build_client_key(tmp_dir, self.client_cn, self.CERTTOOL)

        # scp cacert.pem, clientcert.pem and clientkey.pem to client.
        client_session = self.client_session
        cmd = "mkdir -p %s" % self.libvirt_pki_private_dir
        status, output = client_session.cmd_status_output(cmd)
        if status:
            raise ConnMkdirError(self.libvirt_pki_private_dir, output)

        scp_dict = {cacert_path: self.pki_CA_dir,
                    clientcert_path: self.libvirt_pki_dir,
                    clientkey_path: self.libvirt_pki_private_dir}

        for key in scp_dict:
            local_path = key
            remote_path = scp_dict[key]
            try:
                remote.copy_files_to(client_ip, 'scp', client_user,
                                     client_pwd, '22', local_path, remote_path)
            except remote.SCPError, detail:
                raise ConnSCPError('AdminHost', local_path,
                                   client_ip, remote_path, detail)

        # edit /etc/hosts on client
        pattern2repl = {r".*%s.*" % self.server_cn:
                        "%s %s" % (self.server_ip, self.server_cn)}
        self.client_hosts.sub_else_add(pattern2repl)


def build_client_key(tmp_dir, client_cn="TLSClient", certtool="certtool"):
    """
    (1).initialization for variables.
    (2).make a private key with certtool command.
    (3).prepare a info file.
    (4).make a certificate file with certtool command.
    """
    # Initialize variables
    cakey_path = '%s/tcakey.pem' % tmp_dir
    cacert_path = '%s/cacert.pem' % tmp_dir
    clientkey_path = '%s/clientkey.pem' % tmp_dir
    clientcert_path = '%s/clientcert.pem' % tmp_dir
    clientinfo_path = '%s/client.info' % tmp_dir

    # make a private key.
    cmd = "%s --generate-privkey > %s" % (certtool, clientkey_path)
    CmdResult = utils.run(cmd, ignore_status=True)
    if CmdResult.exit_status:
        raise ConnPrivKeyError(CmdResult.stderr)

    # prepare a info file to build clientcert.
    clientinfo_file = open(clientinfo_path, "w")
    clientinfo_file.write("organization = AUTOTEST.VIRT\n")
    clientinfo_file.write("cn = %s\n" % (client_cn))
    clientinfo_file.write("tls_www_client\n")
    clientinfo_file.write("encryption_key\n")
    clientinfo_file.write("signing_key\n")
    clientinfo_file.close()

    # make a client certificate file and a client key file.
    cmd = ("%s --generate-certificate --load-privkey %s \
           --load-ca-certificate %s --load-ca-privkey %s \
           --template %s --outfile %s" %
           (certtool, clientkey_path, cacert_path,
            cakey_path, clientinfo_path, clientcert_path))
    CmdResult = utils.run(cmd, ignore_status=True)
    if CmdResult.exit_status:
        raise ConnCertError(clientinfo_path, CmdResult.stderr)


def build_server_key(tmp_dir, server_cn="TLSServer", certtool="certtool"):
    """
    (1).initialization for variables.
    (2).make a private key with certtool command.
    (3).prepare a info file.
    (4).make a certificate file with certtool command.
    """
    # initialize variables
    cakey_path = '%s/tcakey.pem' % tmp_dir
    cacert_path = '%s/cacert.pem' % tmp_dir
    serverkey_path = '%s/serverkey.pem' % tmp_dir
    servercert_path = '%s/servercert.pem' % tmp_dir
    serverinfo_path = '%s/server.info' % tmp_dir

    # make a private key
    cmd = "%s --generate-privkey > %s" % (certtool, serverkey_path)
    cmd_result = utils.run(cmd, ignore_status=True)
    if cmd_result.exit_status:
        raise ConnPrivKeyError(serverkey_path, cmd_result.stderr)

    # prepare a info file to build servercert and serverkey
    serverinfo_file = open(serverinfo_path, "w")
    serverinfo_file.write("organization = AUTOTEST.VIRT\n")
    serverinfo_file.write("cn = %s\n" % (server_cn))
    serverinfo_file.write("tls_www_server\n")
    serverinfo_file.write("encryption_key\n")
    serverinfo_file.write("signing_key\n")
    serverinfo_file.close()

    # make a server certificate file and a server key file
    cmd = ("%s --generate-certificate --load-privkey %s \
           --load-ca-certificate %s --load-ca-privkey %s \
           --template %s --outfile %s" %
           (certtool, serverkey_path, cacert_path,
            cakey_path, serverinfo_path, servercert_path))
    CmdResult = utils.run(cmd, ignore_status=True)
    if CmdResult.exit_status:
        raise ConnCertError(serverinfo_path, CmdResult.stderr)


def build_CA(tmp_dir, certtool="certtool"):
    """
    setup private key and certificate file which are needed to build.
    certificate file for client and server.

    (1).initialization for variables.
    (2).make a private key with certtool command.
    (3).prepare a info file.
    (4).make a certificate file with certtool command.
    """
    # initialize variables
    cakey_path = '%s/tcakey.pem' % tmp_dir
    cainfo_path = '%s/ca.info' % tmp_dir
    cacert_path = '%s/cacert.pem' % tmp_dir

    # make a private key
    cmd = "%s --generate-privkey > %s " % (certtool, cakey_path)
    cmd_result = utils.run(cmd, ignore_status=True, timeout=10)
    if cmd_result.exit_status:
        raise ConnPrivKeyError(cakey_path, cmd_result.stderr)
    # prepare a info file to build certificate file
    cainfo_file = open(cainfo_path, "w")
    cainfo_file.write("cn = AUTOTEST.VIRT\n")
    cainfo_file.write("ca\n")
    cainfo_file.write("cert_signing_key\n")
    cainfo_file.close()

    # make a certificate file to build clientcert and servercert
    cmd = ("%s --generate-self-signed --load-privkey %s\
           --template %s --outfile %s" %
           (certtool, cakey_path, cainfo_path, cacert_path))
    CmdResult = utils.run(cmd, ignore_status=True)
    if CmdResult.exit_status:
        raise ConnCertError(cainfo_path, CmdResult.stderr)

########NEW FILE########
__FILENAME__ = utils_disk
"""
Virtualization test - Virtual disk related utility functions

:copyright: Red Hat Inc.
"""
import os
import glob
import shutil
import tempfile
import logging
import ConfigParser
import re
from autotest.client import utils
from autotest.client.shared import error


# Whether to print all shell commands called
DEBUG = False


def copytree(src, dst, overwrite=True, ignore=''):
    """
    Copy dirs from source to target.

    :param src: source directory
    :param dst: destination directory
    :param overwrite: overwrite file if exist or not
    :param ignore: files want to ignore
    """
    ignore = glob.glob(os.path.join(src, ignore))
    for root, dirs, files in os.walk(src):
        dst_dir = root.replace(src, dst)
        if not os.path.exists(dst_dir):
            os.makedirs(dst_dir)
        for _ in files:
            if _ in ignore:
                continue
            src_file = os.path.join(root, _)
            dst_file = os.path.join(dst_dir, _)
            if os.path.exists(dst_file):
                if overwrite:
                    os.remove(dst_file)
                else:
                    continue
            shutil.copy(src_file, dst_dir)


def is_mount(src, dst):
    """
    Check is src or dst mounted.

    :param src: source device or directory, if None will skip to check
    :param dst: mountpoint, if None will skip to check

    :return: if mounted mountpoint or device, else return False
    """
    if dst and os.path.ismount(dst):
        return dst
    if src and (src in str(open('/proc/mounts', 'r')) or
                src in utils.system_output('losetup -a')):
        return src
    return False


def mount(src, dst, fstype=None, options=None, verbose=False):
    """
    Mount src under dst if it's really mounted, then remout with options.

    :param src: source device or directory, if None will skip to check
    :param dst: mountpoint, if None will skip to check
    :param fstype: filesystem type need to mount

    :return: if mounted return True else return False
    """
    options = (options and [options] or [''])[0]
    if is_mount(src, dst):
        if 'remount' not in options:
            options = 'remount,%s' % options
    cmd = ['mount']
    if fstype:
        cmd.extend(['-t', fstype])
    if options:
        cmd.extend(['-o', options])
    cmd.extend([src, dst])
    cmd = ' '.join(cmd)
    return utils.system(cmd, verbose=verbose) == 0


def umount(src, dst, verbose=False):
    """
    Umount src from dst, if src really mounted under dst.

    :param src: source device or directory, if None will skip to check
    :param dst: mountpoint, if None will skip to check

    :return: if unmounted return True else return False
    """
    mounted = is_mount(src, dst)
    if mounted:
        fuser_cmd = "fuser -km %s" % mounted
        utils.system(fuser_cmd, ignore_status=True, verbose=True)
        umount_cmd = "umount %s" % mounted
        return utils.system(umount_cmd, ignore_status=True, verbose=True) == 0
    return True


@error.context_aware
def cleanup(folder):
    """
    If folder is a mountpoint, do what is possible to unmount it. Afterwards,
    try to remove it.

    :param folder: Directory to be cleaned up.
    """
    error.context("cleaning up unattended install directory %s" % folder)
    umount(None, folder)
    if os.path.isdir(folder):
        shutil.rmtree(folder)


@error.context_aware
def clean_old_image(image):
    """
    Clean a leftover image file from previous processes. If it contains a
    mounted file system, do the proper cleanup procedures.

    :param image: Path to image to be cleaned up.
    """
    error.context("cleaning up old leftover image %s" % image)
    if os.path.exists(image):
        umount(image, None)
        os.remove(image)


class Disk(object):

    """
    Abstract class for Disk objects, with the common methods implemented.
    """

    def __init__(self):
        self.path = None

    def get_answer_file_path(self, filename):
        return os.path.join(self.mount, filename)

    def copy_to(self, src):
        logging.debug("Copying %s to disk image mount", src)
        dst = os.path.join(self.mount, os.path.basename(src))
        if os.path.isdir(src):
            shutil.copytree(src, dst)
        elif os.path.isfile(src):
            shutil.copyfile(src, dst)

    def close(self):
        os.chmod(self.path, 0755)
        cleanup(self.mount)
        logging.debug("Disk %s successfully set", self.path)


class FloppyDisk(Disk):

    """
    Represents a floppy disk. We can copy files to it, and setup it in
    convenient ways.
    """
    @error.context_aware
    def __init__(self, path, qemu_img_binary, tmpdir, vfd_size):
        error.context("Creating unattended install floppy image %s" % path)
        self.mount = tempfile.mkdtemp(prefix='floppy_virttest_', dir=tmpdir)
        self.path = path
        self.vfd_size = vfd_size
        clean_old_image(path)
        try:
            c_cmd = '%s create -f raw %s %s' % (qemu_img_binary, path,
                                                self.vfd_size)
            utils.run(c_cmd, verbose=DEBUG)
            f_cmd = 'mkfs.msdos -s 1 %s' % path
            utils.run(f_cmd, verbose=DEBUG)
        except error.CmdError, e:
            logging.error("Error during floppy initialization: %s" % e)
            cleanup(self.mount)
            raise

    def close(self):
        """
        Copy everything that is in the mountpoint to the floppy.
        """
        pwd = os.getcwd()
        try:
            os.chdir(self.mount)
            path_list = glob.glob('*')
            for path in path_list:
                self.copy_to(path)
        finally:
            os.chdir(pwd)

        cleanup(self.mount)

    def copy_to(self, src):
        logging.debug("Copying %s to floppy image", src)
        mcopy_cmd = "mcopy -s -o -n -i %s %s ::/" % (self.path, src)
        utils.run(mcopy_cmd, verbose=DEBUG)

    def _copy_virtio_drivers(self, virtio_floppy):
        """
        Copy the virtio drivers on the virtio floppy to the install floppy.

        1) Mount the floppy containing the viostor drivers
        2) Copy its contents to the root of the install floppy
        """
        pwd = os.getcwd()
        try:
            m_cmd = 'mcopy -s -o -n -i %s ::/* %s' % (
                virtio_floppy, self.mount)
            utils.run(m_cmd, verbose=DEBUG)
        finally:
            os.chdir(pwd)

    def setup_virtio_win2003(self, virtio_floppy, virtio_oemsetup_id):
        """
        Setup the install floppy with the virtio storage drivers, win2003 style.

        Win2003 and WinXP depend on the file txtsetup.oem file to install
        the virtio drivers from the floppy, which is a .ini file.
        Process:

        1) Copy the virtio drivers on the virtio floppy to the install floppy
        2) Parse the ini file with config parser
        3) Modify the identifier of the default session that is going to be
           executed on the config parser object
        4) Re-write the config file to the disk
        """
        self._copy_virtio_drivers(virtio_floppy)
        txtsetup_oem = os.path.join(self.mount, 'txtsetup.oem')

        if not os.path.isfile(txtsetup_oem):
            raise IOError('File txtsetup.oem not found on the install '
                          'floppy. Please verify if your floppy virtio '
                          'driver image has this file')

        parser = ConfigParser.ConfigParser()
        parser.read(txtsetup_oem)

        if not parser.has_section('Defaults'):
            raise ValueError('File txtsetup.oem does not have the session '
                             '"Defaults". Please check txtsetup.oem')

        default_driver = parser.get('Defaults', 'SCSI')
        if default_driver != virtio_oemsetup_id:
            parser.set('Defaults', 'SCSI', virtio_oemsetup_id)
            fp = open(txtsetup_oem, 'w')
            parser.write(fp)
            fp.close()

    def setup_virtio_win2008(self, virtio_floppy):
        """
        Setup the install floppy with the virtio storage drivers, win2008 style.

        Win2008, Vista and 7 require people to point out the path to the drivers
        on the unattended file, so we just need to copy the drivers to the
        driver floppy disk. Important to note that it's possible to specify
        drivers from a CDROM, so the floppy driver copy is optional.
        Process:

        1) Copy the virtio drivers on the virtio floppy to the install floppy,
           if there is one available
        """
        if os.path.isfile(virtio_floppy):
            self._copy_virtio_drivers(virtio_floppy)
        else:
            logging.debug(
                "No virtio floppy present, not needed for this OS anyway")


class CdromDisk(Disk):

    """
    Represents a CDROM disk that we can master according to our needs.
    """

    def __init__(self, path, tmpdir):
        self.mount = tempfile.mkdtemp(prefix='cdrom_virttest_', dir=tmpdir)
        self.tmpdir = tmpdir
        self.path = path
        clean_old_image(path)
        if not os.path.isdir(os.path.dirname(path)):
            os.makedirs(os.path.dirname(path))

    def _copy_virtio_drivers(self, virtio_floppy, cdrom_virtio):
        """
        Copy the virtio drivers from floppy and cdrom to install cdrom.

        1) Mount the floppy and cdrom containing the virtio drivers
        2) Copy its contents to the root of the install cdrom
        """
        pwd = os.getcwd()
        mnt_pnt = tempfile.mkdtemp(prefix='cdrom_virtio_', dir=self.tmpdir)
        mount(cdrom_virtio, mnt_pnt, options='loop,ro', verbose=DEBUG)
        try:
            copytree(mnt_pnt, self.mount, ignore='*.vfd')
            cmd = 'mcopy -s -o -n -i %s ::/* %s' % (virtio_floppy, self.mount)
            utils.run(cmd, verbose=DEBUG)
        finally:
            os.chdir(pwd)
            umount(None, mnt_pnt, verbose=DEBUG)
            os.rmdir(mnt_pnt)

    def setup_virtio_win2008(self, virtio_floppy, cdrom_virtio):
        """
        Setup the install cdrom with the virtio storage drivers, win2008 style.

        Win2008, Vista and 7 require people to point out the path to the drivers
        on the unattended file, so we just need to copy the drivers to the
        extra cdrom disk. Important to note that it's possible to specify
        drivers from a CDROM, so the floppy driver copy is optional.
        Process:

        1) Copy the virtio drivers on the virtio floppy to the install cdrom,
           if there is one available
        """
        if os.path.isfile(virtio_floppy):
            self._copy_virtio_drivers(virtio_floppy, cdrom_virtio)
        else:
            logging.debug(
                "No virtio floppy present, not needed for this OS anyway")

    @error.context_aware
    def close(self):
        error.context("Creating unattended install CD image %s" % self.path)
        g_cmd = ('mkisofs -o %s -max-iso9660-filenames '
                 '-relaxed-filenames -D --input-charset iso8859-1 '
                 '%s' % (self.path, self.mount))
        utils.run(g_cmd, verbose=DEBUG)

        os.chmod(self.path, 0755)
        cleanup(self.mount)
        logging.debug("unattended install CD image %s successfully created",
                      self.path)


class CdromInstallDisk(Disk):

    """
    Represents a install CDROM disk that we can master according to our needs.
    """

    def __init__(self, path, tmpdir, source_cdrom, extra_params):
        self.mount = tempfile.mkdtemp(prefix='cdrom_unattended_', dir=tmpdir)
        self.path = path
        self.extra_params = extra_params
        self.source_cdrom = source_cdrom
        cleanup(path)
        if not os.path.isdir(os.path.dirname(path)):
            os.makedirs(os.path.dirname(path))
        cp_cmd = ('cp -r %s/isolinux/ %s/' % (source_cdrom, self.mount))
        listdir = os.listdir(self.source_cdrom)
        for i in listdir:
            if i == 'isolinux':
                continue
            os.symlink(os.path.join(self.source_cdrom, i),
                       os.path.join(self.mount, i))
        utils.run(cp_cmd)

    def get_answer_file_path(self, filename):
        return os.path.join(self.mount, 'isolinux', filename)

    @error.context_aware
    def close(self):
        error.context("Creating unattended install CD image %s" % self.path)
        f = open(os.path.join(self.mount, 'isolinux', 'isolinux.cfg'), 'w')
        f.write('default /isolinux/vmlinuz append initrd=/isolinux/initrd.img '
                '%s\n' % self.extra_params)
        f.close()
        m_cmd = ('mkisofs -o %s -b isolinux/isolinux.bin -c isolinux/boot.cat '
                 '-no-emul-boot -boot-load-size 4 -boot-info-table -f -R -J '
                 '-V -T %s' % (self.path, self.mount))
        utils.run(m_cmd)
        os.chmod(self.path, 0755)
        cleanup(self.mount)
        cleanup(self.source_cdrom)
        logging.debug("unattended install CD image %s successfully created",
                      self.path)


class GuestFSModiDisk(object):

    """
    class of guest disk using guestfs lib to do some operation(like read/write)
    on guest disk:
    """

    def __init__(self, disk):
        try:
            import guestfs
        except ImportError:
            install_cmd = "yum -y install python-libguestfs"
            try:
                utils.run(install_cmd)
                import guestfs
            except Exception:
                raise error.TestNAError('We need python-libguestfs (or the '
                                        'equivalent for your distro) for this '
                                        'particular feature (modifying guest '
                                        'files with libguestfs)')

        self.g = guestfs.GuestFS()
        self.disk = disk
        self.g.add_drive(disk)
        logging.debug("Launch the disk %s, wait..." % self.disk)
        self.g.launch()

    def os_inspects(self):
        self.roots = self.g.inspect_os()
        if self.roots:
            return self.roots
        else:
            return None

    def mounts(self):
        return self.g.mounts()

    def mount_all(self):
        def compare(a, b):
            if len(a[0]) > len(b[0]):
                return 1
            elif len(a[0]) == len(b[0]):
                return 0
            else:
                return -1

        roots = self.os_inspects()
        if roots:
            for root in roots:
                mps = self.g.inspect_get_mountpoints(root)
                mps.sort(compare)
                for mp_dev in mps:
                    try:
                        msg = "Mount dev '%s' partitions '%s' to '%s'"
                        logging.info(msg % (root, mp_dev[1], mp_dev[0]))
                        self.g.mount(mp_dev[1], mp_dev[0])
                    except RuntimeError, err_msg:
                        logging.info("%s (ignored)" % err_msg)
        else:
            raise error.TestError("inspect_vm: no operating systems found")

    def umount_all(self):
        logging.debug("Umount all device partitions")
        if self.mounts():
            self.g.umount_all()

    def read_file(self, file_name):
        """
        read file from the guest disk, return the content of the file

        :param file_name: the file you want to read.
        """

        try:
            self.mount_all()
            o = self.g.cat(file_name)
            if o:
                return o
            else:
                err_msg = "Can't read file '%s', check is it exist?"
                raise error.TestError(err_msg % file_name)
        finally:
            self.umount_all()

    def write_to_image_file(self, file_name, content, w_append=False):
        """
        Write content to the file on the guest disk.

        When using this method all the original content will be overriding.
        if you don't hope your original data be override set ``w_append=True``.

        :param file_name: the file you want to write
        :param content: the content you want to write.
        :param w_append: append the content or override
        """

        try:
            try:
                self.mount_all()
                if w_append:
                    self.g.write_append(file_name, content)
                else:
                    self.g.write(file_name, content)
            except Exception:
                raise error.TestError("write '%s' to file '%s' error!"
                                      % (content, file_name))
        finally:
            self.umount_all()

    def replace_image_file_content(self, file_name, find_con, rep_con):
        """
        replace file content matchs in the file with rep_con.
        suport using Regular expression

        :param file_name: the file you want to replace
        :param find_con: the orign content you want to replace.
        :param rep_con: the replace content you want.
        """

        try:
            self.mount_all()
            file_content = self.g.cat(file_name)
            if file_content:
                file_content_after_replace = re.sub(find_con, rep_con,
                                                    file_content)
                if file_content != file_content_after_replace:
                    self.g.write(file_name, file_content_after_replace)
            else:
                err_msg = "Can't read file '%s', check is it exist?"
                raise error.TestError(err_msg % file_name)
        finally:
            self.umount_all()

########NEW FILE########
__FILENAME__ = utils_env
import cPickle
import UserDict
import os
import logging
import re
import time

import utils_misc
import virt_vm
import aexpect
import remote
import threading

ENV_VERSION = 1


def get_env_version():
    return ENV_VERSION


class EnvSaveError(Exception):
    pass


def lock_safe(function):
    """
    Get the environment safe lock, run the function, then release the lock.

    Unfortunately, it only works if the 1st argument of the function is an
    Env instance. This is mostly to save up code.

    :param function: Function to wrap.
    """
    def wrapper(*args, **kwargs):
        env = args[0]
        env.save_lock.acquire()
        try:
            return function(*args, **kwargs)
        finally:
            env.save_lock.release()
    wrapper.__name__ = function.__name__
    wrapper.__doc__ = function.__doc__
    wrapper.__dict__.update(function.__dict__)
    return wrapper


@lock_safe
def _update_address_cache(env, line):
    if re.search("Your.IP", line, re.IGNORECASE):
        matches = re.findall(r"\d*\.\d*\.\d*\.\d*", line)
        if matches:
            env["address_cache"]["last_seen"] = matches[0]

    if re.search("Client.Ethernet.Address", line, re.IGNORECASE):
        matches = re.findall(r"\w*:\w*:\w*:\w*:\w*:\w*", line)
        if matches and env["address_cache"].get("last_seen"):
            mac_address = matches[0].lower()
            last_time = env["address_cache"].get("time_%s" % mac_address, 0)
            last_ip = env["address_cache"].get("last_seen")
            cached_ip = env["address_cache"].get(mac_address)

            if (time.time() - last_time > 5 or cached_ip != last_ip):
                logging.debug("(address cache) DHCP lease OK: %s --> %s",
                              mac_address, env["address_cache"].get("last_seen"))

            env["address_cache"][mac_address] = env["address_cache"].get("last_seen")
            env["address_cache"]["time_%s" % mac_address] = time.time()
            del env["address_cache"]["last_seen"]
        elif matches:
            env["address_cache"]["last_seen_mac"] = matches[0]

    if re.search("Requested.IP", line, re.IGNORECASE):
        matches = matches = re.findall(r"\d*\.\d*\.\d*\.\d*", line)
        if matches and env["address_cache"].get("last_seen_mac"):
            ip_address = matches[0]
            mac_address = env["address_cache"].get("last_seen_mac")
            last_time = env["address_cache"].get("time_%s" % mac_address, 0)

            if time.time() - last_time > 10:
                logging.debug("(address cache) DHCP lease OK: %s --> %s",
                              mac_address, ip_address)

            env["address_cache"][mac_address] = ip_address
            env["address_cache"]["time_%s" % mac_address] = time.time()
            del env["address_cache"]["last_seen_mac"]

    # ipv6 address cache:
    mac_ipv6_reg = r"client-ID.*?([0-9a-fA-F]{12})\).*IA_ADDR (.*) pltime"
    if re.search("dhcp6 (request|renew|confirm)", line, re.IGNORECASE):
        matches = re.search(mac_ipv6_reg, line, re.I)
        if matches:
            ipinfo = matches.groups()
            mac_address = ":".join(re.findall("..", ipinfo[0])).lower()
            request_ip = ipinfo[1].lower()
            logging.debug("(address cache) DHCPV6 lease OK: %s --> %s",
                          mac_address, request_ip)
            env["address_cache"]["%s_6" % mac_address] = request_ip

    if re.search("dhcp6 (reply|advertise)", line, re.IGNORECASE):
        ipv6_mac_reg = "IA_ADDR (.*) pltime.*client-ID.*?([0-9a-fA-F]{12})\)"
        matches = re.search(ipv6_mac_reg, line, re.I)
        if matches:
            ipinfo = matches.groups()
            mac_address = ":".join(re.findall("..", ipinfo[1])).lower()
            allocate_ip = ipinfo[0].lower()
            logging.debug("(address cache) DHCPV6 lease OK: %s --> %s",
                          mac_address, allocate_ip)
            env["address_cache"]["%s_6" % mac_address] = allocate_ip


def _tcpdump_handler(env, filename, line):
    """
    Helper for handler tcpdump output.

    :params address_cache: address cache path.
    :params filename: Log file name for tcpdump message.
    :params line: Tcpdump output message.
    """
    try:
        utils_misc.log_line(filename, line)
    except Exception, reason:
        logging.warn("Can't log tcpdump output, '%s'", reason)

    _update_address_cache(env, line)


class Env(UserDict.IterableUserDict):

    """
    A dict-like object containing global objects used by tests.
    """

    def __init__(self, filename=None, version=0):
        """
        Create an empty Env object or load an existing one from a file.

        If the version recorded in the file is lower than version, or if some
        error occurs during unpickling, or if filename is not supplied,
        create an empty Env object.

        :param filename: Path to an env file.
        :param version: Required env version (int).
        """
        UserDict.IterableUserDict.__init__(self)
        empty = {"version": version}
        self._filename = filename
        self._tcpdump = None
        self._params = None
        self.save_lock = threading.RLock()
        if filename:
            try:
                if os.path.isfile(filename):
                    f = open(filename, "r")
                    env = cPickle.load(f)
                    f.close()
                    if env.get("version", 0) >= version:
                        self.data = env
                    else:
                        logging.warn(
                            "Incompatible env file found. Not using it.")
                        self.data = empty
                else:
                    # No previous env file found, proceed...
                    logging.warn("Creating new, empty env file")
                    self.data = empty
            # Almost any exception can be raised during unpickling, so let's
            # catch them all
            except Exception, e:
                logging.warn("Exception thrown while loading env")
                logging.warn(e)
                logging.warn("Creating new, empty env file")
                self.data = empty
        else:
            logging.warn("Creating new, empty env file")
            self.data = empty

    def save(self, filename=None):
        """
        Pickle the contents of the Env object into a file.

        :param filename: Filename to pickle the dict into.  If not supplied,
                use the filename from which the dict was loaded.
        """
        filename = filename or self._filename
        if filename is None:
            raise EnvSaveError("No filename specified for this env file")
        self.save_lock.acquire()
        try:
            f = open(filename, "w")
            cPickle.dump(self.data, f)
            f.close()
        finally:
            self.save_lock.release()

    def get_all_vms(self):
        """
        Return a list of all VM objects in this Env object.
        """
        vm_list = []
        for key in self.data.keys():
            if key and key.startswith("vm__"):
                vm_list.append(self.data[key])
        return vm_list

    def clean_objects(self):
        """
        Destroy all objects registered in this Env object.
        """
        self.stop_tcpdump()
        for key in self.data:
            try:
                if key.startswith("vm__"):
                    self.data[key].destroy(gracefully=False)
            except Exception:
                pass
        self.data = {}

    def destroy(self):
        """
        Destroy all objects stored in Env and remove the backing file.
        """
        self.clean_objects()
        if self._filename is not None:
            if os.path.isfile(self._filename):
                os.unlink(self._filename)

    def get_vm(self, name):
        """
        Return a VM object by its name.

        :param name: VM name.
        """
        return self.data.get("vm__%s" % name)

    def create_vm(self, vm_type, target, name, params, bindir):
        """
        Create and register a VM in this Env object
        """
        vm_class = virt_vm.BaseVM.lookup_vm_class(vm_type, target)
        if vm_class is not None:
            vm = vm_class(name, params, bindir, self.get("address_cache"))
            self.register_vm(name, vm)
            return vm

    @lock_safe
    def register_vm(self, name, vm):
        """
        Register a VM in this Env object.

        :param name: VM name.
        :param vm: VM object.
        """
        self.data["vm__%s" % name] = vm

    @lock_safe
    def unregister_vm(self, name):
        """
        Remove a given VM.

        :param name: VM name.
        """
        del self.data["vm__%s" % name]

    @lock_safe
    def register_syncserver(self, port, server):
        """
        Register a Sync Server in this Env object.

        :param port: Sync Server port.
        :param server: Sync Server object.
        """
        self.data["sync__%s" % port] = server

    @lock_safe
    def unregister_syncserver(self, port):
        """
        Remove a given Sync Server.

        :param port: Sync Server port.
        """
        del self.data["sync__%s" % port]

    def get_syncserver(self, port):
        """
        Return a Sync Server object by its port.

        :param port: Sync Server port.
        """
        return self.data.get("sync__%s" % port)

    @lock_safe
    def register_lvmdev(self, name, lvmdev):
        """
        Register lvm device object into env;

        :param name: name of register lvmdev object
        :param lvmdev: lvmdev object;
        """
        self.data["lvmdev__%s" % name] = lvmdev

    @lock_safe
    def unregister_lvmdev(self, name):
        """
        Remove lvm device object from env;

        :param name: name of lvm device object;
        """
        del self.data["lvmdev__%s" % name]

    def get_lvmdev(self, name):
        """
        Get lvm device object by name from env;

        :param name: lvm device object name;
        :return: lvmdev object
        """
        return self.data.get("lvmdev__%s" % name)

    def _start_tcpdump(self):
        port = self._params.get('shell_port')
        prompt = self._params.get('shell_prompt')
        address = self._params.get('ovirt_node_address')
        username = self._params.get('ovirt_node_user')
        password = self._params.get('ovirt_node_password')

        cmd_template = "%s -npvvvi any 'port 68 or port 546'"
        cmd = cmd_template % utils_misc.find_command("tcpdump")
        if self._params.get("remote_preprocess") == "yes":
            login_cmd = ("ssh -o UserKnownHostsFile=/dev/null "
                         "-o StrictHostKeyChecking=no "
                         "-o PreferredAuthentications=password -p %s %s@%s" %
                         (port, username, address))

            self._tcpdump = aexpect.ShellSession(
                login_cmd,
                output_func=_update_address_cache,
                output_params=(self,))

            remote.handle_prompts(self._tcpdump, username, password, prompt)
            self._tcpdump.sendline(cmd)

        else:
            self._tcpdump = aexpect.Tail(command=cmd,
                                         output_func=_tcpdump_handler,
                                         output_params=(self, "tcpdump.log"))

        if utils_misc.wait_for(lambda: not self._tcpdump.is_alive(),
                               0.1, 0.1, 1.0):
            logging.warn("Could not start tcpdump")
            logging.warn("Status: %s", self._tcpdump.get_status())
            msg = utils_misc.format_str_for_message(self._tcpdump.get_output())
            logging.warn("Output: %s", msg)

    def start_tcpdump(self, params):
        self._params = params

        if "address_cache" not in self.data:
            self.data["address_cache"] = {}

        if self._tcpdump is None:
            self._start_tcpdump()
        else:
            if not self._tcpdump.is_alive():
                del self._tcpdump
                self._start_tcpdump()

    def stop_tcpdump(self):
        if self._tcpdump is not None:
            self._tcpdump.close()
            del self._tcpdump
            self._tcpdump = None

########NEW FILE########
__FILENAME__ = utils_env_unittest
#!/usr/bin/python
import unittest
import time
import logging
import os
import threading

import common
import utils_env
import utils_params
import utils_misc


class FakeVm(object):

    def __init__(self, vm_name, params):
        self.name = vm_name
        self.params = params
        self.vm_type = self.params.get('vm_type')
        self.driver_type = self.params.get('driver_type')
        self.instance = ("%s-%s" % (
            time.strftime("%Y%m%d-%H%M%S"),
            utils_misc.generate_random_string(16)))

    def get_params(self):
        return self.params

    def is_alive(self):
        logging.info("Fake VM %s (instance %s)", self.name, self.instance)


class FakeSyncListenServer(object):

    def __init__(self, address='', port=123, tmpdir=None):
        self.instance = ("%s-%s" % (
            time.strftime("%Y%m%d-%H%M%S"),
            utils_misc.generate_random_string(16)))
        self.port = port

    def close(self):
        logging.info("Closing sync server (instance %s)", self.instance)


class TestEnv(unittest.TestCase):

    def setUp(self):
        self.envfilename = "/dev/shm/EnvUnittest" + self.id()

    def tearDown(self):
        if os.path.exists(self.envfilename):
            os.unlink(self.envfilename)

    def test_save(self):
        """
        1) Verify that calling env.save() with no filename where env doesn't
           specify a filename will throw an EnvSaveError.
        2) Register a VM in environment, save env to a file, recover env from
           that file, get the vm and verify that the instance attribute of the
           2 objects is the same.
        3) Register a SyncListenServer and don't save env. Restore env from
           file and try to get the syncserver, verify it doesn't work.
        4) Now save env to a file, restore env from file and verify that
           the syncserver can be found there, and that the sync server
           instance attribute is equal to the initial sync server instance.
        """

        env = utils_env.Env()
        self.assertRaises(utils_env.EnvSaveError, env.save, {})

        params = utils_params.Params({"main_vm": 'rhel7-migration'})
        vm1 = FakeVm(params['main_vm'], params)
        vm1.is_alive()
        env.register_vm(params['main_vm'], vm1)
        env.save(filename=self.envfilename)
        env2 = utils_env.Env(filename=self.envfilename)
        vm2 = env2.get_vm(params['main_vm'])
        vm2.is_alive()
        assert vm1.instance == vm2.instance

        sync1 = FakeSyncListenServer(port=222)
        env.register_syncserver(222, sync1)
        env3 = utils_env.Env(filename=self.envfilename)
        syncnone = env3.get_syncserver(222)
        assert syncnone is None

        env.save(filename=self.envfilename)
        env4 = utils_env.Env(filename=self.envfilename)
        sync2 = env4.get_syncserver(222)
        assert sync2.instance == sync1.instance

    def test_register_vm(self):
        """
        1) Create an env object.
        2) Create a VM and register it from env.
        3) Get the vm back from the env.
        4) Verify that the 2 objects are the same.
        """
        env = utils_env.Env(filename=self.envfilename)
        params = utils_params.Params({"main_vm": 'rhel7-migration'})
        vm1 = FakeVm(params['main_vm'], params)
        vm1.is_alive()
        env.register_vm(params['main_vm'], vm1)
        vm2 = env.get_vm(params['main_vm'])
        vm2.is_alive()
        assert vm1 == vm2

    def test_unregister_vm(self):
        """
        1) Create an env object.
        2) Register 2 vms to the env.
        3) Verify both vms are in the env.
        4) Remove one of those vms.
        5) Verify that the removed vm is no longer in env.
        """
        env = utils_env.Env(filename=self.envfilename)
        params = utils_params.Params({"main_vm": 'rhel7-migration'})
        vm1 = FakeVm(params['main_vm'], params)
        vm1.is_alive()
        vm2 = FakeVm('vm2', params)
        vm2.is_alive()
        env.register_vm(params['main_vm'], vm1)
        env.register_vm('vm2', vm2)
        assert vm1 in env.get_all_vms()
        assert vm2 in env.get_all_vms()
        env.unregister_vm('vm2')
        assert vm1 in env.get_all_vms()
        assert vm2 not in env.get_all_vms()

    def test_get_all_vms(self):
        """
        1) Create an env object.
        2) Create 2 vms and register them in the env.
        3) Create a SyncListenServer and register it in the env.
        4) Verify that the 2 vms are in the output of get_all_vms.
        5) Verify that the sync server is not in the output of get_all_vms.
        """
        env = utils_env.Env(filename=self.envfilename)
        params = utils_params.Params({"main_vm": 'rhel7-migration'})
        vm1 = FakeVm(params['main_vm'], params)
        vm1.is_alive()
        vm2 = FakeVm('vm2', params)
        vm2.is_alive()
        env.register_vm(params['main_vm'], vm1)
        env.register_vm('vm2', vm2)
        sync1 = FakeSyncListenServer(port=333)
        env.register_syncserver(333, sync1)
        assert vm1 in env.get_all_vms()
        assert vm2 in env.get_all_vms()
        assert sync1 not in env.get_all_vms()

    def test_register_syncserver(self):
        """
        1) Create an env file.
        2) Create a SyncListenServer object and register it in the env.
        3) Get that SyncListenServer with get_syncserver.
        4) Verify that both objects are the same.
        """
        env = utils_env.Env(filename=self.envfilename)
        sync1 = FakeSyncListenServer(port=333)
        env.register_syncserver(333, sync1)
        sync2 = env.get_syncserver(333)
        assert sync1 == sync2

    def test_unregister_syncserver(self):
        """
        Unregister a sync server.

        1) Create an env file.
        2) Create and register 2 SyncListenServers in the env.
        3) Get one of the SyncListenServers in the env.
        4) Unregister one of the SyncListenServers.
        5) Verify that the SyncListenServer unregistered can't be retrieved
           anymore with ``get_syncserver()``.

        """
        env = utils_env.Env(filename=self.envfilename)
        sync1 = FakeSyncListenServer(port=333)
        env.register_syncserver(333, sync1)
        sync2 = FakeSyncListenServer(port=444)
        env.register_syncserver(444, sync2)
        sync3 = env.get_syncserver(333)
        assert sync1 == sync3
        env.unregister_syncserver(444)
        sync4 = env.get_syncserver(444)
        assert sync4 is None

    def test_locking(self):
        """
        1) Create an env file.
        2) Create a thread that creates a dict as one of env's elements, and
           keeps updating it, using the env save_lock attribute.
        3) Try to save the environment.
        """
        termination_event = threading.Event()
        env = utils_env.Env(filename=self.envfilename)

        def update_env(env):
            @utils_env.lock_safe
            def _update_env(env, key, value):
                env["changing_dict"][key] = value

            if "changing_dict" not in env:
                env["changing_dict"] = {}
            while True:
                key = "%s" % utils_misc.generate_random_string(length=10)
                value = "%s" % utils_misc.generate_random_string(length=10)
                _update_env(env, key, value)
                if termination_event.isSet():
                    break

        changing_thread = threading.Thread(target=update_env,
                                           args=(env,))
        changing_thread.start()
        time.sleep(0.3)
        try:
            env.save()
        finally:
            termination_event.set()

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = utils_libguestfs
"""
libguestfs tools test utility functions.
"""

import logging
import signal
import os
import re

from autotest.client import os_dep, utils
from autotest.client.shared import error
import aexpect
import propcan


class LibguestfsCmdError(Exception):

    """
    Error of libguestfs-tool command.
    """

    def __init__(self, details=''):
        self.details = details
        Exception.__init__(self)

    def __str__(self):
        return str(self.details)


def lgf_cmd_check(cmd):
    """
    To check whether the cmd is supported on this host.

    :param cmd: the cmd to use a libguest tool.
    :return: None if the cmd is not exist, otherwise return its path.
    """
    libguestfs_cmds = ['libguestfs-test-tool', 'guestfish', 'guestmount',
                       'virt-alignment-scan', 'virt-cat', 'virt-copy-in',
                       'virt-copy-out', 'virt-df', 'virt-edit',
                       'virt-filesystems', 'virt-format', 'virt-inspector',
                       'virt-list-filesystems', 'virt-list-partitions',
                       'virt-ls', 'virt-make-fs', 'virt-rescue',
                       'virt-resize', 'virt-sparsify', 'virt-sysprep',
                       'virt-tar', 'virt-tar-in', 'virt-tar-out',
                       'virt-win-reg', 'virt-inspector2']

    if cmd not in libguestfs_cmds:
        raise LibguestfsCmdError(
            "Command %s is not supported by libguestfs yet." % cmd)

    try:
        return os_dep.command(cmd)
    except ValueError:
        logging.warning("You have not installed %s on this host.", cmd)
        return None


def lgf_command(cmd, ignore_status=True, debug=False, timeout=60):
    """
    Interface of libguestfs tools' commands.

    :param cmd: Command line to execute.
    :return: CmdResult object.
    :raise: LibguestfsCmdError if non-zero exit status
            and ignore_status=False
    """
    if debug:
        logging.debug("Running command %s in debug mode.", cmd)

    # Raise exception if ignore_status is False
    try:
        ret = utils.run(cmd, ignore_status=ignore_status,
                        verbose=debug, timeout=timeout)
    except error.CmdError, detail:
        raise LibguestfsCmdError(detail)

    if debug:
        logging.debug("status: %s", ret.exit_status)
        logging.debug("stdout: %s", ret.stdout.strip())
        logging.debug("stderr: %s", ret.stderr.strip())

    # Return CmdResult instance when ignore_status is True
    return ret


class LibguestfsBase(propcan.PropCanBase):

    """
    Base class of libguestfs tools.
    """

    __slots__ = ['ignore_status', 'debug', 'timeout', 'uri', 'lgf_exec']

    def __init__(self, lgf_exec="/bin/true", ignore_status=True,
                 debug=False, timeout=60, uri=None):
        init_dict = {}
        init_dict['ignore_status'] = ignore_status
        init_dict['debug'] = debug
        init_dict['timeout'] = timeout
        init_dict['uri'] = uri
        init_dict['lgf_exec'] = lgf_exec
        super(LibguestfsBase, self).__init__(init_dict)

    def set_ignore_status(self, ignore_status):
        """
        Enforce setting ignore_status as a boolean.
        """
        if bool(ignore_status):
            self.__dict_set__('ignore_status', True)
        else:
            self.__dict_set__('ignore_status', False)

    def set_debug(self, debug):
        """
        Accessor method for 'debug' property that logs message on change
        """
        if not self.INITIALIZED:
            self.__dict_set__('debug', debug)
        else:
            current_setting = self.__dict_get__('debug')
            desired_setting = bool(debug)
            if not current_setting and desired_setting:
                self.__dict_set__('debug', True)
                logging.debug("Libguestfs debugging enabled")
            # current and desired could both be True
            if current_setting and not desired_setting:
                self.__dict_set__('debug', False)
                logging.debug("Libguestfs debugging disabled")

    def set_timeout(self, timeout):
        """
        Accessor method for 'timeout' property, timeout should be digit
        """
        if type(timeout) is int:
            self.__dict_set__('timeout', timeout)
        else:
            try:
                timeout = int(str(timeout))
                self.__dict_set__('timeout', timeout)
            except ValueError:
                logging.debug("Set timeout failed.")

    def get_uri(self):
        """
        Accessor method for 'uri' property that must exist
        """
        # self.get() would call get_uri() recursivly
        try:
            return self.__dict_get__('uri')
        except KeyError:
            return None


# There are two ways to call guestfish:
# 1.Guestfish classies provided below(shell session)
# 2.guestfs module provided in system libguestfs package

class Guestfish(LibguestfsBase):

    """
    Execute guestfish, using a new guestfish shell each time.
    """

    __slots__ = []

    def __init__(self, disk_img=None, ro_mode=False,
                 libvirt_domain=None, inspector=False,
                 uri=None, mount_options=None, run_mode="interactive"):
        """
        Initialize guestfish command with options.

        :param disk_img: if it is not None, use option '-a disk'.
        :param ro_mode: only for disk_img. add option '--ro' if it is True.
        :param libvirt_domain: if it is not None, use option '-d domain'.
        :param inspector: guestfish mounts vm's disks automatically
        :param uri: guestfish's connect uri
        :param mount_options: Mount the named partition or logical volume
                               on the given mountpoint.
        """
        guestfs_exec = "guestfish"
        if lgf_cmd_check(guestfs_exec) is None:
            raise LibguestfsCmdError

        if run_mode not in ['remote', 'interactive']:
            raise AssertionError("run_mode should be remote or interactive")

        if run_mode == "remote":
            guestfs_exec += " --listen"
        else:
            if uri:
                guestfs_exec += " -c '%s'" % uri
            if disk_img:
                guestfs_exec += " -a '%s'" % disk_img
            if libvirt_domain:
                guestfs_exec += " -d '%s'" % libvirt_domain
            if ro_mode:
                guestfs_exec += " --ro"
            if inspector:
                guestfs_exec += " -i"
            if mount_options is not None:
                guestfs_exec += " --mount %s" % mount_options

        super(Guestfish, self).__init__(guestfs_exec)

    def complete_cmd(self, command):
        """
        Execute built-in command in a complete guestfish command
        (Not a guestfish session).
        command: guestfish [--options] [commands]
        """
        guestfs_exec = self.__dict_get__('lgf_exec')
        ignore_status = self.__dict_get__('ignore_status')
        debug = self.__dict_get__('debug')
        timeout = self.__dict_get__('timeout')
        if command:
            guestfs_exec += " %s" % command
            return lgf_command(guestfs_exec, ignore_status, debug, timeout)
        else:
            raise LibguestfsCmdError("No built-in command was passed.")


class GuestfishSession(aexpect.ShellSession):

    """
    A shell session of guestfish.
    """

    # Check output against list of known error-status strings
    ERROR_REGEX_LIST = ['libguestfs: error:\s*']

    def __init__(self, guestfs_exec=None, a_id=None, prompt=r"><fs>\s*"):
        """
        Initialize guestfish session server, or client if id set.

        :param guestfs_cmd: path to guestfish executable
        :param id: ID of an already running server, if accessing a running
                server, or None if starting a new one.
        :param prompt: Regular expression describing the shell's prompt line.
        """
        # aexpect tries to auto close session because no clients connected yet
        super(GuestfishSession, self).__init__(guestfs_exec, a_id,
                                               prompt=prompt,
                                               auto_close=False)

    def cmd_status_output(self, cmd, timeout=60, internal_timeout=None,
                          print_func=None):
        """
        Send a guestfish command and return its exit status and output.

        :param cmd: guestfish command to send
                    (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :return: A tuple (status, output) where status is the exit status and
                output is the output of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellStatusError: Raised if the exit status cannot be obtained
        :raise ShellError: Raised if an unknown error occurs
        """
        out = self.cmd_output(cmd, timeout, internal_timeout, print_func)
        for line in out.splitlines():
            if self.match_patterns(line, self.ERROR_REGEX_LIST) is not None:
                return 1, out
        return 0, out

    def cmd_result(self, cmd, ignore_status=False):
        """Mimic utils.run()"""
        exit_status, stdout = self.cmd_status_output(cmd)
        stderr = ''  # no way to retrieve this separately
        result = utils.CmdResult(cmd, stdout, stderr, exit_status)
        if not ignore_status and exit_status:
            raise error.CmdError(cmd, result,
                                 "Guestfish Command returned non-zero exit status")
        return result


class GuestfishRemote(object):

    """
    Remote control of guestfish.
    """

    # Check output against list of known error-status strings
    ERROR_REGEX_LIST = ['libguestfs: error:\s*']

    def __init__(self, guestfs_exec=None, a_id=None):
        """
        Initialize guestfish session server, or client if id set.

        :param guestfs_cmd: path to guestfish executable
        :param a_id: guestfish remote id
        """
        if a_id is None:
            try:
                ret = utils.run(guestfs_exec, ignore_status=False,
                                verbose=True, timeout=60)
            except error.CmdError, detail:
                raise LibguestfsCmdError(detail)
            self.a_id = re.search("\d+", ret.stdout.strip()).group()
        else:
            self.a_id = a_id

    def get_id(self):
        return self.a_id

    def cmd_status_output(self, cmd, ignore_status=None, verbose=None, timeout=60):
        """
        Send a guestfish command and return its exit status and output.

        :param cmd: guestfish command to send(must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to return
        :return: A tuple (status, output) where status is the exit status
                 and output is the output of cmd
        :raise LibguestfsCmdError: Raised if commands execute failed
        """
        guestfs_exec = "guestfish --remote=%s " % self.a_id
        cmd = guestfs_exec + cmd
        try:
            ret = utils.run(cmd, ignore_status=ignore_status,
                            verbose=verbose, timeout=timeout)
        except error.CmdError, detail:
            raise LibguestfsCmdError(detail)

        for line in self.ERROR_REGEX_LIST:
            if re.search(line, ret.stdout.strip()):
                raise LibguestfsCmdError(detail)

        logging.debug("command: %s", cmd)
        logging.debug("stdout: %s", ret.stdout.strip())

        return 0, ret.stdout.strip()

    def cmd(self, cmd, ignore_status=False):
        """Mimic utils.run()"""
        exit_status, stdout = self.cmd_status_output(cmd)
        stderr = ''  # no way to retrieve this separately
        result = utils.CmdResult(cmd, stdout, stderr, exit_status)
        if not ignore_status and exit_status:
            raise error.CmdError(cmd, result,
                                 "Guestfish Command returned non-zero exit status")
        return result

    def cmd_result(self, cmd, ignore_status=False):
        """Mimic utils.run()"""
        exit_status, stdout = self.cmd_status_output(cmd)
        stderr = ''  # no way to retrieve this separately
        result = utils.CmdResult(cmd, stdout, stderr, exit_status)
        if not ignore_status and exit_status:
            raise error.CmdError(cmd, result,
                                 "Guestfish Command returned non-zero exit status")
        return result


class GuestfishPersistent(Guestfish):

    """
    Execute operations using persistent guestfish session.
    """

    __slots__ = ['session_id', 'run_mode']

    # Help detect leftover sessions
    SESSION_COUNTER = 0

    def __init__(self, disk_img=None, ro_mode=False,
                 libvirt_domain=None, inspector=False,
                 uri=None, mount_options=None, run_mode="interactive"):
        super(GuestfishPersistent, self).__init__(disk_img, ro_mode,
                                                  libvirt_domain, inspector,
                                                  uri, mount_options, run_mode)
        self.__dict_set__('run_mode', run_mode)

        if self.get('session_id') is None:
            # set_uri does not call when INITIALIZED = False
            # and no session_id passed to super __init__
            self.new_session()

        # Check whether guestfish session is prepared.
        guestfs_session = self.open_session()
        if run_mode != "remote":
            status, output = guestfs_session.cmd_status_output('is-config', timeout=60)
            if status != 0:
                logging.debug("Persistent guestfish session is not responding.")
                raise aexpect.ShellStatusError(self.lgf_exec, 'is-config')

    def close_session(self):
        """
        If a persistent session exists, close it down.
        """
        try:
            run_mode = self.get('run_mode')
            existing = self.open_session()
            # except clause exits function
            # Try to end session with inner command 'quit'
            try:
                existing.cmd("quit")
            # It should jump to exception followed normally
            except aexpect.ShellProcessTerminatedError:
                self.__class__.SESSION_COUNTER -= 1
                self.__dict_del__('session_id')
                return  # guestfish session was closed normally
            # Close with 'quit' did not respond
            # So close with aexpect functions
            if run_mode != "remote":
                if existing.is_alive():
                    # try nicely first
                    existing.close()
                    if existing.is_alive():
                        # Be mean, incase it's hung
                        existing.close(sig=signal.SIGTERM)
                    # Keep count:
                    self.__class__.SESSION_COUNTER -= 1
                    self.__dict_del__('session_id')
        except LibguestfsCmdError:
            # Allow other exceptions to be raised
            pass  # session was closed already

    def new_session(self):
        """
        Open new session, closing any existing
        """
        # Accessors may call this method, avoid recursion
        # Must exist, can't be None
        guestfs_exec = self.__dict_get__('lgf_exec')
        self.close_session()
        # Always create new session
        run_mode = self.get('run_mode')
        if run_mode == "remote":
            new_session = GuestfishRemote(guestfs_exec)
        else:
            new_session = GuestfishSession(guestfs_exec)
        # Keep count
        self.__class__.SESSION_COUNTER += 1
        session_id = new_session.get_id()
        self.__dict_set__('session_id', session_id)

    def open_session(self):
        """
        Return session with session_id in this class.
        """
        try:
            session_id = self.__dict_get__('session_id')
            run_mode = self.get('run_mode')
            if session_id:
                try:
                    if run_mode == "remote":
                        return GuestfishRemote(a_id=session_id)
                    else:
                        return GuestfishSession(a_id=session_id)
                except aexpect.ShellStatusError:
                    # session was already closed
                    self.__dict_del__('session_id')
                    raise LibguestfsCmdError(
                        "Open session '%s' failed." % session_id)
        except KeyError:
            raise LibguestfsCmdError("No session id.")

    # Inner command for guestfish should be executed in a guestfish session
    def inner_cmd(self, command):
        """
        Execute inner command of guestfish in a pesistent session.

        :param command: inner command to be executed.
        """
        session = self.open_session()
        # Allow to raise error by default.
        ignore_status = self.__dict_get__('ignore_status')
        return session.cmd_result(command, ignore_status=ignore_status)

    def add_drive(self, filename):
        """
        add-drive - add an image to examine or modify

        This function is the equivalent of calling "add_drive_opts" with no
        optional parameters, so the disk is added writable, with the format
        being detected automatically.
        """
        return self.inner_cmd("add-drive %s" % filename)

    def add_drive_opts(self, filename, readonly=False, format=None,
                       iface=None, name=None):
        """
        add-drive-opts - add an image to examine or modify.

        This function adds a disk image called "filename" to the handle.
        "filename" may be a regular host file or a host device.
        """
        cmd = "add-drive-opts %s" % filename

        if readonly:
            cmd += " readonly:true"
        else:
            cmd += " readonly:false"
        if format:
            cmd += " format:%s" % format
        if iface:
            cmd += " iface:%s" % iface
        if name:
            cmd += " name:%s" % name

        return self.inner_cmd(cmd)

    def add_drive_ro(self, filename):
        """
        add-ro/add-drive-ro - add a drive in snapshot mode (read-only)

        This function is the equivalent of calling "add_drive_opts" with the
        optional parameter "GUESTFS_ADD_DRIVE_OPTS_READONLY" set to 1, so the
        disk is added read-only, with the format being detected automatically.
        """
        return self.inner_cmd("add-drive-ro %s" % filename)

    def add_domain(self, domain, libvirturi=None, readonly=False, iface=None,
                   live=False, allowuuid=False, readonlydisk=None):
        """
        domain/add-domain - add the disk(s) from a named libvirt domain

        This function adds the disk(s) attached to the named libvirt domain
        "dom". It works by connecting to libvirt, requesting the domain and
        domain XML from libvirt, parsing it for disks, and calling
        "add_drive_opts" on each one.
        """
        cmd = "add-domain %s" % domain

        if libvirturi:
            cmd += " libvirturi:%s" % libvirturi
        if readonly:
            cmd += " readonly:true"
        else:
            cmd += " readonly:false"
        if iface:
            cmd += " iface:%s" % iface
        if live:
            cmd += " live:true"
        if allowuuid:
            cmd += " allowuuid:true"
        if readonlydisk:
            cmd += " readonlydisk:%s" % readonlydisk

        return self.inner_cmd(cmd)

    def run(self):
        """
        run/launch - launch the qemu subprocess

        Internally libguestfs is implemented by running a virtual machine
        using qemu.
        """
        return self.inner_cmd("launch")

    def df(self):
        """
        df - report file system disk space usage

        This command runs the "df" command to report disk space used.
        """
        return self.inner_cmd("df")

    def list_partitions(self):
        """
        list-partitions - list the partitions

        List all the partitions detected on all block devices.
        """
        return self.inner_cmd("list-partitions")

    def mount(self, device, mountpoint):
        """
        mount - mount a guest disk at a position in the filesystem

        Mount a guest disk at a position in the filesystem.
        """
        return self.inner_cmd("mount %s %s" % (device, mountpoint))

    def mount_ro(self, device, mountpoint):
        """
        mount-ro - mount a guest disk, read-only

        This is the same as the "mount" command, but it mounts the
        filesystem with the read-only (*-o ro*) flag.
        """
        return self.inner_cmd("mount-ro %s %s" % (device, mountpoint))

    def mount_options(self, options, device, mountpoint):
        """
        mount - mount a guest disk at a position in the filesystem

        Mount a guest disk at a position in the filesystem.
        """
        return self.inner_cmd("mount-options %s %s %s" % (options, device, mountpoint))

    def mounts(self):
        """
        mounts - show mounted filesystems

        This returns the list of currently mounted filesystems.
        """
        return self.inner_cmd("mounts")

    def mountpoints(self):
        """
        mountpoints - show mountpoints

        This call is similar to "mounts".
        That call returns a list of devices.
        """
        return self.inner_cmd("mountpoints")

    def do_mount(self, mountpoint):
        """
        do_mount - Automaticly mount

        Mount a lvm or physical partation to '/'
        """
        partition_type = self.params.get("partition_type")
        if partition_type == "lvm":
            vg_name = self.params.get("vg_name", "vol_test")
            lv_name = self.params.get("lv_name", "vol_file")
            device = "/dev/%s/%s" % (vg_name, lv_name)
            logging.info("mount lvm partition...%s" % device)
        elif partition_type == "physical":
            pv_name = self.params.get("pv_name", "/dev/sdb")
            device = pv_name + "1"
            logging.info("mount physical partition...%s" % device)
        self.mount(device, mountpoint)

    def read_file(self, path):
        """
        read-file - read a file

        This calls returns the contents of the file "path" as a buffer.
        """
        return self.inner_cmd("read-file %s" % path)

    def cat(self, path):
        """
        cat - list the contents of a file

        Return the contents of the file named "path".
        """
        return self.inner_cmd("cat %s" % path)

    def write(self, path, content):
        """
        write - create a new file

        This call creates a file called "path". The content of the file
        is the string "content" (which can contain any 8 bit data).
        """
        return self.inner_cmd("write '%s' '%s'" % (path, content))

    def write_append(self, path, content):
        """
        write-append - append content to end of file

        This call appends "content" to the end of file "path".
        If "path" does not exist, then a new file is created.
        """
        return self.inner_cmd("write-append '%s' '%s'" % (path, content))

    def inspect_os(self):
        """
        inspect-os - inspect disk and return list of operating systems found

        This function uses other libguestfs functions and certain heuristics to
        inspect the disk(s) (usually disks belonging to a virtual machine),
        looking for operating systems.
        """
        return self.inner_cmd("inspect-os")

    def inspect_get_roots(self):
        """
        inspect-get-roots - return list of operating systems found by
        last inspection

        This function is a convenient way to get the list of root devices
        """
        return self.inner_cmd("inspect-get-roots")

    def inspect_get_arch(self, root):
        """
        inspect-get-arch - get architecture of inspected operating system

        This returns the architecture of the inspected operating system.
        """
        return self.inner_cmd("inspect-get-arch %s" % root)

    def inspect_get_distro(self, root):
        """
        inspect-get-distro - get distro of inspected operating system

        This returns the distro (distribution) of the inspected
        operating system.
        """
        return self.inner_cmd("inspect-get-distro %s" % root)

    def inspect_get_filesystems(self, root):
        """
        inspect-get-filesystems - get filesystems associated with inspected
        operating system

        This returns a list of all the filesystems that we think are associated
        with this operating system.
        """
        return self.inner_cmd("inspect-get-filesystems %s" % root)

    def inspect_get_hostname(self, root):
        """
        inspect-get-hostname - get hostname of the operating system

        This function returns the hostname of the operating system as found by
        inspection of the guest's configuration files.
        """
        return self.inner_cmd("inspect-get-hostname %s" % root)

    def inspect_get_major_version(self, root):
        """
        inspect-get-major-version - get major version of inspected operating
        system

        This returns the major version number of the inspected
        operating system.
        """
        return self.inner_cmd("inspect-get-major-version %s" % root)

    def inspect_get_minor_version(self, root):
        """
        inspect-get-minor-version - get minor version of inspected operating
        system

        This returns the minor version number of the inspected operating system
        """
        return self.inner_cmd("inspect-get-minor-version %s" % root)

    def inspect_get_mountpoints(self, root):
        """
        inspect-get-mountpoints - get mountpoints of inspected operating system

        This returns a hash of where we think the filesystems associated with
        this operating system should be mounted.
        """
        return self.inner_cmd("inspect-get-mountpoints %s" % root)

    def list_filesystems(self):
        """
        list-filesystems - list filesystems

        This inspection command looks for filesystems on partitions, block
        devices and logical volumes, returning a list of devices containing
        filesystems and their type.
        """
        return self.inner_cmd("list-filesystems")

    def list_devices(self):
        """
        list-devices - list the block devices

        List all the block devices.
        """
        return self.inner_cmd("list-devices")

    def tar_out(self, directory, tarfile):
        """
        tar-out - pack directory into tarfile

        This command packs the contents of "directory" and downloads it
        to local file "tarfile".
        """
        return self.inner_cmd("tar-out %s %s" % (directory, tarfile))

    def tar_in(self, tarfile, directory):
        """
        tar-in - unpack tarfile to directory

        This command uploads and unpacks local file "tarfile"
        (an *uncompressed* tar file) into "directory".
        """
        return self.inner_cmd("tar-in %s %s" % (tarfile, directory))

    def tar_in_opts(self, tarfile, directory, compress=None):
        """
        tar-in-opts - unpack tarfile to directory

        This command uploads and unpacks local file "tarfile"
        (an *compressed* tar file) into "directory".
        """
        if compress:
            return self.inner_cmd("tar-in-opts %s %s compress:%s" % (tarfile, directory, compress))
        else:
            return self.inner_cmd("tar-in-opts %s %s" % (tarfile, directory))

    def file_architecture(self, filename):
        """
        file-architecture - detect the architecture of a binary file

        This detects the architecture of the binary "filename", and returns it
        if known.
        """
        return self.inner_cmd("file-architecture %s" % filename)

    def filesize(self, file):
        """
        filesize - return the size of the file in bytes

        This command returns the size of "file" in bytes.
        """
        return self.inner_cmd("filesize %s" % file)

    def stat(self, path):
        """
        stat - get file information

        Returns file information for the given "path".
        """
        return self.inner_cmd("stat %s" % path)

    def lstat(self, path):
        """
        lstat - get file information for a symbolic link

        Returns file information for the given "path".
        """
        return self.inner_cmd("lstat %s" % path)

    def lstatlist(self, path, names):
        """
        lstatlist - lstat on multiple files

        This call allows you to perform the "lstat" operation on multiple files,
        where all files are in the directory "path". "names" is the list of
        files from this directory.
        """
        return self.inner_cmd("lstatlist %s %s" % (path, names))

    def umask(self, mask):
        """
        umask - set file mode creation mask (umask)

        This function sets the mask used for creating new files and device nodes
        to "mask & 0777".
        """
        return self.inner_cmd("umask %s" % mask)

    def get_umask(self):
        """
        get-umask - get the current umask

        Return the current umask. By default the umask is 022 unless it has been
        set by calling "umask".
        """
        return self.inner_cmd("get-umask")

    def mkdir(self, path):
        """
        mkdir - create a directory

        Create a directory named "path".
        """
        return self.inner_cmd("mkdir %s" % path)

    def mkdir_mode(self, path, mode):
        """
        mkdir-mode - create a directory with a particular mode

        This command creates a directory, setting the initial permissions of the
        directory to "mode".
        """
        return self.inner_cmd("mkdir-mode %s %s" % (path, mode))

    def mknod(self, mode, devmajor, devminor, path):
        """
        mknod - make block, character or FIFO devices

        This call creates block or character special devices, or named pipes
        (FIFOs).
        """
        return self.inner_cmd("mknod %s %s %s %s" % (mode, devmajor, devminor, path))

    def rm_rf(self, path):
        """
        rm-rf - remove a file or directory recursively

        Remove the file or directory "path", recursively removing the contents
        if its a directory. This is like the "rm -rf" shell command.
        """
        return self.inner_cmd("rm-rf %s" % path)

    def copy_out(self, remote, localdir):
        """
        copy-out - copy remote files or directories out of an image

        "copy-out" copies remote files or directories recursively out of the
        disk image, placing them on the host disk in a local directory called
        "localdir" (which must exist).
        """
        return self.inner_cmd("copy-out %s %s" % (remote, localdir))

    def copy_in(self, local, remotedir):
        """
        copy-in - copy local files or directories into an image

        "copy-in" copies local files or directories recursively into the disk
        image, placing them in the directory called "/remotedir" (which must
        exist).
        """
        return self.inner_cmd("copy-in %s /%s" % (local, remotedir))

    def chmod(self, mode, path):
        """
        chmod - change file mode

        Change the mode (permissions) of "path" to "mode". Only numeric modes
        are supported.
        """
        return self.inner_cmd("chmod %s %s" % (mode, path))

    def chown(self, owner, group, path):
        """
        chown - change file owner and group

        Change the file owner to "owner" and group to "group".
        """
        return self.inner_cmd("chown %s %s %s" % (owner, group, path))

    def lchown(self, owner, group, path):
        """
        lchown - change file owner and group

        Change the file owner to "owner" and group to "group". This is like
        "chown" but if "path" is a symlink then the link itself is changed, not
        the target.
        """
        return self.inner_cmd("lchown %s %s %s" % (owner, group, path))

    def du(self, path):
        """
        du - estimate file space usage

        This command runs the "du -s" command to estimate file space usage for
        "path".
        """
        return self.inner_cmd("du %s" % path)

    def file(self, path):
        """
        file - determine file type

        This call uses the standard file(1) command to determine the type or
        contents of the file.
        """
        return self.inner_cmd("file %s" % path)

    def rm(self, path):
        """
        rm - remove a file

        Remove the single file "path".
        """
        return self.inner_cmd("rm %s" % path)

    def is_file(self, path, followsymlinks=None):
        """
        is-file - test if a regular file

        This returns "true" if and only if there is a regular file with the
        given "path" name.
        """
        cmd = "is-file %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_file_opts(self, path, followsymlinks=None):
        """
        is-file_opts - test if a regular file

        This returns "true" if and only if there is a regular file with the
        given "path" name.

        An alias of command is-file
        """
        cmd = "is-file-opts %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_blockdev(self, path, followsymlinks=None):
        """
        is-blockdev - test if block device

        This returns "true" if and only if there is a block device with the
        given "path" name
        """
        cmd = "is-blockdev %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_blockdev_opts(self, path, followsymlinks=None):
        """
        is-blockdev_opts - test if block device

        This returns "true" if and only if there is a block device with the
        given "path" name

        An alias of command is-blockdev
        """
        cmd = "is-blockdev-opts %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_chardev(self, path, followsymlinks=None):
        """
        is-chardev - test if character device

        This returns "true" if and only if there is a character device with the
        given "path" name.
        """
        cmd = "is-chardev %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_chardev_opts(self, path, followsymlinks=None):
        """
        is-chardev_opts - test if character device

        This returns "true" if and only if there is a character device with the
        given "path" name.

        An alias of command is-chardev
        """
        cmd = "is-chardev-opts %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_dir(self, path, followsymlinks=None):
        """
        is-dir - test if a directory

        This returns "true" if and only if there is a directory with the given
        "path" name. Note that it returns false for other objects like files.
        """
        cmd = "is-dir %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_dir_opts(self, path, followsymlinks=None):
        """
        is-dir-opts - test if character device

        This returns "true" if and only if there is a character device with the
        given "path" name.

        An alias of command is-dir
        """
        cmd = "is-dir-opts %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_fifo(self, path, followsymlinks=None):
        """
        is-fifo - test if FIFO (named pipe)

        This returns "true" if and only if there is a FIFO (named pipe) with
        the given "path" name.
        """
        cmd = "is-fifo %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_fifo_opts(self, path, followsymlinks=None):
        """
        is-fifo-opts - test if FIFO (named pipe)

        This returns "true" if and only if there is a FIFO (named pipe) with
        the given "path" name.

        An alias of command is-fifo
        """
        cmd = "is-fifo-opts %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_lv(self, device):
        """
        is-lv - test if device is a logical volume

        This command tests whether "device" is a logical volume, and returns
        true iff this is the case.
        """
        return self.inner_cmd("is-lv %s" % device)

    def is_socket(self, path, followsymlinks=None):
        """
        is-socket - test if socket

        This returns "true" if and only if there is a Unix domain socket with
        the given "path" name.
        """
        cmd = "is-socket %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_socket_opts(self, path, followsymlinks=None):
        """
        is-socket-opts - test if socket

        This returns "true" if and only if there is a Unix domain socket with
        the given "path" name.

        An alias of command is-socket
        """
        cmd = "is-socket-opts %s" % path

        if followsymlinks:
            cmd += " followsymlinks:%s" % followsymlinks

        return self.inner_cmd(cmd)

    def is_symlink(self, path):
        """
        is-symlink - test if symbolic link

        This returns "true" if and only if there is a symbolic link with the
        given "path" name.
        """
        return self.inner_cmd("is-symlink %s" % path)

    def is_whole_device(self, device):
        """
        is-symlink - test if symbolic link

        This returns "true" if and only if "device" refers to a whole block
        device. That is, not a partition or a logical device.
        """
        return self.inner_cmd("is-whole-device %s" % device)

    def is_zero(self, path):
        """
        is-zero - test if a file contains all zero bytes

        This returns true iff the file exists and the file is empty or it
        contains all zero bytes.
        """
        return self.inner_cmd("is-zero %s" % path)

    def is_zero_device(self, device):
        """
        is-zero-device - test if a device contains all zero bytes

        This returns true iff the device exists and contains all zero bytes.
        Note that for large devices this can take a long time to run.
        """
        return self.inner_cmd("is-zero-device %s" % device)

    def cp(self, src, dest):
        """
        cp - copy a file

        This copies a file from "src" to "dest" where "dest" is either a
        destination filename or destination directory.
        """
        return self.inner_cmd("cp %s %s" % (src, dest))

    def exists(self, path):
        """
        exists - test if file or directory exists

        This returns "true" if and only if there is a file, directory (or
        anything) with the given "path" name
        """
        return self.inner_cmd("exists %s" % path)

    def cp_a(self, src, dest):
        """
        cp-a - copy a file or directory recursively

        This copies a file or directory from "src" to "dest" recursively using
        the "cp -a" command.
        """
        return self.inner_cmd("cp-a %s %s" % (src, dest))

    def equal(self, file1, file2):
        """
        equal - test if two files have equal contents

        This compares the two files "file1" and "file2" and returns true if
        their content is exactly equal, or false otherwise.
        """
        return self.inner_cmd("equal %s %s" % (file1, file2))

    def download(self, remotefilename, filename):
        """
        download - download a file to the local machine

        Download file "remotefilename" and save it as "filename" on the local
        machine.
        """
        return self.inner_cmd("download %s %s" % (remotefilename, filename))

    def part_init(self, device, parttype):
        """
        part-init - create an empty partition table

        This creates an empty partition table on "device" of one of the
        partition types listed below. Usually "parttype" should be either
        "msdos" or "gpt" (for large disks).
        """
        return self.inner_cmd("part-init %s %s" % (device, parttype))

    def part_add(self, device, prlogex, startsect, endsect):
        """
        part-add - add a partition to the device

        This command adds a partition to "device". If there is no partition
        table on the device, call "part_init" first.
        """
        cmd = "part-add %s %s %s %s" % (device, prlogex, startsect, endsect)
        return self.inner_cmd(cmd)

    def part_del(self, device, partnum):
        """
        part-del device partnum

        This command deletes the partition numbered "partnum" on "device".

        Note that in the case of MBR partitioning, deleting an extended
        partition also deletes any logical partitions it contains.
        """
        return self.inner_cmd("part_del %s %s" % (device, partnum))

    def part_set_bootable(self, device, partnum, bootable):
        """
        part-set-bootable device partnum bootable

        This sets the bootable flag on partition numbered "partnum" on device
        "device". Note that partitions are numbered from 1.
        """
        return self.inner_cmd("part-set-bootable %s %s %s" % (device, partnum, bootable))

    def part_set_mbr_id(self, device, partnum, idbyte):
        """
        part-set-mbr-id - set the MBR type byte (ID byte) of a partition

        Sets the MBR type byte (also known as the ID byte) of the numbered
        partition "partnum" to "idbyte". Note that the type bytes quoted in
        most documentation are in fact hexadecimal numbers, but usually documented
        without any leading "0x" which might be confusing.
        """
        return self.inner_cmd("part-set-mbr-id %s %s %s" % (device, partnum, idbyte))

    def part_set_name(self, device, partnum, name):
        """
        part-set-name - set partition name

        This sets the partition name on partition numbered "partnum" on device
        "device". Note that partitions are numbered from 1.
        """
        return self.inner_cmd("part-set-name %s %s %s" % (device, partnum, name))

    def part_to_dev(self, partition):
        """
        part-to-dev - convert partition name to device name

        This function takes a partition name (eg. "/dev/sdb1") and removes the
        partition number, returning the device name (eg. "/dev/sdb").

        The named partition must exist, for example as a string returned from
        "list_partitions".
        """
        return self.inner_cmd("part-to-dev %s" % partition)

    def part_to_partnum(self, partition):
        """
        part-to-partnum - convert partition name to partition number

        This function takes a partition name (eg. "/dev/sdb1") and returns the
        partition number (eg. 1).

        The named partition must exist, for example as a string returned from
        "list_partitions".
        """
        return self.inner_cmd("part_to_partnum %s" % partition)

    def checksum(self, csumtype, path):
        """
        checksum - compute MD5, SHAx or CRC checksum of file

        This call computes the MD5, SHAx or CRC checksum of the file named
        "path".
        """
        return self.inner_cmd("checksum %s %s" % (csumtype, path))

    def checksum_device(self, csumtype, device):
        """
        checksum-device - compute MD5, SHAx or CRC checksum of the contents of a
        device

        This call computes the MD5, SHAx or CRC checksum of the contents of the
        device named "device". For the types of checksums supported see the
        "checksum" command.
        """
        return self.inner_cmd("checksum-device %s %s" % (csumtype, device))

    def checksums_out(self, csumtype, directory, sumsfile):
        """
        checksums-out - compute MD5, SHAx or CRC checksum of files in a
        directory

        This command computes the checksums of all regular files in "directory"
        and then emits a list of those checksums to the local output file
        "sumsfile".
        """
        return self.inner_cmd("checksums-out %s %s %s" % (csumtype, directory, sumsfile))

    def is_config(self):
        """
        is-config - is ready to accept commands

        This returns true if this handle is in the "CONFIG" state
        """
        return self.inner_cmd("is-config")

    def is_ready(self):
        """
        is-ready - is ready to accept commands

        This returns true if this handle is ready to accept commands
        (in the "READY" state).
        """
        return self.inner_cmd("is-ready")

    def part_list(self, device):
        """
        part-list - list partitions on a device

        This command parses the partition table on "device" and
        returns the list of partitions found.
        """
        return self.inner_cmd("part-list %s" % device)

    def mkfs(self, fstype, device):
        """
        mkfs - make a filesystem

        This creates a filesystem on "device" (usually a partition or LVM
        logical volume). The filesystem type is "fstype", for example "ext3".
        """
        return self.inner_cmd("mkfs %s %s" % (fstype, device))

    def mkfs_opts(self, fstype, device, opts):
        """
        mkfs-opts - make a filesystem with optional arguments

        This creates a filesystem on "device" (usually a partition or LVM
        logical volume). The filesystem type is "fstype", for example "ext3".
        """
        return self.inner_cmd("mkfs %s %s %s" % (fstype, device, opts))

    def part_disk(self, device, parttype):
        """
        part-disk - partition whole disk with a single primary partition

        This command is simply a combination of "part_init" followed by
        "part_add" to create a single primary partition covering
        the whole disk.
        """
        return self.inner_cmd("part-disk %s %s" % (device, parttype))

    def part_get_bootable(self, device, partnum):
        """
        part-get-bootable - return true if a partition is bootable

        This command returns true if the partition "partnum" on "device"
        has the bootable flag set.
        """
        return self.inner_cmd("part-get-bootable %s %s" % (device, partnum))

    def part_get_mbr_id(self, device, partnum):
        """
        part-get-mbr-id - get the MBR type byte (ID byte) from a partition

        Returns the MBR type byte (also known as the ID byte) from the
        numbered partition "partnum".
        """
        return self.inner_cmd("part-get-mbr-id %s %s" % (device, partnum))

    def part_get_parttype(self, device):
        """
        part-get-parttype - get the partition table type

        This command examines the partition table on "device" and returns the
        partition table type (format) being used.
        """
        return self.inner_cmd("part-get-parttype %s" % device)

    def fsck(self, fstype, device):
        """
        fsck - run the filesystem checker

        This runs the filesystem checker (fsck) on "device" which should have
        filesystem type "fstype".
        """
        return self.inner_cmd("fsck %s %s" % (fstype, device))

    def blockdev_getss(self, device):
        """
        blockdev-getss - get sectorsize of block device

        This returns the size of sectors on a block device. Usually 512,
        but can be larger for modern devices.
        """
        return self.inner_cmd("blockdev-getss %s" % device)

    def blockdev_getsz(self, device):
        """
        blockdev-getsz - get total size of device in 512-byte sectors

        This returns the size of the device in units of 512-byte sectors
        (even if the sectorsize isn't 512 bytes ... weird).
        """
        return self.inner_cmd("blockdev-getsz %s" % device)

    def blockdev_getbsz(self, device):
        """
        blockdev-getbsz - get blocksize of block device

        This returns the block size of a device.
        """
        return self.inner_cmd("blockdev-getbsz %s" % device)

    def blockdev_getsize64(self, device):
        """
        blockdev-getsize64 - get total size of device in bytes

        This returns the size of the device in bytes
        """
        return self.inner_cmd("blockdev-getsize64 %s" % device)

    def blockdev_setbsz(self, device, blocksize):
        """
        blockdev-setbsz - set blocksize of block device

        This sets the block size of a device.
        """
        return self.inner_cmd("blockdev-setbsz %s %s" % (device, blocksize))

    def blockdev_getro(self, device):
        """
        blockdev-getro - is block device set to read-only

        Returns a boolean indicating if the block device is read-only
        (true if read-only, false if not).
        """
        return self.inner_cmd("blockdev-getro %s" % device)

    def blockdev_setro(self, device):
        """
        blockdev-setro - set block device to read-only

        Sets the block device named "device" to read-only.
        """
        return self.inner_cmd("blockdev-setro %s" % device)

    def blockdev_setrw(self, device):
        """
        blockdev-setrw - set block device to read-write

        Sets the block device named "device" to read-write.
        """
        return self.inner_cmd("blockdev-setrw %s" % device)

    def blockdev_flushbufs(self, device):
        """
        blockdev-flushbufs - flush device buffers

        This tells the kernel to flush internal buffers associated with
        "device".
        """
        return self.inner_cmd("blockdev-flushbufs %s" % device)

    def blockdev_rereadpt(self, device):
        """
        blockdev-rereadpt - reread partition table

        Reread the partition table on "device".
        """
        return self.inner_cmd("blockdev-rereadpt %s" % device)

    def canonical_device_name(self, device):
        """
        canonical-device-name - return canonical device name

        This utility function is useful when displaying device names to
        the user.
        """
        return self.inner_cmd("canonical-device-name %s" % device)

    def device_index(self, device):
        """
        device-index - convert device to index

        This function takes a device name (eg. "/dev/sdb") and returns the
        index of the device in the list of devices
        """
        return self.inner_cmd("device-index %s" % device)

    def disk_format(self, filename):
        """
        disk-format - detect the disk format of a disk image

        Detect and return the format of the disk image called "filename",
        "filename" can also be a host device, etc
        """
        return self.inner_cmd("disk-format %s" % filename)

    def disk_has_backing_file(self, filename):
        """
        disk-has-backing-file - return whether disk has a backing file

        Detect and return whether the disk image "filename" has a backing file
        """
        return self.inner_cmd("disk-has-backing-file %s" % filename)

    def disk_virtual_size(self, filename):
        """
        disk-virtual-size - return virtual size of a disk

        Detect and return the virtual size in bytes of the disk image"
        """
        return self.inner_cmd("disk-virtual-size %s" % filename)

    def max_disks(self):
        """
        max-disks - maximum number of disks that may be added

        Return the maximum number of disks that may be added to a handle
        """
        return self.inner_cmd("max-disks")

    def nr_devices(self):
        """
        nr-devices - return number of whole block devices (disks) added

        This returns the number of whole block devices that were added
        """
        return self.inner_cmd("nr-devices")

    def scrub_device(self, device):
        """
        scrub-device - scrub (securely wipe) a device

        This command writes patterns over "device" to make data retrieval more
        difficult
        """
        return self.inner_cmd("scrub-device %s" % device)

    def scrub_file(self, file):
        """
        scrub-file - scrub (securely wipe) a file

        This command writes patterns over a file to make data retrieval more
        difficult
        """
        return self.inner_cmd("scrub-file %s" % file)

    def scrub_freespace(self, dir):
        """
        scrub-freespace - scrub (securely wipe) free space

        This command creates the directory "dir" and then fills it with files
        until the filesystem is full,and scrubs the files as for "scrub_file",
        and deletes them. The intention is to scrub any free space on the
        partition containing "dir"
        """
        return self.inner_cmd("scrub-freespace %s" % dir)

    def md_create(self, name, device, missingbitmap=None, nrdevices=None,
                  spare=None, chunk=None, level=None):
        """
        md-create - create a Linux md (RAID) device

        Create a Linux md (RAID) device named "name" on the devices in the list
        "devices".
        """
        cmd = "md-create %s %s" % (name, device)

        if missingbitmap:
            cmd += " missingbitmap:%s" % missingbitmap
        if nrdevices:
            cmd += " nrdevices:%s" % nrdevices
        if spare:
            cmd += " spare:%s" % spare
        if chunk:
            cmd += " chunk:%s" % chunk
        if level:
            cmd += " level:%s" % level

        return self.inner_cmd(cmd)

    def list_md_devices(self):
        """
        list-md-devices - list Linux md (RAID) devices

        List all Linux md devices.
        """
        return self.inner_cmd("list-md-devices")

    def md_stop(self, md):
        """
        md-stop - stop a Linux md (RAID) device

        This command deactivates the MD array named "md".
        The device is stopped, but it is not destroyed or zeroed.
        """
        return self.inner_cmd("md-stop %s" % md)

    def md_stat(self, md):
        """
        md-stat - get underlying devices from an MD device

        This call returns a list of the underlying devices which make up the
        single software RAID array device "md".
        """
        return self.inner_cmd("md-stat %s" % md)

    def md_detail(self, md):
        """
        md-detail - obtain metadata for an MD device

        This command exposes the output of 'mdadm -DY <md>'. The following
        fields are usually present in the returned hash. Other fields may also
        be present.
        """
        return self.inner_cmd("md-detail %s" % md)

    def sfdisk(self, device, cyls, heads, sectors, lines):
        """
        sfdisk - create partitions on a block device

        This is a direct interface to the sfdisk(8) program for creating
        partitions on block devices.

        *This function is deprecated.* In new code, use the "part-add" call
        instead.

        Deprecated functions will not be removed from the API, but the fact
        that they are deprecated indicates that there are problems with correct
        use of these functions.
        """
        return self.inner_cmd("sfdisk %s %s %s %s %s"
                              % (device, cyls, heads, sectors, lines))

    def sfdisk_l(self, device):
        """
        sfdisk-l - display the partition table

        This displays the partition table on "device", in the human-readable
        output of the sfdisk(8) command. It is not intended to be parsed.

        *This function is deprecated.* In new code, use the "part-list" call
        instead.
        """
        return self.inner_cmd("sfdisk-l %s" % device)

    def sfdiskM(self, device, lines):
        """
        sfdiskM - create partitions on a block device

        This is a simplified interface to the "sfdisk" command, where partition
        sizes are specified in megabytes only (rounded to the nearest cylinder)
        and you don't need to specify the cyls, heads and sectors parameters
        which were rarely if ever used anyway.

        *This function is deprecated.* In new code, use the "part-add" call
        instead.
        """
        return self.inner_cmd("sfdiskM %s %s" % (device, lines))

    def sfdisk_N(self, device, partnum, cyls, heads, sectors, line):
        """
        sfdisk-N - modify a single partition on a block device

        This runs sfdisk(8) option to modify just the single partition "n"
        (note: "n" counts from 1).

        For other parameters, see "sfdisk". You should usually pass 0 for the
        cyls/heads/sectors parameters.

        *This function is deprecated.* In new code, use the "part-add" call
        instead.
        """
        return self.inner_cmd("sfdisk-N %s %s %s %s %s %s"
                              % (device, partnum, cyls, heads, sectors, line))

    def sfdisk_disk_geometry(self, device):
        """
        sfdisk-disk-geometry - display the disk geometry from the partition
        table

        This displays the disk geometry of "device" read from the partition
        table. Especially in the case where the underlying block device has
        been resized, this can be different from the kernel's idea of the
        geometry
        """
        return self.inner_cmd("sfdisk-disk-geometry %s" % device)

    def sfdisk_kernel_geometry(self, device):
        """
        sfdisk-kernel-geometry - display the kernel geometry

        This displays the kernel's idea of the geometry of "device".
        """
        return self.inner_cmd("sfdisk-kernel-geometry %s" % device)

    def pvcreate(self, physvols):
        """
        pvcreate - create an LVM physical volume

        This creates an LVM physical volume called "physvols".
        """
        return self.inner_cmd("pvcreate %s" % (physvols))

    def vgcreate(self, volgroup, physvols):
        """
        vgcreate - create an LVM volume group

        This creates an LVM volume group called "volgroup" from the
        non-empty list of physical volumes "physvols".
        """
        return self.inner_cmd("vgcreate %s %s" % (volgroup, physvols))

    def vgs(self):
        """
        vgs - list the LVM volume groups (VGs)

        List all the volumes groups detected.
        """
        return self.inner_cmd("vgs")

    def vgrename(self, volgroup, newvolgroup):
        """
        vgrename - rename an LVM volume group

        Rename a volume group "volgroup" with the new name "newvolgroup".
        """
        return self.inner_cmd("vgrename %s %s" % (volgroup, newvolgroup))

    def vgremove(self, vgname):
        """
        vgremove - remove an LVM volume group

        Remove an LVM volume group "vgname", (for example "VG").
        """
        return self.inner_cmd("vgremove %s" % vgname)

    def lvcreate(self, logvol, volgroup, mbytes):
        """
        lvcreate - create an LVM logical volume

        This creates an LVM logical volume called "logvol" on the
        volume group "volgroup", with "size" megabytes.
        """
        return self.inner_cmd("lvcreate %s %s %s" % (logvol, volgroup, mbytes))

    def lvuuid(self, device):
        """
        lvuuid - get the UUID of a logical volume

        This command returns the UUID of the LVM LV "device".
        """
        return self.inner_cmd("lvuuid %s" % device)

    def lvm_canonical_lv_name(self, lvname):
        """
        lvm-canonical-lv-name - get canonical name of an LV

        This converts alternative naming schemes for LVs that you might
        find to the canonical name.
        """
        return self.inner_cmd("lvm-canonical-lv-name %s" % lvname)

    def lvremove(self, device):
        """
        lvremove - remove an LVM logical volume

        Remove an LVM logical volume "device", where "device" is the path
        to the LV, such as "/dev/VG/LV".
        """
        return self.inner_cmd("lvremove %s" % device)

    def lvresize(self, device, mbytes):
        """
        lvresize - resize an LVM logical volume

        This resizes (expands or shrinks) an existing LVM logical volume to
        "mbytes".
        """
        return self.inner_cmd("lvresize %s %s" % (device, mbytes))

    def lvs(self):
        """
        lvs - list the LVM logical volumes (LVs)

        List all the logical volumes detected.
        """
        return self.inner_cmd("lvs")

    def lvs_full(self):
        """
        lvs-full - list the LVM logical volumes (LVs)

        List all the logical volumes detected. This is the equivalent of the
        lvs(8) command. The "full" version includes all fields.
        """
        return self.inner_cmd("lvs-full")

    def lvm_clear_filter(self):
        """
        lvm-clear-filter - clear LVM device filter

        This undoes the effect of "lvm_set_filter". LVM will be able to see
        every block device.
        This command also clears the LVM cache and performs a volume group scan.
        """
        return self.inner_cmd("lvm-clear-filter")

    def lvm_remove_all(self):
        """
        lvm-remove-all - remove all LVM LVs, VGs and PVs

        This command removes all LVM logical volumes, volume groups and physical
        volumes.
        """
        return self.inner_cmd("lvm-remove-all")

    def lvm_set_filter(self, device):
        """
        lvm-set-filter - set LVM device filter

        This sets the LVM device filter so that LVM will only be able to "see"
        the block devices in the list "devices", and will ignore all other
        attached block devices.
        """
        return self.inner_cmd("lvm-set-filter %s" % device)

    def lvresize_free(self, lv, percent):
        """
        lvresize-free - expand an LV to fill free space

        This expands an existing logical volume "lv" so that it fills "pc"% of
        the remaining free space in the volume group. Commonly you would call
        this with pc = 100 which expands the logical volume as much as possible,
        using all remaining free space in the volume group.
        """
        return self.inner_cmd("lvresize-free %s %s" % (lv, percent))

    def vfs_type(self, mountable):
        """
        vfs-type - get the Linux VFS type corresponding to a mounted device

        Gets the filesystem type corresponding to the filesystem on "mountable"
        """
        return self.inner_cmd("vfs-type %s" % (mountable))

    def touch(self, path):
        """
        touch - update file timestamps or create a new file

        Touch acts like the touch(1) command. It can be used to update the
        timestamps on a file, or, if the file does not exist, to create a new
        zero-length file.
        """
        return self.inner_cmd("touch %s" % (path))

    def umount_all(self):
        """
        umount-all - unmount all filesystems

        This unmounts all mounted filesystems.
        Some internal mounts are not unmounted by this call.
        """
        return self.inner_cmd("umount-all")

    def ll(self, directory):
        """
        ll - list the files in a directory (long format)

        List the files in "directory" (relative to the root directory, there is
        no cwd) in the format of 'ls -la'.
        """
        return self.inner_cmd("ll %s" % (directory))

    def sync(self):
        """
        lsync - sync disks, writes are flushed through to the disk image

        This syncs the disk, so that any writes are flushed through to the
        underlying disk image.
        """
        return self.inner_cmd("sync")

# libguestfs module functions follow #####


def libguest_test_tool_cmd(qemuarg=None, qemudirarg=None,
                           timeoutarg=None, ignore_status=True,
                           debug=False, timeout=60):
    """
    Execute libguest-test-tool command.

    :param qemuarg: the qemu option
    :param qemudirarg: the qemudir option
    :param timeoutarg: the timeout option
    :return: a CmdResult object
    :raise: raise LibguestfsCmdError
    """
    cmd = "libguestfs-test-tool"
    if qemuarg is not None:
        cmd += " --qemu '%s'" % qemuarg
    if qemudirarg is not None:
        cmd += " --qemudir '%s'" % qemudirarg
    if timeoutarg is not None:
        cmd += " --timeout %s" % timeoutarg

    # Allow to raise LibguestfsCmdError if ignore_status is False.
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_edit_cmd(disk_or_domain, file_path, is_disk=False, options=None,
                  extra=None, expr=None, connect_uri=None, ignore_status=True,
                  debug=False, timeout=60):
    """
    Execute virt-edit command to check whether it is ok.

    Since virt-edit will need uses' interact, maintain and return
    a session if there is no raise after command has been executed.

    :param disk_or_domain: a img path or a domain name.
    :param file_path: the file need to be edited in img file.
    :param options: the options of virt-edit.
    :param extra: additional suffix of command.
    :return: a session of executing virt-edit command.
    """
    # disk_or_domain and file_path are necessary parameters.
    cmd = "virt-edit"
    if connect_uri is not None:
        cmd += " -c %s" % connect_uri
    if is_disk:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    cmd += " %s" % file_path
    if options is not None:
        cmd += " %s" % options
    if extra is not None:
        cmd += " %s" % extra
    if expr is not None:
        cmd += " -e '%s'" % expr

    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_clone_cmd(original, newname=None, autoclone=False, **dargs):
    """
    Clone existing virtual machine images.

    :param original: Name of the original guest to be cloned.
    :param newname: Name of the new guest virtual machine instance.
    :param autoclone: Generate a new guest name, and paths for new storage.
    :param dargs: Standardized function API keywords. There are many
                  options not listed, they can be passed in dargs.
    """
    def storage_config(cmd, options):
        """Configure options for storage"""
        # files should be a list
        files = options.get("files", [])
        if len(files):
            for file in files:
                cmd += " --file '%s'" % file
        if options.get("nonsparse") is not None:
            cmd += " --nonsparse"
        return cmd

    def network_config(cmd, options):
        """Configure options for network"""
        mac = options.get("mac")
        if mac is not None:
            cmd += " --mac '%s'" % mac
        return cmd

    cmd = "virt-clone --original '%s'" % original
    if newname is not None:
        cmd += " --name '%s'" % newname
    if autoclone is True:
        cmd += " --auto-clone"
    # Many more options can be added if necessary.
    cmd = storage_config(cmd, dargs)
    cmd = network_config(cmd, dargs)

    ignore_status = dargs.get("ignore_status", True)
    debug = dargs.get("debug", False)
    timeout = dargs.get("timeout", 60)

    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_sparsify_cmd(indisk, outdisk, compress=False, convert=None,
                      format=None, ignore_status=True, debug=False,
                      timeout=60):
    """
    Make a virtual machine disk sparse.

    :param indisk: The source disk to be sparsified.
    :param outdisk: The destination disk.
    """
    cmd = "virt-sparsify"
    if compress is True:
        cmd += " --compress"
    if format is not None:
        cmd += " --format '%s'" % format
    cmd += " '%s'" % indisk

    if convert is not None:
        cmd += " --convert '%s'" % convert
    cmd += " '%s'" % outdisk
    # More options can be added if necessary.

    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_resize_cmd(indisk, outdisk, **dargs):
    """
    Resize a virtual machine disk.

    :param indisk: The source disk to be resized
    :param outdisk: The destination disk.
    """
    cmd = "virt-resize"
    ignore_status = dargs.get("ignore_status", True)
    debug = dargs.get("debug", False)
    timeout = dargs.get("timeout", 60)
    resize = dargs.get("resize")
    resized_size = dargs.get("resized_size", "0")
    expand = dargs.get("expand")
    shrink = dargs.get("shrink")
    ignore = dargs.get("ignore")
    delete = dargs.get("delete")
    if resize is not None:
        cmd += " --resize %s=%s" % (resize, resized_size)
    if expand is not None:
        cmd += " --expand %s" % expand
    if shrink is not None:
        cmd += " --shrink %s" % shrink
    if ignore is not None:
        cmd += " --ignore %s" % ignore
    if delete is not None:
        cmd += " --delete %s" % delete
    cmd += " %s %s" % (indisk, outdisk)

    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_list_partitions_cmd(disk_or_domain, long=False, total=False,
                             human_readable=False, ignore_status=True,
                             debug=False, timeout=60):
    """
    "virt-list-partitions" is a command line tool to list the partitions
    that are contained in a virtual machine or disk image.

    :param disk_or_domain: a disk or a domain to be mounted
    """
    cmd = "virt-list-partitions %s" % disk_or_domain
    if long is True:
        cmd += " --long"
    if total is True:
        cmd += " --total"
    if human_readable is True:
        cmd += " --human-readable"
    return lgf_command(cmd, ignore_status, debug, timeout)


def guestmount(disk_or_domain, mountpoint, inspector=False,
               readonly=False, **dargs):
    """
    guestmount - Mount a guest filesystem on the host using
                 FUSE and libguestfs.

    :param disk_or_domain: a disk or a domain to be mounted
           If you need to mount a disk, set is_disk to True in dargs
    :param mountpoint: the mountpoint of filesystems
    :param inspector: mount all filesystems automatically
    :param readonly: if mount filesystem with readonly option
    """
    def get_special_mountpoint(cmd, options):
        special_mountpoints = options.get("special_mountpoints", [])
        for mountpoint in special_mountpoints:
            cmd += " -m %s" % mountpoint
        return cmd

    cmd = "guestmount"
    ignore_status = dargs.get("ignore_status", True)
    debug = dargs.get("debug", False)
    timeout = dargs.get("timeout", 60)
    # If you need to mount a disk, set is_disk to True
    is_disk = dargs.get("is_disk", False)
    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    if inspector is True:
        cmd += " -i"
    if readonly is True:
        cmd += " --ro"
    cmd = get_special_mountpoint(cmd, dargs)
    cmd += " %s" % mountpoint
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_filesystems(disk_or_domain, **dargs):
    """
    virt-filesystems - List filesystems, partitions, block devices,
    LVM in a virtual machine or disk image

    :param disk_or_domain: a disk or a domain to be mounted
           If you need to mount a disk, set is_disk to True in dargs
    """
    def get_display_type(cmd, options):
        all = options.get("all", False)
        filesystems = options.get("filesystems", False)
        extra = options.get("extra", False)
        partitions = options.get("partitions", False)
        block_devices = options.get("block_devices", False)
        logical_volumes = options.get("logical_volumes", False)
        volume_groups = options.get("volume_groups", False)
        physical_volumes = options.get("physical_volumes", False)
        long_format = options.get("long_format", False)
        human_readable = options.get("human_readable", False)
        if all is True:
            cmd += " --all"
        if filesystems is True:
            cmd += " --filesystems"
        if extra is True:
            cmd += " --extra"
        if partitions is True:
            cmd += " --partitions"
        if block_devices is True:
            cmd += " --block_devices"
        if logical_volumes is True:
            cmd += " --logical_volumes"
        if volume_groups is True:
            cmd += " --volume_groups"
        if physical_volumes is True:
            cmd += " --physical_volumes"
        if long_format is True:
            cmd += " --long"
        if human_readable is True:
            cmd += " -h"
        return cmd

    cmd = "virt-filesystems"
    # If you need to mount a disk, set is_disk to True
    is_disk = dargs.get("is_disk", False)
    ignore_status = dargs.get("ignore_status", True)
    debug = dargs.get("debug", False)
    timeout = dargs.get("timeout", 60)

    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    cmd = get_display_type(cmd, dargs)
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_list_partitions(disk_or_domain, long=False, total=False,
                         human_readable=False, ignore_status=True,
                         debug=False, timeout=60):
    """
    "virt-list-partitions" is a command line tool to list the partitions
    that are contained in a virtual machine or disk image.

    :param disk_or_domain: a disk or a domain to be mounted
    """
    cmd = "virt-list-partitions %s" % disk_or_domain
    if long is True:
        cmd += " --long"
    if total is True:
        cmd += " --total"
    if human_readable is True:
        cmd += " --human-readable"
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_list_filesystems(disk_or_domain, format=None, long=False,
                          all=False, ignore_status=True, debug=False,
                          timeout=60):
    """
    "virt-list-filesystems" is a command line tool to list the filesystems
    that are contained in a virtual machine or disk image.

    :param disk_or_domain: a disk or a domain to be mounted
    """
    cmd = "virt-list-filesystems %s" % disk_or_domain
    if format is not None:
        cmd += " --format %s" % format
    if long is True:
        cmd += " --long"
    if all is True:
        cmd += " --all"
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_df(disk_or_domain, ignore_status=True, debug=False, timeout=60):
    """
    "virt-df" is a command line tool to display free space on
    virtual machine filesystems.
    """
    cmd = "virt-df %s" % disk_or_domain
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_sysprep_cmd(disk_or_domain, options=None,
                     extra=None, ignore_status=True,
                     debug=False, timeout=600):
    """
    Execute virt-sysprep command to reset or unconfigure a virtual machine.

    :param disk_or_domain: a img path or a domain name.
    :param options: the options of virt-sysprep.
    :return: a CmdResult object.
    """
    if os.path.isfile(disk_or_domain):
        disk_or_domain = "-a " + disk_or_domain
    else:
        disk_or_domain = "-d " + disk_or_domain
    cmd = "virt-sysprep %s" % (disk_or_domain)
    if options is not None:
        cmd += " %s" % options
    if extra is not None:
        cmd += " %s" % extra

    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_cat_cmd(disk_or_domain, file_path, options=None, ignore_status=True,
                 debug=False, timeout=60):
    """
    Execute virt-cat command to print guest's file detail.

    :param disk_or_domain: a img path or a domain name.
    :param file_path: the file to print detail
    :param options: the options of virt-cat.
    :return: a CmdResult object.
    """
    # disk_or_domain and file_path are necessary parameters.
    if os.path.isfile(disk_or_domain):
        disk_or_domain = "-a " + disk_or_domain
    else:
        disk_or_domain = "-d " + disk_or_domain
    cmd = "virt-cat %s '%s'" % (disk_or_domain, file_path)
    if options is not None:
        cmd += " %s" % options

    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_tar_in(disk_or_domain, tar_file, destination, is_disk=False,
                ignore_status=True, debug=False, timeout=60):
    """
    "virt-tar-in" unpacks an uncompressed tarball into a virtual machine
    disk image or named libvirt domain.
    """
    cmd = "virt-tar-in"
    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    cmd += " %s %s" % (tar_file, destination)
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_tar_out(disk_or_domain, directory, tar_file, is_disk=False,
                 ignore_status=True, debug=False, timeout=60):
    """
    "virt-tar-out" packs a virtual machine disk image directory into a tarball.
    """
    cmd = "virt-tar-out"
    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    cmd += " %s %s" % (directory, tar_file)
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_copy_in(disk_or_domain, file, destination, is_disk=False,
                 ignore_status=True, debug=False, timeout=60):
    """
    "virt-copy-in" copies files and directories from the local disk into a
    virtual machine disk image or named libvirt domain.
    #TODO: expand file to files
    """
    cmd = "virt-copy-in"
    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    cmd += " %s %s" % (file, destination)
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_copy_out(disk_or_domain, file_path, localdir, is_disk=False,
                  ignore_status=True, debug=False, timeout=60):
    """
    "virt-copy-out" copies files and directories out of a virtual machine
    disk image or named libvirt domain.
    """
    cmd = "virt-copy-out"
    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    cmd += " %s %s" % (file_path, localdir)
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_format(disk, filesystem=None, image_format=None, lvm=None,
                partition=None, wipe=False, ignore_status=False,
                debug=False, timeout=60):
    """
    Virt-format takes an existing disk file (or it can be a host partition,
    LV etc), erases all data on it, and formats it as a blank disk.
    """
    cmd = "virt-format -a %s" % disk
    if filesystem is not None:
        cmd += " --filesystem=%s" % filesystem
    if image_format is not None:
        cmd += " --format=%s" % image_format
    if lvm is not None:
        cmd += " --lvm=%s" % lvm
    if partition is not None:
        cmd += " --partition=%s" % partition
    if wipe is True:
        cmd += " --wipe"
    return lgf_command(cmd, ignore_status, debug, timeout)


def virt_inspector(disk_or_domain, is_disk=False, ignore_status=True,
                   debug=False, timeout=30):
    """
    virt-inspector2 examines a virtual machine or disk image and tries to
    determine the version of the operating system and other information
    about the virtual machine.
    """
    # virt-inspector has been replaced by virt-inspector2 in RHEL7
    # Check it here to choose which one to be used.
    cmd = lgf_cmd_check("virt-inspector2")
    if cmd is None:
        cmd = "virt-inspector"

    # If you need to mount a disk, set is_disk to True
    if is_disk is True:
        cmd += " -a %s" % disk_or_domain
    else:
        cmd += " -d %s" % disk_or_domain
    return lgf_command(cmd, ignore_status, debug, timeout)

########NEW FILE########
__FILENAME__ = utils_libguestfs_unittest
#!/usr/bin/python
import unittest
import logging

import common
from autotest.client import os_dep
import utils_libguestfs as lgf


class LibguestfsTest(unittest.TestCase):

    def test_lgf_cmd_check(self):
        cmds = ['virt-ls', 'virt-cat']
        for cmd in cmds:
            try:
                os_dep.command(cmd)
                self.assertTrue(lgf.lgf_cmd_check(cmd))
            except ValueError:
                logging.warning("Command %s not installed, skipping "
                                "unittest...", cmd)

    def test_lgf_cmd_check_raises(self):
        cmds = ['virt-test-fail', '']
        for cmd in cmds:
            self.assertRaises(lgf.LibguestfsCmdError,
                              lgf.lgf_cmd_check, cmd)

    def test_lgf_cmd(self):
        cmd = "libguestfs-test-tool"
        try:
            os_dep.command(cmd)
            self.assertEqual(lgf.lgf_command(cmd).exit_status, 0)
        except ValueError:
            logging.warning("Command %s not installed, skipping unittest...",
                            cmd)


class SlotsCheckTest(unittest.TestCase):

    def test_LibguestfsBase_default_slots(self):
        """Default slots' value check"""
        lfb = lgf.LibguestfsBase()
        self.assertEqual(lfb.ignore_status, True)
        self.assertEqual(lfb.debug, False)
        self.assertEqual(lfb.timeout, 60)
        self.assertEqual(lfb.uri, None)
        self.assertEqual(lfb.lgf_exec, "/bin/true")

    def test_LibguestfsBase_update_slots(self):
        """Update slots"""
        lfb = lgf.LibguestfsBase()
        lfb.set_ignore_status(False)
        self.assertEqual(lfb.ignore_status, False)
        lfb.set_debug(True)
        self.assertEqual(lfb.debug, True)
        lfb.set_timeout(240)
        self.assertEqual(lfb.timeout, 240)

    def test_Guestfish_slots(self):
        """Test Guestfish slots"""
        try:
            gf = lgf.Guestfish()
            self.assertEqual(gf.lgf_exec, "guestfish")
            gf = lgf.Guestfish(
                disk_img="test.img", ro_mode=True, inspector=True)
            self.assertEqual(gf.lgf_exec, "guestfish -a 'test.img' --ro -i")
            gf = lgf.Guestfish(libvirt_domain="test", inspector=True,
                               uri="qemu+ssh://root@EXAMPLE/system")
            gf_cmd = "guestfish -c 'qemu+ssh://root@EXAMPLE/system' -d 'test' -i"
            self.assertEqual(gf.lgf_exec, gf_cmd)
        except lgf.LibguestfsCmdError:
            logging.warning("Command guestfish not present, skipping "
                            "unittest...")


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = utils_libvirtd
"""
Module to control libvirtd service.
"""
import logging

from virttest import remote, utils_misc
from autotest.client import utils, os_dep
from virttest.staging import service


try:
    os_dep.command("libvirtd")
    LIBVIRTD = "libvirtd"
except ValueError:
    LIBVIRTD = None


class Libvirtd(object):

    """
    Class to manage libvirtd service on host or guest.
    """

    def __init__(self, session=None):
        """
        Initialize an service object for libvirtd.

        :params session: An session to guest or remote host.
        """
        self.session = session

        if self.session:
            self.remote_runner = remote.RemoteRunner(session=self.session)
            runner = self.remote_runner.run
        else:
            runner = utils.run

        if LIBVIRTD is None:
            logging.warning("Libvirtd service is not available in host, "
                            "utils_libvirtd module will not function normally")
        self.libvirtd = service.Factory.create_service(LIBVIRTD, run=runner)

    def _wait_for_start(self, timeout=60):
        """
        Wait n seconds for libvirt to start. Default is 10 seconds.
        """
        def _check_start():
            virsh_cmd = "virsh list"
            try:
                if self.session:
                    self.session.cmd(virsh_cmd, timeout=2)
                else:
                    utils.run(virsh_cmd, timeout=2)
                return True
            except:
                return False
        return utils_misc.wait_for(_check_start, timeout=timeout)

    def start(self):
        # pylint: disable=E1103
        self.libvirtd.start()
        return self._wait_for_start()

    def stop(self):
        # pylint: disable=E1103
        self.libvirtd.stop()

    def restart(self):
        # pylint: disable=E1103
        self.libvirtd.restart()
        return self._wait_for_start()

    def is_running(self):
        # pylint: disable=E1103
        return self.libvirtd.status()


def deprecation_warning():
    """
    As the utils_libvirtd.libvirtd_xxx interfaces are deprecated,
    this function are printing the warning to user.
    """
    logging.warning("This function was deprecated, Please use "
                    "class utils_libvirtd.Libvirtd to manage "
                    "libvirtd service.")


def libvirtd_start():
    libvirtd_instance = Libvirtd()
    deprecation_warning()
    return libvirtd_instance.start()


def libvirtd_is_running():
    libvirtd_instance = Libvirtd()
    deprecation_warning()
    return libvirtd_instance.is_running()


def libvirtd_stop():
    libvirtd_instance = Libvirtd()
    deprecation_warning()
    return libvirtd_instance.stop()


def libvirtd_restart():
    libvirtd_instance = Libvirtd()
    deprecation_warning()
    return libvirtd_instance.restart()


def service_libvirtd_control(action):
    libvirtd_instance = Libvirtd()
    deprecation_warning()
    getattr(libvirtd_instance, action)()

########NEW FILE########
__FILENAME__ = utils_misc
"""
Virtualization test utility functions.

:copyright: 2008-2009 Red Hat Inc.
"""

import time
import string
import random
import socket
import os
import stat
import signal
import re
import logging
import commands
import fcntl
import sys
import inspect
import tarfile
import shutil
import getpass
import ctypes
from autotest.client import utils, os_dep
from autotest.client.shared import error, logging_config
from autotest.client.shared import git
import data_dir
try:
    from staging import utils_koji
except ImportError:
    from autotest.client.shared import utils_koji


import platform
ARCH = platform.machine()


class UnsupportedCPU(error.TestError):
    pass

# TODO: remove this import when log_last_traceback is moved to autotest
import traceback

# TODO: this function is being moved into autotest. For compatibility
# reasons keep it here too but new code should use the one from base_utils.


def log_last_traceback(msg=None, log=logging.error):
    """
    Writes last traceback into specified log.

    :warning: This function is being moved into autotest and your code should
              use autotest.client.shared.base_utils function instead.

    :param msg: Override the default message. ["Original traceback"]
    :param log: Where to log the traceback [logging.error]
    """
    if not log:
        log = logging.error
    if msg:
        log(msg)
    exc_type, exc_value, exc_traceback = sys.exc_info()
    if not exc_traceback:
        log('Requested log_last_traceback but no exception was raised.')
        return
    log("Original " +
        "".join(traceback.format_exception(exc_type, exc_value,
                                           exc_traceback)))


def aton(sr):
    """
    Transform a string to a number(include float and int). If the string is
    not in the form of number, just return false.

    :param sr: string to transfrom
    :return: float, int or False for failed transform
    """
    try:
        return int(sr)
    except ValueError:
        try:
            return float(sr)
        except ValueError:
            return False


def find_substring(string, pattern1, pattern2=None):
    """
    Return the match of pattern1 in string. Or return the match of pattern2
    if pattern is not matched.

    :param string: string
    :param pattern1: first pattern want to match in string, must set.
    :param pattern2: second pattern, it will be used if pattern1 not match, optional.

    :return: Match substing or None
    """
    if not pattern1:
        logging.debug("pattern1: get empty string.")
        return None
    pattern = pattern1
    if pattern2:
        pattern += "|%s" % pattern2
    ret = re.findall(pattern, string)
    if not ret:
        logging.debug("Could not find matched string with pattern: %s",
                      pattern)
        return None
    return ret[0]


def lock_file(filename, mode=fcntl.LOCK_EX):
    lockfile = open(filename, "w")
    fcntl.lockf(lockfile, mode)
    return lockfile


def unlock_file(lockfile):
    fcntl.lockf(lockfile, fcntl.LOCK_UN)
    lockfile.close()


# Utility functions for dealing with external processes


def unique(llist):
    """
    Return a list of the elements in list, but without duplicates.

    :param list: List with values.
    :return: List with non duplicate elements.
    """
    n = len(llist)
    if n == 0:
        return []
    u = {}
    try:
        for x in llist:
            u[x] = 1
    except TypeError:
        return None
    else:
        return u.keys()


def find_command(cmd):
    """
    Try to find a command in the PATH, paranoid version.

    :param cmd: Command to be found.
    :raise: ValueError in case the command was not found.
    """
    common_bin_paths = ["/usr/libexec", "/usr/local/sbin", "/usr/local/bin",
                        "/usr/sbin", "/usr/bin", "/sbin", "/bin"]
    try:
        path_paths = os.environ['PATH'].split(":")
    except IndexError:
        path_paths = []
    path_paths = unique(common_bin_paths + path_paths)

    for dir_path in path_paths:
        cmd_path = os.path.join(dir_path, cmd)
        if os.path.isfile(cmd_path):
            return os.path.abspath(cmd_path)

    raise ValueError('Missing command: %s' % cmd)


def pid_exists(pid):
    """
    Return True if a given PID exists.

    :param pid: Process ID number.
    """
    try:
        os.kill(pid, 0)
        return True
    except Exception:
        return False


def safe_kill(pid, signal):
    """
    Attempt to send a signal to a given process that may or may not exist.

    :param signal: Signal number.
    """
    try:
        os.kill(pid, signal)
        return True
    except Exception:
        return False


def kill_process_tree(pid, sig=signal.SIGKILL):
    """Signal a process and all of its children.

    If the process does not exist -- return.

    :param pid: The pid of the process to signal.
    :param sig: The signal to send to the processes.
    """
    if not safe_kill(pid, signal.SIGSTOP):
        return
    children = commands.getoutput("ps --ppid=%d -o pid=" % pid).split()
    for child in children:
        kill_process_tree(int(child), sig)
    safe_kill(pid, sig)
    safe_kill(pid, signal.SIGCONT)


def get_open_fds(pid):
    return len(os.listdir('/proc/%s/fd' % pid))


def get_virt_test_open_fds():
    return get_open_fds(os.getpid())


def process_or_children_is_defunct(ppid):
    """Verify if any processes from PPID is defunct.

    Attempt to verify if parent process and any children from PPID is defunct
    (zombie) or not.
    :param ppid: The parent PID of the process to verify.
    """
    defunct = False
    try:
        pids = utils.get_children_pids(ppid)
    except error.CmdError:  # Process doesn't exist
        return True
    for pid in pids:
        cmd = "ps --no-headers -o cmd %d" % int(pid)
        proc_name = utils.system_output(cmd, ignore_status=True)
        if '<defunct>' in proc_name:
            defunct = True
            break
    return defunct

# The following are utility functions related to ports.


def is_port_free(port, address):
    """
    Return True if the given port is available for use.

    :param port: Port number
    """
    try:
        s = socket.socket()
        #s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        if address == "localhost":
            s.bind(("localhost", port))
            free = True
        else:
            s.connect((address, port))
            free = False
    except socket.error:
        if address == "localhost":
            free = False
        else:
            free = True
    s.close()
    return free


def find_free_port(start_port, end_port, address="localhost"):
    """
    Return a host free port in the range [start_port, end_port].

    :param start_port: First port that will be checked.
    :param end_port: Port immediately after the last one that will be checked.
    """
    for i in range(start_port, end_port):
        if is_port_free(i, address):
            return i
    return None


def find_free_ports(start_port, end_port, count, address="localhost"):
    """
    Return count of host free ports in the range [start_port, end_port].

    :param count: Initial number of ports known to be free in the range.
    :param start_port: First port that will be checked.
    :param end_port: Port immediately after the last one that will be checked.
    """
    ports = []
    i = start_port
    while i < end_port and count > 0:
        if is_port_free(i, address):
            ports.append(i)
            count -= 1
        i += 1
    return ports


# An easy way to log lines to files when the logging system can't be used

_open_log_files = {}
_log_file_dir = "/tmp"


def log_line(filename, line):
    """
    Write a line to a file.

    :param filename: Path of file to write to, either absolute or relative to
                     the dir set by set_log_file_dir().
    :param line: Line to write.
    """
    global _open_log_files, _log_file_dir

    path = get_path(_log_file_dir, filename)
    if path not in _open_log_files:
        # First, let's close the log files opened in old directories
        close_log_file(filename)
        # Then, let's open the new file
        try:
            os.makedirs(os.path.dirname(path))
        except OSError:
            pass
        _open_log_files[path] = open(path, "w")
    timestr = time.strftime("%Y-%m-%d %H:%M:%S")
    _open_log_files[path].write("%s: %s\n" % (timestr, line))
    _open_log_files[path].flush()


def set_log_file_dir(directory):
    """
    Set the base directory for log files created by log_line().

    :param dir: Directory for log files.
    """
    global _log_file_dir
    _log_file_dir = directory


def close_log_file(filename):
    global _open_log_files, _log_file_dir
    remove = []
    for k in _open_log_files:
        if os.path.basename(k) == filename:
            f = _open_log_files[k]
            f.close()
            remove.append(k)
    if remove:
        for key_to_remove in remove:
            _open_log_files.pop(key_to_remove)


# The following are miscellaneous utility functions.

def get_path(base_path, user_path):
    """
    Translate a user specified path to a real path.
    If user_path is relative, append it to base_path.
    If user_path is absolute, return it as is.

    :param base_path: The base path of relative user specified paths.
    :param user_path: The user specified path.
    """
    if os.path.isabs(user_path):
        return user_path
    else:
        return os.path.join(base_path, user_path)


def generate_random_string(length, ignore_str=string.punctuation,
                           convert_str=""):
    """
    Return a random string using alphanumeric characters.

    :param length: Length of the string that will be generated.
    :param ignore_str: Characters that will not include in generated string.
    :param convert_str: Characters that need to be escaped (prepend "\\").

    :return: The generated random string.
    """
    r = random.SystemRandom()
    sr = ""
    chars = string.letters + string.digits + string.punctuation
    if not ignore_str:
        ignore_str = ""
    for i in ignore_str:
        chars = chars.replace(i, "")

    while length > 0:
        tmp = r.choice(chars)
        if convert_str and (tmp in convert_str):
            tmp = "\\%s" % tmp
        sr += tmp
        length -= 1
    return sr


def generate_random_id():
    """
    Return a random string suitable for use as a qemu id.
    """
    return "id" + generate_random_string(6)


def generate_tmp_file_name(file_name, ext=None, directory='/tmp/'):
    """
    Returns a temporary file name. The file is not created.
    """
    while True:
        file_name = (file_name + '-' + time.strftime("%Y%m%d-%H%M%S-") +
                     generate_random_string(4))
        if ext:
            file_name += '.' + ext
        file_name = os.path.join(directory, file_name)
        if not os.path.exists(file_name):
            break

    return file_name


def format_str_for_message(sr):
    """
    Format str so that it can be appended to a message.
    If str consists of one line, prefix it with a space.
    If str consists of multiple lines, prefix it with a newline.

    :param str: string that will be formatted.
    """
    lines = str.splitlines()
    num_lines = len(lines)
    sr = "\n".join(lines)
    if num_lines == 0:
        return ""
    elif num_lines == 1:
        return " " + sr
    else:
        return "\n" + sr


def wait_for(func, timeout, first=0.0, step=1.0, text=None):
    """
    Wait until func() evaluates to True.

    If func() evaluates to True before timeout expires, return the
    value of func(). Otherwise return None.

    :param timeout: Timeout in seconds
    :param first: Time to sleep before first attempt
    :param steps: Time to sleep between attempts in seconds
    :param text: Text to print while waiting, for debug purposes
    """
    start_time = time.time()
    end_time = time.time() + timeout

    time.sleep(first)

    while time.time() < end_time:
        if text:
            logging.debug("%s (%f secs)", text, (time.time() - start_time))

        output = func()
        if output:
            return output

        time.sleep(step)

    return None


def get_hash_from_file(hash_path, dvd_basename):
    """
    Get the a hash from a given DVD image from a hash file
    (Hash files are usually named MD5SUM or SHA1SUM and are located inside the
    download directories of the DVDs)

    :param hash_path: Local path to a hash file.
    :param cd_image: Basename of a CD image
    """
    hash_file = open(hash_path, 'r')
    for line in hash_file.readlines():
        if dvd_basename in line:
            return line.split()[0]


def run_tests(parser, job):
    """
    Runs the sequence of KVM tests based on the list of dictionaries
    generated by the configuration system, handling dependencies.

    :param parser: Config parser object.
    :param job: Autotest job object.

    :return: True, if all tests ran passed, False if any of them failed.
    """
    last_index = -1
    for i, d in enumerate(parser.get_dicts()):
        logging.info("Test %4d:  %s" % (i + 1, d["shortname"]))
        last_index += 1

    status_dict = {}
    failed = False
    # Add the parameter decide if setup host env in the test case
    # For some special tests we only setup host in the first and last case
    # When we need to setup host env we need the host_setup_flag as following:
    #    0(00): do nothing
    #    1(01): setup env
    #    2(10): cleanup env
    #    3(11): setup and cleanup env
    index = 0
    setup_flag = 1
    cleanup_flag = 2
    for param_dict in parser.get_dicts():
        if param_dict.get("host_setup_flag", None) is not None:
            flag = int(param_dict["host_setup_flag"])
            if index == 0:
                param_dict["host_setup_flag"] = flag | setup_flag
            elif index == last_index:
                param_dict["host_setup_flag"] = flag | cleanup_flag
            else:
                param_dict["host_setup_flag"] = flag
        else:
            if index == 0:
                param_dict["host_setup_flag"] = setup_flag
            elif index == last_index:
                param_dict["host_setup_flag"] = cleanup_flag
        index += 1

        # Add kvm module status
        sysfs_dir = param_dict.get("sysfs_dir", "/sys")
        param_dict["kvm_default"] = get_module_params(sysfs_dir, 'kvm')

        if param_dict.get("skip") == "yes":
            continue
        dependencies_satisfied = True
        for dep in param_dict.get("dep"):
            for test_name in status_dict.keys():
                if dep not in test_name:
                    continue
                # So the only really non-fatal state is WARN,
                # All the others make it not safe to proceed with dependency
                # execution
                if status_dict[test_name] not in ['GOOD', 'WARN']:
                    dependencies_satisfied = False
                    break
        test_iterations = int(param_dict.get("iterations", 1))
        test_tag = param_dict.get(
            "vm_type") + "." + param_dict.get("shortname")

        if dependencies_satisfied:
            # Setting up profilers during test execution.
            profilers = param_dict.get("profilers", "").split()
            for profiler in profilers:
                job.profilers.add(profiler, **param_dict)
            # We need only one execution, profiled, hence we're passing
            # the profile_only parameter to job.run_test().
            profile_only = bool(profilers) or None
            test_timeout = int(param_dict.get("test_timeout", 14400))
            current_status = job.run_test_detail("virt",
                                                 params=param_dict,
                                                 tag=test_tag,
                                                 iterations=test_iterations,
                                                 profile_only=profile_only,
                                                 timeout=test_timeout)
            for profiler in profilers:
                job.profilers.delete(profiler)
        else:
            # We will force the test to fail as TestNA during preprocessing
            param_dict['dependency_failed'] = 'yes'
            current_status = job.run_test_detail("virt",
                                                 params=param_dict,
                                                 tag=test_tag,
                                                 iterations=test_iterations)

        if not current_status:
            failed = True
        status_dict[param_dict.get("name")] = current_status

    return not failed


def display_attributes(instance):
    """
    Inspects a given class instance attributes and displays them, convenient
    for debugging.
    """
    logging.debug("Attributes set:")
    for member in inspect.getmembers(instance):
        name, value = member
        attribute = getattr(instance, name)
        if not (name.startswith("__") or callable(attribute) or not value):
            logging.debug("    %s: %s", name, value)


def get_full_pci_id(pci_id):
    """
    Get full PCI ID of pci_id.

    :param pci_id: PCI ID of a device.
    """
    cmd = "lspci -D | awk '/%s/ {print $1}'" % pci_id
    status, full_id = commands.getstatusoutput(cmd)
    if status != 0:
        return None
    return full_id


def get_vendor_from_pci_id(pci_id):
    """
    Check out the device vendor ID according to pci_id.

    :param pci_id: PCI ID of a device.
    """
    cmd = "lspci -n | awk '/%s/ {print $3}'" % pci_id
    return re.sub(":", " ", commands.getoutput(cmd))


def get_archive_tarball_name(source_dir, tarball_name, compression):
    '''
    Get the name for a tarball file, based on source, name and compression
    '''
    if tarball_name is None:
        tarball_name = os.path.basename(source_dir)

    if not tarball_name.endswith('.tar'):
        tarball_name = '%s.tar' % tarball_name

    if compression and not tarball_name.endswith('.%s' % compression):
        tarball_name = '%s.%s' % (tarball_name, compression)

    return tarball_name


def archive_as_tarball(source_dir, dest_dir, tarball_name=None,
                       compression='bz2', verbose=True):
    '''
    Saves the given source directory to the given destination as a tarball

    If the name of the archive is omitted, it will be taken from the
    source_dir. If it is an absolute path, dest_dir will be ignored. But,
    if both the destination directory and tarball anem is given, and the
    latter is not an absolute path, they will be combined.

    For archiving directory '/tmp' in '/net/server/backup' as file
    'tmp.tar.bz2', simply use:

    >>> utils_misc.archive_as_tarball('/tmp', '/net/server/backup')

    To save the file it with a different name, say 'host1-tmp.tar.bz2'
    and save it under '/net/server/backup', use:

    >>> utils_misc.archive_as_tarball('/tmp', '/net/server/backup',
                                      'host1-tmp')

    To save with gzip compression instead (resulting in the file
    '/net/server/backup/host1-tmp.tar.gz'), use:

    >>> utils_misc.archive_as_tarball('/tmp', '/net/server/backup',
                                      'host1-tmp', 'gz')
    '''
    tarball_name = get_archive_tarball_name(source_dir,
                                            tarball_name,
                                            compression)
    if not os.path.isabs(tarball_name):
        tarball_path = os.path.join(dest_dir, tarball_name)
    else:
        tarball_path = tarball_name

    if verbose:
        logging.debug('Archiving %s as %s' % (source_dir,
                                              tarball_path))

    os.chdir(os.path.dirname(source_dir))
    tarball = tarfile.TarFile(name=tarball_path, mode='w')
    tarball = tarball.open(name=tarball_path, mode='w:%s' % compression)
    tarball.add(os.path.basename(source_dir))
    tarball.close()


def parallel(targets):
    """
    Run multiple functions in parallel.

    :param targets: A sequence of tuples or functions.  If it's a sequence of
            tuples, each tuple will be interpreted as (target, args, kwargs) or
            (target, args) or (target,) depending on its length.  If it's a
            sequence of functions, the functions will be called without
            arguments.
    :return: A list of the values returned by the functions called.
    """
    threads = []
    for target in targets:
        if isinstance(target, tuple) or isinstance(target, list):
            t = utils.InterruptedThread(*target)
        else:
            t = utils.InterruptedThread(target)
        threads.append(t)
        t.start()
    return [t.join() for t in threads]


class VirtLoggingConfig(logging_config.LoggingConfig):

    """
    Used with the sole purpose of providing convenient logging setup
    for the KVM test auxiliary programs.
    """

    def configure_logging(self, results_dir=None, verbose=False):
        super(VirtLoggingConfig, self).configure_logging(use_console=True,
                                                         verbose=verbose)


def umount(src, mount_point, fstype, verbose=False, fstype_mtab=None):
    """
    Umount the src mounted in mount_point.

    :src: mount source
    :mount_point: mount point
    :type: file system type
    :param fstype_mtab: file system type in mtab could be different
    :type fstype_mtab: str
    """
    if fstype_mtab is None:
        fstype_mtab = fstype

    if is_mounted(src, mount_point, fstype, None, verbose, fstype_mtab):
        umount_cmd = "umount %s" % mount_point
        try:
            utils.system(umount_cmd, verbose=verbose)
            return True
        except error.CmdError:
            return False
    else:
        logging.debug("%s is not mounted under %s", src, mount_point)
        return True


def mount(src, mount_point, fstype, perm=None, verbose=False, fstype_mtab=None):
    """
    Mount the src into mount_point of the host.

    :src: mount source
    :mount_point: mount point
    :fstype: file system type
    :perm: mount permission
    :param fstype_mtab: file system type in mtab could be different
    :type fstype_mtab: str
    """
    if perm is None:
        perm = "rw"
    if fstype_mtab is None:
        fstype_mtab = fstype

    if is_mounted(src, mount_point, fstype, perm, verbose, fstype_mtab):
        logging.debug("%s is already mounted in %s with %s",
                      src, mount_point, perm)
        return True
    mount_cmd = "mount -t %s %s %s -o %s" % (fstype, src, mount_point, perm)
    try:
        utils.system(mount_cmd, verbose=verbose)
    except error.CmdError:
        return False
    return is_mounted(src, mount_point, fstype, perm, verbose, fstype_mtab)


def is_mounted(src, mount_point, fstype, perm=None, verbose=False,
               fstype_mtab=None):
    """
    Check mount status from /etc/mtab

    :param src: mount source
    :type src: string
    :param mount_point: mount point
    :type mount_point: string
    :param fstype: file system type
    :type fstype: string
    :param perm: mount permission
    :type perm: string
    :param verbose: if display mtab content
    :type verbose: Boolean
    :param fstype_mtab: file system type in mtab could be different
    :type fstype_mtab: str
    :return: if the src is mounted as expect
    :rtype: Boolean
    """
    if perm is None:
        perm = ""
    if fstype_mtab is None:
        fstype_mtab = fstype

    # Version 4 nfs displays 'nfs4' in mtab
    if fstype == "nfs":
        fstype_mtab = "nfs\d?"

    mount_point = os.path.realpath(mount_point)
    if fstype not in ['nfs', 'smbfs', 'glusterfs']:
        if src:
            src = os.path.realpath(src)
        else:
            # Allow no passed src(None or "")
            src = ""
    mount_string = "%s %s %s %s" % (src, mount_point, fstype_mtab, perm)
    logging.debug("Searching '%s' in mtab...", mount_string)
    if verbose:
        logging.debug("/etc/mtab contents:\n%s", file("/etc/mtab").read())
    if re.findall(mount_string.strip(), file("/etc/mtab").read()):
        logging.debug("%s is mounted.", src)
        return True
    else:
        logging.debug("%s is not mounted.", src)
        return False


def install_host_kernel(job, params):
    """
    Install a host kernel, given the appropriate params.

    :param job: Job object.
    :param params: Dict with host kernel install params.
    """
    install_type = params.get('host_kernel_install_type')

    if install_type == 'rpm':
        logging.info('Installing host kernel through rpm')

        rpm_url = params.get('host_kernel_rpm_url')
        k_basename = os.path.basename(rpm_url)
        dst = os.path.join("/var/tmp", k_basename)
        k = utils.get_file(rpm_url, dst)
        host_kernel = job.kernel(k)
        host_kernel.install(install_vmlinux=False)
        utils.write_keyval(job.resultdir,
                           {'software_version_kernel': k_basename})
        host_kernel.boot()

    elif install_type in ['koji', 'brew']:
        logging.info('Installing host kernel through koji/brew')

        koji_cmd = params.get('host_kernel_koji_cmd')
        koji_build = params.get('host_kernel_koji_build')
        koji_tag = params.get('host_kernel_koji_tag')

        k_deps = utils_koji.KojiPkgSpec(tag=koji_tag, build=koji_build,
                                        package='kernel',
                                        subpackages=['kernel-devel', 'kernel-firmware'])
        k = utils_koji.KojiPkgSpec(tag=koji_tag, build=koji_build,
                                   package='kernel', subpackages=['kernel'])

        c = utils_koji.KojiClient(koji_cmd)
        logging.info('Fetching kernel dependencies (-devel, -firmware)')
        c.get_pkgs(k_deps, job.tmpdir)
        logging.info('Installing kernel dependencies (-devel, -firmware) '
                     'through %s', install_type)
        k_deps_rpm_file_names = [os.path.join(job.tmpdir, rpm_file_name) for
                                 rpm_file_name in c.get_pkg_rpm_file_names(k_deps)]
        utils.run('rpm -U --force %s' % " ".join(k_deps_rpm_file_names))

        c.get_pkgs(k, job.tmpdir)
        k_rpm = os.path.join(job.tmpdir,
                             c.get_pkg_rpm_file_names(k)[0])
        host_kernel = job.kernel(k_rpm)
        host_kernel.install(install_vmlinux=False)
        utils.write_keyval(job.resultdir,
                           {'software_version_kernel':
                            " ".join(c.get_pkg_rpm_file_names(k_deps))})
        host_kernel.boot()

    elif install_type == 'git':
        logging.info('Chose to install host kernel through git, proceeding')

        repo = params.get('host_kernel_git_repo')
        repo_base = params.get('host_kernel_git_repo_base', None)
        branch = params.get('host_kernel_git_branch')
        commit = params.get('host_kernel_git_commit')
        patch_list = params.get('host_kernel_patch_list')
        if patch_list:
            patch_list = patch_list.split()
        kernel_config = params.get('host_kernel_config', None)

        repodir = os.path.join("/tmp", 'kernel_src')
        r = git.GitRepoHelper(uri=repo, branch=branch, destination_dir=repodir,
                              commit=commit, base_uri=repo_base)
        r.execute()
        host_kernel = job.kernel(r.destination_dir)
        if patch_list:
            host_kernel.patch(patch_list)
        if kernel_config:
            host_kernel.config(kernel_config)
        host_kernel.build()
        host_kernel.install()
        git_repo_version = '%s:%s:%s' % (r.uri, r.branch, r.get_top_commit())
        utils.write_keyval(job.resultdir,
                           {'software_version_kernel': git_repo_version})
        host_kernel.boot()

    else:
        logging.info('Chose %s, using the current kernel for the host',
                     install_type)
        k_version = utils.system_output('uname -r', ignore_status=True)
        utils.write_keyval(job.resultdir,
                           {'software_version_kernel': k_version})


def install_disktest_on_vm(test, vm, src_dir, dst_dir):
    """
    Install stress to vm.

    :param vm: virtual machine.
    :param src_dir: Source path.
    :param dst_dir: Instaltation path.
    """
    disktest_src = src_dir
    disktest_dst = os.path.join(dst_dir, "disktest")
    session = vm.wait_for_login()
    session.cmd("rm -rf %s" % (disktest_dst))
    session.cmd("mkdir -p %s" % (disktest_dst))
    session.cmd("sync")
    vm.copy_files_to(disktest_src, disktest_dst)
    session.cmd("sync")
    session.cmd("cd %s; make;" %
                (os.path.join(disktest_dst, "src")))
    session.cmd("sync")
    session.close()


def qemu_has_option(option, qemu_path="/usr/bin/qemu-kvm"):
    """
    Helper function for command line option wrappers

    :param option: Option need check.
    :param qemu_path: Path for qemu-kvm.
    """
    hlp = commands.getoutput("%s -help" % qemu_path)
    return bool(re.search(r"^-%s(\s|$)" % option, hlp, re.MULTILINE))


def bitlist_to_string(data):
    """
    Transform from bit list to ASCII string.

    :param data: Bit list to be transformed
    """
    result = []
    pos = 0
    c = 0
    while pos < len(data):
        c += data[pos] << (7 - (pos % 8))
        if (pos % 8) == 7:
            result.append(c)
            c = 0
        pos += 1
    return ''.join([chr(c) for c in result])


def string_to_bitlist(data):
    """
    Transform from ASCII string to bit list.

    :param data: String to be transformed
    """
    data = [ord(c) for c in data]
    result = []
    for ch in data:
        i = 7
        while i >= 0:
            if ch & (1 << i) != 0:
                result.append(1)
            else:
                result.append(0)
            i -= 1
    return result


def strip_console_codes(output):
    """
    Remove the Linux console escape and control sequences from the console
    output. Make the output readable and can be used for result check. Now
    only remove some basic console codes using during boot up.

    :param output: The output from Linux console
    :type output: string
    :return: the string wihout any special codes
    :rtype: string
    """
    if "\x1b" not in output:
        return output

    old_word = ""
    return_str = ""
    index = 0
    output = "\x1b[m%s" % output
    console_codes = "%G|\[m|\[[\d;]+[HJnrm]"
    while index < len(output):
        tmp_index = 0
        tmp_word = ""
        while (len(re.findall("\x1b", tmp_word)) < 2
               and index + tmp_index < len(output)):
            tmp_word += output[index + tmp_index]
            tmp_index += 1

        tmp_word = re.sub("\x1b", "", tmp_word)
        index += len(tmp_word) + 1
        if tmp_word == old_word:
            continue
        try:
            special_code = re.findall(console_codes, tmp_word)[0]
        except IndexError:
            if index + tmp_index < len(output):
                raise ValueError("%s is not included in the known console "
                                 "codes list %s" % (tmp_word, console_codes))
            continue
        if special_code == tmp_word:
            continue
        old_word = tmp_word
        return_str += tmp_word[len(special_code):]
    return return_str


def get_module_params(sys_path, module_name):
    """
    Get the kvm module params
    :param sys_path: sysfs path for modules info
    :param module_name: module to check
    """
    dir_params = os.path.join(sys_path, "module", module_name, "parameters")
    module_params = {}
    if os.path.isdir(dir_params):
        for filename in os.listdir(dir_params):
            full_dir = os.path.join(dir_params, filename)
            tmp = open(full_dir, 'r').read().strip()
            module_params[full_dir] = tmp
    else:
        return None
    return module_params


def create_x509_dir(path, cacert_subj, server_subj, passphrase,
                    secure=False, bits=1024, days=1095):
    """
    Creates directory with freshly generated:
    ca-cart.pem, ca-key.pem, server-cert.pem, server-key.pem,

    :param path: defines path to directory which will be created
    :param cacert_subj: ca-cert.pem subject
    :param server_key.csr: subject
    :param passphrase: passphrase to ca-key.pem
    :param secure: defines if the server-key.pem will use a passphrase
    :param bits: bit length of keys
    :param days: cert expiration

    :raise ValueError: openssl not found or rc != 0
    :raise OSError: if os.makedirs() fails
    """

    ssl_cmd = os_dep.command("openssl")
    path = path + os.path.sep  # Add separator to the path
    shutil.rmtree(path, ignore_errors=True)
    os.makedirs(path)

    server_key = "server-key.pem.secure"
    if secure:
        server_key = "server-key.pem"

    cmd_set = [
        ('%s genrsa -des3 -passout pass:%s -out %sca-key.pem %d' %
         (ssl_cmd, passphrase, path, bits)),
        ('%s req -new -x509 -days %d -key %sca-key.pem -passin pass:%s -out '
         '%sca-cert.pem -subj "%s"' %
         (ssl_cmd, days, path, passphrase, path, cacert_subj)),
        ('%s genrsa -out %s %d' % (ssl_cmd, path + server_key, bits)),
        ('%s req -new -key %s -out %s/server-key.csr -subj "%s"' %
         (ssl_cmd, path + server_key, path, server_subj)),
        ('%s x509 -req -passin pass:%s -days %d -in %sserver-key.csr -CA '
         '%sca-cert.pem -CAkey %sca-key.pem -set_serial 01 -out %sserver-cert.pem' %
         (ssl_cmd, passphrase, days, path, path, path, path))
    ]

    if not secure:
        cmd_set.append('%s rsa -in %s -out %sserver-key.pem' %
                       (ssl_cmd, path + server_key, path))

    for cmd in cmd_set:
        utils.run(cmd)
        logging.info(cmd)


def convert_ipv4_to_ipv6(ipv4):
    """
    Translates a passed in string of an ipv4 address to an ipv6 address.

    :param ipv4: a string of an ipv4 address
    """

    converted_ip = "::ffff:"
    split_ipaddress = ipv4.split('.')
    try:
        socket.inet_aton(ipv4)
    except socket.error:
        raise ValueError("ipv4 to be converted is invalid")
    if (len(split_ipaddress) != 4):
        raise ValueError("ipv4 address is not in dotted quad format")

    for index, string in enumerate(split_ipaddress):
        if index != 1:
            test = str(hex(int(string)).split('x')[1])
            if len(test) == 1:
                final = "0"
                final += test
                test = final
        else:
            test = str(hex(int(string)).split('x')[1])
            if len(test) == 1:
                final = "0"
                final += test + ":"
                test = final
            else:
                test += ":"
        converted_ip += test
    return converted_ip


def get_thread_cpu(thread):
    """
    Get the light weight process(thread) used cpus.

    :param thread: thread checked
    :type thread: string
    :return: A list include all cpus the thread used
    :rtype: list
    """
    cmd = "ps -o cpuid,lwp -eL | grep -w %s$" % thread
    cpu_thread = utils.system_output(cmd)
    if not cpu_thread:
        return []
    return list(set([_.strip().split()[0] for _ in cpu_thread.splitlines()]))


def get_pid_cpu(pid):
    """
    Get the process used cpus.

    :param pid: process id
    :type thread: string
    :return: A list include all cpus the process used
    :rtype: list
    """
    cmd = "ps -o cpuid -L -p %s" % pid
    cpu_pid = utils.system_output(cmd)
    if not cpu_pid:
        return []
    return list(set([_.strip() for _ in cpu_pid.splitlines()]))


# Utility functions for numa node pinning


def get_node_cpus(i=0):
    """
    Get cpu ids of one node

    :return: the cpu lists
    :rtype: list
    """
    cmd = utils.run("numactl --hardware")
    return re.findall("node %s cpus: (.*)" % i, cmd.stdout)[0].split()


def cpu_str_to_list(origin_str):
    """
    Convert the cpu string to a list. The string may include comma and
    hyphen.

    :param origin_str: the cpu info string read from system
    :type origin_str: string
    :return: A list of the cpu ids
    :rtype: list
    """
    if isinstance(origin_str, str):
        cpu_list = []
        for cpu in origin_str.strip().split(","):
            if "-" in cpu:
                start, end = cpu.split("-")
                for cpu_id in range(int(start), int(end) + 1):
                    cpu_list.append(cpu_id)
            else:
                try:
                    cpu_id = int(cpu)
                    cpu_list.append(cpu_id)
                except ValueError:
                    logging.error("Illegimate string in cpu "
                                  "informations: %s" % cpu)
                    cpu_list = []
                    break
        cpu_list.sort()
        return cpu_list


class NumaInfo(object):

    """
    Numa topology for host. Also provide the function for check the memory status
    of the node.
    """

    def __init__(self, all_nodes_path=None, online_nodes_path=None):
        """
        :param all_nodes_path: Alternative path to
                /sys/devices/system/node/possible. Useful for unittesting.
        :param all_nodes_path: Alternative path to
                /sys/devices/system/node/online. Useful for unittesting.
        """
        self.numa_sys_path = "/sys/devices/system/node"
        self.all_nodes = self.get_all_nodes(all_nodes_path)
        self.online_nodes = self.get_online_nodes(online_nodes_path)
        self.nodes = {}
        self.distances = {}
        for node_id in self.online_nodes:
            self.nodes[node_id] = NumaNode(node_id + 1)
            self.distances[node_id] = self.get_node_distance(node_id)

    def get_all_nodes(self, all_nodes_path=None):
        """
        Get all node ids in host.

        :return: All node ids in host
        :rtype: list
        """
        if all_nodes_path is None:
            all_nodes = get_path(self.numa_sys_path, "possible")
        else:
            all_nodes = all_nodes_path
        all_nodes_file = open(all_nodes, "r")
        nodes_info = all_nodes_file.read()
        all_nodes_file.close()

        return cpu_str_to_list(nodes_info)

    def get_online_nodes(self, online_nodes_path=None):
        """
        Get node ids online in host

        :return: The ids of node which is online
        :rtype: list
        """
        if online_nodes_path is None:
            online_nodes = get_path(self.numa_sys_path, "online")
        else:
            online_nodes = online_nodes_path
        online_nodes_file = open(online_nodes, "r")
        nodes_info = online_nodes_file.read()
        online_nodes_file.close()

        return cpu_str_to_list(nodes_info)

    def get_node_distance(self, node_id):
        """
        Get the distance from the give node to other nodes include itself.

        :param node_id: Node that you want to check
        :type node_id: string
        :return: A list in of distance for the node in positive-sequence
        :rtype: list
        """
        cmd = utils.run("numactl --hardware")
        try:
            node_distances = cmd.stdout.split("node distances:")[-1].strip()
            node_distance = re.findall("%s:" % node_id, node_distances)[0]
            node_distance = node_distance.split(":")[-1]
        except Exception:
            logging.warn("Get unexpect information from numctl")
            numa_sys_path = self.numa_sys_path
            distance_path = get_path(numa_sys_path,
                                     "node%s/distance" % node_id)
            if not os.path.isfile(distance_path):
                logging.error("Can not get distance information for"
                              " node %s" % node_id)
                return []
            node_distance_file = open(distance_path, 'r')
            node_distance = node_distance_file.read()
            node_distance_file.close()

        return node_distance.strip().split()

    def read_from_node_meminfo(self, node_id, key):
        """
        Get specific value of a given node from memoinfo file

        :param node_id: The node you want to check
        :type node_id: string
        :param key: The value you want to check such as MemTotal etc.
        :type key: string
        :return: The value in KB
        :rtype: string
        """
        memory_path = os.path.join(self.numa_sys_path,
                                   "node%s/meminfo" % node_id)
        memory_file = open(memory_path, "r")
        memory_info = memory_file.read()
        memory_file.close()

        return re.findall("%s:\s+(\d+)" % key, memory_info)[0]


class NumaNode(object):

    """
    Numa node to control processes and shared memory.
    """

    def __init__(self, i=-1, all_nodes_path=None, online_nodes_path=None):
        """
        :param all_nodes_path: Alternative path to
                /sys/devices/system/node/possible. Useful for unittesting.
        :param all_nodes_path: Alternative path to
                /sys/devices/system/node/online. Useful for unittesting.
        """
        self.extra_cpus = []
        if i < 0:
            host_numa_info = NumaInfo(all_nodes_path, online_nodes_path)
            available_nodes = host_numa_info.nodes.keys()
            self.cpus = self.get_node_cpus(available_nodes[-1]).split()
            if len(available_nodes) > 1:
                self.extra_cpus = self.get_node_cpus(
                    available_nodes[-2]).split()
            self.node_id = available_nodes[-1]
        else:
            self.cpus = self.get_node_cpus(i - 1).split()
            self.extra_cpus = self.get_node_cpus(i).split()
            self.node_id = i - 1
        self.dict = {}
        for i in self.cpus:
            self.dict[i] = []
        for i in self.extra_cpus:
            self.dict[i] = []

    def get_node_cpus(self, i):
        """
        Get cpus of a specific node

        :param i: Index of the CPU inside the node.
        """
        cmd = utils.run("numactl --hardware")
        cpus = re.findall("node %s cpus: (.*)" % i, cmd.stdout)
        if cpus:
            cpus = cpus[0]
        else:
            break_flag = False
            cpulist_path = "/sys/devices/system/node/node%s/cpulist" % i
            try:
                cpulist_file = open(cpulist_path, 'r')
                cpus = cpulist_file.read()
                cpulist_file.close()
            except IOError:
                logging.warn("Can not find the cpu list information from both"
                             "numactl and sysfs. Please check your system.")
                break_flag = True
            if not break_flag:
                # Try to expand the numbers with '-' to a string of numbers
                # separated by blank. There number of '-' in the list depends
                # on the physical architecture of the hardware.
                try:
                    convert_list = re.findall("\d+-\d+", cpus)
                    for cstr in convert_list:
                        _ = " "
                        start = min(int(cstr.split("-")[0]),
                                    int(cstr.split("-")[1]))
                        end = max(int(cstr.split("-")[0]),
                                  int(cstr.split("-")[1]))
                        for n in range(start, end + 1, 1):
                            _ += "%s " % str(n)
                        cpus = re.sub(cstr, _, cpus)
                except (IndexError, ValueError):
                    logging.warn("The format of cpu list is not the same as"
                                 " expected.")
                    break_flag = False
            if break_flag:
                cpus = ""

        return cpus

    def free_cpu(self, i, thread=None):
        """
        Release pin of one node.

        :param i: Index of the node.
        :param thread: Thread ID, remove all threads if thread ID isn't set
        """
        if not thread:
            self.dict[i] = []
        else:
            self.dict[i].remove(thread)

    def _flush_pin(self):
        """
        Flush pin dict, remove the record of exited process.
        """
        cmd = utils.run("ps -eLf | awk '{print $4}'")
        all_pids = cmd.stdout
        for i in self.cpus:
            for j in self.dict[i]:
                if str(j) not in all_pids:
                    self.free_cpu(i, j)

    @error.context_aware
    def pin_cpu(self, process, cpu=None, extra=False):
        """
        Pin one process to a single cpu.

        :param process: Process ID.
        :param cpu: CPU ID, pin thread to free CPU if cpu ID isn't set
        """
        self._flush_pin()
        if cpu:
            error.context("Pinning process %s to the CPU(%s)" % (process, cpu))
        else:
            error.context("Pinning process %s to the available CPU" % (process))

        cpus = self.cpus
        if extra:
            cpus = self.extra_cpus

        for i in cpus:
            if (cpu is not None and cpu == i) or (cpu is None and not self.dict[i]):
                self.dict[i].append(process)
                cmd = "taskset -p %s %s" % (hex(2 ** int(i)), process)
                logging.debug("NumaNode (%s): " % i + cmd)
                utils.run(cmd)
                return i

    def show(self):
        """
        Display the record dict in a convenient way.
        """
        logging.info("Numa Node record dict:")
        for i in self.cpus:
            logging.info("    %s: %s" % (i, self.dict[i]))


class Flag(str):

    """
    Class for easy merge cpuflags.
    """
    aliases = {}

    def __new__(cls, flag):
        if flag in Flag.aliases:
            flag = Flag.aliases[flag]
        return str.__new__(cls, flag)

    def __eq__(self, other):
        s = set(self.split("|"))
        o = set(other.split("|"))
        if s & o:
            return True
        else:
            return False

    def __str__(self):
        return self.split("|")[0]

    def __repr__(self):
        return self.split("|")[0]

    def __hash__(self, *args, **kwargs):
        return 0


kvm_map_flags_to_test = {
    Flag('avx'): set(['avx']),
    Flag('sse3|pni'): set(['sse3']),
    Flag('ssse3'): set(['ssse3']),
    Flag('sse4.1|sse4_1|sse4.2|sse4_2'): set(['sse4']),
    Flag('aes'): set(['aes', 'pclmul']),
    Flag('pclmuldq'): set(['pclmul']),
    Flag('pclmulqdq'): set(['pclmul']),
    Flag('rdrand'): set(['rdrand']),
    Flag('sse4a'): set(['sse4a']),
    Flag('fma4'): set(['fma4']),
    Flag('xop'): set(['xop']),
}


kvm_map_flags_aliases = {
    'sse4_1': 'sse4.1',
    'sse4_2': 'sse4.2',
    'pclmuldq': 'pclmulqdq',
    'sse3': 'pni',
    'ffxsr': 'fxsr_opt',
    'xd': 'nx',
    'i64': 'lm',
           'psn': 'pn',
           'clfsh': 'clflush',
           'dts': 'ds',
           'htt': 'ht',
           'CMPXCHG8B': 'cx8',
           'Page1GB': 'pdpe1gb',
           'LahfSahf': 'lahf_lm',
           'ExtApicSpace': 'extapic',
           'AltMovCr8': 'cr8_legacy',
           'cr8legacy': 'cr8_legacy'
}


def kvm_flags_to_stresstests(flags):
    """
    Covert [cpu flags] to [tests]

    :param cpuflags: list of cpuflags
    :return: Return tests like string.
    """
    tests = set([])
    for f in flags:
        tests |= kvm_map_flags_to_test[f]
    param = ""
    for f in tests:
        param += "," + f
    return param


def get_cpu_flags(cpu_info=""):
    """
    Returns a list of the CPU flags
    """
    cpu_flags_re = "flags\s+:\s+([\w\s]+)\n"
    if not cpu_info:
        fd = open("/proc/cpuinfo")
        cpu_info = fd.read()
        fd.close()
    cpu_flag_lists = re.findall(cpu_flags_re, cpu_info)
    if not cpu_flag_lists:
        return []
    cpu_flags = cpu_flag_lists[0]
    return re.split("\s+", cpu_flags.strip())


def get_cpu_vendor(cpu_info="", verbose=True):
    """
    Returns the name of the CPU vendor
    """
    vendor_re = "vendor_id\s+:\s+(\w+)"
    if not cpu_info:
        fd = open("/proc/cpuinfo")
        cpu_info = fd.read()
        fd.close()
    vendor = re.findall(vendor_re, cpu_info)
    if not vendor:
        vendor = 'unknown'
    else:
        vendor = vendor[0]
    if verbose:
        logging.debug("Detected CPU vendor as '%s'", vendor)
    return vendor


def get_support_machine_type(qemu_binary="/usr/libexec/qemu-kvm"):
    """
    Get the machine type the host support,return a list of machine type
    """
    o = utils.system_output("%s -M ?" % qemu_binary)
    s = re.findall("(\S*)\s*RHEL\s", o)
    c = re.findall("(RHEL.*PC)", o)
    return (s, c)


def get_host_cpu_models():
    """
    Get cpu model from host cpuinfo
    """
    def _cpu_flags_sort(cpu_flags):
        """
        Update the cpu flags get from host to a certain order and format
        """
        flag_list = re.split("\s+", cpu_flags.strip())
        flag_list.sort()
        cpu_flags = " ".join(flag_list)
        return cpu_flags

    def _make_up_pattern(flags):
        """
        Update the check pattern to a certain order and format
        """
        pattern_list = re.split(",", flags.strip())
        pattern_list.sort()
        pattern = r"(\b%s\b)" % pattern_list[0]
        for i in pattern_list[1:]:
            pattern += r".+(\b%s\b)" % i
        return pattern

    if ARCH == 'ppc64':
        return ['POWER7']

    cpu_types = {"AuthenticAMD": ["Opteron_G5", "Opteron_G4", "Opteron_G3",
                                  "Opteron_G2", "Opteron_G1"],
                 "GenuineIntel": ["SandyBridge", "Westmere", "Nehalem",
                                  "Penryn", "Conroe"]}
    cpu_type_re = {"Opteron_G5": "f16c,fma,tbm",
                   "Opteron_G4":
                   "avx,xsave,aes,sse4.2|sse4_2,sse4.1|sse4_1,cx16,ssse3,sse4a",
                   "Opteron_G3": "cx16,sse4a",
                   "Opteron_G2": "cx16",
                   "Opteron_G1": "",
                   "SandyBridge":
                   "avx,xsave,aes,sse4_2|sse4.2,sse4.1|sse4_1,cx16,ssse3",
                   "Westmere": "aes,sse4.2|sse4_2,sse4.1|sse4_1,cx16,ssse3",
                   "Nehalem": "sse4.2|sse4_2,sse4.1|sse4_1,cx16,ssse3",
                   "Penryn": "sse4.1|sse4_1,cx16,ssse3",
                   "Conroe": "ssse3"}

    fd = open("/proc/cpuinfo")
    cpu_info = fd.read()
    fd.close()

    cpu_flags = " ".join(get_cpu_flags(cpu_info))
    vendor = get_cpu_vendor(cpu_info)

    cpu_model = None
    cpu_support_model = []
    if cpu_flags:
        cpu_flags = _cpu_flags_sort(cpu_flags)
        for cpu_type in cpu_types.get(vendor):
            pattern = _make_up_pattern(cpu_type_re.get(cpu_type))
            if re.findall(pattern, cpu_flags):
                cpu_model = cpu_type
                break
    else:
        logging.warn("Can not Get cpu flags from cpuinfo")

    if cpu_model:
        cpu_type_list = cpu_types.get(vendor)
        cpu_support_model = cpu_type_list[cpu_type_list.index(cpu_model):]

    return cpu_support_model


def extract_qemu_cpu_models(qemu_cpu_help_text):
    """
    Get all cpu models from qemu -cpu help text.

    :param qemu_cpu_help_text: text produced by <qemu> -cpu '?'
    :return: list of cpu models
    """
    def check_model_list(pattern):
        cpu_re = re.compile(pattern)
        qemu_cpu_model_list = cpu_re.findall(qemu_cpu_help_text)
        if qemu_cpu_model_list:
            return qemu_cpu_model_list
        else:
            return None

    x86_pattern_list = "x86\s+\[?([a-zA-Z0-9_-]+)\]?.*\n"
    ppc64_pattern_list = "PowerPC\s+\[?([a-zA-Z0-9_-]+\.?[0-9]?)\]?.*\n"

    for pattern_list in [x86_pattern_list, ppc64_pattern_list]:
        model_list = check_model_list(pattern_list)
        if model_list is not None:
            return model_list

    e_msg = ("CPU models reported by qemu -cpu ? not supported by virt-tests. "
             "Please work with us to add support for it")
    logging.error(e_msg)
    for line in qemu_cpu_help_text.splitlines():
        logging.error(line)
    raise UnsupportedCPU(e_msg)


def get_qemu_cpu_models(qemu_binary):
    """Get listing of CPU models supported by QEMU

    Get list of CPU models by parsing the output of <qemu> -cpu '?'
    """
    cmd = qemu_binary + " -cpu '?'"
    result = utils.run(cmd)
    return extract_qemu_cpu_models(result.stdout)


def _get_backend_dir(params):
    """
    Get the appropriate backend directory. Example: backends/qemu.
    """
    return os.path.join(data_dir.get_root_dir(), 'backends',
                        params.get("vm_type"))


def get_qemu_binary(params):
    """
    Get the path to the qemu binary currently in use.
    """
    # Update LD_LIBRARY_PATH for built libraries (libspice-server)
    qemu_binary_path = get_path(_get_backend_dir(params),
                                params.get("qemu_binary", "qemu"))

    if not os.path.isfile(qemu_binary_path):
        logging.debug('Could not find params qemu in %s, searching the '
                      'host PATH for one to use', qemu_binary_path)
        try:
            qemu_binary = find_command('qemu-kvm')
            logging.debug('Found %s', qemu_binary)
        except ValueError:
            qemu_binary = find_command('kvm')
            logging.debug('Found %s', qemu_binary)
    else:
        library_path = os.path.join(_get_backend_dir(params), 'install_root', 'lib')
        if os.path.isdir(library_path):
            library_path = os.path.abspath(library_path)
            qemu_binary = ("LD_LIBRARY_PATH=%s %s" %
                           (library_path, qemu_binary_path))
        else:
            qemu_binary = qemu_binary_path

    return qemu_binary


def get_qemu_dst_binary(params):
    """
    Get the path to the qemu dst binary currently in use.
    """
    qemu_dst_binary = params.get("qemu_dst_binary", None)
    if qemu_dst_binary is None:
        return qemu_dst_binary

    qemu_binary_path = get_path(_get_backend_dir(params), qemu_dst_binary)

    # Update LD_LIBRARY_PATH for built libraries (libspice-server)
    library_path = os.path.join(_get_backend_dir(params), 'install_root', 'lib')
    if os.path.isdir(library_path):
        library_path = os.path.abspath(library_path)
        qemu_dst_binary = ("LD_LIBRARY_PATH=%s %s" %
                           (library_path, qemu_binary_path))
    else:
        qemu_dst_binary = qemu_binary_path

    return qemu_dst_binary


def get_qemu_img_binary(params):
    """
    Get the path to the qemu-img binary currently in use.
    """
    qemu_img_binary_path = get_path(_get_backend_dir(params),
                                    params.get("qemu_img_binary", "qemu-img"))
    if not os.path.isfile(qemu_img_binary_path):
        logging.debug('Could not find params qemu-img in %s, searching the '
                      'host PATH for one to use', qemu_img_binary_path)
        qemu_img_binary = find_command('qemu-img')
        logging.debug('Found %s', qemu_img_binary)
    else:
        qemu_img_binary = qemu_img_binary_path

    return qemu_img_binary


def get_qemu_io_binary(params):
    """
    Get the path to the qemu-io binary currently in use.
    """
    qemu_io_binary_path = get_path(_get_backend_dir(params),
                                   params.get("qemu_io_binary", "qemu-io"))
    if not os.path.isfile(qemu_io_binary_path):
        logging.debug('Could not find params qemu-io in %s, searching the '
                      'host PATH for one to use', qemu_io_binary_path)
        qemu_io_binary = find_command('qemu-io')
        logging.debug('Found %s', qemu_io_binary)
    else:
        qemu_io_binary = qemu_io_binary_path

    return qemu_io_binary


def get_qemu_best_cpu_model(params):
    """
    Try to find out the best CPU model available for qemu.

    This function can't be in qemu_vm, because it is used in env_process,
    where there's no vm object available yet, and env content is synchronized
    in multi host testing.

    1) Get host CPU model
    2) Verify if host CPU model is in the list of supported qemu cpu models
    3) If so, return host CPU model
    4) If not, return the default cpu model set in params, if none defined,
        return 'qemu64'.
    """
    host_cpu_models = get_host_cpu_models()
    qemu_binary = get_qemu_binary(params)
    qemu_cpu_models = get_qemu_cpu_models(qemu_binary)
    # Let's try to find a suitable model on the qemu list
    for host_cpu_model in host_cpu_models:
        if host_cpu_model in qemu_cpu_models:
            return host_cpu_model
    # If no host cpu model can be found on qemu_cpu_models, choose the default
    return params.get("default_cpu_model", "qemu64")


def check_if_vm_vcpu_match(vcpu_desire, vm):
    """
    This checks whether the VM vCPU quantity matches
    the value desired.
    """
    vcpu_actual = vm.get_cpu_count()
    if vcpu_desire != vcpu_actual:
        logging.debug("CPU quantity mismatched !!! guest said it got %s "
                      "but we assigned %s" % (vcpu_actual, vcpu_desire))
        return False
    logging.info("CPU quantity matched: %s" % vcpu_actual)
    return True


class ForAll(list):

    def __getattr__(self, name):
        def wrapper(*args, **kargs):
            return map(lambda o: o.__getattribute__(name)(*args, **kargs), self)
        return wrapper


class ForAllP(list):

    """
    Parallel version of ForAll
    """

    def __getattr__(self, name):
        def wrapper(*args, **kargs):
            threads = []
            for o in self:
                threads.append(
                    utils.InterruptedThread(o.__getattribute__(name),
                                            args=args, kwargs=kargs))
            for t in threads:
                t.start()
            return map(lambda t: t.join(), threads)
        return wrapper


class ForAllPSE(list):

    """
    Parallel version of and suppress exception.
    """

    def __getattr__(self, name):
        def wrapper(*args, **kargs):
            threads = []
            for o in self:
                threads.append(
                    utils.InterruptedThread(o.__getattribute__(name),
                                            args=args, kwargs=kargs))
            for t in threads:
                t.start()

            result = []
            for t in threads:
                ret = {}
                try:
                    ret["return"] = t.join()
                except Exception:
                    ret["exception"] = sys.exc_info()
                    ret["args"] = args
                    ret["kargs"] = kargs
                result.append(ret)
            return result
        return wrapper


def get_pid_path(program_name, pid_files_dir=None):
    if not pid_files_dir:
        base_dir = os.path.dirname(__file__)
        pid_path = os.path.abspath(os.path.join(base_dir, "..", "..",
                                                "%s.pid" % program_name))
    else:
        pid_path = os.path.join(pid_files_dir, "%s.pid" % program_name)

    return pid_path


def write_pid(program_name, pid_files_dir=None):
    """
    Try to drop <program_name>.pid in the main autotest directory.

    Args:
      program_name: prefix for file name
    """
    pidfile = open(get_pid_path(program_name, pid_files_dir), "w")
    try:
        pidfile.write("%s\n" % os.getpid())
    finally:
        pidfile.close()


def delete_pid_file_if_exists(program_name, pid_files_dir=None):
    """
    Tries to remove <program_name>.pid from the main autotest directory.
    """
    pidfile_path = get_pid_path(program_name, pid_files_dir)

    try:
        os.remove(pidfile_path)
    except OSError:
        if not os.path.exists(pidfile_path):
            return
        raise


def get_pid_from_file(program_name, pid_files_dir=None):
    """
    Reads the pid from <program_name>.pid in the autotest directory.

    :param program_name the name of the program
    :return: the pid if the file exists, None otherwise.
    """
    pidfile_path = get_pid_path(program_name, pid_files_dir)
    if not os.path.exists(pidfile_path):
        return None

    pidfile = open(get_pid_path(program_name, pid_files_dir), 'r')

    try:
        try:
            pid = int(pidfile.readline())
        except IOError:
            if not os.path.exists(pidfile_path):
                return None
            raise
    finally:
        pidfile.close()

    return pid


def program_is_alive(program_name, pid_files_dir=None):
    """
    Checks if the process is alive and not in Zombie state.

    :param program_name the name of the program
    :return: True if still alive, False otherwise
    """
    pid = get_pid_from_file(program_name, pid_files_dir)
    if pid is None:
        return False
    return utils.pid_is_alive(pid)


def signal_program(program_name, sig=signal.SIGTERM, pid_files_dir=None):
    """
    Sends a signal to the process listed in <program_name>.pid

    :param program_name the name of the program
    :param sig signal to send
    """
    pid = get_pid_from_file(program_name, pid_files_dir)
    if pid:
        utils.signal_pid(pid, sig)


def normalize_data_size(value_str, order_magnitude="M", factor="1024"):
    """
    Normalize a data size in one order of magnitude to another (MB to GB,
    for example).

    :param value_str: a string include the data and unit
    :param order_magnitude: the magnitude order of result
    :param factor: the factor between two relative order of magnitude.
                   Normally could be 1024 or 1000
    """
    def _get_magnitude_index(magnitude_list, magnitude_value):
        for i in magnitude_list:
            order_magnitude = re.findall("[\s\d](%s)" % i,
                                         str(magnitude_value), re.I)
            if order_magnitude:
                return magnitude_list.index(order_magnitude[0].upper())
        return -1

    magnitude_list = ['B', 'K', 'M', 'G', 'T']
    try:
        data = float(re.findall("[\d\.]+", value_str)[0])
    except IndexError:
        logging.error("Incorrect data size format. Please check %s"
                      " has both data and unit." % value_str)
        return ""

    magnitude_index = _get_magnitude_index(magnitude_list, value_str)
    order_magnitude_index = _get_magnitude_index(magnitude_list,
                                                 " %s" % order_magnitude)

    if data == 0:
        return 0
    elif magnitude_index < 0 or order_magnitude_index < 0:
        logging.error("Unknown input order of magnitude. Please check your"
                      "value '%s' and desired order of magnitude"
                      " '%s'." % (value_str, order_magnitude))
        return ""

    if magnitude_index > order_magnitude_index:
        multiple = float(factor)
    else:
        multiple = float(factor) ** -1

    for _ in range(abs(magnitude_index - order_magnitude_index)):
        data *= multiple

    return str(data)


def verify_running_as_root():
    """
    Verifies whether we're running under UID 0 (root).

    :raise: error.TestNAError
    """
    if os.getuid() != 0:
        raise error.TestNAError("This test requires root privileges "
                                "(currently running with user %s)" %
                                getpass.getuser())


def selinux_enforcing():
    """
    Returns True if SELinux is in enforcing mode, False if permissive/disabled
    """
    cmdresult = utils.run('getenforce', ignore_status=True, verbose=False)
    mobj = re.search('Enforcing', cmdresult.stdout)
    return mobj is not None


def get_winutils_vol(session, label="WIN_UTILS"):
    """
    Return Volume ID of winutils CDROM ISO file should be create via command
    ``mkisofs -V $label -o winutils.iso``.

    :param session: session Object
    :param label: volume ID of WIN_UTILS.iso
    :return: volume ID
    """
    cmd = "wmic logicaldisk where (VolumeName='%s') get DeviceID" % label
    output = session.cmd(cmd, timeout=120)
    device = re.search(r'(\w):', output, re.M)
    if not device:
        return ""
    return device.group(1)


def valued_option_dict(options, split_pattern, start_count=0, dict_split=None):
    """
    Divide the valued options into key and value

    :param options: the valued options get from cfg
    :param split_pattern: patten used to split options
    :param dict_split: patten used to split sub options and insert into dict
    :param start_count: the start_count to insert option_dict
    :return: dict include option and its value
    """
    option_dict = {}
    if options.strip() is not None:
        pat = re.compile(split_pattern)
        option_list = pat.split(options.lstrip(split_pattern))
        logging.debug("option_list is %s", option_list)

        for match in option_list[start_count:]:
            match_list = match.split(dict_split)
            if len(match_list) == 2:
                key = match_list[0]
                value = match_list[1]
                if key not in option_dict:
                    option_dict[key] = value
                else:
                    logging.debug("key %s in option_dict", key)
                    option_dict[key] = option_dict[key].split()
                    option_dict[key].append(value)

    return option_dict


def get_image_info(image_file):
    """
    Get image information and put it into a dict. Image information like this:

    ::

        *******************************
        image: /path/vm1_6.3.img
        file format: raw
        virtual size: 10G (10737418240 bytes)
        disk size: 888M
        ....
        ....
        *******************************

    And the image info dict will be like this

    ::

        image_info_dict = {'format':'raw',
                           'vsize' : '10737418240'
                           'dsize' : '931135488'}

    :todo: Add more information to `image_info_dict`.
    """
    try:
        cmd = "qemu-img info %s" % image_file
        image_info = utils.run(cmd, ignore_status=False).stdout.strip()
        image_info_dict = {}
        if image_info:
            for line in image_info.splitlines():
                if line.find("format") != -1:
                    image_info_dict['format'] = line.split(':')[-1].strip()
                elif line.find("virtual size") != -1:
                    vsize = line.split(":")[-1].strip().split(" ")[0]
                    image_info_dict['vsize'] = int(float(normalize_data_size(vsize, "B")))
                elif line.find("disk size") != -1:
                    dsize = line.split(':')[-1].strip()
                    image_info_dict['dsize'] = int(float(normalize_data_size(dsize, "B")))
        return image_info_dict
    except (KeyError, IndexError, error.CmdError), detail:
        raise error.TestError("Fail to get information of %s:\n%s" %
                              (image_file, detail))


def get_test_entrypoint_func(name, module):
    '''
    Returns the test entry point function for a loaded module

    :param name: the name of the test. Usually supplied on a cartesian
                 config file using the "type" key
    :type name: str
    :param module: a loaded python module for containing the code
                        for the test named on ``name``
    :type module: module
    :raises: ValueError if module does not have a suitable function
    :returns: the test entry point function
    :rtype: func
    '''
    has_run = hasattr(module, "run")
    legacy_run = "run_%s" % name
    has_legacy_run = hasattr(module, legacy_run)

    if has_run:
        if has_legacy_run:
            msg = ('Both legacy and new test entry point function names '
                   'present. Please update your test and use "run()" '
                   'instead of "%s()". Also, please avoid using "%s()" '
                   'as a regular function name in your test as it causes '
                   'confusion with the legacy naming standard. Function '
                   '"run()" will be used in favor of "%s()"')
            logging.warn(msg, legacy_run, legacy_run, legacy_run)
        return getattr(module, "run")

    elif has_legacy_run:
        logging.warn('Legacy test entry point function name found. Please '
                     'update your test and use "run()" as the new function '
                     'name')
        return getattr(module, legacy_run)

    else:
        raise ValueError("Missing test entry point")


class KSMError(Exception):

    """
    Base exception for KSM setup
    """
    pass


class KSMNotSupportedError(KSMError):

    """
    Thrown when host does not support KSM.
    """
    pass


class KSMTunedError(KSMError):

    """
    Thrown when KSMTuned Error happen.
    """
    pass


class KSMTunedNotSupportedError(KSMTunedError):

    """
    Thrown when host does not support KSMTune.
    """
    pass


class KSMController(object):

    """KSM Manager"""

    def __init__(self):
        """
        Preparations for ksm.
        """
        _KSM_PATH = "/sys/kernel/mm/ksm/"
        self.ksm_path = _KSM_PATH
        self.ksm_params = {}

        # Default control way is files on host
        # But it will be ksmctl command on older ksm version
        self.interface = "sysfs"
        if os.path.isdir(self.ksm_path):
            _KSM_PARAMS = os.listdir(_KSM_PATH)
            for param in _KSM_PARAMS:
                self.ksm_params[param] = _KSM_PATH + param
            self.interface = "sysfs"
            if not os.path.isfile(self.ksm_params["run"]):
                raise KSMNotSupportedError
        else:
            try:
                os_dep.command("ksmctl")
            except ValueError:
                raise KSMNotSupportedError
            _KSM_PARAMS = ["run", "pages_to_scan", "sleep_millisecs"]
            # No _KSM_PATH needed here
            for param in _KSM_PARAMS:
                self.ksm_params[param] = None
            self.interface = "ksmctl"

    def is_module_loaded(self):
        """Check whether ksm module has been loaded."""
        if utils.system("lsmod |grep ksm", ignore_status=True):
            return False
        return True

    def load_ksm_module(self):
        """Try to load ksm module."""
        utils.system("modprobe ksm")

    def unload_ksm_module(self):
        """Try to unload ksm module."""
        utils.system("modprobe -r ksm")

    def get_ksmtuned_pid(self):
        """
        Return ksmtuned process id(0 means not running).
        """
        try:
            os_dep.command("ksmtuned")
        except ValueError:
            raise KSMTunedNotSupportedError

        process_id = utils.system_output("ps -C ksmtuned -o pid=",
                                         ignore_status=True)
        if process_id:
            return int(re.findall("\d+", process_id)[0])
        return 0

    def start_ksmtuned(self):
        """Start ksmtuned service"""
        if self.get_ksmtuned_pid() == 0:
            utils.system("ksmtuned")

    def stop_ksmtuned(self):
        """Stop ksmtuned service"""
        pid = self.get_ksmtuned_pid()
        if pid:
            utils.system("kill -1 %s" % pid)

    def restart_ksmtuned(self):
        """Restart ksmtuned service"""
        self.stop_ksmtuned()
        self.start_ksmtuned()

    def start_ksm(self, pages_to_scan=None, sleep_ms=None):
        """
        Start ksm function.
        """
        if not self.is_ksm_running():
            feature_args = {'run': 1}
            if self.interface == "ksmctl":
                if pages_to_scan is None:
                    pages_to_scan = 5000
                if sleep_ms is None:
                    sleep_ms = 50
                feature_args["pages_to_scan"] = pages_to_scan
                feature_args["sleep_millisecs"] = sleep_ms
            self.set_ksm_feature(feature_args)

    def stop_ksm(self):
        """
        Stop ksm function.
        """
        if self.is_ksm_running():
            return self.set_ksm_feature({"run": 0})

    def restart_ksm(self, pages_to_scan=None, sleep_ms=None):
        """Restart ksm service"""
        self.stop_ksm()
        self.start_ksm(pages_to_scan, sleep_ms)

    def is_ksm_running(self):
        """
        Verify whether ksm is running.
        """
        if self.interface == "sysfs":
            running = utils.system_output("cat %s" % self.ksm_params["run"])
        else:
            output = utils.system_output("ksmctl info")
            try:
                running = re.findall("\d+", output)[0]
            except IndexError:
                raise KSMError
        if running != '0':
            return True
        return False

    def get_writable_features(self):
        """Get writable features for setting"""
        writable_features = []
        if self.interface == "sysfs":
            # Get writable parameters
            for key, value in self.ksm_params.items():
                if stat.S_IMODE(os.stat(value).st_mode) & stat.S_IWRITE:
                    writable_features.append(key)
        else:
            for key in self.ksm_params.keys():
                writable_features.append(key)
        return writable_features

    def set_ksm_feature(self, feature_args):
        """
        Set ksm features.

        :param feature_args: a dict include features and their's value.
        """
        for key in feature_args.keys():
            if key not in self.get_writable_features():
                logging.error("Do not support setting of '%s'.", key)
                raise KSMError
        if self.interface == "sysfs":
            # Get writable parameters
            for key, value in feature_args.items():
                utils.system("echo %s > %s" % (value, self.ksm_params[key]))
        else:
            if "run" in feature_args.keys() and feature_args["run"] == 0:
                utils.system("ksmctl stop")
            else:
                # For ksmctl both pages_to_scan and sleep_ms should have value
                # So start it anyway if run is 1
                # Default is original value if feature is not in change list.
                if "pages_to_scan" not in feature_args.keys():
                    pts = self.get_ksm_feature("pages_to_scan")
                else:
                    pts = feature_args["pages_to_scan"]
                if "sleep_millisecs" not in feature_args.keys():
                    ms = self.get_ksm_feature("sleep_millisecs")
                else:
                    ms = feature_args["sleep_millisecs"]
                utils.system("ksmctl start %s %s" % (pts, ms))

    def get_ksm_feature(self, feature):
        """
        Get ksm feature's value.
        """
        if feature in self.ksm_params.keys():
            feature = self.ksm_params[feature]

        if self.interface == "sysfs":
            return utils.system_output("cat %s" % feature).strip()
        else:
            output = utils.system_output("ksmctl info")
            _KSM_PARAMS = ["run", "pages_to_scan", "sleep_millisecs"]
            ksminfos = re.findall("\d+", output)
            if len(ksminfos) != 3:
                raise KSMError
            try:
                return ksminfos[_KSM_PARAMS.index(feature)]
            except ValueError:
                raise KSMError


def monotonic_time():
    """
    Get monotonic time
    """
    def monotonic_time_os():
        """
        Get monotonic time using ctypes
        """
        class struct_timespec(ctypes.Structure):
            _fields_ = [('tv_sec', ctypes.c_long), ('tv_nsec', ctypes.c_long)]

        lib = ctypes.CDLL("librt.so.1", use_errno=True)
        clock_gettime = lib.clock_gettime
        clock_gettime.argtypes = [ctypes.c_int, ctypes.POINTER(struct_timespec)]

        timespec = struct_timespec()
        # CLOCK_MONOTONIC_RAW == 4
        if not clock_gettime(4, ctypes.pointer(timespec)) == 0:
            errno = ctypes.get_errno()
            raise OSError(errno, os.strerror(errno))

        return timespec.tv_sec + timespec.tv_nsec * 10 ** -9

    monotonic_attribute = getattr(time, "monotonic", None)
    if callable(monotonic_attribute):
        # Introduced in Python 3.3
        return time.monotonic()
    else:
        return monotonic_time_os()

########NEW FILE########
__FILENAME__ = utils_misc_unittest
#!/usr/bin/python

import os
import tempfile
import unittest

import common
from autotest.client import utils
from autotest.client.shared.test_utils import mock
import utils_misc
import cartesian_config
import build_helper


class TestUtilsMisc(unittest.TestCase):

    def test_cpu_vendor_intel(self):
        cpu_info = """processor : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 58
model name      : Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz
"""
        vendor = utils_misc.get_cpu_vendor(cpu_info, False)
        self.assertEqual(vendor, 'GenuineIntel')

    def test_cpu_vendor_amd(self):
        cpu_info = """processor : 3
vendor_id       : AuthenticAMD
cpu family      : 21
model           : 16
model name      : AMD A10-5800K APU with Radeon(tm) HD Graphics
"""
        vendor = utils_misc.get_cpu_vendor(cpu_info, False)
        self.assertEqual(vendor, 'AuthenticAMD')

    def test_vendor_unknown(self):
        cpu_info = "this is an unknown cpu"
        vendor = utils_misc.get_cpu_vendor(cpu_info, False)
        self.assertEqual(vendor, 'unknown')

    def test_get_archive_tarball_name(self):
        tarball_name = utils_misc.get_archive_tarball_name('/tmp',
                                                           'tmp-archive',
                                                           'bz2')
        self.assertEqual(tarball_name, 'tmp-archive.tar.bz2')

    def test_get_archive_tarball_name_absolute(self):
        tarball_name = utils_misc.get_archive_tarball_name('/tmp',
                                                           '/var/tmp/tmp',
                                                           'bz2')
        self.assertEqual(tarball_name, '/var/tmp/tmp.tar.bz2')

    def test_get_archive_tarball_name_from_dir(self):
        tarball_name = utils_misc.get_archive_tarball_name('/tmp',
                                                           None,
                                                           'bz2')
        self.assertEqual(tarball_name, 'tmp.tar.bz2')

    def test_git_repo_param_helper(self):
        config = """git_repo_foo_uri = git://git.foo.org/foo.git
git_repo_foo_branch = next
git_repo_foo_lbranch = local
git_repo_foo_commit = bc732ad8b2ed8be52160b893735417b43a1e91a8
"""
        config_parser = cartesian_config.Parser()
        config_parser.parse_string(config)
        params = config_parser.get_dicts().next()

        h = build_helper.GitRepoParamHelper(params, 'foo', '/tmp/foo')
        self.assertEqual(h.name, 'foo')
        self.assertEqual(h.branch, 'next')
        self.assertEqual(h.lbranch, 'local')
        self.assertEqual(h.commit, 'bc732ad8b2ed8be52160b893735417b43a1e91a8')

    def test_normalize_data_size(self):
        n1 = utils_misc.normalize_data_size("12M")
        n2 = utils_misc.normalize_data_size("1024M", "G")
        n3 = utils_misc.normalize_data_size("1024M", "T")
        n4 = utils_misc.normalize_data_size("1000M", "G", 1000)
        n5 = utils_misc.normalize_data_size("1T", "G", 1000)
        n6 = utils_misc.normalize_data_size("1T", "M")
        self.assertEqual(n1, "12.0")
        self.assertEqual(n2, "1.0")
        self.assertEqual(n3, "0.0009765625")
        self.assertEqual(n4, "1.0")
        self.assertEqual(n5, "1000.0")
        self.assertEqual(n6, "1048576.0")


class FakeCmd(object):

    def __init__(self, cmd):
        self.fake_cmds = [
            {"cmd": "numactl --hardware",
             "stdout": """
available: 1 nodes (0)
node 0 cpus: 0 1 2 3 4 5 6 7
node 0 size: 18431 MB
node 0 free: 17186 MB
node distances:
node   0
  0:  10
"""},
            {"cmd": "ps -eLf | awk '{print $4}'",
             "stdout": """
1230
1231
1232
1233
1234
1235
1236
1237
"""},
            {"cmd": "taskset -p 0x1 1230", "stdout": ""},
            {"cmd": "taskset -p 0x2 1231", "stdout": ""},
            {"cmd": "taskset -p 0x4 1232", "stdout": ""},
            {"cmd": "taskset -p 0x8 1233", "stdout": ""},
            {"cmd": "taskset -p 0x10 1234", "stdout": ""},
            {"cmd": "taskset -p 0x20 1235", "stdout": ""},
            {"cmd": "taskset -p 0x40 1236", "stdout": ""},
            {"cmd": "taskset -p 0x80 1237", "stdout": ""},

        ]

        self.stdout = self.get_stdout(cmd)

    def get_stdout(self, cmd):
        for fake_cmd in self.fake_cmds:
            if fake_cmd['cmd'] == cmd:
                return fake_cmd['stdout']
        raise ValueError("Could not locate locate '%s' on fake cmd db" % cmd)


def utils_run(cmd):
    return FakeCmd(cmd)

all_nodes_contents = "0\n"
online_nodes_contents = "0\n"


class TestNumaNode(unittest.TestCase):

    def setUp(self):
        self.god = mock.mock_god(ut=self)
        self.god.stub_with(utils, 'run', utils_run)
        all_nodes = tempfile.NamedTemporaryFile(delete=False)
        all_nodes.write(all_nodes_contents)
        all_nodes.close()
        online_nodes = tempfile.NamedTemporaryFile(delete=False)
        online_nodes.write(online_nodes_contents)
        online_nodes.close()
        self.all_nodes_path = all_nodes.name
        self.online_nodes_path = online_nodes.name
        self.numa_node = utils_misc.NumaNode(-1,
                                             self.all_nodes_path,
                                             self.online_nodes_path)

    def test_get_node_cpus(self):
        self.assertEqual(self.numa_node.get_node_cpus(0), '0 1 2 3 4 5 6 7')

    def test_pin_cpu(self):
        self.assertEqual(self.numa_node.pin_cpu("1230"), "0")
        self.assertEqual(self.numa_node.dict["0"], ["1230"])

        self.assertEqual(self.numa_node.pin_cpu("1231"), "1")
        self.assertEqual(self.numa_node.dict["1"], ["1231"])

        self.assertEqual(self.numa_node.pin_cpu("1232"), "2")
        self.assertEqual(self.numa_node.dict["2"], ["1232"])

        self.assertEqual(self.numa_node.pin_cpu("1233"), "3")
        self.assertEqual(self.numa_node.dict["3"], ["1233"])

        self.assertEqual(self.numa_node.pin_cpu("1234"), "4")
        self.assertEqual(self.numa_node.dict["4"], ["1234"])

        self.assertEqual(self.numa_node.pin_cpu("1235"), "5")
        self.assertEqual(self.numa_node.dict["5"], ["1235"])

        self.assertEqual(self.numa_node.pin_cpu("1236"), "6")
        self.assertEqual(self.numa_node.dict["6"], ["1236"])

        self.assertEqual(self.numa_node.pin_cpu("1237"), "7")
        self.assertEqual(self.numa_node.dict["7"], ["1237"])

        self.assertTrue("free" not in self.numa_node.dict.values())

    def test_free_cpu(self):
        self.assertEqual(self.numa_node.pin_cpu("1230"), "0")
        self.assertEqual(self.numa_node.dict["0"], ["1230"])

        self.assertEqual(self.numa_node.pin_cpu("1231"), "1")
        self.assertEqual(self.numa_node.dict["1"], ["1231"])

        self.numa_node.free_cpu("0")
        self.assertEqual(self.numa_node.dict["0"], [])
        self.assertEqual(self.numa_node.dict["1"], ["1231"])

    def test_bitlist_to_string(self):
        string = 'foo'
        bitlist = [0, 1, 1, 0, 0, 1, 1, 0, 0, 1,
                   1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]
        self.assertEqual(utils_misc.string_to_bitlist(string), bitlist)

    def test_string_to_bitlist(self):
        bitlist = [0, 1, 1, 0, 0, 0, 1, 0, 0, 1,
                   1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0]
        string = 'bar'
        self.assertEqual(utils_misc.bitlist_to_string(bitlist), string)

    def tearDown(self):
        self.god.unstub_all()
        os.unlink(self.all_nodes_path)
        os.unlink(self.online_nodes_path)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = utils_net
import openvswitch
import re
import os
import socket
import fcntl
import struct
import logging
import random
import math
import time
import shelve
import commands
from autotest.client import utils, os_dep
from autotest.client.shared import error
import propcan
import utils_misc
import arch
import aexpect
from versionable_class import factory

CTYPES_SUPPORT = True
try:
    import ctypes
except ImportError:
    CTYPES_SUPPORT = False

SYSFS_NET_PATH = "/sys/class/net"
PROCFS_NET_PATH = "/proc/net/dev"
# globals
sock = None
sockfd = None


class NetError(Exception):
    pass


class TAPModuleError(NetError):

    def __init__(self, devname, action="open", details=None):
        NetError.__init__(self, devname)
        self.devname = devname
        self.details = details

    def __str__(self):
        e_msg = "Can't %s %s" % (self.action, self.devname)
        if self.details is not None:
            e_msg += " : %s" % self.details
        return e_msg


class TAPNotExistError(NetError):

    def __init__(self, ifname):
        NetError.__init__(self, ifname)
        self.ifname = ifname

    def __str__(self):
        return "Interface %s does not exist" % self.ifname


class TAPCreationError(NetError):

    def __init__(self, ifname, details=None):
        NetError.__init__(self, ifname, details)
        self.ifname = ifname
        self.details = details

    def __str__(self):
        e_msg = "Cannot create TAP device %s" % self.ifname
        if self.details is not None:
            e_msg += ": %s" % self.details
        return e_msg


class MacvtapCreationError(NetError):

    def __init__(self, ifname, base_interface, details=None):
        NetError.__init__(self, ifname, details)
        self.ifname = ifname
        self.interface = base_interface
        self.details = details

    def __str__(self):
        e_msg = "Cannot create macvtap device %s " % self.ifname
        e_msg += "base physical interface %s." % self.interface
        if self.details is not None:
            e_msg += ": %s" % self.details
        return e_msg


class MacvtapGetBaseInterfaceError(NetError):

    def __init__(self, ifname=None, details=None):
        NetError.__init__(self, ifname, details)
        self.ifname = ifname
        self.details = details

    def __str__(self):
        e_msg = "Cannot get a valid physical interface to create macvtap."
        if self.ifname:
            e_msg += "physical interface is : %s " % self.ifname
        if self.details is not None:
            e_msg += "error info: %s" % self.details
        return e_msg


class TAPBringUpError(NetError):

    def __init__(self, ifname):
        NetError.__init__(self, ifname)
        self.ifname = ifname

    def __str__(self):
        return "Cannot bring up TAP %s" % self.ifname


class BRAddIfError(NetError):

    def __init__(self, ifname, brname, details):
        NetError.__init__(self, ifname, brname, details)
        self.ifname = ifname
        self.brname = brname
        self.details = details

    def __str__(self):
        return ("Can't add interface %s to bridge %s: %s" %
                (self.ifname, self.brname, self.details))


class BRDelIfError(NetError):

    def __init__(self, ifname, brname, details):
        NetError.__init__(self, ifname, brname, details)
        self.ifname = ifname
        self.brname = brname
        self.details = details

    def __str__(self):
        return ("Can't remove interface %s from bridge %s: %s" %
                (self.ifname, self.brname, self.details))


class IfNotInBridgeError(NetError):

    def __init__(self, ifname, details):
        NetError.__init__(self, ifname, details)
        self.ifname = ifname
        self.details = details

    def __str__(self):
        return ("Interface %s is not present on any bridge: %s" %
                (self.ifname, self.details))


class OpenflowSwitchError(NetError):

    def __init__(self, brname):
        NetError.__init__(self, brname)
        self.brname = brname

    def __str__(self):
        return ("Only support openvswitch, make sure your env support ovs, "
                "and your bridge %s is an openvswitch" % self.brname)


class BRNotExistError(NetError):

    def __init__(self, brname, details):
        NetError.__init__(self, brname, details)
        self.brname = brname
        self.details = details

    def __str__(self):
        return ("Bridge %s does not exist: %s" % (self.brname, self.details))


class IfChangeBrError(NetError):

    def __init__(self, ifname, old_brname, new_brname, details):
        NetError.__init__(self, ifname, old_brname, new_brname, details)
        self.ifname = ifname
        self.new_brname = new_brname
        self.old_brname = old_brname
        self.details = details

    def __str__(self):
        return ("Can't move interface %s from bridge %s to bridge %s: %s" %
                (self.ifname, self.new_brname, self.oldbrname, self.details))


class IfChangeAddrError(NetError):

    def __init__(self, ifname, ipaddr, details):
        NetError.__init__(self, ifname, ipaddr, details)
        self.ifname = ifname
        self.ipaddr = ipaddr
        self.details = details

    def __str__(self):
        return ("Can't change interface IP address %s from interface %s: %s" %
                (self.ifname, self.ipaddr, self.details))


class BRIpError(NetError):

    def __init__(self, brname):
        NetError.__init__(self, brname)
        self.brname = brname

    def __str__(self):
        return ("Bridge %s doesn't have an IP address assigned. It's"
                " impossible to start dnsmasq for this bridge." %
                (self.brname))


class VMIPV6NeighNotFoundError(NetError):

    def __init__(self, ipv6_address):
        NetError.__init__(self, ipv6_address)
        self.ipv6_address = ipv6_address

    def __str__(self):
        return "No IPV6 neighbours with address %s" % self.ipv6_address


class VMIPV6AdressError(NetError):

    def __init__(self, error_info):
        NetError.__init__(self, error_info)
        self.error_info = error_info

    def __str__(self):
        return "%s, check your test env supports IPV6" % self.error_info


class HwAddrSetError(NetError):

    def __init__(self, ifname, mac):
        NetError.__init__(self, ifname, mac)
        self.ifname = ifname
        self.mac = mac

    def __str__(self):
        return "Can not set mac %s to interface %s" % (self.mac, self.ifname)


class HwAddrGetError(NetError):

    def __init__(self, ifname):
        NetError.__init__(self, ifname)
        self.ifname = ifname

    def __str__(self):
        return "Can not get mac of interface %s" % self.ifname


class IPAddrGetError(NetError):

    def __init__(self, mac_addr, details=None):
        NetError.__init__(self, mac_addr)
        self.mac_addr = mac_addr
        self.details = details

    def __str__(self):
        details_msg = "Get guest nic ['%s'] IP address error" % self.mac_addr
        details_msg += "error info: %s" % self.details
        return details_msg


class HwOperstarteGetError(NetError):

    def __init__(self, ifname, details=None):
        NetError.__init__(self, ifname)
        self.ifname = ifname
        self.details = details

    def __str__(self):
        return "Get nic %s operstate error, %s" % (self.ifname, self.details)


class VlanError(NetError):

    def __init__(self, ifname, details):
        NetError.__init__(self, ifname, details)
        self.ifname = ifname
        self.details = details

    def __str__(self):
        return ("Vlan error on interface %s: %s" %
                (self.ifname, self.details))


class VMNetError(NetError):

    def __str__(self):
        return ("VMNet instance items must be dict-like and contain "
                "a 'nic_name' mapping")


class DbNoLockError(NetError):

    def __str__(self):
        return "Attempt made to access database with improper locking"


class DelLinkError(NetError):

    def __init__(self, ifname, details=None):
        NetError.__init__(self, ifname, details)
        self.ifname = ifname
        self.details = details

    def __str__(self):
        e_msg = "Cannot delete interface %s" % self.ifname
        if self.details is not None:
            e_msg += ": %s" % self.details
        return e_msg


def warp_init_del(func):
    def new_func(*args, **argkw):
        globals()["sock"] = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        globals()["sockfd"] = globals()["sock"].fileno()
        try:
            return func(*args, **argkw)
        finally:
            globals()["sock"].close()
            globals()["sock"] = None
            globals()["sockfd"] = None
    return new_func


class Interface(object):

    ''' Class representing a Linux network device. '''

    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return "<%s %s at 0x%x>" % (self.__class__.__name__,
                                    self.name, id(self))

    @warp_init_del
    def up(self):
        '''
        Bring up the bridge interface. Equivalent to ifconfig [iface] up.
        '''

        # Get existing device flags
        ifreq = struct.pack('16sh', self.name, 0)
        flags = struct.unpack('16sh',
                              fcntl.ioctl(sockfd, arch.SIOCGIFFLAGS, ifreq))[1]

        # Set new flags
        flags = flags | arch.IFF_UP
        ifreq = struct.pack('16sh', self.name, flags)
        fcntl.ioctl(sockfd, arch.SIOCSIFFLAGS, ifreq)

    @warp_init_del
    def down(self):
        '''
        Bring up the bridge interface. Equivalent to ifconfig [iface] down.
        '''

        # Get existing device flags
        ifreq = struct.pack('16sh', self.name, 0)
        flags = struct.unpack('16sh',
                              fcntl.ioctl(sockfd, arch.SIOCGIFFLAGS, ifreq))[1]

        # Set new flags
        flags = flags & ~arch.IFF_UP
        ifreq = struct.pack('16sh', self.name, flags)
        fcntl.ioctl(sockfd, arch.SIOCSIFFLAGS, ifreq)

    @warp_init_del
    def is_up(self):
        '''
        Return True if the interface is up, False otherwise.
        '''
        # Get existing device flags
        ifreq = struct.pack('16sh', self.name, 0)
        flags = struct.unpack('16sh',
                              fcntl.ioctl(sockfd, arch.SIOCGIFFLAGS, ifreq))[1]

        # Set new flags
        if flags & arch.IFF_UP:
            return True
        else:
            return False

    @warp_init_del
    def get_mac(self):
        '''
        Obtain the device's mac address.
        '''
        ifreq = struct.pack('16sH14s', self.name, socket.AF_UNIX, '\x00' * 14)
        res = fcntl.ioctl(sockfd, arch.SIOCGIFHWADDR, ifreq)
        address = struct.unpack('16sH14s', res)[2]
        mac = struct.unpack('6B8x', address)

        return ":".join(['%02X' % i for i in mac])

    @warp_init_del
    def set_mac(self, newmac):
        '''
        Set the device's mac address. Device must be down for this to
        succeed.
        '''
        macbytes = [int(i, 16) for i in newmac.split(':')]
        ifreq = struct.pack('16sH6B8x', self.name, socket.AF_UNIX, *macbytes)
        fcntl.ioctl(sockfd, arch.SIOCSIFHWADDR, ifreq)

    @warp_init_del
    def get_ip(self):
        """
        Get ip address of this interface
        """
        ifreq = struct.pack('16sH14s', self.name, socket.AF_INET, '\x00' * 14)
        try:
            res = fcntl.ioctl(sockfd, arch.SIOCGIFADDR, ifreq)
        except IOError:
            return None
        ip = struct.unpack('16sH2x4s8x', res)[2]

        return socket.inet_ntoa(ip)

    @warp_init_del
    def set_ip(self, newip):
        """
        Set the ip address of the interface
        """
        ipbytes = socket.inet_aton(newip)
        ifreq = struct.pack('16sH2s4s8s', self.name,
                            socket.AF_INET, '\x00' * 2, ipbytes, '\x00' * 8)
        fcntl.ioctl(sockfd, arch.SIOCSIFADDR, ifreq)

    @warp_init_del
    def get_netmask(self):
        """
        Get ip network netmask
        """
        if not CTYPES_SUPPORT:
            raise error.TestNAError(
                "Getting the netmask requires python > 2.4")
        ifreq = struct.pack('16sH14s', self.name, socket.AF_INET, '\x00' * 14)
        try:
            res = fcntl.ioctl(sockfd, arch.SIOCGIFNETMASK, ifreq)
        except IOError:
            return 0
        netmask = socket.ntohl(struct.unpack('16sH2xI8x', res)[2])

        return 32 - int(math.log(ctypes.c_uint32(~netmask).value + 1, 2))

    @warp_init_del
    def set_netmask(self, netmask):
        """
        Set netmask
        """
        if not CTYPES_SUPPORT:
            raise error.TestNAError(
                "Setting the netmask requires python > 2.4")
        netmask = ctypes.c_uint32(~((2 ** (32 - netmask)) - 1)).value
        nmbytes = socket.htonl(netmask)
        ifreq = struct.pack('16sH2si8s', self.name,
                            socket.AF_INET, '\x00' * 2, nmbytes, '\x00' * 8)
        fcntl.ioctl(sockfd, arch.SIOCSIFNETMASK, ifreq)

    @warp_init_del
    def get_index(self):
        '''
        Convert an interface name to an index value.
        '''
        ifreq = struct.pack('16si', self.name, 0)
        res = fcntl.ioctl(sockfd, arch.SIOCGIFINDEX, ifreq)
        return struct.unpack("16si", res)[1]

    @warp_init_del
    def get_stats(self):
        """
        Get the status information of the Interface
        """
        spl_re = re.compile(r"\s+")

        fp = open(PROCFS_NET_PATH)
        # Skip headers
        fp.readline()
        fp.readline()
        while True:
            data = fp.readline()
            if not data:
                return None

            name, stats_str = data.split(":")
            if name.strip() != self.name:
                continue

            stats = [int(a) for a in spl_re.split(stats_str.strip())]
            break

        titles = ["rx_bytes", "rx_packets", "rx_errs", "rx_drop", "rx_fifo",
                  "rx_frame", "rx_compressed", "rx_multicast", "tx_bytes",
                  "tx_packets", "tx_errs", "tx_drop", "tx_fifo", "tx_colls",
                  "tx_carrier", "tx_compressed"]
        return dict(zip(titles, stats))

    def is_brport(self):
        """
        Check Whether this Interface is a bridge port_to_br
        """
        path = os.path.join(SYSFS_NET_PATH, self.name)
        if os.path.exists(os.path.join(path, "brport")):
            return True
        else:
            return False

    def __netlink_pack(self, msgtype, flags, seq, pid, data):
        '''
        Pack with Netlink message header and data
        into Netlink package
        :msgtype:  Message types: e.g. RTM_DELLINK
        :flags: Flag bits
        :seq: The sequence number of the message
        :pid: Process ID
        :data:  data
        :return: return the package
        '''
        return struct.pack('IHHII', 16 + len(data),
                           msgtype, flags, seq, pid) + data

    def __netlink_unpack(self, data):
        '''
        Unpack the data from kernel
        '''
        out = []
        while data:
            length, msgtype, flags, seq, pid = struct.unpack('IHHII',
                                                             data[:16])
            if len(data) < length:
                raise RuntimeError("Buffer overrun!")
            out.append((msgtype, flags, seq, pid, data[16:length]))
            data = data[length:]

        return out

    def dellink(self):
        '''
        Delete the interface. Equivalent to 'ip link delete NAME'.
        '''
        # create socket
        sock = socket.socket(socket.AF_NETLINK,
                             socket.SOCK_RAW,
                             arch.NETLINK_ROUTE)

        # Get the interface index
        interface_index = self.get_index()

        # send data to socket
        sock.send(self.__netlink_pack(msgtype=arch.RTM_DELLINK,
                                      flags=arch.NLM_F_REQUEST | arch.NLM_F_ACK,
                                      seq=1, pid=0,
                                      data=struct.pack('BxHiII', arch.AF_PACKET,
                                                       0, interface_index, 0, 0)))

        # receive data from socket
        try:
            while True:
                data_recv = sock.recv(1024)
                for msgtype, flags, mseq, pid, data in \
                        self.__netlink_unpack(data_recv):
                    if msgtype == arch.NLMSG_ERROR:
                        (err_no,) = struct.unpack("i", data[:4])
                        if err_no == 0:
                            return 0
                        else:
                            raise DelLinkError(self.name, os.strerror(-err_no))
                    else:
                        raise DelLinkError(self.name, "unexpected error")
        finally:
            sock.close()


class Macvtap(Interface):

    """
    class of macvtap, base Interface
    """

    def __init__(self, tapname=None):
        if tapname is None:
            self.tapname = "macvtap" + utils_misc.generate_random_id()
        else:
            self.tapname = tapname
        Interface.__init__(self, self.tapname)

    def get_tapname(self):
        return self.tapname

    def get_device(self):
        return "/dev/tap%s" % self.get_index()

    def ip_link_ctl(self, params, ignore_status=False):
        return utils.run(os_dep.command("ip"), timeout=10,
                         ignore_status=ignore_status, verbose=False,
                         args=params)

    def create(self, device, mode="vepa"):
        """
        Create a macvtap device, only when the device does not exist.

        :param device: Macvtap device to be created.
        :param mode: Creation mode.
        """
        path = os.path.join(SYSFS_NET_PATH, self.tapname)
        if not os.path.exists(path):
            self.ip_link_ctl(["link", "add", "link", device, "name",
                              self.tapname, "type", "macvtap", "mode", mode])

    def delete(self):
        path = os.path.join(SYSFS_NET_PATH, self.tapname)
        if os.path.exists(path):
            self.ip_link_ctl(["link", "delete", self.tapname])

    def open(self):
        device = self.get_device()
        try:
            return os.open(device, os.O_RDWR)
        except OSError, e:
            raise TAPModuleError(device, "open", e)


def get_macvtap_base_iface(base_interface=None):
    """
    Get physical interface to create macvtap, if you assigned base interface
    is valid(not belong to any bridge and is up), will use it; else use the
    first physical interface,  which is not a brport and up.
    """
    tap_base_device = None

    (dev_int, _) = get_sorted_net_if()
    if not dev_int:
        err_msg = "Cannot get any physical interface from the host"
        raise MacvtapGetBaseInterfaceError(details=err_msg)

    if base_interface and base_interface in dev_int:
        base_inter = Interface(base_interface)
        if (not base_inter.is_brport()) and base_inter.is_up():
            tap_base_device = base_interface

    if not tap_base_device:
        if base_interface:
            warn_msg = "Can not use '%s' as macvtap base interface, "
            warn_msg += "will choice automatically"
            logging.warn(warn_msg % base_interface)
        for interface in dev_int:
            base_inter = Interface(interface)
            if base_inter.is_brport():
                continue
            if base_inter.is_up():
                tap_base_device = interface
                break

    if not tap_base_device:
        err_msg = ("Could not find a valid physical interface to create "
                   "macvtap, make sure the interface is up and it does not "
                   "belong to any bridge.")
        raise MacvtapGetBaseInterfaceError(details=err_msg)
    return tap_base_device


def create_macvtap(ifname, mode="vepa", base_if=None, mac_addr=None):
    """
    Create Macvtap device, return a object of Macvtap

    :param ifname: macvtap interface name
    :param mode:  macvtap type mode ("vepa, bridge,..)
    :param base_if: physical interface to create macvtap
    :param mac_addr: macvtap mac address
    """
    try:
        base_if = get_macvtap_base_iface(base_if)
        o_macvtap = Macvtap(ifname)
        o_macvtap.create(base_if, mode)
        if mac_addr:
            o_macvtap.set_mac(mac_addr)
        return o_macvtap
    except Exception, e:
        raise MacvtapCreationError(ifname, base_if, e)


def open_macvtap(macvtap_object, queues=1):
    """
    Open a macvtap device and returns its file descriptors which are used by
    fds=<fd1:fd2:..> parameter of qemu

    For single queue, only returns one file descriptor, it's used by
    fd=<fd> legacy parameter of qemu

    If you not have a switch support vepa in you env, run this type case you
    need at least two nic on you host [just workaround]

    :param macvtap_object:  macvtap object
    :param queues: Queue number
    """
    tapfds = []
    for queue in range(int(queues)):
        tapfds.append(str(macvtap_object.open()))
    return ":".join(tapfds)


def create_and_open_macvtap(ifname, mode="vepa", queues=1, base_if=None,
                            mac_addr=None):
    """
    Create a new macvtap device, open it, and return the fds

    :param ifname: macvtap interface name
    :param mode:  macvtap type mode ("vepa, bridge,..)
    :param queues: Queue number
    :param base_if: physical interface to create macvtap
    :param mac_addr: macvtap mac address
    """
    o_macvtap = create_macvtap(ifname, mode, base_if, mac_addr)
    return open_macvtap(o_macvtap, queues)


class Bridge(object):

    def get_structure(self):
        """
        Get bridge list.
        """
        ebr_i = re.compile(r"^(\S+).*?\s+$", re.MULTILINE)
        br_i = re.compile(r"^(\S+).*?(\S+)$", re.MULTILINE)
        nbr_i = re.compile(r"^\s+(\S+)$", re.MULTILINE)
        out_line = (utils.run(r"brctl show", verbose=False).stdout.splitlines())
        result = dict()
        bridge = None
        iface = None

        for line in out_line[1:]:
            br_line = ebr_i.findall(line)
            if br_line:
                (tmpbr) = br_line[0]
                bridge = tmpbr
                result[bridge] = []
            else:
                br_line = br_i.findall(line)
                if br_line:
                    (tmpbr, iface) = br_i.findall(line)[0]
                    bridge = tmpbr
                    result[bridge] = []
                else:
                    if_line = nbr_i.findall(line)
                    if if_line:
                        iface = if_line[0]

            if iface and iface not in ['yes', 'no']:  # add interface to bridge
                result[bridge].append(iface)

        return result

    def list_br(self):
        return self.get_structure().keys()

    def list_iface(self):
        """
        Return all interfaces used by bridge.
        """
        interface_list = []
        for value in self.get_structure().values():
            interface_list += value
        return list(set(interface_list))

    def port_to_br(self, port_name):
        """
        Return bridge which contain port.

        :param port_name: Name of port.
        :return: Bridge name or None if there is no bridge which contain port.
        """
        bridge = None
        for (br, ifaces) in self.get_structure().iteritems():
            if port_name in ifaces:
                bridge = br
        return bridge

    def _br_ioctl(self, io_cmd, brname, ifname):
        ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)
        index = if_nametoindex(ifname)
        if index == 0:
            raise TAPNotExistError(ifname)
        ifr = struct.pack("16si", brname, index)
        _ = fcntl.ioctl(ctrl_sock, io_cmd, ifr)
        ctrl_sock.close()

    def add_port(self, brname, ifname):
        """
        Add a device to bridge

        :param ifname: Name of TAP device
        :param brname: Name of the bridge
        """
        try:
            self._br_ioctl(arch.SIOCBRADDIF, brname, ifname)
        except IOError, details:
            raise BRAddIfError(ifname, brname, details)

    def del_port(self, brname, ifname):
        """
        Remove a TAP device from bridge

        :param ifname: Name of TAP device
        :param brname: Name of the bridge
        """
        try:
            self._br_ioctl(arch.SIOCBRDELIF, brname, ifname)
        except IOError, details:
            raise BRDelIfError(ifname, brname, details)

    def add_bridge(self, brname):
        """
        Add a bridge in host
        """
        ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)
        fcntl.ioctl(ctrl_sock, arch.SIOCBRADDBR, brname)
        ctrl_sock.close()

    def del_bridge(self, brname):
        """
        Delete a bridge in host
        """
        ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)
        fcntl.ioctl(ctrl_sock, arch.SIOCBRDELBR, brname)
        ctrl_sock.close()


def __init_openvswitch(func):
    """
    Decorator used for late init of __ovs variable.
    """
    def wrap_init(*args, **kargs):
        global __ovs
        if __ovs is None:
            try:
                __ovs = factory(openvswitch.OpenVSwitchSystem)()
                __ovs.init_system()
                if (not __ovs.check()):
                    raise Exception("Check of OpenVSwitch failed.")
            except Exception, e:
                logging.debug("Host does not support OpenVSwitch: %s", e)

        return func(*args, **kargs)
    return wrap_init


# Global variable for OpenVSwitch
__ovs = None
__bridge = Bridge()


def if_nametoindex(ifname):
    """
    Map an interface name into its corresponding index.
    Returns 0 on error, as 0 is not a valid index

    :param ifname: interface name
    """
    ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)
    ifr = struct.pack("16si", ifname, 0)
    r = fcntl.ioctl(ctrl_sock, arch.SIOCGIFINDEX, ifr)
    index = struct.unpack("16si", r)[1]
    ctrl_sock.close()
    return index


def vnet_mq_probe(tapfd):
    """
    Check if the IFF_MULTI_QUEUE is support by tun.

    :param tapfd: the file descriptor of /dev/net/tun
    """
    u = struct.pack("I", 0)
    try:
        r = fcntl.ioctl(tapfd, arch.TUNGETFEATURES, u)
    except OverflowError:
        logging.debug("Fail to get tun features!")
        return False
    flags = struct.unpack("I", r)[0]
    if flags & arch.IFF_MULTI_QUEUE:
        return True
    else:
        return False


def vnet_hdr_probe(tapfd):
    """
    Check if the IFF_VNET_HDR is support by tun.

    :param tapfd: the file descriptor of /dev/net/tun
    """
    u = struct.pack("I", 0)
    try:
        r = fcntl.ioctl(tapfd, arch.TUNGETFEATURES, u)
    except OverflowError:
        logging.debug("Fail to get tun features!")
        return False
    flags = struct.unpack("I", r)[0]
    if flags & arch.IFF_VNET_HDR:
        return True
    else:
        return False


def open_tap(devname, ifname, queues=1, vnet_hdr=True):
    """
    Open a tap device and returns its file descriptors which are used by
    fds=<fd1:fd2:..> parameter of qemu

    For single queue, only returns one file descriptor, it's used by
    fd=<fd> legacy parameter of qemu

    :param devname: TUN device path
    :param ifname: TAP interface name
    :param queues: Queue number
    :param vnet_hdr: Whether enable the vnet header
    """
    tapfds = []

    for i in range(int(queues)):
        try:
            tapfds.append(str(os.open(devname, os.O_RDWR)))
        except OSError, e:
            raise TAPModuleError(devname, "open", e)

        flags = arch.IFF_TAP | arch.IFF_NO_PI

        if vnet_mq_probe(int(tapfds[i])):
            flags |= arch.IFF_MULTI_QUEUE
        elif (int(queues) > 1):
            raise TAPCreationError(ifname, "Host doesn't support MULTI_QUEUE")

        if vnet_hdr and vnet_hdr_probe(int(tapfds[i])):
            flags |= arch.IFF_VNET_HDR

        ifr = struct.pack("16sh", ifname, flags)
        try:
            r = fcntl.ioctl(int(tapfds[i]), arch.TUNSETIFF, ifr)
        except IOError, details:
            raise TAPCreationError(ifname, details)

    return ':'.join(tapfds)


def is_virtual_network_dev(dev_name):
    """
    :param dev_name: Device name.

    :return: True if dev_name is in virtual/net dir, else false.
    """
    if dev_name in os.listdir("/sys/devices/virtual/net/"):
        return True
    else:
        return False


def find_dnsmasq_listen_address():
    """
    Search all dnsmasq listen addresses.

    :param bridge_name: Name of bridge.
    :param bridge_ip: Bridge ip.
    :return: List of ip where dnsmasq is listening.
    """
    cmd = "ps -Af | grep dnsmasq"
    result = utils.run(cmd).stdout
    return re.findall("--listen-address (.+?) ", result, re.MULTILINE)


def local_runner(cmd, timeout=None):
    return utils.run(cmd, verbose=False, timeout=timeout).stdout


def local_runner_status(cmd, timeout=None):
    return utils.run(cmd, verbose=False, timeout=timeout).exit_status


def get_net_if(runner=None, state=None):
    """
    :param runner: command runner.
    :param div_phy_virt: if set true, will return a tuple division real
                         physical interface and virtual interface
    :return: List of network interfaces.
    """
    if runner is None:
        runner = local_runner
    if state is None:
        state = ".*"
    cmd = "ip link"
    result = runner(cmd)
    return re.findall(r"^\d+: (\S+?)[@:].*state %s.*$" % (state),
                      result,
                      re.MULTILINE)


def get_sorted_net_if():
    """
    Get all network interfaces, but sort them among physical and virtual if.

    :return: Tuple (physical interfaces, virtual interfaces)
    """
    all_interfaces = get_net_if()
    phy_interfaces = []
    vir_interfaces = []
    for d in all_interfaces:
        path = os.path.join(SYSFS_NET_PATH, d)
        if not os.path.isdir(path):
            continue
        if not os.path.exists(os.path.join(path, "device")):
            vir_interfaces.append(d)
        else:
            phy_interfaces.append(d)
    return (phy_interfaces, vir_interfaces)


def get_net_if_addrs(if_name, runner=None):
    """
    Get network device ip addresses. ioctl not used because it's not
    compatible with ipv6 address.

    :param if_name: Name of interface.
    :return: List ip addresses of network interface.
    """
    if runner is None:
        runner = local_runner
    cmd = "ip addr show %s" % (if_name)
    result = runner(cmd)
    return {"ipv4": re.findall("inet (.+?)/..?", result, re.MULTILINE),
            "ipv6": re.findall("inet6 (.+?)/...?", result, re.MULTILINE),
            "mac": re.findall("link/ether (.+?) ", result, re.MULTILINE)}


def get_net_if_addrs_win(session, mac_addr):
    """
    Try to get windows guest nic address by serial session

    :param session: serial sesssion
    :param mac_addr:  guest nic mac address
    :return: List ip addresses of network interface.
    """
    ip_address = get_windows_nic_attribute(session, "macaddress",
                                           mac_addr, "IPAddress",
                                           global_switch="nicconfig")
    return {"ipv4": re.findall('(\d+.\d+.\d+.\d+)"', ip_address),
            "ipv6": re.findall('(fe80.*?)"', ip_address)}


def get_net_if_and_addrs(runner=None):
    """
    :return: Dict of interfaces and their addresses {"ifname": addrs}.
    """
    ret = {}
    ifs = get_net_if(runner)
    for iface in ifs:
        ret[iface] = get_net_if_addrs(iface, runner)
    return ret


def get_guest_ip_addr(session, mac_addr, os_type="linux", ip_version="ipv4",
                      linklocal=False):
    """
    Get guest ip addresses by serial session

    :param session: serial session
    :param mac_addr: nic mac address of the nic that you want get
    :param os_type: guest os type, windows or linux
    :param ip_version: guest ip version, ipv4 or ipv6
    :param linklocal: Wether ip address is local or remote
    :return: ip addresses of network interface.
    """
    if ip_version == "ipv6" and linklocal:
        return ipv6_from_mac_addr(mac_addr)
    try:
        if os_type == "linux":
            nic_ifname = get_linux_ifname(session, mac_addr)
            info_cmd = "ifconfig -a; ethtool -S %s" % nic_ifname
            nic_address = get_net_if_addrs(nic_ifname, session.cmd)
        elif os_type == "windows":
            info_cmd = "ipconfig /all"
            nic_address = get_net_if_addrs_win(session, mac_addr)
        else:
            info_cmd = ""
            raise IPAddrGetError(mac_addr, "Unknown os type")

        if ip_version == "ipv4":
            return nic_address["ipv4"][-1]
        else:
            global_address = [x for x in nic_address["ipv6"]
                              if not x.lower().startswith("fe80")]
            if global_address:
                return global_address[0]
    except Exception, err:
        logging.debug(session.cmd_output(info_cmd))
        raise IPAddrGetError(mac_addr, err)


def renew_guest_ip(session, mac_addr, os_type="linux", ip_version="ipv4"):
    """
    Renew guest ip by serial session

    :param session: serial session
    :param mac_addr: nic mac address of the nic that you want renew
    :param os_type: guest os type, windows or linux
    :param ip_version: guest ip version, ipv4 or ipv6
    """
    if os_type == "linux":
        nic_ifname = get_linux_ifname(session, mac_addr)
        renew_cmd = "ifconfig %s up; " % nic_ifname
        renew_cmd += "pidof dhclient && killall dhclient; "
        if ip_version == "ipv6":
            renew_cmd += "dhclient -6 %s &" % nic_ifname
        else:
            renew_cmd += "dhclient %s &" % nic_ifname
    elif os_type == "windows":
        nic_connectionid = get_windows_nic_attribute(session,
                                                     "macaddress", mac_addr,
                                                     "netconnectionid")
        renew_cmd = 'ipconfig /renew "%s"' % nic_connectionid

    session.cmd_output_safe(renew_cmd)


def set_net_if_ip(if_name, ip_addr, runner=None):
    """
    Get network device ip addresses. ioctl not used because there is
    incompatibility with ipv6.

    :param if_name: Name of interface.
    :param ip_addr: Interface ip addr in format "ip_address/mask".
    :raise: IfChangeAddrError.
    """
    if runner is None:
        runner = local_runner
    cmd = "ip addr add %s dev %s" % (ip_addr, if_name)
    try:
        runner(cmd)
    except error.CmdError, e:
        raise IfChangeAddrError(if_name, ip_addr, e)


def get_net_if_operstate(ifname, runner=None):
    """
    Get linux host/guest network device operstate.

    :param if_name: Name of the interface.
    :raise: HwOperstarteGetError.
    """
    if runner is None:
        runner = local_runner
    cmd = "cat /sys/class/net/%s/operstate" % ifname
    try:
        operstate = runner(cmd)
        if "up" in operstate:
            return "up"
        elif "down" in operstate:
            return "down"
        elif "unknown" in operstate:
            return "unknown"
        else:
            raise HwOperstarteGetError(ifname, "operstate is not known.")
    except error.CmdError:
        raise HwOperstarteGetError(ifname, "run operstate cmd error.")


def ipv6_from_mac_addr(mac_addr):
    """
    :return: Ipv6 address for communication in link range.
    """
    mp = mac_addr.split(":")
    mp[0] = ("%x") % (int(mp[0], 16) ^ 0x2)
    mac_address = "fe80::%s%s:%sff:fe%s:%s%s" % tuple(mp)
    return ":".join(map(lambda x: x.lstrip("0"), mac_address.split(":")))


def refresh_neigh_table(interface_name=None, neigh_address="ff02::1"):
    """
    Refresh host neighbours table, if interface_name is assigned only refresh
    neighbours of this interface, else refresh the all the neighbours.
    """
    if isinstance(interface_name, list):
        interfaces = interface_name
    elif isinstance(interface_name, str):
        interfaces = interface_name.split()
    else:
        interfaces = filter(lambda x: "-" not in x, get_net_if())
        interfaces.remove("lo")

    for interface in interfaces:
        refresh_cmd = "ping6 -c 2 -I %s %s > /dev/null" % (interface,
                                                           neigh_address)
        utils.system(refresh_cmd, ignore_status=True)


def get_neighbours_info(neigh_address="", interface_name=None):
    """
    Get the neighbours infomation
    """
    refresh_neigh_table(interface_name, neigh_address)
    cmd = "ip -6 neigh show nud reachable"
    if neigh_address:
        cmd += " %s" % neigh_address
    output = utils.system_output(cmd)
    if not output:
        raise VMIPV6NeighNotFoundError(neigh_address)
    all_neigh = {}
    neigh_info = {}
    for line in output.splitlines():
        neigh_address = line.split()[0]
        neigh_info["address"] = neigh_address
        neigh_info["attach_if"] = line.split()[2]
        neigh_mac = line.split()[4]
        neigh_info["mac"] = neigh_mac
        all_neigh[neigh_mac] = neigh_info
        all_neigh[neigh_address] = neigh_info
    return all_neigh


def neigh_reachable(neigh_address, attach_if=None):
    """
    Check the neighbour is reachable
    """
    try:
        get_neighbours_info(neigh_address, attach_if)
    except VMIPV6NeighNotFoundError:
        return False
    return True


def get_neigh_attch_interface(neigh_address):
    """
    Get the interface wihch can reach the neigh_address
    """
    return get_neighbours_info(neigh_address)[neigh_address]["attach_if"]


def get_neigh_mac(neigh_address):
    """
    Get neighbour mac by his address
    """
    return get_neighbours_info(neigh_address)[neigh_address]["mac"]


def check_add_dnsmasq_to_br(br_name, tmpdir):
    """
    Add dnsmasq for bridge. dnsmasq could be added only if bridge
    has assigned ip address.

    :param bridge_name: Name of bridge.
    :param bridge_ip: Bridge ip.
    :param tmpdir: Tmp dir for save pid file and ip range file.
    :return: When new dnsmasq is started name of pidfile  otherwise return
             None because system dnsmasq is already started on bridge.
    """
    br_ips = get_net_if_addrs(br_name)["ipv4"]
    if not br_ips:
        raise BRIpError(br_name)
    dnsmasq_listen = find_dnsmasq_listen_address()
    dhcp_ip_start = br_ips[0].split(".")
    dhcp_ip_start[3] = "128"
    dhcp_ip_start = ".".join(dhcp_ip_start)

    dhcp_ip_end = br_ips[0].split(".")
    dhcp_ip_end[3] = "254"
    dhcp_ip_end = ".".join(dhcp_ip_end)

    pidfile = ("%s-dnsmasq.pid") % (br_ips[0])
    leases = ("%s.leases") % (br_ips[0])

    if not (set(br_ips) & set(dnsmasq_listen)):
        logging.debug("There is no dnsmasq on br %s."
                      "Starting new one." % (br_name))
        utils.run("/usr/sbin/dnsmasq --strict-order --bind-interfaces"
                  " --pid-file=%s --conf-file= --except-interface lo"
                  " --listen-address %s --dhcp-range %s,%s --dhcp-leasefile=%s"
                  " --dhcp-lease-max=127 --dhcp-no-override" %
                  (os.path.join(tmpdir, pidfile), br_ips[0], dhcp_ip_start,
                   dhcp_ip_end, (os.path.join(tmpdir, leases))))
        return pidfile
    return None


@__init_openvswitch
def find_bridge_manager(br_name, ovs=None):
    """
    Finds bridge which contain interface iface_name.

    :param br_name: Name of interface.
    :return: (br_manager) which contain bridge or None.
    """
    if ovs is None:
        ovs = __ovs
    # find ifname in standard linux bridge.
    if br_name in __bridge.list_br():
        return __bridge
    elif ovs is not None and br_name in ovs.list_br():
        return ovs
    else:
        return None


@__init_openvswitch
def find_current_bridge(iface_name, ovs=None):
    """
    Finds bridge which contains interface iface_name.

    :param iface_name: Name of interface.
    :return: (br_manager, Bridge) which contain iface_name or None.
    """
    if ovs is None:
        ovs = __ovs
    # find ifname in standard linux bridge.
    master = __bridge
    bridge = master.port_to_br(iface_name)
    if bridge is None and ovs:
        master = ovs
        bridge = master.port_to_br(iface_name)

    if bridge is None:
        master = None

    return (master, bridge)


@__init_openvswitch
def change_iface_bridge(ifname, new_bridge, ovs=None):
    """
    Change bridge on which interface was added.

    :param ifname: Iface name or Iface struct.
    :param new_bridge: Name of new bridge.
    """
    if ovs is None:
        ovs = __ovs
    br_manager_new = find_bridge_manager(new_bridge, ovs)
    if br_manager_new is None:
        raise BRNotExistError(new_bridge, "")

    if type(ifname) is str:
        (br_manager_old, br_old) = find_current_bridge(ifname, ovs)
        if br_manager_old is not None:
            br_manager_old.del_port(br_old, ifname)
        br_manager_new.add_port(new_bridge, ifname)
    elif issubclass(type(ifname), VirtIface):
        br_manager_old = find_bridge_manager(ifname.netdst, ovs)
        if br_manager_old is not None:
            br_manager_old.del_port(ifname.netdst, ifname.ifname)
        br_manager_new.add_port(new_bridge, ifname.ifname)
        ifname.netdst = new_bridge
    else:
        raise error.AutotestError("Network interface %s is wrong type %s." %
                                  (ifname, new_bridge))


@__init_openvswitch
def add_to_bridge(ifname, brname, ovs=None):
    """
    Add a TAP device to bridge

    :param ifname: Name of TAP device
    :param brname: Name of the bridge
    :param ovs: OpenVSwitch object.
    """
    if ovs is None:
        ovs = __ovs

    _ifname = None
    if type(ifname) is str:
        _ifname = ifname
    elif issubclass(type(ifname), VirtIface):
        _ifname = ifname.ifname

    if brname in __bridge.list_br():
        # Try add port to standard bridge or openvswitch in compatible mode.
        __bridge.add_port(brname, _ifname)
        return

    if ovs is None:
        raise BRAddIfError(ifname, brname, "There is no bridge in system.")
    # Try add port to OpenVSwitch bridge.
    if brname in ovs.list_br():
        ovs.add_port(brname, ifname)


@__init_openvswitch
def del_from_bridge(ifname, brname, ovs=None):
    """
    Del a TAP device to bridge

    :param ifname: Name of TAP device
    :param brname: Name of the bridge
    :param ovs: OpenVSwitch object.
    """
    if ovs is None:
        ovs = __ovs

    _ifname = None
    if type(ifname) is str:
        _ifname = ifname
    elif issubclass(type(ifname), VirtIface):
        _ifname = ifname.ifname

    if ovs is None:
        raise BRDelIfError(ifname, brname, "There is no bridge in system.")

    if brname in __bridge.list_br():
        # Try add port to standard bridge or openvswitch in compatible mode.
        __bridge.del_port(brname, _ifname)
        return

    # Try add port to OpenVSwitch bridge.
    if brname in ovs.list_br():
        ovs.del_port(brname, _ifname)


@__init_openvswitch
def openflow_manager(br_name, command, flow_options=None, ovs=None):
    """
    Manager openvswitch flow rules

    :param br_name: name of the bridge
    :param command: manager cmd(add-flow, del-flows, dump-flows..)
    :param flow_options: open flow options
    :param ovs: OpenVSwitch object.
    """
    if ovs is None:
        ovs = __ovs

    if ovs is None or br_name not in ovs.list_br():
        raise OpenflowSwitchError(br_name)

    manager_cmd = "ovs-ofctl %s %s" % (command, br_name)
    if flow_options:
        manager_cmd += " %s" % flow_options
    utils.run(manager_cmd)


def bring_up_ifname(ifname):
    """
    Bring up an interface

    :param ifname: Name of the interface
    """
    ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)
    ifr = struct.pack("16sh", ifname, arch.IFF_UP)
    try:
        fcntl.ioctl(ctrl_sock, arch.SIOCSIFFLAGS, ifr)
    except IOError:
        raise TAPBringUpError(ifname)
    ctrl_sock.close()


def bring_down_ifname(ifname):
    """
    Bring down an interface

    :param ifname: Name of the interface
    """
    ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)
    ifr = struct.pack("16sh", ifname, 0)
    try:
        fcntl.ioctl(ctrl_sock, arch.SIOCSIFFLAGS, ifr)
    except IOError:
        raise TAPBringUpError(ifname)
    ctrl_sock.close()


def if_set_macaddress(ifname, mac):
    """
    Set the mac address for an interface

    :param ifname: Name of the interface
    :param mac: Mac address
    """
    ctrl_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 0)

    ifr = struct.pack("256s", ifname)
    try:
        mac_dev = fcntl.ioctl(ctrl_sock, arch.SIOCGIFHWADDR, ifr)[18:24]
        mac_dev = ":".join(["%02x" % ord(m) for m in mac_dev])
    except IOError, e:
        raise HwAddrGetError(ifname)

    if mac_dev.lower() == mac.lower():
        return

    ifr = struct.pack("16sH14s", ifname, 1,
                      "".join([chr(int(m, 16)) for m in mac.split(":")]))
    try:
        fcntl.ioctl(ctrl_sock, arch.SIOCSIFHWADDR, ifr)
    except IOError, e:
        logging.info(e)
        raise HwAddrSetError(ifname, mac)
    ctrl_sock.close()


class VirtIface(propcan.PropCan, object):

    """
    Networking information for single guest interface and host connection.
    """

    __slots__ = ['nic_name', 'g_nic_name', 'mac', 'nic_model', 'ip',
                 'nettype', 'netdst']
    # Make sure first byte generated is always zero and it follows
    # the class definition.  This helps provide more predictable
    # addressing while avoiding clashes between multiple NICs.
    LASTBYTE = random.SystemRandom().randint(0x00, 0xff)

    def __getstate__(self):
        state = {}
        for key in self.__class__.__all_slots__:
            if key in self:
                state[key] = self[key]
        return state

    def __setstate__(self, state):
        self.__init__(state)

    @classmethod
    def name_is_valid(cls, nic_name):
        """
        Corner-case prevention where nic_name is not a sane string value
        """
        try:
            return isinstance(nic_name, str) and len(nic_name) > 1
        except (TypeError, KeyError, AttributeError):
            return False

    @classmethod
    def mac_is_valid(cls, mac):
        try:
            mac = cls.mac_str_to_int_list(mac)
        except TypeError:
            return False
        return True  # Though may be less than 6 bytes

    @classmethod
    def mac_str_to_int_list(cls, mac):
        """
        Convert list of string bytes to int list
        """
        if isinstance(mac, (str, unicode)):
            mac = mac.split(':')
        # strip off any trailing empties
        for rindex in xrange(len(mac), 0, -1):
            if not mac[rindex - 1].strip():
                del mac[rindex - 1]
            else:
                break
        try:
            assert len(mac) < 7
            for byte_str_index in xrange(0, len(mac)):
                byte_str = mac[byte_str_index]
                assert isinstance(byte_str, (str, unicode))
                assert len(byte_str) > 0
                try:
                    value = eval("0x%s" % byte_str, {}, {})
                except SyntaxError:
                    raise AssertionError
                assert value >= 0x00
                assert value <= 0xFF
                mac[byte_str_index] = value
        except AssertionError:
            raise TypeError("%s %s is not a valid MAC format "
                            "string or list" % (str(mac.__class__),
                                                str(mac)))
        return mac

    @classmethod
    def int_list_to_mac_str(cls, mac_bytes):
        """
        Return string formatting of int mac_bytes
        """
        for byte_index in xrange(0, len(mac_bytes)):
            mac = mac_bytes[byte_index]
            # Project standardized on lower-case hex
            if mac < 16:
                mac_bytes[byte_index] = "0%x" % mac
            else:
                mac_bytes[byte_index] = "%x" % mac
        return mac_bytes

    @classmethod
    def generate_bytes(cls):
        """
        Return next byte from ring
        """
        cls.LASTBYTE += 1
        if cls.LASTBYTE > 0xff:
            cls.LASTBYTE = 0
        yield cls.LASTBYTE

    @classmethod
    def complete_mac_address(cls, mac):
        """
        Append randomly generated byte strings to make mac complete

        :param mac: String or list of mac bytes (possibly incomplete)
        :raise: TypeError if mac is not a string or a list
        """
        mac = cls.mac_str_to_int_list(mac)
        if len(mac) == 6:
            return ":".join(cls.int_list_to_mac_str(mac))
        for rand_byte in cls.generate_bytes():
            mac.append(rand_byte)
            return cls.complete_mac_address(cls.int_list_to_mac_str(mac))


class LibvirtIface(VirtIface):

    """
    Networking information specific to libvirt
    """
    __slots__ = []


class QemuIface(VirtIface):

    """
    Networking information specific to Qemu
    """
    __slots__ = ['vlan', 'device_id', 'ifname', 'tapfds',
                 'tapfd_ids', 'netdev_id', 'tftp',
                 'romfile', 'nic_extra_params',
                 'netdev_extra_params', 'queues', 'vhostfds',
                 'vectors']


class VMNet(list):

    """
    Collection of networking information.
    """

    # don't flood discard warnings
    DISCARD_WARNINGS = 10

    # __init__ must not presume clean state, it should behave
    # assuming there is existing properties/data on the instance
    # and take steps to preserve or update it as appropriate.
    def __init__(self, container_class=VirtIface, virtiface_list=[]):
        """
        Initialize from list-like virtiface_list using container_class
        """
        if container_class != VirtIface and (
                not issubclass(container_class, VirtIface)):
            raise TypeError("Container class must be Base_VirtIface "
                            "or subclass not a %s" % str(container_class))
        self.container_class = container_class
        super(VMNet, self).__init__([])
        if isinstance(virtiface_list, list):
            for virtiface in virtiface_list:
                self.append(virtiface)
        else:
            raise VMNetError

    def __getstate__(self):
        return [nic for nic in self]

    def __setstate__(self, state):
        VMNet.__init__(self, self.container_class, state)

    def __getitem__(self, index_or_name):
        if isinstance(index_or_name, str):
            index_or_name = self.nic_name_index(index_or_name)
        return super(VMNet, self).__getitem__(index_or_name)

    def __setitem__(self, index_or_name, value):
        if not isinstance(value, dict):
            raise VMNetError
        if self.container_class.name_is_valid(value['nic_name']):
            if isinstance(index_or_name, str):
                index_or_name = self.nic_name_index(index_or_name)
            self.process_mac(value)
            super(VMNet, self).__setitem__(index_or_name,
                                           self.container_class(value))
        else:
            raise VMNetError

    def __delitem__(self, index_or_name):
        if isinstance(index_or_name, str):
            index_or_name = self.nic_name_index(index_or_name)
        super(VMNet, self).__delitem__(index_or_name)

    def subclass_pre_init(self, params, vm_name):
        """
        Subclasses must establish style before calling VMNet. __init__()
        """
        # TODO: Get rid of this function.  it's main purpose is to provide
        # a shared way to setup style (container_class) from params+vm_name
        # so that unittests can run independently for each subclass.
        self.vm_name = vm_name
        self.params = params.object_params(self.vm_name)
        self.vm_type = self.params.get('vm_type', 'default')
        self.driver_type = self.params.get('driver_type', 'default')
        for key, value in VMNetStyle(self.vm_type,
                                     self.driver_type).items():
            setattr(self, key, value)

    def process_mac(self, value):
        """
        Strips 'mac' key from value if it's not valid
        """
        original_mac = mac = value.get('mac')
        if mac:
            mac = value['mac'] = value['mac'].lower()
            if len(mac.split(':')
                   ) == 6 and self.container_class.mac_is_valid(mac):
                return
            else:
                del value['mac']  # don't store invalid macs
                # Notify user about these, but don't go crazy
                if self.__class__.DISCARD_WARNINGS >= 0:
                    logging.warning('Discarded invalid mac "%s" for nic "%s" '
                                    'from input, %d warnings remaining.'
                                    % (original_mac,
                                       value.get('nic_name'),
                                       self.__class__.DISCARD_WARNINGS))
                    self.__class__.DISCARD_WARNINGS -= 1

    def mac_list(self):
        """
        Return a list of all mac addresses used by defined interfaces
        """
        return [nic.mac for nic in self if hasattr(nic, 'mac')]

    def append(self, value):
        newone = self.container_class(value)
        newone_name = newone['nic_name']
        if newone.name_is_valid(newone_name) and (
                newone_name not in self.nic_name_list()):
            self.process_mac(newone)
            super(VMNet, self).append(newone)
        else:
            raise VMNetError

    def nic_name_index(self, name):
        """
        Return the index number for name, or raise KeyError
        """
        if not isinstance(name, str):
            raise TypeError("nic_name_index()'s nic_name must be a string")
        nic_name_list = self.nic_name_list()
        try:
            return nic_name_list.index(name)
        except ValueError:
            raise IndexError("Can't find nic named '%s' among '%s'" %
                             (name, nic_name_list))

    def nic_name_list(self):
        """
        Obtain list of nic names from lookup of contents 'nic_name' key.
        """
        namelist = []
        for item in self:
            # Rely on others to throw exceptions on 'None' names
            namelist.append(item['nic_name'])
        return namelist

    def nic_lookup(self, prop_name, prop_value):
        """
        Return the first index with prop_name key matching prop_value or None
        """
        for nic_index in xrange(0, len(self)):
            if self[nic_index].has_key(prop_name):
                if self[nic_index][prop_name] == prop_value:
                    return nic_index
        return None


# TODO: Subclass VMNet into Qemu/Libvirt variants and
# pull them, along with ParmasNet and maybe DbNet based on
# Style definitions.  i.e. libvirt doesn't need DbNet at all,
# but could use some custom handling at the VMNet layer
# for xen networking.  This will also enable further extensions
# to network information handing in the future.
class VMNetStyle(dict):

    """
    Make decisions about needed info from vm_type and driver_type params.
    """

    # Keyd first by vm_type, then by driver_type.
    VMNet_Style_Map = {
        'default': {
            'default': {
                'mac_prefix': '9a',
                'container_class': QemuIface,
            }
        },
        'libvirt': {
            'default': {
                'mac_prefix': '9a',
                'container_class': LibvirtIface,
            },
            'qemu': {
                'mac_prefix': '52:54:00',
                'container_class': LibvirtIface,
            },
            'xen': {
                'mac_prefix': '00:16:3e',
                'container_class': LibvirtIface,
            }
        }
    }

    def __new__(cls, vm_type, driver_type):
        return cls.get_style(vm_type, driver_type)

    @classmethod
    def get_vm_type_map(cls, vm_type):
        return cls.VMNet_Style_Map.get(vm_type,
                                       cls.VMNet_Style_Map['default'])

    @classmethod
    def get_driver_type_map(cls, vm_type_map, driver_type):
        return vm_type_map.get(driver_type,
                               vm_type_map['default'])

    @classmethod
    def get_style(cls, vm_type, driver_type):
        style = cls.get_driver_type_map(cls.get_vm_type_map(vm_type),
                                        driver_type)
        return style


class ParamsNet(VMNet):

    """
    Networking information from Params

        Params contents specification-
            vms = <vm names...>
            nics = <nic names...>
            nics_<vm name> = <nic names...>
            # attr: mac, ip, model, nettype, netdst, etc.
            <attr> = value
            <attr>_<nic name> = value
    """

    # __init__ must not presume clean state, it should behave
    # assuming there is existing properties/data on the instance
    # and take steps to preserve or update it as appropriate.

    def __init__(self, params, vm_name):
        self.subclass_pre_init(params, vm_name)
        # use temporary list to initialize
        result_list = []
        nic_name_list = self.params.objects('nics')
        for nic_name in nic_name_list:
            # nic name is only in params scope
            nic_dict = {'nic_name': nic_name}
            nic_params = self.params.object_params(nic_name)
            # avoid processing unsupported properties
            proplist = list(self.container_class().__all_slots__)
            # nic_name was already set, remove from __slots__ list copy
            del proplist[proplist.index('nic_name')]
            for propertea in proplist:
                # Merge existing propertea values if they exist
                try:
                    existing_value = getattr(self[nic_name], propertea, None)
                except ValueError:
                    existing_value = None
                except IndexError:
                    existing_value = None
                nic_dict[propertea] = nic_params.get(propertea, existing_value)
            result_list.append(nic_dict)
        VMNet.__init__(self, self.container_class, result_list)

    def mac_index(self):
        """
        Generator over mac addresses found in params
        """
        for nic_name in self.params.get('nics'):
            nic_obj_params = self.params.object_params(nic_name)
            mac = nic_obj_params.get('mac')
            if mac:
                yield mac
            else:
                continue

    def reset_mac(self, index_or_name):
        """
        Reset to mac from params if defined and valid, or undefine.
        """
        nic = self[index_or_name]
        nic_name = nic.nic_name
        nic_params = self.params.object_params(nic_name)
        params_mac = nic_params.get('mac')
        if params_mac and self.container_class.mac_is_valid(params_mac):
            new_mac = params_mac.lower()
        else:
            new_mac = None
        nic.mac = new_mac

    def reset_ip(self, index_or_name):
        """
        Reset to ip from params if defined and valid, or undefine.
        """
        nic = self[index_or_name]
        nic_name = nic.nic_name
        nic_params = self.params.object_params(nic_name)
        params_ip = nic_params.get('ip')
        if params_ip:
            new_ip = params_ip
        else:
            new_ip = None
        nic.ip = new_ip


class DbNet(VMNet):

    """
    Networking information from database

        Database specification-
            database values are python string-formatted lists of dictionaries
    """

    # __init__ must not presume clean state, it should behave
    # assuming there is existing properties/data on the instance
    # and take steps to preserve or update it as appropriate.

    def __init__(self, params, vm_name, db_filename, db_key):
        self.subclass_pre_init(params, vm_name)
        self.db_key = db_key
        self.db_filename = db_filename
        self.db_lockfile = db_filename + ".lock"
        # Merge (don't overwrite) existing propertea values if they
        # exist in db
        try:
            self.lock_db()
            entry = self.db_entry()
        except KeyError:
            entry = []
        self.unlock_db()
        proplist = list(self.container_class().__all_slots__)
        # nic_name was already set, remove from __slots__ list copy
        del proplist[proplist.index('nic_name')]
        nic_name_list = self.nic_name_list()
        for db_nic in entry:
            nic_name = db_nic['nic_name']
            if nic_name in nic_name_list:
                for propertea in proplist:
                    # only set properties in db but not in self
                    if propertea in db_nic:
                        self[nic_name].set_if_none(
                            propertea, db_nic[propertea])
        if entry:
            VMNet.__init__(self, self.container_class, entry)
        # Assume self.update_db() called elsewhere

    def lock_db(self):
        if not hasattr(self, 'lock'):
            self.lock = utils_misc.lock_file(self.db_lockfile)
            if not hasattr(self, 'db'):
                self.db = shelve.open(self.db_filename)
            else:
                raise DbNoLockError
        else:
            raise DbNoLockError

    def unlock_db(self):
        if hasattr(self, 'db'):
            self.db.close()
            del self.db
            if hasattr(self, 'lock'):
                utils_misc.unlock_file(self.lock)
                del self.lock
            else:
                raise DbNoLockError
        else:
            raise DbNoLockError

    def db_entry(self, db_key=None):
        """
        Returns a python list of dictionaries from locked DB string-format entry
        """
        if not db_key:
            db_key = self.db_key
        try:
            db_entry = self.db[db_key]
        except AttributeError:  # self.db doesn't exist:
            raise DbNoLockError
        # Always wear protection
        try:
            eval_result = eval(db_entry, {}, {})
        except SyntaxError:
            raise ValueError("Error parsing entry for %s from "
                             "database '%s'" % (self.db_key,
                                                self.db_filename))
        if not isinstance(eval_result, list):
            raise ValueError("Unexpected database data: %s" % (
                str(eval_result)))
        result = []
        for result_dict in eval_result:
            if not isinstance(result_dict, dict):
                raise ValueError("Unexpected database sub-entry data %s" % (
                    str(result_dict)))
            result.append(result_dict)
        return result

    def save_to_db(self, db_key=None):
        """
        Writes string representation out to database
        """
        if db_key is None:
            db_key = self.db_key
        data = str(self)
        # Avoid saving empty entries
        if len(data) > 3:
            try:
                self.db[self.db_key] = data
            except AttributeError:
                raise DbNoLockError
        else:
            try:
                # make sure old db entry is removed
                del self.db[db_key]
            except KeyError:
                pass

    def update_db(self):
        self.lock_db()
        self.save_to_db()
        self.unlock_db()

    def mac_index(self):
        """Generator of mac addresses found in database"""
        try:
            for db_key in self.db.keys():
                for nic in self.db_entry(db_key):
                    mac = nic.get('mac')
                    if mac:
                        yield mac
                    else:
                        continue
        except AttributeError:
            raise DbNoLockError

ADDRESS_POOL_FILENAME = os.path.join("/tmp", "address_pool")
ADDRESS_POOL_LOCK_FILENAME = ADDRESS_POOL_FILENAME + ".lock"


def clean_tmp_files():
    """
    Remove the base address pool filename.
    """
    if os.path.isfile(ADDRESS_POOL_LOCK_FILENAME):
        os.unlink(ADDRESS_POOL_LOCK_FILENAME)
    if os.path.isfile(ADDRESS_POOL_FILENAME):
        os.unlink(ADDRESS_POOL_FILENAME)


class VirtNet(DbNet, ParamsNet):

    """
    Persistent collection of VM's networking information.
    """
    # __init__ must not presume clean state, it should behave
    # assuming there is existing properties/data on the instance
    # and take steps to preserve or update it as appropriate.

    def __init__(self, params, vm_name, db_key,
                 db_filename=ADDRESS_POOL_FILENAME):
        """
        Load networking info. from db, then from params, then update db.

        :param params: Params instance using specification above
        :param vm_name: Name of the VM as might appear in Params
        :param db_key: database key uniquely identifying VM instance
        :param db_filename: database file to cache previously parsed params
        """
        # Params always overrides database content
        DbNet.__init__(self, params, vm_name, db_filename, db_key)
        ParamsNet.__init__(self, params, vm_name)
        self.update_db()

    # Delegating get/setstate() details more to ancestor classes
    # doesn't play well with multi-inheritence.  While possibly
    # more difficult to maintain, hard-coding important property
    # names for pickling works. The possibility also remains open
    # for extensions via style-class updates.
    def __getstate__(self):
        state = {'container_items': VMNet.__getstate__(self)}
        for attrname in ['params', 'vm_name', 'db_key', 'db_filename',
                         'vm_type', 'driver_type', 'db_lockfile']:
            state[attrname] = getattr(self, attrname)
        for style_attr in VMNetStyle(self.vm_type, self.driver_type).keys():
            state[style_attr] = getattr(self, style_attr)
        return state

    def __setstate__(self, state):
        for key in state.keys():
            if key == 'container_items':
                continue  # handle outside loop
            setattr(self, key, state.pop(key))
        VMNet.__setstate__(self, state.pop('container_items'))

    def __eq__(self, other):
        if len(self) != len(other):
            return False
        # Order doesn't matter for most OS's as long as MAC & netdst match
        for nic_name in self.nic_name_list():
            if self[nic_name] != other[nic_name]:
                return False
        return True

    def __ne__(self, other):
        return not self.__eq__(other)

    def mac_index(self):
        """
        Generator for all allocated mac addresses (requires db lock)
        """
        for mac in DbNet.mac_index(self):
            yield mac
        for mac in ParamsNet.mac_index(self):
            yield mac

    def generate_mac_address(self, nic_index_or_name, attempts=1024):
        """
        Set & return valid mac address for nic_index_or_name or raise NetError

        :param nic_index_or_name: index number or name of NIC
        :return: MAC address string
        :raise: NetError if mac generation failed
        """
        nic = self[nic_index_or_name]
        if nic.has_key('mac'):
            logging.warning("Overwriting mac %s for nic %s with random"
                            % (nic.mac, str(nic_index_or_name)))
        self.free_mac_address(nic_index_or_name)
        attempts_remaining = attempts
        while attempts_remaining > 0:
            mac_attempt = nic.complete_mac_address(self.mac_prefix)
            self.lock_db()
            if mac_attempt not in self.mac_index():
                nic.mac = mac_attempt.lower()
                self.unlock_db()
                self.update_db()
                return self[nic_index_or_name].mac
            else:
                attempts_remaining -= 1
                self.unlock_db()
        raise NetError("%s/%s MAC generation failed with prefix %s after %d "
                       "attempts for NIC %s on VM %s (%s)" % (
                           self.vm_type,
                           self.driver_type,
                           self.mac_prefix,
                           attempts,
                           str(nic_index_or_name),
                           self.vm_name,
                           self.db_key))

    def free_mac_address(self, nic_index_or_name):
        """
        Remove the mac value from nic_index_or_name and cache unless static

        :param nic_index_or_name: index number or name of NIC
        """
        nic = self[nic_index_or_name]
        if nic.has_key('mac'):
            # Reset to params definition if any, or None
            self.reset_mac(nic_index_or_name)
        self.update_db()

    def set_mac_address(self, nic_index_or_name, mac):
        """
        Set a MAC address to value specified

        :param nic_index_or_name: index number or name of NIC
        :raise: NetError if mac already assigned
        """
        nic = self[nic_index_or_name]
        if nic.has_key('mac'):
            logging.warning("Overwriting mac %s for nic %s with %s"
                            % (nic.mac, str(nic_index_or_name), mac))
        nic.mac = mac.lower()
        self.update_db()

    def get_mac_address(self, nic_index_or_name):
        """
        Return a MAC address for nic_index_or_name

        :param nic_index_or_name: index number or name of NIC
        :return: MAC address string.
        """
        return self[nic_index_or_name].mac.lower()

    def generate_ifname(self, nic_index_or_name):
        """
        Return and set network interface name
        """
        nic_index = self.nic_name_index(self[nic_index_or_name].nic_name)
        prefix = "t%d-" % nic_index
        postfix = utils_misc.generate_random_string(6)
        # Ensure interface name doesn't excede 11 characters
        self[nic_index_or_name].ifname = (prefix + postfix)[-11:]
        self.update_db()
        return self[nic_index_or_name].ifname


def parse_arp():
    """
    Read /proc/net/arp, return a mapping of MAC to IP

    :return: dict mapping MAC to IP
    """
    ret = {}
    arp_cache = file('/proc/net/arp').readlines()

    for line in arp_cache:
        mac = line.split()[3]
        ip = line.split()[0]

        # Skip the header
        if mac.count(":") != 5:
            continue

        ret[mac] = ip

    return ret


def verify_ip_address_ownership(ip, macs, timeout=10.0):
    """
    Use arping and the ARP cache to make sure a given IP address belongs to one
    of the given MAC addresses.

    :param ip: An IP address.
    :param macs: A list or tuple of MAC addresses.
    :return: True if ip is assigned to a MAC address in macs.
    """
    ip_map = parse_arp()
    for mac in macs:
        if ip_map.get(mac) == ip:
            return True

    # Compile a regex that matches the given IP address and any of the given
    # MAC addresses
    mac_regex = "|".join("(%s)" % mac for mac in macs)
    regex = re.compile(r"\b%s\b.*\b(%s)\b" % (ip, mac_regex), re.IGNORECASE)

    # Get the name of the bridge device for arping
    o = commands.getoutput("%s route get %s" %
                           (utils_misc.find_command("ip"), ip))
    dev = re.findall(r"dev\s+\S+", o, re.IGNORECASE)
    if not dev:
        return False
    dev = dev[0].split()[-1]

    # Send an ARP request
    o = commands.getoutput("%s -f -c 3 -I %s %s" %
                           (utils_misc.find_command("arping"), dev, ip))
    return bool(regex.search(o))


def generate_mac_address_simple():
    r = random.SystemRandom()
    mac = "9a:%02x:%02x:%02x:%02x:%02x" % (r.randint(0x00, 0xff),
                                           r.randint(0x00, 0xff),
                                           r.randint(0x00, 0xff),
                                           r.randint(0x00, 0xff),
                                           r.randint(0x00, 0xff))
    return mac


def get_ip_address_by_interface(ifname):
    """
    returns ip address by interface
    :param ifname - interface name
    :raise NetError - When failed to fetch IP address (ioctl raised IOError.).

    Retrieves interface address from socket fd trough ioctl call
    and transforms it into string from 32-bit packed binary
    by using socket.inet_ntoa().

    """
    mysocket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        return socket.inet_ntoa(fcntl.ioctl(
            mysocket.fileno(),
            arch.SIOCGIFADDR,
            # ifname to binary IFNAMSIZ == 16
            struct.pack('256s', ifname[:15])
        )[20:24])
    except IOError:
        raise NetError(
            "Error while retrieving IP address from interface %s." % ifname)


def get_host_ip_address(params):
    """
    returns ip address of host specified in host_ip_addr parameter If provided
    otherwise ip address on interface specified in netdst parameter is returned
    :param params
    """
    host_ip = params.get('host_ip_addr', None)
    if not host_ip:
        host_ip = get_ip_address_by_interface(params.get('netdst'))
        logging.warning("No IP address of host was provided, using IP address"
                        " on %s interface", str(params.get('netdst')))
    return host_ip


def get_correspond_ip(remote_ip):
    """
    Get local ip address which is used to contact remote ip.

    :param remote_ip: Remote ip
    :return: Local corespond IP.
    """
    result = utils.run("ip route get %s" % (remote_ip)).stdout
    local_ip = re.search("src (.+)", result)
    if local_ip is not None:
        local_ip = local_ip.groups()[0]
    return local_ip


def get_linux_ifname(session, mac_address=""):
    """
    Get the interface name through the mac address.

    :param session: session to the virtual machine
    :param mac_address: the macaddress of nic

    :raise error.TestError in case it was not possible to determine the
            interface name.
    """
    def _process_output(cmd, reg_pattern):
        try:
            output = session.cmd(cmd)
            ifname_list = re.findall(reg_pattern, output, re.I)
            if not ifname_list:
                return None
            if mac_address:
                return ifname_list[0]
            if "lo" in ifname_list:
                ifname_list.remove("lo")
            return ifname_list
        except aexpect.ShellCmdError:
            return None

    # Try ifconfig first
    i = _process_output("ifconfig -a", r"(\w+)\s+Link.*%s" % mac_address)
    if i is not None:
        return i

    # No luck, try ip link
    i = _process_output("ip link | grep -B1 '%s' -i" % mac_address,
                        r"\d+:\s+(\w+):\s+.*")
    if i is not None:
        return i

    # No luck, look on /sys
    cmd = r"grep '%s' /sys/class/net/*/address " % mac_address
    i = _process_output(cmd, r"net/(\w+)/address:%s" % mac_address)
    if i is not None:
        return i

    # If we came empty handed, let's raise an error
    raise error.TestError("Failed to determine interface name with "
                          "mac %s" % mac_address)


def restart_guest_network(session, nic_name=None):
    """
    Restart guest's network via serial console.

    :param session: session to virtual machine
    :param nic_name: nic card name in guest to restart
    """
    if_list = []
    if not nic_name:
        # initiate all interfaces on guest.
        o = session.cmd_output("ip link")
        if_list = re.findall(r"\d+: (eth\d+):", o)
    else:
        if_list.append(nic_name)

    if if_list:
        session.sendline("killall dhclient && "
                         "dhclient %s &" % ' '.join(if_list))


def update_mac_ip_address(vm, params, timeout=None):
    """
    Get mac and ip address from guest then update the mac pool and
    address cache

    :param vm: VM object
    :param params: Dictionary with the test parameters.
    """
    network_query = params.get("network_query", "ifconfig")
    restart_network = params.get("restart_network", "service network restart")
    mac_ip_filter = params.get("mac_ip_filter")
    if timeout is None:
        timeout = int(params.get("login_timeout"))
    session = vm.wait_for_serial_login(timeout=360)
    end_time = time.time() + timeout
    macs_ips = []
    num = 0
    while time.time() < end_time:
        try:
            if num % 3 == 0 and num != 0:
                session.cmd(restart_network)
            output = session.cmd_status_output(network_query)[1]
            macs_ips = re.findall(mac_ip_filter, output, re.S)
            # Get nics number
        except Exception, err:
            logging.error(err)
        nics = params.get("nics")
        nic_minimum = len(re.split(r"\s+", nics.strip()))
        if len(macs_ips) == nic_minimum:
            break
        num += 1
        time.sleep(5)
    if len(macs_ips) < nic_minimum:
        logging.error("Not all nics get ip address")

    for (_ip, mac) in macs_ips:
        vlan = macs_ips.index((_ip, mac))
        # _ip, mac are in different sequence in Fedora and RHEL guest.
        if re.match(".\d+\.\d+\.\d+\.\d+", mac):
            _ip, mac = mac, _ip
        if "-" in mac:
            mac = mac.replace("-", ".")
        vm.address_cache[mac.lower()] = _ip
        vm.virtnet.set_mac_address(vlan, mac)


def get_windows_nic_attribute(session, key, value, target, timeout=240,
                              global_switch="nic"):
    """
    Get the windows nic attribute using wmic. All the support key you can
    using wmic to have a check.

    :param session: session to the virtual machine
    :param key: the key supported by wmic
    :param value: the value of the key
    :param target: which nic attribute you want to get.

    """
    cmd = 'wmic %s where %s="%s" get %s' % (global_switch, key, value, target)
    o = session.cmd(cmd, timeout=timeout).strip()
    if not o:
        err_msg = "Get guest %s attribute %s failed!" % (global_switch, target)
        raise error.TestError(err_msg)
    return o.splitlines()[-1]


def set_win_guest_nic_status(session, connection_id, status, timeout=240):
    """
    Set windows guest nic ENABLED/DISABLED

    :param  session : session to virtual machine
    :param  connection_id : windows guest nic netconnectionid
    :param  status : set nic ENABLED/DISABLED
    """
    cmd = 'netsh interface set interface name="%s" admin=%s'
    session.cmd(cmd % (connection_id, status), timeout=timeout)


def disable_windows_guest_network(session, connection_id, timeout=240):
    return set_win_guest_nic_status(session, connection_id,
                                    "DISABLED", timeout)


def enable_windows_guest_network(session, connection_id, timeout=240):
    return set_win_guest_nic_status(session, connection_id,
                                    "ENABLED", timeout)


def restart_windows_guest_network(session, connection_id, timeout=240,
                                  mode="netsh"):
    """
    Restart guest's network via serial console. mode "netsh" can not
    works in winxp system

    :param session: session to virtual machine
    :param connection_id: windows nic connectionid,it means connection name,
                          you Can get connection id string via wmic
    """
    if mode == "netsh":
        disable_windows_guest_network(session, connection_id, timeout=timeout)
        enable_windows_guest_network(session, connection_id, timeout=timeout)
    elif mode == "devcon":
        restart_windows_guest_network_by_devcon(session, connection_id)


def restart_windows_guest_network_by_key(session, key, value, timeout=240,
                                         mode="netsh"):
    """
    Restart the guest network by nic Attribute like connectionid,
    interfaceindex, "netsh" can not work in winxp system.
    using devcon mode must download devcon.exe and put it under c:\

    :param session: session to virtual machine
    :param key: the key supported by wmic nic
    :param value: the value of the key
    :param timeout: timeout
    :param mode: command mode netsh or devcon
    """
    if mode == "netsh":
        oper_key = "netconnectionid"
    elif mode == "devcon":
        oper_key = "pnpdeviceid"

    id = get_windows_nic_attribute(session, key, value, oper_key, timeout)
    if not id:
        raise error.TestError("Get nic %s failed" % oper_key)
    if mode == "devcon":
        id = id.split("&")[-1]

    restart_windows_guest_network(session, id, timeout, mode)


def set_guest_network_status_by_devcon(session, status, netdevid,
                                       timeout=240):
    """
    using devcon to enable/disable the network device.
    using it must download the devcon.exe, and put it under c:\
    """
    set_cmd = r"c:\devcon.exe %s  =Net @PCI\*\*%s" % (status, netdevid)
    session.cmd(set_cmd, timeout=timeout)


def restart_windows_guest_network_by_devcon(session, netdevid, timeout=240):

    set_guest_network_status_by_devcon(session, 'disable', netdevid)
    set_guest_network_status_by_devcon(session, 'enable', netdevid)


def get_host_iface():
    """
    List the nic interface in host.
    :return: a list of the interfaces in host
    :rtype: list
    """
    proc_net_file = open(PROCFS_NET_PATH, 'r')
    host_iface_info = proc_net_file.read()
    proc_net_file.close()
    return [_.strip() for _ in re.findall("(.*):", host_iface_info)]

########NEW FILE########
__FILENAME__ = utils_netperf
import os
import logging
import re
from autotest.client import utils
import remote
import aexpect
import data_dir


class NetperfError(Exception):
    pass


class NetperfPackageError(NetperfError):

    def __init__(self, error_info):
        NetperfError.__init__(self)
        self.error_info = error_info

    def __str__(self):
        e_msg = "Packeage Error: %s" % self.error_info
        return e_msg


class NetserverError(NetperfError):

    def __init__(self, error_info):
        NetperfError.__init__(self)
        self.error_info = error_info

    def __str__(self):
        e_msg = "Netserver Error: %s" % self.error_info
        return e_msg


class NetperfTestError(NetperfError):

    def __init__(self, error_info):
        NetperfError.__init__(self)
        self.error_info = error_info

    def __str__(self):
        e_msg = "Netperf test error: %s" % self.error_info
        return e_msg


class NetperfPackage(remote.Remote_Package):

    def __init__(self, address, netperf_path, md5sum="", local_path="",
                 client="ssh", port="22", username="root", password="redhat",
                 check_command=None):
        """
        Class NetperfPackage just represent the netperf package
        Init NetperfPackage class.

        :param address: Remote host or guest address
        :param netperf_path: Remote netperf path
        :param me5sum: Local netperf package me5sum
        :param local_path: Local netperf (path or link) path
        :param client: The client to use ('ssh', 'telnet' or 'nc')
        :param port: Port to connect to
        :param username: Username (if required)
        :param password: Password (if required)
        """
        super(NetperfPackage, self).__init__(address, client, username,
                                             password, port, netperf_path)

        self.local_netperf = local_path
        self.pack_suffix = ""
        if client == "nc":
            self.prompt = r"^\w:\\.*>\s*$"
            self.linesep = "\r\n"
        else:
            self.prompt = "^\[.*\][\#\$]\s*$"
            self.linesep = "\n"
            if self.remote_path.endswith("tar.bz2"):
                self.pack_suffix = ".tar.bz2"
                self.decomp_cmd = "tar jxvf"
            elif self.remote_path.endswith("tar.gz"):
                self.pack_suffix = ".tar.gz"
                self.decomp_cmd = "tar zxvf"

            self.netperf_dir = self.remote_path.rstrip(self.pack_suffix)
            self.netperf_base_dir = os.path.dirname(self.remote_path)
            self.netperf_exec = os.path.basename(self.remote_path)

        logging.debug("Create remote session")
        self.session = remote.remote_login(self.client, self.address,
                                           self.port, self.username,
                                           self.password, self.prompt,
                                           self.linesep, timeout=360)

        self.build_tool = True
        if check_command:
            netperf_status = self.session.cmd_status("which %s" %
                                                     check_command)
            if netperf_status == 0:
                self.build_tool = False

        if self.build_tool:
            if utils.is_url(local_path):
                logging.debug("Download URL file to local path")
                tmp_dir = data_dir.get_download_dir()
                self.local_netperf = utils.unmap_url_cache(tmp_dir, local_path,
                                                           md5sum)
            self.push_file(self.local_netperf)

    def __del__(self):
        self.env_cleanup()

    def env_cleanup(self, clean_all=True):
        if self.build_tool:
            clean_cmd = "rm -rf %s" % self.netperf_dir
            if clean_all:
                clean_cmd += " rm -rf %s" % self.remote_path
            self.session.cmd(clean_cmd, ignore_all_errors=True)

    def pack_compile(self, compile_option=""):
        pre_setup_cmd = "cd %s " % self.netperf_base_dir
        pre_setup_cmd += " && %s %s" % (self.decomp_cmd, self.netperf_exec)
        netperf_dir = self.session.cmd("tar -tf %s | sed -n 1p" %
                                       self.remote_path).strip()
        self.netperf_dir = os.path.join(self.netperf_base_dir, netperf_dir)
        pre_setup_cmd += " && cd %s " % self.netperf_dir
        setup_cmd = "./configure %s > /dev/null " % compile_option
        setup_cmd += " && make > /dev/null"
        self.env_cleanup(clean_all=False)
        cmd = "%s && %s " % (pre_setup_cmd, setup_cmd)
        try:
            self.session.cmd(cmd)
        except aexpect.ShellError, e:
            raise NetperfPackageError("Compile failed: %s" % e)


class NetperfServer(NetperfPackage):

    def __init__(self, address, netperf_path, md5sum="", local_path="",
                 client="ssh", port="22", username="root", password="redhat",
                 compile_option="--enable-demo=yes"):
        """
        Init NetperfServer class.

        :param address: Remote host or guest address
        :param netperf_path: Remote netperf path
        :param me5sum: Local netperf package me5sum
        :param local_path: Local netperf (path or link) with will transfer to
                           remote
        :param client: The client to use ('ssh', 'telnet' or 'nc')
        :param port: Port to connect to
        :param username: Username (if required)
        :param password: Password (if required)
        """
        super(NetperfServer, self).__init__(address, netperf_path, md5sum,
                                            local_path, client, port, username,
                                            password,
                                            check_command="netserver")

        if self.build_tool:
            if self.pack_suffix:
                logging.debug("Compiling netserver from source")
                self.pack_compile(compile_option)
                self.netserver_path = os.path.join(self.netperf_dir,
                                                   "src/netserver")
            else:
                self.netserver_path = self.remote_path
        else:
            netserver_path = self.session.cmd_output("which netserver")
            self.netserver_path = netserver_path.rstrip()
            logging.debug("Using local netserver binary: %s" %
                          self.netserver_path)

    def start(self, restart=False):
        """
        Start/Restart netserver

        :param restart: if restart=True, will restart the netserver
        """

        logging.info("Start netserver ...")
        server_cmd = ""
        if self.client == "nc":
            server_cmd += "start /b %s" % self.netserver_path
        else:
            server_cmd = self.netserver_path

        if restart:
            self.stop()
        if not self.is_server_running():
            logging.debug("Start netserver with cmd: '%s'" % server_cmd)
            self.session.cmd_output_safe(server_cmd)

        if not self.is_server_running():
            raise NetserverError("Can not start netperf server!")
        logging.info("Netserver start successfully")

    def is_server_running(self):
        if self.client == "nc":
            check_reg = re.compile(r"NETSERVER.*EXE", re.I)
            if check_reg.findall(self.session.cmd_output("tasklist")):
                return True
        else:
            status_cmd = "pidof netserver"
            if not self.session.cmd_status(status_cmd):
                return True
        return False

    def stop(self):
        if self.client == "nc":
            stop_cmd = "taskkill /F /IM netserver*"
        else:
            stop_cmd = "killall netserver"
        if self.is_server_running():
            self.session.cmd(stop_cmd, ignore_all_errors=True)
        if self.is_server_running():
            raise NetserverError("Cannot stop the netserver")
        logging.info("Stop netserver successfully")


class NetperfClient(NetperfPackage):

    def __init__(self, address, netperf_path, md5sum="", local_path="",
                 client="ssh", port="22", username="root", password="redhat",
                 compile_option=""):
        """
        Init NetperfClient class.

        :param address: Remote host or guest address
        :param netperf_path: Remote netperf path
        :param me5sum: Local netperf package me5sum
        :param local_path: Local netperf (path or link) with will transfer to
                           remote
        :param client: The client to use ('ssh', 'telnet' or 'nc')
        :param port: Port to connect to
        :param username: Username (if required)
        :param password: Password (if required)
        """
        super(NetperfClient, self).__init__(address, netperf_path, md5sum,
                                            local_path, client, port, username,
                                            password,
                                            check_command="netserver")

        if self.build_tool:
            if self.pack_suffix:
                logging.debug("Compiling netperf from source")
                self.pack_compile(compile_option)
                self.netperf_path = os.path.join(self.netperf_dir,
                                                 "src/netperf")
            else:
                self.netperf_path = self.remote_path
        else:
            netperf_path = self.session.cmd_output("which netperf")
            self.netperf_path = netperf_path.rstrip()
            logging.debug("Using local netperf binary: %s" % self.netperf_path)

    def start(self, server_address, test_option="", timeout=1200,
              cmd_prefix=""):
        """
        Run netperf test

        :param server_address: Remote netserver address
        :param netperf_path: netperf test option (global/test option)
        :param timeout: Netperf test timeout(-l)
        :return: return test result
        """
        netperf_cmd = "%s %s -H %s %s " % (cmd_prefix, self.netperf_path,
                                           server_address, test_option)
        logging.debug("Start netperf with cmd: '%s'" % netperf_cmd)
        (status, output) = self.session.cmd_status_output(netperf_cmd,
                                                          timeout=timeout)
        if status:
            raise NetperfTestError("Run netperf error. %s" % output)
        self.result = output
        return self.result

    def bg_start(self, server_address, test_option="", session_num=1,
                 cmd_prefix=""):
        """
        Run netperf background, for stress test, Only support linux now
        Have no output

        :param server_address: Remote netserver address
        :param netperf_path: netperf test option (global/test option)
        :param timeout: Netperf test timeout(-l)
        """
        if self.client == "nc":
            raise NetperfTestError("Currently only support linux client")

        netperf_cmd = "%s %s -H %s %s " % (cmd_prefix, self.netperf_path,
                                           server_address, test_option)
        logging.debug("Start %s sessions netperf background with cmd: '%s'" %
                      (session_num, netperf_cmd))
        for _ in xrange(int(session_num)):
            self.session.cmd_output_safe("%s &" % netperf_cmd)
        return

    def stop(self):
        if self.client == "nc":
            kill_cmd = "taskkill /F /IM netperf*"
        else:
            kill_cmd = "killall netperf"
        self.session.cmd(kill_cmd, ignore_all_errors=True)

    def is_test_running(self):
        if self.client == "nc":
            check_reg = re.compile(r"NETPERF.*EXE", re.I)
            if check_reg.findall(self.session.cmd_output("tasklist")):
                return True
        else:
            status_cmd = "pidof netperf"
            if not self.session.cmd_status(status_cmd):
                return True
        return False

########NEW FILE########
__FILENAME__ = utils_net_unittest
#!/usr/bin/python

import unittest
import time
import logging
import sys
import random
import os
import shelve

import common
from autotest.client import utils
from autotest.client.shared.test_utils import mock
import utils_net
import utils_misc
import cartesian_config
import utils_params
import propcan


class FakeVm(object):

    def __init__(self, vm_name, params):
        self.name = vm_name
        self.params = params
        self.vm_type = self.params.get('vm_type')
        self.driver_type = self.params.get('driver_type')
        self.instance = ("%s-%s" % (
            time.strftime("%Y%m%d-%H%M%S"),
            utils_misc.generate_random_string(16)))

    def get_params(self):
        return self.params

    def is_alive(self):
        logging.info("Fake VM %s (instance %s)", self.name, self.instance)


class TestBridge(unittest.TestCase):

    class FakeCmd(object):
        iter = 0

        def __init__(self, *args, **kargs):
            self.fake_cmds = [
                """bridge name    bridge id        STP enabled    interfaces
virbr0        8000.52540018638c    yes        virbr0-nic
virbr1        8000.525400c0b080    yes        em1
                                              virbr1-nic
""",
                """bridge name    bridge id        STP enabled    interfaces
virbr0        8000.52540018638c    yes
""",
                """bridge name    bridge id        STP enabled    interfaces
""",
                """bridge name    bridge id        STP enabled    interfaces
virbr0        8000.52540018638c    yes        virbr0-nic
                                              virbr2-nic
                                              virbr3-nic
virbr1        8000.525400c0b080    yes        em1
                                              virbr1-nic
                                              virbr4-nic
                                              virbr5-nic
virbr2        8000.525400c0b080    yes        em1
                                              virbr10-nic
                                              virbr40-nic
                                              virbr50-nic
"""]

            self.stdout = self.get_stdout()
            self.__class__.iter += 1

        def get_stdout(self):
            return self.fake_cmds[self.__class__.iter]

    def setUp(self):
        self.god = mock.mock_god(ut=self)

        def utils_run(*args, **kargs):
            return TestBridge.FakeCmd(*args, **kargs)

        self.god.stub_with(utils, 'run', utils_run)

    def test_getstructure(self):

        br = utils_net.Bridge().get_structure()
        self.assertEqual(br, {'virbr1': ['em1', 'virbr1-nic'],
                              'virbr0': ['virbr0-nic']})

        br = utils_net.Bridge().get_structure()
        self.assertEqual(br, {'virbr0': []})

        br = utils_net.Bridge().get_structure()
        self.assertEqual(br, {})

        br = utils_net.Bridge().get_structure()
        self.assertEqual(br, {'virbr2': ['em1', 'virbr10-nic',
                                         'virbr40-nic', 'virbr50-nic'],
                              'virbr1': ['em1', 'virbr1-nic', 'virbr4-nic',
                                         'virbr5-nic'],
                              'virbr0': ['virbr0-nic', 'virbr2-nic',
                                         'virbr3-nic']})

    def tearDown(self):
        self.god.unstub_all()


class TestVirtIface(unittest.TestCase):

    VirtIface = utils_net.VirtIface

    def setUp(self):
        logging.disable(logging.INFO)
        logging.disable(logging.WARNING)
        utils_net.VirtIface.LASTBYTE = -1  # Restart count at zero
        # These warnings are annoying during testing
        utils_net.VMNet.DISCARD_WARNINGS - 1

    def loop_assert(self, virtiface, test_keys, what_func):
        for propertea in test_keys:
            attr_access_value = getattr(virtiface, propertea)
            can_access_value = virtiface[propertea]
            get_access_value = virtiface.get(propertea, None)
            expected_value = what_func(propertea)
            self.assertEqual(attr_access_value, can_access_value)
            self.assertEqual(can_access_value, expected_value)
            self.assertEqual(get_access_value, expected_value)

    def test_half_set(self):
        half_prop_end = (len(self.VirtIface.__all_slots__) / 2) + 1
        props = {}
        for propertea in self.VirtIface.__all_slots__[0:half_prop_end]:
            props[propertea] = utils_misc.generate_random_string(16)
        virtiface = self.VirtIface(props)
        what_func = lambda propertea: props[propertea]
        self.loop_assert(virtiface, props.keys(), what_func)

    def test_full_set(self):
        props = {}
        for propertea in self.VirtIface.__all_slots__:
            props[propertea] = utils_misc.generate_random_string(16)
        virtiface = self.VirtIface(props)
        what_func = lambda propertea: props[propertea]
        self.loop_assert(virtiface, props.keys(), what_func)

    def test_apendex_set(self):
        """
        Verify container ignores unknown key names
        """
        props = {}
        for propertea in self.VirtIface.__all_slots__:
            props[propertea] = utils_misc.generate_random_string(16)
        more_props = {}
        for _ in xrange(0, 16):
            key = utils_misc.generate_random_string(16)
            value = utils_misc.generate_random_string(16)
            more_props[key] = value
        # Keep separated for testing
        apendex_set = {}
        apendex_set.update(props)
        apendex_set.update(more_props)
        virtiface = self.VirtIface(apendex_set)
        what_func = lambda propertea: props[propertea]
        # str(props) guarantees apendex set wasn't incorporated
        self.loop_assert(virtiface, props.keys(), what_func)

    def test_mac_completer(self):
        for test_mac in ['9a', '01:02:03:04:05:06', '00', '1:2:3:4:5:6',
                         '0a:0b:0c:0d:0e:0f', 'A0:B0:C0:D0:E0:F0',
                         "01:02:03:04:05:", "01:02:03:04::", "01:02::::",
                         "00:::::::::::::::::::", ":::::::::::::::::::",
                         ":"]:
            # Tosses an exception if test_mac can't be completed
            self.VirtIface.complete_mac_address(test_mac)
        self.assertRaises(TypeError, self.VirtIface.complete_mac_address,
                          '01:f0:0:ba:r!:00')
        self.assertRaises(TypeError, self.VirtIface.complete_mac_address,
                          "01:02:03::05:06")


class TestQemuIface(TestVirtIface):

    def setUp(self):
        super(TestQemuIface, self).setUp()
        self.VirtIface = utils_net.QemuIface


class TestLibvirtIface(TestVirtIface):

    def setUp(self):
        super(TestLibvirtIface, self).setUp()
        self.VirtIface = utils_net.LibvirtIface


class TestVmNetStyle(unittest.TestCase):

    def setUp(self):
        logging.disable(logging.INFO)
        logging.disable(logging.WARNING)

    def get_style(self, vm_type, driver_type):
        return utils_net.VMNetStyle.get_style(vm_type, driver_type)

    def test_default_default(self):
        style = self.get_style(utils_misc.generate_random_string(16),
                               utils_misc.generate_random_string(16))
        self.assertEqual(style['mac_prefix'], '9a')
        self.assertEqual(style['container_class'], utils_net.QemuIface)
        self.assert_(issubclass(style['container_class'], utils_net.VirtIface))

    def test_libvirt(self):
        style = self.get_style('libvirt',
                               utils_misc.generate_random_string(16))
        self.assertEqual(style['container_class'], utils_net.LibvirtIface)
        self.assert_(issubclass(style['container_class'], utils_net.VirtIface))


class TestVmNet(unittest.TestCase):

    def setUp(self):
        logging.disable(logging.INFO)
        logging.disable(logging.WARNING)
        utils_net.VirtIface.LASTBYTE = -1  # Restart count at zero
        # These warnings are annoying during testing
        utils_net.VMNet.DISCARD_WARNINGS - 1

    def test_string_container(self):
        self.assertRaises(TypeError, utils_net.VMNet, str, ["Foo"])

    def test_VirtIface_container(self):
        test_data = [
            {'nic_name': 'nic1',
             'mac': '0a'},
            {'nic_name': ''},  # test data index 1
            {'foo': 'bar',
             'nic_name': 'nic2'},
            {'nic_name': 'nic3',
             'mac': '01:02:03:04:05:06'}
        ]
        self.assertRaises(utils_net.VMNetError,
                          utils_net.VMNet,
                          utils_net.VirtIface, test_data)
        del test_data[1]
        vmnet = utils_net.VMNet(utils_net.VirtIface, test_data)
        self.assertEqual(vmnet[0].nic_name, test_data[0]['nic_name'])
        self.assertEqual(vmnet['nic1'].__class__, utils_net.VirtIface)
        self.assertEqual(False, hasattr(vmnet['nic1'], 'mac'))
        self.assertEqual(False, 'mac' in vmnet['nic1'].keys())
        self.assertEqual(vmnet.nic_name_list(), ['nic1', 'nic2', 'nic3'])
        self.assertEqual(vmnet.nic_name_index('nic2'), 1)
        self.assertRaises(TypeError, vmnet.nic_name_index, 0)
        self.assertEqual(True, hasattr(vmnet[2], 'mac'))
        self.assertEqual(test_data[2]['mac'], vmnet[2]['mac'])


class TestVmNetSubclasses(unittest.TestCase):

    nettests_cartesian = ("""
    variants:
        - onevm:
            vms=vm1
        - twovms:
            vms=vm1 vm2
        - threevms:
            vms=vm1 vm2 vm3

    variants:
        - typeundefined:
        - libvirt:
            vm_type = libvirt
            variants:
                - unsetdrivertype:
                - xen:
                    driver_type = xen
                    nics=nic1
                - qemu:
                    driver_type = qemu
                    nics=nic1 nic2
                - kvm:
                    driver_type = kvm
                    nics=nic1 nic2 nic3
                - lxc:
                    driver_type = lxc
                    nics=nic1 nic2 nic3 nic4
        - qemu:
            vm_type = qemu
            variants:
                - unsetdrivertype:
                - kvm:
                    driver_type = kvm
                - qemu:
                    driver_type = qemu

    variants:
        -propsundefined:
        -defaultprops:
            mac = 9a
            nic_model = virtio
            nettype = bridge
            netdst = virbr0
            vlan = 0
        -mixedpropsone:
            mac_nic1 = 9a:01
            nic_model_nic1 = rtl8139
            nettype_nic1 = bridge
            netdst_nic1 = virbr1
            vlan_nic1 = 1
            ip_nic1 = 192.168.122.101
            netdev_nic1 = foobar
        -mixedpropstwo:
            mac_nic2 = 9a:02
            nic_model_nic2 = e1000
            nettype_nic2 = network
            netdst_nic2 = eth2
            vlan_nic2 = 2
            ip_nic2 = 192.168.122.102
            netdev_nic2 = barfoo
        -mixedpropsthree:
            mac_nic1 = 01:02:03:04:05:06
            mac_nic2 = 07:08:09:0a:0b:0c
            mac_nic4 = 0d:0e:0f:10:11:12
        -mixedpropsthree:
            nettype_nic3 = bridge
            netdst_nic3 = virbr3
            netdev_nic3 = qwerty
    """)

    mac_prefix = "01:02:03:04:05:"
    db_filename = '/dev/shm/UnitTest_AddressPool'
    db_item_count = 0
    counter = 0  # for printing dots

    def setUp(self):
        """
        Runs before every test
        """
        logging.disable(logging.INFO)
        logging.disable(logging.WARNING)
        # MAC generator produces from incrementing byte list
        # at random starting point (class property).
        # make sure it starts counting at zero before every test
        utils_net.VirtIface.LASTBYTE = -1
        # These warnings are annoying during testing
        utils_net.VMNet.DISCARD_WARNINGS - 1
        parser = cartesian_config.Parser()
        parser.parse_string(self.nettests_cartesian)
        self.CartesianResult = []
        for d in parser.get_dicts():
            params = utils_params.Params(d)
            self.CartesianResult.append(params)
            for vm_name in params.objects('vms'):
                vm = params.object_params(vm_name)
                nics = vm.get('nics')
                if nics and len(nics.split()) > 0:
                    self.db_item_count += 1

    def fakevm_generator(self):
        for params in self.CartesianResult:
            for vm_name in params.get('vms').split():
                # Return iterator covering all types of vms
                # in exactly the same order each time. For more info, see:
                # http://docs.python.org/reference/simple_stmts.html#yield
                yield FakeVm(vm_name, params)

    def zero_counter(self, increment=100):
        # rough total, doesn't include the number of vms
        self.increment = increment
        self.counter = 0
        sys.stdout.write(".")
        sys.stdout.flush()

    def print_and_inc(self):
        self.counter += 1
        if self.counter >= self.increment:
            self.counter = 0
            sys.stdout.write(".")
            sys.stdout.flush()

    def test_cmp_Virtnet(self):
        self.zero_counter()
        to_test = 600  # Random generator slows this test way down
        for fakevm1 in self.fakevm_generator():
            to_test -= 1
            if to_test < 1:
                break
            fvm1p = fakevm1.get_params()
            fakevm1.virtnet = utils_net.VirtNet(fvm1p, fakevm1.name,
                                                fakevm1.instance,
                                                self.db_filename)
            if len(fakevm1.virtnet) < 2:
                continue
            fakevm2 = FakeVm(fakevm1.name + "_2", fvm1p)
            fakevm2.virtnet = utils_net.VirtNet(fvm1p, fakevm2.name,
                                                fakevm2.instance,
                                                self.db_filename)
            # Verify nic order doesn't matter
            fvm3p = utils_params.Params(fvm1p.items())  # work on copy
            nic_list = fvm1p.object_params(fakevm1.name).get(
                "nics", fvm1p.get('nics', "")).split()
            random.shuffle(nic_list)
            fvm3p['nics'] = " ".join(nic_list)
            fakevm3 = FakeVm(fakevm1.name + "_3", fvm3p)
            fakevm3.virtnet = utils_net.VirtNet(fvm3p, fakevm3.name,
                                                fakevm3.instance,
                                                self.db_filename)
            self.assertTrue(fakevm1.virtnet == fakevm1.virtnet)
            self.assertTrue(fakevm1.virtnet == fakevm2.virtnet)
            self.assertTrue(fakevm1.virtnet == fakevm3.virtnet)
            self.assertTrue(fakevm2.virtnet == fakevm3.virtnet)
            if len(fakevm1.virtnet) > 1:
                del fakevm1.virtnet[0]
                self.assertFalse(fakevm1.virtnet == fakevm2.virtnet)
                self.assertFalse(fakevm1.virtnet == fakevm3.virtnet)
                self.assertTrue(fakevm1.virtnet != fakevm2.virtnet)
                self.assertTrue(fakevm1.virtnet != fakevm3.virtnet)
            self.print_and_inc()

    def test_01_Params(self):
        """
        Load Cartesian combinatorial result verifies against all styles of VM.

        Note: There are some cases where the key should NOT be set, in this
              case an exception is caught prior to verifying
        """
        self.zero_counter()
        for fakevm in self.fakevm_generator():
            test_params = fakevm.get_params()
            virtnet = utils_net.ParamsNet(test_params,
                                          fakevm.name)
            self.assert_(virtnet.container_class)
            self.assert_(virtnet.mac_prefix)
            self.assert_(issubclass(virtnet.__class__, list))
            # Assume params actually came from CartesianResult because
            # Checking this takes a very long time across all combinations
            param_nics = test_params.object_params(fakevm.name).get(
                "nics", test_params.get('nics', "")).split()
            # Size of list should match number of nics configured
            self.assertEqual(len(param_nics), len(virtnet))
            # Test each interface data
            for virtnet_index in xrange(0, len(virtnet)):
                # index correspondence already established/asserted
                virtnet_nic = virtnet[virtnet_index]
                params_nic = param_nics[virtnet_index]
                self.assert_(issubclass(virtnet_nic.__class__,
                                        propcan.PropCan))
                self.assertEqual(virtnet_nic.nic_name, params_nic,
                                 "%s != %s" % (virtnet_nic.nic_name,
                                               params_nic))
                # __slots__ functionality established/asserted elsewhere
                props_to_check = list(utils_net.VirtIface.__all_slots__)
                # other tests check mac address handling
                del props_to_check[props_to_check.index('mac')]
                for propertea in props_to_check:
                    params_propertea = test_params.object_params(params_nic
                                                                 ).get(propertea)
                    # Double-verify dual-mode access works
                    try:
                        virtnet_propertea1 = getattr(virtnet_nic, propertea)
                        virtnet_propertea2 = virtnet_nic[propertea]
                    except (KeyError, AttributeError):
                        # This style may not support all properties, skip
                        continue
                    # Only check stuff cartesian config actually set
                    if params_propertea:
                        self.assertEqual(params_propertea, virtnet_propertea1)
                        self.assertEqual(
                            virtnet_propertea1, virtnet_propertea2)
            self.print_and_inc()

    def test_02_db(self):
        """
        Load Cartesian combinatorial result from params into database
        """
        try:
            os.unlink(self.db_filename)
        except OSError:
            pass
        self.zero_counter()
        for fakevm in self.fakevm_generator():
            test_params = fakevm.get_params()
            virtnet = utils_net.DbNet(test_params, fakevm.name,
                                      self.db_filename, fakevm.instance)
            self.assert_(hasattr(virtnet, 'container_class'))
            self.assert_(hasattr(virtnet, 'mac_prefix'))
            self.assert_(not hasattr(virtnet, 'lock'))
            self.assert_(not hasattr(virtnet, 'db'))
            vm_name_params = test_params.object_params(fakevm.name)
            nic_name_list = vm_name_params.objects('nics')
            for nic_name in nic_name_list:
                # nic name is only in params scope
                nic_dict = {'nic_name': nic_name}
                nic_params = test_params.object_params(nic_name)
                # avoid processing unsupported properties
                proplist = list(virtnet.container_class().__all_slots__)
                # name was already set, remove from __slots__ list copy
                del proplist[proplist.index('nic_name')]
                for propertea in proplist:
                    nic_dict[propertea] = nic_params.get(propertea)
                virtnet.append(nic_dict)
            virtnet.update_db()
            # db shouldn't store empty items
            self.print_and_inc()

    def test_03_db(self):
        """
        Load from database created in test_02_db, verify data against params
        """
        # Verify on-disk data matches dummy data just written
        self.zero_counter()
        db = shelve.open(self.db_filename)
        db_keys = db.keys()
        self.assertEqual(len(db_keys), self.db_item_count)
        for key in db_keys:
            db_value = eval(db[key], {}, {})
            self.assert_(isinstance(db_value, list))
            self.assert_(len(db_value) > 0)
            self.assert_(isinstance(db_value[0], dict))
            for nic in db_value:
                mac = nic.get('mac')
                if mac:
                    # Another test already checked mac_is_valid behavior
                    self.assert_(utils_net.VirtIface.mac_is_valid(mac))
            self.print_and_inc()
        db.close()

    def test_04_VirtNet(self):
        """
        Populate database with max - 1 mac addresses
        """
        try:
            os.unlink(self.db_filename)
        except OSError:
            pass
        self.zero_counter(25)
        # setup() method already set LASTBYTE to '-1'
        for lastbyte in xrange(0, 0xFF):
            # test_07_VirtNet demands last byte in name and mac match
            vm_name = "vm%d" % lastbyte
            if lastbyte < 16:
                mac = "%s0%x" % (self.mac_prefix, lastbyte)
            else:
                mac = "%s%x" % (self.mac_prefix, lastbyte)
            params = utils_params.Params({
                "nics": "nic1",
                "vms": vm_name,
                "mac_nic1": mac,
            })
            virtnet = utils_net.VirtNet(params, vm_name,
                                        vm_name, self.db_filename)
            virtnet.mac_prefix = self.mac_prefix
            self.assertEqual(virtnet['nic1'].mac, mac)
            self.assertEqual(virtnet.get_mac_address(0), mac)
            # Confirm only lower-case macs are stored
            self.assertEqual(virtnet.get_mac_address(0).lower(),
                             virtnet.get_mac_address(0))
            self.assertEqual(virtnet.mac_list(), [mac])
            self.print_and_inc()

    def test_05_VirtNet(self):
        """
        Load max - 1 entries from db, overriding params.

        DEPENDS ON test_04_VirtNet running first
        """
        self.zero_counter(25)
        # second loop forces db load from disk
        # also confirming params merge with db data
        for lastbyte in xrange(0, 0xFF):
            vm_name = "vm%d" % lastbyte
            params = utils_params.Params({
                "nics": "nic1",
                "vms": vm_name
            })
            virtnet = utils_net.VirtNet(params, vm_name,
                                        vm_name, self.db_filename)
            if lastbyte < 16:
                mac = "%s0%x" % (self.mac_prefix, lastbyte)
            else:
                mac = "%s%x" % (self.mac_prefix, lastbyte)
            self.assertEqual(virtnet['nic1'].mac, mac)
            self.assertEqual(virtnet.get_mac_address(0), mac)
            self.print_and_inc()

    def test_06_VirtNet(self):
        """
        Generate last possibly mac and verify value.

        DEPENDS ON test_05_VirtNet running first
        """
        self.zero_counter(25)
        # test two nics, second mac generation should fail (pool exhausted)
        params = utils_params.Params({
            "nics": "nic1 nic2",
            "vms": "vm255"
        })
        virtnet = utils_net.VirtNet(params, 'vm255',
                                    'vm255', self.db_filename)
        virtnet.mac_prefix = self.mac_prefix
        self.assertRaises(AttributeError, virtnet.get_mac_address, 'nic1')
        mac = "%s%x" % (self.mac_prefix, 255)
        # This will grab the last available address
        # only try 300 times, guarantees LASTBYTE counter will loop once
        self.assertEqual(virtnet.generate_mac_address(0, 300), mac)
        # This will fail allocation
        self.assertRaises(utils_net.NetError,
                          virtnet.generate_mac_address, 1, 300)

    def test_07_VirtNet(self):
        """
        Release mac from beginning, midle, and end, re-generate + verify value
        """
        self.zero_counter(1)
        beginning_params = utils_params.Params({
            "nics": "nic1 nic2",
            "vms": "vm0"
        })
        middle_params = utils_params.Params({
            "nics": "nic1 nic2",
            "vms": "vm127"
        })
        end_params = utils_params.Params({
            "nics": "nic1 nic2",
            "vms": "vm255",
        })
        for params in (beginning_params, middle_params, end_params):
            vm_name = params['vms']
            virtnet = utils_net.VirtNet(params, vm_name,
                                        vm_name, self.db_filename)
            virtnet.mac_prefix = self.mac_prefix
            iface = virtnet['nic1']
            last_db_mac_byte = iface.mac_str_to_int_list(iface.mac)[-1]
            last_vm_name_byte = int(vm_name[2:])
            # Sequential generation from test_04_VirtNet guarantee
            self.assertEqual(last_db_mac_byte, last_vm_name_byte)
            # only try 300 times, guarantees LASTBYTE counter will loop once
            self.assertRaises(
                utils_net.NetError, virtnet.generate_mac_address, 1, 300)
            virtnet.free_mac_address(0)
            virtnet.free_mac_address(1)
            # generate new on nic1 to verify mac_index generator catches it
            # and to signify database updated after generation
            virtnet.generate_mac_address(1, 300)
            last_db_mac_byte = virtnet['nic2'].mac_str_to_int_list(
                virtnet['nic2'].mac)[-1]
            self.assertEqual(last_db_mac_byte, last_vm_name_byte)
            self.assertEqual(virtnet.get_mac_address(1), virtnet[1].mac)
            self.print_and_inc()

    def test_08_ifname(self):
        for fakevm in self.fakevm_generator():
            # only need to test kvm instance
            if fakevm.vm_type != 'qemu':
                continue
            test_params = fakevm.get_params()
            virtnet = utils_net.VirtNet(test_params,
                                        fakevm.name,
                                        fakevm.name)
            for virtnet_index in xrange(0, len(virtnet)):
                result = virtnet.generate_ifname(virtnet_index)
                self.assertEqual(result, virtnet[virtnet_index].ifname)
                # assume less than 10 nics
                self.assert_(len(result) < 11)
            if len(virtnet) == 2:
                break  # no need to test every possible combination

    def test_99_ifname(self):
        # cleanup
        try:
            os.unlink(self.db_filename)
        except OSError:
            pass


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = utils_params
import UserDict
from threading import Lock

from autotest.client.shared import error


class ParamNotFound(error.TestNAError):
    pass


class Params(UserDict.IterableUserDict):

    """
    A dict-like object passed to every test.
    """
    lock = Lock()

    def __getitem__(self, key):
        """ overrides the error messages of missing params[$key] """
        try:
            return UserDict.IterableUserDict.__getitem__(self, key)
        except KeyError:
            raise ParamNotFound("Mandatory parameter '%s' is missing. "
                                "Check your cfg files for typos/mistakes" %
                                key)

    def objects(self, key):
        """
        Return the names of objects defined using a given key.

        :param key: The name of the key whose value lists the objects
                (e.g. 'nics').
        """
        return self.get(key, "").split()

    def object_params(self, obj_name):
        """
        Return a dict-like object containing the parameters of an individual
        object.

        This method behaves as follows: the suffix '_' + obj_name is removed
        from all key names that have it.  Other key names are left unchanged.
        The values of keys with the suffix overwrite the values of their
        suffixless versions.

        :param obj_name: The name of the object (objects are listed by the
                objects() method).
        """
        suffix = "_" + obj_name
        self.lock.acquire()
        new_dict = self.copy()
        self.lock.release()
        for key in new_dict.keys():
            if key.endswith(suffix):
                new_key = key.split(suffix)[0]
                new_dict[new_key] = new_dict[key]
        return new_dict

    def object_counts(self, count_key, base_name):
        """
        This is a generator method: to give it the name of a count key and a
        base_name, and it returns an iterator over all the values from params
        """
        count = self.get(count_key, 1)
        # Protect in case original is modified for some reason
        cpy = self.copy()
        for number in xrange(1, int(count) + 1):
            key = "%s%s" % (base_name, number)
            yield (key, cpy.get(key))

########NEW FILE########
__FILENAME__ = utils_params_unittest
#!/usr/bin/python

import unittest

import common
import utils_params

BASE_DICT = {
    'image_boot': 'yes',
    'image_boot_stg': 'no',
    'image_chain': '',
    'image_clone_command': 'cp --reflink=auto %s %s',
    'image_format': 'qcow2',
    'image_format_stg': 'qcow2',
    'image_name': 'images/f18-64',
    'image_name_stg': 'enospc',
    'image_raw_device': 'no',
    'image_remove_command': 'rm -rf %s',
    'image_size': '10G',
    'image_snapshot_stg': 'no',
    'image_unbootable_pattern': 'Hard Disk.*not a bootable disk',
    'image_verify_bootable': 'yes',
    'images': 'image1 stg',
}

CORRECT_RESULT_MAPPING = {"image1": {'image_boot_stg': 'no',
                                     'image_snapshot_stg': 'no',
                                     'image_chain': '',
                                     'image_unbootable_pattern': 'Hard Disk.*not a bootable disk',
                                     'image_name': 'images/f18-64',
                                     'image_remove_command': 'rm -rf %s',
                                     'image_name_stg': 'enospc',
                                     'image_clone_command': 'cp --reflink=auto %s %s',
                                     'image_size': '10G', 'images': 'image1 stg',
                                     'image_raw_device': 'no',
                                     'image_format': 'qcow2',
                                     'image_boot': 'yes',
                                     'image_verify_bootable': 'yes',
                                     'image_format_stg': 'qcow2'},
                          "stg": {'image_snapshot': 'no',
                                  'image_boot_stg': 'no',
                                  'image_snapshot_stg': 'no',
                                  'image_chain': '',
                                  'image_unbootable_pattern': 'Hard Disk.*not a bootable disk',
                                  'image_name': 'enospc',
                                  'image_remove_command': 'rm -rf %s',
                                  'image_name_stg': 'enospc',
                                  'image_clone_command': 'cp --reflink=auto %s %s',
                                  'image_size': '10G',
                                  'images': 'image1 stg',
                                  'image_raw_device': 'no',
                                  'image_format': 'qcow2',
                                  'image_boot': 'no',
                                  'image_verify_bootable': 'yes',
                                  'image_format_stg': 'qcow2'}}


class TestParams(unittest.TestCase):

    def setUp(self):
        self.params = utils_params.Params(BASE_DICT)

    def testObjects(self):
        self.assertEquals(self.params.objects("images"), ['image1', 'stg'])

    def testObjectsParams(self):
        for key in CORRECT_RESULT_MAPPING.keys():
            self.assertEquals(self.params.object_params(key),
                              CORRECT_RESULT_MAPPING[key])

    def testGetItemMissing(self):
        try:
            self.params['bogus']
            raise ValueError("Did not get a ParamNotFound error when trying "
                             "to access a non-existing param")
        # pylint: disable=E0712
        except utils_params.ParamNotFound:
            pass

    def testGetItem(self):
        self.assertEqual(self.params['image_size'], "10G")


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = utils_selinux
"""
selinux test utility functions.
"""

import logging
import re
import os.path
from autotest.client import utils


class SelinuxError(Exception):

    """
    Error selinux utility functions.
    """
    pass


class SeCmdError(SelinuxError):

    """
    Error in executing cmd.
    """

    def __init__(self, cmd, detail):
        SelinuxError.__init__(self)
        self.cmd = cmd
        self.detail = detail

    def __str__(self):
        return str("Execute command %s failed.\n"
                   "Detail: %s .\n" % (self.cmd, self.detail))


class SemanageError(SelinuxError):

    """
    Error when semanage binary is not found
    """

    def __str__(self):
        return ("The semanage command is not available, "
                "please install policycoreutils "
                "or equivalent for your platform.")


class RestoreconError(SelinuxError):

    def __str__(self):
        return ("Output from the restorecon command"
                "does not match the expected format")

STATUS_LIST = ['enforcing', 'permissive', 'disabled']


def get_status():
    """
    Get the status of selinux.

    :return: string of status in STATUS_LIST.
    :raise SeCmdError: if execute 'getenforce' failed.
    :raise SelinuxError: if 'getenforce' command exit 0,
                    but the output is not expected.
    """
    cmd = 'getenforce'
    result = utils.run(cmd, ignore_status=True)
    if result.exit_status:
        raise SeCmdError(cmd, result.stderr)

    for status in STATUS_LIST:
        if result.stdout.lower().count(status):
            return status
        else:
            continue

    raise SelinuxError("result of 'getenforce' (%s)is not expected."
                       % result.stdout)


def set_status(status):
    """
    Set status of selinux.

    :param status: status want to set selinux.
    :raise SelinuxError: status is not supported.
    :raise SelinuxError: need to reboot host.
    :raise SeCmdError: execute setenforce failed.
    :raise SelinuxError: cmd setenforce exit normally,
                but status of selinux is not set to expected.
    """
    if status not in STATUS_LIST:
        raise SelinuxError("Status %s is not accepted." % status)

    current_status = get_status()
    if status == current_status:
        return
    else:
        if current_status == "disabled" or status == "disabled":
            raise SelinuxError("Please modify /etc/selinux/config and "
                               "reboot host to set selinux to %s." % status)
        else:
            cmd = "setenforce %s" % status
            result = utils.run(cmd, ignore_status=True)
            if result.exit_status:
                raise SeCmdError(cmd, result.stderr)
            else:
                current_status = get_status()
                if not status == current_status:
                    raise SelinuxError("Status of selinux is set to %s,"
                                       "but not expected %s. "
                                       % (current_status, status))
                else:
                    pass

    logging.debug("Set status of selinux to %s success.", status)


def is_disabled():
    """
    Return True if the selinux is disabled.
    """
    status = get_status()
    if status == "disabled":
        return True
    else:
        return False


def is_not_disabled():
    """
    Return True if the selinux is not disabled.
    """
    return not is_disabled()


def get_context_from_str(context):
    """
    Get the context in a context.

    :param context: SELinux context string
    :raise SelinuxError: if there is no context in context.
    """
    context_pattern = (r"[a-z,_]*_u:[a-z,_]*_r:[a-z,_]*_t"
                       # non-greedy/non-group match on optional MLS range
                       r"(?:\:[s,\-,0-9,:[c,\,,0-9]*]*)?")
    if re.search(context_pattern, context):
        context_list = re.findall(context_pattern, context)
        return context_list[0]

    raise SelinuxError("There is no context in %s." % context)


def get_type_from_context(context):
    """
    Return just the type component of a full context string

    :param context: SELinux context string
    :return: Type component of SELinux context string
    """
    # Raise exception if not a context string
    get_context_from_str(context)
    type_pattern = (r"[a-z,_]*_u:[a-z,_]*_r:([a-z,_]*_t)"
                    r"(?:\:[s,\-,0-9,:[c,\,,0-9]*]*)?")
    return re.search(type_pattern, context).group(1)


def get_context_of_file(filename):
    """
    Get the context of file.

    :raise SeCmdError: if execute 'getfattr' failed.
    """
    # More direct than scraping 'ls' output.
    cmd = "getfattr --name security.selinux %s" % filename
    result = utils.run(cmd, ignore_status=True)
    if result.exit_status:
        raise SeCmdError(cmd, result.stderr)

    output = result.stdout
    return get_context_from_str(output)


def set_context_of_file(filename, context):
    """
    Set context of file.

    :raise SeCmdError: if failed to execute chcon.
    :raise SelinuxError: if command chcon execute
                        normally, but the context of
                        file is not setted to context.
    """
    context = context.strip()
    # setfattr used for consistency with getfattr use above
    cmd = ("setfattr --name security.selinux --value \"%s\" %s"
           % (context, filename))
    result = utils.run(cmd, ignore_status=True)
    if result.exit_status:
        raise SeCmdError(cmd, result.stderr)

    context_result = get_context_of_file(filename)
    if not context == context_result:
        raise SelinuxError("Context of %s after chcon is %s, "
                           "but not expected %s."
                           % (filename, context_result, context))

    logging.debug("Set context of %s success.", filename)


def get_context_of_process(pid):
    """
    Get context of process.
    """
    attr_filepath = "/proc/%s/attr/current" % pid

    attr_file = open(attr_filepath)

    output = attr_file.read()
    return get_context_from_str(output)

# Force uniform handling if semanage not found (used in unittests)


def _no_semanage(cmdresult):
    if cmdresult.exit_status == 127:
        if cmdresult.stdout.lower().count('command not found'):
            raise SemanageError()


def get_defcon(local=False):
    """
    Return list of dictionaries containing SELinux default file context types

    :param local: Only return locally modified default contexts
    :return: list of dictionaries of default context attributes
    """
    if local:
        result = utils.run("semanage fcontext --list -C", ignore_status=True)
    else:
        result = utils.run("semanage fcontext --list", ignore_status=True)
    _no_semanage(result)
    if result.exit_status != 0:
        raise SeCmdError('semanage', result.stderr)
    result_list = result.stdout.strip().split('\n')
    # Need to process top-down instead of bottom-up
    result_list.reverse()
    first_line = result_list.pop()
    # First column name has a space in it
    column_names = [name.strip().lower().replace(' ', '_')
                    for name in first_line.split('  ')
                    if len(name) > 0]
    # Shorten first column name
    column_names[0] = column_names[0].replace("selinux_", "")
    fcontexts = []
    for line in result_list:
        if len(line) < 1:  # skip blank lines
            continue
        column_data = [name.strip()
                       for name in line.split('  ')
                       if len(name) > 0]
        # Enumerating data raises exception if no column_names match
        fcontext = dict([(column_names[idx], data)
                         for idx, data in enumerate(column_data)])
        # find/set functions only accept type, not full context string
        fcontext['context'] = get_type_from_context(fcontext['context'])
        fcontexts.append(fcontext)
    return fcontexts


def find_defcon_idx(defcon, pathname):
    """
    Returns the index into defcon where pathname matches or None
    """
    # Default context path regexes only work on canonical paths
    pathname = os.path.realpath(pathname)
    for default_context in defcon:
        if bool(re.search(default_context['fcontext'], pathname)):
            return defcon.index(default_context)
    return None


def find_defcon(defcon, pathname):
    """
    Returns the context type of first match to pathname or None
    """
    # Default context path regexes only work on canonical paths
    pathname = os.path.realpath(pathname)
    idx = find_defcon_idx(defcon, pathname)
    if idx is not None:
        return get_type_from_context(defcon[idx]['context'])
    else:
        return None


def find_pathregex(defcon, pathname):
    """
    Returns the regular expression in defcon matching pathname
    """
    # Default context path regexes only work on canonical paths
    pathname = os.path.realpath(pathname)
    idx = find_defcon_idx(defcon, pathname)
    if idx is not None:
        return defcon[idx]['fcontext']
    else:
        return None


def set_defcon(context_type, pathregex):
    """
    Set the default context of a file/path in local SELinux policy

    :param context_type: The selinux context (only type is used)
    :param pathregex: Pathname regex e.g. r"/foo/bar/baz(/.*)?"
    :raise SelinuxError: if semanage command not found
    :raise SeCmdError: if semanage exits non-zero
    """
    cmd = ("semanage fcontext --add -t %s '%s'" % (context_type, pathregex))
    result = utils.run(cmd, ignore_status=True)
    _no_semanage(result)
    if result.exit_status != 0:
        raise SeCmdError(cmd, result.stderr)


def del_defcon(context_type, pathregex):
    """
    Remove the default local SELinux policy type for a file/path

    :param context: The selinux context (only type is used)
    :pramm pathregex: Pathname regex e.g. r"/foo/bar/baz(/.*)?"
    :raise SelinuxError: if semanage command not found
    :raise SeCmdError: if semanage exits non-zero
    """
    cmd = ("semanage fcontext --delete -t %s '%s'" % (context_type, pathregex))
    result = utils.run(cmd, ignore_status=True)
    _no_semanage(result)
    if result.exit_status != 0:
        raise SeCmdError(cmd, result.stderr)

# Process pathname/dirdesc in uniform way for all defcon functions + unittests


def _run_restorecon(pathname, dirdesc, readonly=True):
    cmd = 'restorecon -v'
    if dirdesc:
        cmd += 'R'
    if readonly:
        cmd += 'n'
    cmd += ' "%s"' % pathname
    # Always returns 0, even if contexts wrong
    return utils.run(cmd).stdout.strip()


def verify_defcon(pathname, dirdesc=False):
    """
    Verify contexts of pathspec (and/or below, if dirdesc) match default

    :param pathname: Absolute path to file, directory, or symlink
    :param dirdesc: True to descend into sub-directories
    :return: True if all components match default contexts
    :note: By default DOES NOT follow symlinks
    """
    # Default context path regexes only work on canonical paths
    changes = _run_restorecon(pathname, dirdesc)
    if changes.count('restorecon reset'):
        return False
    else:
        return True


# Provide uniform formatting for diff and apply functions

def _format_changes(changes):
    result = []
    if changes:  # Empty string or None - return empty list
        # Could be many changes, need efficient line searching
        regex = re.compile('^restorecon reset (.+) context (.+)->(.+)')
        for change_line in changes.split('\n'):
            mobj = regex.search(change_line)
            if mobj is None:
                raise RestoreconError()
            pathname = mobj.group(1)
            from_con = mobj.group(2)
            to_con = mobj.group(3)
            result.append((pathname, from_con, to_con))
    return result


def diff_defcon(pathname, dirdesc=False):
    """
    Return a list of tuple(pathname, from, to) for current & default contexts

    :param pathname: Absolute path to file, directory, or symlink
    :param dirdesc: True to descend into sub-directories
    :return: List of tuple(pathname, from context, to context)
    """
    return _format_changes(_run_restorecon(pathname, dirdesc))


def apply_defcon(pathname, dirdesc=False):
    """
    Apply default contexts to pathname, possibly descending into sub-dirs also.

    :param pathname: Absolute path to file, directory, or symlink
    :param dirdesc: True to descend into sub-directories
    :return: List of changes applied tuple(pathname, from context, to context)
    """
    return _format_changes(_run_restorecon(pathname, dirdesc, readonly=False))


def transmogrify_usr_local(pathregex):
    """
    Replace usr/local/something with usr/(local/)?something
    """
    # Whoa! don't mess with short path regex's
    if len(pathregex) < 3:
        return pathregex
    if pathregex.count('usr/local'):
        pathregex = pathregex.replace('usr/local/', r'usr/(local/)?')
    return pathregex


def transmogrify_sub_dirs(pathregex):
    """
    Append '(/.*)?' regex to end of pathregex to optionally match all subdirs
    """
    # Whoa! don't mess with short path regex's
    if len(pathregex) < 3:
        return pathregex
    # Doesn't work with path having trailing slash
    if pathregex.endswith('/'):
        pathregex = pathregex[0:-1]
    return pathregex + r'(/.*)?'

########NEW FILE########
__FILENAME__ = utils_spice
"""
Common spice test utility functions.

"""
import os
import logging
import time
import sys
from autotest.client.shared import error
from aexpect import ShellCmdError, ShellStatusError
from virttest import utils_net, utils_misc


class RVConnectError(Exception):

    """Exception raised in case that remote-viewer fails to connect"""
    pass


def _is_pid_alive(session, pid):

    try:
        session.cmd("ps -p %s" % pid)
    except ShellCmdError:
        return False

    return True


def wait_timeout(timeout=10):
    """
    time.sleep(timeout) + logging.debug(timeout)

    :param timeout=10
    """
    logging.debug("Waiting (timeout=%ss)", timeout)
    time.sleep(timeout)


def verify_established(client_vm, host, port, rv_binary,
                       tls_port=None, secure_channels=None):
    """
    Parses netstat output for established connection on host:port
    :param client_session - vm.wait_for_login()
    :param host - host ip addr
    :param port - port for client to connect
    :param rv_binary - remote-viewer binary
    """
    rv_binary = rv_binary.split(os.path.sep)[-1]

    client_session = client_vm.wait_for_login(timeout=60)
    tls_count = 0

    # !!! -n means do not resolve port names
    if ".exe" in rv_binary:
        cmd = "netstat -n"

    else:
        cmd = ('(netstat -pn 2>&1| grep "^tcp.*:.*%s.*ESTABLISHED.*%s.*")' %
               (host, rv_binary))
    netstat_out = client_session.cmd_output(cmd)
    logging.info("netstat output: %s", netstat_out)

    if tls_port:
        tls_count = netstat_out.count(tls_port)
    else:
        tls_port = port

    if (netstat_out.count(port) + tls_count) < 4:
        logging.error("Not enough channels were open")
        raise RVConnectError()
    if secure_channels:
        if tls_count < len(secure_channels.split(',')):
            logging.error("Not enough secure channels open")
            raise RVConnectError()
    for line in netstat_out.split('\n'):
        if ((port in line and "ESTABLISHED" not in line) or
                (tls_port in line and "ESTABLISHED" not in line)):
            logging.error("Failed to get established connection from netstat")
            raise RVConnectError()
    if "ESTABLISHED" not in netstat_out:
        logging.error("Failed to get established connection from netstat")
        raise RVConnectError()
    logging.info("%s connection to %s:%s successful.",
                 rv_binary, host, port)

    client_session.close()


def start_vdagent(guest_session, test_timeout):
    """
    Sending commands to start the spice-vdagentd service

    :param guest_session: ssh session of the VM
    :param test_timeout: timeout time for the cmds
    """
    cmd = "service spice-vdagentd start"
    try:
        guest_session.cmd(cmd, print_func=logging.info,
                          timeout=test_timeout)
    except ShellStatusError:
        logging.debug("Status code of \"%s\" was not obtained, most likely"
                      "due to a problem with colored output" % cmd)
    except:
        raise error.TestFail("Guest Vdagent Daemon Start failed")

    logging.debug("------------ End of guest checking for Spice Vdagent"
                  " Daemon ------------")
    wait_timeout(3)


def restart_vdagent(guest_session, test_timeout):
    """
    Sending commands to restart the spice-vdagentd service

    :param guest_session: ssh session of the VM
    :param test_timeout: timeout time for the cmds
    """
    cmd = "service spice-vdagentd restart"
    try:
        guest_session.cmd(cmd, print_func=logging.info,
                          timeout=test_timeout)
    except ShellCmdError:
        raise error.TestFail("Couldn't restart spice vdagent process")
    except:
        raise error.TestFail("Guest Vdagent Daemon Check failed")

    logging.debug("------------ End of Spice Vdagent"
                  " Daemon  Restart ------------")
    wait_timeout(3)


def stop_vdagent(guest_session, test_timeout):
    """
    Sending commands to stop the spice-vdagentd service

    :param guest_session: ssh session of the VM
    :param test_timeout: timeout time for the cmds
    """
    cmd = "service spice-vdagentd stop"
    try:
        guest_session.cmd(cmd, print_func=logging.info,
                          timeout=test_timeout)
    except ShellStatusError:
        logging.debug("Status code of \"%s\" was not obtained, most likely"
                      "due to a problem with colored output" % cmd)
    except ShellCmdError:
        raise error.TestFail("Couldn't turn off spice vdagent process")
    except:
        raise error.TestFail("Guest Vdagent Daemon Check failed")

    logging.debug("------------ End of guest checking for Spice Vdagent"
                  " Daemon ------------")
    wait_timeout(3)


def verify_vdagent(guest_session, test_timeout):
    """
    Verifying vdagent is installed on a VM

    :param guest_session: ssh session of the VM
    :param test_timeout: timeout time for the cmds
    """
    cmd = "rpm -qa | grep spice-vdagent"

    try:
        guest_session.cmd(cmd, print_func=logging.info, timeout=test_timeout)
    finally:
        logging.debug("----------- End of guest check to see if vdagent package"
                      " is available ------------")
    wait_timeout(3)


def get_vdagent_status(vm_session, test_timeout):
    """
    Return the status of vdagent
    :param vm_session:  ssh session of the VM
    :param test_timeout: timeout time for the cmd
    """
    output = ""
    cmd = "service spice-vdagentd status"

    wait_timeout(3)
    try:
        output = vm_session.cmd(
            cmd, print_func=logging.info, timeout=test_timeout)
    except ShellCmdError:
        # getting the status of vdagent stopped returns 3, which results in a
        # ShellCmdError
        return("stopped")
    except:
        print "Unexpected error:", sys.exc_info()[0]
        raise error.TestFail(
            "Failed attempting to get status of spice-vdagentd")
    wait_timeout(3)
    return(output)


def verify_virtio(guest_session, test_timeout):
    """
    Verify Virtio linux driver is properly loaded.

    :param guest_session: ssh session of the VM
    :param test_timeout: timeout time for the cmds
    """
    #cmd = "lsmod | grep virtio_console"
    cmd = "ls /dev/virtio-ports/"
    try:
        guest_session.cmd(cmd, print_func=logging.info, timeout=test_timeout)
    finally:
        logging.debug("------------ End of guest check of the Virtio-Serial"
                      " Driver------------")
    wait_timeout(3)


def install_rv_win(client, host_path, client_path='C:\\virt-viewer.msi'):
    """
    Install remote-viewer on a windows client

    :param client:      VM object
    :param host_path:   Location of installer on host
    :param client_path: Location of installer after copying
    """
    session = client.wait_for_login(
        timeout=int(client.params.get("login_timeout", 360)))
    client.copy_files_to(host_path, client_path)
    try:
        session.cmd_output(client_path + " /S")
    except:
        pass


def clear_interface(vm, login_timeout=360, timeout=5):
    """
    Clears user interface of a vm without restart

    :param vm:      VM where cleaning is required
    """
    logging.info("restarting X on: %s", vm.name)
    session = vm.wait_for_login(username="root", password="123456",
                                timeout=login_timeout)
    pid = session.cmd("pgrep Xorg")
    session.cmd("killall Xorg")

    utils_misc.wait_for(lambda: _is_pid_alive(session, pid), 10, timeout, 0.2)

    try:
        session.cmd("ps -C Xorg")
    except ShellCmdError:
        raise error.TestFail("X not running")


def deploy_epel_repo(guest_session, params):
    """
    Deploy epel repository to RHEL VM If It's RHEL6 or 5.

    :param guest_session - ssh session to guest VM
    :param params
    """

    # Check existence of epel repository
    try:
        guest_session.cmd("test -a /etc/yum.repos.d/epel.repo")
    except ShellCmdError:
        arch = guest_session.cmd("arch")
        if "i686" in arch:
            arch = "i386"
        else:
            arch = arch[:-1]
        if "release 5" in guest_session.cmd("cat /etc/redhat-release"):
            cmd = ("yum -y localinstall http://download.fedoraproject.org/"
                   "pub/epel/5/%s/epel-release-5-4.noarch.rpm 2>&1" % arch)
            logging.info("Installing epel repository to %s",
                         params.get("guest_vm"))
            guest_session.cmd(cmd, print_func=logging.info, timeout=90)
        elif "release 6" in guest_session.cmd("cat /etc/redhat-release"):
            cmd = ("yum -y localinstall http://download.fedoraproject.org/"
                   "pub/epel/6/%s/epel-release-6-8.noarch.rpm 2>&1" % arch)
            logging.info("Installing epel repository to %s",
                         params.get("guest_vm"))
            guest_session.cmd(cmd, print_func=logging.info, timeout=90)
        else:
            raise Exception("Unsupported RHEL guest")


def gen_rv_file(params, guest_vm, host_subj=None, cacert=None):
    """
    Generates vv file for remote-viewer

    :param params:          all parameters of the test
    :param guest_vm:        object of a guest VM
    :param host_subj:    subject of the host
    :param cacert:          location of certificate of host
    """
    full_screen = params.get("full_screen")
    proxy = params.get("spice_proxy")

    rv_file = open('rv_file.vv', 'w')
    rv_file.write("[virt-viewer]\n" +
                  "type=%s\n" % params.get("display") +
                  "host=%s\n" % utils_net.get_host_ip_address(params) +
                  "port=%s\n" % guest_vm.get_spice_var("spice_port"))

    ticket = params.get("spice_password")
    ticket_send = params.get("spice_password_send")
    qemu_ticket = params.get("qemu_password")
    if ticket_send:
        ticket = ticket_send
    if qemu_ticket:
        ticket = qemu_ticket
    rv_file.write("password=%s\n" % ticket)

    if guest_vm.get_spice_var("spice_ssl") == "yes":
        rv_file.write("tls-port=%s\n" %
                      guest_vm.get_spice_var("spice_tls_port"))
        rv_file.write("tls-ciphers=DEFAULT\n")
    if host_subj:
        rv_file.write("host-subject=%s\n" % host_subj)
    if cacert:
        cert = open(cacert)
        ca = cert.read()
        ca = ca.replace('\n', r'\n')
        rv_file.write("ca=%s\n" % ca)
    if full_screen == "yes":
        rv_file.write("fullscreen=1\n")
    if proxy:
        rv_file.write("proxy=%s\n" % proxy)

########NEW FILE########
__FILENAME__ = libguestfs
import re
import os
import logging
import commands
from autotest.client.shared import error, utils
from virttest import virsh, virt_vm, libvirt_vm, data_dir
from virttest import utils_net, xml_utils
from virttest.libvirt_xml import vm_xml, xcepts
from virttest import utils_libguestfs as lgf
from virttest import qemu_storage


class VTError(Exception):
    pass


class VTAttachError(VTError):

    def __init__(self, cmd, output):
        super(VTAttachError, self).__init__(cmd, output)
        self.cmd = cmd
        self.output = output

    def __str__(self):
        return ("Attach command failed:%s\n%s" % (self.cmd, self.output))


class VTMountError(VTError):

    def __init__(self, cmd, output):
        VTError.__init__(self, cmd, output)
        self.cmd = cmd
        self.output = output

    def __str__(self):
        return ("Mount command failed:%s\n%s" % (self.cmd, self.output))


class VTXMLParseError(VTError):

    def __init__(self, cmd, output):
        super(VTXMLParseError, self).__init__(cmd, output)
        self.cmd = cmd
        self.output = output

    def __str__(self):
        return ("Parse XML with '%s' failed:%s" % (self.cmd, self.output))


def preprocess_image(params):
    """
    Create a disk which used by guestfish

    params: Get params from cfg file
    """
    image_dir = params.get("img_dir", data_dir.get_tmp_dir())
    image_name = params.get("image_name", "gs_common")
    image = qemu_storage.QemuImg(params, image_dir, image_name)
    image_path, _ = image.create(params)

    logging.info("Image created in %s" % image_path)
    return image_path


def primary_disk_virtio(vm):
    """
    To verify if system disk is virtio.

    :param vm: Libvirt VM object.
    """
    vmdisks = vm.get_disk_devices()
    if "vda" in vmdisks.keys():
        return True
    return False


def get_primary_disk(vm):
    """
    Get primary disk source.

    :param vm: Libvirt VM object.
    """
    vmdisks = vm.get_disk_devices()
    if len(vmdisks):
        pri_target = ['vda', 'sda']
        for target in pri_target:
            try:
                return vmdisks[target]['source']
            except KeyError:
                pass
    return None


def attach_additional_disk(vm, disksize, targetdev):
    """
    Create a disk with disksize, then attach it to given vm.

    :param vm: Libvirt VM object.
    :param disksize: size of attached disk
    :param targetdev: target of disk device
    """
    logging.info("Attaching disk...")
    disk_path = os.path.join(data_dir.get_tmp_dir(), targetdev)
    cmd = "qemu-img create %s %s" % (disk_path, disksize)
    status, output = commands.getstatusoutput(cmd)
    if status:
        return (False, output)

    # To confirm attached device do not exist.
    virsh.detach_disk(vm.name, targetdev, extra="--config")

    attach_result = virsh.attach_disk(vm.name, disk_path, targetdev,
                                      extra="--config", debug=True)
    if attach_result.exit_status:
        return (False, attach_result)
    return (True, disk_path)


def define_new_vm(vm_name, new_name):
    """
    Just define a new vm from given name
    """
    try:
        vmxml = vm_xml.VMXML.new_from_dumpxml(vm_name)
        vmxml.vm_name = new_name
        del vmxml.uuid
        logging.debug(str(vmxml))
        vmxml.define()
        return True
    except xcepts.LibvirtXMLError, detail:
        logging.error(detail)
        return False


def cleanup_vm(vm_name=None, disk=None):
    """
    Cleanup the vm with its disk deleted.
    """
    try:
        if vm_name is not None:
            virsh.undefine(vm_name)
    except error.CmdError, detail:
        logging.error("Undefine %s failed:%s", vm_name, detail)
    try:
        if disk is not None:
            os.remove(disk)
    except IOError, detail:
        logging.error("Remove disk %s failed:%s", disk, detail)


class VirtTools(object):

    """
    Useful functions for virt-commands.

    Some virt-tools need an input disk and output disk.
    Main for virt-clone, virt-sparsify, virt-resize.
    """

    def __init__(self, vm, params):
        self.params = params
        self.oldvm = vm
        # Many command will create a new vm or disk, init it here
        self.newvm = libvirt_vm.VM("VTNEWVM", vm.params, vm.root_dir,
                                   vm.address_cache)
        # Preapre for created vm disk
        self.indisk = get_primary_disk(vm)
        self.outdisk = None

    def update_vm_disk(self):
        """
        Update oldvm's disk, and then create a newvm.
        """
        target_dev = self.params.get("gf_updated_target_dev", "vdb")
        device_size = self.params.get("gf_updated_device_size", "50M")
        self.newvm.name = self.params.get("gf_updated_new_vm")
        if self.newvm.is_alive():
            self.newvm.destroy()
            self.newvm.wait_for_shutdown()

        attachs, attacho = attach_additional_disk(self.newvm,
                                                  disksize=device_size,
                                                  targetdev=target_dev)
        if attachs:
            # Restart vm for guestfish command
            # Otherwise updated disk is not visible
            try:
                self.newvm.start()
                self.newvm.wait_for_login()
                self.newvm.destroy()
                self.newvm.wait_for_shutdown()
                self.params['added_disk_path'] = attacho
            except virt_vm.VMError, detail:
                raise VTAttachError("", str(detail))
        else:
            raise VTAttachError("", attacho)

    def clone_vm_filesystem(self, newname=None):
        """
        Clone a new vm with only its filesystem disk.

        :param newname:if newname is None,
                       create a new name with clone added.
        """
        logging.info("Cloning...")
        # Init options for virt-clone
        options = {}
        autoclone = bool(self.params.get("autoclone", False))
        new_filesystem_path = self.params.get("new_filesystem_path")
        cloned_files = []
        if new_filesystem_path:
            self.outdisk = new_filesystem_path
        elif self.indisk is not None:
            self.outdisk = "%s-clone" % self.indisk
        cloned_files.append(self.outdisk)
        options['files'] = cloned_files
        # cloned_mac can be CREATED, RANDOM or a string.
        cloned_mac = self.params.get("cloned_mac", "CREATED")
        if cloned_mac == "CREATED":
            options['mac'] = utils_net.generate_mac_address_simple()
        else:
            options['mac'] = cloned_mac

        options['ignore_status'] = True
        options['debug'] = True
        options['timeout'] = int(self.params.get("timeout", 240))
        if newname is None:
            newname = "%s-virtclone" % self.oldvm.name
        result = lgf.virt_clone_cmd(self.oldvm.name, newname,
                                    autoclone, **options)
        if result.exit_status:
            error_info = "Clone %s to %s failed." % (self.oldvm.name, newname)
            logging.error(error_info)
            return (False, result)
        else:
            self.newvm.name = newname
            cloned_mac = vm_xml.VMXML.get_first_mac_by_name(newname)
            if cloned_mac is not None:
                self.newvm.address_cache[cloned_mac] = None
            return (True, result)

    def sparsify_disk(self):
        """
        Sparsify a disk
        """
        logging.info("Sparsifing...")
        if self.indisk is None:
            logging.error("No disk can be sparsified.")
            return (False, "Input disk is None.")
        if self.outdisk is None:
            self.outdisk = "%s-sparsify" % self.indisk
        timeout = int(self.params.get("timeout", 240))
        result = lgf.virt_sparsify_cmd(self.indisk, self.outdisk,
                                       ignore_status=True, debug=True,
                                       timeout=timeout)
        if result.exit_status:
            error_info = "Sparsify %s to %s failed." % (self.indisk,
                                                        self.outdisk)
            logging.error(error_info)
            return (False, result)
        return (True, result)

    def define_vm_with_newdisk(self):
        """
        Define the new vm with old vm's configuration

        Changes:
        1.replace name
        2.delete uuid
        3.replace disk
        """
        logging.info("Define a new vm:")
        old_vm_name = self.oldvm.name
        new_vm_name = "%s-vtnewdisk" % old_vm_name
        self.newvm.name = new_vm_name
        old_disk = self.indisk
        new_disk = self.outdisk
        try:
            vmxml = vm_xml.VMXML.new_from_dumpxml(old_vm_name)
            vmxml.vm_name = new_vm_name
            vmxml.uuid = ""
            vmxml.set_xml(re.sub(old_disk, new_disk,
                                 str(vmxml.__dict_get__('xml'))))
            logging.debug(vmxml.__dict_get__('xml'))
            vmxml.define()
        except xcepts.LibvirtXMLError, detail:
            logging.debug(detail)
            return (False, detail)
        return (True, vmxml.xml)

    def expand_vm_filesystem(self, resize_part_num=2, resized_size="+1G",
                             new_disk=None):
        """
        Expand vm's filesystem with virt-resize.
        """
        logging.info("Resizing vm's disk...")
        options = {}
        options['resize'] = "/dev/sda%s" % resize_part_num
        options['resized_size'] = resized_size
        if new_disk is not None:
            self.outdisk = new_disk
        elif self.outdisk is None:
            self.outdisk = "%s-resize" % self.indisk

        options['ignore_status'] = True
        options['debug'] = True
        options['timeout'] = int(self.params.get("timeout", 480))
        result = lgf.virt_resize_cmd(self.indisk, self.outdisk, **options)
        if result.exit_status:
            logging.error(result)
            return (False, result)
        return (True, self.outdisk)

    def guestmount(self, mountpoint, disk_or_domain=None):
        """
        Mount filesystems in a disk or domain to host mountpoint.

        :param disk_or_domain: if it is None, use default vm in params
        """
        logging.info("Mounting filesystems...")
        if disk_or_domain is None:
            disk_or_domain = self.oldvm.name
        if not os.path.isdir(mountpoint):
            os.mkdir(mountpoint)
        if os.path.ismount(mountpoint):
            utils.run("umount -l %s" % mountpoint, ignore_status=True)
        inspector = "yes" == self.params.get("gm_inspector", "yes")
        readonly = "yes" == self.params.get("gm_readonly", "no")
        special_mountpoints = self.params.get("special_mountpoints", [])
        is_disk = "yes" == self.params.get("gm_is_disk", "no")
        options = {}
        options['ignore_status'] = True
        options['debug'] = True
        options['timeout'] = int(self.params.get("timeout", 240))
        options['special_mountpoints'] = special_mountpoints
        options['is_disk'] = is_disk
        result = lgf.guestmount(disk_or_domain, mountpoint,
                                inspector, readonly, **options)
        if result.exit_status:
            error_info = "Mount %s to %s failed." % (disk_or_domain,
                                                     mountpoint)
            logging.error(result)
            return (False, error_info)
        return (True, mountpoint)

    def write_file_with_guestmount(self, mountpoint, path,
                                   content=None, vm_ref=None,
                                   cleanup=True):
        """
        Write content to file with guestmount
        """
        logging.info("Creating file...")
        gms, gmo = self.guestmount(mountpoint, vm_ref)
        if gms is True:
            mountpoint = gmo
        else:
            logging.error("Create file %s failed.", path)
            return (False, gmo)

        # file's path on host's mountpoint
        file_path = os.path.join(mountpoint, path)
        if content is None:
            content = "This is a temp file with guestmount."
        try:
            fd = open(file_path, "w")
            fd.write(content)
            fd.close()
        except IOError, detail:
            logging.error(detail)
            return (False, detail)
        logging.info("Create file %s successfully", file_path)
        # Cleanup created file
        if cleanup:
            utils.run("rm -f %s" % file_path, ignore_status=True)
        return (True, file_path)

    def get_primary_disk_fs_type(self):
        """
        Get primary disk filesystem type
        """
        result = lgf.virt_filesystems(self.oldvm.name, long_format=True)
        if result.exit_status:
            raise error.TestNAError("Cannot get primary disk"
                                    " filesystem information!")
        fs_info = result.stdout.strip().splitlines()
        if len(fs_info) <= 1:
            raise error.TestNAError("No disk filesystem information!")
        try:
            primary_disk_info = fs_info[1]
            fs_type = primary_disk_info.split()[2]
            return fs_type
        except (KeyError, ValueError), detail:
            raise error.TestFail(str(detail))

    def tar_in(self, tar_file, dest="/tmp", vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_tar_in(vm_ref, tar_file, dest,
                                 debug=True, ignore_status=True)
        return result

    def tar_out(self, directory, tar_file="temp.tar", vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_tar_out(vm_ref, directory, tar_file,
                                  debug=True, ignore_status=True)
        return result

    def cat(self, filename, vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_cat_cmd(vm_ref, filename, debug=True,
                                  ignore_status=True)
        return result

    def copy_in(self, filename, dest="/tmp", vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_copy_in(vm_ref, filename, dest, debug=True,
                                  ignore_status=True)
        return result

    def copy_out(self, file_path, localdir="/tmp", vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_copy_out(vm_ref, file_path, localdir,
                                   debug=True, ignore_status=True)
        return result

    def format_disk(self, disk_path=None, filesystem=None, partition=None,
                    lvm=None):
        """
        :param disk_path: None for additional disk by update_vm_disk() only
        """
        if disk_path is None:
            disk_path = self.params.get("added_disk_path")
        result = lgf.virt_format(disk_path, filesystem,
                                 lvm=lvm, partition=partition,
                                 debug=True, ignore_status=True)
        return result

    def get_filesystems_info(self, vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_filesystems(vm_ref, long_format=True,
                                      debug=True, all=True,
                                      ignore_status=True)
        return result

    def list_df(self, vm_ref=None):
        if vm_ref is None:
            vm_ref = self.oldvm.name
        result = lgf.virt_df(vm_ref, debug=True, ignore_status=True)
        return result

    def get_vm_info_with_inspector(self, vm_ref=None):
        """
        Return a dict includes os information.
        """
        if vm_ref is None:
            vm_ref = self.oldvm.name
        # A dict to include system information
        sys_info = {}
        result = lgf.virt_inspector(vm_ref, ignore_status=True)
        if result.exit_status:
            logging.error("Get %s information with inspector(2) failed:\n%s",
                          vm_ref, result)
            return sys_info
        # Analyse output to get information
        try:
            xmltreefile = xml_utils.XMLTreeFile(result.stdout)
            os_root = xmltreefile.find("operatingsystem")
            if os_root is None:
                raise VTXMLParseError("operatingsystem", os_root)
        except (IOError, VTXMLParseError), detail:
            logging.error(detail)
            return sys_info
        sys_info['root'] = os_root.findtext("root")
        sys_info['name'] = os_root.findtext("name")
        sys_info['arch'] = os_root.findtext("arch")
        sys_info['distro'] = os_root.findtext("distro")
        sys_info['release'] = os_root.findtext("product_name")
        sys_info['major_version'] = os_root.findtext("major_version")
        sys_info['minor_version'] = os_root.findtext("minor_version")
        sys_info['hostname'] = os_root.findtext("hostname")
        # filesystems and mountpoints are dict to restore detail info
        mountpoints = {}
        for node in os_root.find("mountpoints"):
            mp_device = node.get("dev")
            if mp_device is not None:
                mountpoints[mp_device] = node.text
        sys_info['mountpoints'] = mountpoints
        filesystems = {}
        for node in os_root.find("filesystems"):
            fs_detail = {}
            fs_device = node.get("dev")
            if fs_device is not None:
                fs_detail['type'] = node.findtext("type")
                fs_detail['label'] = node.findtext("label")
                fs_detail['uuid'] = node.findtext("uuid")
                filesystems[fs_device] = fs_detail
        sys_info['filesystems'] = filesystems
        logging.debug("VM information:\n%s", sys_info)
        return sys_info


class GuestfishTools(lgf.GuestfishPersistent):

    """Useful Tools for Guestfish class."""

    __slots__ = ('params', )

    def __init__(self, params):
        """
        Init a persistent guestfish shellsession.
        """
        self.params = params
        disk_img = params.get("disk_img")
        ro_mode = bool(params.get("gf_ro_mode", False))
        libvirt_domain = params.get("libvirt_domain")
        inspector = bool(params.get("gf_inspector", False))
        mount_options = params.get("mount_options")
        run_mode = params.get("gf_run_mode", "interactive")
        super(GuestfishTools, self).__init__(disk_img, ro_mode,
                                             libvirt_domain, inspector,
                                             mount_options=mount_options,
                                             run_mode=run_mode)

    def get_root(self):
        """
        Get root filesystem w/ guestfish
        """
        getroot_result = self.inspect_os()
        roots_list = getroot_result.stdout.splitlines()
        if getroot_result.exit_status or not len(roots_list):
            logging.error("Get root failed:%s", getroot_result)
            return (False, getroot_result)
        return (True, roots_list[0].strip())

    def analyse_release(self):
        """
        Analyse /etc/redhat-release
        """
        logging.info("Analysing /etc/redhat-release...")
        release_result = self.cat("/etc/redhat-release")
        logging.debug(release_result)
        if release_result.exit_status:
            logging.error("Cat /etc/redhat-release failed")
            return (False, release_result)

        release_type = {'rhel': "Red Hat Enterprise Linux",
                        'fedora': "Fedora"}
        for key in release_type:
            if re.search(release_type[key], release_result.stdout):
                return (True, key)

    def write_file(self, path, content):
        """
        Create a new file to vm with guestfish
        """
        logging.info("Creating file %s in vm...", path)
        write_result = self.write(path, content)
        if write_result.exit_status:
            logging.error("Create '%s' with content '%s' failed:%s",
                          path, content, write_result)
            return False
        return True

    def get_partitions_info(self, device="/dev/sda"):
        """
        Get disk partition's information.
        """
        list_result = self.part_list(device)
        if list_result.exit_status:
            logging.error("List partition info failed:%s", list_result)
            return (False, list_result)
        list_lines = list_result.stdout.splitlines()
        # This dict is a struct like this: {key:{a dict}, key:{a dict}}
        partitions = {}
        # This dict is a struct of normal dict, for temp value of a partition
        part_details = {}
        index = -1
        for line in list_lines:
            # Init for a partition
            if re.search("\[\d\]\s+=", line):
                index = line.split("]")[0].split("[")[-1]
                part_details = {}
                partitions[index] = part_details

            if re.search("part_num", line):
                part_num = int(line.split(":")[-1].strip())
                part_details['num'] = part_num
            elif re.search("part_start", line):
                part_start = int(line.split(":")[-1].strip())
                part_details['start'] = part_start
            elif re.search("part_end", line):
                part_end = int(line.split(":")[-1].strip())
                part_details['end'] = part_end
            elif re.search("part_size", line):
                part_size = int(line.split(":")[-1].strip())
                part_details['size'] = part_size

            if index != -1:
                partitions[index] = part_details
        logging.info(partitions)
        return (True, partitions)

    def get_part_size(self, part_num):
        status, partitions = self.get_partitions_info()
        if status is False:
            return None
        for partition in partitions.values():
            if str(partition.get("num")) == str(part_num):
                return partition.get("size")

    def create_fs(self):
        """
        Create filesystem of disk

        Choose lvm or physical partition and create fs on it
        """
        image_path = self.params.get("image_path")
        self.add_drive(image_path)
        self.run()

        partition_type = self.params.get("partition_type")
        fs_type = self.params.get("fs_type", "ext3")
        image_size = self.params.get("image_size", "6G")
        with_blocksize = self.params.get("with_blocksize")
        blocksize = self.params.get("blocksize")
        tarball_path = self.params.get("tarball_path")

        if partition_type not in ['lvm', 'physical']:
            return (False, "partition_type is incorrect, support [physical,lvm]")

        if partition_type == "lvm":
            logging.info("create lvm partition...")
            pv_name = self.params.get("pv_name", "/dev/sdb")
            vg_name = self.params.get("vg_name", "vol_test")
            lv_name = self.params.get("lv_name", "vol_file")
            mount_point = "/dev/%s/%s" % (vg_name, lv_name)
            lv_size = int(image_size.replace('G', '')) * 1000

            self.pvcreate(pv_name)
            self.vgcreate(vg_name, pv_name)
            self.lvcreate(lv_name, vg_name, lv_size)

        elif partition_type == "physical":
            logging.info("create physical partition...")
            pv_name = self.params.get("pv_name", "/dev/sdb")
            mount_point = pv_name + "1"

            self.part_disk(pv_name, "mbr")
            self.part_list(pv_name)

        self.params["mount_point"] = mount_point
        if with_blocksize == "yes" and fs_type != "btrfs":
            if blocksize:
                self.mkfs_opts(fs_type, mount_point, "blocksize:%s" % (blocksize))
                self.vfs_type(mount_point)
            else:
                logging.error("with_blocksize is set but blocksize not given")
                self.umount_all()
                self.sync()
                return (False, "with_blocksize is set but blocksize not given")
        else:
            self.mkfs(fs_type, mount_point)
            self.vfs_type(mount_point)

        if tarball_path:
            self.mount_options("noatime", mount_point, '/')
            self.tar_in_opts(tarball_path, '/', 'gzip')
            self.ll('/')

        self.umount_all()
        self.sync()
        return (True, "create_fs successfully")

    def create_msdos_part(self, device, start="1", end="-1"):
        """
        Create a msdos partition in given device.
        Default partition section is whole disk(1~-1).
        And return its part name if part add succeed.
        """
        logging.info("Creating a new partition on %s...", device)
        init_result = self.part_init(device, "msdos")
        if init_result.exit_status:
            logging.error("Init disk failed:%s", init_result)
            return (False, init_result)
        add_result = self.part_add(device, "p", start, end)
        if add_result.exit_status:
            logging.error("Add a partition failed:%s", add_result)
            return (False, add_result)

        # Get latest created part num to return
        status, partitions = self.get_partitions_info(device)
        if status is False:
            return (False, partitions)
        part_num = -1
        for partition in partitions.values():
            cur_num = partition.get("num")
            if cur_num > part_num:
                part_num = cur_num

        if part_num == -1:
            return (False, partitions)

        return (True, part_num)

    def create_whole_disk_msdos_part(self, device):
        """
        Create only one msdos partition in given device.
        And return its part name if part add succeed.
        """
        logging.info("Creating one partition of whole %s...", device)
        init_result = self.part_init(device, "msdos")
        if init_result.exit_status:
            logging.error("Init disk failed:%s", init_result)
            return (False, init_result)
        disk_result = self.part_disk(device, "msdos")
        if disk_result.exit_status:
            logging.error("Init disk failed:%s", disk_result)
            return (False, disk_result)

        # Get latest created part num to return
        status, partitions = self.get_partitions_info(device)
        if status is False:
            return (False, partitions)
        part_num = -1
        for partition in partitions.values():
            cur_num = partition.get("num")
            if cur_num > part_num:
                part_num = cur_num

        if part_num == -1:
            return (False, partitions)

        return (True, part_num)

    def get_bootable_part(self, device="/dev/sda"):
        status, partitions = self.get_partitions_info(device)
        if status is False:
            return (False, partitions)
        for partition in partitions.values():
            num = partition.get("num")
            ba_result = self.part_get_bootable(device, num)
            if ba_result.stdout.strip() == "true":
                return (True, "%s%s" % (device, num))
        return (False, partitions)

    def get_mbr_id(self, device="/dev/sda"):
        status, partitions = self.get_partitions_info(device)
        if status is False:
            return (False, partitions)
        for partition in partitions.values():
            num = partition.get("num")
            mbr_id_result = self.part_get_mbr_id(device, num)
            if mbr_id_result.exit_status == 0:
                return (True, mbr_id_result.stdout.strip())
        return (False, partitions)

    def get_part_type(self, device="/dev/sda"):
        part_type_result = self.part_get_parttype(device)
        if part_type_result.exit_status:
            return (False, part_type_result)
        return (True, part_type_result.stdout.strip())

    def get_md5(self, path):
        """
        Get files md5 value.
        """
        logging.info("Computing %s's md5...", path)
        md5_result = self.checksum("md5", path)
        if md5_result.exit_status:
            logging.error("Check %s's md5 failed:%s", path, md5_result)
            return (False, md5_result)
        return (True, md5_result.stdout.strip())

    def reset_interface(self, iface_mac):
        """
        Check interface through guestfish.Fix mac if necessary.
        """
        # disk or domain
        vm_ref = self.params.get("libvirt_domain")
        if not vm_ref:
            vm_ref = self.params.get("disk_img")
            if not vm_ref:
                logging.error("No object to edit.")
                return False
        logging.info("Resetting %s's mac to %s", vm_ref, iface_mac)

        # Fix file which includes interface devices information
        # Default is /etc/udev/rules.d/70-persistent-net.rules
        devices_file = "/etc/udev/rules.d/70-persistent-net.rules"
        # Set file which binds mac and IP-address
        ifcfg_files = ["/etc/sysconfig/network-scripts/ifcfg-p1p1",
                       "/etc/sysconfig/network-scripts/ifcfg-eth0"]
        # Fix devices file
        mac_regex = (r"\w.:\w.:\w.:\w.:\w.:\w.")
        edit_expr = "s/%s/%s/g" % (mac_regex, iface_mac)
        file_ret = self.is_file(devices_file)
        if file_ret.stdout.strip() == "true":
            self.close_session()
            try:
                result = lgf.virt_edit_cmd(vm_ref, devices_file,
                                           expr=edit_expr, debug=True,
                                           ignore_status=True)
                if result.exit_status:
                    logging.error("Edit %s failed:%s", devices_file, result)
                    return False
            except lgf.LibguestfsCmdError, detail:
                logging.error("Edit %s failed:%s", devices_file, detail)
                return False
            self.new_session()
            # Just to keep output looking better
            self.is_ready()
            logging.debug(self.cat(devices_file))

        # Fix interface file
        for ifcfg_file in ifcfg_files:
            file_ret = self.is_file(ifcfg_file)
            if file_ret.stdout.strip() == "false":
                continue
            self.close_session()
            self.params['ifcfg_file'] = ifcfg_file
            try:
                result = lgf.virt_edit_cmd(vm_ref, ifcfg_file,
                                           expr=edit_expr, debug=True,
                                           ignore_status=True)
                if result.exit_status:
                    logging.error("Edit %s failed:%s", ifcfg_file, result)
                    return False
            except lgf.LibguestfsCmdError, detail:
                logging.error("Edit %s failed:%s", ifcfg_file, detail)
                return False
            self.new_session()
            # Just to keep output looking better
            self.is_ready()
            logging.debug(self.cat(ifcfg_file))
        return True

    def copy_ifcfg_back(self):
        # This function must be called after reset_interface()
        ifcfg_file = self.params.get("ifcfg_file")
        bak_file = "%s.bak" % ifcfg_file
        if ifcfg_file:
            self.is_ready()
            is_need = self.is_file(ifcfg_file)
            if is_need.stdout.strip() == "false":
                cp_result = self.cp(bak_file, ifcfg_file)
                if cp_result.exit_status:
                    logging.warn("Recover ifcfg file failed:%s", cp_result)
                    return False
        return True

########NEW FILE########
__FILENAME__ = libvirt
"""
High-level libvirt test utility functions.

This module is meant to reduce code size by performing common test procedures.
Generally, code here should look like test code.

More specifically:
    - Functions in this module should raise exceptions if things go wrong
    - Functions in this module typically use functions and classes from
      lower-level modules (e.g. utils_misc, qemu_vm, aexpect).
    - Functions in this module should not be used by lower-level modules.
    - Functions in this module should be used in the right context.
      For example, a function should not be used where it may display
      misleading or inaccurate info or debug messages.

:copyright: 2014 Red Hat Inc.
"""

import re
import os
import logging
import shutil
import threading
import time
from virttest import virsh
from virttest import xml_utils
from virttest import iscsi
from virttest import nfs
from virttest import data_dir
from virttest import aexpect
from virttest import utils_misc
from virttest import utils_selinux
from virttest import libvirt_storage
from virttest import utils_net
from virttest import gluster
from autotest.client import utils
from autotest.client.shared import error
from virttest.libvirt_xml import vm_xml
from __init__ import ping
try:
    from autotest.client import lv_utils
except ImportError:
    from virttest.staging import lv_utils


def cpus_parser(cpulist):
    """
    Parse a list of cpu list, its syntax is a comma separated list,
    with '-' for ranges and '^' denotes exclusive.
    :param cpulist: a list of physical CPU numbers
    """
    hyphens = []
    carets = []
    commas = []
    others = []

    if cpulist is None:
        return None

    else:
        if "," in cpulist:
            cpulist_list = re.split(",", cpulist)
            for cpulist in cpulist_list:
                if "-" in cpulist:
                    tmp = re.split("-", cpulist)
                    hyphens = hyphens + range(int(tmp[0]), int(tmp[-1]) + 1)
                elif "^" in cpulist:
                    tmp = re.split("\^", cpulist)[-1]
                    carets.append(int(tmp))
                else:
                    try:
                        commas.append(int(cpulist))
                    except ValueError:
                        logging.error("The cpulist has to be an "
                                      "integer. (%s)", cpulist)
        elif "-" in cpulist:
            tmp = re.split("-", cpulist)
            hyphens = range(int(tmp[0]), int(tmp[-1]) + 1)
        elif "^" in cpulist:
            tmp = re.split("^", cpulist)[-1]
            carets.append(int(tmp))
        else:
            try:
                others.append(int(cpulist))
                return others
            except ValueError:
                logging.error("The cpulist has to be an "
                              "integer. (%s)", cpulist)

        cpus_set = set(hyphens).union(set(commas)).difference(set(carets))

        return sorted(list(cpus_set))


def cpus_string_to_affinity_list(cpus_string, num_cpus):
    """
    Parse the cpus_string string to a affinity list.

    e.g
    host_cpu_count = 4
    0       -->     [y,-,-,-]
    0,1     -->     [y,y,-,-]
    0-2     -->     [y,y,y,-]
    0-2,^2  -->     [y,y,-,-]
    r       -->     [y,y,y,y]
    """
    # Check the input string.
    single_pattern = r"\d+"
    between_pattern = r"\d+-\d+"
    exclude_pattern = r"\^\d+"
    sub_pattern = r"(%s)|(%s)|(%s)" % (exclude_pattern,
                                       single_pattern, between_pattern)
    pattern = r"^((%s),)*(%s)$" % (sub_pattern, sub_pattern)
    if not re.match(pattern, cpus_string):
        logging.debug("Cpus_string=%s is not a supported format for cpu_list."
                      % cpus_string)
    # Init a list for result.
    affinity = []
    for i in range(int(num_cpus)):
        affinity.append('-')
    # Letter 'r' means all cpus.
    if cpus_string == "r":
        for i in range(len(affinity)):
            affinity[i] = "y"
        return affinity
    # Split the string with ','.
    sub_cpus = cpus_string.split(",")
    # Parse each sub_cpus.
    for cpus in sub_cpus:
        if "-" in cpus:
            minmum = cpus.split("-")[0]
            maxmum = cpus.split("-")[-1]
            for i in range(int(minmum), int(maxmum) + 1):
                affinity[i] = "y"
        elif "^" in cpus:
            affinity[int(cpus.strip("^"))] = "-"
        else:
            affinity[int(cpus)] = "y"
    return affinity


def cpu_allowed_list_by_task(pid, tid):
    """
    Get the Cpus_allowed_list in status of task.
    """
    cmd = "cat /proc/%s/task/%s/status|grep Cpus_allowed_list:| awk '{print $2}'" % (pid, tid)
    result = utils.run(cmd, ignore_status=True)
    if result.exit_status:
        return None
    return result.stdout.strip()


def clean_up_snapshots(vm_name, snapshot_list=[]):
    """
    Do recovery after snapshot

    :param vm_name: Name of domain
    :param snapshot_list: The list of snapshot name you want to remove
    """
    if not snapshot_list:
        # Get all snapshot names from virsh snapshot-list
        snapshot_list = virsh.snapshot_list(vm_name)

        # Get snapshot disk path
        for snap_name in snapshot_list:
            # Delete useless disk snapshot file if exists
            snap_xml = virsh.snapshot_dumpxml(vm_name,
                                              snap_name).stdout.strip()
            xtf_xml = xml_utils.XMLTreeFile(snap_xml)
            disks_path = xtf_xml.findall('disks/disk/source')
            for disk in disks_path:
                os.system('rm -f %s' % disk.get('file'))
            # Delete snapshots of vm
            virsh.snapshot_delete(vm_name, snap_name)
    else:
        # Get snapshot disk path from domain xml because
        # there is no snapshot info with the name
        dom_xml = vm_xml.VMXML.new_from_dumpxml(vm_name).xmltreefile
        disk_path = dom_xml.find('devices/disk/source').get('file')
        for name in snapshot_list:
            snap_disk_path = disk_path.split(".")[0] + "." + name
            os.system('rm -f %s' % snap_disk_path)


def get_all_cells():
    """
    Use virsh freecell --all to get all cells on host

    ::

        # virsh freecell --all
            0:     124200 KiB
            1:    1059868 KiB
        --------------------
        Total:    1184068 KiB

    That would return a dict like:

    ::

        cell_dict = {"0":"124200 KiB", "1":"1059868 KiB", "Total":"1184068 KiB"}

    :return: cell_dict
    """
    fc_result = virsh.freecell(options="--all", ignore_status=True)
    if fc_result.exit_status:
        if fc_result.stderr.count("NUMA not supported"):
            raise error.TestNAError(fc_result.stderr.strip())
        else:
            raise error.TestFail(fc_result.stderr.strip())
    output = fc_result.stdout.strip()
    cell_list = output.splitlines()
    # remove "------------" line
    del cell_list[-2]
    cell_dict = {}
    for cell_line in cell_list:
        cell_info = cell_line.split(":")
        cell_num = cell_info[0].strip()
        cell_mem = cell_info[-1].strip()
        cell_dict[cell_num] = cell_mem
    return cell_dict


def check_blockjob(vm_name, target, check_point="none", value="0"):
    """
    Run blookjob command to check block job progress, bandwidth, ect.

    :param vm_name: Domain name
    :param target: Domian disk target dev
    :param check_point: Job progrss, bandwidth or none(no job)
    :param value: Value of progress, bandwidth or 0(no job)
    :return: Boolean value, true for pass, false for fail
    """
    if check_point not in ["progress", "bandwidth", "none"]:
        logging.error("Check point must be: progress, bandwidth or none")
        return False

    try:
        cmd_result = virsh.blockjob(vm_name, target, "--info", ignore_status=True)
        output = cmd_result.stdout.strip()
        err = cmd_result.stderr.strip()
        status = cmd_result.exit_status
    except:
        raise error.TestFail("Error occur when running blockjob command.")
    if status == 0:
        # libvirt print job progress to stderr
        if not len(err):
            logging.debug("No block job find")
            if check_point == "none":
                return True
        else:
            if check_point == "none":
                logging.error("Expect no job but find block job:\n%s", err)
            elif check_point == "progress":
                progress = value + " %"
                if re.search(progress, err):
                    return True
            elif check_point == "bandwidth":
                bandwidth = value + " MiB/s"
                if bandwidth == output.split(':')[1].strip():
                    logging.debug("Bandwidth is equal to %s", bandwidth)
                    return True
                else:
                    logging.error("Bandwidth is not equal to %s", bandwidth)
    else:
        logging.error("Run blockjob command fail")
    return False


def setup_or_cleanup_nfs(is_setup, mount_dir="", is_mount=False,
                         export_options="rw,no_root_squash",
                         mount_src="nfs-export"):
    """
    Set up or clean up nfs service on localhost.

    :param is_setup: Boolean value, true for setup, false for cleanup
    :param mount_dir: NFS mount point
    :param is_mount: Boolean value, true for mount, false for umount
    :param export_options: options for nfs dir
    :return: export nfs path or nothing
    """
    tmpdir = os.path.join(data_dir.get_root_dir(), 'tmp')
    if not os.path.isabs(mount_src):
        mount_src = os.path.join(tmpdir, mount_src)
    if not mount_dir:
        mount_dir = os.path.join(tmpdir, 'nfs-mount')

    nfs_params = {"nfs_mount_dir": mount_dir, "nfs_mount_options": "rw",
                  "nfs_mount_src": mount_src, "setup_local_nfs": "yes",
                  "export_options": "rw,no_root_squash"}
    _nfs = nfs.Nfs(nfs_params)
    # Set selinux to permissive that the file in nfs
    # can be used freely
    if utils_misc.selinux_enforcing():
        sv_status = utils_selinux.get_status()
        utils_selinux.set_status("permissive")
    if is_setup:
        _nfs.setup()
        if not is_mount:
            _nfs.umount()
        return mount_src
    else:
        _nfs.unexportfs_in_clean = True
        _nfs.cleanup()
        return ""


def setup_or_cleanup_iscsi(is_setup, is_login=True,
                           emulated_image="emulated_iscsi", image_size="1G"):
    """
    Set up(and login iscsi target) or clean up iscsi service on localhost.

    :param is_setup: Boolean value, true for setup, false for cleanup
    :param is_login: Boolean value, true for login, false for not login
    :param emulated_image: name of iscsi device
    :param image_size: emulated image's size
    :return: iscsi device name or iscsi target
    """
    try:
        utils_misc.find_command("tgtadm")
        utils_misc.find_command("iscsiadm")
    except ValueError:
        raise error.TestNAError("Missing command 'tgtadm' and/or 'iscsiadm'.")

    tmpdir = os.path.join(data_dir.get_root_dir(), 'tmp')
    emulated_path = os.path.join(tmpdir, emulated_image)
    emulated_target = "iqn.2001-01.com.virttest:%s.target" % emulated_image
    iscsi_params = {"emulated_image": emulated_path, "target": emulated_target,
                    "image_size": image_size, "iscsi_thread_id": "virt"}
    _iscsi = iscsi.Iscsi(iscsi_params)
    if is_setup:
        sv_status = None
        if utils_misc.selinux_enforcing():
            sv_status = utils_selinux.get_status()
            utils_selinux.set_status("permissive")
        _iscsi.export_target()
        if sv_status is not None:
            utils_selinux.set_status(sv_status)
        if is_login:
            _iscsi.login()
            # The device doesn't necessarily appear instantaneously, so give
            # about 5 seconds for it to appear before giving up
            iscsi_device = utils_misc.wait_for(_iscsi.get_device_name, 5, 0, 1,
                                               "Searching iscsi device name.")
            if iscsi_device:
                logging.debug("iscsi device: %s", iscsi_device)
                return iscsi_device
            if not iscsi_device:
                logging.error("Not find iscsi device.")
            # Cleanup and return "" - caller needs to handle that
            # _iscsi.export_target() will have set the emulated_id and
            # export_flag already on success...
            _iscsi.cleanup()
            utils.run("rm -f %s" % emulated_path)
        else:
            return emulated_target
    else:
        _iscsi.export_flag = True
        _iscsi.emulated_id = _iscsi.get_target_id()
        _iscsi.cleanup()
        utils.run("rm -f %s" % emulated_path)
    return ""


def get_host_ipv4_addr():
    """
    Get host ipv4 addr
    """
    if_up = utils_net.get_net_if(state="UP")
    for i in if_up:
        ipv4_value = utils_net.get_net_if_addrs(i)["ipv4"]
        logging.debug("ipv4_value is %s", ipv4_value)
        if ipv4_value != []:
            ip_addr = ipv4_value[0]
            break
    if ip_addr is not None:
        logging.info("ipv4 address is %s", ip_addr)
    else:
        raise error.TestFail("Fail to get ip address")
    return ip_addr


def setup_or_cleanup_gluster(is_setup, vol_name, brick_path="", pool_name=""):
    """
    Set up or clean up glusterfs environment on localhost
    :param is_setup: Boolean value, true for setup, false for cleanup
    :param vol_name: gluster created volume name
    :param brick_path: Dir for create glusterfs
    :return: ip_addr or nothing
    """
    if not brick_path:
        tmpdir = os.path.join(data_dir.get_root_dir(), 'tmp')
        brick_path = os.path.join(tmpdir, pool_name)
    if is_setup:
        ip_addr = get_host_ipv4_addr()
        gluster.glusterd_start()
        logging.debug("finish start gluster")
        gluster.gluster_vol_create(vol_name, ip_addr, brick_path)
        logging.debug("finish vol create in gluster")
        return ip_addr
    else:
        gluster.gluster_vol_stop(vol_name, True)
        gluster.gluster_vol_delete(vol_name)
        gluster.gluster_brick_delete(brick_path)
        return ""


def define_pool(pool_name, pool_type, pool_target, cleanup_flag):
    """
    To define a given type pool(Support types: 'dir', 'netfs', logical',
    iscsi', 'disk' and 'fs').

    :param pool_name: Name of the pool
    :param pool_type: Type of the pool
    :param pool_target: Target for underlying storage
    """
    extra = ""
    vg_name = pool_name
    cleanup_nfs = False
    cleanup_iscsi = False
    cleanup_logical = False
    if not os.path.exists(pool_target):
        os.mkdir(pool_target)
    if pool_type == "dir":
        pass
    elif pool_type == "netfs":
        # Set up NFS server without mount
        nfs_path = setup_or_cleanup_nfs(True, pool_target, False)
        cleanup_nfs = True
        extra = "--source-host %s --source-path %s" % ('localhost',
                                                       nfs_path)
    elif pool_type == "logical":
        # Create vg by using iscsi device
        lv_utils.vg_create(vg_name, setup_or_cleanup_iscsi(True))
        cleanup_iscsi = True
        cleanup_logical = True
        extra = "--source-name %s" % vg_name
    elif pool_type == "iscsi":
        # Set up iscsi target without login
        iscsi_target = setup_or_cleanup_iscsi(True, False)
        cleanup_iscsi = True
        extra = "--source-host %s  --source-dev %s" % ('localhost',
                                                       iscsi_target)
    elif pool_type == "disk":
        # Set up iscsi target and login
        device_name = setup_or_cleanup_iscsi(True)
        cleanup_iscsi = True
        # Create a partition to make sure disk pool can start
        cmd = "parted -s %s mklabel msdos" % device_name
        utils.run(cmd)
        cmd = "parted -s %s mkpart primary ext4 0 100" % device_name
        utils.run(cmd)
        extra = "--source-dev %s" % device_name
    elif pool_type == "fs":
        # Set up iscsi target and login
        device_name = setup_or_cleanup_iscsi(True)
        cleanup_iscsi = True
        # Format disk to make sure fs pool can start
        cmd = "mkfs.ext4 -F %s" % device_name
        utils.run(cmd)
        extra = "--source-dev %s" % device_name
    elif pool_type in ["scsi", "mpath", "rbd", "sheepdog"]:
        raise error.TestNAError(
            "Pool type '%s' has not yet been supported in the test." %
            pool_type)
    else:
        raise error.TestFail("Invalid pool type: '%s'." % pool_type)
    # Mark the clean up flags
    cleanup_flag[0] = cleanup_nfs
    cleanup_flag[1] = cleanup_iscsi
    cleanup_flag[2] = cleanup_logical
    try:
        result = virsh.pool_define_as(pool_name, pool_type, pool_target, extra,
                                      ignore_status=True)
    except error.CmdError:
        logging.error("Define '%s' type pool fail.", pool_type)
    return result


def verify_virsh_console(session, user, passwd, timeout=10, debug=False):
    """
    Run commands in console session.
    """
    log = ""
    console_cmd = "cat /proc/cpuinfo"
    try:
        while True:
            match, text = session.read_until_last_line_matches(
                [r"[E|e]scape character is", r"login:",
                 r"[P|p]assword:", session.prompt],
                timeout, internal_timeout=1)

            if match == 0:
                if debug:
                    logging.debug("Got '^]', sending '\\n'")
                session.sendline()
            elif match == 1:
                if debug:
                    logging.debug("Got 'login:', sending '%s'", user)
                session.sendline(user)
            elif match == 2:
                if debug:
                    logging.debug("Got 'Password:', sending '%s'", passwd)
                session.sendline(passwd)
            elif match == 3:
                if debug:
                    logging.debug("Got Shell prompt -- logged in")
                break

        status, output = session.cmd_status_output(console_cmd)
        logging.info("output of command:\n%s", output)
        session.close()
    except (aexpect.ShellError,
            aexpect.ExpectError), detail:
        log = session.get_output()
        logging.error("Verify virsh console failed:\n%s\n%s", detail, log)
        session.close()
        return False

    if not re.search("processor", output):
        logging.error("Verify virsh console failed: Result does not match.")
        return False

    return True


def pci_label_from_address(address_dict, radix=10):
    """
    Generate a pci label from a dict of address.

    :param address_dict: A dict contains domain, bus, slot and function.
    :param radix: The radix of your data in address_dict.

    Example:

    ::

        address_dict = {'domain': '0x0000', 'bus': '0x08', 'slot': '0x10', 'function': '0x0'}
        radix = 16
        return = pci_0000_08_10_0
    """
    if not set(['domain', 'bus', 'slot', 'function']).issubset(
            address_dict.keys()):
        raise error.TestError("Param %s does not contain keys of "
                              "['domain', 'bus', 'slot', 'function']." %
                              str(address_dict))
    domain = int(address_dict['domain'], radix)
    bus = int(address_dict['bus'], radix)
    slot = int(address_dict['slot'], radix)
    function = int(address_dict['function'], radix)
    pci_label = ("pci_%04x_%02x_%02x_%01x" % (domain, bus, slot, function))
    return pci_label


def mk_part(disk, size="100M", session=None):
    """
    Create a partition for disk
    """
    mklabel_cmd = "parted -s %s mklabel msdos" % disk
    mkpart_cmd = "parted -s %s mkpart primary ext4 0 %s" % (disk, size)
    if session:
        session.cmd(mklabel_cmd)
        session.cmd(mkpart_cmd)
    else:
        utils.run(mklabel_cmd)
        utils.run(mkpart_cmd)


def check_actived_pool(pool_name):
    """
    Check if pool_name exist in active pool list
    """
    sp = libvirt_storage.StoragePool()
    if not sp.pool_exists(pool_name):
        raise error.TestFail("Can't find pool %s" % pool_name)
    if not sp.is_pool_active(pool_name):
        raise error.TestFail("Pool %s is not active." % pool_name)
    logging.debug("Find active pool %s", pool_name)
    return True


class PoolVolumeTest(object):

    """Test class for storage pool or volume"""

    def __init__(self, test, params):
        self.tmpdir = test.tmpdir
        self.params = params

    def cleanup_pool(self, pool_name, pool_type, pool_target, emulated_image,
                     source_name=None):
        """
        Delete vols, destroy the created pool and restore the env
        """
        sp = libvirt_storage.StoragePool()
        try:
            if sp.pool_exists(pool_name):
                pv = libvirt_storage.PoolVolume(pool_name)
                if pool_type in ["dir", "netfs", "logical", "disk"]:
                    vols = pv.list_volumes()
                    for vol in vols:
                        # Ignore failed deletion here for deleting pool
                        pv.delete_volume(vol)
                if not sp.delete_pool(pool_name):
                    raise error.TestFail("Delete pool %s failed" % pool_name)
        finally:
            if pool_type == "netfs":
                nfs_server_dir = self.params.get("nfs_server_dir", "nfs-server")
                nfs_path = os.path.join(self.tmpdir, nfs_server_dir)
                setup_or_cleanup_nfs(is_setup=False, mount_dir=nfs_path)
                if os.path.exists(nfs_path):
                    shutil.rmtree(nfs_path)
            if pool_type == "logical":
                cmd = "pvs |grep vg_logical|awk '{print $1}'"
                pv = utils.system_output(cmd)
                # Cleanup logical volume anyway
                utils.run("vgremove -f vg_logical", ignore_status=True)
                utils.run("pvremove %s" % pv, ignore_status=True)
            # These types used iscsi device
            if pool_type in ["logical", "iscsi", "fs", "disk", "scsi"]:
                setup_or_cleanup_iscsi(is_setup=False,
                                       emulated_image=emulated_image)
            if pool_type in ["dir", "fs", "netfs"]:
                pool_target = os.path.join(self.tmpdir, pool_target)
                if os.path.exists(pool_target):
                    shutil.rmtree(pool_target)
            if pool_type == "gluster":
                setup_or_cleanup_gluster(False, source_name)

    def pre_pool(self, pool_name, pool_type, pool_target, emulated_image,
                 image_size="100M", pre_disk_vol=[], source_name=None,
                 source_path=None):
        """
        Preapare the specific type pool

        Note:
            1. For scsi type pool, it only could be created from xml file
            2. Other type pools can be created by pool_creat_as function
            3. Disk pool will not allow to create volume with virsh commands
               So we can prepare it before pool created

        :param pool_name: created pool name
        :param pool_type: dir, disk, logical, fs, netfs or else
        :param pool_target: target of storage pool
        :param emulated_image: use an image file to simulate a scsi disk
                               it could be used for disk, logical pool
        :param image_size: the size for emulated image
        :param pre_disk_vol: a list include partition size to be created
                             no more than 4 partition because msdos label
        """
        extra = ""
        if pool_type == "dir":
            logging.info("Pool path:%s", self.tmpdir)
            pool_target = os.path.join(self.tmpdir, pool_target)
            if not os.path.exists(pool_target):
                os.mkdir(pool_target)
        elif pool_type == "disk":
            device_name = setup_or_cleanup_iscsi(is_setup=True,
                                                 emulated_image=emulated_image,
                                                 image_size=image_size)
            # If pre_vol is None, disk pool will have no volume
            if type(pre_disk_vol) == list and len(pre_disk_vol):
                for vol in pre_disk_vol:
                    mk_part(device_name, vol)
            extra = " --source-dev %s" % device_name
        elif pool_type == "fs":
            device_name = setup_or_cleanup_iscsi(is_setup=True,
                                                 emulated_image=emulated_image,
                                                 image_size=image_size)
            cmd = "mkfs.ext4 -F %s" % device_name
            pool_target = os.path.join(self.tmpdir, pool_target)
            if not os.path.exists(pool_target):
                os.mkdir(pool_target)
            extra = " --source-dev %s" % device_name
            utils.run(cmd)
        elif pool_type == "logical":
            logical_device = setup_or_cleanup_iscsi(is_setup=True,
                                                    emulated_image=emulated_image,
                                                    image_size=image_size)
            cmd_pv = "pvcreate %s" % logical_device
            vg_name = "vg_%s" % pool_type
            cmd_vg = "vgcreate %s %s" % (vg_name, logical_device)
            extra = "--source-name %s" % vg_name
            utils.run(cmd_pv)
            utils.run(cmd_vg)
            # Create a small volume for verification
            # And VG path will not exist if no any volume in.(bug?)
            cmd_lv = "lvcreate --name default_lv --size 1M %s" % vg_name
            utils.run(cmd_lv)
        elif pool_type == "netfs":
            nfs_server_dir = self.params.get("nfs_server_dir", "nfs-server")
            nfs_path = os.path.join(self.tmpdir, nfs_server_dir)
            if not os.path.exists(nfs_path):
                os.mkdir(nfs_path)
            pool_target = os.path.join(self.tmpdir, pool_target)
            if not os.path.exists(pool_target):
                os.mkdir(pool_target)
            setup_or_cleanup_nfs(is_setup=True,
                                 export_options="rw,async,no_root_squash",
                                 mount_src=nfs_path)
            source_host = self.params.get("source_host", "localhost")
            extra = "--source-host %s --source-path %s" % (source_host,
                                                           nfs_path)
        elif pool_type == "iscsi":
            setup_or_cleanup_iscsi(is_setup=True,
                                   emulated_image=emulated_image,
                                   image_size=image_size)
            # Verify if expected iscsi device has been set
            iscsi_sessions = iscsi.iscsi_get_sessions()
            iscsi_target = ()
            for iscsi_node in iscsi_sessions:
                if iscsi_node[1].count(emulated_image):
                    # Remove port for pool operations
                    ip_addr = iscsi_node[0].split(":3260")[0]
                    iscsi_device = (ip_addr, iscsi_node[1])
                    break
            if iscsi_device == ():
                raise error.TestFail("No matched iscsi device.")
            if "::" in iscsi_device[0]:
                iscsi_device = ('localhost', iscsi_device[1])
            extra = " --source-host %s  --source-dev %s" % iscsi_device
        elif pool_type == "scsi":
            scsi_xml_file = self.params.get("scsi_xml_file")
            if not os.path.exists(scsi_xml_file):
                scsi_xml_file = os.path.join(self.tmpdir, scsi_xml_file)
                logical_device = setup_or_cleanup_iscsi(is_setup=True,
                                                        emulated_image=emulated_image,
                                                        image_size=image_size)
                cmd = ("iscsiadm -m session -P 3 |grep -B3 %s| grep Host|awk "
                       "'{print $3}'" % logical_device.split('/')[2])
                scsi_host = utils.system_output(cmd)
                scsi_xml = """
<pool type='scsi'>
  <name>%s</name>
   <source>
    <adapter type='scsi_host' name='host%s'/>
  </source>
  <target>
    <path>/dev/disk/by-path</path>
  </target>
</pool>
""" % (pool_name, scsi_host)
                logging.debug("Prepare the scsi pool xml: %s", scsi_xml)
                xml_object = open(scsi_xml_file, 'w')
                xml_object.write(scsi_xml)
                xml_object.close()
        elif pool_type == "gluster":
            # Prepare gluster service and create volume
            hostip = setup_or_cleanup_gluster(True, source_name,
                                              pool_name=pool_name)
            logging.debug("hostip is %s", hostip)
            cleanup_gluster = True
            extra = "--source-host %s --source-path %s --source-name %s" % \
                    (hostip, source_path, source_name)

        # Create pool
        if pool_type == "scsi":
            re_v = virsh.pool_create(scsi_xml_file)
        else:
            re_v = virsh.pool_create_as(pool_name, pool_type,
                                        pool_target, extra)
        if not re_v:
            raise error.TestFail("Create pool failed.")
        # Check the created pool
        check_actived_pool(pool_name)

    def pre_vol(self, vol_name, vol_format, capacity, allocation, pool_name):
        """
        Preapare the specific type volume in pool
        """
        pv = libvirt_storage.PoolVolume(pool_name)
        if not pv.create_volume(vol_name, capacity, allocation, vol_format):
            raise error.TestFail("Prepare volume failed.")
        if not pv.volume_exists(vol_name):
            raise error.TestFail("Can't find volume: %s", vol_name)


##########Migration Relative functions##############
class MigrationTest(object):

    """Class for migration tests"""

    def __init__(self):
        # To get result in thread, using member parameters
        # Result of virsh migrate command
        # True means command executed successfully
        self.RET_MIGRATION = True
        # A lock for threads
        self.RET_LOCK = threading.RLock()
        # The time spent when migrating vms
        # format: vm_name -> time(seconds)
        self.mig_time = {}

    def thread_func_migration(self, vm, desturi, options=None):
        """
        Thread for virsh migrate command.

        :param vm: A libvirt vm instance(local or remote).
        :param desturi: remote host uri.
        """
        # Migrate the domain.
        try:
            if options is None:
                options = "--live --timeout=60"
            stime = int(time.time())
            vm.migrate(desturi, option=options, ignore_status=False,
                       debug=True)
            etime = int(time.time())
            self.mig_time[vm.name] = etime - stime
        except error.CmdError, detail:
            logging.error("Migration to %s failed:\n%s", desturi, detail)
            self.RET_LOCK.acquire()
            self.RET_MIGRATION = False
            self.RET_LOCK.release()

    def do_migration(self, vms, srcuri, desturi, migration_type, options=None,
                     thread_timeout=60):
        """
        Migrate vms.

        :param vms: migrated vms.
        :param srcuri: local uri, used when migrate vm from remote to local
        :param descuri: remote uri, used when migrate vm from local to remote
        :param migration_type: do orderly for simultaneous migration
        """
        if migration_type == "orderly":
            for vm in vms:
                migration_thread = threading.Thread(target=self.thread_func_migration,
                                                    args=(vm, desturi, options))
                migration_thread.start()
                migration_thread.join(thread_timeout)
                if migration_thread.isAlive():
                    logging.error("Migrate %s timeout.", migration_thread)
                    self.RET_LOCK.acquire()
                    self.RET_MIGRATION = False
                    self.RET_LOCK.release()
        elif migration_type == "cross":
            # Migrate a vm to remote first,
            # then migrate another to remote with the first vm back
            vm_remote = vms.pop()
            self.thread_func_migration(vm_remote, desturi)
            for vm in vms:
                thread1 = threading.Thread(target=self.thread_func_migration,
                                           args=(vm_remote, srcuri, options))
                thread2 = threading.Thread(target=self.thread_func_migration,
                                           args=(vm, desturi, options))
                thread1.start()
                thread2.start()
                thread1.join(thread_timeout)
                thread2.join(thread_timeout)
                vm_remote = vm
                if thread1.isAlive() or thread1.isAlive():
                    logging.error("Cross migrate timeout.")
                    self.RET_LOCK.acquire()
                    self.RET_MIGRATION = False
                    self.RET_LOCK.release()
            # Add popped vm back to list
            vms.append(vm_remote)
        elif migration_type == "simultaneous":
            migration_threads = []
            for vm in vms:
                migration_threads.append(threading.Thread(
                                         target=self.thread_func_migration,
                                         args=(vm, desturi, options)))
            # let all migration going first
            for thread in migration_threads:
                thread.start()

            # listen threads until they end
            for thread in migration_threads:
                thread.join(thread_timeout)
                if thread.isAlive():
                    logging.error("Migrate %s timeout.", thread)
                    self.RET_LOCK.acquire()
                    self.RET_MIGRATION = False
                    self.RET_LOCK.release()

        if not self.RET_MIGRATION:
            raise error.TestFail()

    def cleanup_dest_vm(self, vm, srcuri, desturi):
        """
        Cleanup migrated vm on remote host.
        """
        vm.connect_uri = desturi
        if vm.exists():
            if vm.is_persistent():
                vm.undefine()
            if vm.is_alive():
                # If vm on remote host is unaccessible
                # graceful shutdown may cause confused
                vm.destroy(gracefully=False)
        # Set connect uri back to local uri
        vm.connect_uri = srcuri


def check_exit_status(result, expect_error=False):
    """
    Check the exit status of virsh commands.

    :param result: Virsh command result object
    :param expect_error: Boolean value, expect command success or fail
    """
    if not expect_error:
        if result.exit_status != 0:
            raise error.TestFail(result.stderr)
        else:
            logging.debug("Command output:\n%s", result.stdout.strip())
    elif expect_error and result.exit_status == 0:
        raise error.TestFail("Expect fail, but run successfully.")


def check_iface(iface_name, checkpoint, extra=""):
    """
    Check interface with specified checkpoint.

    :param iface_name: Interface name
    :param checkpoint: Check if interface exists, MAC address, IP address or
                       ping out. Support values: [exists, mac, ip, ping]
    :param extra: Extra string for checking
    :return: Boolean value, true for pass, false for fail
    """
    support_check = ["exists", "mac", "ip", "ping"]
    iface = utils_net.Interface(name=iface_name)
    check_pass = False
    try:
        if checkpoint == "exists":
            # extra is iface-list option
            list_find, ifcfg_find = (False, False)
            # Check virsh list output
            result = virsh.iface_list(extra, ignore_status=True)
            check_exit_status(result, False)
            output = re.findall(r"(\S+)\ +(\S+)\ +(\S+)[\ +\n]",
                                str(result.stdout))
            if filter(lambda x: x[0] == iface_name, output[1:]):
                list_find = True
            logging.debug("Find '%s' in virsh iface-list output: %s",
                          iface_name, list_find)
            # Check network script
            iface_script = "/etc/sysconfig/network-scripts/ifcfg-" + iface_name
            ifcfg_find = os.path.exists(iface_script)
            logging.debug("Find '%s': %s", iface_script, ifcfg_find)
            check_pass = list_find and ifcfg_find
        elif checkpoint == "mac":
            # extra is the MAC address to compare
            iface_mac = iface.get_mac().lower()
            check_pass = iface_mac == extra
            logging.debug("MAC address of %s: %s", iface_name, iface_mac)
        elif checkpoint == "ip":
            # extra is the IP address to compare
            iface_ip = iface.get_ip()
            check_pass = iface_ip == extra
            logging.debug("IP address of %s: %s", iface_name, iface_ip)
        elif checkpoint == "ping":
            # extra is the ping destination
            ping_s, _ = ping(dest=extra, count=3, interface=iface_name,
                             timeout=5,)
            check_pass = ping_s == 0
        else:
            logging.debug("Support check points are: %s", support_check)
            logging.error("Unsupport check point: %s", checkpoint)
    except Exception, detail:
        raise error.TestFail("Interface check failed: %s" % detail)
    return check_pass

########NEW FILE########
__FILENAME__ = qemu
"""
High-level QEMU test utility functions.

This module is meant to reduce code size by performing common test procedures.
Generally, code here should look like test code.

More specifically:
    - Functions in this module should raise exceptions if things go wrong
    - Functions in this module typically use functions and classes from
      lower-level modules (e.g. utils_misc, qemu_vm, aexpect).
    - Functions in this module should not be used by lower-level modules.
    - Functions in this module should be used in the right context.
      For example, a function should not be used where it may display
      misleading or inaccurate info or debug messages.

:copyright: 2008-2013 Red Hat Inc.
"""

import commands
import cPickle
import errno
import fcntl
import logging
import os
import re
import socket
import threading
import time

from autotest.client import utils
from autotest.client.shared import error
from autotest.client.shared.syncdata import SyncData, SyncListenServer

from virttest import env_process, remote, storage, utils_misc

try:
    from virttest.staging import utils_memory
except ImportError:
    from autotest.client.shared import utils_memory


def guest_active(vm):
    o = vm.monitor.info("status")
    if isinstance(o, str):
        return "status: running" in o
    else:
        if "status" in o:
            return o.get("status") == "running"
        else:
            return o.get("running")


def get_numa_status(numa_node_info, qemu_pid, debug=True):
    """
    Get the qemu process memory use status and the cpu list in each node.

    :param numa_node_info: Host numa node information
    :type numa_node_info: NumaInfo object
    :param qemu_pid: process id of qemu
    :type numa_node_info: string
    :param debug: Print the debug info or not
    :type debug: bool
    :return: memory and cpu list in each node
    :rtype: tuple
    """
    node_list = numa_node_info.online_nodes
    qemu_memory = []
    qemu_cpu = []
    cpus = utils_misc.get_pid_cpu(qemu_pid)
    for node_id in node_list:
        qemu_memory_status = utils_memory.read_from_numa_maps(qemu_pid,
                                                              "N%d" % node_id)
        memory = sum([int(_) for _ in qemu_memory_status.values()])
        qemu_memory.append(memory)
        cpu = [_ for _ in cpus if _ in numa_node_info.nodes[node_id].cpus]
        qemu_cpu.append(cpu)
        if debug:
            logging.debug("qemu-kvm process using %s pages and cpu %s in "
                          "node %s" % (memory, " ".join(cpu), node_id))
    return (qemu_memory, qemu_cpu)


def pin_vm_threads(vm, node):
    """
    Pin VM threads to single cpu of a numa node

    :param vm: VM object
    :param node: NumaNode object
    """
    if len(vm.vcpu_threads) + len(vm.vhost_threads) < len(node.cpus):
        for i in vm.vcpu_threads:
            logging.info("pin vcpu thread(%s) to cpu(%s)" % (i, node.pin_cpu(i)))
        for i in vm.vhost_threads:
            logging.info("pin vhost thread(%s) to cpu(%s)" % (i, node.pin_cpu(i)))
    elif (len(vm.vcpu_threads) <= len(node.cpus) and
          len(vm.vhost_threads) <= len(node.cpus)):
        for i in vm.vcpu_threads:
            logging.info("pin vcpu thread(%s) to cpu(%s)" %
                         (i, node.pin_cpu(i)))
        for i in vm.vhost_threads:
            logging.info("pin vhost thread(%s) to extra cpu(%s)" %
                         (i, node.pin_cpu(i, extra=True)))
    else:
        logging.info("Skip pinning, no enough nodes")


def migrate(vm, env=None, mig_timeout=3600, mig_protocol="tcp",
            mig_cancel=False, offline=False, stable_check=False,
            clean=False, save_path=None, dest_host='localhost', mig_port=None):
    """
    Migrate a VM locally and re-register it in the environment.

    :param vm: The VM to migrate.
    :param env: The environment dictionary.  If omitted, the migrated VM will
            not be registered.
    :param mig_timeout: timeout value for migration.
    :param mig_protocol: migration protocol
    :param mig_cancel: Test migrate_cancel or not when protocol is tcp.
    :param dest_host: Destination host (defaults to 'localhost').
    :param mig_port: Port that will be used for migration.
    :return: The post-migration VM, in case of same host migration, True in
            case of multi-host migration.
    """
    def mig_finished():
        try:
            o = vm.monitor.info("migrate")
            if isinstance(o, str):
                return "status: active" not in o
            else:
                return o.get("status") != "active"
        except Exception:
            pass

    def mig_succeeded():
        o = vm.monitor.info("migrate")
        if isinstance(o, str):
            return "status: completed" in o
        else:
            return o.get("status") == "completed"

    def mig_failed():
        o = vm.monitor.info("migrate")
        if isinstance(o, str):
            return "status: failed" in o
        else:
            return o.get("status") == "failed"

    def mig_cancelled():
        o = vm.monitor.info("migrate")
        if isinstance(o, str):
            return ("Migration status: cancelled" in o or
                    "Migration status: canceled" in o)
        else:
            return (o.get("status") == "cancelled" or
                    o.get("status") == "canceled")

    def wait_for_migration():
        if not utils_misc.wait_for(mig_finished, mig_timeout, 2, 2,
                                   "Waiting for migration to finish"):
            raise error.TestFail("Timeout expired while waiting for migration "
                                 "to finish")

    if dest_host == 'localhost':
        dest_vm = vm.clone()

    if (dest_host == 'localhost') and stable_check:
        # Pause the dest vm after creation
        dest_vm.params['extra_params'] = (dest_vm.params.get('extra_params', '')
                                          + ' -S')

    if dest_host == 'localhost':
        dest_vm.create(migration_mode=mig_protocol, mac_source=vm)

    try:
        try:
            if mig_protocol in ["tcp", "rdma", "x-rdma"]:
                if dest_host == 'localhost':
                    uri = mig_protocol + ":0:%d" % dest_vm.migration_port
                else:
                    uri = mig_protocol + ':%s:%d' % (dest_host, mig_port)
            elif mig_protocol == "unix":
                uri = "unix:%s" % dest_vm.migration_file
            elif mig_protocol == "exec":
                uri = '"exec:nc localhost %s"' % dest_vm.migration_port

            if offline:
                vm.pause()
            vm.monitor.migrate(uri)

            if mig_cancel:
                time.sleep(2)
                vm.monitor.cmd("migrate_cancel")
                if not utils_misc.wait_for(mig_cancelled, 60, 2, 2,
                                           "Waiting for migration "
                                           "cancellation"):
                    raise error.TestFail("Failed to cancel migration")
                if offline:
                    vm.resume()
                if dest_host == 'localhost':
                    dest_vm.destroy(gracefully=False)
                return vm
            else:
                wait_for_migration()
                if (dest_host == 'localhost') and stable_check:
                    save_path = None or "/tmp"
                    save1 = os.path.join(save_path, "src")
                    save2 = os.path.join(save_path, "dst")

                    vm.save_to_file(save1)
                    dest_vm.save_to_file(save2)

                    # Fail if we see deltas
                    md5_save1 = utils.hash_file(save1)
                    md5_save2 = utils.hash_file(save2)
                    if md5_save1 != md5_save2:
                        raise error.TestFail("Mismatch of VM state before "
                                             "and after migration")

                if (dest_host == 'localhost') and offline:
                    dest_vm.resume()
        except Exception:
            if dest_host == 'localhost':
                dest_vm.destroy()
            raise

    finally:
        if (dest_host == 'localhost') and stable_check and clean:
            logging.debug("Cleaning the state files")
            if os.path.isfile(save1):
                os.remove(save1)
            if os.path.isfile(save2):
                os.remove(save2)

    # Report migration status
    if mig_succeeded():
        logging.info("Migration finished successfully")
    elif mig_failed():
        raise error.TestFail("Migration failed")
    else:
        status = vm.monitor.info("migrate")
        raise error.TestFail("Migration ended with unknown status: %s" %
                             status)

    if dest_host == 'localhost':
        if dest_vm.monitor.verify_status("paused"):
            logging.debug("Destination VM is paused, resuming it")
            dest_vm.resume()

    # Kill the source VM
    vm.destroy(gracefully=False)

    # Replace the source VM with the new cloned VM
    if (dest_host == 'localhost') and (env is not None):
        env.register_vm(vm.name, dest_vm)

    # Return the new cloned VM
    if dest_host == 'localhost':
        return dest_vm
    else:
        return vm


class MigrationData(object):

    def __init__(self, params, srchost, dsthost, vms_name, params_append):
        """
        Class that contains data needed for one migration.
        """
        self.params = params.copy()
        self.params.update(params_append)

        self.source = False
        if params.get("hostid") == srchost:
            self.source = True

        self.destination = False
        if params.get("hostid") == dsthost:
            self.destination = True

        self.src = srchost
        self.dst = dsthost
        self.hosts = [srchost, dsthost]
        self.mig_id = {'src': srchost, 'dst': dsthost, "vms": vms_name}
        self.vms_name = vms_name
        self.vms = []
        self.vm_ports = None

    def is_src(self):
        """
        :return: True if host is source.
        """
        return self.source

    def is_dst(self):
        """
        :return: True if host is destination.
        """
        return self.destination


class MultihostMigration(object):

    """
    Class that provides a framework for multi-host migration.

    Migration can be run both synchronously and asynchronously.
    To specify what is going to happen during the multi-host
    migration, it is necessary to reimplement the method
    migration_scenario. It is possible to start multiple migrations
    in separate threads, since self.migrate is thread safe.

    Only one test using multihost migration framework should be
    started on one machine otherwise it is necessary to solve the
    problem with listen server port.

    Multihost migration starts SyncListenServer through which
    all messages are transferred, since the multiple hosts can
    be in different states.

    Class SyncData is used to transfer data over network or
    synchronize the migration process. Synchronization sessions
    are recognized by session_id.

    It is important to note that, in order to have multi-host
    migration, one needs shared guest image storage. The simplest
    case is when the guest images are on an NFS server.

    Example:

    ::

        class TestMultihostMigration(utils_misc.MultihostMigration):
            def __init__(self, test, params, env):
                super(testMultihostMigration, self).__init__(test, params, env)

            def migration_scenario(self):
                srchost = self.params.get("hosts")[0]
                dsthost = self.params.get("hosts")[1]

                def worker(mig_data):
                    vm = env.get_vm("vm1")
                    session = vm.wait_for_login(timeout=self.login_timeout)
                    session.sendline("nohup dd if=/dev/zero of=/dev/null &")
                    session.cmd("killall -0 dd")

                def check_worker(mig_data):
                    vm = env.get_vm("vm1")
                    session = vm.wait_for_login(timeout=self.login_timeout)
                    session.cmd("killall -9 dd")

                # Almost synchronized migration, waiting to end it.
                # Work is started only on first VM.
                self.migrate_wait(["vm1", "vm2"], srchost, dsthost,
                                  worker, check_worker)

                # Migration started in different threads.
                # It allows to start multiple migrations simultaneously.
                mig1 = self.migrate(["vm1"], srchost, dsthost,
                                    worker, check_worker)
                mig2 = self.migrate(["vm2"], srchost, dsthost)
                mig2.join()
                mig1.join()

        mig = TestMultihostMigration(test, params, env)
        mig.run()
    """

    def __init__(self, test, params, env, preprocess_env=True):
        self.test = test
        self.params = params
        self.env = env
        self.hosts = params.get("hosts")
        self.hostid = params.get('hostid', "")
        self.comm_port = int(params.get("comm_port", 13234))
        vms_count = len(params["vms"].split())

        self.login_timeout = int(params.get("login_timeout", 360))
        self.disk_prepare_timeout = int(params.get("disk_prepare_timeout",
                                                   160 * vms_count))
        self.finish_timeout = int(params.get("finish_timeout",
                                             120 * vms_count))

        self.new_params = None

        if params.get("clone_master") == "yes":
            self.clone_master = True
        else:
            self.clone_master = False

        self.mig_timeout = int(params.get("mig_timeout"))
        # Port used to communicate info between source and destination
        self.regain_ip_cmd = params.get("regain_ip_cmd", None)
        self.not_login_after_mig = params.get("not_login_after_mig", None)

        self.vm_lock = threading.Lock()

        self.sync_server = None
        if self.clone_master:
            self.sync_server = SyncListenServer()

        if preprocess_env:
            self.preprocess_env()
            self._hosts_barrier(self.hosts, self.hosts, 'disk_prepared',
                                self.disk_prepare_timeout)

    def migration_scenario(self):
        """
        Multi Host migration_scenario is started from method run where the
        exceptions are checked. It is not necessary to take care of
        cleaning up after test crash or finish.
        """
        raise NotImplementedError

    def post_migration(self, vm, cancel_delay, mig_offline, dsthost, vm_ports,
                       not_wait_for_migration, fd, mig_data):
        pass

    def migrate_vms_src(self, mig_data):
        """
        Migrate vms source.

        :param mig_Data: Data for migration.

        For change way how machine migrates is necessary
        re implement this method.
        """
        def mig_wrapper(vm, cancel_delay, dsthost, vm_ports,
                        not_wait_for_migration, mig_offline, mig_data):
            vm.migrate(cancel_delay=cancel_delay, offline=mig_offline,
                       dest_host=dsthost, remote_port=vm_ports[vm.name],
                       not_wait_for_migration=not_wait_for_migration)

            self.post_migration(vm, cancel_delay, mig_offline, dsthost,
                                vm_ports, not_wait_for_migration, None,
                                mig_data)

        logging.info("Start migrating now...")
        cancel_delay = mig_data.params.get("cancel_delay")
        if cancel_delay is not None:
            cancel_delay = int(cancel_delay)
        not_wait_for_migration = mig_data.params.get("not_wait_for_migration")
        if not_wait_for_migration == "yes":
            not_wait_for_migration = True
        mig_offline = mig_data.params.get("mig_offline")
        if mig_offline == "yes":
            mig_offline = True
        else:
            mig_offline = False

        multi_mig = []
        for vm in mig_data.vms:
            multi_mig.append((mig_wrapper, (vm, cancel_delay, mig_data.dst,
                                            mig_data.vm_ports,
                                            not_wait_for_migration,
                                            mig_offline, mig_data)))
        utils_misc.parallel(multi_mig)

    def migrate_vms_dest(self, mig_data):
        """
        Migrate vms destination. This function is started on dest host during
        migration.

        :param mig_Data: Data for migration.
        """
        pass

    def __del__(self):
        if self.sync_server:
            self.sync_server.close()

    def master_id(self):
        return self.hosts[0]

    def _hosts_barrier(self, hosts, session_id, tag, timeout):
        logging.debug("Barrier timeout: %d tags: %s" % (timeout, tag))
        tags = SyncData(self.master_id(), self.hostid, hosts,
                        "%s,%s,barrier" % (str(session_id), tag),
                        self.sync_server).sync(tag, timeout)
        logging.debug("Barrier tag %s" % (tags))

    def preprocess_env(self):
        """
        Prepare env to start vms.
        """
        storage.preprocess_images(self.test.bindir, self.params, self.env)

    def _check_vms_source(self, mig_data):
        start_mig_tout = mig_data.params.get("start_migration_timeout", None)
        if start_mig_tout is None:
            for vm in mig_data.vms:
                vm.wait_for_login(timeout=self.login_timeout)

        if mig_data.params.get("host_mig_offline") != "yes":
            sync = SyncData(self.master_id(), self.hostid, mig_data.hosts,
                            mig_data.mig_id, self.sync_server)
            mig_data.vm_ports = sync.sync(timeout=240)[mig_data.dst]
            logging.info("Received from destination the migration port %s",
                         str(mig_data.vm_ports))

    def _check_vms_dest(self, mig_data):
        mig_data.vm_ports = {}
        for vm in mig_data.vms:
            logging.info("Communicating to source migration port %s",
                         vm.migration_port)
            mig_data.vm_ports[vm.name] = vm.migration_port

        if mig_data.params.get("host_mig_offline") != "yes":
            SyncData(self.master_id(), self.hostid,
                     mig_data.hosts, mig_data.mig_id,
                     self.sync_server).sync(mig_data.vm_ports, timeout=240)

    def _prepare_params(self, mig_data):
        """
        Prepare separate params for vm migration.

        :param vms_name: List of vms.
        """
        new_params = mig_data.params.copy()
        new_params["vms"] = " ".join(mig_data.vms_name)
        return new_params

    def _check_vms(self, mig_data):
        """
        Check if vms are started correctly.

        :param vms: list of vms.
        :param source: Must be True if is source machine.
        """
        if mig_data.is_src():
            self._check_vms_source(mig_data)
        else:
            self._check_vms_dest(mig_data)

    def _quick_check_vms(self, mig_data):
        """
        Check if vms are started correctly.

        :param vms: list of vms.
        :param source: Must be True if is source machine.
        """
        logging.info("Try check vms %s" % (mig_data.vms_name))
        for vm in mig_data.vms_name:
            if self.env.get_vm(vm) not in mig_data.vms:
                mig_data.vms.append(self.env.get_vm(vm))
        for vm in mig_data.vms:
            logging.info("Check vm %s on host %s" % (vm.name, self.hostid))
            vm.verify_alive()

    def prepare_for_migration(self, mig_data, migration_mode):
        """
        Prepare destination of migration for migration.

        :param mig_data: Class with data necessary for migration.
        :param migration_mode: Migration mode for prepare machine.
        """
        new_params = self._prepare_params(mig_data)

        new_params['migration_mode'] = migration_mode
        new_params['start_vm'] = 'yes'

        if self.params.get("migration_sync_vms", "no") == "yes":
            if mig_data.is_src():
                self.vm_lock.acquire()
                env_process.process(self.test, new_params, self.env,
                                    env_process.preprocess_image,
                                    env_process.preprocess_vm)
                self.vm_lock.release()
                self._quick_check_vms(mig_data)

                # Send vms configuration to dst host.
                vms = cPickle.dumps([self.env.get_vm(vm_name)
                                     for vm_name in mig_data.vms_name])

                self.env.get_vm(mig_data.vms_name[0]).monitor.info("qtree")
                SyncData(self.master_id(), self.hostid,
                         mig_data.hosts, mig_data.mig_id,
                         self.sync_server).sync(vms, timeout=240)
            elif mig_data.is_dst():
                # Load vms configuration from src host.
                vms = cPickle.loads(SyncData(self.master_id(), self.hostid,
                                             mig_data.hosts, mig_data.mig_id,
                                             self.sync_server).sync(timeout=240)[mig_data.src])
                for vm in vms:
                    # Save config to env. Used for create machine.
                    # When reuse_previous_config params is set don't check
                    # machine.
                    vm.address_cache = self.env.get("address_cache")
                    self.env.register_vm(vm.name, vm)

                self.vm_lock.acquire()
                env_process.process(self.test, new_params, self.env,
                                    env_process.preprocess_image,
                                    env_process.preprocess_vm)
                vms[0].monitor.info("qtree")
                self.vm_lock.release()
                self._quick_check_vms(mig_data)
        else:
            self.vm_lock.acquire()
            env_process.process(self.test, new_params, self.env,
                                env_process.preprocess_image,
                                env_process.preprocess_vm)
            self.vm_lock.release()
            self._quick_check_vms(mig_data)

        self._check_vms(mig_data)

    def migrate_vms(self, mig_data):
        """
        Migrate vms.
        """
        if mig_data.is_src():
            self.migrate_vms_src(mig_data)
        else:
            self.migrate_vms_dest(mig_data)

    def check_vms_dst(self, mig_data):
        """
        Check vms after migrate.

        :param mig_data: object with migration data.
        """
        for vm in mig_data.vms:
            vm.resume()
            if not guest_active(vm):
                raise error.TestFail("Guest not active after migration")

        logging.info("Migrated guest appears to be running")

        logging.info("Logging into migrated guest after migration...")
        for vm in mig_data.vms:
            if self.regain_ip_cmd is not None:
                session_serial = vm.wait_for_serial_login(timeout=self.login_timeout)
                # There is sometime happen that system sends some message on
                # serial console and IP renew command block test. Because
                # there must be added "sleep" in IP renew command.
                session_serial.cmd(self.regain_ip_cmd)

            if not self.not_login_after_mig:
                vm.wait_for_login(timeout=self.login_timeout)

    def check_vms_src(self, mig_data):
        """
        Check vms after migrate.

        :param mig_data: object with migration data.
        """
        pass

    def postprocess_env(self):
        """
        Kill vms and delete cloned images.
        """
        pass

    def before_migration(self, mig_data):
        """
        Do something right before migration.

        :param mig_data: object with migration data.
        """
        pass

    def migrate(self, vms_name, srchost, dsthost, start_work=None,
                check_work=None, mig_mode="tcp", params_append=None):
        """
        Migrate machine from srchost to dsthost. It executes start_work on
        source machine before migration and executes check_work on dsthost
        after migration.

        Migration execution progress:

        ::

            source host                   |   dest host
            --------------------------------------------------------
               prepare guest on both sides of migration
                - start machine and check if machine works
                - synchronize transfer data needed for migration
            --------------------------------------------------------
            start work on source guests   |   wait for migration
            --------------------------------------------------------
                         migrate guest to dest host.
                  wait on finish migration synchronization
            --------------------------------------------------------
                                          |   check work on vms
            --------------------------------------------------------
                        wait for sync on finish migration

        :param vms_name: List of vms.
        :param srchost: src host id.
        :param dsthost: dst host id.
        :param start_work: Function started before migration.
        :param check_work: Function started after migration.
        :param mig_mode: Migration mode.
        :param params_append: Append params to self.params only for migration.
        """
        def migrate_wrap(vms_name, srchost, dsthost, start_work=None,
                         check_work=None, params_append=None):
            logging.info("Starting migrate vms %s from host %s to %s" %
                         (vms_name, srchost, dsthost))
            pause = self.params.get("paused_after_start_vm")
            mig_error = None
            mig_data = MigrationData(self.params, srchost, dsthost,
                                     vms_name, params_append)
            cancel_delay = self.params.get("cancel_delay", None)
            host_offline_migration = self.params.get("host_mig_offline")

            try:
                try:
                    if mig_data.is_src():
                        self.prepare_for_migration(mig_data, None)
                    elif self.hostid == dsthost:
                        if host_offline_migration != "yes":
                            self.prepare_for_migration(mig_data, mig_mode)
                    else:
                        return

                    if mig_data.is_src():
                        if start_work:
                            if pause != "yes":
                                start_work(mig_data)
                            else:
                                raise error.TestNAError("Can't start work if "
                                                        "vm is paused.")

                    # Starts VM and waits timeout before migration.
                    if pause == "yes" and mig_data.is_src():
                        for vm in mig_data.vms:
                            vm.resume()
                        wait = self.params.get("start_migration_timeout", 0)
                        logging.debug("Wait for migraiton %s seconds." %
                                      (wait))
                        time.sleep(int(wait))

                    self.before_migration(mig_data)

                    self.migrate_vms(mig_data)

                    timeout = 60
                    if cancel_delay is None:
                        if host_offline_migration == "yes":
                            self._hosts_barrier(self.hosts,
                                                mig_data.mig_id,
                                                'wait_for_offline_mig',
                                                self.finish_timeout)
                            if mig_data.is_dst():
                                self.prepare_for_migration(mig_data, mig_mode)
                            self._hosts_barrier(self.hosts,
                                                mig_data.mig_id,
                                                'wait2_for_offline_mig',
                                                self.finish_timeout)

                        if (not mig_data.is_src()):
                            timeout = self.mig_timeout
                        self._hosts_barrier(mig_data.hosts, mig_data.mig_id,
                                            'mig_finished', timeout)

                        if mig_data.is_dst():
                            self.check_vms_dst(mig_data)
                            if check_work:
                                check_work(mig_data)
                        else:
                            self.check_vms_src(mig_data)
                            if check_work:
                                check_work(mig_data)
                except:
                    mig_error = True
                    raise
            finally:
                if mig_error and cancel_delay is not None:
                    self._hosts_barrier(self.hosts,
                                        mig_data.mig_id,
                                        'test_finihed',
                                        self.finish_timeout)
                elif mig_error:
                    raise

        def wait_wrap(vms_name, srchost, dsthost):
            mig_data = MigrationData(self.params, srchost, dsthost, vms_name,
                                     None)
            timeout = (self.login_timeout + self.mig_timeout +
                       self.finish_timeout)

            self._hosts_barrier(self.hosts, mig_data.mig_id,
                                'test_finihed', timeout)

        if (self.hostid in [srchost, dsthost]):
            mig_thread = utils.InterruptedThread(migrate_wrap, (vms_name,
                                                                srchost,
                                                                dsthost,
                                                                start_work,
                                                                check_work,
                                                                params_append))
        else:
            mig_thread = utils.InterruptedThread(wait_wrap, (vms_name,
                                                             srchost,
                                                             dsthost))
        mig_thread.start()
        return mig_thread

    def migrate_wait(self, vms_name, srchost, dsthost, start_work=None,
                     check_work=None, mig_mode="tcp", params_append=None):
        """
        Migrate machine from srchost to dsthost and wait for finish.
        It executes start_work on source machine before migration and executes
        check_work on dsthost after migration.

        :param vms_name: List of vms.
        :param srchost: src host id.
        :param dsthost: dst host id.
        :param start_work: Function which is started before migration.
        :param check_work: Function which is started after
                           done of migration.
        """
        self.migrate(vms_name, srchost, dsthost, start_work, check_work,
                     mig_mode, params_append).join()

    def cleanup(self):
        """
        Cleanup env after test.
        """
        if self.clone_master:
            self.sync_server.close()
            self.postprocess_env()

    def run(self):
        """
        Start multihost migration scenario.
        After scenario is finished or if scenario crashed it calls postprocess
        machines and cleanup env.
        """
        try:
            self.migration_scenario()

            self._hosts_barrier(self.hosts, self.hosts, 'all_test_finihed',
                                self.finish_timeout)
        finally:
            self.cleanup()


class MultihostMigrationFd(MultihostMigration):

    def __init__(self, test, params, env, preprocess_env=True):
        super(MultihostMigrationFd, self).__init__(test, params, env,
                                                   preprocess_env)

    def migrate_vms_src(self, mig_data):
        """
        Migrate vms source.

        :param mig_Data: Data for migration.

        For change way how machine migrates is necessary
        re implement this method.
        """
        def mig_wrapper(vm, cancel_delay, mig_offline, dsthost, vm_ports,
                        not_wait_for_migration, fd):
            vm.migrate(cancel_delay=cancel_delay, offline=mig_offline,
                       dest_host=dsthost,
                       not_wait_for_migration=not_wait_for_migration,
                       protocol="fd",
                       fd_src=fd)

            self.post_migration(vm, cancel_delay, mig_offline, dsthost,
                                vm_ports, not_wait_for_migration, fd, mig_data)

        logging.info("Start migrating now...")
        cancel_delay = mig_data.params.get("cancel_delay")
        if cancel_delay is not None:
            cancel_delay = int(cancel_delay)
        not_wait_for_migration = mig_data.params.get("not_wait_for_migration")
        if not_wait_for_migration == "yes":
            not_wait_for_migration = True
        mig_offline = mig_data.params.get("mig_offline")
        if mig_offline == "yes":
            mig_offline = True
        else:
            mig_offline = False

        multi_mig = []
        for vm in mig_data.vms:
            fd = vm.params.get("migration_fd")
            multi_mig.append((mig_wrapper, (vm, cancel_delay, mig_offline,
                                            mig_data.dst, mig_data.vm_ports,
                                            not_wait_for_migration,
                                            fd)))
        utils_misc.parallel(multi_mig)

    def _check_vms_source(self, mig_data):
        start_mig_tout = mig_data.params.get("start_migration_timeout", None)
        if start_mig_tout is None:
            for vm in mig_data.vms:
                vm.wait_for_login(timeout=self.login_timeout)
        self._hosts_barrier(mig_data.hosts, mig_data.mig_id,
                            'prepare_VMS', 60)

    def _check_vms_dest(self, mig_data):
        self._hosts_barrier(mig_data.hosts, mig_data.mig_id,
                            'prepare_VMS', 120)
        for vm in mig_data.vms:
            fd = vm.params.get("migration_fd")
            os.close(fd)

    def _connect_to_server(self, host, port, timeout=60):
        """
        Connect to network server.
        """
        endtime = time.time() + timeout
        sock = None
        while endtime > time.time():
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            try:
                sock.connect((host, port))
                break
            except socket.error, err:
                (code, _) = err
                if (code != errno.ECONNREFUSED):
                    raise
                time.sleep(1)

        return sock

    def _create_server(self, port, timeout=60):
        """
        Create network server.
        """
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        sock.settimeout(timeout)
        sock.bind(('', port))
        sock.listen(1)
        return sock

    def migrate_wait(self, vms_name, srchost, dsthost, start_work=None,
                     check_work=None, mig_mode="fd", params_append=None):
        vms_count = len(vms_name)
        mig_ports = []

        if self.params.get("hostid") == srchost:
            last_port = 5199
            for _ in range(vms_count):
                last_port = utils_misc.find_free_port(last_port + 1, 6000)
                mig_ports.append(last_port)

        sync = SyncData(self.master_id(), self.hostid,
                        self.params.get("hosts"),
                        {'src': srchost, 'dst': dsthost,
                         'port': "ports"}, self.sync_server)

        mig_ports = sync.sync(mig_ports, timeout=120)
        mig_ports = mig_ports[srchost]
        logging.debug("Migration port %s" % (mig_ports))

        if self.params.get("hostid") != srchost:
            sockets = []
            for mig_port in mig_ports:
                sockets.append(self._connect_to_server(srchost, mig_port))
            try:
                fds = {}
                for s, vm_name in zip(sockets, vms_name):
                    fds["migration_fd_%s" % vm_name] = s.fileno()
                logging.debug("File descrtiptors %s used for"
                              " migration." % (fds))

                super_cls = super(MultihostMigrationFd, self)
                super_cls.migrate_wait(vms_name, srchost, dsthost,
                                       start_work=start_work, mig_mode="fd",
                                       params_append=fds)
            finally:
                for s in sockets:
                    s.close()
        else:
            sockets = []
            for mig_port in mig_ports:
                sockets.append(self._create_server(mig_port))
            try:
                conns = []
                for s in sockets:
                    conns.append(s.accept()[0])
                fds = {}
                for conn, vm_name in zip(conns, vms_name):
                    fds["migration_fd_%s" % vm_name] = conn.fileno()
                logging.debug("File descrtiptors %s used for"
                              " migration." % (fds))

                # Prohibits descriptor inheritance.
                for fd in fds.values():
                    flags = fcntl.fcntl(fd, fcntl.F_GETFD)
                    flags |= fcntl.FD_CLOEXEC
                    fcntl.fcntl(fd, fcntl.F_SETFD, flags)

                super_cls = super(MultihostMigrationFd, self)
                super_cls.migrate_wait(vms_name, srchost, dsthost,
                                       start_work=start_work, mig_mode="fd",
                                       params_append=fds)
                for conn in conns:
                    conn.close()
            finally:
                for s in sockets:
                    s.close()


class MultihostMigrationExec(MultihostMigration):

    def __init__(self, test, params, env, preprocess_env=True):
        super(MultihostMigrationExec, self).__init__(test, params, env,
                                                     preprocess_env)

    def post_migration(self, vm, cancel_delay, mig_offline, dsthost,
                       mig_exec_cmd, not_wait_for_migration, fd,
                       mig_data):
        if mig_data.params.get("host_mig_offline") == "yes":
            src_tmp = vm.params.get("migration_sfiles_path")
            dst_tmp = vm.params.get("migration_dfiles_path")
            username = vm.params.get("username")
            password = vm.params.get("password")
            remote.scp_to_remote(dsthost, "22", username, password,
                                 src_tmp, dst_tmp)

    def migrate_vms_src(self, mig_data):
        """
        Migrate vms source.

        :param mig_Data: Data for migration.

        For change way how machine migrates is necessary
        re implement this method.
        """
        def mig_wrapper(vm, cancel_delay, mig_offline, dsthost, mig_exec_cmd,
                        not_wait_for_migration, mig_data):
            vm.migrate(cancel_delay=cancel_delay,
                       offline=mig_offline,
                       dest_host=dsthost,
                       not_wait_for_migration=not_wait_for_migration,
                       protocol="exec",
                       migration_exec_cmd_src=mig_exec_cmd)

            self.post_migration(vm, cancel_delay, mig_offline,
                                dsthost, mig_exec_cmd,
                                not_wait_for_migration, None, mig_data)

        logging.info("Start migrating now...")
        cancel_delay = mig_data.params.get("cancel_delay")
        if cancel_delay is not None:
            cancel_delay = int(cancel_delay)
        not_wait_for_migration = mig_data.params.get("not_wait_for_migration")
        if not_wait_for_migration == "yes":
            not_wait_for_migration = True
        mig_offline = mig_data.params.get("mig_offline")
        if mig_offline == "yes":
            mig_offline = True
        else:
            mig_offline = False

        multi_mig = []
        for vm in mig_data.vms:
            mig_exec_cmd = vm.params.get("migration_exec_cmd_src")
            multi_mig.append((mig_wrapper, (vm, cancel_delay,
                                            mig_offline,
                                            mig_data.dst,
                                            mig_exec_cmd,
                                            not_wait_for_migration,
                                            mig_data)))
        utils_misc.parallel(multi_mig)

    def _check_vms_source(self, mig_data):
        start_mig_tout = mig_data.params.get("start_migration_timeout", None)
        if start_mig_tout is None:
            for vm in mig_data.vms:
                vm.wait_for_login(timeout=self.login_timeout)

        if mig_data.params.get("host_mig_offline") != "yes":
            self._hosts_barrier(mig_data.hosts, mig_data.mig_id,
                                'prepare_VMS', 60)

    def _check_vms_dest(self, mig_data):
        if mig_data.params.get("host_mig_offline") != "yes":
            self._hosts_barrier(mig_data.hosts, mig_data.mig_id,
                                'prepare_VMS', 120)

    def migrate_wait(self, vms_name, srchost, dsthost, start_work=None,
                     check_work=None, mig_mode="exec", params_append=None):
        vms_count = len(vms_name)
        mig_ports = []

        host_offline_migration = self.params.get("host_mig_offline")

        sync = SyncData(self.master_id(), self.hostid,
                        self.params.get("hosts"),
                        {'src': srchost, 'dst': dsthost,
                         'port': "ports"}, self.sync_server)

        mig_params = {}

        if host_offline_migration != "yes":
            if self.params.get("hostid") == dsthost:
                last_port = 5199
                for _ in range(vms_count):
                    last_port = utils_misc.find_free_port(last_port + 1, 6000)
                    mig_ports.append(last_port)

            mig_ports = sync.sync(mig_ports, timeout=120)
            mig_ports = mig_ports[dsthost]
            logging.debug("Migration port %s" % (mig_ports))
            mig_cmds = {}
            for mig_port, vm_name in zip(mig_ports, vms_name):
                mig_dst_cmd = "nc -l %s %s" % (dsthost, mig_port)
                mig_src_cmd = "nc %s %s" % (dsthost, mig_port)
                mig_params["migration_exec_cmd_src_%s" %
                           (vm_name)] = mig_src_cmd
                mig_params["migration_exec_cmd_dst_%s" %
                           (vm_name)] = mig_dst_cmd
        else:
            # Generate filenames for migration.
            mig_fnam = {}
            for vm_name in vms_name:
                while True:
                    fnam = ("mig_" + utils.generate_random_string(6) +
                            "." + vm_name)
                    fpath = os.path.join(self.test.tmpdir, fnam)
                    if (fnam not in mig_fnam.values() and
                            not os.path.exists(fnam)):
                        mig_fnam[vm_name] = fpath
                        break
            mig_fs = sync.sync(mig_fnam, timeout=120)
            mig_cmds = {}
            # Prepare cmd and files.
            if self.params.get("hostid") == srchost:
                mig_src_cmd = "gzip -c > %s"
                for vm_name in vms_name:
                    mig_params["migration_sfiles_path_%s" % (vm_name)] = (
                        mig_fs[srchost][vm_name])
                    mig_params["migration_dfiles_path_%s" % (vm_name)] = (
                        mig_fs[dsthost][vm_name])

                    mig_params["migration_exec_cmd_src_%s" % (vm_name)] = (
                        mig_src_cmd % mig_fs[srchost][vm_name])

            if self.params.get("hostid") == dsthost:
                mig_dst_cmd = "gzip -c -d %s"
                for vm_name in vms_name:
                    mig_params["migration_exec_cmd_dst_%s" % (vm_name)] = (
                        mig_dst_cmd % mig_fs[dsthost][vm_name])

        logging.debug("Exec commands %s", mig_cmds)

        super_cls = super(MultihostMigrationExec, self)
        super_cls.migrate_wait(vms_name, srchost, dsthost,
                               start_work=start_work, mig_mode=mig_mode,
                               params_append=mig_params)


class GuestSuspend(object):

    """
    Suspend guest, supports both Linux and Windows.

    """
    SUSPEND_TYPE_MEM = "mem"
    SUSPEND_TYPE_DISK = "disk"

    def __init__(self, params, vm):
        if not params or not vm:
            raise error.TestError("Missing 'params' or 'vm' parameters")

        self._open_session_list = []
        self.vm = vm
        self.params = params
        self.login_timeout = float(self.params.get("login_timeout", 360))
        self.services_up_timeout = float(self.params.get("services_up_timeout",
                                                         30))
        self.os_type = self.params.get("os_type")

    def _get_session(self):
        self.vm.verify_alive()
        session = self.vm.wait_for_login(timeout=self.login_timeout)
        return session

    def _session_cmd_close(self, session, cmd):
        try:
            return session.cmd_status_output(cmd)
        finally:
            try:
                session.close()
            except Exception:
                pass

    def _cleanup_open_session(self):
        try:
            for s in self._open_session_list:
                if s:
                    s.close()
        except Exception:
            pass

    @error.context_aware
    def setup_bg_program(self, **args):
        """
        Start up a program as a flag in guest.
        """
        suspend_bg_program_setup_cmd = args.get("suspend_bg_program_setup_cmd")

        error.context("Run a background program as a flag", logging.info)
        session = self._get_session()
        self._open_session_list.append(session)

        logging.debug("Waiting all services in guest are fully started.")
        time.sleep(self.services_up_timeout)

        session.sendline(suspend_bg_program_setup_cmd)

    @error.context_aware
    def check_bg_program(self, **args):
        """
        Make sure the background program is running as expected
        """
        suspend_bg_program_chk_cmd = args.get("suspend_bg_program_chk_cmd")

        error.context("Verify background program is running", logging.info)
        session = self._get_session()
        s, _ = self._session_cmd_close(session, suspend_bg_program_chk_cmd)
        if s:
            raise error.TestFail("Background program is dead. Suspend failed.")

    @error.context_aware
    def kill_bg_program(self, **args):
        error.context("Kill background program after resume")
        suspend_bg_program_kill_cmd = args.get("suspend_bg_program_kill_cmd")

        try:
            session = self._get_session()
            self._session_cmd_close(session, suspend_bg_program_kill_cmd)
        except Exception, e:
            logging.warn("Could not stop background program: '%s'", e)
            pass

    @error.context_aware
    def _check_guest_suspend_log(self, **args):
        error.context("Check whether guest supports suspend",
                      logging.info)
        suspend_support_chk_cmd = args.get("suspend_support_chk_cmd")

        session = self._get_session()
        s, o = self._session_cmd_close(session, suspend_support_chk_cmd)

        return s, o

    def verify_guest_support_suspend(self, **args):
        s, _ = self._check_guest_suspend_log(**args)
        if s:
            raise error.TestError("Guest doesn't support suspend.")

    @error.context_aware
    def start_suspend(self, **args):
        suspend_start_cmd = args.get("suspend_start_cmd")
        error.context("Start suspend [%s]" % (suspend_start_cmd), logging.info)

        session = self._get_session()
        self._open_session_list.append(session)

        # Suspend to disk
        session.sendline(suspend_start_cmd)

    @error.context_aware
    def verify_guest_down(self, **args):
        # Make sure the VM goes down
        error.context("Wait for guest goes down after suspend")
        suspend_timeout = 240 + int(self.params.get("smp")) * 60
        if not utils_misc.wait_for(self.vm.is_dead, suspend_timeout, 2, 2):
            raise error.TestFail("VM refuses to go down. Suspend failed.")

    @error.context_aware
    def resume_guest_mem(self, **args):
        error.context("Resume suspended VM from memory")
        self.vm.monitor.system_wakeup()

    @error.context_aware
    def resume_guest_disk(self, **args):
        error.context("Resume suspended VM from disk")
        self.vm.create()

    @error.context_aware
    def verify_guest_up(self, **args):
        error.context("Verify guest system log", logging.info)
        suspend_log_chk_cmd = args.get("suspend_log_chk_cmd")

        session = self._get_session()
        s, o = self._session_cmd_close(session, suspend_log_chk_cmd)
        if s:
            raise error.TestError("Could not find suspend log. [%s]" % (o))

    @error.context_aware
    def action_before_suspend(self, **args):
        error.context("Actions before suspend")
        pass

    @error.context_aware
    def action_during_suspend(self, **args):
        error.context("Sleep a while before resuming guest", logging.info)

        time.sleep(10)
        if self.os_type == "windows":
            # Due to WinXP/2003 won't suspend immediately after issue S3 cmd,
            # delay 10~60 secs here, maybe there's a bug in windows os.
            logging.info("WinXP/2003 need more time to suspend, sleep 50s.")
            time.sleep(50)

    @error.context_aware
    def action_after_suspend(self, **args):
        error.context("Actions after suspend")
        pass

########NEW FILE########
__FILENAME__ = utils_v2v
"""
Virt-v2v test utility functions.

:copyright: 2008-2012 Red Hat Inc.
"""

import os
import re
import logging

import ovirt
from autotest.client import os_dep, utils
from autotest.client.shared import ssh_key

import libvirt_vm as lvirt

DEBUG = False

try:
    V2V_EXEC = os_dep.command('virt-v2v')
except ValueError:
    V2V_EXEC = None


def build_esx_no_verify(params):
    """
    Build esx no verify relationship.
    """
    netrc = params.get('netrc')
    path = os.path.join(os.getenv("HOME"), '.netrc')

    fp = open(path, 'a+')

    if netrc not in fp.read():
        fp.write(netrc + '\n')

    fp.close()

    # The .netrc file must have a permission mask of 0600
    # to be read correctly by virt-v2v
    if oct(os.stat(path).st_mode & 0777) != '0600':
        os.chmod(path, 0600)


class Uri(object):

    """
    This class is used for generating uri.
    """

    def __init__(self, hypervisor):
        if hypervisor is None:
            # kvm is a default hypervisor
            hypervisor = "kvm"
        self.hyper = hypervisor

    def get_uri(self, hostname):
        """
        Uri dispatcher.

        :param hostname: String with host name.
        """
        uri_func = getattr(self, "_get_%s_uri" % self.hyper)
        self.host = hostname
        return uri_func()

    def _get_kvm_uri(self):
        """
        Return kvm uri.
        """
        uri = "qemu+ssh://" + self.host + "/system"
        return uri

    def _get_xen_uri(self):
        """
        Return xen uri.
        """
        uri = "xen+ssh://" + self.host + "/"
        return uri

    def _get_esx_uri(self):
        """
        Return esx uri.
        """
        uri = "esx://" + self.host + "/?no_verify=1"
        return uri

    # add new hypervisor in here.


class Target(object):

    """
    This class is used for generating command options.
    """

    def __init__(self, target, uri):
        if target is None:
            # libvirt is a default target
            target = "libvirt"
        self.tgt = target
        self.uri = uri

    def get_cmd_options(self, params):
        """
        Target dispatcher.
        """
        opts_func = getattr(self, "_get_%s_options" % self.tgt)
        self.params = params
        options = opts_func()

        self.input = params.get('input')
        self.files = params.get('files')
        if self.files is not None:
            # add files as its sequence
            file_list = self.files.split().reverse()
            for file in file_list:
                options = " -f %s %s " % (file, options)
        if self.input is not None:
            options = " -i %s %s" % (self.input, options)
        return options

    def _get_libvirt_options(self):
        """
        Return command options.
        """
        options = " -ic %s -os %s -b %s %s " % (self.uri,
                                                self.params.get('storage'), self.params.get('network'),
                                                self.params.get('vms'))
        return options

    def _get_libvirtxml_options(self):
        """
        Return command options.
        """
        options = " -os %s -b %s %s " % (self.params.get('storage'),
                                         self.params.get('network'),
                                         self.params.get('vms'))
        return options

    def _get_ovirt_options(self):
        """
        Return command options.
        """
        options = " -ic %s -o rhev -os %s -n %s %s " % (self.uri,
                                                        self.params.get('storage'), self.params.get('network'),
                                                        self.params.get('vms'))

        return options

    # add new target in here.


class LinuxVMCheck(object):

    """
    This class handles all basic linux VM check operations.
    """
    # Timeout definition for session login.
    LOGIN_TIMEOUT = 480

    def __init__(self, test, params, env):
        self.vm = None
        self.test = test
        self.env = env
        self.params = params
        self.name = params.get('vms')
        self.target = params.get('target')

        if self.name is None:
            logging.error("vm name not exist")

        # libvirt is a default target
        if self.target == "libvirt" or self.target is None:
            self.vm = lvirt.VM(self.name, self.params, self.test.bindir,
                               self.env.get("address_cache"))
        elif self.target == "ovirt":
            self.vm = ovirt.VMManager(self.params, self.test.bindir,
                                      self.env.get("address_cache"))
        else:
            raise ValueError("Doesn't support %s target now" % self.target)

        if self.vm.is_alive():
            self.vm.shutdown()
            self.vm.start()
        else:
            self.vm.start()

    def get_vm_kernel(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm kernel info.
        """
        cmd = "uname -r"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            kernel_version = session.cmd(cmd)
            session.close()
        else:
            kernel_version = session.cmd(cmd)
        logging.debug("The kernel of VM '%s' is: %s" %
                      (self.vm.name, kernel_version))
        return kernel_version

    def get_vm_os_info(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm os info.
        """
        cmd = "cat /etc/issue"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            output = session.cmd(cmd).split('\n', 1)[0]
            session.close()
        else:
            output = session.cmd(cmd).split('\n', 1)[0]
        logging.debug("The os info is: %s" % output)
        return output

    def get_vm_os_vendor(self, session=None, nic_index=0,
                         timeout=LOGIN_TIMEOUT):
        """
        Get vm os vendor.
        """
        os_info = self.get_vm_os_info(session, nic_index, timeout)
        if re.search('Red Hat', os_info):
            vendor = 'Red Hat'
        elif re.search('Fedora', os_info):
            vendor = 'Fedora Core'
        elif re.search('SUSE', os_info):
            vendor = 'SUSE'
        elif re.search('Ubuntu', os_info):
            vendor = 'Ubuntu'
        elif re.search('Debian', os_info):
            vendor = 'Debian'
        else:
            vendor = 'Unknown'
        logging.debug("The os vendor of VM '%s' is: %s" %
                      (self.vm.name, vendor))
        return vendor

    def get_vm_parted(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm parted info.
        """
        cmd = "parted -l"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            parted_output = session.cmd(cmd)
            session.close()
        else:
            parted_output = session.cmd(cmd)
        logging.debug("The parted output is:\n %s" % parted_output)
        return parted_output

    def get_vm_modprobe_conf(self, session=None, nic_index=0,
                             timeout=LOGIN_TIMEOUT):
        """
        Get /etc/modprobe.conf info.
        """
        cmd = "cat /etc/modprobe.conf"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            modprobe_output = session.cmd(cmd, ok_status=[0, 1])
            session.close()
        else:
            modprobe_output = session.cmd(cmd, ok_status=[0, 1])
        logging.debug("modprobe conf is:\n %s" % modprobe_output)
        return modprobe_output

    def get_vm_modules(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm modules list.
        """
        cmd = "lsmod"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            modules = session.cmd(cmd)
            session.close()
        else:
            modules = session.cmd(cmd)
        logging.debug("VM modules list is:\n %s" % modules)
        return modules

    def get_vm_pci_list(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm pci list.
        """
        cmd = "lspci"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            lspci_output = session.cmd(cmd)
            session.close()
        else:
            lspci_output = session.cmd(cmd)
        logging.debug("VM pci devices list is:\n %s" % lspci_output)
        return lspci_output

    def get_vm_rc_local(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm /etc/rc.local output.
        """
        cmd = "cat /etc/rc.local"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            rc_output = session.cmd(cmd, ok_status=[0, 1])
            session.close()
        else:
            rc_output = session.cmd(cmd, ok_status=[0, 1])
        return rc_output

    def has_vmware_tools(self, session=None, nic_index=0,
                         timeout=LOGIN_TIMEOUT):
        """
        Check vmware tools.
        """
        rpm_cmd = "rpm -q VMwareTools"
        ls_cmd = "ls /usr/bin/vmware-uninstall-tools.pl"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            rpm_cmd_status = session.cmd_status(rpm_cmd)
            ls_cmd_status = session.cmd_status(ls_cmd)
            session.close()
        else:
            rpm_cmd_status = session.cmd_status(rpm_cmd)
            ls_cmd_status = session.cmd_status(ls_cmd)

        if (rpm_cmd_status == 0 or ls_cmd_status == 0):
            return True
        else:
            return False

    def get_vm_tty(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm tty config.
        """
        confs = ('/etc/securetty', '/etc/inittab', '/boot/grub/grub.conf',
                 '/etc/default/grub')
        tty = ''
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            for conf in confs:
                cmd = "cat " + conf
                tty += session.cmd(cmd, ok_status=[0, 1])
            session.close()
        else:
            for conf in confs:
                cmd = "cat " + conf
                tty += session.cmd(cmd, ok_status=[0, 1])
        return tty

    def get_vm_video(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Get vm video config.
        """
        cmd = "cat /etc/X11/xorg.conf /etc/X11/XF86Config"
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            xorg_output = session.cmd(cmd, ok_status=[0, 1])
            session.close()
        else:
            xorg_output = session.cmd(cmd, ok_status=[0, 1])
        return xorg_output

    def is_net_virtio(self, session=None, nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Check whether vm's interface is virtio
        """
        cmd = "ls -l /sys/class/net/eth%s/device" % nic_index
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            driver_output = session.cmd(cmd, ok_status=[0, 1])
            session.close()
        else:
            driver_output = session.cmd(cmd, ok_status=[0, 1])

        if re.search("virtio", driver_output.split('/')[-1]):
            return True
        return False

    def is_disk_virtio(self, session=None, disk="/dev/vda",
                       nic_index=0, timeout=LOGIN_TIMEOUT):
        """
        Check whether disk is virtio.
        """
        cmd = "fdisk -l %s" % disk
        if not session:
            session = self.vm.wait_for_login(nic_index, timeout)
            disk_output = session.cmd(cmd, ok_status=[0, 1])
            session.close()
        else:
            disk_output = session.cmd(cmd, ok_status=[0, 1])

        if re.search(disk, disk_output):
            return True
        return False


class WindowsVMCheck(object):

    """
    This class handles all basic windows VM check operations.
    """
    pass


def v2v_cmd(params):
    """
    Append cmd to 'virt-v2v' and execute, optionally return full results.

    :param params: A dictionary includes all of required parameters such as
                    'target', 'hypervisor' and 'hostname', etc.
    :return: stdout of command
    """
    if V2V_EXEC is None:
        raise ValueError('Missing command: virt-v2v')

    target = params.get('target')
    hypervisor = params.get('hypervisor')
    hostname = params.get('hostname')
    username = params.get('username')
    password = params.get('password')

    uri_obj = Uri(hypervisor)
    # Return actual 'uri' according to 'hostname' and 'hypervisor'
    uri = uri_obj.get_uri(hostname)

    tgt_obj = Target(target, uri)
    # Return virt-v2v command line options based on 'target' and 'hypervisor'
    options = tgt_obj.get_cmd_options(params)

    # Convert a existing VM without or with connection authorization.
    if hypervisor == 'esx':
        build_esx_no_verify(params)
    elif hypervisor == 'xen' or hypervisor == 'kvm':
        # Setup ssh key for build connection without password.
        ssh_key.setup_ssh_key(hostname, user=username, port=22,
                              password=password)
    else:
        pass

    # Construct a final virt-v2v command
    cmd = '%s %s' % (V2V_EXEC, options)
    logging.debug('%s' % cmd)
    cmd_result = utils.run(cmd, verbose=DEBUG)
    return cmd_result

########NEW FILE########
__FILENAME__ = version
#!/usr/bin/python
"""
Based on work from Douglas Creager <dcreager@dcreager.net>

Gets the current version number.  If possible, this is the
output of "git describe", modified to conform to the versioning
scheme that setuptools uses.  If "git describe" returns an error
(most likely because we're in an unpacked copy of a release tarball,
rather than in a git working copy), then we fall back on reading the
contents of the RELEASE-VERSION file.
"""
__all__ = ("get_git_version", "get_version", "get_top_commit",
           "get_current_branch", "get_pretty_version_info")


import os
import sys
import common
from autotest.client import utils
from autotest.client.shared import error

import data_dir

_ROOT_PATH = data_dir.get_root_dir()
RELEASE_VERSION_PATH = os.path.join(_ROOT_PATH, 'RELEASE-VERSION')

global _GIT_VERSION_CACHE, _VERSION_CACHE, _TOP_COMMIT_CACHE
global _CURRENT_BRANCH_CACHE, _PRETTY_VERSION_CACHE

_GIT_VERSION_CACHE = None
_VERSION_CACHE = None
_TOP_COMMIT_CACHE = None
_CURRENT_BRANCH_CACHE = None
_PRETTY_VERSION_CACHE = None


def _execute_git_command(command):
    """
    As git is sensitive to the $CWD, change to the top dir to execute git cmds.

    :param: command - Git command to be executed.
    """
    cwd = os.getcwd()
    os.chdir(_ROOT_PATH)
    try:
        try:
            return utils.system_output(command).strip()
        finally:
            os.chdir(cwd)
    except error.CmdError:
        return 'unknown'


def get_git_version(abbrev=4):
    global _GIT_VERSION_CACHE
    if _GIT_VERSION_CACHE is not None:
        return _GIT_VERSION_CACHE

    _GIT_VERSION_CACHE = _execute_git_command('git describe --abbrev=%d' %
                                              abbrev)

    return _GIT_VERSION_CACHE


def get_top_commit():
    global _TOP_COMMIT_CACHE
    if _TOP_COMMIT_CACHE is not None:
        return _TOP_COMMIT_CACHE

    _TOP_COMMIT_CACHE = _execute_git_command(
        "git show --summary --pretty='%H' | head -1")

    return _TOP_COMMIT_CACHE


def get_current_branch():
    global _CURRENT_BRANCH_CACHE
    if _CURRENT_BRANCH_CACHE is not None:
        return _CURRENT_BRANCH_CACHE
    _CURRENT_BRANCH_CACHE = _execute_git_command('git rev-parse '
                                                 '--abbrev-ref HEAD')
    return _CURRENT_BRANCH_CACHE


def _read_release_version():
    try:
        f = open(RELEASE_VERSION_PATH, "r")
        try:
            version = f.readlines()[0]
            return version.strip()
        finally:
            f.close()
    except:
        return 'unknown'


def _write_release_version(version):
    f = open(RELEASE_VERSION_PATH, "w")
    f.write("%s\n" % version)
    f.close()


def get_version(abbrev=4):
    global _GIT_VERSION_CACHE
    release_version = _read_release_version()
    if _GIT_VERSION_CACHE is not None:
        version = _GIT_VERSION_CACHE
    else:
        _GIT_VERSION_CACHE = get_git_version(abbrev)
        version = _GIT_VERSION_CACHE

    if version is 'unknown':
        version = release_version

    if version is 'unknown':
        return version

    if version != release_version:
        _write_release_version(version)

    return version


def get_pretty_version_info():
    return ("Virt Test '%s', Branch '%s', SHA1 '%s'" %
            (get_version(), get_current_branch(), get_top_commit()))


if __name__ == "__main__":
    print get_pretty_version_info()

########NEW FILE########
__FILENAME__ = versionable_class
import sys
import types


"""
Versioning system provides class hierarchy which automatically select the right
version of a class. Class and module manipulation is used for this reason.

By this reason is:
    Advantage) Only one class with some version is working in one process.
               It is possible use class variables. Others version of same
               class have different class variables. Supports pickling.
               Much cleaner debugging and faster running of code than
               using of __getattribute__.
    Disadvantage) It is necessary create class with
                        fatory(orig_class, params for is_right_ver)
               access to specific class through class Manager.


Example of usage (in versionable_class_unittest):


# SIMPLE EXAPMLE

from versionable_class import Manager, factory, VersionableClass
#register module to class manager. Necessary for pickling.
man = Manager(__name__)
# pylint: disable=E1003

class VM(object):
    @classmethod
    def _is_right_ver(cls, version):
        return version < 1

    def __init__(self, *args, **kargs):
        super(VM, self).__init__(*args, **kargs)

    def fn1(self):
        print "fn1_VM"



class VM1(VM):
    @classmethod
    def _is_right_ver(cls, version):
        return version >= 1

    def __init__(self, *args, **kargs):
        super(VM1, self).__init__(*args, **kargs)

    def fn1(self):
        print "fn1_VM1"

class VM_container(test_vers.VersionableClass):
    __master__ = VM1


o = test_vers.factory(VM_container, version=0) # return class.
o = o()    # create instance of class
p = test_vers.factory(VM_container, version=2)()
o.fn1()
p.fn1()


# ADVANCED EXAPMLE

from versionable_class import Manager, factory, VersionableClass
man = Manager(__name__)
# pylint: disable=E1003


def qemu_verison():
    return 2


class VM(object):
    __slot__ = ["cls"]

    test_class_vm1 = None

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "qemu_version" in kargs:
            ver = kargs['qemu_version']
        else:
            ver = qemu_verison()
        if ver < 1:
            return True
        else:
            return False


    def __new__(cls, *args, **kargs):
        return super(VM, cls).__new__(cls, *args, **kargs)


    def __init__(self, *args, **kargs):
        super(VM, self).__init__()
        self.cls = self.__class__.__name__


    def __str__(self):
        return "%s" % self.cls


    def func1(self):
        print "VM_func1"


    def func3(self):
        pass


class VM1(VM):
    __slot__ = ["VM1_cls"]
    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "qemu_version" in kargs:
            ver = kargs['qemu_version']
        else:
            ver = qemu_verison()
        if ver > 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(VM1, self).__init__(*args, **kargs)
        self.cls = self.__class__.__name__
        self.VM1_cls = "VM1"


    def __str__(self):
        return "%s" % self.cls


    def func1(self):
        super(VM1, self).func1()


    def func2(self):
        print "func2"


    def func3(self):
        pass


class VM_container(VersionableClass):
    __master__ = VM1

    def __new__(cls, *args, **kargs):
        return super(man[cls, VM_container], cls).__new__(cls, *args, **kargs)


class BB(VM_container):
    test_class_bb = None

    def __new__(cls, *args, **kargs):
        return super(man[cls, BB], cls).__new__(cls, *args, **kargs)


    def func1(self):
        super(man[self.__class__, BB], self).func1()


    def func2(self):
        super(man[self.__class__, BB], self).func2()
"""


def isclass(obj):
    """
    :param obj: Object for inspection if obj is class.
    :return: true if the object is a class.
    """
    return isinstance(obj, (type, types.ClassType))


class ModuleWrapper(object):

    """
    Wrapper around module.

    Necessary for pickling of dynamic class.
    """

    def __init__(self, wrapped):
        """
        :param wrapped: module for wrapping.
        :type wrapped: Module.
        """
        self.wrapped = wrapped

    def __dir__(self):
        return dir(self.wrapped)

    def __getattr__(self, name):
        """
        Override method `__getattr__` allows manipulate with modules.

        :param name: Name of specific object.
        :type name: string.
        :return: specific class when name of class starts with managed or
                 normal attribute from wrapped class.
        """
        if name not in self.wrapped.__dict__:
            if name.startswith("managed"):
                cls_name = name.split("_")
                cls = self.wrapped.__dict__[cls_name[1]]
                m_cls, _ = Manager(self.wrapped.__name__, self).factory(cls,
                                                                        _class_names=cls_name)
                return m_cls
        cls = getattr(self.wrapped, name)
        return cls


class VersionableClass(object):

    """
    Class used for marking of mutable class.
    """
    def __new__(cls, *args, **kargs):
        """
        If this method is invoked it means that something went wrong because
        this class should be replaced by :class:`Manager` factory.
        """
        raise Exception("Class %s is not prepared for usage. "
                        "You have to call versionable_class.factory(cls) "
                        "before you can use it" % (cls))


class Manager(object):

    def __init__(self, name, wrapper=None):
        """
        Manager for module.

        :param name: Name of module.
        :type name: string
        :param wrapper: Module dictionary wrapper. Should be None.
        """
        __import__(name)
        if not wrapper:
            if not isinstance(sys.modules[name], ModuleWrapper):
                self.wrapper = ModuleWrapper(sys.modules[name])
                sys.modules[name] = self.wrapper
            else:
                self.wrapper = sys.modules[name]
        else:
            self.wrapper = wrapper

    def factory(self, _class, *args, **kargs):
        """
        Create new class with right version of subclasses.

        Goes through class structure and search subclasses with right version.

        :param _class: Class which should be prepared.
        :type _class: class.
        :param args: Params for _is_right_ver function.
        :params kargs: Params for _is_right_ver function.
        """
        def add_to_structure(cl, new_bases):
            if VersionableClass in cl.__mro__:
                cls, cls_vn = self.factory(cl, *args, **kargs)
                new_bases.append(cls)
                return cls_vn
            else:
                new_bases.append(cl)
                return ""

        _class_names = None
        if "_class_names" in kargs:
            _class_names = kargs["_class_names"]
        if (_class.__name__.startswith("managed") and
                hasattr(_class, "__original_class__")):
            _class = _class.__original_class__
        new_bases = []
        cls_ver_name = ""
        if VersionableClass in _class.__bases__:  # parent is VersionableClass
            for m_cls in _class.__bases__:
                if m_cls is VersionableClass:
                    mro = _class.__master__.__mro__    # Find good version.
                    if _class_names:
                        for cl in mro[:-1]:
                            if cl.__name__ in _class_names:
                                cls_ver_name += "_" + cl.__name__
                                cls_ver_name += add_to_structure(cl, new_bases)
                                break
                    else:
                        for cl in mro[:-1]:
                            if cl._is_right_ver(*args, **kargs):
                                cls_ver_name += "_" + cl.__name__
                                cls_ver_name += add_to_structure(cl, new_bases)
                                break
                else:
                    cls_ver_name += add_to_structure(m_cls, new_bases)
        else:
            for m_cls in _class.__bases__:
                if (VersionableClass in m_cls.__mro__ or
                        hasattr(m_cls, "__original_class__")):
                    cls, cls_vn = self.factory(m_cls, *args, **kargs)
                    new_bases.append(cls)
                    cls_ver_name += cls_vn
                else:
                    new_bases.append(m_cls)
        class_name = "managed_%s%s" % (_class.__name__, cls_ver_name)

        if hasattr(self.wrapper.wrapped, class_name):
            # Don't override already created class.
            return self.wrapper.wrapped.__dict__[class_name], cls_ver_name

        class_dict = _class.__dict__.copy()
        class_dict["__original_class__"] = _class
        cls = type(class_name, tuple(new_bases), class_dict)
        self.wrapper.wrapped.__dict__[class_name] = cls

        return cls, cls_ver_name

    def __getitem__(self, o_cls):
        return self.getcls(*o_cls)

    def getcls(self, cls, orig_class):
        """
        Return class correspond class and original class.

        :param cls: class for which should be found derived alternative.
        :type cls: class
        :param orig_class: Original class
        :type orig_class: class

        :return: Derived alternative class
        :rtype: class
        """
        for m_cls in cls.__mro__:
            if hasattr(m_cls, "__original_class__"):
                if m_cls.__original_class__ is orig_class:
                    return m_cls
            elif m_cls is orig_class:
                return m_cls
        raise Exception("Couldn't find derived alternative in %s for"
                        " class %s" % (cls, orig_class))


def factory(orig_cls, *args, **kargs):
    """
    Create class with specific version.

    :param orig_class: Class from which should be derived good version.
    :param args: list of parameters for _ir_right_ver
    :params kargs: dict of named parameters for _ir_right_ver
    :return: params specific class.
    :rtype: class
    """
    return Manager(orig_cls.__module__).factory(orig_cls, *args, **kargs)[0]

########NEW FILE########
__FILENAME__ = versionable_class_unittest
#!/usr/bin/python

import unittest
import cPickle
import sys

import common
from autotest.client.shared import utils
from autotest.client.shared.test_utils import mock
from versionable_class import Manager, factory, VersionableClass
man = Manager(__name__)

# pylint: disable=E1003


def qemu_verison():
    return 2


class VM(object):
    __slot__ = ["cls"]

    test_class_vm1 = None

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "qemu_version" in kargs:
            ver = kargs['qemu_version']
        else:
            ver = qemu_verison()
        if ver < 1:
            return True
        else:
            return False

    def __new__(cls, *args, **kargs):
        return super(VM, cls).__new__(cls, *args, **kargs)

    def __init__(self, *args, **kargs):
        super(VM, self).__init__()
        self.cls = self.__class__.__name__

    def __str__(self):
        return "%s" % self.cls

    def func1(self):
        print "VM_func1"

    def func3(self):
        pass


class VM1(VM):
    __slot__ = ["VM1_cls"]

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "qemu_version" in kargs:
            ver = kargs['qemu_version']
        else:
            ver = qemu_verison()
        if ver > 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(VM1, self).__init__(*args, **kargs)
        self.cls = self.__class__.__name__
        self.VM1_cls = "VM1"

    def __str__(self):
        return "%s" % self.cls

    def func1(self):
        super(VM1, self).func1()

    def func2(self):
        print "func2"

    def func3(self):
        pass


class VM_container(VersionableClass):
    __master__ = VM1

    def __new__(cls, *args, **kargs):
        return super(man[cls, VM_container], cls).__new__(cls, *args, **kargs)


class BB(VM_container):
    test_class_bb = None

    def __new__(cls, *args, **kargs):
        return super(man[cls, BB], cls).__new__(cls, *args, **kargs)

    def func1(self):
        super(man[self.__class__, BB], self).func1()

    def func2(self):
        super(man[self.__class__, BB], self).func2()


def system_version():
    return 2


class System(object):

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "system_version" in kargs:
            ver = kargs['system_version']
        else:
            ver = system_version()
        if ver < 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(System, self).__init__()
        self.aa = self.__class__.__name__

    def __str__(self):
        return "VM1 %s" % self.aa


class System1(System):

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "system_version" in kargs:
            ver = kargs['system_version']
        else:
            ver = system_version()
        if ver > 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(System1, self).__init__(*args, **kargs)
        self.aa = self.__class__.__name__

    def __str__(self):
        return "VM1 %s" % self.aa


class System_Container(VersionableClass):
    __master__ = System1

    def __new__(cls, *args, **kargs):
        return super(man[cls, System_Container], cls).__new__(cls, *args, **kargs)


class Q(object):

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "q_version" in kargs:
            ver = kargs['q_version']
        else:
            ver = system_version()
        if ver < 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(Q, self).__init__()
        self.cls = self.__class__.__name__

    def __str__(self):
        return "%s" % self.cls


class Q1(Q):

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "q_version" in kargs:
            ver = kargs['q_version']
        else:
            ver = system_version()
        if ver > 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(man[self.__class__, Q1], self).__init__(*args, **kargs)
        self.cls = self.__class__.__name__

    def __str__(self):
        return "%s" % self.cls


class Q_Container(VersionableClass):
    __master__ = Q1


class Sys(Q_Container):

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "system_version" in kargs:
            ver = kargs['system_version']
        else:
            ver = system_version()
        if ver < 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(man[self.__class__, Sys], self).__init__(*args, **kargs)
        self.cls = self.__class__.__name__

    def __str__(self):
        return "%s" % self.cls


class Sys1(Sys):

    @classmethod
    def _is_right_ver(cls, *args, **kargs):
        ver = None
        if "system_version" in kargs:
            ver = kargs['system_version']
        else:
            ver = system_version()
        if ver > 1:
            return True
        else:
            return False

    def __init__(self, *args, **kargs):
        super(man[self.__class__, Sys1], self).__init__(*args, **kargs)
        self.cls = self.__class__.__name__

    def __str__(self):
        return "%s" % self.cls


class Sys_Container(VersionableClass):
    __master__ = Sys1

    def __new__(cls, *args, **kargs):
        return super(man[cls, Sys_Container], cls).__new__(cls, *args, **kargs)


class AA(Sys_Container, BB, System_Container):

    def __new__(cls, *args, **kargs):
        return super(man[cls, AA], cls).__new__(cls, *args, **kargs)


class TestVersionableClass(unittest.TestCase):

    def setUp(self):
        self.god = mock.mock_god(ut=self)
        self.god.stub_function(utils.logging, 'warn')
        self.god.stub_function(utils.logging, 'debug')
        self.version = 1

    def tearDown(self):
        self.god.unstub_all()

    def test_simple_versioning(self):
        self.god.stub_function(VM, "func1")
        self.god.stub_function(VM1, "func2")

        VM1.func2.expect_call()
        VM.func1.expect_call()

        mm = factory(BB)()
        # check class name.
        self.assertEqual(str(mm), "managed_BB_VM1")
        mm.func2()   # call BB.func2(m) -> VM1.func2
        mm.func1()   # call VM1.func1(m) -> VM.func1

        self.god.check_playback()

    def test_simple_create_by_params_v0(self):
        def wrap(mm):
            mm.VM1_cls

        self.god.stub_function(VM, "func3")
        self.god.stub_function(VM1, "func3")

        VM.func3.expect_call()

        mm = factory(BB, qemu_version=0)()
        # check class name.
        self.assertEqual(str(mm), "managed_BB_VM")
        mm.func3()   # call VM1.func1(m) -> VM.func1
        self.assertRaises(AttributeError, wrap, mm)

        self.god.check_playback()

    def test_simple_create_by_params_v1(self):
        self.god.stub_function(VM, "func3")
        self.god.stub_function(VM1, "func3")

        VM1.func3.expect_call()

        mm = factory(BB, qemu_version=2)()
        # check class name.
        self.assertEqual(str(mm), "managed_BB_VM1")
        mm.func3()   # call VM1.func1(m) -> VM.func1
        self.assertEqual(mm.VM1_cls, "VM1")

        self.god.check_playback()

    def test_sharing_data_in_same_version(self):
        mm = factory(BB)()
        bb = factory(BB)()
        cc = factory(BB, qemu_version=0)()

        # Get corespond class in versionable class
        man[bb.__class__, VM].test_class_vm1 = 1
        man[bb.__class__, BB].test_class_bb = 2
        man[cc.__class__, BB].test_class_bb = 3
        # check class name.
        self.assertEqual(bb.__class__.test_class_vm1,
                         mm.__class__.test_class_vm1)
        self.assertEqual(bb.__class__.test_class_bb,
                         mm.__class__.test_class_bb)

        # In class hierarchy is class which don't have to be versioned
        # because that first value should be equal and second one shouldn't.
        self.assertEqual(bb.__class__.test_class_vm1,
                         cc.__class__.test_class_vm1)
        self.assertNotEqual(bb.__class__.test_class_bb,
                            cc.__class__.test_class_bb)

    def test_complicated_versioning(self):
        self.god.stub_function(VM, "func3")
        self.god.stub_function(VM1, "func3")

        VM1.func3.expect_call()

        mm = factory(AA)()
        # check class name.
        self.assertEqual(str(mm), "managed_AA_Sys1_Q1_VM1_System1")
        mm.func3()   # call VM1.func1(m) -> VM.func1

        self.god.check_playback()

    def test_complicated_multiple_create_params(self):
        self.god.stub_function(VM, "func3")
        self.god.stub_function(VM1, "func3")

        VM1.func3.expect_call()

        mm = factory(AA, qemu_version=0, system_version=2, q_version=0)()
        # check class name.
        self.assertEqual(str(mm), "managed_AA_Sys1_Q_VM_System1")
        mm.func3()   # call VM1.func1(m) -> VM.func1

        self.god.check_playback()

    def test_pickleing(self):
        """
        Test pickling for example save vm env.
        """
        m = factory(AA, system_version=0, qemu_version=0)()
        mm = factory(BB, qemu_version=3)()

        f = open("/tmp/pick", "w+")
        cPickle.dump(m, f, cPickle.HIGHEST_PROTOCOL)
        cPickle.dump(mm, f, cPickle.HIGHEST_PROTOCOL)
        f.close()

        # Delete classes for ensure that pickel works correctly.
        name = m.__class__.__name__
        del m
        del globals()[name]

        name = mm.__class__.__name__
        del mm
        del globals()[name]

        f = open("/tmp/pick", "r+")
        c = cPickle.load(f)
        cc = cPickle.load(f)
        f.close()


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = video_maker
"""
Video Maker transforms screenshots taken during a test into a HTML 5
compatible video, so that one can watch the screen activity of the
whole test from inside your own browser.

This relies on generally available multimedia libraries, frameworks
and tools.
"""


import os
import time
import glob
import logging
import re


__all__ = ['GstPythonVideoMaker', 'video_maker']


#
# Check what kind of video libraries tools we have available
#
# Gstreamer python bindings are our first choice
try:
    import gst
    GST_PYTHON_INSTALLED = True
except ImportError:
    GST_PYTHON_INSTALLED = False


#
# PIL is also required to normalize images
#
try:
    import PIL.Image
    PIL_INSTALLED = True
except ImportError:
    PIL_INSTALLED = False


#
# We only do video
#
CONTAINER_PREFERENCE = ['ogg', 'webm']
ENCODER_PREFERENCE = ['theora', 'vp8']


class GstPythonVideoMaker(object):

    '''
    Makes a movie out of screendump images using gstreamer-python
    '''

    CONTAINER_MAPPING = {'ogg': 'oggmux',
                         'webm': 'webmmux'}

    ENCODER_MAPPING = {'theora': 'theoraenc',
                       'vp8': 'vp8enc'}

    CONTAINER_ENCODER_MAPPING = {'ogg': 'theora',
                                 'webm': 'vp8'}

    def __init__(self, verbose=False):
        if not GST_PYTHON_INSTALLED:
            raise ValueError('gstreamer-python library was not found')
        if not PIL_INSTALLED:
            raise ValueError('python-imaging library was not found')

        self.verbose = verbose

    def get_most_common_image_size(self, input_dir):
        '''
        Find the most common image size
        '''
        image_sizes = {}
        image_files = glob.glob(os.path.join(input_dir, '*.jpg'))
        for f in image_files:
            i = PIL.Image.open(f)
            if not image_sizes.has_key(i.size):
                image_sizes[i.size] = 1
            else:
                image_sizes[i.size] += 1

        most_common_size_counter = 0
        most_common_size = None
        for image_size, image_counter in image_sizes.items():
            if image_counter > most_common_size_counter:
                most_common_size_counter = image_counter
                most_common_size = image_size
        return most_common_size

    def normalize_images(self, input_dir):
        '''
        GStreamer requires all images to be the same size, so we do it here
        '''
        image_size = self.get_most_common_image_size(input_dir)
        if image_size is None:
            image_size = (800, 600)

        if self.verbose:
            logging.debug('Normalizing image files to size: %s', image_size)
        image_files = glob.glob(os.path.join(input_dir, '*.jpg'))
        for f in image_files:
            i = PIL.Image.open(f)
            if i.size != image_size:
                i.resize(image_size).save(f)

    def has_element(self, kind):
        '''
        Returns True if a gstreamer element is available
        '''
        return gst.element_factory_find(kind) is not None

    def get_container_name(self):
        '''
        Gets the video container available that is the best based on preference
        '''
        for c in CONTAINER_PREFERENCE:
            element_kind = self.CONTAINER_MAPPING.get(c, c)
            if self.has_element(element_kind):
                return element_kind

        raise ValueError('No suitable container format was found')

    def get_encoder_name(self):
        '''
        Gets the video encoder available that is the best based on preference
        '''
        for c in ENCODER_PREFERENCE:
            element_kind = self.ENCODER_MAPPING.get(c, c)
            if self.has_element(element_kind):
                return element_kind

        raise ValueError('No suitable encoder format was found')

    def get_element(self, name):
        '''
        Makes and returns and element from the gst factory interface
        '''
        if self.verbose:
            logging.debug('GStreamer element requested: %s', name)
        return gst.element_factory_make(name, name)

    def start(self, input_dir, output_file):
        '''
        Process the input files and output the video file
        '''
        self.normalize_images(input_dir)
        file_list = glob.glob(os.path.join(input_dir, '*.jpg'))
        no_files = len(file_list)
        if no_files == 0:
            if self.verbose:
                logging.debug("Number of files to encode as video is zero")
            return
        index_list = []
        for ifile in file_list:
            index_list.append(int(re.findall(r"/+.*/(\d{4})\.jpg", ifile)[0]))
            index_list.sort()
        if self.verbose:
            logging.debug('Number of files to encode as video: %s', no_files)

        pipeline = gst.Pipeline("pipeline")

        source = self.get_element("multifilesrc")
        source_location = os.path.join(input_dir, "%04d.jpg")
        if self.verbose:
            logging.debug("Source location: %s", source_location)
        source.set_property('location', source_location)
        source.set_property('index', index_list[0])
        source_caps = gst.Caps()
        source_caps.append('image/jpeg,framerate=(fraction)4/1')
        source.set_property('caps', source_caps)

        decoder = self.get_element("jpegdec")

        # Attempt to auto detect the chosen encoder/mux based on output_file
        encoder = None
        container = None

        for container_name in self.CONTAINER_ENCODER_MAPPING:
            if output_file.endswith('.%s' % container_name):

                enc_name = self.CONTAINER_ENCODER_MAPPING[container_name]
                enc_name_gst = self.ENCODER_MAPPING[enc_name]
                encoder = self.get_element(enc_name_gst)

                cont_name_gst = self.CONTAINER_MAPPING[container_name]
                container = self.get_element(cont_name_gst)

        # If auto detection fails, choose from the list of preferred codec/mux
        if encoder is None:
            encoder = self.get_element(self.get_encoder_name())
        if container is None:
            container = self.get_element(self.get_container_name())

        output = self.get_element("filesink")
        output.set_property('location', output_file)

        pipeline.add_many(source, decoder, encoder, container, output)
        gst.element_link_many(source, decoder, encoder, container, output)

        pipeline.set_state(gst.STATE_PLAYING)
        while True:
            if source.get_property('index') <= no_files:
                if self.verbose:
                    logging.debug("Currently processing image number: %s",
                                  source.get_property('index'))
                time.sleep(1)
            else:
                break
        time.sleep(3)
        pipeline.set_state(gst.STATE_NULL)


def video_maker(input_dir, output_file):
    '''
    Instantiates and runs a video maker
    '''
    v = GstPythonVideoMaker()
    v.start(input_dir, output_file)


if __name__ == '__main__':
    import sys
    if len(sys.argv) < 3:
        print 'Usage: %s <input_dir> <output_file>' % sys.argv[0]
    else:
        video_maker(sys.argv[1], sys.argv[2])

########NEW FILE########
__FILENAME__ = virsh
"""
Utility classes and functions to handle connection to a libvirt host system

The entire contents of callables in this module (minus the names defined in
NOCLOSE below), will become methods of the Virsh and VirshPersistent classes.
A Closure class is used to wrap the module functions, lambda does not
properly store instance state in this implementation.

Because none of the methods have a 'self' parameter defined, the classes
are defined to be dict-like, and get passed in to the methods as a the
special ``**dargs`` parameter.  All virsh module functions _MUST_ include a
special ``**dargs`` (variable keyword arguments) to accept non-default
keyword arguments.

The standard set of keyword arguments to all functions/modules is declared
in the VirshBase class.  Only the 'virsh_exec' key is guaranteed to always
be present, the remainder may or may not be provided.  Therefor, virsh
functions/methods should use the dict.get() method to retrieve with a default
for non-existant keys.

:copyright: 2012 Red Hat Inc.
"""

import signal
import logging
import urlparse
import re
import weakref
import time
import select
import utils_misc
from autotest.client import utils
from autotest.client import os_dep
from autotest.client.shared import error
from virttest import aexpect
from virttest import propcan
from virttest import remote

# list of symbol names NOT to wrap as Virsh class methods
# Everything else from globals() will become a method of Virsh class
NOCLOSE = globals().keys() + [
    'NOCLOSE', 'SCREENSHOT_ERROR_COUNT', 'VIRSH_COMMAND_CACHE',
    'VIRSH_EXEC', 'VirshBase', 'VirshClosure', 'VirshSession', 'Virsh',
    'VirshPersistent', 'VirshConnectBack', 'VIRSH_COMMAND_GROUP_CACHE',
    'VIRSH_COMMAND_GROUP_CACHE_NO_DETAIL',
]

# Needs to be in-scope for Virsh* class screenshot method and module function
SCREENSHOT_ERROR_COUNT = 0

# Cache of virsh commands, used by help_command_group() and help_command_only()
# TODO: Make the cache into a class attribute on VirshBase class.
VIRSH_COMMAND_CACHE = None
VIRSH_COMMAND_GROUP_CACHE = None
VIRSH_COMMAND_GROUP_CACHE_NO_DETAIL = False

# This is used both inside and outside classes
try:
    VIRSH_EXEC = os_dep.command("virsh")
except ValueError:
    logging.warning("Virsh executable not set or found on path, "
                    "virsh module will not function normally")
    VIRSH_EXEC = '/bin/true'


class VirshBase(propcan.PropCanBase):

    """
    Base Class storing libvirt Connection & state to a host
    """

    __slots__ = ('uri', 'ignore_status', 'debug', 'virsh_exec', 'readonly')

    def __init__(self, *args, **dargs):
        """
        Initialize instance with virsh_exec always set to something
        """
        init_dict = dict(*args, **dargs)
        init_dict['virsh_exec'] = init_dict.get('virsh_exec', VIRSH_EXEC)
        init_dict['uri'] = init_dict.get('uri', None)
        init_dict['debug'] = init_dict.get('debug', False)
        init_dict['ignore_status'] = init_dict.get('ignore_status', False)
        init_dict['readonly'] = init_dict.get('readonly', False)
        super(VirshBase, self).__init__(init_dict)

    def get_uri(self):
        """
        Accessor method for 'uri' property that must exist
        """
        # self.get() would call get_uri() recursivly
        try:
            return self.__dict_get__('uri')
        except KeyError:
            return None


class VirshSession(aexpect.ShellSession):

    """
    A virsh shell session, used with Virsh instances.
    """

    # No way to get virsh sub-command "exit" status
    # Check output against list of known error-status strings
    ERROR_REGEX_LIST = ['error:\s*.+$', '.*failed.*']

    def __init__(self, virsh_exec=None, uri=None, a_id=None,
                 prompt=r"virsh\s*[\#\>]\s*", remote_ip=None,
                 remote_user=None, remote_pwd=None,
                 ssh_remote_auth=False, readonly=False,
                 unprivileged_user=None,
                 auto_close=False):
        """
        Initialize virsh session server, or client if id set.

        :param virsh_exec: path to virsh executable
        :param uri: uri of libvirt instance to connect to
        :param id: ID of an already running server, if accessing a running
                server, or None if starting a new one.
        :param prompt: Regular expression describing the shell's prompt line.
        :param remote_ip: Hostname/IP of remote system to ssh into (if any)
        :param remote_user: Username to ssh in as (if any)
        :param remote_pwd: Password to use, or None for host/pubkey
        :param auto_close: Param to init ShellSession.
        :param ssh_remote_auth: ssh to remote first.(VirshConnectBack).
                                Then execute virsh commands.

        Because the VirshSession is designed for class VirshPersistent, so
        the default value of auto_close is False, and we manage the reference
        to VirshSession in VirshPersistent manually with counter_increase and
        counter_decrease. If you really want to use it directly over VirshPe-
        rsistent, please init it with auto_close=True, then the session will
        be closed in __del__.

            * session = VirshSession(virsh.VIRSH_EXEC, auto_close=True)
        """

        self.uri = uri
        self.remote_ip = remote_ip
        self.remote_user = remote_user
        self.remote_pwd = remote_pwd

        # Special handling if setting up a remote session
        if ssh_remote_auth:  # remote to remote
            if remote_pwd:
                pref_auth = "-o PreferredAuthentications=password"
            else:
                pref_auth = "-o PreferredAuthentications=hostbased,publickey"
            # ssh_cmd is not None flags this as remote session
            ssh_cmd = ("ssh -o UserKnownHostsFile=/dev/null %s -p %s %s@%s"
                       % (pref_auth, 22, self.remote_user, self.remote_ip))
            self.virsh_exec = ("%s \"%s -c '%s'\""
                               % (ssh_cmd, virsh_exec, self.uri))
        else:  # setting up a local session or re-using a session
            self.virsh_exec = virsh_exec
            if self.uri:
                self.virsh_exec += " -c '%s'" % self.uri
            ssh_cmd = None  # flags not-remote session

        if readonly:
            self.virsh_exec += " -r"

        if unprivileged_user:
            self.virsh_exec = "su - %s -c '%s'" % (unprivileged_user,
                                                   self.virsh_exec)

        # aexpect tries to auto close session because no clients connected yet
        aexpect.ShellSession.__init__(self, self.virsh_exec, a_id,
                                      prompt=prompt, auto_close=auto_close)

        # Handle remote session prompts:
        # 1.remote to remote with ssh
        # 2.local to remote with "virsh -c uri"
        if ssh_remote_auth or self.uri:
            # Handle ssh / password prompts
            remote.handle_prompts(self, self.remote_user, self.remote_pwd,
                                  prompt, debug=True)

        # fail if libvirtd is not running
        if self.cmd_status('list', timeout=60) != 0:
            logging.debug("Persistent virsh session is not responding, "
                          "libvirtd may be dead.")
            self.auto_close = True
            raise aexpect.ShellStatusError(virsh_exec, 'list')

    def cmd_status_output(self, cmd, timeout=60, internal_timeout=None,
                          print_func=None):
        """
        Send a virsh command and return its exit status and output.

        :param cmd: virsh command to send (must not contain newline characters)
        :param timeout: The duration (in seconds) to wait for the prompt to
                return
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :return: A tuple (status, output) where status is the exit status and
                output is the output of cmd
        :raise ShellTimeoutError: Raised if timeout expires
        :raise ShellProcessTerminatedError: Raised if the shell process
                terminates while waiting for output
        :raise ShellStatusError: Raised if the exit status cannot be obtained
        :raise ShellError: Raised if an unknown error occurs
        """
        out = self.cmd_output(cmd, timeout, internal_timeout, print_func)
        for line in out.splitlines():
            if self.match_patterns(line, self.ERROR_REGEX_LIST) is not None:
                return 1, out
        return 0, out

    def cmd_result(self, cmd, ignore_status=False, debug=False):
        """Mimic utils.run()"""
        exit_status, stdout = self.cmd_status_output(cmd)
        stderr = ''  # no way to retrieve this separately
        result = utils.CmdResult(cmd, stdout, stderr, exit_status)
        if not ignore_status and exit_status:
            raise error.CmdError(cmd, result,
                                 "Virsh Command returned non-zero exit status")
        if debug:
            logging.debug(result)
        return result

    def read_until_output_matches(self, patterns, filter_func=lambda x: x,
                                  timeout=60, internal_timeout=None,
                                  print_func=None, match_func=None):
        """
        Read from child using read_nonblocking until a pattern matches.

        Read using read_nonblocking until a match is found using match_patterns,
        or until timeout expires. Before attempting to search for a match, the
        data is filtered using the filter_func function provided.

        :param patterns: List of strings (regular expression patterns)
        :param filter_func: Function to apply to the data read from the child before
                attempting to match it against the patterns (should take and
                return a string)
        :param timeout: The duration (in seconds) to wait until a match is
                found
        :param internal_timeout: The timeout to pass to read_nonblocking
        :param print_func: A function to be used to print the data being read
                (should take a string parameter)
        :param match_func: Function to compare the output and patterns.
        :return: Tuple containing the match index and the data read so far
        :raise ExpectTimeoutError: Raised if timeout expires
        :raise ExpectProcessTerminatedError: Raised if the child process
                terminates while waiting for output
        :raise ExpectError: Raised if an unknown error occurs
        """
        if not match_func:
            match_func = self.match_patterns
        fd = self._get_fd("expect")
        o = ""
        end_time = time.time() + timeout
        while True:
            try:
                r, w, x = select.select([fd], [], [],
                                        max(0, end_time - time.time()))
            except (select.error, TypeError):
                break
            if not r:
                raise aexpect.ExpectTimeoutError(patterns, o)
            # Read data from child
            data = self.read_nonblocking(internal_timeout,
                                         end_time - time.time())
            if not data:
                break
            # Print it if necessary
            if print_func:
                for line in data.splitlines():
                    print_func(line)
            # Look for patterns
            o += data

            out = ''
            match = match_func(filter_func(o), patterns)
            if match is not None:
                output = o.splitlines()
                # Find the second match in output reverse list, only return
                # the content between the last match and the second last match.
                # read_nonblocking might include output of last command or help
                # info when session initiated,
                # e.g.
                # When use VirshPersistent initiate a virsh session, an list
                # command is send in to test libvirtd status, and the first
                # command output will be like:
                # Welcome to virsh, the virtualization interactive terminal.
                #
                # Type:  'help' for help with commands
                #       'quit' to quit
                #
                # virsh #  Id    Name                           State
                #----------------------------------------------------
                #
                # virsh #
                # the session help info is included, and the exact output
                # should be the content start after first virsh # prompt.
                # The list command did no harm here with help info included,
                # but sometime other commands get list command output included,
                # e.g.
                #  Running virsh command: net-list --all
                #  Sending command: net-list --all
                #  Id    Name                           State
                #  ----------------------------------------------------
                #
                #  virsh #  Name            State      Autostart     Persistent
                #  ----------------------------------------------------------
                #  default              active     yes           yes
                #
                #  virsh #
                # The list command output is mixed in the net-list command
                # output, this will fail to extract network name if use set
                # number 2 in list of output splitlines like in function
                # virsh.net_state_dict.
                for i in reversed(range(len(output)-1)):
                    if match_func(output[i].strip(), patterns) is not None:
                        if re.split(patterns[match], output[i])[-1]:
                            output[i] = re.split(patterns[match],
                                                 output[i])[-1]
                            output_slice = output[i:]
                        else:
                            output_slice = output[i+1:]
                        for j in range(len(output_slice)-1):
                            output_slice[j] = output_slice[j] + '\n'
                        for k in range(len(output_slice)):
                            out += output_slice[k]
                        return match, out
                return match, o

        # Check if the child has terminated
        if utils_misc.wait_for(lambda: not self.is_alive(), 5, 0, 0.1):
            raise aexpect.ExpectProcessTerminatedError(patterns,
                                                       self.get_status(), o)
        else:
            # This shouldn't happen
            raise aexpect.ExpectError(patterns, o)


# Work around for inconsistent builtin closure local reference problem
# across different versions of python
class VirshClosure(object):

    """
    Callable with weak ref. to override ``**dargs`` when calling reference_function
    """

    def __init__(self, reference_function, dict_like_instance):
        """
        Callable reference_function with weak ref dict_like_instance
        """
        if not issubclass(dict_like_instance.__class__, dict):
            raise ValueError("dict_like_instance %s must be dict or subclass"
                             % dict_like_instance.__class__.__name__)
        self.reference_function = reference_function
        self.dict_like_weakref = weakref.ref(dict_like_instance)

    def __call__(self, *args, **dargs):
        """
        Call reference_function with dict_like_instance augmented by **dargs

        :param args: Passthrough to reference_function
        :param dargs: Updates dict_like_instance copy before call
        """
        new_dargs = self.dict_like_weakref()
        if new_dargs is None:
            new_dargs = {}
        for key in new_dargs.keys():
            if key not in dargs.keys():
                dargs[key] = new_dargs[key]
        return self.reference_function(*args, **dargs)


class Virsh(VirshBase):

    """
    Execute libvirt operations, using a new virsh shell each time.
    """

    __slots__ = []

    def __init__(self, *args, **dargs):
        """
        Initialize Virsh instance with persistent options

        :param args: Initial property keys/values
        :param dargs: Initial property keys/values
        """
        super(Virsh, self).__init__(*args, **dargs)
        # Define the instance callables from the contents of this module
        # to avoid using class methods and hand-written aliases
        for sym, ref in globals().items():
            if sym not in NOCLOSE and callable(ref):
                # Adding methods, not properties, so avoid special __slots__
                # handling.  __getattribute__ will still find these.
                self.__super_set__(sym, VirshClosure(ref, self))


class VirshPersistent(Virsh):

    """
    Execute libvirt operations using persistent virsh session.
    """

    __slots__ = ('session_id', 'remote_pwd', 'remote_user', 'uri',
                 'remote_ip', 'ssh_remote_auth', 'unprivileged_user',
                 'readonly')

    # B/c the auto_close of VirshSession is False, we
    # need to manager the ref-count of it manully.
    COUNTERS = {}

    def __init__(self, *args, **dargs):
        super(VirshPersistent, self).__init__(*args, **dargs)
        if self.get('session_id') is None:
            # set_uri does not call when INITIALIZED = False
            # and no session_id passed to super __init__
            self.new_session()
        # increase the counter of session_id in COUNTERS.
        self.counter_increase()

    def __del__(self):
        """
        Clean up any leftover sessions
        """
        self.close_session()

    def counter_increase(self):
        """
        Method to increase the counter to self.a_id in COUNTERS.
        """
        session_id = self.__dict_get__("session_id")
        try:
            counter = self.__class__.COUNTERS[session_id]
        except KeyError, e:
            VirshPersistent.COUNTERS[session_id] = 1
            return
        # increase the counter of session_id.
        VirshPersistent.COUNTERS[session_id] += 1

    def counter_decrease(self):
        """
        Method to decrease the counter to self.a_id in COUNTERS.
        If the counter is less than 1, it means there is no more
        VirshSession instance referring to the session. So close
        this session, and return True.
        Else, decrease the counter in COUNTERS and return False.
        """
        session_id = self.__dict_get__("session_id")
        self.__class__.COUNTERS[session_id] -= 1
        counter = self.__class__.COUNTERS[session_id]
        if counter <= 0:
            # The last reference to this session. Closing it.
            session = VirshSession(a_id=session_id)
            # try nicely first
            session.close()
            if session.is_alive():
                # Be mean, incase it's hung
                session.close(sig=signal.SIGTERM)
            del self.__class__.COUNTERS[session_id]
            return True
        else:
            return False

    def close_session(self):
        """
        If a persistent session exists, close it down.
        """
        try:
            session_id = self.__dict_get__('session_id')
            if session_id:
                try:
                    existing = VirshSession(a_id=session_id)
                    if existing.is_alive():
                        self.counter_decrease()
                except (aexpect.ShellStatusError,
                        aexpect.ShellProcessTerminatedError):
                    # session was already closed
                    pass  # don't check is_alive or update counter
                self.__dict_del__("session_id")
        except KeyError:
            # Allow other exceptions to be raised
            pass  # session was closed already

    def new_session(self):
        """
        Open new session, closing any existing
        """
        # Accessors may call this method, avoid recursion
        virsh_exec = self.__dict_get__('virsh_exec')  # Must exist, can't be None
        uri = self.__dict_get__('uri')  # Must exist, can be None
        readonly = self.__dict_get__('readonly')
        try:
            remote_user = self.__dict_get__('remote_user')
        except KeyError:
            remote_user = "root"
        try:
            remote_pwd = self.__dict_get__('remote_pwd')
        except KeyError:
            remote_pwd = None
        try:
            remote_ip = self.__dict_get__('remote_ip')
        except KeyError:
            remote_ip = None
        try:
            ssh_remote_auth = self.__dict_get__('ssh_remote_auth')
        except KeyError:
            ssh_remote_auth = False
        try:
            unprivileged_user = self.__dict_get__('unprivileged_user')
        except KeyError:
            unprivileged_user = None

        self.close_session()
        # Always create new session
        new_session = VirshSession(virsh_exec, uri, a_id=None,
                                   remote_ip=remote_ip,
                                   remote_user=remote_user,
                                   remote_pwd=remote_pwd,
                                   ssh_remote_auth=ssh_remote_auth,
                                   unprivileged_user=unprivileged_user,
                                   readonly=readonly)
        session_id = new_session.get_id()
        self.__dict_set__('session_id', session_id)

    def set_uri(self, uri):
        """
        Accessor method for 'uri' property, create new session on change
        """
        if not self.INITIALIZED:
            # Allow __init__ to call new_session
            self.__dict_set__('uri', uri)
        else:
            # If the uri is changing
            if self.__dict_get__('uri') != uri:
                self.__dict_set__('uri', uri)
                self.new_session()
            # otherwise do nothing


class VirshConnectBack(VirshPersistent):

    """
    Persistent virsh session connected back from a remote host
    """

    __slots__ = ('remote_ip', )

    def new_session(self):
        """
        Open new remote session, closing any existing
        """

        # Accessors may call this method, avoid recursion
        virsh_exec = self.__dict_get__('virsh_exec')  # Must exist, can't be None
        uri = self.__dict_get__('uri')  # Must exist, can be None
        remote_ip = self.__dict_get__('remote_ip')
        try:
            remote_user = self.__dict_get__('remote_user')
        except KeyError:
            remote_user = 'root'
        try:
            remote_pwd = self.__dict_get__('remote_pwd')
        except KeyError:
            remote_pwd = None
        super(VirshConnectBack, self).close_session()
        new_session = VirshSession(virsh_exec, uri, a_id=None,
                                   remote_ip=remote_ip,
                                   remote_user=remote_user,
                                   remote_pwd=remote_pwd,
                                   ssh_remote_auth=True)
        session_id = new_session.get_id()
        self.__dict_set__('session_id', session_id)

    @staticmethod
    def kosher_args(remote_ip, uri):
        """
        Convenience static method to help validate argument sanity before use

        :param remote_ip: ip/hostname of remote libvirt helper-system
        :param uri: fully qualified libvirt uri of local system, from remote.
        :return: True/False if checks pass or not
        """
        if remote_ip is None or uri is None:
            return False
        all_false = [
            # remote_ip checks
            bool(remote_ip.count("EXAMPLE.COM")),
            bool(remote_ip.count("localhost")),
            bool(remote_ip.count("127.")),
            # uri checks
            uri is None,
            uri is "",
            bool(uri.count("default")),
            bool(uri.count(':///')),
            bool(uri.count("localhost")),
            bool(uri.count("127."))
        ]
        return True not in all_false


# virsh module functions follow (See module docstring for API) #####


def command(cmd, **dargs):
    """
    Interface to cmd function as 'cmd' symbol is polluted.

    :param cmd: Command line to append to virsh command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    :raise: CmdError if non-zero exit status and ignore_status=False
    """

    virsh_exec = dargs.get('virsh_exec', VIRSH_EXEC)
    uri = dargs.get('uri', None)
    debug = dargs.get('debug', False)
    # Caller deals with errors
    ignore_status = dargs.get('ignore_status', True)
    session_id = dargs.get('session_id', None)
    readonly = dargs.get('readonly', False)
    unprivileged_user = dargs.get('unprivileged_user', None)

    # Check if this is a VirshPersistent method call
    if session_id:
        # Retrieve existing session
        session = VirshSession(a_id=session_id)
    else:
        session = None

    if debug:
        logging.debug("Running virsh command: %s", cmd)

    if session:
        # Utilize persistent virsh session, not suit for readonly mode
        if readonly:
            logging.debug("Ignore readonly flag for this virsh session")
        ret = session.cmd_result(cmd, ignore_status, debug)
        # Mark return value with session it came from
        ret.from_session_id = session_id
    else:
        # Normal call to run virsh command
        # Readonly mode
        if readonly:
            cmd = " -r " + cmd

        if uri:
            # uri argument IS being used
            uri_arg = " -c '%s' " % uri
        else:
            uri_arg = " "  # No uri argument being used

        cmd = "%s%s%s" % (virsh_exec, uri_arg, cmd)

        if unprivileged_user:
            # Run cmd as unprivileged user
            cmd = "su - %s -c '%s'" % (unprivileged_user, cmd)

        # Raise exception if ignore_status is False
        ret = utils.run(cmd, verbose=debug, ignore_status=ignore_status)
        # Mark return as not coming from persistent virsh session
        ret.from_session_id = None

    # Always log debug info, if persistent session or not
    if debug:
        logging.debug("status: %s", ret.exit_status)
        logging.debug("stdout: %s", ret.stdout.strip())
        logging.debug("stderr: %s", ret.stderr.strip())

    # Return CmdResult instance when ignore_status is True
    return ret


def domname(dom_id_or_uuid, **dargs):
    """
    Convert a domain id or UUID to domain name

    :param dom_id_or_uuid: a domain id or UUID.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("domname --domain %s" % dom_id_or_uuid, **dargs)


def qemu_monitor_command(name, cmd, **dargs):
    """
    This helps to execute the qemu monitor command through virsh command.

    :param name: Name of monitor domain
    :param cmd: monitor command to execute
    :param dargs: standardized virsh function API keywords
    """

    cmd_qemu_monitor = "qemu-monitor-command %s --hmp \'%s\'" % (name, cmd)
    return command(cmd_qemu_monitor, **dargs)


def setvcpus(name, count, extra="", **dargs):
    """
    Change the number of virtual CPUs in the guest domain.

    :param name: name of vm to affect
    :param count: value for vcpu parameter
    :param options: any extra command options.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object from command
    """
    cmd = "setvcpus %s %s %s" % (name, count, extra)
    return command(cmd, **dargs)


def vcpupin(name, vcpu, cpu_list, options="", **dargs):
    """
    Changes the cpu affinity for respective vcpu.

    :param name: name of domain
    :param vcpu: virtual CPU to modify
    :param cpu_list: physical CPU specification (string)
    :param dargs: standardized virsh function API keywords
    :param options: --live, --current or --config.
    :return: CmdResult object.
    """
    cmd_vcpupin = "vcpupin %s %s %s %s" % (name, vcpu, cpu_list, options)
    return command(cmd_vcpupin, **dargs)


def vcpuinfo(name, **dargs):
    """
    :param name: name of domain
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("vcpuinfo %s" % name, **dargs)


def freecell(cellno=None, options="", **dargs):
    """
    Prints the available amount of memory on the machine or within a NUMA cell.

    :param cellno: number of cell to show.
    :param options: extra argument string to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "freecell "
    if cellno:
        cmd = "%s --cellno %s " % (cmd, cellno)
    cmd = "%s %s" % (cmd, options)
    return command(cmd, **dargs)


def nodeinfo(extra="", **dargs):
    """
    Returns basic information about the node,like number and type of CPU,
    and size of the physical memory.

    :param extra: extra argument string to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd_nodeinfo = "nodeinfo %s" % extra
    return command(cmd_nodeinfo, **dargs)


def nodecpumap(extra="", **dargs):
    """
    Displays the node's total number of CPUs, the number of online
    CPUs and the list of online CPUs.

    :param extra: extra argument string to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nodecpumap %s" % extra
    CmdResult = command(cmd, **dargs)

    return CmdResult


def nodesuspend(target, duration, extra='', **dargs):
    """
    Suspend the host node for a given time duration.

    :param target: Suspend target mem/disk/hybrid.
                   mem(Suspend-to-RAM)
                   disk(Suspend-to-Disk)
                   hybrid(Hybrid-Suspend)
    :param duration: Suspend duration in seconds, at least 60.
    :param extra: extra argument string to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nodesuspend %s %s" % (target, duration)
    if extra:
        cmd += " %s" % extra
    return command(cmd, **dargs)


def canonical_uri(option='', **dargs):
    """
    Return the hypervisor canonical URI.

    :param option: additional option string to pass
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    return command("uri %s" % option, **dargs).stdout.strip()


def hostname(option='', **dargs):
    """
    Return the hypervisor hostname.

    :param option: additional option string to pass
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    return command("hostname %s" % option, **dargs).stdout.strip()


def version(option='', **dargs):
    """
    Return the major version info about what this built from.

    :param option: additional option string to pass
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("version %s" % option, **dargs)


def maxvcpus(option='', **dargs):
    """
    Return the connection vcpu maximum number.

    :param: option: additional option string to pass
    :param: dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "maxvcpus %s" % option
    CmdResult = command(cmd, **dargs)

    return CmdResult


def dom_list(options="", **dargs):
    """
    Return the list of domains.

    :param options: options to pass to list command
    :return: CmdResult object
    """
    return command("list %s" % options, **dargs)


def reboot(name, options="", **dargs):
    """
    Run a reboot command in the target domain.

    :param name: Name of domain.
    :param options: options: options to pass to reboot command
    :return: CmdResult object
    """
    return command("reboot --domain %s %s" % (name, options), **dargs)


def managedsave(name, options="", **dargs):
    """
    Managed save of a domain state.

    :param name: Name of domain to save
    :param options: options: options to pass to list command
    :return: CmdResult object
    """
    return command("managedsave --domain %s %s" % (name, options), **dargs)


def managedsave_remove(name, **dargs):
    """
    Remove managed save of a domain

    :param name: name of managed-saved domain to remove
    :return: CmdResult object
    """
    return command("managedsave-remove --domain %s" % name, **dargs)


def driver(**dargs):
    """
    Return the driver by asking libvirt

    :param dargs: standardized virsh function API keywords
    :return: VM driver name
    """
    # libvirt schme composed of driver + command
    # ref: http://libvirt.org/uri.html
    scheme = urlparse.urlsplit(canonical_uri(**dargs))[0]
    # extract just the driver, whether or not there is a '+'
    return scheme.split('+', 2)[0]


def domstate(name, extra="", **dargs):
    """
    Return the state about a running domain.

    :param name: VM name
    :param extra: command options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("domstate %s %s" % (name, extra), **dargs)


def domid(name_or_uuid, **dargs):
    """
    Return VM's ID.

    :param name_or_uuid: VM name or uuid
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("domid %s" % (name_or_uuid), **dargs)


def dominfo(name, **dargs):
    """
    Return the VM information.

    :param name: VM's name or id,uuid.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("dominfo %s" % (name), **dargs)


def domuuid(name_or_id, **dargs):
    """
    Return the Converted domain name or id to the domain UUID.

    :param name_or_id: VM name or id
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("domuuid %s" % name_or_id, **dargs)


def screenshot(name, filename, **dargs):
    """
    Capture a screenshot of VM's console and store it in file on host

    :param name: VM name
    :param filename: name of host file
    :param dargs: standardized virsh function API keywords
    :return: filename
    """
    # Don't take screenshots of shut-off domains
    if is_dead(name, **dargs):
        return None
    global SCREENSHOT_ERROR_COUNT
    dargs['ignore_status'] = False
    try:
        command("screenshot %s %s" % (name, filename), **dargs)
    except error.CmdError, detail:
        if SCREENSHOT_ERROR_COUNT < 1:
            logging.error("Error taking VM %s screenshot. You might have to "
                          "set take_regular_screendumps=no on your "
                          "tests.cfg config file \n%s.  This will be the "
                          "only logged error message.", name, detail)
        SCREENSHOT_ERROR_COUNT += 1
    return filename


def screenshot_test(name, filename="", options="", **dargs):
    """
    Capture a screenshot of VM's console and store it in file on host

    :param name: VM name or id
    :param filename: name of host file
    :param options: command options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("screenshot %s %s %s" % (name, filename, options), **dargs)


def domblkstat(name, device, option, **dargs):
    """
    Store state of VM into named file.

    :param name: VM's name.
    :param device: VM's device.
    :param option: command domblkstat option.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("domblkstat %s %s %s" % (name, device, option), **dargs)


def dumpxml(name, extra="", to_file="", **dargs):
    """
    Return the domain information as an XML dump.

    :param name: VM name
    :param to_file: optional file to write XML output to
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object.
    """
    cmd = "dumpxml %s %s" % (name, extra)
    result = command(cmd, **dargs)
    if to_file:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    return result


def domifstat(name, interface, **dargs):
    """
    Get network interface stats for a running domain.

    :param name: Name of domain
    :param interface: interface device
    :return: CmdResult object
    """
    return command("domifstat %s %s" % (name, interface), **dargs)


def domjobinfo(name, **dargs):
    """
    Get domain job information.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("domjobinfo %s" % name, **dargs)


def edit(options, **dargs):
    """
    Edit the XML configuration for a domain.

    :param options: virsh edit options string.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("edit %s" % options, **dargs)


def dompmsuspend(name, target, duration=0, **dargs):
    """
    Suspends a running domain using guest OS's power management.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "dompmsuspend %s %s --duration %s" % (name, target, duration)
    return command(cmd, **dargs)


def dompmwakeup(name, **dargs):
    """
     Wakeup a domain that was previously suspended by power management.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("dompmwakeup %s" % name, **dargs)


def domjobabort(name, **dargs):
    """
    Aborts the currently running domain job.

    :param name: VM's name, id or uuid.
    :param dargs: standardized virsh function API keywords
    :return: result from command
    """
    return command("domjobabort %s" % name, **dargs)


def domxml_from_native(info_format, native_file, options=None, **dargs):
    """
    Convert native guest configuration format to domain XML format.

    :param info_format:The command's options. For exmple:qemu-argv.
    :param native_file:Native information file.
    :param options:extra param.
    :param dargs: standardized virsh function API keywords.
    :return: result from command
    """
    cmd = "domxml-from-native %s %s %s" % (info_format, native_file, options)
    return command(cmd, **dargs)


def domxml_to_native(info_format, xml_file, options, **dargs):
    """
    Convert domain XML config to a native guest configuration format.

    :param info_format:The command's options. For exmple:qemu-argv.
    :param xml_file:XML config file.
    :param options:extra param.
    :param dargs: standardized virsh function API keywords
    :return: result from command
    """
    cmd = "domxml-to-native %s %s %s" % (info_format, xml_file, options)
    return command(cmd, **dargs)


def vncdisplay(name, **dargs):
    """
    Output the IP address and port number for the VNC display.

    :param name: VM's name or id,uuid.
    :param dargs: standardized virsh function API keywords.
    :return: result from command
    """
    return command("vncdisplay %s" % name, **dargs)


def is_alive(name, **dargs):
    """
    Return True if the domain is started/alive.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: True operation was successful
    """
    return not is_dead(name, **dargs)


def is_dead(name, **dargs):
    """
    Return True if the domain is undefined or not started/dead.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: True operation was successful
    """
    dargs['ignore_status'] = False
    try:
        state = domstate(name, **dargs).stdout.strip()
    except error.CmdError:
        return True
    if state not in ('running', 'idle', 'paused', 'in shutdown', 'shut off',
                     'crashed', 'pmsuspended', 'no state'):
        logging.debug("State '%s' not known", state)
    if state in ('shut off', 'crashed', 'no state'):
        return True
    return False


def suspend(name, **dargs):
    """
    True on successful suspend of VM - kept in memory and not scheduled.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("suspend %s" % (name), **dargs)


def resume(name, **dargs):
    """
    True on successful moving domain out of suspend

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("resume %s" % (name), **dargs)


def dommemstat(name, extra="", **dargs):
    """
    Store state of VM into named file.

    :param name: VM name
    :param extra: extra options to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("dommemstat %s %s" % (name, extra), **dargs)


def dump(name, path, option="", **dargs):
    """
    Dump the core of a domain to a file for analysis.

    :param name: VM name
    :param path: absolute path to state file
    :param option: command's option.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("dump %s %s %s" % (name, path, option), **dargs)


def save(name, path, options="", **dargs):
    """
    Store state of VM into named file.

    :param name: VM'name, id or uuid.
    :param path: absolute path to state file
    :param options: command's options.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("save %s %s %s" % (name, path, options), **dargs)


def restore(path, options="", **dargs):
    """
    Load state of VM from named file and remove file.

    :param path: absolute path to state file.
    :param options: options for virsh restore.
    :param dargs: standardized virsh function API keywords
    """
    return command("restore %s %s" % (path, options), **dargs)


def start(name, options="", **dargs):
    """
    True on successful start of (previously defined) inactive domain.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object.
    """
    return command("start %s %s" % (name, options), **dargs)


def shutdown(name, options="", **dargs):
    """
    True on successful domain shutdown.

    :param name: VM name
    :param options: options for virsh shutdown.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("shutdown %s %s" % (name, options), **dargs)


def destroy(name, **dargs):
    """
    True on successful domain destruction

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("destroy %s" % (name), **dargs)


def define(xml_path, **dargs):
    """
    Return True on successful domain define.

    :param xml_path: XML file path
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "define --file %s" % xml_path
    logging.debug("Define VM from %s", xml_path)
    return command(cmd, **dargs)


def undefine(name, options=None, **dargs):
    """
    Return cmd result of domain undefine (after shutdown/destroy).

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "undefine %s" % name
    if options is not None:
        cmd += " %s" % options

    logging.debug("Undefine VM %s", name)
    return command(cmd, **dargs)


def remove_domain(name, options=None, **dargs):
    """
    Return True after forcefully removing a domain if it exists.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: True operation was successful
    """
    if domain_exists(name, **dargs):
        if is_alive(name, **dargs):
            destroy(name, **dargs)
        try:
            dargs['ignore_status'] = False
            undefine(name, options, **dargs)
        except error.CmdError, detail:
            logging.error("Undefine VM %s failed:\n%s", name, detail)
            return False
    return True


def domain_exists(name, **dargs):
    """
    Return True if a domain exits.

    :param name: VM name
    :param dargs: standardized virsh function API keywords
    :return: True operation was successful
    """
    dargs['ignore_status'] = False
    try:
        command("domstate %s" % name, **dargs)
        return True
    except error.CmdError, detail:
        logging.warning("VM %s does not exist", name)
        if dargs.get('debug', False):
            logging.warning(str(detail))
        return False


def migrate(name="", dest_uri="", option="", extra="", **dargs):
    """
    Migrate a guest to another host.

    :param name: name of guest on uri.
    :param dest_uri: libvirt uri to send guest to
    :param option: Free-form string of options to virsh migrate
    :param extra: Free-form string of options to follow <domain> <desturi>
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "migrate"
    if option:
        cmd += " %s" % option
    if name:
        cmd += " --domain %s" % name
    if dest_uri:
        cmd += " --desturi %s" % dest_uri
    if extra:
        cmd += " %s" % extra

    return command(cmd, **dargs)


def migrate_setspeed(domain, bandwidth, extra=None, **dargs):
    """
    Set the maximum migration bandwidth (in MiB/s) for
    a domain which is being migrated to another host.

    :param domain: name/uuid/id of guest
    :param bandwidth: migration bandwidth limit in MiB/s
    :param dargs: standardized virsh function API keywords
    """

    cmd = "migrate-setspeed %s %s" % (domain, bandwidth)
    if extra is not None:
        cmd += " %s" % extra
    return command(cmd, **dargs)


def migrate_getspeed(domain, **dargs):
    """
    Get the maximum migration bandwidth (in MiB/s) for
    a domain.

    :param domain: name/uuid/id of guest
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    cmd = "migrate-getspeed %s" % domain
    return command(cmd, **dargs)


def migrate_setmaxdowntime(domain, downtime, extra=None, **dargs):
    """
    Set maximum tolerable downtime of a domain
    which is being live-migrated to another host.

    :param domain: name/uuid/id of guest
    :param downtime: downtime number of live migration
    """
    cmd = "migrate-setmaxdowntime %s %s" % (domain, downtime)
    if extra is not None:
        cmd += " %s" % extra
    return command(cmd, **dargs)


def migrate_compcache(domain, size=None, **dargs):
    """
    Get/set compression cache size for migration.

    :param domain: name/uuid/id of guest
    :param size: compression cache size to be set.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = 'migrate-compcache %s' % domain
    if size is not None:
        cmd += ' --size %s' % size
    return command(cmd, **dargs)


def _adu_device(action, domainarg=None, filearg=None,
                domain_opt=None, file_opt=None,
                flagstr=None, **dargs):
    """
    Private helper for attach, detach, update device commands
    """
    # N/B: Parameter order is significant: RH BZ 1018369
    cmd = action
    if domain_opt is not None:
        cmd += " --domain %s" % domain_opt
    if domainarg is not None:
        cmd += " %s" % domainarg
    if file_opt is not None:
        cmd += " --file %s" % file_opt
    if filearg is not None:
        cmd += " %s" % filearg
    if flagstr is not None:
        cmd += " %s" % flagstr
    return command(cmd, **dargs)


def attach_device(domainarg=None, filearg=None,
                  domain_opt=None, file_opt=None,
                  flagstr=None, **dargs):
    """
    Attach a device using full parameter/argument set.

    :param domainarg: Domain name (first pos. parameter)
    :param filearg: File name (second pos. parameter)
    :param domain_opt: Option to --domain parameter
    :param file_opt: Option to --file parameter
    :param flagstr: string of "--force, --persistent, etc."
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return _adu_device("attach-device", domainarg=domainarg, filearg=filearg,
                       domain_opt=domain_opt, file_opt=file_opt,
                       flagstr=flagstr, **dargs)


def detach_device(domainarg=None, filearg=None,
                  domain_opt=None, file_opt=None,
                  flagstr=None, **dargs):
    """
    Attach a device using full parameter/argument set.

    :param domainarg: Domain name (first pos. parameter)
    :param filearg: File name (second pos. parameter)
    :param domain_opt: Option to --domain parameter
    :param file_opt: Option to --file parameter
    :param flagstr: string of "--force, --persistent, etc."
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return _adu_device("detach-device", domainarg=domainarg, filearg=filearg,
                       domain_opt=domain_opt, file_opt=file_opt,
                       flagstr=flagstr, **dargs)


def update_device(domainarg=None, filearg=None,
                  domain_opt=None, file_opt=None,
                  flagstr="", **dargs):
    """
    Update device from an XML <file>.

    :param domainarg: Domain name (first pos. parameter)
    :param filearg: File name (second pos. parameter)
    :param domain_opt: Option to --domain parameter
    :param file_opt: Option to --file parameter
    :param flagstr: string of "--force, --persistent, etc."
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "update-device"
    return _adu_device("update-device", domainarg=domainarg, filearg=filearg,
                       domain_opt=domain_opt, file_opt=file_opt,
                       flagstr=flagstr, **dargs)


def attach_disk(name, source, target, extra="", **dargs):
    """
    Attach a disk to VM.

    :param name: name of guest
    :param source: source of disk device
    :param target: target of disk device
    :param extra: additional arguments to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "attach-disk --domain %s --source %s --target %s %s"\
        % (name, source, target, extra)
    return command(cmd, **dargs)


def detach_disk(name, target, extra="", **dargs):
    """
    Detach a disk from VM.

    :param name: name of guest
    :param target: target of disk device
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "detach-disk --domain %s --target %s %s" % (name, target, extra)
    return command(cmd, **dargs)


def attach_interface(name, option="", **dargs):
    """
    Attach a NIC to VM.

    :param name: name of guest
    :param option: options to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "attach-interface "

    if name:
        cmd += "--domain %s" % name
    if option:
        cmd += " %s" % option

    return command(cmd, **dargs)


def detach_interface(name, option="", **dargs):
    """
    Detach a NIC to VM.

    :param name: name of guest
    :param option: options to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "detach-interface "

    if name:
        cmd += "--domain %s" % name
    if option:
        cmd += " %s" % option

    return command(cmd, **dargs)


def net_dumpxml(name, extra="", to_file="", **dargs):
    """
    Dump XML from network named param name.

    :param name: Name of a network
    :param extra: Extra parameters to pass to command
    :param to_file: Send result to a file
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "net-dumpxml %s %s" % (name, extra)
    result = command(cmd, **dargs)
    if to_file:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    return result


def net_create(xml_file, extra="", **dargs):
    """
    Create _transient_ network from a XML file.

    :param xml_file: xml defining network
    :param extra: extra parameters to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-create %s %s" % (xml_file, extra), **dargs)


def net_define(xml_file, extra="", **dargs):
    """
    Define network from a XML file, do not start

    :param xml_file: xml defining network
    :param extra: extra parameters to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-define %s %s" % (xml_file, extra), **dargs)


def net_list(options, extra="", **dargs):
    """
    List networks on host.

    :param options: options to pass to command
    :param extra: extra parameters to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-list %s %s" % (options, extra), **dargs)


def net_state_dict(only_names=False, virsh_instance=None, **dargs):
    """
    Return network name to state/autostart/persistent mapping

    :param only_names: When true, return network names as keys and None values
    :param virsh_instance: Call net_list() on this instance instead of module
    :param dargs: standardized virsh function API keywords
    :return: dictionary
    """
    # Using multiple virsh commands in different ways
    dargs['ignore_status'] = False  # force problem detection
    if virsh_instance is not None:
        net_list_result = virsh_instance.net_list("--all", **dargs)
    else:
        net_list_result = net_list("--all", **dargs)
    # If command failed, exception would be raised here
    netlist = net_list_result.stdout.strip().splitlines()
    # First two lines contain table header followed by entries
    # for each network on the host, such as:
    #
    #   Name                 State      Autostart     Persistent
    #  ----------------------------------------------------------
    #   default              active     yes           yes
    #
    # TODO: Double-check first-two lines really are header
    netlist = netlist[2:]
    result = {}
    for line in netlist:
        # Split on whitespace, assume 3 columns
        linesplit = line.split(None, 3)
        name = linesplit[0]
        # Several callers in libvirt_xml only require defined names
        if only_names:
            result[name] = None
            continue
        # Keep search fast & avoid first-letter capital problems
        active = not bool(linesplit[1].count("nactive"))
        autostart = bool(linesplit[2].count("es"))
        if len(linesplit) == 4:
            persistent = bool(linesplit[3].count("es"))
        else:
            # There is no representation of persistent status in output
            # in older libvirt. When libvirt older than 0.10.2 no longer
            # supported, this block can be safely removed.
            try:
                # Rely on net_autostart will raise() if not persistent state
                if autostart:  # Enabled, try enabling again
                    # dargs['ignore_status'] already False
                    if virsh_instance is not None:
                        virsh_instance.net_autostart(name, **dargs)
                    else:
                        net_autostart(name, **dargs)
                else:  # Disabled, try disabling again
                    if virsh_instance is not None:
                        virsh_instance.net_autostart(name, "--disable", **dargs)
                    else:
                        net_autostart(name, "--disable", **dargs)
                # no exception raised, must be persistent
                persistent = True
            except error.CmdError, detail:
                # Exception thrown, could be transient or real problem
                if bool(str(detail.result_obj).count("ransient")):
                    persistent = False
                else:  # A unexpected problem happened, re-raise it.
                    raise
        # Warning: These key names are used by libvirt_xml and test modules!
        result[name] = {'active': active,
                        'autostart': autostart,
                        'persistent': persistent}
    return result


def net_start(network, extra="", **dargs):
    """
    Start network on host.

    :param network: name/parameter for network option/argument
    :param extra: extra parameters to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-start %s %s" % (network, extra), **dargs)


def net_destroy(network, extra="", **dargs):
    """
    Destroy (stop) an activated network on host.

    :param network: name/parameter for network option/argument
    :param extra: extra string to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-destroy %s %s" % (network, extra), **dargs)


def net_undefine(network, extra="", **dargs):
    """
    Undefine a defined network on host.

    :param network: name/parameter for network option/argument
    :param extra: extra string to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-undefine %s %s" % (network, extra), **dargs)


def net_name(uuid, extra="", **dargs):
    """
    Get network name on host.

    :param uuid: network UUID.
    :param extra: extra parameters to pass to command.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-name %s %s" % (uuid, extra), **dargs)


def net_uuid(network, extra="", **dargs):
    """
    Get network UUID on host.

    :param network: name/parameter for network option/argument
    :param extra: extra parameters to pass to command.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-uuid %s %s" % (network, extra), **dargs)


def net_autostart(network, extra="", **dargs):
    """
    Set/unset a network to autostart on host boot

    :param network: name/parameter for network option/argument
    :param extra: extra parameters to pass to command (e.g. --disable)
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("net-autostart %s %s" % (network, extra), **dargs)


def net_info(network, extra="", **dargs):
    """
    Get network information

    :param network: name/parameter for network option/argument
    :param extra: extra parameters to pass to command.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("net-info %s %s" % (network, extra), **dargs)


def net_update(network, update_cmd, section, xml, extra="", **dargs):
    """
    Update parts of an existing network's configuration

    :param network: network name or uuid
    :param update_cmd: type of update (add-first, add-last, delete, or modify)
    :param section: which section of network configuration to update
    :param xml: name of file containing xml
    :param extra: extra parameters to pass to command.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "net-update %s %s %s %s %s" \
          % (network, update_cmd, section, xml, extra)
    return command(cmd, **dargs)


def pool_info(name, **dargs):
    """
    Returns basic information about the storage pool.

    :param name: name of pool
    :param dargs: standardized virsh function API keywords
    """
    cmd = "pool-info %s" % name
    return command(cmd, **dargs)


def pool_destroy(name, **dargs):
    """
    Forcefully stop a given pool.

    :param name: name of pool
    :param dargs: standardized virsh function API keywords
    """
    cmd = "pool-destroy %s" % name
    dargs['ignore_status'] = False
    try:
        command(cmd, **dargs)
        return True
    except error.CmdError, detail:
        logging.error("Failed to destroy pool: %s.", detail)
        return False


def pool_create(xml_file, extra="", **dargs):
    """
    Create a pool from an xml file.

    :param xml_file: file containing an XML pool description
    :param extra: extra parameters to pass to command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("pool-create %s %s" % (extra, xml_file), **dargs)


def pool_create_as(name, pool_type, target, extra="", **dargs):
    """
    Create a pool from a set of args.

    :param name: name of pool
    :param pool_type: storage pool type such as 'dir'
    :param target: libvirt uri to send guest to
    :param extra: Free-form string of options
    :param dargs: standardized virsh function API keywords
    :return: True if pool creation command was successful
    """

    if not name:
        logging.error("Please give a pool name")

    types = ['dir', 'fs', 'netfs', 'disk', 'iscsi', 'logical', 'gluster']

    if pool_type and pool_type not in types:
        logging.error("Only support pool types: %s.", types)
    elif not pool_type:
        pool_type = types[0]

    logging.info("Create %s type pool %s", pool_type, name)
    cmd = "pool-create-as --name %s --type %s --target %s %s" \
          % (name, pool_type, target, extra)
    dargs['ignore_status'] = False
    try:
        command(cmd, **dargs)
        return True
    except error.CmdError, detail:
        logging.error("Failed to create pool: %s.", detail)
        return False


def pool_list(option="", extra="", **dargs):
    """
    Prints the pool information of Host.

    :param option: options given to command

    all
        gives all pool details, including inactive
    inactive
        gives only inactive pool details
    details
        Gives the complete details about the pools

    :param extra: to provide extra options(to enter invalid options)
    """
    return command("pool-list %s %s" % (option, extra), **dargs)


def pool_uuid(name, **dargs):
    """
    Convert a pool name to pool UUID

    :param name: Name of the pool
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("pool-uuid %s" % name, **dargs)


def pool_name(uuid, **dargs):
    """
    Convert a pool UUID to pool name

    :param name: UUID of the pool
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("pool-name %s" % uuid, **dargs)


def pool_refresh(name, **dargs):
    """
    Refresh a pool

    :param name: Name of the pool
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("pool-refresh %s" % name, **dargs)


def pool_delete(name, **dargs):
    """
    Destroy the resources used by a given pool object

    :param name: Name of the pool
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("pool-delete %s" % name, **dargs)


def pool_state_dict(only_names=False, **dargs):
    """
    Return pool name to state/autostart mapping

    :param only_names: When true, return pool names as keys and None values
    :param dargs: standardized virsh function API keywords
    :return: dictionary
    """
    # Using multiple virsh commands in different ways
    dargs['ignore_status'] = False  # force problem detection
    pool_list_result = pool_list("--all", **dargs)
    # If command failed, exception would be raised here
    poollist = pool_list_result.stdout.strip().splitlines()
    # First two lines contain table header followed by entries
    # for each pool on the host, such as:
    #
    #   Name                 State      Autostart
    #  -------------------------------------------
    #   default              active     yes
    #   iscsi-net-pool       active     yes
    #
    # TODO: Double-check first-two lines really are header
    poollist = poollist[2:]
    result = {}
    for line in poollist:
        # Split on whitespace, assume 3 columns
        linesplit = line.split(None, 3)
        name = linesplit[0]
        # Several callers in libvirt_xml only require defined names
        #  TODO: Copied from net_state_dict where this is true, but
        #        as of writing only caller is virsh_pool_create test
        #        which doesn't use this 'feature'.
        if only_names:
            result[name] = None
            continue
        # Keep search fast & avoid first-letter capital problems
        active = not bool(linesplit[1].count("nactive"))
        autostart = bool(linesplit[2].count("es"))

        # Warning: These key names are used by libvirt_xml and test modules!
        result[name] = {'active': active,
                        'autostart': autostart}
    return result


def pool_define_as(name, pool_type, target, extra="", **dargs):
    """
    Define the pool from the arguments

    :param name: Name of the pool to be defined
    :param typ: Type of the pool to be defined

        dir
            file system directory
        disk
            Physical Disk Device
        fs
            Pre-formatted Block Device
        netfs
            Network Exported Directory
        iscsi
            iSCSI Target
        logical
            LVM Volume Group
        mpath
            Multipath Device Enumerater
        scsi
            SCSI Host Adapter

    :param target: libvirt uri to send guest to
    :param extra: Free-form string of options
    :param dargs: standardized virsh function API keywords
    :return: True if pool define command was successful
    """

    types = ['dir', 'fs', 'netfs', 'disk', 'iscsi', 'logical']

    if pool_type and pool_type not in types:
        logging.error("Only support pool types: %s.", types)
    elif not pool_type:
        pool_type = types[0]

    logging.debug("Try to define %s type pool %s", pool_type, name)
    cmd = "pool-define-as --name %s --type %s --target %s %s" \
          % (name, pool_type, target, extra)
    return command(cmd, **dargs)


def pool_start(name, extra="", **dargs):
    """
    Start the defined pool

    :param name: Name of the pool to be started
    :param extra: Free-form string of options
    :param dargs: standardized virsh function API keywords
    :return: True if pool start command was successful
    """
    return command("pool-start %s %s" % (name, extra), **dargs)


def pool_autostart(name, extra="", **dargs):
    """
    Mark for autostart of a pool

    :param name: Name of the pool to be mark for autostart
    :param extra: Free-form string of options
    :param dargs: standardized virsh function API keywords
    :return: True if pool autostart command was successful
    """
    return command("pool-autostart %s %s" % (name, extra), **dargs)


def pool_edit(name, **dargs):
    """
    Edit XML configuration for a storage pool.

    :param name: pool name or uuid
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "pool-edit %s" % name
    return command(cmd, **dargs)


def pool_undefine(name, extra="", **dargs):
    """
    Undefine the given pool

    :param name: Name of the pool to be undefined
    :param extra: Free-form string of options
    :param dargs: standardized virsh function API keywords
    :return: True if pool undefine command was successful
    """
    return command("pool-undefine %s %s" % (name, extra), **dargs)


def pool_build(name, options="", **dargs):
    """
    Build pool.

    :param name: Name of the pool to be built
    :param options: options for pool-build
    """
    return command("pool-build %s %s" % (name, options), **dargs)


def find_storage_pool_sources_as(source_type, options="", **dargs):
    """
    Find potential storage pool sources

    :param source_type: type of storage pool sources to find
    :param options: cmd options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("find-storage-pool-sources-as %s %s"
                   % (source_type, options), **dargs)


def find_storage_pool_sources(source_type, srcSpec, **dargs):
    """
    Find potential storage pool sources

    :param source_type: type of storage pool sources to find
    :param srcSpec: file of source xml to qurey for pools
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("find-storage-pool-sources %s %s"
                   % (source_type, srcSpec), **dargs)


def pool_dumpxml(name, extra="", to_file="", **dargs):
    """
    Return the pool information as an XML dump.

    :param name: pool_name name
    :param to_file: optional file to write XML output to
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    dargs['ignore_status'] = True
    cmd = "pool-dumpxml %s %s" % (name, extra)
    result = command(cmd, **dargs)
    if to_file:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    if result.exit_status:
        raise error.CmdError(cmd, result,
                             "Virsh dumpxml returned non-zero exit status")
    return result.stdout.strip()


def pool_define(xml_path, **dargs):
    """
    Return True on successful pool define.

    :param xml_path: XML file path
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "pool-define --file %s" % xml_path
    return command(cmd, **dargs)


def vol_create(pool_name, xml_file, extra="", **dargs):
    """
    To create the volumes from xml file.

    :param pool_name: Name of the pool to be used
    :param xml_file: file containing an XML vol description
    :param extra: string of extra options
    :return: CmdResult object
    """
    cmd = "vol-create --pool %s --file %s %s" % (pool_name, xml_file, extra)
    return command(cmd, **dargs)


def vol_create_as(volume_name, pool_name, capacity,
                  allocation, frmt, extra="", **dargs):
    """
    To create the volumes on different available pool

    :param name: Name of the volume to be created
    :param pool_name: Name of the pool to be used
    :param capacity: Size of the volume
    :param allocaltion: Size of the volume to be pre-allocated
    :param frmt: volume formats(e.g. raw, qed, qcow2)
    :param extra: Free-form string of options
    :param dargs: standardized virsh function API keywords
    :return: True if pool undefine command was successful
    """

    cmd = "vol-create-as --pool %s" % pool_name
    cmd += " %s --capacity %s" % (volume_name, capacity)

    if allocation:
        cmd += " --allocation %s" % (allocation)
    if frmt:
        cmd += " --format %s" % (frmt)
    if extra:
        cmd += " %s" % (extra)
    return command(cmd, **dargs)


def vol_create_from(pool_name, vol_file, input_vol, input_pool, extra="",
                    **dargs):
    """
    Create a vol, using another volume as input

    :param: pool_name: Name of the pool to create the volume in
    :param: vol_file: XML <file> with the volume definition
    :param: input_vol: Name of the source volume
    :param: input_pool: Name of the pool the source volume is in
    :param: extra: Free-form string of options
    :return: True if volume create successfully
    """
    cmd = ("vol-create-from --pool %s --file %s --vol %s --inputpool %s" %
           (pool_name, vol_file, input_vol, input_pool))
    if extra:
        cmd += " %s" % (extra)
    return command(cmd, **dargs)


def vol_list(pool_name, extra="", **dargs):
    """
    List the volumes for a given pool

    :param pool_name: Name of the pool
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("vol-list %s %s" % (pool_name, extra), **dargs)


def vol_delete(volume_name, pool_name, extra="", **dargs):
    """
    Delete a given volume

    :param volume_name: Name of the volume
    :param pool_name: Name of the pool
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("vol-delete %s %s %s" %
                   (volume_name, pool_name, extra), **dargs)


def vol_key(volume_name, pool_name, extra="", **drags):
    """
    Prints the key of the given volume name

    :param volume_name: Name of the volume
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("vol-key --vol %s --pool %s %s" %
                   (volume_name, pool_name, extra), **drags)


def vol_info(volume_name, pool_name, extra="", **drags):
    """
    Prints the given volume info

    :param volume_name: Name of the volume
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    cmd = "vol-info --vol %s" % volume_name
    if pool_name:
        cmd += " --pool %s" % pool_name
    if extra:
        cmd += " %s" % extra
    return command(cmd, **drags)


def vol_name(volume_key, extra="", **drags):
    """
    Prints the given volume name

    :param volume_name: Name of the volume
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("vol-name --vol %s %s" % (volume_key, extra), **drags)


def vol_path(volume_name, pool_name, extra="", **dargs):
    """
    Prints the give volume path

    :param volume_name: Name of the volume
    :param pool_name: Name of the pool
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("vol-path --vol %s --pool %s %s" %
                   (volume_name, pool_name, extra), **dargs)


def vol_dumpxml(volume_name, pool_name, to_file=None, options="", **dargs):
    """
    Dumps volume details in xml

    :param volume_name: Name of the volume
    :param pool_name: Name of the pool
    :param to_file: path of the file to store the output
    :param options: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    cmd = ('vol-dumpxml --vol %s --pool %s %s' %
           (volume_name, pool_name, options))
    result = command(cmd, **dargs)
    if to_file is not None:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    return result


def vol_pool(volume_name, extra="", **dargs):
    """
    Returns pool name for a given vol-key

    :param volume_name: Name of the volume
    :param extra: Free-form string options
    :param dargs: standardized virsh function API keywords
    :return: returns the output of the command
    """
    return command("vol-pool %s %s" % (volume_name, extra), **dargs)


def vol_clone(volume_name, new_name, pool_name="", extra="", **dargs):
    """
    Clone an existing volume.

    :param volume_name: Name of the original volume
    :param new_name: Clone name
    :param pool_name: Name of the pool
    :param extra: Free-form string options
    :param dargs: Standardized virsh function API keywords
    :return: Returns the output of the command
    """
    cmd = "vol-clone --vol %s --newname %s %s" % (volume_name, new_name, extra)
    if pool_name:
        cmd += " --pool %s" % pool_name
    return command(cmd, **dargs)


def vol_wipe(volume_name, pool_name="", alg="", **dargs):
    """
    Ensure data previously on a volume is not accessible to future reads.

    :param volume_name: Name of the volume
    :param pool_name: Name of the pool
    :param alg: Perform selected wiping algorithm
    :param dargs: Standardized virsh function API keywords
    :return: Returns the output of the command
    """
    cmd = "vol-wipe --vol %s" % volume_name
    if pool_name:
        cmd += " --pool %s" % pool_name
    if alg:
        cmd += " --algorithm %s" % alg
    return command(cmd, **dargs)


def vol_resize(volume_name, capacity, pool_name="", extra="", **dargs):
    """
    Resizes a storage volume.

    :param volume_name: Name of the volume
    :param capacity: New capacity for the volume (default bytes)
    :param pool_name: Name of the pool
    :param extra: Free-form string options
    :param dargs: Standardized virsh function API keywords
    :return: Returns the output of the command
    """
    cmd = "vol-resize --vol %s --capacity %s " % (volume_name, capacity)
    if pool_name:
        cmd += " --pool %s " % pool_name
    if extra:
        cmd += extra
    return command(cmd, **dargs)


def capabilities(option='', **dargs):
    """
    Return output from virsh capabilities command

    :param option: additional options (takes none)
    :param dargs: standardized virsh function API keywords
    """
    return command('capabilities %s' % option, **dargs).stdout.strip()


def nodecpustats(option='', **dargs):
    """
    Returns basic information about the node CPU statistics

    :param option: additional options (takes none)
    :param dargs: standardized virsh function API keywords
    """

    cmd_nodecpustat = "nodecpustats %s" % option
    return command(cmd_nodecpustat, **dargs)


def nodememstats(option='', **dargs):
    """
    Returns basic information about the node Memory statistics

    :param option: additional options (takes none)
    :param dargs: standardized virsh function API keywords
    """

    return command('nodememstats %s' % option, **dargs)


def memtune_set(name, options, **dargs):
    """
    Set the memory controller parameters

    :param domname: VM Name
    :param options: contains the values limit, state and value
    """
    return command("memtune %s %s" % (name, options), **dargs)


def memtune_list(name, **dargs):
    """
    List the memory controller value of a given domain

    :param domname: VM Name
    """
    return command("memtune %s" % (name), **dargs)


def memtune_get(name, key):
    """
    Get the specific memory controller value

    :param domname: VM Name
    :param key: memory controller limit for which the value needed
    :return: the memory value of a key in Kbs
    """
    memtune_output = memtune_list(name)
    memtune_value = re.findall(r"%s\s*:\s+(\S+)" % key, str(memtune_output))
    if memtune_value:
        return int(memtune_value[0])
    else:
        return -1


def help_command(options='', cache=False, **dargs):
    """
    Return list of commands and groups in help command output

    :param options: additional options to pass to help command
    :param cache: Return cached result if True, or refreshed cache if False
    :param dargs: standardized virsh function API keywords
    :return: List of command and group names
    """
    # Combine virsh command list and virsh group list.
    virsh_command_list = help_command_only(options, cache, **dargs)
    virsh_group_list = help_command_group(options, cache, **dargs)
    virsh_command_group = None
    virsh_command_group = virsh_command_list + virsh_group_list
    return virsh_command_group


def help_command_only(options='', cache=False, **dargs):
    """
    Return list of commands in help command output

    :param options: additional options to pass to help command
    :param cache: Return cached result if True, or refreshed cache if False
    :param dargs: standardized virsh function API keywords
    :return: List of command names
    """
    # global needed to support this function's use in Virsh method closure
    global VIRSH_COMMAND_CACHE
    if not VIRSH_COMMAND_CACHE or cache is False:
        VIRSH_COMMAND_CACHE = []
        regx_command_word = re.compile(r"\s+([a-z0-9-]+)\s+")
        for line in help(options, **dargs).stdout.strip().splitlines():
            # Get rid of 'keyword' line
            if line.find("keyword") != -1:
                continue
            mobj_command_word = regx_command_word.search(line)
            if mobj_command_word:
                VIRSH_COMMAND_CACHE.append(mobj_command_word.group(1))
    # Prevent accidental modification of cache itself
    return list(VIRSH_COMMAND_CACHE)


def help_command_group(options='', cache=False, **dargs):
    """
    Return list of groups in help command output

    :param options: additional options to pass to help command
    :param cache: Return cached result if True, or refreshed cache if False
    :param dargs: standardized virsh function API keywords
    :return: List of group names
    """
    # global needed to support this function's use in Virsh method closure
    global VIRSH_COMMAND_GROUP_CACHE, VIRSH_COMMAND_GROUP_CACHE_NO_DETAIL
    if VIRSH_COMMAND_GROUP_CACHE_NO_DETAIL:
        return []
    if not VIRSH_COMMAND_GROUP_CACHE or cache is False:
        VIRSH_COMMAND_GROUP_CACHE = []
        regx_group_word = re.compile(r"[\']([a-zA-Z0-9]+)[\']")
        for line in help(options, **dargs).stdout.strip().splitlines():
            # 'keyword' only exists in group line.
            if line.find("keyword") != -1:
                mojb_group_word = regx_group_word.search(line)
                if mojb_group_word:
                    VIRSH_COMMAND_GROUP_CACHE.append(mojb_group_word.group(1))
    if len(list(VIRSH_COMMAND_GROUP_CACHE)) == 0:
        VIRSH_COMMAND_GROUP_CACHE_NO_DETAIL = True
    # Prevent accidental modification of cache itself
    return list(VIRSH_COMMAND_GROUP_CACHE)


def has_help_command(virsh_cmd, options='', **dargs):
    """
    String match on virsh command in help output command list

    :param virsh_cmd: Name of virsh command or group to look for
    :param options: Additional options to send to help command
    :param dargs: standardized virsh function API keywords
    :return: True/False
    """
    return bool(help_command_only(options, cache=True,
                                  **dargs).count(virsh_cmd))


def has_command_help_match(virsh_cmd, regex, **dargs):
    """
    Regex search on subcommand help output

    :param virsh_cmd: Name of virsh command or group to match help output
    :param regex: regular expression string to match
    :param dargs: standardized virsh function API keywords
    :return: re match object
    """
    command_help_output = help(virsh_cmd, **dargs).stdout.strip()
    return re.search(regex, command_help_output)


def help(virsh_cmd='', **dargs):
    """
    Prints global help, command specific help, or help for a
    group of related commands

    :param virsh_cmd: Name of virsh command or group
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("help %s" % virsh_cmd, **dargs)


def schedinfo(domain, options="", **dargs):
    """
    Show/Set scheduler parameters.

    :param domain: vm's name id or uuid.
    :param options: additional options.
    :param dargs: standardized virsh function API keywords
    """
    cmd = "schedinfo %s %s" % (domain, options)
    return command(cmd, **dargs)


def setmem(domainarg=None, sizearg=None, domain=None,
           size=None, use_kilobytes=False, flagstr="", **dargs):
    """
    Change the current memory allocation in the guest domain.

    :param domainarg: Domain name (first pos. parameter)
    :param sizearg: Memory size in KiB (second. pos. parameter)
    :param domain: Option to --domain parameter
    :param size: Option to --size or --kilobytes parameter
    :param use_kilobytes: True for --kilobytes, False for --size
    :param dargs: standardized virsh function API keywords
    :param flagstr: string of "--config, --live, --current, etc."
    :return: CmdResult instance
    :raise: error.CmdError: if libvirtd is not running
    """

    cmd = "setmem"
    if domainarg is not None:  # Allow testing of ""
        cmd += " %s" % domainarg
    if domain is not None:  # Allow testing of --domain ""
        cmd += " --domain %s" % domain
    if sizearg is not None:  # Allow testing of 0 and ""
        cmd += " %s" % sizearg
    if size is not None:  # Allow testing of --size "" or --size 0
        if use_kilobytes:
            cmd += " --kilobytes %s" % size
        else:
            cmd += " --size %s" % size
    if len(flagstr) > 0:
        cmd += " %s" % flagstr
    return command(cmd, **dargs)


def setmaxmem(domainarg=None, sizearg=None, domain=None,
              size=None, use_kilobytes=False, flagstr="", **dargs):
    """
    Change the maximum memory allocation for the guest domain.

    :param domainarg: Domain name (first pos. parameter)
    :param sizearg: Memory size in KiB (second. pos. parameter)
    :param domain: Option to --domain parameter
    :param size: Option to --size or --kilobytes parameter
    :param use_kilobytes: True for --kilobytes, False for --size
    :param flagstr: string of "--config, --live, --current, etc."
    :return: CmdResult instance
    :raise: error.CmdError: if libvirtd is not running.
    """
    cmd = "setmaxmem"
    if domainarg is not None:  # Allow testing of ""
        cmd += " %s" % domainarg
    if sizearg is not None:  # Allow testing of 0 and ""
        cmd += " %s" % sizearg
    if domain is not None:  # Allow testing of --domain ""
        cmd += " --domain %s" % domain
    if size is not None:  # Allow testing of --size "" or --size 0
        if use_kilobytes:
            cmd += " --kilobytes %s" % size
        else:
            cmd += " --size %s" % size
    if len(flagstr) > 0:
        cmd += " %s" % flagstr
    return command(cmd, **dargs)


def snapshot_create(name, options="", **dargs):
    """
    Create snapshot of domain.

    :param name: name of domain
    :param dargs: standardized virsh function API keywords
    :return: name of snapshot
    """
    cmd = "snapshot-create %s %s" % (name, options)
    return command(cmd, **dargs)


def snapshot_edit(name, options="", **dargs):
    """
    Edit snapshot xml

    :param name: name of domain
    :param options: options of snapshot-edit command
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "snapshot-edit %s %s" % (name, options)
    return command(cmd, **dargs)


def snapshot_create_as(name, options="", **dargs):
    """
    Create snapshot of domain with options.

    :param name: name of domain
    :param options: options of snapshot-create-as
    :param dargs: standardized virsh function API keywords
    :return: name of snapshot
    """
    # CmdResult is handled here, force ignore_status
    cmd = "snapshot-create-as %s" % name
    if options is not None:
        cmd += " %s" % options

    return command(cmd, **dargs)


def snapshot_parent(name, options, **dargs):
    """
    Get name of snapshot parent

    :param name: name of domain
    :param options: options of snapshot-parent
    :param dargs: standardized virsh function API keywords
    :return: name of snapshot
    """
    cmd = "snapshot-parent %s %s" % (name, options)
    return command(cmd, **dargs)


def snapshot_current(name, options="--name", **dargs):
    """
    Get name or xml of current snapshot.

    :param name: name of domain
    :param options: options of snapshot-current, default is --name
    :param dargs: standardized virsh function API keywords
    :return: name or xml of snapshot
    """
    # CmdResult is handled here, force ignore_status
    dargs['ignore_status'] = True
    cmd = "snapshot-current %s" % name
    if options is not None:
        cmd += " %s" % options
    sc_output = command(cmd, **dargs)
    if sc_output.exit_status != 0 and dargs['readonly'] is False:
        raise error.CmdError(cmd, sc_output, "Failed to get current snapshot")
    elif sc_output.exit_status != 0:
        return sc_output

    return sc_output.stdout.strip()


def snapshot_list(name, options=None, **dargs):
    """
    Get list of snapshots of domain.

    :param name: name of domain
    :param options: options of snapshot_list
    :param dargs: standardized virsh function API keywords
    :return: list of snapshot names
    """
    # CmdResult is handled here, force ignore_status
    dargs['ignore_status'] = True
    ret = []
    cmd = "snapshot-list %s" % name
    if options is not None:
        cmd += " %s" % options

    sc_output = command(cmd, **dargs)
    if sc_output.exit_status != 0:
        raise error.CmdError(cmd, sc_output, "Failed to get list of snapshots")

    data = re.findall("\S* *\d*-\d*-\d* \d*:\d*:\d* [+-]\d* \w*",
                      sc_output.stdout)
    for rec in data:
        if not rec:
            continue
        ret.append(re.match("\S*", rec).group())

    return ret


def snapshot_dumpxml(name, snapshot, options=None, to_file=None, **dargs):
    """
    Get dumpxml of snapshot

    :param name: name of domain
    :param snapshot: name of snapshot
    :param options: options of snapshot_list
    :param to_file: optional file to write XML output to
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    cmd = "snapshot-dumpxml %s %s" % (name, snapshot)
    if options is not None:
        cmd += " %s" % options
    result = command(cmd, **dargs)
    if to_file is not None:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()

    return result


def snapshot_info(name, snapshot, **dargs):
    """
    Check snapshot information.

    :param name: name of domain
    :param snapshot: name os snapshot to verify
    :param dargs: standardized virsh function API keywords
    :return: snapshot information dictionary
    """
    # CmdResult is handled here, force ignore_status
    dargs['ignore_status'] = True
    ret = {}
    values = ["Name", "Domain", "Current", "State", "Parent",
              "Children", "Descendants", "Metadata"]

    cmd = "snapshot-info %s %s" % (name, snapshot)
    sc_output = command(cmd, **dargs)
    if sc_output.exit_status != 0:
        raise error.CmdError(cmd, sc_output, "Failed to get snapshot info")

    for val in values:
        data = re.search("(?<=%s:) *\w*" % val, sc_output.stdout)
        if data is None:
            continue
        ret[val] = data.group(0).strip()

    if ret["Parent"] == "-":
        ret["Parent"] = None

    return ret


def snapshot_revert(name, snapshot, options="", **dargs):
    """
    Revert domain state to saved snapshot.

    :param name: name of domain
    :param dargs: standardized virsh function API keywords
    :param snapshot: snapshot to revert to
    :return: CmdResult instance
    """
    cmd = "snapshot-revert %s %s %s" % (name, snapshot, options)
    return command(cmd, **dargs)


def snapshot_delete(name, snapshot, options='', **dargs):
    """
    Remove domain snapshot

    :param name: name of domain
    :param dargs: standardized virsh function API keywords
    :param snapshot: snapshot to delete
    :return: CmdResult instance
    """
    cmd = "snapshot-delete %s %s %s" % (name, snapshot, options)
    return command(cmd, **dargs)


def blockcommit(name, path, options="", **dargs):
    """
    Start a block commit operation.

    :param name: name of domain
    :param options: options of blockcommit
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "blockcommit %s %s" % (name, path)
    if options is not None:
        cmd += " %s" % options

    return command(cmd, **dargs)


def blockpull(name, path, options="", **dargs):
    """
    Start a block pull operation.

    :param name: name of domain
    :param options: options of blockpull
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "blockpull %s %s" % (name, path)
    if options is not None:
        cmd += " %s" % options

    return command(cmd, **dargs)


def blockresize(name, path, size, **dargs):
    """
    Resize block device of domain.

    :param name: name of domain
    :param path: path of block device
    :size: new size of the block device
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("blockresize %s %s %s" % (name, path, size), **dargs)


def domblkinfo(name, device, **dargs):
    """
    Get block device size info for a domain.

    :param name: VM's name or id,uuid.
    :param device: device of VM.
    :param dargs: standardized virsh function API keywords.
    :return: CmdResult object.
    """
    return command("domblkinfo %s %s" % (name, device), **dargs)


def domblklist(name, options=None, **dargs):
    """
    Get domain devices.

    :param name: name of domain
    :param options: options of domblklist.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "domblklist %s" % name
    if options:
        cmd += " %s" % options

    return command(cmd, **dargs)


def domiflist(name, options='', extra='', **dargs):
    """
    Get the domain network devices

    :param name: name of domain
    :param options: options of domiflist
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """

    return command('domiflist %s %s %s' % (name, options, extra), **dargs)


def cpu_stats(name, options, **dargs):
    """
    Display per-CPU and total statistics about domain's CPUs

    :param name: name of domain
    :param options: options of cpu_stats
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "cpu-stats %s" % name
    if options:
        cmd += " %s" % options

    return command(cmd, **dargs)


def change_media(name, device, options, **dargs):
    """
    Change media of CD or floppy drive.

    :param name: VM's name.
    :param path: Fully-qualified path or target of disk device
    :param options: command change_media options.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "change-media %s %s " % (name, device)
    if options:
        cmd += " %s " % options
    return command(cmd, **dargs)


def cpu_compare(xml_file, **dargs):
    """
    Compare host CPU with a CPU described by an XML file

    :param xml_file: file containing an XML CPU description.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("cpu-compare %s" % xml_file, **dargs)


def cpu_baseline(xml_file, **dargs):
    """
    Compute baseline CPU for a set of given CPUs.

    :param xml_file: file containing an XML CPU description.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("cpu-baseline %s" % xml_file, **dargs)


def numatune(name, mode=None, nodeset=None, options=None, **dargs):
    """
    Set or get a domain's numa parameters
    :param name: name of domain
    :param options: options may be live, config and current
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "numatune %s" % name
    if options:
        cmd += " --%s" % options
    if mode:
        cmd += " --mode %s" % mode
    if nodeset:
        cmd += " --nodeset %s" % nodeset

    return command(cmd, **dargs)


def nodedev_reset(name, options="", **dargs):
    """
    Trigger a device reset for device node.

    :param name: device node name to be reset.
    :param options: additional options passed to virsh command
    :param dargs: standardized virsh function API keywords
    :return: cmdresult object.
    """
    cmd = ("nodedev-reset --device %s %s" % (name, options))
    CmdResult = command(cmd, **dargs)

    return CmdResult


def ttyconsole(name, **dargs):
    """
    Print tty console device.

    :param name: name, uuid or id of domain
    :return: CmdResult instance
    """
    return command("ttyconsole %s" % name, **dargs)


def nodedev_dumpxml(name, options="", to_file=None, **dargs):
    """
    Do dumpxml for node device.

    :param name: the name of device.
    :param options: extra options to nodedev-dumpxml cmd.
    :param to_file: optional file to write XML output to.

    :return: Cmdobject of virsh nodedev-dumpxml.
    """
    cmd = ('nodedev-dumpxml %s %s' % (name, options))
    result = command(cmd, **dargs)
    if to_file is not None:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()

    return result


def connect(connect_uri="", options="", **dargs):
    """
    Run a connect command to the uri.

    :param connect_uri: target uri connect to.
    :param options: options to pass to connect command
    :return: CmdResult object.
    """
    return command("connect %s %s" % (connect_uri, options), **dargs)


def domif_setlink(name, interface, state, options=None, **dargs):
    """
    Set network interface stats for a running domain.

    :param name: Name of domain
    :param interface: interface device
    :param state: new state of the device  up or down
    :param options: command options.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "domif-setlink %s %s %s " % (name, interface, state)
    if options:
        cmd += " %s" % options

    return command(cmd, **dargs)


def domif_getlink(name, interface, options=None, **dargs):
    """
    Get network interface stats for a running domain.

    :param name: Name of domain
    :param interface: interface device
    :param options: command options.
    :param dargs: standardized virsh function API keywords
    :return: domif state
    """
    cmd = "domif-getlink %s %s " % (name, interface)
    if options:
        cmd += " %s" % options

    return command(cmd, **dargs)


def nodedev_list(tree=False, cap="", options="", **dargs):
    """
    List the node devices.

    :param tree: list devices in a tree
    :param cap: capability names, separated by comma
    :param options: extra command options.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object.
    """
    cmd = "nodedev-list"
    if tree:
        cmd += " --tree"
    if cap:
        cmd += " --cap %s" % cap
    if options:
        cmd += " %s" % options

    return command(cmd, **dargs)


def nodedev_detach(name, options="", **dargs):
    """
    Detach node device from host.

    :return: cmdresult object.
    """
    cmd = ("nodedev-detach --device %s %s" % (name, options))
    CmdResult = command(cmd, **dargs)

    return CmdResult


def nodedev_dettach(name, options="", **dargs):
    """
    Detach node device from host.

    :return: nodedev_detach(name).
    """
    return nodedev_detach(name, options, **dargs)


def nodedev_reattach(name, options="", **dargs):
    """
    If node device is detached, this action will
    reattach it to its device driver.

    :return: cmdresult object.
    """
    cmd = ("nodedev-reattach --device %s %s" % (name, options))
    CmdResult = command(cmd, **dargs)

    return CmdResult


def vcpucount(name, options="", **dargs):
    """
    Get the vcpu count of guest.

    :param name: name of domain.
    :param options: options for vcpucoutn command.
    :return: CmdResult object.
    """
    cmd = "vcpucount %s %s" % (name, options)
    return command(cmd, **dargs)


def blockcopy(name, path, dest, options="", **dargs):
    """
    Start a block copy operation.

    :param name: name of domain.
    :param path: fully-qualified path or target of disk.
    :param dest: path of the copy to create.
    :param options: options of blockcopy.
    :param dargs: standardized virsh function API keywords.
    :return: CmdResult instance.
    """
    cmd = "blockcopy %s %s %s %s" % (name, path, dest, options)
    return command(cmd, **dargs)


def blockjob(name, path, options="", **dargs):
    """
    Manage active block operations.

    :param name: name of domain.
    :param path: fully-qualified path or target of disk.
    :param options: options of blockjob.
    :param dargs: standardized virsh function API keywords.
    :return: CmdResult instance.
    """
    cmd = "blockjob %s %s %s" % (name, path, options)
    return command(cmd, **dargs)


def domiftune(name, interface, options=None, inbound=None,
              outbound=None, **dargs):
    """
    Set/get parameters of a virtual interface.

    :param name: name of domain.
    :param interface: interface device (MAC Address).
    :param inbound: control domain's incoming traffics.
    :param outbound: control domain's outgoing traffics.
    :param options: options may be live, config and current.
    :param dargs: standardized virsh function API keywords.
    :return: CmdResult instance.
    """
    cmd = "domiftune %s %s" % (name, interface)
    if inbound:
        cmd += "  --inbound %s" % inbound
    if outbound:
        cmd += "  --outbound %s" % outbound
    if options:
        cmd += " --%s" % options
    return command(cmd, **dargs)


def desc(name, options, desc_str, **dargs):
    """
    Show or modify description or title of a domain.

    :param name: name of domain.
    :param options: options for desc command.
    :param desc_str: new desc message.
    :param dargs: standardized virsh function API keywords.
    :return: CmdResult object.
    """
    if desc_str:
        options = options + " \"%s\"" % desc_str
    cmd = "desc %s %s" % (name, options)
    return command(cmd, **dargs)


def autostart(name, options, **dargs):
    """
    Autostart a domain

    :return: cmdresult object.
    """
    cmd = ("autostart %s %s" % (name, options))
    CmdResult = command(cmd, **dargs)

    return CmdResult


def node_memtune(shm_pages_to_scan=None, shm_sleep_millisecs=None,
                 shm_merge_across_nodes=None, options=None, **dargs):
    """
    Get or set node memory parameters.

    :param options: Extra options to virsh.
    :param shm-pages-to-scan: Pages to scan.
    :param shm-sleep-millisecs: Sleep time (ms).
    :param shm-merge-across-nodes: Merge across nodes.
    :param dargs: Standardized virsh function API keywords.
    :return: CmdResult instance
    """
    cmd = "node-memory-tune"
    if shm_pages_to_scan:
        cmd += " --shm-pages-to-scan %s" % shm_pages_to_scan
    if shm_sleep_millisecs:
        cmd += " --shm-sleep-millisecs %s" % shm_sleep_millisecs
    if shm_merge_across_nodes:
        cmd += " --shm-merge-across-nodes %s" % shm_merge_across_nodes
    if options:
        cmd += " --%s" % options

    return command(cmd, **dargs)


def iface_list(extra="", **dargs):
    """
    List physical host interfaces.

    :param extra: Free-form string of options
    :param dargs: Standardized virsh functiont API keywords
    :return: CmdResult object
    """
    return command("iface-list %s" % extra, **dargs)


def iface_define(xml_path, **dargs):
    """
    Define (but don't start) a physical host interface from an XML file.

    :param xml_path: XML file path
    :param dargs: Standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-define --file %s" % xml_path, **dargs)


def iface_start(iface, **dargs):
    """
    Start a physical host interface.

    :param iface: Interface name or MAC address
    :param dargs: Standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-start %s" % iface, **dargs)


def iface_destroy(iface, **dargs):
    """
    Destroy a physical host interface.

    :param iface: Interface name or MAC address
    :param dargs: Standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-destroy %s" % iface, **dargs)


def iface_undefine(iface, **dargs):
    """
    Undefine a physical host interface (remove it from configuration).

    :param iface: Interface name or MAC address
    :param dargs: Standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-undefine %s" % iface, **dargs)


def iface_dumpxml(iface, extra="", to_file="", **dargs):
    """
    Interface information in XML.

    :param iface: Interface name or MAC address
    :param extra: Free-form string of options
    :param to_file: Optional file to write xml
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    dargs['ignore_status'] = True
    cmd = "iface-dumpxml %s %s" % (iface, extra)
    result = command(cmd, **dargs)
    if to_file:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    if result.exit_status:
        raise error.CmdError(cmd, result,
                             "Dumpxml returned non-zero exit status")
    return result.stdout.strip()


def iface_name(mac, **dargs):
    """
    Convert an interface MAC address to interface name.

    :param mac: Interface MAC address
    :param dargs: Standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-name %s" % mac, **dargs)


def iface_mac(name, **dargs):
    """
    Convert an interface name to interface MAC address.

    :param name: Interface name
    :param dargs: Standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-mac %s" % name, **dargs)


def iface_edit(iface, **dargs):
    """
    Edit XML configuration for a physical host interface.

    :param iface: Interface name or MAC address
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    return command("iface-edit %s" % iface, **dargs)


def iface_bridge(iface, bridge, extra="", **dargs):
    """
    Create a bridge device and attach an existing network device to it.

    :param iface: Interface name or MAC address
    :param bridge: New bridge device name
    :param extra: Free-form string of options
    :param dargs: Standardized virsh functiont API keywords
    :return: CmdResult object
    """
    return command("iface-bridge %s %s %s" % (iface, bridge, extra), **dargs)


def iface_unbridge(bridge, extra="", **dargs):
    """
    Undefine a bridge device after detaching its slave device.

    :param bridge: Current bridge device name
    :param extra: Free-form string of options
    :param dargs: Standardized virsh functiont API keywords
    :return: CmdResult object
    """
    return command("iface-unbridge %s %s" % (bridge, extra), **dargs)


def iface_begin(**dargs):
    """
    Create a snapshot of current interfaces settings

    :param: dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("iface-begin", **dargs)


def iface_commit(**dargs):
    """
    Commit changes made since iface-begin and free restore point

    :param: dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("iface-commit", **dargs)


def iface_rollback(**dargs):
    """
    Rollback to previous saved configuration created via iface-begin

    :param: dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    return command("iface-rollback", **dargs)


def emulatorpin(name, cpulist=None, options=None, **dargs):
    """
    Control or query domain emulator affinity
    :param name: name of domain
    :param cpulist: a list of physical CPU numbers
    :param options: options may be live, config and current
    :param dargs: standardized virsh function API keywords
    :return: CmdResult instance
    """
    cmd = "emulatorpin %s" % name
    if options:
        cmd += " --%s" % options
    if cpulist:
        cmd += " --cpulist %s" % cpulist

    return command(cmd, **dargs)


def secret_list(options="", **dargs):
    """
    Get list of secret.

    :param options: the option may be '--ephemeral'
    :param dargs: standardized virsh function API keywords
    :return: list of secret
    """
    # CmdResult is handled here, force ignore_status
    cmd = "secret-list %s" % options
    return command(cmd, **dargs)


def secret_define(xml_file, options=None, **dargs):
    """
    Return True on successful secret define.

    :param xml_file: secret XML file
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "secret-define --file %s" % xml_file
    if options is not None:
        cmd += " %s" % options
    logging.debug("Define secret from %s", xml_file)
    return command(cmd, **dargs)


def secret_undefine(uuid, options=None, **dargs):
    """
    Return cmd result of secret undefine.

    :param uuid: secret UUID
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "secret-undefine %s" % uuid
    if options is not None:
        cmd += " %s" % options

    logging.debug("Undefine secret %s", uuid)
    return command(cmd, **dargs)


def secret_dumpxml(uuid, to_file="", options=None, **dargs):
    """
    Return the secret information as an XML dump.

    :param uuid: secret UUID
    :param to_file: optional file to write XML output to
    :param dargs: standardized virsh function API keywords
    :return: standard output from command
    """
    dargs['ignore_status'] = True
    cmd = "secret-dumpxml %s" % uuid
    if options is not None:
        cmd += " %s" % options
    result = command(cmd, **dargs)
    if to_file:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    if result.exit_status:
        raise error.CmdError(cmd, result,
                             "Virsh secret-dumpxml returned \
                             non-zero exit status")
    return result


def secret_get_value(uuid, options=None, **dargs):
    """
    Get a secret value

    :param uuid: secret UUID
    :return: CmdResult object.
    """
    cmd = "secret-get-value --secret %s" % uuid
    if options:
        cmd += " --%s" % options

    return command(cmd, **dargs)


def secret_set_value(uuid, base64, options=None, **dargs):
    """
    Set a secret value

    :param uuid: secret UUID
    :param base64: base64-encoded secret value
    :return: CmdResult object.
    """
    cmd = "secret-set-value --secret %s" % uuid
    if base64:
        cmd += " --base64 %s" % base64
    if options:
        cmd += " --%s" % options
    return command(cmd, **dargs)


def nodedev_create(xml_file, options=None, **dargs):
    """
    Return cmd result of the device to be created by an XML file

    :param xml_file: device XML file
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nodedev-create %s" % xml_file
    if options is not None:
        cmd += " %s" % options

    logging.debug("Create the device from %s", xml_file)
    return command(cmd, **dargs)


def nodedev_destroy(dev_name, options=None, **dargs):
    """
    Return cmd result of the device to be destroyed

    :param dev_name: name of the device
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nodedev-destroy %s" % dev_name
    if options is not None:
        cmd += " %s" % options

    logging.debug("Destroy the device %s on the node", dev_name)
    return command(cmd, **dargs)


def domfstrim(name, minimum=None, mountpoint=None, options="", **dargs):
    """
    Do fstrim on domain's mounted filesystems

    :param name: name of domain
    :param options: options maybe --minimum <number>, --mountpoint <string>
    :return: CmdResult object
    """
    cmd = "domfstrim %s" % name
    if minimum is not None:
        cmd += " --minimum %s" % minimum
    if mountpoint is not None:
        cmd += " --mountpoint %s" % mountpoint

    cmd += " %s" % options
    return command(cmd, **dargs)


def nwfilter_dumpxml(name, options="", to_file=None, **dargs):
    """
    Do dumpxml for network filter.

    :param name: the name or uuid of filter.
    :param options: extra options to nwfilter-dumpxml cmd.
    :param to_file: optional file to write XML output to.
    :param dargs: standardized virsh function API keywords
    :return: Cmdobject of virsh nwfilter-dumpxml.
    """
    cmd = ('nwfilter-dumpxml %s %s' % (name, options))
    result = command(cmd, **dargs)
    if to_file is not None:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()

    return result


def nwfilter_define(xml_file, options="", **dargs):
    """
    Return True on successful network filter define.

    :param xml_file: network filter XML file
    :param options: extra options to nwfilter-define cmd.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nwfilter-define --file %s %s" % (xml_file, options)
    return command(cmd, **dargs)


def nwfilter_undefine(name, options="", **dargs):
    """
    Return cmd result of network filter undefine.

    :param name: network filter name or uuid
    :param options: extra options to nwfilter-undefine cmd.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nwfilter-undefine %s %s" % (name, options)
    return command(cmd, **dargs)


def nwfilter_list(options="", **dargs):
    """
    Get list of network filters.

    :param options: extra options
    :param dargs: standardized virsh function API keywords
    :return: list of network filters
    """
    cmd = "nwfilter-list %s" % options
    result = command(cmd, **dargs)

    return result


def nwfilter_edit(name, options="", **dargs):
    """
    Edit the XML configuration for a network filter.

    :param name: network filter name or uuid.
    :param options: extra options to nwfilter-edit cmd.
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "nwfilter-edit %s %s" % (name, options)
    return command(cmd, **dargs)


def cd(dir_path, options="", **dargs):
    """
    Run cd command in virsh interactive session.

    :param dir_path: dir path string
    :param options: extra options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "cd --dir %s %s" % (dir_path, options)
    return command(cmd, **dargs)


def pwd(options="", **dargs):
    """
    Run pwd command in virsh session.

    :param options: extra options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "pwd %s" % options
    return command(cmd, **dargs)


def echo(echo_str, options="", **dargs):
    """
    Run echo command in virsh session.

    :param echo_str: the echo string
    :param options: extra options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "echo %s %s" % (echo_str, options)
    return command(cmd, **dargs)


def exit(**dargs):
    """
    Run exit command in virsh session.

    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "exit"
    return command(cmd, **dargs)


def quit(**dargs):
    """
    Run quit command in virsh session.

    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "quit"
    return command(cmd, **dargs)


def sendkey(name, options="", **dargs):
    """
    Send keycodes to the guest
    :param name: name of domain
    :param codeset: the codeset of keycodes
    :param keycode: the key code
    :return: CmdResult object
    """
    cmd = "send-key %s %s" % (name, options)
    return command(cmd, **dargs)


def create(name, options="", **dargs):
    """
    Create guest from xml

    :param name: name of domain
    :param options: --paused
    :return: CmdResult object
    """
    cmd = "create %s %s" % (name, options)
    return command(cmd, **dargs)


def sysinfo(options="", **dargs):
    """
    Return the hypervisor sysinfo xml.

    :param options: extra options
    :return: CmdResult object
    """
    cmd = "sysinfo %s" % options
    return command(cmd, **dargs)


def reset(name, **dargs):
    """
    Reset a domain

    :param name: name of domain
    :return: CmdResult object
    """
    cmd = "reset %s" % name
    return command(cmd, **dargs)


def domdisplay(name, options="", **dargs):
    """
    Get domain display connection URI

    :param name: name of domain
    :param options: options of domdisplay
    :return: CmdResult object
    """
    cmd = "domdisplay %s %s" % (name, options)
    return command(cmd, **dargs)


def domblkerror(name, **dargs):
    """
    Show errors on block devices

    :param name: name of domain
    :return: CmdResult object
    """
    return command("domblkerror %s" % name, **dargs)


def domcontrol(name, options="", **dargs):
    """
    Return domain control interface state.

    :param name: name of domain
    :param options: extra options
    :return: CmdResult object
    """
    cmd = "domcontrol %s %s" % (name, options)
    return command(cmd, **dargs)


def save_image_dumpxml(state_file, options="", to_file="", **dargs):
    """
    Dump xml from saved state file

    :param state_file: saved state file to read
    :param options: extra options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "save-image-dumpxml %s %s" % (state_file, options)
    result = command(cmd, **dargs)
    if to_file:
        result_file = open(to_file, 'w')
        result_file.write(result.stdout.strip())
        result_file.close()
    return result


def save_image_define(state_file, xmlfile, options="", **dargs):
    """
    Redefine the XML for a domain's saved state file

    :param state_file: saved state file to modify
    :param xmlfile: filename containing updated XML for the target
    :param options: extra options
    :param dargs: standardized virsh function API keywords
    :return: CmdResult object
    """
    cmd = "save-image-define %s %s %s" % (state_file, xmlfile, options)
    return command(cmd, **dargs)


def inject_nmi(name, options="", **dargs):
    """
    Inject NMI to the guest

    :param name: domain name
    :param options: extra options
    """
    cmd = "inject-nmi %s %s" % (name, options)
    return command(cmd, **dargs)


def vol_download(name, dfile, options="", **dargs):
    """
    Download volume contents to a file

    :param name: name of volume
    :param dfile: file path that will download to
    :param options: pool name, offset and length
    :return: CmdResult object
    """
    cmd = "vol-download %s %s %s" % (name, dfile, options)
    return command(cmd, **dargs)


def vol_upload(name, dfile, options="", **dargs):
    """
    Upload file contents to a volume

    :param name: name of volume
    :param dfile: file path that will upload from
    :param options: pool name, offset and length
    :return: CmdResult object
    """
    cmd = "vol-upload %s %s %s" % (name, dfile, options)
    return command(cmd, **dargs)

########NEW FILE########
__FILENAME__ = virsh_unittest
#!/usr/bin/python

import unittest
import logging

import common
from autotest.client import utils


class bogusVirshFailureException(unittest.TestCase.failureException):

    def __init__(self, *args, **dargs):
        self.virsh_args = args
        self.virsh_dargs = dargs

    def __str__(self):
        msg = ("Codepath under unittest attempted call to un-mocked virsh"
               " method, with args: '%s' and dargs: '%s'"
               % (self.virsh_args, self.virsh_dargs))
        return msg


def FakeVirshFactory(preserve=None):
    """
    Return Virsh() instance with methods to raise bogusVirshFailureException.

    Users of this class should override methods under test on instance.
    :param preserve: List of symbol names NOT to modify, None for all
    """
    import virsh

    def raise_bogusVirshFailureException(*args, **dargs):
        raise bogusVirshFailureException()

    if preserve is None:
        preserve = []
    fake_virsh = virsh.Virsh(virsh_exec='/bin/false',
                             uri='qemu:///system', debug=True,
                             ignore_status=True)
    # Make all virsh commands throw an exception by calling it
    for symbol in dir(virsh):
        # Get names of just closure functions by Virsh class
        if symbol in virsh.NOCLOSE + preserve:
            continue
        if isinstance(getattr(fake_virsh, symbol), virsh.VirshClosure):
            xcpt = lambda *args, **dargs: raise_bogusVirshFailureException()
            # fake_virsh is a propcan, can't use setattr.
            fake_virsh.__super_set__(symbol, xcpt)
    return fake_virsh


class ModuleLoad(unittest.TestCase):
    import virsh


class ConstantsTest(ModuleLoad):

    def test_ModuleLoad(self):
        self.assertTrue(hasattr(self.virsh, 'NOCLOSE'))
        self.assertTrue(hasattr(self.virsh, 'SCREENSHOT_ERROR_COUNT'))
        self.assertTrue(hasattr(self.virsh, 'VIRSH_COMMAND_CACHE'))
        self.assertTrue(hasattr(self.virsh, 'VIRSH_EXEC'))


class TestVirshClosure(ModuleLoad):

    @staticmethod
    def somefunc(*args, **dargs):
        return (args, dargs)

    class SomeClass(dict):

        def somemethod(self):
            return "foobar"

    def test_init(self):
        # save some typing
        VC = self.virsh.VirshClosure
        # self is guaranteed to be not dict-like
        self.assertRaises(ValueError, VC, self.somefunc, self)
        self.assertRaises(ValueError, VC, lambda: None, self)

    def test_args(self):
        # save some typing
        VC = self.virsh.VirshClosure
        tcinst = self.SomeClass()
        vcinst = VC(self.somefunc, tcinst)
        args, dargs = vcinst('foo')
        self.assertEqual(len(args), 1)
        self.assertEqual(args[0], 'foo')
        self.assertEqual(len(dargs), 0)

    def test_fake_virsh(self):
        fake_virsh = FakeVirshFactory()
        for symb in dir(self.virsh):
            if symb in self.virsh.NOCLOSE:
                continue
            value = fake_virsh.__super_get__(symb)
            self.assertRaises(unittest.TestCase.failureException, value)

    def test_dargs(self):
        # save some typing
        VC = self.virsh.VirshClosure
        tcinst = self.SomeClass(foo='bar')
        vcinst = VC(self.somefunc, tcinst)
        args, dargs = vcinst()
        self.assertEqual(len(args), 0)
        self.assertEqual(len(dargs), 1)
        self.assertEqual(dargs.keys(), ['foo'])
        self.assertEqual(dargs.values(), ['bar'])

    def test_args_and_dargs(self):
        # save some typing
        VC = self.virsh.VirshClosure
        tcinst = self.SomeClass(foo='bar')
        vcinst = VC(self.somefunc, tcinst)
        args, dargs = vcinst('foo')
        self.assertEqual(len(args), 1)
        self.assertEqual(args[0], 'foo')
        self.assertEqual(len(dargs), 1)
        self.assertEqual(dargs.keys(), ['foo'])
        self.assertEqual(dargs.values(), ['bar'])

    def test_args_dargs_subclass(self):
        # save some typing
        VC = self.virsh.VirshClosure
        tcinst = self.SomeClass(foo='bar')
        vcinst = VC(self.somefunc, tcinst)
        args, dargs = vcinst('foo')
        self.assertEqual(len(args), 1)
        self.assertEqual(args[0], 'foo')
        self.assertEqual(len(dargs), 1)
        self.assertEqual(dargs.keys(), ['foo'])
        self.assertEqual(dargs.values(), ['bar'])

    def test_update_args_dargs_subclass(self):
        # save some typing
        VC = self.virsh.VirshClosure
        tcinst = self.SomeClass(foo='bar')
        vcinst = VC(self.somefunc, tcinst)
        args, dargs = vcinst('foo')
        self.assertEqual(len(args), 1)
        self.assertEqual(args[0], 'foo')
        self.assertEqual(len(dargs), 1)
        self.assertEqual(dargs.keys(), ['foo'])
        self.assertEqual(dargs.values(), ['bar'])
        # Update dictionary
        tcinst['sna'] = 'fu'
        # Is everything really the same?
        args, dargs = vcinst('foo', 'baz')
        self.assertEqual(len(args), 2)
        self.assertEqual(args[0], 'foo')
        self.assertEqual(args[1], 'baz')
        self.assertEqual(len(dargs), 2)
        self.assertEqual(dargs['foo'], 'bar')
        self.assertEqual(dargs['sna'], 'fu')

    def test_multi_inst(self):
        # save some typing
        VC1 = self.virsh.VirshClosure
        VC2 = self.virsh.VirshClosure
        tcinst1 = self.SomeClass(darg1=1)
        tcinst2 = self.SomeClass(darg1=2)
        vcinst1 = VC1(self.somefunc, tcinst1)
        vcinst2 = VC2(self.somefunc, tcinst2)
        args1, dargs1 = vcinst1(1)
        args2, dargs2 = vcinst2(2)
        self.assertEqual(len(args1), 1)
        self.assertEqual(len(args2), 1)
        self.assertEqual(args1[0], 1)
        self.assertEqual(args2[0], 2)
        self.assertEqual(len(dargs1), 1)
        self.assertEqual(len(dargs2), 1)
        self.assertEqual(dargs1['darg1'], 1)
        self.assertEqual(dargs2['darg1'], 2)


class ConstructorsTest(ModuleLoad):

    def test_VirshBase(self):
        vb = self.virsh.VirshBase()
        del vb  # keep pylint happy

    def test_Virsh(self):
        v = self.virsh.Virsh()
        del v  # keep pylint happy

    def test_VirshPersistent(self):
        test_virsh = self.virsh.Virsh()
        if test_virsh['virsh_exec'] == '/bin/true':
            return
        else:
            logging.disable(logging.INFO)
            vp = self.virsh.VirshPersistent()
            vp.close_session()  # Make sure session gets cleaned up

    def TestVirshClosure(self):
        class MyDict(dict):
            pass
        vc = self.virsh.VirshClosure(None, MyDict())
        del vc  # keep pylint happy


# Ensure the following tests ONLY run if a valid virsh command exists #####
class ModuleLoadCheckVirsh(unittest.TestCase):
    import virsh

    def run(self, *args, **dargs):
        test_virsh = self.virsh.Virsh()
        if test_virsh['virsh_exec'] == '/bin/true':
            return  # Don't run any tests, no virsh executable was found
        else:
            super(ModuleLoadCheckVirsh, self).run(*args, **dargs)


class SessionManagerTest(ModuleLoadCheckVirsh):

    def test_del_VirshPersistent(self):
        """
        Unittest for __del__ of VirshPersistent.

        This test makes sure the __del__ method of VirshPersistent works
        well in `del vp_instance`.
        """
        vp = self.virsh.VirshPersistent()
        virsh_exec = vp.virsh_exec
        self.assertTrue(utils.process_is_alive(virsh_exec))
        del vp
        self.assertFalse(utils.process_is_alive(virsh_exec))

    def test_VirshSession(self):
        """
        Unittest for VirshSession.

        This test use VirshSession over VirshPersistent with auto_close=True.
        """
        virsh_exec = self.virsh.Virsh()['virsh_exec']
        # Build a VirshSession object.
        session_1 = self.virsh.VirshSession(virsh_exec, auto_close=True)
        self.assertTrue(utils.process_is_alive(virsh_exec))
        del session_1
        self.assertFalse(utils.process_is_alive(virsh_exec))

    def test_VirshPersistent(self):
        """
        Unittest for session manager of VirshPersistent.
        """
        virsh_exec = self.virsh.Virsh()['virsh_exec']
        vp_1 = self.virsh.VirshPersistent()
        self.assertTrue(utils.process_is_alive(virsh_exec))
        # Init the vp_2 with same params of vp_1.
        vp_2 = self.virsh.VirshPersistent(**vp_1)
        # Make sure vp_1 and vp_2 are refer to the same session.
        self.assertEqual(vp_1.session_id, vp_2.session_id)

        del vp_1
        # Make sure the session is not closed when vp_2 still refer to it.
        self.assertTrue(utils.process_is_alive(virsh_exec))
        del vp_2
        # Session was closed since no other VirshPersistent refer to it.
        self.assertFalse(utils.process_is_alive(virsh_exec))


class VirshHasHelpCommandTest(ModuleLoadCheckVirsh):

    def setUp(self):
        # subclasses override self.virsh
        self.VIRSH_COMMAND_CACHE = self.virsh.VIRSH_COMMAND_CACHE

    def test_false_command(self):
        self.assertFalse(self.virsh.has_help_command('print'))
        self.assertFalse(self.virsh.has_help_command('Commands:'))
        self.assertFalse(self.virsh.has_help_command('dom'))
        self.assertFalse(self.virsh.has_help_command('pool'))

    def test_true_command(self):
        self.assertTrue(self.virsh.has_help_command('uri'))
        self.assertTrue(self.virsh.has_help_command('help'))
        self.assertTrue(self.virsh.has_help_command('list'))

    def test_no_cache(self):
        self.VIRSH_COMMAND_CACHE = None
        self.assertTrue(self.virsh.has_help_command('uri'))
        self.VIRSH_COMMAND_CACHE = []
        self.assertTrue(self.virsh.has_help_command('uri'))

    def test_subcommand_help(self):
        regex = r'\s+\[--command\]\s+\<string\>\s+'
        self.assertTrue(self.virsh.has_command_help_match('help', regex))
        self.assertFalse(self.virsh.has_command_help_match('uri', regex))

    def test_groups_in_commands(self):
        # groups will be empty in older libvirt, but test will still work
        groups = self.virsh.help_command_group(cache=True)
        groups_set = set(groups)
        commands = self.virsh.help_command_only(cache=True)
        commands_set = set(commands)
        grp_cmd = self.virsh.help_command(cache=True)
        grp_cmd_set = set(grp_cmd)
        # No duplicates check
        self.assertEqual(len(commands_set), len(commands))
        self.assertEqual(len(groups_set), len(groups))
        self.assertEqual(len(grp_cmd_set), len(grp_cmd))
        # No groups in commands or commands in groups
        self.assertEqual(len(groups_set & commands_set), 0)
        # Groups and Commands in help_command
        self.assertTrue(len(grp_cmd_set), len(commands_set) + len(groups_set))


class VirshHelpCommandTest(ModuleLoadCheckVirsh):

    def test_cache_command(self):
        l1 = self.virsh.help_command(cache=True)
        l2 = self.virsh.help_command()
        l3 = self.virsh.help_command()
        self.assertEqual(l1, l2)
        self.assertEqual(l2, l3)
        self.assertEqual(l3, l1)


class VirshClassHasHelpCommandTest(VirshHasHelpCommandTest):

    def setUp(self):
        logging.disable(logging.INFO)
        super(VirshClassHasHelpCommandTest, self).setUp()
        self.virsh = self.virsh.Virsh(debug=False)


class VirshPersistentClassHasHelpCommandTest(VirshHasHelpCommandTest):

    def setUp(self):
        logging.disable(logging.INFO)
        super(VirshPersistentClassHasHelpCommandTest, self).setUp()
        self.VirshPersistent = self.virsh.VirshPersistent
        self.virsh = self.VirshPersistent(debug=False)
        self.assertTrue(utils.process_is_alive(self.virsh.virsh_exec))

    def test_recycle_session(self):
        # virsh can be used as a dict of it's properties
        another = self.VirshPersistent(**self.virsh)
        self.assertEqual(self.virsh.session_id, another.session_id)

    def tearDown(self):
        self.assertTrue(utils.process_is_alive(self.virsh.virsh_exec))
        self.virsh.close_session()
        self.assertFalse(utils.process_is_alive(self.virsh.virsh_exec))


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = virt_vm
import logging
import time
import glob
import os
import re
import socket
from autotest.client import utils
from autotest.client.shared import error
import utils_misc
import utils_net
import remote
import aexpect
import traceback
import ppm_utils
import data_dir


class VMError(Exception):
    pass


class VMCreateError(VMError):

    def __init__(self, cmd, status, output):
        VMError.__init__(self, cmd, status, output)
        self.cmd = cmd
        self.status = status
        self.output = output

    def __str__(self):
        return ("VM creation command failed:    %r    (status: %s,    "
                "output: %r)" % (self.cmd, self.status, self.output))


class VMStartError(VMError):

    def __init__(self, name, reason=None):
        VMError.__init__(self, name, reason)
        self.name = name
        self.reason = reason

    def __str__(self):
        msg = "VM '%s' failed to start" % self.name
        if self.reason is not None:
            msg += ": %s" % self.reason
        return msg


class VMConfigMissingError(VMError):

    def __init__(self, name, config):
        VMError.__init__(self, name, config)
        self.name = name
        self.config = config

    def __str__(self):
        return "Missing config '%s' for VM %s" % (self.config, self.name)


class VMHashMismatchError(VMError):

    def __init__(self, actual, expected):
        VMError.__init__(self, actual, expected)
        self.actual_hash = actual
        self.expected_hash = expected

    def __str__(self):
        return ("CD image hash (%s) differs from expected one (%s)" %
                (self.actual_hash, self.expected_hash))


class VMImageMissingError(VMError):

    def __init__(self, filename):
        VMError.__init__(self, filename)
        self.filename = filename

    def __str__(self):
        return "CD image file not found: %r" % self.filename


class VMImageCheckError(VMError):

    def __init__(self, filename):
        VMError.__init__(self, filename)
        self.filename = filename

    def __str__(self):
        return "Errors found on image: %r" % self.filename


class VMBadPATypeError(VMError):

    def __init__(self, pa_type):
        VMError.__init__(self, pa_type)
        self.pa_type = pa_type

    def __str__(self):
        return "Unsupported PCI assignable type: %r" % self.pa_type


class VMPAError(VMError):

    def __init__(self, pa_type):
        VMError.__init__(self, pa_type)
        self.pa_type = pa_type

    def __str__(self):
        return ("No PCI assignable devices could be assigned "
                "(pci_assignable=%r)" % self.pa_type)


class VMPostCreateError(VMError):

    def __init__(self, cmd, output):
        VMError.__init__(self, cmd, output)
        self.cmd = cmd
        self.output = output


class VMHugePageError(VMPostCreateError):

    def __str__(self):
        return ("Cannot allocate hugepage memory    (command: %r,    "
                "output: %r)" % (self.cmd, self.output))


class VMKVMInitError(VMPostCreateError):

    def __str__(self):
        return ("Cannot initialize KVM    (command: %r,    output: %r)" %
                (self.cmd, self.output))


class VMDeadError(VMError):

    def __init__(self, reason='', detail=''):
        VMError.__init__(self)
        self.reason = reason
        self.detail = detail

    def __str__(self):
        msg = "VM is dead"
        if self.reason:
            msg += "    reason: %s" % self.reason
        if self.detail:
            msg += "    detail: %r" % self.detail
        return (msg)


class VMDeadKernelCrashError(VMError):

    def __init__(self, kernel_crash):
        VMError.__init__(self, kernel_crash)
        logging.debug(kernel_crash)

    def __str__(self):
        return ("VM is dead due to a kernel crash, "
                "see debug/serial log for details")


class VMInvalidInstructionCode(VMError):

    def __init__(self, invalid_code):
        VMError.__init__(self, invalid_code)
        self.invalid_code = invalid_code

    def __str__(self):
        error = ""
        for invalid_code in self.invalid_code:
            error += "%s" % (invalid_code)
        return ("Invalid instruction was executed on VM:\n%s" % error)


class VMAddressError(VMError):
    pass


class VMInterfaceIndexError(VMError):
    pass


class VMPortNotRedirectedError(VMAddressError):

    def __init__(self, port, virtnet_nic=None):
        VMAddressError.__init__(self, port)
        self.port = port
        self.virtnet_nic = virtnet_nic

    def __str__(self):
        msg = "Don't know how to connect to guest port %s" % self.port
        if self.virtnet_nic is None:
            return msg
        else:
            nic = self.virtnet_nic
            msg += (" with networking type '%s', to destination '%s', for nic "
                    "'%s' with mac '%s' and ip '%s'." % (nic.nettype, nic.netdst,
                                                         nic.nic_name, nic.mac, nic.ip))
            return msg


class VMAddressVerificationError(VMAddressError):

    def __init__(self, mac, ip):
        VMAddressError.__init__(self, mac, ip)
        self.mac = mac
        self.ip = ip

    def __str__(self):
        return ("Could not verify DHCP lease: "
                "%s --> %s" % (self.mac, self.ip))


class VMMACAddressMissingError(VMAddressError):

    def __init__(self, nic_index):
        VMAddressError.__init__(self, nic_index)
        self.nic_index = nic_index

    def __str__(self):
        return "No MAC defined for NIC #%s" % self.nic_index


class VMIPAddressMissingError(VMAddressError):

    def __init__(self, mac, ip_version="ipv4"):
        VMAddressError.__init__(self, mac)
        self.mac = mac
        self.ip_version = ip_version

    def __str__(self):
        return "No %s DHCP lease for MAC %s" % (self.ip_version, self.mac)


class VMUnknownNetTypeError(VMError):

    def __init__(self, vmname, nicname, nettype):
        super(VMUnknownNetTypeError, self).__init__()
        self.vmname = vmname
        self.nicname = nicname
        self.nettype = nettype

    def __str__(self):
        return "Unknown nettype '%s' requested for NIC %s on VM %s" % (
            self.nettype, self.nicname, self.vmname)


class VMAddNetDevError(VMError):
    pass


class VMDelNetDevError(VMError):
    pass


class VMAddNicError(VMError):
    pass


class VMDelNicError(VMError):
    pass


class VMMigrateError(VMError):
    pass


class VMMigrateTimeoutError(VMMigrateError):
    pass


class VMMigrateCancelError(VMMigrateError):
    pass


class VMMigrateFailedError(VMMigrateError):
    pass


class VMMigrateProtoUnknownError(error.TestNAError):

    def __init__(self, protocol):
        self.protocol = protocol

    def __str__(self):
        return ("Virt Test doesn't know migration protocol '%s'. "
                "You would have to add it to the list of known protocols" %
                self.protocol)


class VMMigrateStateMismatchError(VMMigrateError):

    def __init__(self):
        VMMigrateError.__init__(self)

    def __str__(self):
        return ("Mismatch of VM state before and after migration")


class VMRebootError(VMError):
    pass


class VMStatusError(VMError):
    pass


class VMRemoveError(VMError):
    pass


class VMDeviceError(VMError):
    pass


class VMDeviceNotSupportedError(VMDeviceError):

    def __init__(self, name, device):
        VMDeviceError.__init__(self, name, device)
        self.name = name
        self.device = device

    def __str__(self):
        return ("Device '%s' is not supported for vm '%s' on this Host." %
                (self.device, self.name))


class VMPCIDeviceError(VMDeviceError):
    pass


class VMPCISlotInUseError(VMPCIDeviceError):

    def __init__(self, name, slot):
        VMPCIDeviceError.__init__(self, name, slot)
        self.name = name
        self.slot = slot

    def __str__(self):
        return ("PCI slot '0x%s' is already in use on vm '%s'. Please assign"
                " another slot in config file." % (self.slot, self.name))


class VMPCIOutOfRangeError(VMPCIDeviceError):

    def __init__(self, name, max_dev_num):
        VMPCIDeviceError.__init__(self, name, max_dev_num)
        self.name = name
        self.max_dev_num = max_dev_num

    def __str__(self):
        return ("Too many PCI devices added on vm '%s', max supported '%s'" %
                (self.name, str(self.max_dev_num)))


class VMUSBError(VMError):
    pass


class VMUSBControllerError(VMUSBError):
    pass


class VMUSBControllerMissingError(VMUSBControllerError):

    def __init__(self, name, controller_type):
        VMUSBControllerError.__init__(self, name, controller_type)
        self.name = name
        self.controller_type = controller_type

    def __str__(self):
        return ("Could not find '%s' USB Controller on vm '%s'. Please "
                "check config files." % (self.controller_type, self.name))


class VMUSBControllerPortFullError(VMUSBControllerError):

    def __init__(self, name, usb_dev_dict):
        VMUSBControllerError.__init__(self, name, usb_dev_dict)
        self.name = name
        self.usb_dev_dict = usb_dev_dict

    def __str__(self):
        output = ""
        try:
            for ctl, dev_list in self.usb_dev_dict.iteritems():
                output += "%s: %s\n" % (ctl, dev_list)
        except Exception:
            pass

        return ("No available USB port left on VM %s.\n"
                "USB devices map is: \n%s" % (self.name, output))


class VMUSBPortInUseError(VMUSBError):

    def __init__(self, vm_name, controller, port):
        VMUSBError.__init__(self, vm_name, controller, port)
        self.vm_name = vm_name
        self.controller = controller
        self.port = port

    def __str__(self):
        return ("USB port '%d' of controller '%s' is already in use on vm"
                " '%s'. Please assign another port in config file." %
                (self.port, self.controller, self.vm_name))


class VMScreenInactiveError(VMError):

    def __init__(self, vm, inactive_time):
        VMError.__init__(self)
        self.vm = vm
        self.inactive_time = inactive_time

    def __str__(self):
        msg = ("%s screen is inactive for %d s (%d min)" %
               (self.vm.name, self.inactive_time, self.inactive_time / 60))
        return msg


class CpuInfo(object):

    """
    A class for VM's cpu information.
    """

    def __init__(self, model=None, vendor=None, flags=None, family=None,
                 smp=0, maxcpus=0, sockets=0, cores=0, threads=0):
        """
        :param model: CPU Model of VM (use 'qemu -cpu ?' for list)
        :param vendor: CPU Vendor of VM
        :param flags: CPU Flags of VM
        :param flags: CPU Family of VM
        :param smp: set the number of CPUs to 'n' [default=1]
        :param maxcpus: maximum number of total cpus, including
                        offline CPUs for hotplug, etc
        :param cores: number of CPU cores on one socket
        :param threads: number of threads on one CPU core
        :param sockets: number of discrete sockets in the system
        """
        self.model = model
        self.vendor = vendor
        self.flags = flags
        self.family = family
        self.smp = smp
        self.maxcpus = maxcpus
        self.sockets = sockets
        self.cores = cores
        self.threads = threads


class BaseVM(object):

    """
    Base class for all hypervisor specific VM subclasses.

    This class should not be used directly, that is, do not attempt to
    instantiate and use this class. Instead, one should implement a subclass
    that implements, at the very least, all methods defined right after the
    the comment blocks that are marked with:

    "Public API - *must* be reimplemented with virt specific code"

    and

    "Protected API - *must* be reimplemented with virt specific classes"

    The current proposal regarding methods naming convention is:

    - Public API methods: named in the usual way, consumed by tests
    - Protected API methods: name begins with a single underline, to be
      consumed only by BaseVM and subclasses
    - Private API methods: name begins with double underline, to be consumed
      only by the VM subclass itself (usually implements virt specific
      functionality: example: __make_qemu_command())

    So called "protected" methods are intended to be used only by VM classes,
    and not be consumed by tests. Theses should respect a naming convention
    and always be preceded by a single underline.

    Currently most (if not all) methods are public and appears to be consumed
    by tests. It is a ongoing task to determine whether  methods should be
    "public" or "protected".
    """

    #
    # Assuming that all low-level hypervisor have at least migration via tcp
    # (true for xen & kvm). Also true for libvirt (using xen and kvm drivers)
    #
    MIGRATION_PROTOS = ['tcp', ]

    #
    # Timeout definition. This is being kept inside the base class so that
    # sub classes can change the default just for themselves
    #
    LOGIN_TIMEOUT = 10
    LOGIN_WAIT_TIMEOUT = 240
    COPY_FILES_TIMEOUT = 600
    MIGRATE_TIMEOUT = 3600
    REBOOT_TIMEOUT = 240
    CREATE_TIMEOUT = 5

    def __init__(self, name, params):
        self.name = name
        self.params = params
        # Create instance if not already set
        if not hasattr(self, 'instance'):
            self._generate_unique_id()
        # Don't overwrite existing state, update from params
        if hasattr(self, 'virtnet'):
            # Direct reference to self.virtnet makes pylint complain
            # note: virtnet.__init__() supports being called anytime
            getattr(self, 'virtnet').__init__(self.params,
                                              self.name,
                                              self.instance)
        else:  # Create new
            self.virtnet = utils_net.VirtNet(self.params,
                                             self.name,
                                             self.instance)

        if not hasattr(self, 'cpuinfo'):
            self.cpuinfo = CpuInfo()

    def _generate_unique_id(self):
        """
        Generate a unique identifier for this VM
        """
        while True:
            self.instance = (time.strftime("%Y%m%d-%H%M%S-") +
                             utils_misc.generate_random_string(8))
            if not glob.glob("/tmp/*%s" % self.instance):
                break

    def update_vm_id(self):
        """
        Update vm identifier, we need do that when force reboot vm, since vm
        virnet params may be changed.
        """
        self._generate_unique_id()

    @staticmethod
    def lookup_vm_class(vm_type, target):
        if vm_type == 'qemu':
            import qemu_vm
            return qemu_vm.VM
        if vm_type == 'libvirt':
            import libvirt_vm
            return libvirt_vm.VM
        if vm_type == 'v2v':
            if target == 'libvirt' or target is None:
                import libvirt_vm
                return libvirt_vm.VM
            if target == 'ovirt':
                import ovirt
                return ovirt.VMManager

    #
    # Public API - could be reimplemented with virt specific code
    #
    def needs_restart(self, name, params, basedir):
        """
        Verifies whether the current virt_install commandline matches the
        requested one, based on the test parameters.
        """
        try:
            need_restart = (self.make_create_command() !=
                            self.make_create_command(name, params, basedir))
        except Exception:
            logging.error(traceback.format_exc())
            need_restart = True
        if need_restart:
            logging.debug(
                "VM params in env don't match requested, restarting.")
            return True
        else:
            # Command-line encoded state doesn't include all params
            # TODO: Check more than just networking
            other_virtnet = utils_net.VirtNet(params, name, self.instance)
            if self.virtnet != other_virtnet:
                logging.debug("VM params in env match, but network differs, "
                              "restarting")
                logging.debug("\t" + str(self.virtnet))
                logging.debug("\t!=")
                logging.debug("\t" + str(other_virtnet))
                return True
            else:
                logging.debug(
                    "VM params in env do match requested, continuing.")
                return False

    def verify_alive(self):
        """
        Make sure the VM is alive and that the main monitor is responsive.

        Can be subclassed to provide better information on why the VM is
        not alive (reason, detail)

        :raise VMDeadError: If the VM is dead
        :raise: Various monitor exceptions if the monitor is unresponsive
        """
        if self.is_dead():
            raise VMDeadError

    def get_mac_address(self, nic_index=0):
        """
        Return the MAC address of a NIC.

        :param nic_index: Index of the NIC
        :raise VMMACAddressMissingError: If no MAC address is defined for the
                requested NIC
        """
        try:
            mac = self.virtnet[nic_index].mac
            return mac
        except KeyError:
            raise VMMACAddressMissingError(nic_index)

    def get_address(self, index=0):
        """
        Return the IP address of a NIC or guest (in host space).

        :param index: Name or index of the NIC whose address is requested.
        :return: 'localhost': Port redirection is in use
        :return: IP address of NIC if valid in arp cache.
        :raise VMMACAddressMissingError: If no MAC address is defined for the
                requested NIC
        :raise VMIPAddressMissingError: If no IP address is found for the the
                NIC's MAC address
        :raise VMAddressVerificationError: If the MAC-IP address mapping cannot
                be verified (using arping)
        """
        nic = self.virtnet[index]
        self.ip_version = self.params.get("ip_version", "ipv4").lower()
        # TODO: Determine port redirection in use w/o checking nettype
        if nic.nettype not in ['bridge', 'macvtap']:
            hostname = socket.gethostname()
            return socket.gethostbyname(hostname)
        if not nic.has_key('mac') and self.params.get('vm_type') == 'libvirt':
            # Look it up from xml
            nic.mac = self.get_virsh_mac_address(index)
        # else TODO: Look up mac from existing qemu-kvm process
        if not nic.has_key('mac'):
            raise VMMACAddressMissingError(index)
        if self.ip_version == "ipv4":
            # Get the IP address from arp cache, try upper and lower case
            arp_ip = self.address_cache.get(nic.mac.upper())
            if not arp_ip:
                arp_ip = self.address_cache.get(nic.mac.lower())

            if not arp_ip and os.geteuid() != 0:
                # For non-root, tcpdump won't work for finding IP address,
                # try arp
                ip_map = utils_net.parse_arp()
                arp_ip = ip_map.get(nic.mac.lower())
                if arp_ip:
                    self.address_cache[nic.mac.lower()] = arp_ip

            if not arp_ip:
                raise VMIPAddressMissingError(nic.mac)

            # Make sure the IP address is assigned to one or more macs
            # for this guest
            macs = self.virtnet.mac_list()

            # SR-IOV cards may not be in same subnet with the card used by
            # host by default, so arp checks won't work. Therefore, do not
            # raise VMAddressVerificationError when SR-IOV is used.
            nic_params = self.params.object_params(nic.nic_name)
            pci_assignable = nic_params.get("pci_assignable") != "no"

            if not utils_net.verify_ip_address_ownership(arp_ip, macs):
                if pci_assignable:
                    msg = "Could not verify DHCP lease: %s-> %s." % (nic.mac,
                                                                     arp_ip)
                    msg += (" Maybe %s is not in the same subnet "
                            "as the host (SR-IOV in use)" % arp_ip)
                    logging.error(msg)
                else:
                    raise VMAddressVerificationError(nic.mac, arp_ip)

            logging.debug('Found/Verified IP %s for VM %s NIC %s',
                          arp_ip, self.name, str(index))
            return arp_ip

        elif self.ip_version == "ipv6":
            # Try to get and return IPV6 address
            if self.params.get('using_linklocal') == "yes":
                ipv6_addr = utils_net.ipv6_from_mac_addr(nic.mac)
            # Using global address
            else:
                mac_key = "%s_6" % nic.mac
                ipv6_addr = self.address_cache.get(mac_key.lower())
            if not ipv6_addr:
                raise VMIPAddressMissingError(nic.mac)
            # Check whether the ipv6 address is reachable
            utils_net.refresh_neigh_table(nic.netdst, ipv6_addr)
            if not utils_misc.wait_for(lambda: utils_net.neigh_reachable(
                                       ipv6_addr, nic.netdst),
                                       30, 0, 1, "Wait neighbour reachable"):
                raise VMAddressVerificationError(nic.mac, ipv6_addr)
            return ipv6_addr

    def fill_addrs(self, addrs):
        """
        Fill VM's nic address to the virtnet structure based on VM's address
        structure addrs.

        :param addrs: Dict of interfaces and address

        ::

            {"if_name":{"mac":['addrs',],
                        "ipv4":['addrs',],
                        "ipv6":['addrs',]},
              ...}
        """
        for virtnet in self.virtnet:
            for iface_name, iface in addrs.iteritems():
                if virtnet.mac in iface["mac"]:
                    virtnet.ip = {"ipv4": iface["ipv4"],
                                  "ipv6": iface["ipv6"]}
                    virtnet.g_nic_name = iface_name

    def get_port(self, port, nic_index=0):
        """
        Return the port in host space corresponding to port in guest space.

        :param port: Port number in host space.
        :param nic_index: Index of the NIC.
        :return: If port redirection is used, return the host port redirected
                to guest port port. Otherwise return port.
        :raise VMPortNotRedirectedError: If an unredirected port is requested
                in user mode
        """
        nic_nettype = self.virtnet[nic_index].nettype
        if nic_nettype in ["bridge", "macvtap"]:
            return port
        else:
            try:
                return self.redirs[port]
            except KeyError:
                raise VMPortNotRedirectedError(port, self.virtnet[nic_index])

    def free_mac_address(self, nic_index_or_name=0):
        """
        Free a NIC's MAC address.

        :param nic_index: Index of the NIC
        """
        self.virtnet.free_mac_address(nic_index_or_name)

    @error.context_aware
    def wait_for_get_address(self, nic_index_or_name, timeout=30,
                             internal_timeout=1, ip_version='ipv4'):
        """
        Wait for a nic to acquire an IP address, then return it.
        For ipv6 linklocal address, we can generate it by nic mac,
        so we can ignore this case
        """
        # Don't let VMIPAddressMissingError/VMAddressVerificationError through
        def _get_address():
            try:
                return self.get_address(nic_index_or_name)
            except (VMIPAddressMissingError, VMAddressVerificationError):
                return False

        if not utils_misc.wait_for(_get_address, timeout, internal_timeout):
            if self.is_dead():
                raise VMIPAddressMissingError(self.virtnet[nic_index_or_name].mac)
            try:
                s_session = None
                # for windows guest make sure your guest supports
                # login by serial_console
                s_session = self.wait_for_serial_login()
                nic_mac = self.get_mac_address(nic_index_or_name)
                os_type = self.params.get("os_type")
                try:
                    utils_net.renew_guest_ip(s_session, nic_mac,
                                             os_type, ip_version)
                    return self.get_address(nic_index_or_name)
                except (VMIPAddressMissingError, VMAddressVerificationError):
                    try:
                        nic_address = utils_net.get_guest_ip_addr(s_session,
                                                                  nic_mac,
                                                                  os_type,
                                                                  ip_version)
                        if nic_address:
                            mac_key = nic_mac
                            if ip_version == "ipv6":
                                mac_key = "%s_6" % nic_mac
                            self.address_cache[mac_key.lower()] = nic_address
                            return nic_address
                    except Exception, err:
                        logging.debug("Can not get guest address, '%s'" % err)
                        raise VMIPAddressMissingError(nic_mac)
            finally:
                if s_session:
                    s_session.close()
        return self.get_address(nic_index_or_name)

    # Adding/setup networking devices methods split between 'add_*' for
    # setting up virtnet, and 'activate_' for performing actions based
    # on settings.
    def add_nic(self, **params):
        """
        Add new or setup existing NIC with optional model type and mac address

        :param params: Dict with additional NIC parameters to set.
        :return: Dict with new NIC's info.
        """
        if not params.has_key('nic_name'):
            params['nic_name'] = utils_misc.generate_random_id()
        nic_name = params['nic_name']
        if nic_name in self.virtnet.nic_name_list():
            self.virtnet[nic_name].update(**params)
        else:
            self.virtnet.append(params)
        nic = self.virtnet[nic_name]
        if not nic.has_key('mac'):  # generate random mac
            logging.debug("Generating random mac address for nic")
            self.virtnet.generate_mac_address(nic_name)
        # mac of '' or invaid format results in not setting a mac
        if nic.has_key('ip') and nic.has_key('mac'):
            if not self.address_cache.has_key(nic.mac):
                logging.debug("(address cache) Adding static "
                              "cache entry: %s ---> %s" % (nic.mac, nic.ip))
            else:
                logging.debug("(address cache) Updating static "
                              "cache entry from: %s ---> %s"
                              " to: %s ---> %s" % (nic.mac,
                                                   self.address_cache[nic.mac], nic.mac, nic.ip))
            self.address_cache[nic.mac] = nic.ip
        return nic

    def del_nic(self, nic_index_or_name):
        """
        Remove the nic specified by name, or index number
        """
        nic = self.virtnet[nic_index_or_name]
        nic_mac = nic.mac.lower()
        self.free_mac_address(nic_index_or_name)
        try:
            del self.virtnet[nic_index_or_name]
            del self.address_cache[nic_mac]
        except IndexError:
            pass  # continue to not exist
        except KeyError:
            pass  # continue to not exist

    def verify_kernel_crash(self):
        """
        Find kernel crash message on the VM serial console.

        :raise: VMDeadKernelCrashError, in case a kernel crash message was
                found.
        """
        panic_re = [r"BUG:.*---\[ end trace .* \]---"]
        panic_re.append(r"----------\[ cut here.* BUG .*\[ end trace .* \]---")
        panic_re.append(r"general protection fault:.* RSP.*>")
        panic_re = "|".join(panic_re)
        if self.serial_console is not None:
            data = self.serial_console.get_output()
            match = re.search(panic_re, data, re.DOTALL | re.MULTILINE | re.I)
            if match is not None:
                raise VMDeadKernelCrashError(match.group(0))

    def verify_bsod(self, scrdump_file):
        # For windows guest
        if (os.path.exists(scrdump_file) and
                self.params.get("check_guest_bsod", "no") == 'yes' and
                ppm_utils.Image is not None):
            ref_img_path = self.params.get("bsod_reference_img", "")
            bsod_base_dir = os.path.join(data_dir.get_root_dir(),
                                         "shared", "deps",
                                         "bsod_img")
            ref_img = utils_misc.get_path(bsod_base_dir, ref_img_path)
            if ppm_utils.have_similar_img(scrdump_file, ref_img):
                err_msg = "Windows Guest appears to have suffered a BSOD,"
                err_msg += " please check %s against %s." % (scrdump_file, ref_img)
                raise VMDeadKernelCrashError(err_msg)

    def verify_illegal_instruction(self):
        """
        Find illegal instruction code on VM serial console output.

        :raise: VMInvalidInstructionCode, in case a wrong instruction code.
        """
        if self.serial_console is not None:
            data = self.serial_console.get_output()
            match = re.findall(r".*trap invalid opcode.*\n", data,
                               re.MULTILINE)

            if match:
                raise VMInvalidInstructionCode(match)

    def get_params(self):
        """
        Return the VM's params dict. Most modified params take effect only
        upon VM.create().
        """
        return self.params

    def get_testlog_filename(self):
        """
        Return the testlog filename.
        """
        return "/tmp/testlog-%s" % self.instance

    def get_virtio_port_filename(self, port_name):
        """
        Return the filename corresponding to a givven monitor name.
        """
        return "/tmp/virtio_port-%s-%s" % (port_name, self.instance)

    def get_virtio_port_filenames(self):
        """
        Return a list of all virtio port filenames (as specified in the VM's
        params).
        """
        return [self.get_virtio_port_filename(v) for v in
                self.params.objects("virtio_ports")]

    @error.context_aware
    def login(self, nic_index=0, timeout=LOGIN_TIMEOUT,
              username=None, password=None):
        """
        Log into the guest via SSH/Telnet/Netcat.
        If timeout expires while waiting for output from the guest (e.g. a
        password prompt or a shell prompt) -- fail.

        :param nic_index: The index of the NIC to connect to.
        :param timeout: Time (seconds) before giving up logging into the
                guest.
        :return: A ShellSession object.
        """
        error.context("logging into '%s'" % self.name)
        if not username:
            username = self.params.get("username", "")
        if not password:
            password = self.params.get("password", "")
        prompt = self.params.get("shell_prompt", "[\#\$]")
        linesep = eval("'%s'" % self.params.get("shell_linesep", r"\n"))
        client = self.params.get("shell_client")
        ip_version = self.params.get("ip_version", "ipv4").lower()
        neigh_attach_if = ""
        address = self.wait_for_get_address(nic_index, timeout=360,
                                            ip_version=ip_version)
        if address and address.lower().startswith("fe80"):
            neigh_attach_if = utils_net.get_neigh_attch_interface(address)
        port = self.get_port(int(self.params.get("shell_port")))
        log_filename = ("session-%s-%s.log" %
                        (self.name, utils_misc.generate_random_string(4)))
        session = remote.remote_login(client, address, port, username,
                                      password, prompt, linesep,
                                      log_filename, timeout,
                                      interface=neigh_attach_if)
        session.set_status_test_command(self.params.get("status_test_command",
                                                        ""))
        self.remote_sessions.append(session)
        return session

    def remote_login(self, nic_index=0, timeout=LOGIN_TIMEOUT,
                     username=None, password=None):
        """
        Alias for login() for backward compatibility.
        """
        return self.login(nic_index, timeout, username, password)

    @error.context_aware
    def commander(self, nic_index=0, timeout=LOGIN_TIMEOUT,
                  username=None, password=None, commander_path=None):
        """
        Log into the guest via SSH/Telnet/Netcat.
        If timeout expires while waiting for output from the guest (e.g. a
        password prompt or a shell prompt) -- fail.

        :param nic_index: The index of the NIC to connect to.
        :param timeout: Time (seconds) before giving up logging into the
                guest.
        :param commaner_path: Path where will be commader placed.
        :return: A ShellSession object.
        """
        if commander_path is None:
            commander_path = "/tmp"
        error.context("logging into '%s'" % self.name)
        if not username:
            username = self.params.get("username", "")
        if not password:
            password = self.params.get("password", "")
        prompt = "^\s*#"
        linesep = eval("'%s'" % self.params.get("shell_linesep", r"\n"))
        client = self.params.get("shell_client")
        address = self.get_address(nic_index)
        port = self.get_port(int(self.params.get("shell_port")))
        log_filename = None

        import remote_commander as rc
        path = os.path.dirname(rc.__file__)

        f_path = " ".join((os.path.join(path, _) for _ in
                           ("remote_runner.py", "remote_interface.py",
                            "messenger.py")))
        self.copy_files_to(f_path, commander_path)

        # start remote commander
        cmd = remote.remote_commander(client, address, port, username,
                                      password, prompt, linesep, log_filename,
                                      timeout, commander_path)
        self.remote_sessions.append(cmd)
        return cmd

    def remote_commander(self, nic_index=0, timeout=LOGIN_TIMEOUT,
                         username=None, password=None):
        """
        Alias for commander() for backward compatibility.
        """
        return self.commander(nic_index, timeout, username, password)

    def wait_for_login(self, nic_index=0, timeout=LOGIN_WAIT_TIMEOUT,
                       internal_timeout=LOGIN_TIMEOUT,
                       serial=False, restart_network=False,
                       username=None, password=None):
        """
        Make multiple attempts to log into the guest via SSH/Telnet/Netcat.

        :param nic_index: The index of the NIC to connect to.
        :param timeout: Time (seconds) to keep trying to log in.
        :param internal_timeout: Timeout to pass to login().
        :param serial: Whether to use a serial connection when remote login
                (ssh, rss) failed.
        :param restart_network: Whether to try to restart guest's network.
        :return: A ShellSession object.
        """
        error_messages = []
        logging.debug("Attempting to log into '%s' (timeout %ds)", self.name,
                      timeout)
        end_time = time.time() + timeout
        while time.time() < end_time:
            try:
                return self.login(nic_index, internal_timeout,
                                  username, password)
            except (remote.LoginError, VMError), e:
                self.verify_alive()
                e = str(e)
                if e not in error_messages:
                    logging.debug(e)
                    error_messages.append(e)
            time.sleep(2)
        # Timeout expired
        if serial or restart_network:
            # Try to login via serila console
            return self.wait_for_serial_login(timeout, internal_timeout,
                                              restart_network,
                                              username, password)
        else:
            # Try one more time but don't catch exceptions
            return self.login(nic_index, internal_timeout, username, password)

    @error.context_aware
    def copy_files_to(self, host_path, guest_path, nic_index=0, limit="",
                      verbose=False, timeout=COPY_FILES_TIMEOUT,
                      username=None, password=None):
        """
        Transfer files to the remote host(guest).

        :param host_path: Host path
        :param guest_path: Guest path
        :param nic_index: The index of the NIC to connect to.
        :param limit: Speed limit of file transfer.
        :param verbose: If True, log some stats using logging.debug (RSS only)
        :param timeout: Time (seconds) before giving up on doing the remote
                copy.
        """
        error.context("sending file(s) to '%s'" % self.name)
        if not username:
            username = self.params.get("username", "")
        if not password:
            password = self.params.get("password", "")
        client = self.params.get("file_transfer_client")
        address = self.get_address(nic_index)
        neigh_attach_if = ""
        if address.lower().startswith("fe80"):
            neigh_attach_if = utils_net.get_neigh_attch_interface(address)
        port = self.get_port(int(self.params.get("file_transfer_port")))
        log_filename = ("transfer-%s-to-%s-%s.log" %
                        (self.name, address,
                         utils_misc.generate_random_string(4)))
        remote.copy_files_to(address, client, username, password, port,
                             host_path, guest_path, limit, log_filename,
                             verbose, timeout, interface=neigh_attach_if)
        utils_misc.close_log_file(log_filename)

    @error.context_aware
    def copy_files_from(self, guest_path, host_path, nic_index=0, limit="",
                        verbose=False, timeout=COPY_FILES_TIMEOUT,
                        username=None, password=None):
        """
        Transfer files from the guest.

        :param host_path: Guest path
        :param guest_path: Host path
        :param nic_index: The index of the NIC to connect to.
        :param limit: Speed limit of file transfer.
        :param verbose: If True, log some stats using logging.debug (RSS only)
        :param timeout: Time (seconds) before giving up on doing the remote
                copy.
        """
        error.context("receiving file(s) from '%s'" % self.name)
        if not username:
            username = self.params.get("username", "")
        if not password:
            password = self.params.get("password", "")
        client = self.params.get("file_transfer_client")
        address = self.get_address(nic_index)
        neigh_attach_if = ""
        if address.lower().startswith("fe80"):
            neigh_attach_if = utils_net.get_neigh_attch_interface(address)
        port = self.get_port(int(self.params.get("file_transfer_port")))
        log_filename = ("transfer-%s-from-%s-%s.log" %
                        (self.name, address,
                         utils_misc.generate_random_string(4)))
        remote.copy_files_from(address, client, username, password, port,
                               guest_path, host_path, limit, log_filename,
                               verbose, timeout, interface=neigh_attach_if)
        utils_misc.close_log_file(log_filename)

    def create_serial_console(self):
        """
        Establish a session with the serial console.

        Let's consider the first serial port as serial console.
        Note: requires a version of netcat that supports -U
        """
        raise NotImplementedError

    def cleanup_serial_console(self):
        """
        Close serial console and associated log file
        """
        raise NotImplementedError

    @error.context_aware
    def serial_login(self, timeout=LOGIN_TIMEOUT,
                     username=None, password=None):
        """
        Log into the guest via the serial console.
        If timeout expires while waiting for output from the guest (e.g. a
        password prompt or a shell prompt) -- fail.

        :param timeout: Time (seconds) before giving up logging into the guest.
        :return: ShellSession object on success and None on failure.
        """
        error.context("logging into '%s' via serial console" % self.name)
        if not username:
            username = self.params.get("username", "")
        if not password:
            password = self.params.get("password", "")
        prompt = self.params.get("shell_prompt", "[\#\$]")
        linesep = eval("'%s'" % self.params.get("shell_linesep", r"\n"))
        status_test_command = self.params.get("status_test_command", "")

        # Some times need recreate the serial_console.
        if not (self.serial_console and
                os.path.exists(self.serial_console.inpipe_filename)):
            self.create_serial_console()

        self.serial_console.set_linesep(linesep)
        self.serial_console.set_status_test_command(status_test_command)

        # Try to get a login prompt
        self.serial_console.sendline()

        remote.handle_prompts(self.serial_console, username, password,
                              prompt, timeout)
        return self.serial_console

    def wait_for_serial_login(self, timeout=LOGIN_WAIT_TIMEOUT,
                              internal_timeout=LOGIN_TIMEOUT,
                              restart_network=False,
                              username=None, password=None):
        """
        Make multiple attempts to log into the guest via serial console.

        :param timeout: Time (seconds) to keep trying to log in.
        :param internal_timeout: Timeout to pass to serial_login().
        :param restart_network: Whether try to restart guest's network.
        :return: A ShellSession object.
        """
        error_messages = []
        logging.debug("Attempting to log into '%s' via serial console "
                      "(timeout %ds)", self.name, timeout)
        end_time = time.time() + timeout
        while time.time() < end_time:
            try:
                session = self.serial_login(internal_timeout)
                if restart_network:
                    try:
                        utils_net.restart_guest_network(session)
                    except Exception:
                        pass
                return session
            except remote.LoginError, e:
                self.verify_alive()
                e = str(e)
                if e not in error_messages:
                    logging.debug(e)
                    error_messages.append(e)
            time.sleep(2)
        # Timeout expired; try one more time but don't catch exceptions
        return self.serial_login(internal_timeout, username, password)

    def get_uuid(self):
        """
        Catch UUID of the VM.

        :return: None,if not specified in config file
        """
        if self.params.get("uuid") == "random":
            return self.uuid
        else:
            return self.params.get("uuid", None)

    def send_string(self, sr):
        """
        Send a string to the VM.

        :param sr: String, that must consist of alphanumeric characters only.
                Capital letters are allowed.
        """
        for char in sr:
            if char.isupper():
                self.send_key("shift-%s" % char.lower())
            else:
                self.send_key(char)

    def get_cpu_count(self):
        """
        Get the cpu count of the VM.
        """
        session = self.wait_for_login()
        try:
            return int(session.cmd(self.params.get("cpu_chk_cmd")))
        finally:
            session.close()

    def get_memory_size(self, cmd=None, timeout=60, re_str=None):
        """
        Get bootup memory size of the VM.

        :param cmd: Command used to check memory. If not provided,
                    self.params.get("mem_chk_cmd") will be used.
        :param timeout: timeout for cmd
        :param re_str: pattern to get memory size from the command
                       output. If not provided,
                       self.params.get("mem_chk_re_str") will be
                       used.
        """
        session = self.login()
        if re_str is None:
            re_str = self.params.get("mem_chk_re_str", "([0-9]+)")
        try:
            if not cmd:
                cmd = self.params.get("mem_chk_cmd")
            mem_str = session.cmd_output(cmd, timeout=timeout)
            mem = re.findall(re_str, mem_str)
            mem_size = 0
            for m in mem:
                mem_size += int(m)
            if "GB" in mem_str:
                mem_size *= 1024
            elif "MB" in mem_str:
                pass
            else:
                mem_size /= 1024
            return int(mem_size)
        finally:
            session.close()

    def get_current_memory_size(self):
        """
        Get current memory size of the VM, rather than bootup memory.
        """
        cmd = self.params.get("mem_chk_cur_cmd")
        return self.get_memory_size(cmd)

    #
    # Public API - *must* be reimplemented with virt specific code
    #
    def is_alive(self):
        """
        Return True if the VM is alive and the management interface is responsive.
        """
        raise NotImplementedError

    def is_dead(self):
        """
        Return True if the VM is dead.
        """
        raise NotImplementedError

    def is_paused(self):
        """
        Return True if the VM is paused
        """
        raise NotImplementedError

    def activate_nic(self, nic_index_or_name):
        """
        Activate an inactive network device

        :param nic_index_or_name: name or index number for existing NIC
        """
        raise NotImplementedError

    def deactivate_nic(self, nic_index_or_name):
        """
        Deactivate an active network device

        :param nic_index_or_name: name or index number for existing NIC
        """
        raise NotImplementedError

    def verify_userspace_crash(self):
        """
        Verify if the userspace component of the virtualization backend crashed.
        """
        pass

    def clone(self, name, **params):
        """
        Return a clone of the VM object with optionally modified parameters.

        This method should be implemented by
        """
        raise NotImplementedError

    def destroy(self, gracefully=True, free_mac_addresses=True):
        """
        Destroy the VM.

        If gracefully is True, first attempt to shutdown the VM with a shell
        command.  Then, attempt to destroy the VM via the monitor with a 'quit'
        command.  If that fails, send SIGKILL to the qemu process.

        :param gracefully: If True, an attempt will be made to end the VM
                using a shell command before trying to end the qemu process
                with a 'quit' or a kill signal.
        :param free_mac_addresses: If True, the MAC addresses used by the VM
                will be freed.
        """
        raise NotImplementedError

    def migrate(self, timeout=MIGRATE_TIMEOUT, protocol="tcp",
                cancel_delay=None, offline=False, stable_check=False,
                clean=True, save_path="/tmp", dest_host="localhost",
                remote_port=None):
        """
        Migrate the VM.

        If the migration is local, the VM object's state is switched with that
        of the destination VM.  Otherwise, the state is switched with that of
        a dead VM (returned by self.clone()).

        :param timeout: Time to wait for migration to complete.
        :param protocol: Migration protocol ('tcp', 'unix' or 'exec').
        :param cancel_delay: If provided, specifies a time duration after which
                migration will be canceled.  Used for testing migrate_cancel.
        :param offline: If True, pause the source VM before migration.
        :param stable_check: If True, compare the VM's state after migration to
                its state before migration and raise an exception if they
                differ.
        :param clean: If True, delete the saved state files (relevant only if
                stable_check is also True).
        :param save_path: The path for state files.
        :param dest_host: Destination host (defaults to 'localhost').
        :param remote_port: Port to use for remote migration.
        """
        raise NotImplementedError

    def reboot(self, session=None, method="shell", nic_index=0,
               timeout=REBOOT_TIMEOUT):
        """
        Reboot the VM and wait for it to come back up by trying to log in until
        timeout expires.

        :param session: A shell session object or None.
        :param method: Reboot method.  Can be "shell" (send a shell reboot
                command) or "system_reset" (send a system_reset monitor command).
        :param nic_index: Index of NIC to access in the VM, when logging in
                after rebooting.
        :param timeout: Time to wait for login to succeed (after rebooting).
        :return: A new shell session object.
        """
        raise NotImplementedError

    # should this really be expected from VMs of all hypervisor types?
    def send_key(self, keystr):
        """
        Send a key event to the VM.

        :param keystr: A key event string (e.g. "ctrl-alt-delete")
        """
        raise NotImplementedError

    def save_to_file(self, path):
        """
        State of paused VM recorded to path and VM shutdown on success

        Throws a VMStatusError if before/after state is incorrect.

        :param path: file where VM state recorded

        """
        raise NotImplementedError

    def restore_from_file(self, path):
        """
        A shutdown or paused VM is resumed from path, & possibly set running

        Throws a VMStatusError if before/after restore state is incorrect

        :param path: path to file vm state was saved to
        """
        raise NotImplementedError

    def savevm(self, tag_name):
        """
        Save the virtual machine as the tag 'tag_name'

        :param tag_name: tag of the virtual machine that saved

        """
        raise NotImplementedError

    def loadvm(self, tag_name):
        """
        Load the virtual machine tagged 'tag_name'.

        :param tag_name: tag of the virtual machine that saved
        """
        raise NotImplementedError

    def pause(self):
        """
        Stop the VM operation.
        """
        raise NotImplementedError

    def resume(self):
        """
        Resume the VM operation in case it's stopped.
        """
        raise NotImplementedError

########NEW FILE########
__FILENAME__ = xml_utils
"""
    Utility module standardized on ElementTree 2.6 to minimize dependencies
    in python 2.4 systems.

    Often operations on XML files suggest making a backup copy first is a
    prudent measure.  However, it's easy to loose track of these temporary
    files and they can quickly leave a mess behind.  The TempXMLFile class
    helps by trying to clean up the temporary file whenever the instance is
    deleted, goes out of scope, or an exception is thrown.

    The XMLBackup class extends the TempXMLFile class by basing its file-
    like instances off of an automatically created TempXMLFile instead of
    pointing at the source.  Methods are provided for overwriting the backup
    copy from the source, or restoring the source from the backup.  Similar
    to TempXMLFile, the temporary backup files are automatically removed.
    Access to the original source is provided by the sourcefilename
    attribute.

    An interface for querying and manipulating XML data is provided by
    the XMLTreeFile class.  Instances of this class are BOTH file-like
    and ElementTree-like objects.  Whether or not they are constructed
    from a file or a string, the file-like instance always represents a
    temporary backup copy.  Access to the source (even when itself is
    temporary) is provided by the sourcefilename attribute, and a (closed)
    file object attribute sourcebackupfile.  See the ElementTree documentation
    for methods provided by that class.

    Finally, the TemplateXML class represents XML templates that support
    dynamic keyword substitution based on a dictionary.  Substitution keys
    in the XML template (string or file) follow the 'bash' variable reference
    style ($foo or ${bar}).  Extension of the parser is possible by subclassing
    TemplateXML and overriding the ParserClass class attribute.  The parser
    class should be an ElementTree.TreeBuilder class or subclass.  Instances
    of XMLTreeFile are returned by the parse method, which are themselves
    temporary backups of the parsed content.  See the xml_utils_unittest
    module for examples.
"""

import os
import shutil
import tempfile
import string
import StringIO
import logging
from xml.parsers import expat
# We *have* to use our ElementTree fork :(
from virttest import element_tree as ElementTree

# Also used by unittests
TMPPFX = 'xml_utils_temp_'
TMPSFX = '.xml'
EXSFX = '_exception_retained'
ENCODING = "UTF-8"


class TempXMLFile(file):

    """
    Temporary XML file auto-removed on instance del / module exit.
    """

    def __init__(self, suffix=TMPSFX, prefix=TMPPFX, mode="wb+", buffsz=1):
        """
        Initialize temporary XML file removed on instance destruction.

        param: suffix: temporary file's suffix
        param: prefix: temporary file's prefix
        param: mode: second parameter to file()/open()
        param: buffer: third parameter to file()/open()
        """
        fd, path = tempfile.mkstemp(suffix=suffix, prefix=prefix)
        os.close(fd)
        super(TempXMLFile, self).__init__(path, mode, buffsz)

    def _info(self):
        """
        Inform user that file was not auto-deleted due to exceptional exit.
        """
        logging.info("Retaining %s", self.name + EXSFX)

    def unlink(self):
        """
        Unconditionaly delete file, ignoring related exceptions
        """
        try:
            os.unlink(self.name)
            self.close()
        except (OSError, IOError):
            pass  # don't care if delete fails

    def __exit__(self, exc_type, exc_value, traceback):
        """
        unlink temporary backup on unexceptional module exit.
        """

        # there was an exception
        if None not in (exc_type, exc_value, traceback):
            os.rename(self.name, self.name + EXSFX)
        else:
            self.unlink()  # safe if file was renamed
        if hasattr(super(TempXMLFile, self), '__exit__'):
            super(TempXMLFile, self).__exit__(exc_type, exc_value, traceback)

    def __del__(self):
        """
        unlink temporary file on instance delete.
        """
        self.close()
        self.unlink()


class XMLBackup(TempXMLFile):

    """
    Backup file copy of XML data, automatically removed on instance destruction.
    """

    # Allow users to reference original source of XML data
    sourcefilename = None

    def __init__(self, sourcefilename):
        """
        Initialize a temporary backup from sourcefilename.
        """

        super(XMLBackup, self).__init__()
        self.sourcefilename = sourcefilename
        XMLBackup.backup(self)

    def __del__(self):
        # Drop reference, don't delete source!
        self.sourcefilename = None
        super(XMLBackup, self).__del__()

    def _info(self):
        """
        Inform user that file was not auto-deleted due to exceptional exit.
        """
        logging.info("Retaining backup of %s in %s", self.sourcefilename,
                     self.name + EXSFX)

    def backup(self):
        """
        Overwrite temporary backup with contents of original source.
        """
        super(XMLBackup, self).flush()
        super(XMLBackup, self).seek(0)
        super(XMLBackup, self).truncate(0)
        source_file = file(self.sourcefilename, "rb")
        shutil.copyfileobj(source_file,
                           super(XMLBackup, self))
        source_file.close()
        super(XMLBackup, self).flush()

    def restore(self):
        """
        Overwrite original source with contents of temporary backup
        """
        super(XMLBackup, self).flush()
        super(XMLBackup, self).seek(0)
        source_file = file(self.sourcefilename, "wb")
        source_file.truncate(0)
        shutil.copyfileobj(super(XMLBackup, self),
                           source_file)
        source_file.close()


class XMLTreeFile(ElementTree.ElementTree, XMLBackup):

    """
    Combination of ElementTree root and auto-cleaned XML backup file.
    """

    # Closed file object of original source or TempXMLFile
    # self.sourcefilename inherited from parent
    sourcebackupfile = None

    def __init__(self, xml):
        """
        Initialize from a string or filename containing XML source.

        param: xml: A filename or string containing XML
        """

        # xml param could be xml string or readable filename
        # If it's a string, use auto-delete TempXMLFile
        # to hold the original content.
        try:
            # Test if xml is a valid filename
            self.sourcebackupfile = file(xml, "rb")
            self.sourcebackupfile.close()
            # XMLBackup init will take care of creating a copy
        except (IOError, OSError):
            # Assume xml is a string that needs a temporary source file
            self.sourcebackupfile = TempXMLFile()
            self.sourcebackupfile.write(xml)
            self.sourcebackupfile.close()
        # sourcebackupfile now safe to use for base class initialization
        XMLBackup.__init__(self, self.sourcebackupfile.name)
        try:
            ElementTree.ElementTree.__init__(self, element=None,
                                             file=self.name)
        except expat.ExpatError:
            raise IOError("Error parsing XML: '%s'" % xml)
        # Required for TemplateXML class to work
        self.write()
        self.flush()  # make sure it's on-disk

    def __str__(self):
        self.write()
        self.flush()
        xmlstr = StringIO.StringIO()
        self.write(xmlstr)
        return xmlstr.getvalue()

    def backup(self):
        """Overwrite original source from current tree"""
        self.write()
        self.flush()
        # self is the 'original', so backup/restore logic is reversed
        super(XMLTreeFile, self).restore()

    def restore(self):
        """Overwrite and reparse current tree from original source"""
        # self is the 'original', so backup/restore logic is reversed
        super(XMLTreeFile, self).backup()
        try:
            ElementTree.ElementTree.__init__(self, element=None,
                                             file=self.name)
        except expat.ExpatError:
            raise IOError("Original XML is corrupt: '%s'"
                          % self.sourcebackupfile.name)

    def backup_copy(self):
        """Return a copy of instance, including copies of files"""
        return self.__class__(self.name)

    def reroot(self, xpath):
        """
        Return a copy of instance, re-rooted onto xpath
        """
        rerooted = self.backup_copy()
        element = rerooted.find(xpath)
        if element is None:
            del rerooted  # cleanup files
            raise KeyError("No element found at %s" % xpath)
        rerooted._setroot(element)
        return rerooted

    def get_parent_map(self, element=None):
        """
        Return a child to parent mapping dictionary

        param: element: Search only below this element
        """
        d = {}
        for p in self.getiterator(element):
            for c in p:
                d[c] = p
        return d

    def get_parent(self, element, relative_root=None):
        """
        Return the parent node of an element or None

        param: element: Element to retrieve parent of
        param: relative_root: Search only below this element
        """
        try:
            return self.get_parent_map(relative_root)[element]
        except KeyError:
            return None

    def get_xpath(self, element):
        """Return the XPath string formed from first-match tag names"""
        parent_map = self.get_parent_map()
        root = self.getroot()
        assert root in parent_map.values()
        if element == root:
            return '.'
        # List of strings reversed at end
        path_list = []
        while element != root:
            # 2.7+ ElementPath supports predicates, so:
            # element_index = list(parent_map[element]).index(element)
            # element_index += 1 # XPath indexes are 1 based
            # if element_index > 1:
            #     path_list.append(u"%s[%d]" % (element.tag, element_index))
            # else:
            #     path_list.append(u"%s" % element.tag)
            path_list.append(u"%s" % element.tag)
            element = parent_map[element]
        assert element == root
        path_list.reverse()
        return "/".join(path_list)

    def remove(self, element):
        """
        Removes a matching subelement.

        :param element: element to be removed.
        """
        self.get_parent(element).remove(element)

    def remove_by_xpath(self, xpath):
        """
        Remove an element found by xpath

        :param xpath: element name or path to remove
        """
        self.remove(self.find(xpath))  # can't remove root

    def create_by_xpath(self, xpath):
        """
        Creates all elements in simplistic xpath from root if not exist
        """
        cur_element = self.getroot()
        for tag in xpath.split('/'):
            next_element = cur_element.find(tag)
            if next_element is None:
                next_element = ElementTree.SubElement(cur_element, tag)
            cur_element = next_element

    # This overrides the file.write() method
    def write(self, filename=None, encoding=ENCODING):
        """
        Write current XML tree to filename, or self.name if None.
        """

        if filename is None:
            filename = self.name
        # Avoid calling file.write() by mistake
        ElementTree.ElementTree.write(self, filename, encoding)

    def read(self, xml):
        self.__del__()
        self.__init__(xml)


class Sub(object):

    """String substituter using string.Template"""

    def __init__(self, **mapping):
        """Initialize substitution mapping."""

        self._mapping = mapping

    def substitute(self, text):
        """
        Use string.safe_substitute on text and return the result

        :param text: string to substitute
        """

        return string.Template(text).safe_substitute(**self._mapping)


class TemplateXMLTreeBuilder(ElementTree.XMLTreeBuilder, Sub):

    """Resolve XML templates into temporary file-backed ElementTrees"""

    BuilderClass = ElementTree.TreeBuilder

    def __init__(self, **mapping):
        """
        Initialize parser that substitutes keys with values in data

        :param **mapping: values to be substituted for ${key} in XML input
        """

        Sub.__init__(self, **mapping)
        ElementTree.XMLTreeBuilder.__init__(self, target=self.BuilderClass())

    def feed(self, data):
        ElementTree.XMLTreeBuilder.feed(self, self.substitute(data))


class TemplateXML(XMLTreeFile):

    """Template-sourced XML ElementTree backed by temporary file."""

    ParserClass = TemplateXMLTreeBuilder

    def __init__(self, xml, **mapping):
        """
        Initialize from a XML string or filename, and string.template mapping.

        :param xml: A filename or string containing XML
        :param **mapping: keys/values to feed with XML to string.template
        """

        self.parser = self.ParserClass(**mapping)
        # ElementTree.init calls self.parse()
        super(TemplateXML, self).__init__(xml)
        # XMLBase.__init__ calls self.write() after super init

    def parse(self, source, parser=None):
        """
        Parse source XML file or filename using TemplateXMLTreeBuilder

        :param source: XML file or filename
        :param parser: ignored
        """
        if parser is None:
            return super(TemplateXML, self).parse(source, self.parser)
        else:
            return super(TemplateXML, self).parse(source, parser)

    def restore(self):
        """
        Raise an IOError to protect the original template source.
        """

        raise IOError("Protecting template source, disallowing restore to %s" %
                      self.sourcefilename)

########NEW FILE########
__FILENAME__ = xml_utils_unittest
#!/usr/bin/python

import unittest
import tempfile
import os
import glob
import logging

import common
import xml_utils
from virttest import element_tree as ElementTree


class xml_test_data(unittest.TestCase):

    def get_tmp_files(self, prefix, sufix):
        path_string = os.path.join('/tmp', "%s*%s" % (prefix, sufix))
        return glob.glob(path_string)

    def setUp(self):
        xml_utils.TMPPFX = 'xml_utils_unittest_temp_'
        # Compacted to save excess scrolling
        self.TEXT_REPLACE_KEY = "TEST_XML_TEXT_REPLACE"
        self.XMLSTR = """<?xml version='1.0' encoding='UTF-8'?><capabilities><host>
        <uuid>4d515db1-9adc-477d-8195-f817681e72e6</uuid><cpu><arch>x86_64</arch>
        <model>Westmere</model><vendor>Intel</vendor><topology sockets='1'
        cores='2' threads='2'/><feature name='rdtscp'/><feature name='x2apic'/>
        <feature name='xtpr'/><feature name='tm2'/><feature name='est'/>
        <feature name='vmx'/><feature name='ds_cpl'/><feature name='monitor'/>
        <feature name='pbe'/><feature name='tm'/><feature name='ht'/><feature
        name='ss'/><feature name='acpi'/><feature name='ds'/><feature
        name='vme'/></cpu><migration_features><live/><uri_transports>
        <uri_transport>tcp</uri_transport></uri_transports>
        </migration_features><topology><cells num='1'><cell id='0'><cpus
        num='4'><cpu id='0'/><cpu id='1'/><cpu id='2'/><cpu id='3'/></cpus>
        </cell></cells></topology><secmodel><model>selinux</model><doi>0</doi>
        </secmodel></host><guest><os_type>hvm</os_type><arch name='i686'>
        <wordsize>32</wordsize><emulator>$TEST_XML_TEXT_REPLACE</emulator>
        <machine>rhel6.2.0</machine><machine canonical='rhel6.2.0'>pc</machine>
        <machine>rhel6.1.0</machine><machine>rhel6.0.0</machine><machine>
        rhel5.5.0</machine><machine>rhel5.4.4</machine><machine>rhel5.4.0
        </machine><domain type='qemu'></domain><domain type='kvm'><emulator>
        /usr/libexec/qemu-kvm</emulator></domain></arch><features><cpuselection
        /><deviceboot/><pae/><nonpae/><acpi default='on' toggle='yes'/><apic
        default='on' toggle='no'/></features></guest></capabilities>"""
        (fd, self.XMLFILE) = tempfile.mkstemp(suffix=xml_utils.TMPSFX,
                                              prefix=xml_utils.TMPPFX)
        os.write(fd, self.XMLSTR)
        os.close(fd)
        self.canonicalize_test_xml()

    def tearDown(self):
        os.unlink(self.XMLFILE)
        leftovers = self.get_tmp_files(xml_utils.TMPPFX, xml_utils.TMPSFX)
        if len(leftovers) > 0:
            self.fail('Leftover files: %s' % str(leftovers))

    def canonicalize_test_xml(self):
        et = ElementTree.parse(self.XMLFILE)
        et.write(self.XMLFILE, encoding="UTF-8")
        f = file(self.XMLFILE)
        self.XMLSTR = f.read()
        f.close()

    def is_same_contents(self, filename, other=None):
        """Compare filename contents with XMLSTR, or contents of other"""
        try:
            f = file(filename, "rb")
            s = f.read()
        except (IOError, OSError):
            logging.warning("File %s does not exist" % filename)
            return False
        if other is None:
            return s == self.XMLSTR
        else:
            other_f = file(other, "rb")
            other_s = other_f.read()
            return s == other_s


class test_ElementTree(xml_test_data):

    def test_bundled_elementtree(self):
        self.assertEqual(xml_utils.ElementTree.VERSION, ElementTree.VERSION)


class test_TempXMLFile(xml_test_data):

    def test_prefix_sufix(self):
        filename = os.path.basename(self.XMLFILE)
        self.assert_(filename.startswith(xml_utils.TMPPFX))
        self.assert_(filename.endswith(xml_utils.TMPSFX))

    def test_test_TempXMLFile_canread(self):
        tmpf = xml_utils.TempXMLFile()
        tmpf.write(self.XMLSTR)
        tmpf.seek(0)
        stuff = tmpf.read()
        self.assertEqual(stuff, self.XMLSTR)

    def test_TempXMLFile_implicit(self):
        def out_of_scope_tempxmlfile():
            tmpf = xml_utils.TempXMLFile()
            return tmpf.name
        self.assertRaises(OSError, os.stat, out_of_scope_tempxmlfile())

    def test_TempXMLFile_explicit(self):
        tmpf = xml_utils.TempXMLFile()
        tmpf_name = tmpf.name
        # Assert this does NOT raise an exception
        os.stat(tmpf_name)
        del tmpf
        self.assertRaises(OSError, os.stat, tmpf_name)


class test_XMLBackup(xml_test_data):

    class_to_test = xml_utils.XMLBackup

    def test_backup_filename(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        self.assertEqual(xmlbackup.sourcefilename, self.XMLFILE)

    def test_backup_file(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        self.assertTrue(self.is_same_contents(xmlbackup.name))

    def test_rebackup_file(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        oops = file(xmlbackup.name, "wb")
        oops.write("foobar")
        oops.close()
        self.assertFalse(self.is_same_contents(xmlbackup.name))
        xmlbackup.backup()
        self.assertTrue(self.is_same_contents(xmlbackup.name))

    def test_restore_file(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        # nuke source
        os.unlink(xmlbackup.sourcefilename)
        xmlbackup.restore()
        self.assertTrue(self.is_same_contents(xmlbackup.name))

    def test_remove_backup_file(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        filename = xmlbackup.name
        os.unlink(filename)
        del xmlbackup
        self.assertRaises(OSError, os.unlink, filename)

    def test_TempXMLBackup_implicit(self):
        def out_of_scope_xmlbackup():
            tmpf = self.class_to_test(self.XMLFILE)
            return tmpf.name
        filename = out_of_scope_xmlbackup()
        self.assertRaises(OSError, os.unlink, filename)

    def test_TempXMLBackup_exception_exit(self):
        tmpf = self.class_to_test(self.XMLFILE)
        filename = tmpf.name
        # simulate exception exit DOES NOT DELETE
        tmpf.__exit__(Exception, "foo", "bar")
        self.assertTrue(self.is_same_contents(filename + xml_utils.EXSFX))
        os.unlink(filename + xml_utils.EXSFX)

    def test_TempXMLBackup_unexception_exit(self):
        tmpf = self.class_to_test(self.XMLFILE)
        filename = tmpf.name
        # simulate normal exit DOES DELETE
        tmpf.__exit__(None, None, None)
        self.assertRaises(OSError, os.unlink, filename)


class test_XMLTreeFile(xml_test_data):

    class_to_test = xml_utils.XMLTreeFile

    def test_stringify(self):
        xml = self.class_to_test(self.XMLFILE)
        # initialize second copy from parsed string output of first
        testxml = self.class_to_test(str(xml))
        self.assertTrue(self.is_same_contents(xml.name, testxml.name))

    def test_sourcebackupfile_closed_file(self):
        xml = self.class_to_test(self.XMLFILE)
        self.assertRaises(ValueError, xml.sourcebackupfile.write, 'foobar')

    def test_sourcebackupfile_closed_string(self):
        xml = self.class_to_test(self.XMLSTR)
        self.assertRaises(ValueError, xml.sourcebackupfile.write, 'foobar')

    def test_init_str(self):
        xml = self.class_to_test(self.XMLSTR)
        self.assert_(xml.sourcefilename is not None)
        self.assertEqual(xml.sourcebackupfile.name,
                         xml.sourcefilename)

    def test_init_xml(self):
        xml = self.class_to_test(self.XMLFILE)
        self.assert_(xml.sourcefilename is not None)
        self.assertEqual(xml.sourcebackupfile.name,
                         xml.sourcefilename)

    def test_restore_from_string(self):
        xmlbackup = self.class_to_test(self.XMLSTR)
        os.unlink(xmlbackup.sourcefilename)
        xmlbackup.backup()
        self.assertTrue(self.is_same_contents(xmlbackup.sourcefilename))

    def test_restore_from_file(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        os.unlink(xmlbackup.sourcefilename)
        xmlbackup.backup()
        self.assertTrue(self.is_same_contents(xmlbackup.name))

    def test_backup_backup_and_remove(self):
        tmpf = self.class_to_test(self.XMLFILE)
        tmps = self.class_to_test(self.XMLSTR)
        bu_tmpf = tmpf.backup_copy()
        bu_tmps = tmps.backup_copy()
        self.assertTrue(self.is_same_contents(bu_tmpf.name, tmpf.name))
        self.assertTrue(self.is_same_contents(bu_tmps.name, tmps.name))
        tmpf.remove_by_xpath('guest/arch/wordsize')
        tmps.find('guest/arch/wordsize').text = 'FOOBAR'
        tmpf.write()
        tmps.write()
        self.assertFalse(self.is_same_contents(bu_tmpf.name, tmpf.name))
        self.assertFalse(self.is_same_contents(bu_tmps.name, tmps.name))
        self.assertTrue(self.is_same_contents(bu_tmpf.name, bu_tmps.name))
        self.assertFalse(self.is_same_contents(tmpf.name, tmps.name))

    def test_write_default(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        wordsize = xmlbackup.find('guest/arch/wordsize')
        self.assertTrue(wordsize is not None)
        self.assertEqual(int(wordsize.text), 32)
        wordsize.text = str(64)
        xmlbackup.write()
        self.assertFalse(self.is_same_contents(xmlbackup.name))

    def test_write_other(self):
        xmlbackup = self.class_to_test(self.XMLFILE)
        otherfile = xml_utils.TempXMLFile()
        xmlbackup.write(otherfile)
        otherfile.close()
        self.assertTrue(self.is_same_contents(otherfile.name))

    def test_write_other_changed(self):
        xmlbackup = self.class_to_test(self.XMLSTR)
        otherfile = xml_utils.TempXMLFile()
        wordsize = xmlbackup.find('guest/arch/wordsize')
        wordsize.text = str(64)
        xmlbackup.write(otherfile)
        otherfile.close()
        xmlbackup.write(self.XMLFILE)
        xmlbackup.close()
        self.canonicalize_test_xml()
        self.assertTrue(self.is_same_contents(otherfile.name))

    def test_read_other_changed(self):
        xmlbackup = self.class_to_test(self.XMLSTR)
        wordsize = xmlbackup.find('guest/arch/wordsize')
        wordsize.text = str(64)
        otherfile = xml_utils.TempXMLFile()
        xmlbackup.write(otherfile)
        otherfile.close()
        xmlbackup.restore()
        self.assertTrue(self.is_same_contents(xmlbackup.name))
        xmlbackup.read(otherfile.name)
        self.assertFalse(self.is_same_contents(otherfile.name))
        xmlbackup.write(self.XMLFILE)
        self.assertFalse(self.is_same_contents(otherfile.name))
        self.canonicalize_test_xml()
        self.assertTrue(self.is_same_contents(otherfile.name))

    def get_xpath_elements(self, target_path_string):
        xmlbackup = self.class_to_test(self.XMLSTR)
        target_element = xmlbackup.find(target_path_string)
        test_path_string = xmlbackup.get_xpath(target_element)
        test_element = xmlbackup.find(test_path_string)
        return (target_element, test_element)

    def test_get_xpath(self):
        # 2.6 ElementPath doesn't support predicates as in 2.7 :(
        # (it blindly returns the first match)
        self.assertEqual(*self.get_xpath_elements('guest/arch/wordsize'))
        self.assertEqual(*self.get_xpath_elements('guest/arch/machine'))
        self.assertEqual(*self.get_xpath_elements('host/cpu/arch'))

    def test_create_by_xpath(self):
        testxml = self.class_to_test(self.XMLSTR)
        self.assertTrue(testxml.find('host/cpu') is not None)
        self.assertFalse(testxml.find('host/cpu/foo') is not None)
        testxml.create_by_xpath('host/cpu/foo/bar')
        self.assertTrue(testxml.find('host/cpu/foo/bar') is not None)
        self.assertFalse(testxml.find('host/cpu/foo/baz') is not None)
        testxml.create_by_xpath('host/cpu/foo/bar/baz')
        self.assertTrue(testxml.find('host/cpu/foo/bar/baz') is not None)
        # something totally new
        self.assertFalse(testxml.find('foo/bar/baz') is not None)
        testxml.create_by_xpath('foo/bar/baz')
        self.assertTrue(testxml.find('foo/bar/baz') is not None)


class test_templatized_xml(xml_test_data):

    def setUp(self):
        self.MAPPING = {"foo": "bar", "bar": "baz", "baz": "foo"}
        self.FULLREPLACE = """<$foo $bar="$baz">${baz}${foo}${bar}</$foo>"""
        self.RESULTCHECK = """<bar baz="foo">foobarbaz</bar>"""
        super(test_templatized_xml, self).setUp()

    def test_sub(self):
        sub = xml_utils.Sub(**self.MAPPING)
        self.assertEqual(sub.substitute(self.FULLREPLACE), self.RESULTCHECK)

    def test_MappingTreeBuilder_standalone(self):
        txtb = xml_utils.TemplateXMLTreeBuilder(**self.MAPPING)
        txtb.feed(self.FULLREPLACE)
        et = txtb.close()
        result = ElementTree.tostring(et)
        self.assertEqual(result, self.RESULTCHECK)

    def test_TemplateXMLTreeBuilder_nosub(self):
        txtb = xml_utils.TemplateXMLTreeBuilder()
        # elementree pukes on identifiers starting with $
        txtb.feed(self.RESULTCHECK)
        et = txtb.close()
        result = ElementTree.tostring(et)
        self.assertEqual(result, self.RESULTCHECK)

    def test_TemplateXML(self):
        tx = xml_utils.TemplateXML(self.FULLREPLACE, **self.MAPPING)
        et = ElementTree.ElementTree(None, tx.name)
        check = ElementTree.tostring(et.getroot())
        self.assertEqual(check, self.RESULTCHECK)

    def test_restore_fails(self):
        testmapping = {self.TEXT_REPLACE_KEY: "foobar"}
        xmlbackup = xml_utils.TemplateXML(self.XMLFILE, **testmapping)
        # Unless the backup was initialized from a string (into a temp file)
        # assume the source is read-only and should be protected.
        self.assertRaises(IOError, xmlbackup.restore)


if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = yumrepo
'''
This module implements classes that allow a user to create, enable and disable
YUM repositories on the system.
'''


import os


__all__ = ['REPO_DIR', 'YumRepo']


REPO_DIR = '/etc/yum.repos.d'


class YumRepo(object):

    '''
    Represents a YUM repository

    The goal of this class is not to give access to all features of a YUM
    Repository, but to provide a simple way to configure a valid one during
    a test run.

    Sample usage:
       >>> mainrepo = YumRepo("main", "http://download.project.org/repo",
                              "/etc/yum.repos.d/main.repo")

    Or to use a default path:
       >>> mainrepo = YumRepo("main", 'http://download.project.org/repo')

    And then:
       >>> mainrepo.save()

    When it comes to the repo URL, currently there's no support for setting a
    mirrorlist, only a baseurl.
    '''

    def __init__(self, name, baseurl, path=None):
        '''
        Initilizes a new YumRepo object

        If path is not given, it is assumed to be "$(name)s.repo" at
        the default YUM repo directory.

        :param name: the repository name
        :param path: the full path of the file that defines this repository
        '''
        self.name = name
        self.path = path
        if self.path is None:
            self.path = self._get_path_from_name(self.name)

        self.baseurl = baseurl

        self.enabled = True
        self.gpgcheck = False
        self.gpgkey = ''

    @classmethod
    def _get_path_from_name(cls, name):
        '''
        Returns the default path for the a repo of a given name

        :param name: the repository name
        :return: the default repo file path for the given name
        '''
        return os.path.join(REPO_DIR, "%s.repo" % name)

    @classmethod
    def _yum_value_for_boolean(cls, boolean):
        '''
        Returns a boolean in YUM acceptable syntax
        '''
        if boolean:
            return '1'
        else:
            return '0'

    def render(self):
        '''
        Renders the repo file

        Yes, we could use ConfigParser for this, but it produces files with
        spaces between keys and values, which look akward by YUM defaults.
        '''
        template = ("[%(name)s]\n"
                    "name=%(name)s\n"
                    "baseurl=%(baseurl)s\n"
                    "enabled=%(enabled)s\n"
                    "gpgcheck=%(gpgcheck)s\n"
                    "gpgkey=%(gpgkey)s\n")

        values = {'name': self.name,
                  'baseurl': self.baseurl,
                  'enabled': self._yum_value_for_boolean(self.enabled),
                  'gpgcheck': self._yum_value_for_boolean(self.gpgcheck),
                  'gpgkey': self.gpgkey}

        return template % values

    def save(self):
        '''
        Saves the repo file
        '''
        output_file = open(self.path, 'w')
        output_file.write(self.render())
        output_file.close()

    def remove(self):
        '''
        Removes the repo file
        '''
        if os.path.exists(self.path):
            os.unlink(self.path)

########NEW FILE########
