__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Plim documentation build configuration file, created by
# sphinx-quickstart on Tue Jun 12 15:21:53 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.intersphinx', 'sphinx.ext.todo', 'sphinx.ext.coverage', 'sphinx.ext.ifconfig', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.txt'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Plim'
copyright = u'2014, Maxim Avanov'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.9'
# The full version, including alpha/beta/rc tags.
release = '0.9.10'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Plimdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Plim.tex', u'Plim Documentation',
   u'Maxim Avanov', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'plim', u'Plim Documentation',
     [u'Maxim Avanov'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Plim', u'Plim Documentation',
   u'Maxim Avanov', 'Plim', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'Plim'
epub_author = u'Maxim Avanov'
epub_publisher = u'Maxim Avanov'
epub_copyright = u'2014, Maxim Avanov'

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# A tuple containing the cover image and cover page html template filenames.
#epub_cover = ()

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {'http://docs.python.org/': None}

########NEW FILE########
__FILENAME__ = babelplugin
"""gettext message extraction via Babel: http://babel.edgewall.org/"""
from mako.ext.babelplugin import extract as _extract_mako

from .. import preprocessor_factory
from ..util import StringIO, PY3K


def extractor_factory(preprocessor=None):
    if preprocessor is None:
        preprocessor = preprocessor_factory()

    def babel_extractor(fileobj, keywords, comment_tags, options):
        """ Extract messages from Plim templates.

        :param fileobj: the file-like object the messages should be extracted from
        :param keywords: a list of keywords (i.e. function names) that should be
                         recognized as translation functions
        :param comment_tags: a list of translator tags to search for and include
                             in the results
        :param options: a dictionary of additional options (optional)
        :return: an iterator over ``(lineno, funcname, message, comments)`` tuples
        :rtype: ``iterator``
        """
        raw_data = fileobj.read()
        if not PY3K:
            encoding = options.get('input_encoding', options.get('encoding', 'utf-8'))
            raw_data = raw_data.decode(encoding)
        data = preprocessor(raw_data)
        for extracted in _extract_mako(StringIO(data), keywords, comment_tags, options):
            yield extracted

    return babel_extractor

# Default Plim extractor
extract = extractor_factory()

########NEW FILE########
__FILENAME__ = pyramid_renderer
import copy
try:
    from pyramid_mako import MakoRendererFactory
    from pyramid_mako import parse_options_from_settings
    from pyramid_mako import PkgResourceTemplateLookup
except ImportError:
    raise NotImplementedError(
        "It seems that you are trying to integrate Plim with Pyramid. "
        "To do so, please install Pyramid>=1.5 and pyramid_mako>=0.3.1 template bindings."
    )


def add_plim_renderer(config, extension, mako_settings_prefix='mako.', preprocessor='plim.preprocessor'):
    """
    Register a Plim renderer for a template extension.

    This function is available on the Pyramid configurator after
    including the package:

    .. code-block:: python

        config.add_plim_renderer('.plim', mako_settings_prefix='mako.')

    The renderer will load its configuration from a provided mako prefix in the Pyramid
    settings dictionary. The default prefix is 'mako.'.

    :param config: Pyramid Config instance
    :param extension: renderer file extension
    :type extension: str
    :param mako_settings_prefix: prefix of mako configuration options.
    :type mako_settings_prefix: str
    """
    renderer_factory = MakoRendererFactory()
    config.add_renderer(extension, renderer_factory)

    def register():
        settings = copy.copy(config.registry.settings)
        settings['{prefix}preprocessor'.format(prefix=mako_settings_prefix)] = preprocessor

        opts = parse_options_from_settings(settings, mako_settings_prefix, config.maybe_dotted)
        lookup = PkgResourceTemplateLookup(**opts)

        renderer_factory.lookup = lookup

    # read about config.action() at
    # http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/extconfig.html#using-config-action-in-a-directive
    config.action(('plim-renderer', extension), register)


def includeme(config):
    """
    Set up standard configurator registrations. Use via:

    .. code-block:: python

        config = Configurator()
        config.include('pyramid_mako')

    Once this function has been invoked, the ``.plim`` renderer
    is available for use in Pyramid. This can be overridden and more may be
    added via the ``config.add_plim_renderer`` directive.
    """
    config.add_directive('add_plim_renderer', add_plim_renderer)
    config.add_plim_renderer('.plim')

########NEW FILE########
__FILENAME__ = console
"""
This module contains entry points for command-line utilities provided by Plim package.
"""
import sys
import os
import argparse
import codecs
from pkg_resources import get_distribution
from pkg_resources import EntryPoint

from mako.template import Template
from mako.lookup import TemplateLookup

from .util import PY3K


def plimc(args=None, stdout=None):
    """This is the `plimc` command line utility

    :param args: list of command-line arguments. If None, then ``sys.argv[1:]`` will be used.
    :type args: list or None
    :param stdout: file-like object representing stdout. If None, then ``sys.stdout`` will be used.
                   Custom stdout is used for testing purposes.
    :type stdout: None or a file-like object
    """
    # Parse arguments
    # ------------------------------------
    cli_parser = argparse.ArgumentParser(description='Compile plim source files into mako files.')
    cli_parser.add_argument('source', help="path to source plim template")
    cli_parser.add_argument('-o', '--output', help="write result to FILE.")
    cli_parser.add_argument('-e', '--encoding', default='utf-8', help="content encoding")
    cli_parser.add_argument('-p', '--preprocessor', default='plim:preprocessor',
                            help="Preprocessor instance that will be used for parsing the template")
    cli_parser.add_argument('-H', '--html', action='store_true', help="Render HTML output instead of Mako template")
    cli_parser.add_argument('-V', '--version', action='version',
                            version='Plim {}'.format(get_distribution("Plim").version))

    if args is None:
        args = sys.argv[1:]
    args = cli_parser.parse_args(args)

    # Get custom preprocessor, if specified
    # -------------------------------------
    preprocessor_path = args.preprocessor
    # Add an empty string path, so modules located at the current working dir
    # are reachable and considered in the first place (see issue #32).
    sys.path.insert(0, '')
    preprocessor = EntryPoint.parse('x={}'.format(preprocessor_path)).load(False)

    # Render to html, if requested
    # ----------------------------
    if args.html:
        root_dir = os.path.dirname(os.path.abspath(args.source))
        template_file = os.path.basename(args.source)
        lookup = TemplateLookup(directories=[root_dir],
                                input_encoding=args.encoding,
                                output_encoding=args.encoding,
                                preprocessor=preprocessor)
        content = lookup.get_template(template_file).render_unicode()
    else:
        with codecs.open(args.source, 'rb', args.encoding) as fd:
            content = preprocessor(fd.read())

    # Output
    # ------------------------------------
    if args.output is None:
        if stdout is None:
            stdout = PY3K and sys.stdout.buffer or sys.stdout
        fd = stdout
        content = codecs.encode(content, 'utf-8')
    else:
        fd = codecs.open(args.output, 'wb', args.encoding)
    try:
        fd.write(content)
    finally:
        fd.close()

########NEW FILE########
__FILENAME__ = errors
# -*- coding: utf-8 -*-
from .util import u



class PlimError(Exception):
    def __str__(self):
        return self.__unicode__().encode('utf-8')


class PlimSyntaxError(PlimError):
    def __init__(self, msg, line):
        super(PlimSyntaxError, self).__init__()
        self.msg = msg
        self.line = line

    def __unicode__(self):
        return u('{msg} | at line(pos) "{line}"').format(msg=self.msg, line=self.line)


class ParserNotFound(PlimError):
    def __init__(self, lineno, line):
        super(ParserNotFound, self).__init__()
        self.lineno = lineno
        self.line = line

    def __unicode__(self):
        return u("Invalid syntax at line {lineno}: {line}").format(
            lineno=self.lineno, line=self.line)

########NEW FILE########
__FILENAME__ = extensions
from docutils.core import publish_parts
import coffeescript
from scss import Scss
from stylus import Stylus

from .util import u



def rst_to_html(source):
    # This code was taken from http://wiki.python.org/moin/ReStructuredText
    # You may also be interested in http://www.tele3.cz/jbar/rest/about.html
    html = publish_parts(source=source, writer_name='html')
    return html['html_body']


def coffee_to_js(source):
    return u('<script>{js}</script>').format(js=coffeescript.compile(source))


def scss_to_css(source):
    css = Scss().compile(source).strip()
    return u('<style>{css}</style>').format(css=css)


def stylus_to_css(source):
    compiler = Stylus()
    return u('<style>{css}</style>').format(css=compiler.compile(source).strip())

########NEW FILE########
__FILENAME__ = lexer
# -*- coding: utf-8 -*-
"""Plim lexer"""
import functools
import re

import markdown2

from . import errors
from .util import StringIO, MAXSIZE, joined, space_separated, u
from .extensions import rst_to_html
from .extensions import coffee_to_js
from .extensions import scss_to_css
from .extensions import stylus_to_css


# Preface
# ============================================================================================

WHITESPACE = ' '
NEWLINE = '\n'
OPEN_BRACE = '('
CLOSE_BRACE = ')'

CSS_ID_SHORTCUT_DELIMITER = '#'
CSS_CLASS_SHORTCUT_DELIMITER = '.'
# used to separate tag attributes from its inline content and as a prefix of literal blocks
LITERAL_CONTENT_PREFIX = '|'
# Same as above but with the trailing whitespace
LITERAL_CONTENT_SPACE_PREFIX = ','
DYNAMIC_CONTENT_PREFIX = '='
DYNAMIC_CONTENT_SPACE_PREFIX = "=,"
DYNAMIC_ATTRIBUTES_PREFIX = '**'
# used to separate inline tags
INLINE_TAG_SEPARATOR = ':'
# used to separate attribute-value pairs from one another
ATTRIBUTES_DELIMITER = WHITESPACE
# used to separate attribute name from its value
# This is not the same as DYNAMIC_CONTENT_PREFIX
ATTRIBUTE_VALUE_DELIMITER = '='
# port of ruby's boolean methods:
# Ruby's Slim: selected=option_selected?("Slim")
# Python's Plim: selected=option_selected("Plim")?
BOOLEAN_ATTRIBUTE_MARKER = '?'
LINE_BREAK = '\\'

# Please note that in Plim all tag names are intentionally lower-cased
TAG_RULE = '(?P<html_tag>[a-z][a-z0-9]*)'
TAG_RE = re.compile(TAG_RULE)
LINE_PARTS_RE = re.compile('(?P<indent>\s*)(?P<line>.*)\s*')
MAKO_FILTERS_TAIL_RE = re.compile('\|\s*(?P<filters>[a-zA-Z][_.a-zA-Z0-9]*(?:,\s*[a-zA-Z][_.a-zA-Z0-9]*)*)\s*$')
NUMERIC_VALUE_RE = re.compile(
    # Order matters
    # Can parse -NUM, +NUM, NUM, .NUM, NUM% and all its combinations
    '(?P<value>(?:[-+]?[0-9]*\.[0-9]+|[-+]?[0-9]+%?))'
)

STATEMENT_CONVERT = {
    'unless': 'if not (',
    'until': 'while not ('
}

INLINE_PYTHON_TERMINATOR = '---'

CSS_ID_SHORTCUT_TERMINATORS = (
    CSS_CLASS_SHORTCUT_DELIMITER,
    WHITESPACE,
    OPEN_BRACE,
    INLINE_TAG_SEPARATOR
)

CSS_CLASS_SHORTCUT_TERMINATORS = (
    CSS_CLASS_SHORTCUT_DELIMITER,
    WHITESPACE,
    OPEN_BRACE,
    INLINE_TAG_SEPARATOR
)

ATTRIBUTE_TERMINATORS = (
    ATTRIBUTE_VALUE_DELIMITER,
    ATTRIBUTES_DELIMITER,
    INLINE_TAG_SEPARATOR,
    LITERAL_CONTENT_PREFIX,
    LITERAL_CONTENT_SPACE_PREFIX
)

ATTRIBUTE_TERMINATORS_WITH_PARENTHESES = (
    ATTRIBUTE_VALUE_DELIMITER,
    ATTRIBUTES_DELIMITER,
    CLOSE_BRACE
)

ATTRIBUTE_VALUE_TERMINATORS = (
    ATTRIBUTES_DELIMITER,
    INLINE_TAG_SEPARATOR,
    LITERAL_CONTENT_PREFIX,
    LITERAL_CONTENT_SPACE_PREFIX,
    DYNAMIC_CONTENT_PREFIX,
    BOOLEAN_ATTRIBUTE_MARKER
)

ATTRIBUTE_VALUE_TERMINATORS_WITH_PARENTHESES = (
    ATTRIBUTES_DELIMITER,
    INLINE_TAG_SEPARATOR,
    LITERAL_CONTENT_PREFIX,
    LITERAL_CONTENT_SPACE_PREFIX,
    DYNAMIC_CONTENT_PREFIX,
    BOOLEAN_ATTRIBUTE_MARKER,
    CLOSE_BRACE,
    NEWLINE
)

STATEMENT_TERMINATORS = {INLINE_TAG_SEPARATOR, NEWLINE}

PYTHON_EXPR_OPEN_BRACES_RE = re.compile('(?P<start_brace>\(|\{|\[).*')
PYTHON_EXPR_CLOSING_BRACES_RE = re.compile('\)|\}|\].*')

MAKO_EXPR_START_BRACE_RE = re.compile('(?P<start_brace>\$\{).*')
MAKO_EXPR_COUNT_OPEN_BRACES_RE = re.compile('\{')
MAKO_EXPR_COUNT_CLOSING_BRACES_RE = re.compile('\}')
QUOTES_RE = re.compile('(?P<quote_type>\'\'\'|"""|\'|").*') # order matters!

EMBEDDING_QUOTE = '`'
EMBEDDING_QUOTE_ESCAPE = EMBEDDING_QUOTE * 2
EMBEDDING_QUOTE_END = '`_'
EMBEDDING_QUOTES_RE = re.compile('(?P<quote_type>{quote_symbol}).*'.format(quote_symbol=EMBEDDING_QUOTE))


# ============================================================================================
# Okay, let's get started.
# There are three different types of functions below: searchers, parsers, and extractors.
# They are grouped together by API and task similarity.
#
# -- SEARCHERS are helper functions that try to figure out the next step of parsing process
#    based on the current chunk of data.
#    Each searcher MUST accept one required first positional argument *line*.
# ------------------------------
#
# -- PARSERS are the building blocks of Plim. They follow the strict API rules for both
#    input and return values.
#
#    Every parser MUST accept five input arguments:
#    1) ``indent_level`` - an indentation level of the current line. When the parser reaches a line
#       which indentation is lower or equal to ``indent_level``, it returns control to a top-level function.
#    2) ``current_line`` - a line which is being parsed. This is the line that has been matched by
#       ``matched`` object at the previous parsing step.
#    3) ``matched`` - an instance of ``re.MatchObject`` of the regex associated with the current parser.
#    4) ``source`` - an instance of an enumerated object returned by :func:`enumerate_source`.
#    5) ``syntax`` - an instance of one of :class:`plim.syntax.BaseSyntax` children.
#
#    Every parser MUST return a 4-tuple of:
#    1) parsed_data - a string of successfully parsed data
#    2) tail_indent - an indentation level of the ``tail line``
#    3) tail_line - a line which indentation level (``tail_indent``) is lower or equal to
#       the input ``indent_level``.
#    4) ``source`` - an instance of enumerated object returned by :func:`enumerate_source`
#       which represents the remaining (untouched) plim markup.
# ------------------------------
#
# -- EXTRACTORS are "light" versions of parsers. Their input arguments
#    and return values are task-specific. However, they still have several common features:
#      - Each extractor has its own starting and termination sequences.
#      - Each extractor tries to find the starting sequence of characters at the beginning
#        of the input line. If that attempt fails, the extractor returns None (in most cases).
#        If the attempt is successful, the extractor captures all the input characters up to
#        the termination sequence.
#      - The return value of the succeeded extractor MUST contain not only the extracted value,
#        but also an instance of enumerated object returned by :func:`enumerate_source`.
# ------------------------------
#
# P.S. I intentionally did not use "for" statements in conjunction with iterators.
# I wanted to make all parsers free from implicit side-effects.
# Therefore, you can find a number of "while True" and "try/except StopIteration" constructs below.

# Searchers
# ==================================================================================
def search_quotes(line, escape_char='\\', quotes_re=QUOTES_RE):
    """

    :param line: may be empty
    :type line: str
    :param escape_char:
    """
    match = quotes_re.match(line)
    if not match: return None

    find_seq = match.group('quote_type')
    find_seq_len = len(find_seq)
    pos = find_seq_len
    line_len = len(line)

    while pos < line_len:
        if line[pos] == escape_char:
            pos += 2
            continue
        if line[pos:].startswith(find_seq):
            return pos + find_seq_len
        pos += 1
    return None


def search_parser(lineno, line, syntax):
    """Finds a proper parser function for a given line or raises an error

    :param lineno:
    :param line:
    :type syntax: :class:`plim.syntax.BaseSyntax`
    """
    for template, parser in syntax.parsers:
        matched = template.match(line)
        if matched:
            return matched, parser
    raise errors.ParserNotFound(lineno, line)


# Extractors
# ==================================================================================
def extract_embedding_quotes(content):
    """
    ``content`` may be empty

    :param content:
    :param escape_seq:
    """
    match = EMBEDDING_QUOTES_RE.match(content)
    if not match:
        return None

    original_string = [EMBEDDING_QUOTE]
    embedded_string = []
    tail = content[1:]

    while tail:
        if tail.startswith(EMBEDDING_QUOTE_ESCAPE):
            original_string.append(EMBEDDING_QUOTE_ESCAPE)
            embedded_string.append(EMBEDDING_QUOTE)
            tail = tail[len(EMBEDDING_QUOTE_ESCAPE):]
            continue

        if tail.startswith(EMBEDDING_QUOTE):
            append_seq = EMBEDDING_QUOTE_END if tail.startswith(EMBEDDING_QUOTE_END) else EMBEDDING_QUOTE
            original_string.append(append_seq)
            original_string = joined(original_string)
            content = content[len(original_string):]
            embedded_string = joined(embedded_string)
            return embedded_string, original_string, content

        current_char = tail[0]
        original_string.append(current_char)
        embedded_string.append(current_char)
        tail = tail[1:]

    original_string = joined(original_string)
    pos = len(original_string)
    raise errors.PlimSyntaxError(u('Embedding quote is not closed: "{}"').format(original_string), pos)


def _extract_braces_expression(line, source, starting_braces_re, open_braces_re, closing_braces_re):
    """

    :param line: may be empty
    :type line: str
    :param source:
    :type source: str
    :param starting_braces_re:
    :param open_braces_re:
    :param closing_braces_re:
    """
    match = starting_braces_re.match(line)
    if not match:
        return None

    open_brace = match.group('start_brace')
    buf = [open_brace]
    tail = line[len(open_brace):]
    braces_counter = 1

    while True:
        if not tail:
            _, tail = next(source)
            tail = tail.lstrip()

        while tail:
            current_char = tail[0]
            if closing_braces_re.match(current_char):
                braces_counter -= 1
                buf.append(current_char)
                if braces_counter:
                    tail = tail[1:]
                    continue
                return joined(buf), tail[1:], source

            if current_char == NEWLINE:
                _, tail = next(source)
                tail = tail.lstrip()
                continue

            if open_braces_re.match(current_char):
                braces_counter += 1
                buf.append(current_char)
                tail = tail[1:]
                continue

            result = search_quotes(tail)
            if result is not None:
                buf.append(tail[:result])
                tail = tail[result:]
                continue

            buf.append(current_char)
            tail = tail[1:]


extract_braces = lambda line, source: _extract_braces_expression(line, source,
    PYTHON_EXPR_OPEN_BRACES_RE,
    PYTHON_EXPR_OPEN_BRACES_RE,
    PYTHON_EXPR_CLOSING_BRACES_RE
)

extract_mako_expression = lambda line, source: _extract_braces_expression(line, source,
    MAKO_EXPR_START_BRACE_RE,
    MAKO_EXPR_COUNT_OPEN_BRACES_RE,
    MAKO_EXPR_COUNT_CLOSING_BRACES_RE
)


def extract_identifier(line, source, identifier_start='#', terminators=('.', ' ', CLOSE_BRACE, INLINE_TAG_SEPARATOR)):
    """

    :param line: Current line. It may be empty.
    :type line: str or unicode
    :param source:
    :type source: str
    :param identifier_start:
    :param terminators:
    :type terminators: tuple or set
    """
    if not line or not line.startswith(identifier_start):
        return None

    pos = len(identifier_start)
    buf = [identifier_start]
    tail = line[pos:]
    while tail:
        for terminator in terminators:
            if tail.startswith(terminator):
                return joined(buf).rstrip(), tail, source

        # Let's try to find "mako variable" part of possible css-identifier
        result = extract_mako_expression(tail, source)
        if result:
            expr, tail, source = result
            buf.append(expr)
            continue

        # Check for a string object
        result = search_quotes(tail)
        if result is not None:
            buf.append(tail[:result])
            tail = tail[result:]
            continue

        # Try to search braces of function calls etc
        result = extract_braces(tail, source)
        if result:
            result, tail, source = result
            buf.append(result)
            continue
        current_char = tail[0]
        buf.append(current_char)
        tail = tail[1:]
    return joined(buf).rstrip(), tail, source


def extract_digital_attr_value(line):
    result = NUMERIC_VALUE_RE.match(line)
    if result:
        return result.group('value'), line[result.end():]
    return None


def extract_quoted_attr_value(line, search_quotes=search_quotes, remove_escape_seq=True):
    """

    :param line:
    :param search_quotes:
    :param remove_escape_seq: Sometimes escape sequences have to be removed outside of the extractor.
                              This flag prevents double-escaping of backslash sequences.
    :return:
    """
    result = search_quotes(line)
    if result:
        if line.startswith('"""') or line.startswith("'''"):
            skip = 3
        else:
            skip = 1
        # remove quotes from value
        value = line[skip:result - skip]
        # We have to remove backslash escape sequences from the value, but
        # at the same time, preserve unicode escape sequences like "\u4e2d\u6587".
        if remove_escape_seq:
            value = value.encode('raw_unicode_escape')
            value = value.decode('unicode_escape')
        return value, line[result:]
    return None


def extract_dynamic_attr_value(line, source, terminators, syntax):
    result = extract_identifier(line, source, '', terminators)
    if result is None:
        return None
    result, tail, source = result
    if MAKO_EXPR_START_BRACE_RE.match(line):
        # remove VARIABLE_PLACEHOLDER_START_SEQUENCE and VARIABLE_PLACEHOLDER_END_SEQUENCE from variable
        value = result[len(syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE):-len(syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE)]
    elif line.startswith(OPEN_BRACE):
        # remove "(" and ")" from variable
        value = result[1:-1]
    else:
        value = result
    return value, tail, source


def extract_dynamic_tag_attributes(line, source, syntax, inside_parentheses=False):
    """
    Extract one occurrence of ``**dynamic_attributes``
    :param line:
    :param source:
    :param inside_parentheses:
    """
    if not line.startswith(DYNAMIC_ATTRIBUTES_PREFIX):
        return None
    line = line[len(DYNAMIC_ATTRIBUTES_PREFIX):]

    terminators = {
        WHITESPACE,
        NEWLINE,
        LITERAL_CONTENT_PREFIX,
        LITERAL_CONTENT_SPACE_PREFIX,
        # we want to terminate extract_identifier() by DYNAMIC_ATTRIBUTES_PREFIX,
        # but it contains two characters, whereas the function checks only one character.
        # Therefore, we use a single asterisk terminator here instead of DYNAMIC_ATTRIBUTES_PREFIX.
        '*',
        INLINE_TAG_SEPARATOR,
        LINE_BREAK
    }
    if inside_parentheses:
        terminators.add(CLOSE_BRACE)

    result = extract_identifier(line, source, '', terminators)
    if result is None:
        return None

    expr, tail, source = result
    attributes = u(
        '\n%for __plim_key__, __plim_value__ in {expr}.items():\n'
        '{var_start}__plim_key__{var_end}="{var_start}__plim_value__{var_end}"\n'
        '%endfor\n'
    ).format(
        expr=expr,
        var_start=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
        var_end=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
    )
    return attributes, tail, source



def extract_tag_attribute(line, source, syntax, inside_parentheses=False):
    """

    :param line:
    :param source:
    :param inside_parentheses:
    :return:
    """
    terminators = inside_parentheses and ATTRIBUTE_TERMINATORS_WITH_PARENTHESES or ATTRIBUTE_TERMINATORS
    result = extract_identifier(line, source, '', terminators)
    if result and result[0]:
        result, tail, source = result
        attr_name = result
        if tail.startswith(ATTRIBUTE_VALUE_DELIMITER):
            # value is presented in a form of
            # =${dynamic_value} or =dynamic_value or ="value with spaces"
            # ------------------------------------------------------------------
            # remove ATTRIBUTE_VALUE_DELIMITER
            tail = tail[1:]
            # 1. Try to parse quoted literal value
            # -------------------------------------
            result = extract_quoted_attr_value(tail)
            if result:
                value, tail = result
                # remove possible newline character
                value = value.rstrip()
                return u('{attr_name}="{value}"').format(attr_name=attr_name, value=value), tail, source

            # 2. Try to parse digital value
            # -------------------------------------
            result = extract_digital_attr_value(tail)
            if result:
                value, tail = result
                return u('{attr_name}="{value}"').format(attr_name=attr_name, value=value), tail, source

            # 3. Try to parse dynamic value
            # -------------------------------------
            terminators = inside_parentheses and ATTRIBUTE_VALUE_TERMINATORS_WITH_PARENTHESES or ATTRIBUTE_VALUE_TERMINATORS
            result = extract_dynamic_attr_value(tail, source, terminators, syntax)

            if result:
                value, tail, source = result
                # remove possible newline character
                value = value.rstrip()
                if tail.startswith(BOOLEAN_ATTRIBUTE_MARKER):
                    # selected=dynamic_variable?
                    value = u("""{start_var}({value}) and '{attr_name}="{attr_name}"' or ''|n{end_var}""").format(
                        value=value,
                        attr_name=attr_name,
                        start_var=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
                        end_var=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
                    )
                    attribute = value
                    tail = tail[1:]
                else:
                    attribute = u('{attr_name}="{start_var}{value}{end_var}"').format(
                        attr_name=attr_name,
                        value=value,
                        start_var=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
                        end_var=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
                    )
                return attribute, tail, source
            return None

        elif inside_parentheses and tail.startswith(ATTRIBUTES_DELIMITER) or tail.startswith(CLOSE_BRACE):
            # attribute is presented in a form of boolean attribute
            # which should be converted to attr="attr"
            return u('{attr_name}="{attr_name}"').format(attr_name=attr_name), tail, source
        else:
            return None
    return None


def extract_line_break(tail, source):
    """
    Checks the first character of the tail.

    :param tail:
    :param source:
    :return:
    """
    found = False
    while True:
        if tail.startswith(LINE_BREAK):
            found = True
            try:
                _, tail = next(source)
            except StopIteration:
                return found, '', source
            tail = tail.lstrip()
            continue
        break
    return found, tail, source


def extract_statement_expression(tail, source):
    """

    :param tail:
    :param source:
    :return:
    """
    buf = []
    # Ensure that tail ends with a newline character
    # (required by extract_braces() to properly handle multi-line expressions)
    tail = tail.strip() + '\n'
    while tail:
        # Try to search braces of function calls etc
        found, tail, source = extract_line_break(tail, source)
        if found:
            buf.append(' ')
        result = extract_braces(tail, source)
        if result:
            head, tail, source = result
            buf.append(head)
            continue
        buf.append(tail[0])
        tail = tail[1:]
    return joined(buf).strip(), source


def extract_tag_line(line, source, syntax):
    """
    Returns a 3-tuple of inline tags sequence, closing tags sequence, and a dictionary of
    last tag components (name, attributes, content)

    :param line:
    :type line: str
    :param source:
    :type source: enumerate
    :param parsers: 2-tuple of (parser_regex, parser_callable)
    :type parsers: tuple
    """
    buf = []
    close_buf = []
    components = {}
    tail = line

    while tail:
        tag_composer = ['<']
        # Get tag name
        match = TAG_RE.match(tail)
        if match:
            html_tag = match.group('html_tag').lower()
            tail = tail[match.end():]
        else:
            html_tag = 'div'
        tag_composer.append(html_tag)
        components['name'] = html_tag

        # 1. Parse css id
        # --------------------------------------------
        result = extract_identifier(tail, source, CSS_ID_SHORTCUT_DELIMITER, CSS_ID_SHORTCUT_TERMINATORS)
        if result is None:
            css_id = ''
        else:
            result, tail, source = result
            # remove the preceding '#' character
            css_id = result[1:].rstrip()

        # 2. Parse css class shortcut
        # --------------------------------------------
        class_identifiers = []
        while True:
            result = extract_identifier(tail, source, CSS_CLASS_SHORTCUT_DELIMITER, CSS_CLASS_SHORTCUT_TERMINATORS)
            if result:
                result, tail, source = result
                # remove the preceding '.' character
                class_identifiers.append(result[1:].rstrip())
                continue
            break

        # 3. Parse tag attributes
        # -----------------------------------
        _, tail, source = extract_line_break(tail.lstrip(), source)
        inside_parentheses = tail.startswith(OPEN_BRACE)
        if inside_parentheses:
            tail = tail[1:].lstrip()

        attributes = []
        while True:
            _, tail, source = extract_line_break(tail.lstrip(), source)

            # 3.1 try to get and unpack dynamic attributes
            result = extract_dynamic_tag_attributes(tail, source, syntax, inside_parentheses)
            if result:
                dynamic_attrs, tail, source = result
                attributes.append(dynamic_attrs)
                continue

            # 3.2. get attribute-value pairs until the end of the section (indicated by terminators)
            result = extract_tag_attribute(tail, source, syntax, inside_parentheses)
            if result:
                attribute_pair, tail, source = result
                if attribute_pair.startswith('id="') and css_id:
                    raise errors.PlimSyntaxError('Your template has two "id" attribute definitions', line)
                if attribute_pair.startswith('class="'):
                    # len('class="') == 7
                    class_identifiers.append(attribute_pair[7:-1])
                    continue

                attributes.append(attribute_pair)
                continue
            else:
                if inside_parentheses and not tail:
                    # We have reached the end of the line.
                    # Try to parse multiline attributes list.
                    lineno, tail = next(source)
                    continue
                if css_id:
                    attributes.append(u('id="{ids}"').format(ids=css_id))
                if class_identifiers:
                    class_identifiers = space_separated(class_identifiers)
                    attributes.append(u('class="{classes}"').format(classes=class_identifiers))
            break
        attributes = space_separated(attributes)
        components['attributes'] = attributes
        if attributes:
            tag_composer.extend([' ', attributes])

        # 3.2 syntax check
        if inside_parentheses:
            if tail.startswith(CLOSE_BRACE):
                # We have reached the end of attributes definition
                tail = tail[1:].lstrip()
            else:
                raise errors.PlimSyntaxError("Unexpected end of line", tail)
        else:
            if tail.startswith(' '):
                tail = tail.lstrip()

        if html_tag in EMPTY_TAGS:
            tag_composer.append('/>')
        else:
            tag_composer.append('>')
            close_buf.append(u('</{tag}>').format(tag=html_tag))
        buf.append(joined(tag_composer))

        if tail.startswith(INLINE_TAG_SEPARATOR):
            tail = tail[1:].lstrip()
            break

        # 3.3 The remainder of the line will be treated as content
        # ------------------------------------------------------------------
        components['content'] = ''
        if tail:
            if tail.startswith(DYNAMIC_CONTENT_PREFIX):
                tail = tail[1:]
                if tail.startswith(DYNAMIC_CONTENT_PREFIX):
                    # case for the '==' prefix
                    tail = _inject_n_filter(tail)
                    if tail.startswith(DYNAMIC_CONTENT_SPACE_PREFIX):
                        # ensure that a single whitespace is appended
                        tail, source = extract_statement_expression(tail[2:], source)
                        buf.append(u("{start_var}{content}{end_var} ").format(
                            content=tail,
                            start_var=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
                            end_var=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
                        ))
                    else:
                        tail, source = extract_statement_expression(tail[1:], source)
                        buf.append(u("{start_var}{content}{end_var}").format(
                            content=tail,
                            start_var=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
                            end_var=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
                        ))
                else:
                    if tail.startswith(LITERAL_CONTENT_SPACE_PREFIX):
                        # ensure that a single whitespace is appended
                        tail, source = extract_statement_expression(tail[1:], source)
                        buf.append(u("{start_var}{content}{end_var} ").format(
                            content=tail,
                            start_var=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
                            end_var=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
                        ))
                    else:
                        tail, source = extract_statement_expression(tail, source)
                        buf.append(u("{start_var}{content}{end_var}").format(
                            content=tail,
                            start_var=syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE,
                            end_var=syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE
                        ))

            elif tail.startswith(LITERAL_CONTENT_PREFIX):
                tail = _parse_embedded_markup(tail[1:].strip(), syntax)
                buf.append(tail)

            elif tail.startswith(LITERAL_CONTENT_SPACE_PREFIX):
                tail = _parse_embedded_markup(tail[1:].strip(), syntax)
                buf.append(u("{content} ").format(content=tail))

            else:
                tail = _parse_embedded_markup(tail.strip(), syntax)
                buf.append(tail)
            components['content'] = buf[-1]
        tail = ''

    return joined(buf), joined(reversed(close_buf)), components, tail, source


# Parsers
# ==================================================================================
def parse_style_script(indent_level, current_line, matched, source, syntax):
    """

    :param indent_level:
    :param current_line:
    :type current_line: str
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    extracted_html_line, close_buf, _, tail, source = extract_tag_line(current_line, source, syntax)
    buf = [extracted_html_line, '\n']
    parsed_data, tail_indent, tail_line, source = parse_explicit_literal_no_embedded(
        indent_level,
        LITERAL_CONTENT_PREFIX,
        matched,
        source,
        syntax
    )
    buf.extend([parsed_data, close_buf])
    return joined(buf), tail_indent, tail_line, source


def parse_doctype(indent_level, current_line, ___, source, syntax):
    """

    :param indent_level:
    :param current_line:
    :param ___:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    match = syntax.PARSE_DOCTYPE_RE.match(current_line.strip())
    doctype = match.group('type')
    return DOCTYPES.get(doctype, DOCTYPES['5']), indent_level, '', source


def parse_handlebars(indent_level, current_line, ___, source, syntax):
    """

    :param indent_level:
    :param current_line:
    :param ___:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    processed_tag, tail_indent, tail_line, source = parse_tag_tree(indent_level, current_line, ___, source, syntax)
    assert processed_tag.startswith("<handlebars") and processed_tag.endswith("</handlebars>")
    # We don't want to use str.replace() here, therefore
    # len("<handlebars") == len("handlebars>") == 11
    processed_tag = u(
        '<script type="text/x-handlebars"{content}script>'
    ).format(
        content=processed_tag[11:-11]
    )
    return processed_tag, tail_indent, tail_line, source


def parse_tag_tree(indent_level, current_line, ___, source, syntax):
    """

    :param indent_level:
    :param current_line:
    :param ___:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return: 4-tuple
    """
    buf = []
    close_buf = []
    current_line = current_line.strip()
    html_tag, close_seq, _, tail, source = extract_tag_line(current_line, source, syntax)
    buf.append(html_tag)
    close_buf.append(close_seq)
    if tail:
        parsed, tail_indent, tail_line, source = parse_plim_tail(0, indent_level, tail, source, syntax)
        # at this point we have tail_indent <= indent_level
        buf.extend(parsed)
        buf.append(joined(close_buf))
        return joined(buf), tail_indent, tail_line, source

    while True:
        try:
            lineno, current_line = next(source)
        except StopIteration:
            break

        tail_indent, tail_line = scan_line(current_line)
        if not tail_line:
            continue
        if tail_indent <= indent_level:
            buf.append(joined(close_buf))
            return joined(buf), tail_indent, tail_line, source

        # ----------------------------------------------------------
        while tail_line:
            matched_obj, parse = search_parser(lineno, tail_line, syntax)
            parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
            buf.append(parsed_data)
            if tail_indent <= indent_level:
                buf.append(joined(close_buf))
                return joined(buf), tail_indent, tail_line, source

    buf.append(joined(close_buf))
    return joined(buf), 0, '', source


def parse_markup_languages(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    markup_parser = MARKUP_LANGUAGES[matched.group('lang')]
    parsed_data, tail_indent, tail_line, source = parse_explicit_literal_no_embedded(
        indent_level,
        LITERAL_CONTENT_PREFIX,
        matched,
        source,
        syntax
        )
    # This is slow but correct.
    # Trying to remove redundant indentation
    parsed_data = markup_parser(parsed_data)
    return parsed_data.strip(), tail_indent, tail_line, source


def parse_python(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    # TODO: merge with parse_mako_text()
    if matched.group('python').endswith('!'):
        buf = ['<%!\n']
    else:
        buf = ['<%\n']
    inline_statement = matched.group('expr')
    if inline_statement:
        buf.extend([inline_statement.strip(), '\n'])

    parsed_data, tail_indent, tail_line, source = parse_explicit_literal_no_embedded(
        indent_level,
        LITERAL_CONTENT_PREFIX,
        matched,
        source,
        syntax
        )
    # do not render a python block if it's empty
    if not inline_statement and not parsed_data:
        return u(''), tail_indent, tail_line, source

    buf.extend([u('{literal}\n').format(literal=parsed_data.rstrip()), '%>\n'])
    return joined(buf), tail_indent, tail_line, source


def parse_python_new_style(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    buf = [matched.group('excl') and '-py! ' or '-py ']
    inline_statement = matched.group('expr')
    if inline_statement:
        inline_statement, _tail_line_, source = extract_identifier(inline_statement, source, '', {INLINE_PYTHON_TERMINATOR, NEWLINE})
        buf.append(inline_statement)
    converted_line = joined(buf).strip()
    match = syntax.PARSE_PYTHON_CLASSIC_RE.match(converted_line)
    return parse_python(indent_level, __, match, source, syntax)



def parse_mako_text(indent, __, matched, source, syntax):
    """

    :param indent:
    :param __:
    :param matched:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    _, __, components, tail, source = extract_tag_line(matched.group('line').strip(), source, syntax)
    buf = ['\n<%text']
    if components['attributes']:
        buf.extend([' ', components['attributes']])
    buf.append('>\n')
    if components['content']:
        buf.extend([components['content'], '\n'])

    parsed_data, tail_indent, tail_line, source = parse_explicit_literal_no_embedded(
        indent,
        LITERAL_CONTENT_PREFIX,
        matched,
        source,
        syntax
        )
    if parsed_data:
        buf.append(u('{literal}\n').format(literal=parsed_data.rstrip()))
    buf.append('</%text>\n')
    return joined(buf), tail_indent, tail_line, source


def parse_call(indent_level, current_line, matched, source, syntax):
    """

    :param indent_level:
    :param current_line:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return: :raise:
    """
    _, __, components, tail, source = extract_tag_line(matched.group('line').strip(), source, syntax)
    tag = components['content'].strip()
    if not tag:
        raise errors.PlimSyntaxError("-call must contain namespace:defname declaration", current_line)
    buf = [u('\n<%{tag}').format(tag=tag)]
    if components['attributes']:
        buf.extend([' ', components['attributes']])
    buf.append('>\n')

    while True:
        try:
            lineno, tail_line = next(source)
        except StopIteration:
            break

        tail_indent, tail_line = scan_line(tail_line)
        if not tail_line:
            continue
        # Parse tree
        # --------------------------------------------------------
        while tail_line:
            if tail_indent <= indent_level:
                buf.append(u('</%{tag}>\n').format(tag=tag))
                return joined(buf), tail_indent, tail_line, source

            # tail_indent > indent_level
            matched_obj, parse = search_parser(lineno, tail_line, syntax)
            parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
            buf.append(parsed_data)
    buf.append(u('</%{tag}>\n').format(tag=tag))
    return joined(buf), 0, '', source


def parse_comment(indent_level, __, ___, source, syntax):
    """

    :param indent_level:
    :param __:
    :param ___:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    while True:
        try:
            lineno, tail_line = next(source)
        except StopIteration:
            break
        tail_indent, tail_line = scan_line(tail_line)
        if not tail_line:
            continue
        if tail_indent <= indent_level:
            return '', tail_indent, tail_line, source
    return '', 0, '', source


def parse_statements(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    stmnt = matched.group('stmnt')
    expr = matched.group('expr')
    buf = [u('\n{statement_start}{statement}').format(
        statement_start=syntax.STATEMENT_START_START_SEQUENCE,
        statement=stmnt
    )]
    if expr:
        expr, source = extract_statement_expression(expr, source)
        expr, tail_line, source = extract_identifier(expr, source, '', STATEMENT_TERMINATORS)
        expr = expr.lstrip()
        tail_line = tail_line[1:].lstrip()
        parsed, tail_indent, tail_line, source = parse_plim_tail(0, indent_level, tail_line, source, syntax)
        buf.append(joined([' ', expr, syntax.STATEMENT_START_END_SEQUENCE, '\n', joined(parsed)]))
    else:
        # So far only the "-try" statement has empty ``expr`` part
        buf.extend([syntax.STATEMENT_START_END_SEQUENCE, '\n'])
        try:
            lineno, tail_line = next(source)
        except StopIteration:
            tail_indent = 0
            tail_line = ''
        else:
            tail_indent, tail_line = scan_line(tail_line)

    def complete_statement(buf, tail_indent, tail_line, source, statement, syntax):
        buf.extend([
            '\n',
            syntax.STATEMENT_END_START_SEQUENCE,
            u('end{statement}').format(statement=statement),
            syntax.STATEMENT_END_END_SEQUENCE,
            '\n'
        ])
        return joined(buf), tail_indent, tail_line, source

    while True:
        # Parse tree
        # --------------------------------------------------------
        while tail_line:
            if stmnt == 'if':
                if tail_indent == indent_level:
                    # Check for elif/else
                    match = syntax.PARSE_ELIF_ELSE_RE.match(tail_line)
                    if match:
                        if match.group('control') == 'elif':
                            expr, source = extract_statement_expression(match.group('expr'), source)
                            expr, tail_line, source = extract_identifier(expr, source, '', STATEMENT_TERMINATORS)
                            expr = expr.lstrip()
                            tail_line = tail_line[1:].lstrip()
                            parsed, tail_indent, tail_line, source = parse_plim_tail(0, indent_level, tail_line, source, syntax)
                            buf.append(joined([
                                '\n',
                                syntax.STATEMENT_START_START_SEQUENCE,
                                u('elif {expr}').format(expr=expr),
                                syntax.STATEMENT_START_END_SEQUENCE,
                                '\n',
                                joined(parsed)
                            ]))
                            if tail_line:
                                continue
                            break
                        else:
                            # "-else" is found
                            expr = match.group('expr')
                            result = extract_identifier(expr, source, '', STATEMENT_TERMINATORS)
                            if result:
                                expr, tail_line, source = extract_identifier(expr, source, '', STATEMENT_TERMINATORS)
                                tail_line = tail_line[1:].lstrip()
                                parsed, tail_indent, tail_line, source = parse_plim_tail(0, indent_level, tail_line, source, syntax)
                                buf.append(joined([
                                    '\n',
                                    syntax.STATEMENT_START_START_SEQUENCE,
                                    'else',
                                    syntax.STATEMENT_START_END_SEQUENCE,
                                    '\n',
                                    joined(parsed)
                                ]))
                                if tail_line:
                                    continue
                            buf.append(joined([
                                '\n',
                                syntax.STATEMENT_START_START_SEQUENCE,
                                'else',
                                syntax.STATEMENT_START_END_SEQUENCE,
                                '\n'
                            ]))
                            break
                    else:
                        # elif/else is not found, finalize and return buffer
                        return complete_statement(buf, tail_indent, tail_line, source, stmnt, syntax)

                elif tail_indent < indent_level:
                    return complete_statement(buf, tail_indent, tail_line, source, stmnt, syntax)

                # tail_indent > indent_level
                matched_obj, parse = search_parser(lineno, tail_line, syntax)
                parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
                buf.append(parsed_data)

            elif stmnt == 'try':
                if tail_indent == indent_level:
                    # Check for except/else/finally
                    match = syntax.PARSE_EXCEPT_ELSE_FINALLY_RE.match(tail_line)
                    if match:
                        if match.group('control') == 'except':
                            expr, source = extract_statement_expression(match.group('expr'), source)
                            buf.append(u('\n%except {expr}:\n').format(expr=expr))
                            break
                        elif match.group('control') == 'else':
                            buf.append('\n%else:\n')
                            break
                        else:
                            # "-finally" is found
                            buf.append('\n%finally:\n')
                            break
                    else:
                        # elif/else is not found, finalize and return the buffer
                        return complete_statement(buf, tail_indent, tail_line, source, stmnt, syntax)

                elif tail_indent < indent_level:
                    return complete_statement(buf, tail_indent, tail_line, source, stmnt, syntax)

                # tail_indent > indent_level
                matched_obj, parse = search_parser(lineno, tail_line, syntax)
                parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
                buf.append(parsed_data)

            else: # stmnt == for/while
                if tail_indent <= indent_level:
                    return complete_statement(buf, tail_indent, tail_line, source, stmnt, syntax)

                # tail_indent > indent_level
                matched_obj, parse = search_parser(lineno, tail_line, syntax)
                parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
                buf.append(parsed_data)

        try:
            lineno, tail_line = next(source)
        except StopIteration:
            break
        tail_indent, tail_line = scan_line(tail_line)

    return complete_statement(buf, 0, '', source, stmnt, syntax)



def parse_foreign_statements(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    stmnt = STATEMENT_CONVERT[matched.group('stmnt')]
    buf = [u('-{statement}').format(statement=stmnt)]
    expr = matched.group('expr')
    expr, source = extract_statement_expression(expr, source)
    buf.append(joined([expr, ')']))

    matched = syntax.PARSE_STATEMENTS_RE.match(joined(buf))
    return parse_statements(indent_level, __, matched, source, syntax)


def parse_explicit_literal(indent_level, current_line, ___, source, syntax, parse_embedded):
    """
    Parses lines and blocks started with the "|" (pipe) or "," (comma) character.

    :param indent_level:
    :param current_line:
    :param ___:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :param parse_embedded: whether to parse possible embedded Plim markup
    :type parse_embedded: bool
    """
    # Get rid of the pipe character
    trailing_space_required = current_line[0] == LITERAL_CONTENT_SPACE_PREFIX

    # ---------------------------------
    def prepare_result(buf):
        result = joined(buf).rstrip()
        if trailing_space_required:
            result = u("{} ").format(result)
        if parse_embedded:
            result = _parse_embedded_markup(result, syntax)
        return result

    # --------------------------------
    current_line = current_line[1:]
    _, striped_line = scan_line(current_line)
    # Add line and trailing newline character
    buf = [current_line.strip(), striped_line and "\n" or ""]

    align = MAXSIZE
    while True:
        try:
            lineno, current_line = next(source)
        except StopIteration:
            break
        indent, line = scan_line(current_line)
        if not line:
            buf.append('\n')
            continue
        if indent <= indent_level:
            result = prepare_result(buf)
            return result, indent, line, source

        new_align = len(current_line) - len(current_line.lstrip())
        if align > new_align:
            align = new_align
        # remove preceding spaces
        line = current_line[align:].rstrip()
        buf.extend([line.rstrip(), "\n"])

    result = prepare_result(buf)
    return result, 0, '', source

parse_explicit_literal_with_embedded_markup = functools.partial(parse_explicit_literal, parse_embedded=True)
parse_explicit_literal_no_embedded = functools.partial(parse_explicit_literal, parse_embedded=False)


def _parse_embedded_markup(content, syntax):
    """

    :param content:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    :rtype: str
    """
    buf = []
    tail = content
    while tail:
        if tail.startswith(EMBEDDING_QUOTE_ESCAPE):
            tail = tail[len(EMBEDDING_QUOTE_ESCAPE):]
            buf.append(EMBEDDING_QUOTE)
            continue
        result = extract_embedding_quotes(tail)
        if result:
            embedded, original, tail = result
            embedded = embedded.strip()
            if embedded:
                try:
                    embedded = compile_plim_source(embedded, syntax, False)
                except errors.ParserNotFound:
                    # invalid plim markup, leave things as is
                    buf.append(original)
                else:
                    buf.append(embedded)
            continue

        buf.append(tail[0])
        tail = tail[1:]

    return joined(buf)


def _inject_n_filter(line):
    """
    This is a helper function for :func:parse_variable

    :param line:
    """
    # try to find specified filters
    found_filters = MAKO_FILTERS_TAIL_RE.search(line)
    if found_filters:
        # inject "n" filter to specified filters chain
        line = u('{expr}n,{filters}').format(
            expr=line[:found_filters.start('filters')].rstrip(),
            filters=line[found_filters.start('filters'):]
        )
    else:
        line = u('{expr}|n').format(expr=line)
    return line


def parse_variable(indent_level, __, matched, source, syntax):
    """ = variable or == variable

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    explicit_space = matched.group('explicit_space') and ' ' or ''
    prevent_escape = matched.group('prevent_escape')
    buf = [syntax.VARIABLE_PLACEHOLDER_START_SEQUENCE, matched.group('line')]
    while True:
        try:
            lineno, current_line = next(source)
        except StopIteration:
            break
        indent, line = scan_line(current_line)
        if not line:
            continue
        if indent <= indent_level:
            buf = joined(buf)
            if prevent_escape:
                buf = _inject_n_filter(buf)
            # add a closing brace to complete variable expression syntax ("${}" in case of mako).
            buf += syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE + explicit_space
            return buf, indent, line, source
        buf.append(line.strip())

    buf = joined(buf)
    if prevent_escape:
        buf = _inject_n_filter(buf)
    buf += syntax.VARIABLE_PLACEHOLDER_END_SEQUENCE + explicit_space
    return buf, 0, '', source


def parse_early_return(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    return u('\n<% {keyword} %>\n').format(keyword=matched.group('keyword')), indent_level, '', source


def parse_implicit_literal(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    return parse_explicit_literal_with_embedded_markup(
        indent_level,
        u('{}{}').format(LITERAL_CONTENT_PREFIX, matched.group('line')),
        matched,
        source,
        syntax
    )


def parse_raw_html(indent_level, current_line, ___, source, syntax):
    """

    :param indent_level:
    :param current_line:
    :param ___:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    buf = [current_line.strip(), '\n']
    while True:
        try:
            lineno, tail_line = next(source)
        except StopIteration:
            break
        tail_indent, tail_line = scan_line(tail_line)
        if not tail_line:
            continue
        # Parse a tree
        # --------------------------------------------------------
        while tail_line:
            if tail_indent <= indent_level:
                return joined(buf), tail_indent, tail_line, source

            # tail_indent > indent_level
            matched_obj, parse = search_parser(lineno, tail_line, syntax)
            parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
            buf.append(parsed_data)

    return joined(buf), 0, '', source


def parse_mako_one_liners(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    _, __, components, tail, source = extract_tag_line(matched.group('line').strip(), source, syntax)
    buf = [u('<%{tag}').format(tag=components['name'])]
    if components['content']:
        buf.append(u(' file="{name}"').format(name=components['content']))
    if components['attributes']:
        buf.extend([' ', components['attributes']])
    buf.append('/>')
    return joined(buf), indent_level, '', source


def parse_def_block(indent_level, __, matched, source, syntax):
    """

    :param indent_level:
    :param __:
    :param matched:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    _, __, components, tail, source = extract_tag_line(matched.group('line'), source, syntax)
    tag = components['name']
    buf = [u('<%{def_or_block}').format(def_or_block=tag)]
    if components['content']:
        buf.append(u(' name="{name}"').format(name=components['content'].strip()))
    if components['attributes']:
        buf.extend([' ', components['attributes']])
    buf.append('>\n')

    while True:
        try:
            lineno, tail_line = next(source)
        except StopIteration:
            break
        tail_indent, tail_line = scan_line(tail_line)
        if not tail_line:
            continue
        # Parse a tree
        # --------------------------------------------------------
        while tail_line:
            if tail_indent <= indent_level:
                buf.append(u('</%{def_or_block}>\n').format(def_or_block=tag))
                return joined(buf), tail_indent, tail_line, source

            # tail_indent > indent_level
            matched_obj, parse = search_parser(lineno, tail_line, syntax)
            parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
            buf.append(parsed_data)

    buf.append(u('</%{def_or_block}>\n').format(def_or_block=tag))
    return joined(buf), 0, '', source


def parse_plim_tail(lineno, indent_level, tail_line, source, syntax):
    """

    :param lineno:
    :param indent_level:
    :param tail_line:
    :param source:
    :param syntax: an instance of one of :class:`plim.syntax.BaseSyntax` children.
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :return:
    """
    buf = []
    tail_indent = indent_level
    while tail_line:
        matched_obj, parse = search_parser(lineno, tail_line, syntax)
        parsed_data, tail_indent, tail_line, source = parse(indent_level, tail_line, matched_obj, source, syntax)
        buf.append(parsed_data)
        if tail_indent <= indent_level:
            break
    return buf, tail_indent, tail_line, source


# Miscellaneous utilities
# ==================================================================================
def enumerate_source(source):
    """

    :param source:
    :return:
    """
    return enumerate(StringIO(source), start=1)


def scan_line(line):
    """ Returns a 2-tuple of (length_of_the_indentation, line_without_preceding_indentation)

    :param line:
    :type line: str
    """
    match = LINE_PARTS_RE.match(line)
    return len(match.group('indent')), match.group('line')


def compile_plim_source(source, syntax, strip=True):
    """

    :param source:
    :param syntax: a syntax instance
    :type syntax: :class:`plim.syntax.BaseSyntax`
    :param strip: for embedded markup we don't want to strip whitespaces from result
    :type strip: bool
    :return:
    """
    source = enumerate_source(source)
    result = []
    while True:
        try:
            lineno, line = next(source)
        except StopIteration:
            break

        tail_indent, tail_line = scan_line(line)
        if not line:
            continue
        while tail_line:
            matched_obj, parse = search_parser(lineno, tail_line, syntax)
            parsed_data, tail_indent, tail_line, source = parse(tail_indent, tail_line, matched_obj, source, syntax)
            result.append(parsed_data)

    result = joined(result)
    if strip:
        result = result.strip()
    return result


# Acknowledgements
# ============================================================================================

EMPTY_TAGS = {'meta', 'img', 'link', 'input', 'area', 'base', 'col', 'br', 'hr'}

MARKUP_LANGUAGES = {
    'md': markdown2.markdown,
    'markdown': markdown2.markdown,
    'rst': rst_to_html,
    'rest': rst_to_html,
    'coffee': coffee_to_js,
    'scss': scss_to_css,
    'sass': scss_to_css,
    'stylus': stylus_to_css
}

DOCTYPES = {
    'html':'<!DOCTYPE html>',
    '5': '<!DOCTYPE html>',
    '1.1': '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">',
    'strict': '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">',
    'xml': '<?xml version="1.0" encoding="utf-8" ?>',
    'transitional': '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">',
    'frameset': '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Frameset//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-frameset.dtd">',
    'basic': '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML Basic 1.1//EN" "http://www.w3.org/TR/xhtml-basic/xhtml-basic11.dtd">',
    'mobile': '<!DOCTYPE html PUBLIC "-//WAPFORUM//DTD XHTML Mobile 1.2//EN" "http://www.openmobilealliance.org/tech/DTD/xhtml-mobile12.dtd">',
}

########NEW FILE########
__FILENAME__ = syntax
import re

from . import lexer as l
from .util import PY3K


if PY3K:
    PARSE_IMPLICIT_LITERAL_RE = re.compile(
        # Order matters
        '(?P<line>(?:'
            '\$?\{|\(|\[|&.+;|[0-9]+|'
            '(?:'
                '[^\u0021-\u007E]'  # not ASCII 33 - 126
                '|'                 # or
                '[A-Z]'             # uppercase latin letters (ASCII 65 - 90)
            ')'                     # It is possible because TAG_RE can match only lowercase tag names
        ').*)\s*'
    )
else:
    from .unportable import PARSE_IMPLICIT_LITERAL_RE


class BaseSyntax(object):
    VARIABLE_PLACEHOLDER_START_SEQUENCE = '${'
    VARIABLE_PLACEHOLDER_END_SEQUENCE = '}'

    STATEMENT_START_START_SEQUENCE = '%'
    STATEMENT_START_END_SEQUENCE = ':'
    STATEMENT_END_START_SEQUENCE = '%'
    STATEMENT_END_END_SEQUENCE = ''

    # Parsers
    # ----------------------------------
    PARSE_DOCTYPE_RE = re.compile('doctype\s+(?P<type>[0-9a-z\.]+)', re.IGNORECASE)
    PARSE_STYLE_SCRIPT_RE = re.compile('(?:style|script).*', re.IGNORECASE)
    PARSE_HANDLEBARS_RE = re.compile('(?:handlebars).*')
    PARSE_TAG_TREE_RE = re.compile('(?:#|\.|{tag}).*'.format(tag=l.TAG_RULE))
    # This constant uses l.LITERAL_CONTENT_PREFIX and l.LITERAL_CONTENT_SPACE_PREFIX
    PARSE_EXPLICIT_LITERAL_RE = re.compile("(?:\||,).*", re.IGNORECASE)
    PARSE_IMPLICIT_LITERAL_RE = PARSE_IMPLICIT_LITERAL_RE
    PARSE_RAW_HTML_RE = re.compile('\<.*')
    PARSE_VARIABLE_RE = re.compile("=(?P<prevent_escape>=)?(?P<explicit_space>,)?\s*(?P<line>.*)", re.IGNORECASE)
    PARSE_COMMENT_RE = re.compile('/.*')

    PARSE_STATEMENTS_RE = re.compile('-\s*(?P<stmnt>if|for|while|with|try)(?P<expr>.*)')
    PARSE_FOREIGN_STATEMENTS_RE = re.compile('-\s*(?P<stmnt>unless|until)(?P<expr>.*)')
    PARSE_PYTHON_NEW_RE = re.compile('---[-]*(?P<excl>\!)?\s*(?P<expr>[^-].*)?')
    PARSE_PYTHON_CLASSIC_RE = re.compile('-\s*(?P<python>py(?:thon)?(?P<excl>\!?))(?P<expr>\s+.*)?')
    PARSE_DEF_BLOCK_RE = re.compile('-\s*(?P<line>(?:def|block)(?:\s+.*)?)')
    PARSE_MAKO_ONE_LINERS_RE = re.compile('-\s*(?P<line>(?:include|inherit|page|namespace)(?:\s+.*)?)')
    PARSE_MAKO_TEXT_RE = re.compile('-\s*(?P<line>text(?:\s+.*)?)')
    PARSE_CALL_RE = re.compile('-\s*(?P<line>call(?:\s+.*)?)')
    PARSE_EARLY_RETURN_RE = re.compile('-\s*(?P<keyword>return|continue|break)\s*')
    PARSE_EXTENSION_LANGUAGES_RE = re.compile('-\s*(?P<lang>md|markdown|rst|rest|coffee|scss|sass|stylus)\s*')

    PARSE_ELIF_ELSE_RE = re.compile('-\s*(?P<control>elif|else)(?P<expr>.*)')
    PARSE_EXCEPT_ELSE_FINALLY_RE = re.compile('-\s*(?P<control>except|else|finally)(?P<expr>.*)')

    def __init__(self, custom_parsers=None):
        """
        :param custom_parsers: a list of 2-tuples of (parser_regex, parser_callable) or None
        :type custom_parsers: list or None
        """
        if custom_parsers is None:
            custom_parsers = []

        # We initialize standard parsers here rather than in a class' scope, because
        # we would like to be able to discard parsers in some syntax implementations by
        # replacing them with None (see Django syntax vs. Mako syntax definitions below).
        standard_parsers = ( # Order matters
            (self.PARSE_STYLE_SCRIPT_RE, l.parse_style_script),
            (self.PARSE_DOCTYPE_RE, l.parse_doctype),
            (self.PARSE_HANDLEBARS_RE, l.parse_handlebars),
            (self.PARSE_TAG_TREE_RE, l.parse_tag_tree),
            (self.PARSE_EXPLICIT_LITERAL_RE, l.parse_explicit_literal_with_embedded_markup),
            (self.PARSE_IMPLICIT_LITERAL_RE, l.parse_implicit_literal),
            (self.PARSE_RAW_HTML_RE, l.parse_raw_html),
            (self.PARSE_VARIABLE_RE, l.parse_variable),
            (self.PARSE_COMMENT_RE, l.parse_comment),
            (self.PARSE_STATEMENTS_RE, l.parse_statements),
            (self.PARSE_FOREIGN_STATEMENTS_RE, l.parse_foreign_statements),
            (self.PARSE_PYTHON_NEW_RE, l.parse_python_new_style),
            (self.PARSE_PYTHON_CLASSIC_RE, l.parse_python),
            (self.PARSE_DEF_BLOCK_RE, l.parse_def_block),
            (self.PARSE_MAKO_ONE_LINERS_RE, l.parse_mako_one_liners),
            (self.PARSE_MAKO_TEXT_RE, l.parse_mako_text),
            (self.PARSE_CALL_RE, l.parse_call),
            (self.PARSE_EARLY_RETURN_RE, l.parse_early_return),
            (self.PARSE_EXTENSION_LANGUAGES_RE, l.parse_markup_languages)
        )
        custom_parsers.extend(standard_parsers)
        # discard parsers with None pattern
        self.parsers = tuple([p for p in custom_parsers if p[0]])

    def __str__(self):
        return 'Base Syntax'


class Mako(BaseSyntax):
    def __str__(self):
        return 'Mako Syntax'


class Django(BaseSyntax):
    VARIABLE_PLACEHOLDER_START_SEQUENCE = '{{'
    VARIABLE_PLACEHOLDER_END_SEQUENCE = '}}'
    STATEMENT_START_START_SEQUENCE = '{% '
    STATEMENT_START_END_SEQUENCE = ' %}'
    STATEMENT_END_START_SEQUENCE = STATEMENT_START_START_SEQUENCE
    STATEMENT_END_END_SEQUENCE = STATEMENT_START_END_SEQUENCE

    PARSE_MAKO_ONE_LINERS_RE = None
    PARSE_MAKO_TEXT_RE = None

    def __str__(self):
        return 'Django Syntax'

########NEW FILE########
__FILENAME__ = unportable
import re



PARSE_IMPLICIT_LITERAL_RE = re.compile(
    # Order matters
    u'(?P<line>(?:'
        u'\$?\{|\(|\[|&.+;|[0-9]+|'
        u'(?:'
            u'[^\u0021-\u007E]'  # not ASCII 33 - 126
            u'|'                 # or
            u'[A-Z]'             # uppercase latin letters (ASCII 65 - 90)
        u')'                     # It is possible because TAG_RE can match only lowercase tag names
    u').*)\s*'
)

########NEW FILE########
__FILENAME__ = util
import sys


PY3K = sys.version_info >= (3, 0)

if PY3K:
    from io import StringIO

    joined = lambda buf: ''.join(buf)
    space_separated = lambda buf: ' '.join(buf)
    u = str
    MAXSIZE = sys.maxsize

else:
    from StringIO import StringIO

    joined = lambda buf: u('').join(buf)
    space_separated = lambda buf: u(' ').join(buf)
    u = unicode
    MAXSIZE = sys.maxint

########NEW FILE########
__FILENAME__ = test_babelplugin
# -*- coding: utf-8 -*-
from __future__ import unicode_literals
from plim.adapters.babelplugin import extract
from plim.util import StringIO
from .. import TestCaseBase



class TestBabelPlugin(TestCaseBase):

    def test_babel_extractor(self):
        fileobj = StringIO(self.get_file_contents('babelplugin_test.plim'))
        keywords = ['_', 'gettext', 'ungettext', 'pluralize']
        extracted = [(data[1], data[2]) for data in extract(fileobj, keywords, None, {})]
        
        assert ('_', 'Test') in extracted
        assert ('_', 'View more') in extracted

        assert ('pluralize', ('${num} conversation has been marked as read.',
                              '${num} conversations have been marked as read.',
                              None, None)) in extracted
        assert ('ungettext', ('{num} conversation has been marked as read.',
                              '{num} conversations have been marked as read.',
                              None)) in extracted
        
        assert ('gettext', 'N') not in extracted



########NEW FILE########
__FILENAME__ = custom_parser_module
import re
from plim import preprocessor_factory
from plim.util import joined

PARSE_DISPLAY_COMMENT_RE = re.compile('/!.*')

def parse_can_display_comment(indent_level, current_line, matched, source, syntax):
    return joined(['<!-- ', current_line[2:], ' -->']), indent_level, '', source

CUSTOM_PARSERS = [
    (PARSE_DISPLAY_COMMENT_RE, parse_can_display_comment)
]

custom_preprocessor = preprocessor_factory(custom_parsers=CUSTOM_PARSERS, syntax='mako')

########NEW FILE########
__FILENAME__ = test_cli
import os
import subprocess
import sys
import codecs
import tempfile
import shutil

from plim import syntax
from plim.console import plimc
from plim.util import PY3K
from . import TestCaseBase


class TestCLI(TestCaseBase):

    def setUp(self):
        super(TestCLI, self).setUp()
        self.mako_syntax = syntax.Mako()
        if PY3K:
            from io import BytesIO
            self.stdout = BytesIO()
        else:
            from StringIO import StringIO
            self.stdout = StringIO()

    def test_cli_mako_output(self):
        plimc(['tests/fixtures/unicode_attributes_test.plim'], stdout=self.stdout)

    def test_cli_html_output(self):
        plimc(['--html', 'tests/fixtures/unicode_attributes_test.plim'], stdout=self.stdout)

    def test_custom_preprocessor(self):
        initial_cwd = os.getcwd()
        tmp_dir = tempfile.mkdtemp()
        os.chdir(tmp_dir)

        # copy test module into the temporary dir
        test_items = (
            ('custom_parser_module.py', 'a.py'),
            ('custom_parser_template.plim', 'a.plim')
        )
        for item_src, item_dest in test_items:
            item_src = os.path.join(initial_cwd, 'tests', 'cli_fixtures', item_src)
            item_dest = os.path.join(tmp_dir, item_dest)
            shutil.copy(item_src, item_dest)

        # Make tests
        data = subprocess.Popen(
            ['plimc', '-p', 'a:custom_preprocessor', 'a.plim'],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE
        ).communicate()[0]
        data = codecs.decode(data, 'utf-8')

        self.assertNotEqual(initial_cwd, os.getcwd())
        self.assertIn('', sys.path)
        self.assertEqual(data, '<html></html>')

        # Cleanup
        os.chdir(initial_cwd)
        shutil.rmtree(tmp_dir)

########NEW FILE########
__FILENAME__ = test_lexer
# -*- coding: utf-8 -*-
from plim import lexer as l
from plim import syntax
from plim.errors import PlimSyntaxError, ParserNotFound
from . import TestCaseBase



class TestLexerFunctions(TestCaseBase):

    def setUp(self):
        super(TestLexerFunctions, self).setUp()
        self.mako_syntax = syntax.Mako()

    def test_incorrect_directive(self):
        self.assertRaises(ParserNotFound, l.search_parser, 1, "-icorrect_directive", self.mako_syntax)


    def test_control_re(self):
        m = self.syntax.PARSE_STATEMENTS_RE.match("- if 1")
        assert m.group('expr') == ' 1'

        m = self.syntax.PARSE_STATEMENTS_RE.match("-for i in [1,2,3,4,5]")
        assert m.group('expr') == ' i in [1,2,3,4,5]'


    def test_parse_quotes(self):
        self.assertEqual(l.search_quotes('"test"'), 6)

        str_ = "'test'"
        result = l.search_quotes(str_)
        self.assertEqual(result, 6)
        self.assertEqual(str_, str_[:result])

        self.assertEqual(l.search_quotes(r"'test\''"), 8)
        self.assertEqual(l.search_quotes(r'"test\""'), 8)
        self.assertEqual(l.search_quotes(r"'test\\'"), 8)
        self.assertEqual(l.search_quotes(r"'''test\\'''"), 12)
        self.assertEqual(l.search_quotes("'''test'''"), 10)

        self.assertIsNone(l.search_quotes('"test'))
        self.assertIsNone(l.search_quotes("'test"))
        self.assertIsNone(l.search_quotes(r"'test\'"))
        self.assertIsNone(l.search_quotes('"""test'))
        self.assertIsNone(l.search_quotes("'''test"))


    def test_extract_mako_expression(self):
        str_ = '${x}'
        source = l.enumerate_source('')
        result, tail, _ = l.extract_mako_expression(str_, source)
        self.assertEqual(result, str_)
        self.assertEqual(str_[:len(result)], str_)

        str_ = """${{"test\\"":'test}}}'}}"""
        result, tail, _ = l.extract_mako_expression(str_, source)
        self.assertEqual(result, str_)
        self.assertEqual(str_[:len(result)], str_)

        str_ = """${{"test\\"":{'ddd': 'test}}}', 'eee':{}}}}"""
        result, tail, _ = l.extract_mako_expression(str_, source)
        self.assertEqual(result, str_)
        self.assertEqual(str_[:len(result)], str_)

        str_ = """{{"test\\"":'test}}}'}}"""
        result = l.extract_mako_expression(str_, source)
        self.assertIsNone(result)

        str_ = """{{"test\\"":'test}}}'}"""
        result = l.extract_mako_expression(str_, source)
        self.assertIsNone(result)


    def test_extract_ident(self):
        source = l.enumerate_source('')
        str_ = '#test'
        result, _, __ = l.extract_identifier(str_, source)
        self.assertEqual(result, str_)

        str_ = '#test '
        result, _, __ = l.extract_identifier(str_, source)
        self.assertNotEqual(result, str_)
        self.assertEqual(result, str_.strip())

        str_ = '#test.class'
        result, _, __ = l.extract_identifier(str_, source)
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], '#test')
        self.assertEqual(str_[len(result)], '.')

        str_ = '.test.class'
        result, _, __ = l.extract_identifier(str_, source, '.')
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], '.test')

        str_ = '.${test.test}.class'
        result, _, __ = l.extract_identifier(str_, source, '.')
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], '.${test.test}')

        str_ = '.${test.test}test.class'
        result, _, __ = l.extract_identifier(str_, source, '.')
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], '.${test.test}test')

        str_ = '.test-${test.test}test.class'
        result, _, __ = l.extract_identifier(str_, source, '.')
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], '.test-${test.test}test')

        str_ = '.test-${test.test + "${{\'test\':1}}"}${test}test.class'
        result, _, __ = l.extract_identifier(str_, source, '.')
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], '.test-${test.test + "${{\'test\':1}}"}${test}test')

        str_ = u'.абв.где'
        result, _, __ = l.extract_identifier(str_, source, '.')
        self.assertNotEqual(result, str_)
        self.assertEqual(str_[:len(result)], u'.абв')


    def test_parse_tag_attribute(self):
        def assert_this(str_, parentheses, attr_, tail):
            source = l.enumerate_source('')
            result = l.extract_tag_attribute(str_, source, self.mako_syntax, parentheses)
            self.assertEqual(result[0], attr_)
            self.assertEqual(tail, result[1])

        source = l.enumerate_source('')
        self.assertEqual(l.extract_tag_attribute("", source, self.mako_syntax), None)
        self.assertEqual(l.extract_tag_attribute(" ", source, self.mako_syntax), None)
        self.assertEqual(l.extract_tag_attribute("=", source, self.mako_syntax), None)
        self.assertEqual(l.extract_tag_attribute(" = ", source, self.mako_syntax), None)
        self.assertEqual(l.extract_tag_attribute("|", source, self.mako_syntax), None)
        self.assertEqual(l.extract_tag_attribute("'", source, self.mako_syntax), None)
        self.assertEqual(l.extract_tag_attribute("()", source, self.mako_syntax, True), None)
        self.assertEqual(l.extract_tag_attribute(")", source, self.mako_syntax, True), None)

        assert_this('attr="value"', False, 'attr="value"', '')
        assert_this('attr=${val}', False,  'attr="${val}"', '')
        assert_this('attr=(val)', False,  'attr="${val}"', '')

        # Test digital values
        assert_this('attr=7 attr2=val', False,  'attr="7"', ' attr2=val')
        assert_this('attr=.7 attr2=val', False,  'attr=".7"', ' attr2=val')
        assert_this('attr=-7 attr2=val', False,  'attr="-7"', ' attr2=val')
        assert_this('attr=+7 attr2=val', False,  'attr="+7"', ' attr2=val')
        assert_this('attr=-.7 attr2=val', False,  'attr="-.7"', ' attr2=val')
        assert_this('attr=+.7 attr2=val', False,  'attr="+.7"', ' attr2=val')
        assert_this('attr=7% attr2=val', False,  'attr="7%"', ' attr2=val')
        
        assert_this('attr=10.7 attr2=val', False,  'attr="10.7"', ' attr2=val')
        assert_this('attr=-10.7 attr2=val', False,  'attr="-10.7"', ' attr2=val')
        assert_this('attr=+10.7 attr2=val', False,  'attr="+10.7"', ' attr2=val')
        assert_this('attr=10.107 attr2=val', False,  'attr="10.107"', ' attr2=val')
        assert_this('attr=107 attr2=val', False,  'attr="107"', ' attr2=val')

        assert_this('style=c.selected_cover', False,  'style="${c.selected_cover}"', '')
        assert_this('href=item[\'url\']', False,  'href="${item[\'url\']}"', '')
        assert_this('value=extra_title[0]', False,  'value="${extra_title[0]}"', '')

        assert_this('attr=obj.url(request, func("test([\'") + "{test}".format(test="123"), cover[\'image\'])', False,  'attr="${obj.url(request, func("test([\'") + "{test}".format(test="123"), cover[\'image\'])}"', '')

        assert_this('attr=${val} selected', False,  'attr="${val}"', ' selected')
        assert_this('attr=(val) selected', False,  'attr="${val}"', ' selected')
        assert_this('attr=val selected', False,  'attr="${val}"', ' selected')
        assert_this('attr=_(\'i18n message\') selected', False,  'attr="${_(\'i18n message\')}"', ' selected')
        assert_this('attr=${val}? selected', False,  """${(val) and 'attr="attr"' or ''|n}""", ' selected')
        assert_this('attr=(val)? selected', False,  """${(val) and 'attr="attr"' or ''|n}""", ' selected')
        assert_this('attr=val? selected', False,  """${(val) and 'attr="attr"' or ''|n}""", ' selected')
        assert_this('attr=${val + 1}? selected', False,  """${(val + 1) and 'attr="attr"' or ''|n}""", ' selected')
        assert_this('attr=(val + 1)? selected', False,  """${(val + 1) and 'attr="attr"' or ''|n}""", ' selected')
        assert_this('attr="${val}"? selected', False,  'attr="${val}"', '? selected')
        assert_this('attr="${\\"val\\"}"? selected', False,  'attr="${"val"}"', '? selected')

        assert_this('attr="value")', True, 'attr="value"', ')')
        assert_this('attr=${val})', True, 'attr="${val}"', ')')
        assert_this('attr=(val))', True, 'attr="${val}"', ')')
        assert_this('attr=${val}?)', True, """${(val) and 'attr="attr"' or ''|n}""", ')')
        assert_this('attr=(val)?)', True, """${(val) and 'attr="attr"' or ''|n}""", ')')
        assert_this('attr=(val("test() is a function"))?)', True, """${(val("test() is a function")) and 'attr="attr"' or ''|n}""", ')')
        assert_this('attr=${val} selected)', True, 'attr="${val}"', ' selected)')
        assert_this('attr=(val) selected)', True, 'attr="${val}"', ' selected)')
        assert_this('attr=val) selected', True, 'attr="${val}"', ') selected')
        assert_this('attr="${\\"val\\"}"?) selected', True,  'attr="${"val"}"', '?) selected')

        assert_this('attr${attr}attr="${\\"val\\"}"?) selected', True,  'attr${attr}attr="${"val"}"', '?) selected')


    def test_scan_line(self):
        assert l.scan_line('body') == (0, 'body')
        assert l.scan_line("    div") == (4, 'div')
        assert l.scan_line("") == (0, '')
        assert l.scan_line(" ") == (1, '')


    def test_extract_dynamic_attr_value(self):
        for terminators in (l.ATTRIBUTE_VALUE_TERMINATORS_WITH_PARENTHESES, l.ATTRIBUTE_VALUE_TERMINATORS):
            source = l.enumerate_source('')
            value, tail, _ = l.extract_dynamic_attr_value("(value in func('test') and 'yes' or 'no')", source, terminators, self.mako_syntax)
            assert value == "value in func('test') and 'yes' or 'no'"
            assert tail == ''


    def test_extract_dynamic_tag_attributes(self):
        source = l.enumerate_source('')
        attrs, tail, source = l.extract_dynamic_tag_attributes("**test", source, self.mako_syntax, False)
        self.assertTrue(attrs.startswith("\n%for __plim_key__, __plim_value__ in test.items()"))

        attrs, tail, source = l.extract_dynamic_tag_attributes("**test(**values)", source, self.mako_syntax, False)
        self.assertTrue(attrs.startswith("\n%for __plim_key__, __plim_value__ in test(**values).items()"))

        attrs, tail, source = l.extract_dynamic_tag_attributes("**test**test2", source, self.mako_syntax, False)
        self.assertTrue(attrs.startswith("\n%for __plim_key__, __plim_value__ in test.items()"))

        # Test multi-line expression
        source = l.enumerate_source('**values\n)')
        attrs, tail, source = l.extract_dynamic_tag_attributes("**test(\n", source, self.mako_syntax, False)
        self.assertTrue(attrs.startswith("\n%for __plim_key__, __plim_value__ in test(**values).items()"))

    def test_inline_extract_plim_line(self):
        def test_case(template, result_list, result_tail_list):
            source = enumerate('')
            tail = template
            while True:
                result = result_list.pop(0)
                result_tail = result_tail_list.pop(0)
                line, close_buf, _, tail, __ = l.extract_tag_line(tail, source, self.mako_syntax)
                self.assertEqual(line + close_buf, result)
                self.assertEqual(result_tail, tail)
                if not tail:
                    break

        test_case(
            "input#proceed (type='submit' name='proceed' value=_('Start creating my account') disabled)",
            ["""<input type="submit" name="proceed" value="${_('Start creating my account')}" disabled="disabled" id="proceed"/>"""],
            [""]
        )
        
        test_case(
            "input#proceed ( disabled )",
            ["""<input disabled="disabled" id="proceed"/>"""],
            [""]
        )
        
        test_case(
            "input#proceed (disabled)",
            ["""<input disabled="disabled" id="proceed"/>"""],
            [""]
        )

        test_case(
            'body: #layout: ul#list.cls1.cls2: li.active: a href="#" = Page Title',
            [
                '<body></body>',
                '<div id="layout"></div>',
                '<ul id="list" class="cls1 cls2"></ul>',
                '<li class="active"></li>',
                '<a href="#">${Page Title}</a>',
            ],
            [
                '#layout: ul#list.cls1.cls2: li.active: a href="#" = Page Title',
                'ul#list.cls1.cls2: li.active: a href="#" = Page Title',
                'li.active: a href="#" = Page Title',
                'a href="#" = Page Title',
                '',
            ]
        )

        test_case(
            'body: #layout: ul#list.cls1.cls2: li.active: a href="#"=Page Title',
            [
                '<body></body>',
                '<div id="layout"></div>',
                '<ul id="list" class="cls1 cls2"></ul>',
                '<li class="active"></li>',
                '<a href="#">${Page Title}</a>'
            ],
            [
                '#layout: ul#list.cls1.cls2: li.active: a href="#"=Page Title',
                'ul#list.cls1.cls2: li.active: a href="#"=Page Title',
                'li.active: a href="#"=Page Title',
                'a href="#"=Page Title',
                ''
            ],

        )
        test_case(
            'body: #layout: ul#list.cls1.cls2: li.active: a href="#" =, Page Title',
            [
                '<body></body>',
                '<div id="layout"></div>',
                '<ul id="list" class="cls1 cls2"></ul>',
                '<li class="active"></li>',
                '<a href="#">${Page Title} </a>'
            ],
            [
                '#layout: ul#list.cls1.cls2: li.active: a href="#" =, Page Title',
                'ul#list.cls1.cls2: li.active: a href="#" =, Page Title',
                'li.active: a href="#" =, Page Title',
                'a href="#" =, Page Title',
                ''
            ],
        )

        # Check parentheses
        test_case(
            'body(): #layout (): ul#list.cls1.cls2(   ): li.active: a ( href="#" ) = Page Title',
            [
                '<body></body>',
                '<div id="layout"></div>',
                '<ul id="list" class="cls1 cls2"></ul>',
                '<li class="active"></li>',
                '<a href="#">${Page Title}</a>'
            ],
            [
                '#layout (): ul#list.cls1.cls2(   ): li.active: a ( href="#" ) = Page Title',
                'ul#list.cls1.cls2(   ): li.active: a ( href="#" ) = Page Title',
                'li.active: a ( href="#" ) = Page Title',
                'a ( href="#" ) = Page Title',
                ''
            ]
        )

        # test dynamic content
        result = '<body>${Test}</body>'
        test_case('body = Test', [result], [''])
        test_case('body=Test', [result], [''])

        # Test explicit whitespace
        result = '<body>Test </body>'
        test_case('body , Test', [result], [''])
        test_case('body,Test', [result], [''])

        # Test literals
        result = '<div>Test</div>'
        test_case('div | Test', [result], [''])
        test_case('div|Test', [result], [''])
        test_case('div|=Test', ['<div>=Test</div>'], [''])

        # Test dynamic with whitespace
        result = '<div>${Test} </div>'
        test_case('div=,Test', [result], [''])
        test_case('div =, Test', [result], [''])
        test_case('div = , Test', ['<div>${, Test}</div>'], [''])
        test_case('div, =Test', ['<div>=Test </div>'], [''])

        # Test dynamic with "n" filter
        result = '<div>${Test|n}</div>'
        test_case('div==Test', [result], [''])
        test_case('div==Test|u', ['<div>${Test|n,u}</div>'], [''])
        test_case('div == Test', [result], [''])
        test_case('div == Test|u,h', ['<div>${Test|n,u,h}</div>'], [''])
        test_case('div = = Test', ['<div>${= Test}</div>'], [''])
        test_case('div, ==Test', ['<div>==Test </div>'], [''])

        result = '<div>${Test|n} </div>'
        test_case('div==,Test', [result], [''])
        test_case('div==,Test | h', ['<div>${Test |n,h} </div>'], [''])
        test_case('div ==, Test', [result], [''])
        test_case('div ==, Test | h', ['<div>${Test |n,h} </div>'], [''])
        test_case('div == , Test', ['<div>${, Test|n}</div>'], [''])

        # Test parentheses and functions as dynamic variables
        test_case('div attr=func(test("test")) Test', ['<div attr="${func(test("test"))}">Test</div>'], [''])

        result = '<div attr="${func(test())}">${Test}</div>'
        test_case('div (attr=func(test()))= Test', [result], [''])

        result = '<div attr="${func(test())}" attr2="${test()}">${Test}</div>'
        test_case('div( attr=func(test()) attr2=test() )= Test', [result], [''])

        result = '<div attr="${func(test())}" ${(test()) and \'attr2="attr2"\' or \'\'|n}>${Test}</div>'
        test_case('div( attr=func(test()) attr2=test()? )= Test', [result], [''])


    def test_explicit_literal(self):
        result, _, __, ___ = l.parse_explicit_literal_with_embedded_markup(
            0, "| Test", None, l.enumerate_source(""), self.mako_syntax)
        assert result == "Test"

        result, _, __, ___ = l.parse_explicit_literal_with_embedded_markup(
            0, ", Test", None, l.enumerate_source(""), self.mako_syntax)
        assert result == "Test "

        result, _, __, ___ = l.parse_explicit_literal_with_embedded_markup(
            0, ",Test\n Test", None, l.enumerate_source(""), self.mako_syntax)
        assert result == "Test\n Test "


    def test_multiline_extract_plim_line(self):
        def test_case(template, result):
            """Use files for multiline test cases"""
            template = l.enumerate_source(self.get_file_contents(template))
            result = l.enumerate_source(self.get_file_contents(result))
            for lineno, line in template:
                if line.strip():
                    _, result_line = next(result)
                    line, close_buf, _, tail, __ = l.extract_tag_line(line, template, self.mako_syntax)
                    self.assertEqual(line + close_buf, result_line.rstrip())

        test_case('plim_multiline_tag_test.plim', 'plim_multiline_tag_result.mako')

    def test_extract_embedding_quotes(self):
        result = l.extract_embedding_quotes('Test `abc`')
        self.assertEqual(result, None)

        embedded, original, content = l.extract_embedding_quotes('`abc`')
        self.assertEqual(embedded, 'abc')
        self.assertEqual(original, '`abc`')
        self.assertEqual(content, '')

        embedded, original, content = l.extract_embedding_quotes('`abc`_')
        self.assertEqual(embedded, 'abc')
        self.assertEqual(original, '`abc`_')
        self.assertEqual(content, '')

        embedded, original, content = l.extract_embedding_quotes('`abc`_Test')
        self.assertEqual(embedded, 'abc')
        self.assertEqual(original, '`abc`_')
        self.assertEqual(content, 'Test')

        embedded, original, content = l.extract_embedding_quotes('`abc`Test')
        self.assertEqual(embedded, 'abc')
        self.assertEqual(original, '`abc`')
        self.assertEqual(content, 'Test')

        embedded, original, content = l.extract_embedding_quotes('``abc Test')
        self.assertEqual(embedded, '')
        self.assertEqual(original, '``')
        self.assertEqual(content, 'abc Test')

        self.assertRaises(PlimSyntaxError, l.extract_embedding_quotes, '`abc``Test')


    def test_parse_embedded_markup(self):
        result = l._parse_embedded_markup("this is a `test`", self.mako_syntax)
        self.assertEqual(result, "this is a <test></test>")

        self.assertRaises(PlimSyntaxError, l._parse_embedded_markup, "this is a `test", self.mako_syntax)

        result = l._parse_embedded_markup("this is a ``test", self.mako_syntax)
        self.assertEqual(result, "this is a `test")

        self.assertRaises(PlimSyntaxError, l._parse_embedded_markup, "this is a ```test", self.mako_syntax)

        result = l._parse_embedded_markup("this is a ````test", self.mako_syntax)
        self.assertEqual(result, "this is a ``test")

        result = l._parse_embedded_markup("this is a `recursive Test ``recursive Test```test", self.mako_syntax)
        self.assertEqual(result, "this is a <recursive>Test <recursive>Test</recursive></recursive>test")


    def test_parse_markdown(self):
        source = self.get_file_contents('markdown_test.plim')
        source = l.enumerate_source(source)
        _, line = next(source)
        result = self.get_file_contents('markdown_result.mako')
        data, _, __, ___ = l.parse_markup_languages(0, '', self.mako_syntax.PARSE_EXTENSION_LANGUAGES_RE.match(line), source, self.mako_syntax)
        self.assertEqual(data.strip(), result.strip())


    def test_parse_rst(self):
        source = self.get_file_contents('reST_test.plim')
        source = l.enumerate_source(source)
        _, line = next(source)
        result = self.get_file_contents('reST_result.mako')
        data, _, __, ___ = l.parse_markup_languages(0, '', self.mako_syntax.PARSE_EXTENSION_LANGUAGES_RE.match(line), source, self.mako_syntax)
        self.assertEqual(data.strip(), result.strip())


    def test_sass(self):
        source = self.get_file_contents('scss_test.plim')
        source = l.enumerate_source(source)
        _, line = next(source)
        result = self.get_file_contents('scss_result.mako')
        data, _, __, ___ = l.parse_markup_languages(0, '', self.mako_syntax.PARSE_EXTENSION_LANGUAGES_RE.match(line), source, self.mako_syntax)
        self.assertEqual(data.strip(), result.strip())

        
    def test_coffee(self):
        source = self.get_file_contents('coffee_test.plim')
        source = l.enumerate_source(source)
        _, line = next(source)
        result = self.get_file_contents('coffee_result.mako')
        data, _, __, ___ = l.parse_markup_languages(
            0,
            '',
            self.mako_syntax.PARSE_EXTENSION_LANGUAGES_RE.match(line),
            source,
            self.mako_syntax)
        self.assertEqual(data.strip(), result.strip())
        
        
    def test_stylus(self):
        source = self.get_file_contents('stylus_test.plim')
        source = l.enumerate_source(source)
        _, line = next(source)
        result = self.get_file_contents('stylus_result.mako')
        data, _, __, ___ = l.parse_markup_languages(0, '', self.mako_syntax.PARSE_EXTENSION_LANGUAGES_RE.match(line), source, self.mako_syntax)
        self.assertEqual(data.strip(), result.strip())
########NEW FILE########
