__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# librosa documentation build configuration file, created by
# sphinx-quickstart on Tue Jun 25 13:12:33 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('../librosa'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'librosa'
copyright = u'2014, Dawen Liang, Brian McFee, Matt McVicar, Colin Raffel'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.2'
# The full version, including alpha/beta/rc tags.
release = '0.2.1'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
import sphinx_bootstrap_theme
html_theme = 'bootstrap'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
html_theme_options = {
    'bootswatch_theme':     'flatly', 
    'bootstrap_version':    '3',
    'navbar_title':         'LibROSA',
    'source_link_position': None,

}

# Add any paths that contain custom themes here, relative to this directory.
html_theme_path = sphinx_bootstrap_theme.get_html_theme_path()

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
# html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
html_use_index = True

# If true, the index is split into individual pages for each letter.
# html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'librosadoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'librosa.tex', u'librosa Documentation',
   u'Dawen Liang, Brian McFee, Matt McVicar, Colin Raffel', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'librosa', u'librosa Documentation',
     [u'Dawen Liang, Brian McFee, Matt McVicar, Colin Raffel'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'librosa', u'librosa Documentation',
   u'Dawen Liang, Brian McFee, Matt McVicar, Colin Raffel', 'librosa', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = beat_tracker
#!/usr/bin/env python
'''
CREATED:2013-02-11 18:37:30 by Brian McFee <brm2132@columbia.edu>

Track beat events in an audio file

Usage:   ./beat_tracker.py [-h] input_file.mp3    output_beats.csv
'''

import sys, librosa, argparse

# 1. load the wav file and resample to 22.050 KHz
def beat_track(input_file, output_csv):
    '''Beat tracking function
    
    :parameters:
      - input_file : str
          Path to input audio file (wav, mp3, m4a, flac, etc.)

      - output_file : str
          Path to save beat event timestamps as a CSV file
    '''

    print 'Loading ', input_file
    y, sr         = librosa.load(input_file, sr=22050)

    # Use a default hop size of 64 frames @ 22KHz ~= 11.6ms
    HOP_LENGTH  = 64

    # This is the window length used by default in stft
    N_FFT       = 2048

    print 'Tracking beats'
    tempo, beats    = librosa.beat.beat_track(y=y, sr=sr, hop_length=HOP_LENGTH)

    print 'Estimated tempo: %0.2f beats per minute' % tempo

    # 3. save output
    # 'beats' will contain the frame numbers of beat events.

    beat_times = librosa.frames_to_time(beats, sr=sr, hop_length=HOP_LENGTH, n_fft=N_FFT)

    print 'Saving output to ', output_csv
    librosa.output.times_csv(output_csv, beat_times)
    print 'done!'


def process_arguments():
    '''Argparse function to get the program parameters'''

    parser = argparse.ArgumentParser(description='librosa beat-tracking example')

    parser.add_argument(    'input_file',
                            action      =   'store',
                            help        =   'path to the input file (wav, mp3, etc)')

    parser.add_argument(    'output_file',
                            action      =   'store',
                            help        =   'path to the output file (csv of beat times)')

    return vars(parser.parse_args(sys.argv[1:]))


if __name__ == '__main__':
    # Get the parameters
    parameters = process_arguments()

    # Run the beat tracker
    beat_track(parameters['input_file'], parameters['output_file'])

########NEW FILE########
__FILENAME__ = hpss
#!/usr/bin/env python
'''
CREATED:2013-12-08 14:28:34 by Brian McFee <brm2132@columbia.edu>
 
Demonstration of harmonic-percussive source separation

Usage: ./hpss.py [-h] input_file.mp3  output_harmonic.wav  output_percussive.wav

'''

import sys, argparse
import librosa


def hpss_demo(input_file, output_harmonic, output_percussive):
    '''HPSS demo function.

    :parameters:
      - input_file : str
          path to input audio
      - output_harmonic : str
          path to save output harmonic (wav)
      - output_percussive : str
          path to save output harmonic (wav)
    '''

    N_FFT       = 2048
    HOP_LENGTH  = N_FFT /4

    # 1. Load the wav file, resample
    print 'Loading ', input_file

    y, sr = librosa.load(input_file)

    # 2. generate STFT @ 2048 samples
    print 'Computing short-time fourier transform... '
    D = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)

    # 3. HPSS.  The default kernel size isn't necessarily optimal, but works okay enough
    print 'Separating harmonics and percussives... '
    harmonic, percussive = librosa.decompose.hpss(D)

    # 4. Invert STFT
    print 'Inverting harmonics and percussives... '
    y_harmonic   = librosa.istft(harmonic, hop_length=HOP_LENGTH)
    y_percussive = librosa.istft(percussive, hop_length=HOP_LENGTH)

    # 5. Save the results
    print 'Saving harmonic audio to: ', output_harmonic
    librosa.output.write_wav(output_harmonic, y_harmonic, sr)

    print 'Saving percussive audio to: ', output_percussive
    librosa.output.write_wav(output_percussive, y_percussive, sr)

def process_arguments():
    '''Argparse function to get the program parameters'''

    parser = argparse.ArgumentParser(description='librosa harmonic-percussive source separation example')

    parser.add_argument(    'input_file',
                            action      =   'store',
                            help        =   'path to the input file (wav, mp3, etc)')

    parser.add_argument(    'output_harmonic',
                            action      =   'store',
                            help        =   'path to the harmonic output (wav)')

    parser.add_argument(    'output_percussive',
                            action      =   'store',
                            help        =   'path to the percussive output (wav)')

    return vars(parser.parse_args(sys.argv[1:]))

if __name__ == '__main__':
    # get the parameters
    parameters = process_arguments()

    # Run the HPSS code
    hpss_demo(  parameters['input_file'], 
                parameters['output_harmonic'],
                parameters['output_percussive'])

########NEW FILE########
__FILENAME__ = hpss_beats
#!/usr/bin/env python
'''
CREATED:2013-02-12 16:33:40 by Brian McFee <brm2132@columbia.edu>

Beat tracking with HPSS filtering

Usage: ./hpss_beats.py [-h] input_audio.mp3 output_beats.csv
'''

import argparse
import numpy as np
import sys
import librosa

# Some magic number defaults, FFT window and hop length
N_FFT       = 2048

# We use a hop of 64 here so that the HPSS spectrogram input
# matches the default beat tracker parameters
HOP_LENGTH  = 64

def percussive(y):
    '''Extract the percussive component of an audio time series'''

    D = librosa.stft(y)
    P = librosa.decompose.hpss(D)[1]
    
    return librosa.istft(P)

def hpss_beats(input_file, output_csv):
    '''HPSS beat tracking
    
    :parameters:
      - input_file : str
          Path to input audio file (wav, mp3, m4a, flac, etc.)

      - output_file : str
          Path to save beat event timestamps as a CSV file
    '''

    # Load the file
    print 'Loading  ', input_file
    y, sr = librosa.load(input_file)

    # Do HPSS
    print 'Harmonic-percussive separation ... '
    y = percussive(y)

    # Construct onset envelope from percussive component
    print 'Tracking beats on percussive component'
    onsets = librosa.onset.onset_strength(y=y, sr=sr, hop_length=HOP_LENGTH, n_fft=N_FFT, aggregate=np.median)

    # Track the beats
    tempo, beats = librosa.beat.beat_track( onsets=onsets, 
                                            sr=sr, 
                                            hop_length=HOP_LENGTH)

    beat_times  = librosa.frames_to_time(beats, 
                                         sr=sr, 
                                         hop_length=HOP_LENGTH,
                                         n_fft=N_FFT)
    # Save the output
    print 'Saving beats to ', output_csv
    librosa.output.times_csv(output_csv, beat_times)


def process_arguments():
    '''Argparse function to get the program parameters'''

    parser = argparse.ArgumentParser(description='librosa HPSS beat-tracking example')

    parser.add_argument(    'input_file',
                            action      =   'store',
                            help        =   'path to the input file (wav, mp3, etc)')

    parser.add_argument(    'output_file',
                            action      =   'store',
                            help        =   'path to the output file (csv of beat times)')

    return vars(parser.parse_args(sys.argv[1:]))

if __name__ == '__main__':
    # Get the parameters
    parameters = process_arguments()

    # Run the beat tracker
    hpss_beats(parameters['input_file'], parameters['output_file'])

########NEW FILE########
__FILENAME__ = time_stretch
#!/usr/bin/env python
'''
CREATED:2013-12-08 14:28:34 by Brian McFee <brm2132@columbia.edu>
 
Demonstration of phase vocoder time stretching 

Usage: ./time_stretch.py [-h] [-s STRETCH_FACTOR] input_file.mp3  output_harmonic.wav

'''

import sys, argparse
import librosa


def stretch_demo(input_file, output_file, speed):
    '''Phase-vocoder time stretch demo function.

    :parameters:
      - input_file : str
          path to input audio
      - output_file : str
          path to save output (wav)
      - speed : float > 0
          speed up by this factor
    '''

    N_FFT       = 2048
    HOP_LENGTH  = N_FFT /4

    # 1. Load the wav file, resample
    print 'Loading ', input_file

    y, sr = librosa.load(input_file)

    # 2. generate STFT @ 2048 samples
    print 'Computing short-time fourier transform... '
    D = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)

    print 'Playing back at %3.f%% speed' % (speed * 100)
    D_stretch = librosa.phase_vocoder(D, speed, hop_length=HOP_LENGTH)

    y_stretch = librosa.istft(D_stretch, hop_length=HOP_LENGTH)

    print 'Saving stretched audio to: ', output_file
    librosa.output.write_wav(output_file, y_stretch, sr)

def process_arguments():
    '''Argparse function to get the program parameters'''

    parser = argparse.ArgumentParser(description='librosa phase vocoder time stretching')

    parser.add_argument(    'input_file',
                            action      =   'store',
                            help        =   'path to the input file (wav, mp3, etc)')

    parser.add_argument(    'output_file',
                            action      =   'store',
                            help        =   'path to the stretched output (wav)')

    parser.add_argument(    '-s',
                            '--speed',
                            action      =   'store',
                            type        =   float,
                            default     =   2.0,
                            required    =   False,
                            help        =   'speed')

    return vars(parser.parse_args(sys.argv[1:]))

if __name__ == '__main__':
    # get the parameters
    parameters = process_arguments()

    # Run the HPSS code
    stretch_demo(   parameters['input_file'], 
                    parameters['output_file'],
                    parameters['speed'])

########NEW FILE########
__FILENAME__ = tuning
#!/usr/bin/env python
'''
CREATED:2013-12-09 00:02:54 by Brian McFee <brm2132@columbia.edu>
 
Estimate the tuning (deviation from A440) of a recording.

Usage: ./tuning.py [-h] input_file
'''

import sys, argparse
import numpy as np

import librosa

def estimate_tuning(input_file):
    print 'Loading ', input_file
    y, sr = librosa.load(input_file)

    # Get the instantaneous-frequency pitch track
    print 'Tracking pitches... '
    pitches, magnitudes, D = librosa.feature.ifptrack(  y, sr )

    print 'Estimating tuning ... '
    # Just track the pitches associated with high magnitude
    pitches = pitches[magnitudes > np.median(magnitudes)]

    tuning = librosa.feature.estimate_tuning(pitches)
    print '%+0.2f cents' % (100 * tuning)


def process_arguments():
    '''Argparse function to get the program parameters'''

    parser = argparse.ArgumentParser(description='librosa tuning estimation example')

    parser.add_argument(    'input_file',
                            action      =   'store',
                            help        =   'path to the input file (wav, mp3, etc)')

    return vars(parser.parse_args(sys.argv[1:]))
   

if __name__ == '__main__':
    # Get the parameters
    parameters = process_arguments()

    # Run the beat tracker
    estimate_tuning(parameters['input_file'])

########NEW FILE########
__FILENAME__ = beat
#!/usr/bin/env python
"""Beat tracking and tempo estimation"""

import numpy as np
import scipy
import scipy.signal

import librosa.core
import librosa.feature
import librosa.onset

def beat_track(y=None, sr=22050, onsets=None, hop_length=64, 
               start_bpm=120.0, tightness=400, trim=True, bpm=None):
    r'''Dynamic programming beat tracker.

    Beats are detected in three stages:
      1. Measure onset strength
      2. Estimate tempo from onset correlation
      3. Pick peaks in onset strength approximately consistent with estimated tempo

    :usage:
        >>> # Track beats using time series input
        >>> tempo, beats = librosa.beat.beat_track( y, sr )

        >>> # Track beats using a pre-computed onset envelope
        >>> tempo, beats = librosa.beat.beat_track( onsets=onset_envelope, 
                                                    sr=sr, 
                                                    hop_length=hop_length)

    :parameters:
      - y          : np.ndarray or None
          audio time series

      - sr         : int > 0
          sampling rate of ``y``

      - onsets     : np.ndarray or None
          (optional) pre-computed onset strength envelope
          See ``librosa.onset.onset_strength``

      - hop_length : int > 0
          number of audio samples between successive ``onsets`` values (FFT frames)

      - start_bpm  : float > 0
          initial guess for the tempo estimator

      - tightness  : float
          tightness of beat distribution around tempo

      - trim       : bool
          trim leading/trailing beats with weak onsets?

      - bpm        : float
          (optional) If provided, use this BPM instead of estimating it

      .. note:: One of either ``onsets`` or ``y`` must be provided.

    :returns: 
      - tempo : float
          estimated global tempo

      - beats : np.ndarray
          estimated frame numbers of beats

    :raises:
      - ValueError  
          if neither ``y`` nor ``onsets`` are provided

    .. note::
      If no onset strength could be detected, beat_tracker estimates 0 BPM and returns
      an empty list.

    .. note:: 
      - http://labrosa.ee.columbia.edu/projects/beattrack/
      - @article{ellis2007beat,
            title={Beat tracking by dynamic programming},
            author={Ellis, Daniel PW},
            journal={Journal of New Music Research},
            volume={36},
            number={1},
            pages={51--60},
            year={2007},
            publisher={Taylor \& Francis} }
    '''

    # First, get the frame->beat strength profile if we don't already have one
    if onsets is None:
        if y is None:
            raise ValueError('Either "y" or "onsets" must be provided')

        onsets  = librosa.onset.onset_strength( y=y, 
                                                sr=sr, 
                                                hop_length=hop_length)

    # Do we have any onsets to grab?
    if not onsets.any():
        return (0, np.array([], dtype=int))

    # Estimate BPM if one was not provided
    if bpm is None:
        bpm = estimate_tempo(onsets, sr=sr, hop_length=hop_length, start_bpm=start_bpm)
    
    # Then, run the tracker
    beats   = __beat_tracker(onsets, bpm, float(sr) / hop_length, tightness, trim)

    return (bpm, beats)

def estimate_tempo(onsets, sr=22050, hop_length=64, start_bpm=120, std_bpm=1.0, ac_size=4.0, duration=90.0, offset=0.0):
    """Estimate the tempo (beats per minute) from an onset envelope

    :usage:
        >>> tempo = librosa.beat.estimate_tempo(onset_strength, sr=sr, hop_length)

    :parameters:
      - onsets    : np.ndarray   
          onset strength envelope.
          See ``librosa.onset.onset_strength()`` for details.

      - sr:       : int > 0
          sampling rate of the time series

      - hop_length : int > 0
          hop length of the time series

      - start_bpm : float
          initial guess of the BPM

      - std_bpm : float > 0
          standard deviation of tempo distribution

      - ac_size : float > 0
          length (in seconds) of the auto-correlation window

      - duration : float > 0
          length of signal (in seconds) to use in estimating tempo

      - offset : float > 0
          offset (in seconds) of signal sample to use in estimating tempo

    :returns:
      - tempo      : float
          estimated tempo (beats per minute)
    """

    
    fft_res     = float(sr) / hop_length

    # Chop onsets to X[(upper_limit - duration):upper_limit]
    # or as much as will fit
    maxcol      = int(min(len(onsets)-1, np.round((offset + duration) * fft_res)))
    mincol      = int(max(0,    maxcol - np.round(duration * fft_res)))

    # Use auto-correlation out of 4 seconds (empirically set??)
    ac_window   = min(maxcol, np.round(ac_size * fft_res))

    # Compute the autocorrelation
    x_corr      = librosa.core.autocorrelate(onsets[mincol:maxcol], ac_window)

    # re-weight the autocorrelation by log-normal prior
    bpms    = 60.0 * fft_res / (np.arange(1, ac_window+1))

    # Smooth the autocorrelation by a log-normal distribution
    x_corr  = x_corr * np.exp(-0.5 * ((np.log2(bpms / start_bpm)) / std_bpm)**2)

    # Get the local maximum of weighted correlation
    x_peaks = librosa.core.localmax(x_corr)

    # Zero out all peaks before the first negative
    x_peaks[:np.argmax(x_corr < 0)] = False


    # Choose the best peak out of .33, .5, 2, 3 * start_period
    candidates      = np.multiply(  np.argmax(x_peaks * x_corr), 
                                    [1.0/3, 1.0/2, 1.0, 2.0, 3.0])

    candidates      = candidates.astype(int)
    candidates      = candidates[candidates < ac_window]

    best_period     = np.argmax(x_corr[candidates])

    if candidates[best_period] > 0:
        return 60.0 * fft_res / candidates[best_period]

    return start_bpm

def __beat_tracker(onsets, bpm, fft_res, tightness, trim):
    """Internal function that does beat tracking from a given onset profile.

    :parameters:
      - onsets   : np.ndarray
          onset envelope
      - bpm      : float
          tempo estimate
      - fft_res  : float
          resolution of the fft (sr / hop_length)
      - tightness: float
          how closely do we adhere to bpm?
      - trim     : bool
          trim leading/trailing beats with weak onsets?

    :returns:
      - beats    : np.ndarray
          frame numbers of beat events

    """

    #--- First, some helper functions ---#
    def rbf(points):
        """Makes a smoothing filter for onsets"""
        
        return np.exp(-0.5 * (points**2))

    def beat_track_dp(localscore):  
        """Core dynamic program for beat tracking"""

        backlink    = np.zeros_like(localscore, dtype=int)
        cumscore    = np.zeros_like(localscore)

        # Search range for previous beat
        window      = np.arange(-2*period, -np.round(period/2) + 1, dtype=int)

        # Make a score window, which begins biased toward start_bpm and skewed 
        txwt        = - tightness * np.log(-window /period)**2

        # Are we on the first beat?
        first_beat  = True
        for i in xrange(len(localscore)):

            # Are we reaching back before time 0?
            z_pad = np.maximum(0, min(- window[0], len(window)))

            # Search over all possible predecessors 
            candidates          = txwt.copy()
            candidates[z_pad:]  = candidates[z_pad:] + cumscore[window[z_pad:]]

            # Find the best preceding beat
            beat_location       = np.argmax(candidates)

            # Add the local score
            cumscore[i]         = localscore[i] + candidates[beat_location]

            # Special case the first onset.  Stop if the localscore is small
            if first_beat and localscore[i] < 0.01 * localscore.max():
                backlink[i]     = -1
            else:
                backlink[i]     = window[beat_location]
                first_beat      = False

            # Update the time range
            window  = window + 1

        return (backlink, cumscore)

    def get_last_beat(cumscore):
        """Get the last beat from the cumulative score array"""

        maxes       = librosa.core.localmax(cumscore)
        med_score   = np.median(cumscore[np.argwhere(maxes)])

        # The last of these is the last beat (since score generally increases)
        return np.argwhere((cumscore * maxes * 2 > med_score)).max()

    def smooth_beats(beats, trim):
        """Final post-processing: throw out spurious leading/trailing beats"""
        
        smooth_boe  = scipy.signal.convolve(localscore[beats], 
                                            scipy.signal.hann(5), 'same')

        if trim:
            threshold   = 0.5 * ((smooth_boe**2).mean()**0.5)
        else:
            threshold   = 0.0

        valid       = np.argwhere(smooth_boe > threshold)

        return  beats[valid.min():valid.max()]
    
    def normalize_onsets(onsets):
        '''Maps onset strength function into the range [0, 1]'''

        norm = onsets.std(ddof=1)
        if norm > 0:
            onsets = onsets / norm
        return onsets

    #--- End of helper functions ---#

    # convert bpm to a sample period for searching
    period      = round(60.0 * fft_res / bpm)

    # localscore is a smoothed version of AGC'd onset envelope


    localscore  = scipy.signal.convolve(
                        normalize_onsets(onsets), 
                        rbf(np.arange(-period, period+1)*32.0/period), 
                        'same')

    ### run the DP
    (backlink, cumscore) = beat_track_dp(localscore)

    ### get the position of the last beat
    beats   = [get_last_beat(cumscore)]

    ### Reconstruct the beat path from backlinks
    while backlink[beats[-1]] >= 0:
        beats.append(backlink[beats[-1]])

    ### Put the beats in ascending order
    beats.reverse()

    ### Convert into an array of frame numbers
    beats = np.array(beats, dtype=int)

    ### Discard spurious trailing beats
    beats = smooth_beats(beats, trim)

    return beats

########NEW FILE########
__FILENAME__ = core
#!/usr/bin/env python
"""Core IO, DSP and utility functions."""

import os
import audioread
import re

import numpy as np
import numpy.fft as fft
import scipy.signal
import scipy.ndimage

from . import filters
from . import feature
from . import util

# Do we have scikits.samplerate?
try:
    # Pylint won't handle dynamic imports, so we suppress this warning
    import scikits.samplerate as samplerate     # pylint: disable=import-error
    _HAS_SAMPLERATE = True
except ImportError:
    _HAS_SAMPLERATE = False

# Constrain STFT block sizes to 128 MB
_MAX_MEM_BLOCK = 2**7 * 2**20

#-- CORE ROUTINES --#
def load(path, sr=22050, mono=True, offset=0.0, duration=None, dtype=np.float32):
    """Load an audio file as a floating point time series.

    :usage:
        >>> # Load a wav file
        >>> y, sr = librosa.load('file.wav')

        >>> # Load a wav file and resample to 11 KHz
        >>> y, sr = librosa.load('file.wav', sr=11025)

        >>> # Load 5 seconds of a wav file, starting 15 seconds in
        >>> y, sr = librosa.load('file.wav', offset=15.0, duration=5.0)

    :parameters:
      - path : string
          path to the input file.  
          Any format supported by ``audioread`` will work.

      - sr   : int > 0
          target sampling rate
          'None' uses the native sampling rate

      - mono : bool
          convert signal to mono

      - offset : float
          start reading after this time (in seconds)

      - duration : float
          only load up to this much audio (in seconds)

      - dtype : numeric type
          data type of y

    :returns:
      - y    : np.ndarray
          audio time series

      - sr   : int  
          sampling rate of ``y``

    """

    with audioread.audio_open(os.path.realpath(path)) as input_file:
        sr_native = input_file.samplerate

        s_start = int(np.floor(sr_native * offset) * input_file.channels)

        if duration is None:
            s_end = np.inf
        else:
            s_end = s_start + int(np.ceil(sr_native * duration) 
                                * input_file.channels)


        scale = float(1<<15)

        y = []
        n = 0

        for frame in input_file:
            frame   = np.frombuffer(frame, '<i2').astype(dtype)
            n_prev  = n
            n       = n + len(frame)

            if n < s_start:
                # offset is after the current frame
                # keep reading
                continue
            
            if s_end < n_prev:
                # we're off the end.  stop reading
                break

            if s_end < n:
                # the end is in this frame.  crop.
                frame = frame[:s_end - n_prev]

            if n_prev <= s_start < n:
                # beginning is in this frame
                frame = frame[s_start - n_prev : ]

            # tack on the current frame
            y.append(frame)


        y = np.concatenate(y) / scale
        if input_file.channels > 1:
            if mono:
                y = 0.5 * (y[::2] + y[1::2])
            else:
                y = y.reshape( (-1, 2)).T

    if sr is not None:
        y = resample(y, sr_native, sr)
    else:
        sr = sr_native

    return (y, sr)

def resample(y, orig_sr, target_sr, res_type='sinc_fastest'):
    """Resample a signal from orig_sr to target_sr

    :usage:
        >>> # Downsample from 22 KHz to 8 KHz
        >>> y, sr   = librosa.load('file.wav', sr=22050)
        >>> y_8k    = librosa.resample(y, sr, 8000)

    :parameters:
      - y           : np.ndarray
          audio time series 

      - orig_sr     : int
          original sampling rate of ``y``

      - target_sr   : int
          target sampling rate

      - res_type    : str
          resample type (see note)
    
    :returns:
      - y_hat       : np.ndarray
          ``y`` resampled from ``orig_sr`` to ``target_sr``

    .. note::
        If scikits.samplerate is installed, resample will use res_type
        otherwise, it will fall back on scipy.signal.resample

    """

    if orig_sr == target_sr:
        return y

    if _HAS_SAMPLERATE:
        y_hat = samplerate.resample(y.T, float(target_sr) / orig_sr, res_type).T
    else:
        n_samples = y.shape[-1] * target_sr / orig_sr
        y_hat = scipy.signal.resample(y, n_samples, axis=-1)

    return y_hat

def stft(y, n_fft=2048, hop_length=None, win_length=None, window=None):
    """Short-time Fourier transform.

    Returns a complex-valued matrix D such that
      - ``np.abs(D[f, t])`` is the magnitude of frequency bin ``f`` at time ``t``
      - ``np.angle(D[f, t])`` is the phase of frequency bin ``f`` at time ``t``

    :usage:
        >>> y, sr = librosa.load('file.wav')
        >>> D = librosa.stft(y)

    :parameters:
      - y           : np.ndarray, real-valued
          the input signal (audio time series)

      - n_fft       : int
          FFT window size

      - hop_length  : int
          number audio of frames between STFT columns.
          If unspecified, defaults ``win_length / 4``.

      - win_length  : int <= n_fft
          Each frame of audio is windowed by the ``window`` function (see below).
          The window will be of length ``win_length`` and then padded with zeros
          to match ``n_fft``.

          If unspecified, defaults to ``win_length = n_fft``.

      - window      : None, function, np.ndarray
          - None (default): use an asymmetric Hann window
          - a window function, such as ``scipy.signal.hanning``
          - a vector or array of length ``n_fft``

    :returns:
      - D           : np.ndarray, dtype=complex
          STFT matrix

    """

    # By default, use the entire frame
    if win_length is None:
        win_length = n_fft

    # Set the default hop, if it's not already specified
    if hop_length is None:
        hop_length = int(win_length / 4)

    if window is None:
        # Default is an asymmetric Hann window
        fft_window = scipy.signal.hann(win_length, sym=False)

    elif hasattr(window, '__call__'):
        # User supplied a window function
        fft_window = window(win_length)

    else:
        # User supplied a window vector.
        # Make sure it's an array:
        fft_window = np.asarray(window)

        # validate length compatibility
        if fft_window.size != n_fft:
            raise ValueError('Size mismatch between n_fft and len(window)')

    # Pad the window out to n_fft size
    fft_window = util.pad_center(fft_window, n_fft)

    # Reshape so that the window can be broadcast
    fft_window  = fft_window.reshape((-1, 1))

    # Window the time series. 
    y_frames    = util.frame(y, frame_length=n_fft, hop_length=hop_length)

    # Pre-allocate the STFT matrix
    stft_matrix = np.empty((1 + n_fft / 2, y_frames.shape[1]), 
                           dtype=np.complex64, 
                           order='F')
    
    # how many columns can we fit within MAX_MEM_BLOCK?
    n_columns = int(_MAX_MEM_BLOCK / (stft_matrix.shape[0] * stft_matrix.itemsize))
    
    for block_start in xrange(0, stft_matrix.shape[1], n_columns):
        block_end = min(block_start + n_columns, 
                        stft_matrix.shape[1])
        
        # RFFT and Conjugate here to match phase from DPWE code
        stft_matrix[:, block_start:block_end] = fft.rfft(fft_window * y_frames[:, block_start:block_end], 
                                                   axis=0).conj()
    
    return stft_matrix

def istft(stft_matrix, hop_length=None, win_length=None, window=None):  
    """
    Inverse short-time Fourier transform.

    Converts a complex-valued spectrogram ``stft_matrix`` to time-series ``y``.

    :usage:
        >>> y, sr   = librosa.load('file.wav')
        >>> D       = librosa.stft(y)
        >>> y_hat   = librosa.istft(D)

    :parameters:
      - stft_matrix : np.ndarray, shape=(1 + n_fft/2, t)
          STFT matrix from ``stft()``

      - hop_length  : int
          Number of frames between STFT columns.
          If unspecified, defaults to ``win_length / 4``.

      - win_length  : int <= n_fft = 2 * (stft_matrix.shape[0] - 1)
          When reconstructing the time series, each frame is windowed
          according to the ``window`` function (see below).
          
          If unspecified, defaults to ``n_fft``.

      - window      : None, function, np.ndarray
          - None (default): use an asymmetric Hann window * 2/3
          - a window function, such as ``scipy.signal.hanning``
          - a user-specified window vector of length ``n_fft``

    :returns:
      - y           : np.ndarray
          time domain signal reconstructed from ``stft_matrix``

    """

    n_fft       = 2 * (stft_matrix.shape[0] - 1)

    # By default, use the entire frame
    if win_length is None:
        win_length = n_fft

    # Set the default hop, if it's not already specified
    if hop_length is None:
        hop_length = win_length / 4

    if window is None: 
        # Default is an asymmetric Hann window.
        # 2/3 scaling is to make stft(istft(.)) identity for 25% hop
        ifft_window =  scipy.signal.hann(win_length, sym=False) * (2.0 / 3)

    elif hasattr(window, '__call__'):
        # User supplied a windowing function
        ifft_window = window(win_length)

    else:
        # User supplied a window vector.
        # Make it into an array
        ifft_window = np.asarray(window)

        # Verify that the shape matches
        if ifft_window.size != n_fft:
            raise ValueError('Size mismatch between n_fft and window size')

    # Pad out to match n_fft
    ifft_window = util.pad_center(ifft_window, n_fft)

    n_frames    = stft_matrix.shape[1]
    y           = np.zeros(n_fft + hop_length * (n_frames - 1))

    for i in xrange(n_frames):
        sample  = i * hop_length
        spec    = stft_matrix[:, i].flatten()
        spec    = np.concatenate((spec.conj(), spec[-2:0:-1] ), 0)
        ytmp    = ifft_window * fft.ifft(spec).real

        y[sample:(sample+n_fft)] = y[sample:(sample+n_fft)] + ytmp

    return y

def ifgram(y, sr=22050, n_fft=2048, hop_length=None, win_length=None, norm=False):
    '''Compute the instantaneous frequency (as a proportion of the sampling rate)
    obtained as the time-derivative of the phase of the complex spectrum as 
    described by Toshihiro Abe et al. in ICASSP'95, Eurospeech'97. 
    
    Calculates regular STFT as a side effect.

    :usage:
        >>> y, sr = librosa.load('file.wav')
        >>> frequencies, D = librosa.ifgram(y, sr=sr)

    :parameters:
      - y       : np.ndarray
          audio time series

      - sr      : int > 0
          sampling rate of ``y``

      - n_fft   : int > 0
          FFT window size

      - hop_length : int > 0
          hop length, number samples between subsequent frames.
          If not supplied, defaults to ``win_length / 4``.

      - win_length : int > 0, <= n_fft
          Window length. Defaults to n_fft.
          See ``stft()`` for details.

      - norm : bool
          Normalize the STFT. 

    :returns:
      - if_gram : np.ndarray, dtype=real
          Instantaneous frequency spectrogram:
          ``if_gram[f, t]`` is the frequency at bin ``f``, time ``t``

      - D : np.ndarray, dtype=complex
          Short-time Fourier transform

    .. note::

      @inproceedings{abe1995harmonics,
            title={Harmonics tracking and pitch extraction based on instantaneous frequency},
            author={Abe, Toshihiko and Kobayashi, Takao and Imai, Satoshi},
            booktitle={Acoustics, Speech, and Signal Processing, 1995. ICASSP-95., 1995 International Conference on},
            volume={1},
            pages={756--759},
            year={1995},
            organization={IEEE}
            }
    '''


    if win_length is None:
        win_length = n_fft

    if hop_length is None:
        hop_length = win_length / 4

    # Construct a padded hann window
    window          = util.pad_center(scipy.signal.hann(win_length, sym=False), n_fft)

    # Window for discrete differentiation
    freq_angular    = np.linspace(0, 2 * np.pi, n_fft, endpoint=False)

    d_window        = np.sin( - freq_angular ) * np.pi / n_fft

    stft_matrix     = stft(y, n_fft=n_fft, hop_length=hop_length, window=window)
    diff_stft       = stft(y, n_fft=n_fft, hop_length=hop_length, window=d_window).conj()

    # Compute power normalization. Suppress zeros.
    power               = np.abs(stft_matrix)**2
    power[power == 0]   = 1.0
    
    # Pylint does not correctly infer the type here, but it's correct.
    freq_angular    = freq_angular.reshape((-1, 1)) # pylint: disable=maybe-no-member
    
    if_gram = (freq_angular[:n_fft/2 + 1] + (stft_matrix * diff_stft).imag / power) * sr / (2 * np.pi)
    
    if norm:
        stft_matrix = stft_matrix * 2.0 / window.sum()

    return if_gram, stft_matrix

def cqt(y, sr, hop_length=512, fmin=None, fmax=None, bins_per_octave=12, tuning=None, 
        resolution=2, aggregate=None, samples=None, basis=None):
    '''Compute the constant-Q transform of an audio signal.
    
    :usage:
        >>> y, sr = librosa.load('file.wav')
        >>> C = librosa.cqt(y, sr)

        >>> # Limit the frequency range
        >>> C = librosa.cqt(y, sr, fmin=librosa.midi_to_hz(36), fmax=librosa.midi_to_hz(96))

        >>> # Use a pre-computed CQT basis
        >>> basis = librosa.filters.constant_q(sr, ...)
        >>> C = librosa.cqt(y, sr, basis=basis)

    :parameters:
      - y : np.ndarray
          audio time series
    
      - sr : int > 0
          sampling rate of ``y``
        
      - hop_length : int > 0
          number of samples between successive CQT columns.
    
      - fmin : float > 0
          Minimum frequency. Defaults to C1 ~= 16.35 Hz
        
      - fmax : float > 0
          Maximum frequency. Defaults to C9 ~= 4816.01 Hz
        
      - bins_per_octave : int > 0
          Number of bins per octave
        
      - tuning : None or float in [-0.5, 0.5)
          Tuning offset in fractions of a bin (cents)
          If None, tuning will be automatically estimated.
        
      - resolution : float > 0
          Filter resolution factor. Larger values use longer windows.
        
      - aggregate : function
          Aggregator function to merge filter response power within frames.
          Default: np.mean
        
      - samples : None or array-like
          Aggregate power at times ``y[samples[i]:samples[i+1]]``, 
          instead of ``y[i * hop_length : (i+1)*hop_length]``
        
          Note that boundary sample times ``(0, len(y))`` will be automatically added.

      - basis : None or list of arrays
          (optinal) alternate set of CQT basis filters.
          See ``librosa.filters.constant_q`` for details.

    :returns:
      - CQT : np.ndarray
          Constant-Q power for each frequency at each time.    
    '''

    if aggregate is None:
        aggregate = np.mean

    # Do we have tuning?
    def __get_tuning():
        '''Helper function to compute tuning from y,sr'''
        pitches, mags = feature.ifptrack(y, sr=sr)[:2]
        threshold = np.median(mags)
        return feature.estimate_tuning( pitches[mags>threshold], 
                                        bins_per_octave=bins_per_octave)

    if tuning is None:
        tuning = __get_tuning()

    # Generate the CQT filters
    if basis is None:
        basis = filters.constant_q(sr, 
                            fmin=fmin, 
                            fmax=fmax, 
                            bins_per_octave=bins_per_octave, 
                            tuning=tuning, 
                            resolution=resolution)
    
    if samples is None:
        samples    = np.arange(0, len(y), hop_length)
    else:
        samples    = np.asarray([samples]).flatten()

    cqt_power = np.empty((len(basis), len(y)), dtype=np.float32, order='F')
    
    for i, filt in enumerate(basis):
        cqt_power[i]  = np.abs(scipy.signal.fftconvolve(y, filt, mode='same'))**2
    
    cqt_power = feature.sync(cqt_power, samples, aggregate=aggregate)
    
    return cqt_power
    
def logamplitude(S, ref_power=1.0, amin=1e-10, top_db=80.0):
    """Log-scale the amplitude of a spectrogram.

    :usage:
        >>> # Get a power spectrogram from a waveform y
        >>> S       = np.abs(librosa.stft(y)) ** 2
        >>> log_S   = librosa.logamplitude(S)

        >>> # Compute dB relative to peak power
        >>> log_S   = librosa.logamplitude(S, ref_power=S.max())

    :parameters:
      - S       : np.ndarray
          input spectrogram

      - ref_power : float
          reference against which ``S`` is compared.

      - amin    : float
          minimum amplitude threshold 

      - top_db  : float
          threshold log amplitude at top_db below the peak:
          ``max(log(S)) - top_db``

    :returns:
      log_S   : np.ndarray
          ``log_S ~= 10 * log10(S) - 10 * log10(abs(ref_power))``
    """

    log_spec    =   10.0 * np.log10(np.maximum(amin, np.abs(S))) 
    log_spec    -=  10.0 * np.log10(np.abs(ref_power))

    if top_db is not None:
        log_spec = np.maximum(log_spec, log_spec.max() - top_db)

    return log_spec

def magphase(D):
    """Separate a complex-valued spectrogram D into its magnitude (S)
    and phase (P) components, so that ``D = S * P``.

    :usage:
        >>> D = librosa.stft(y)
        >>> S, P = librosa.magphase(D)
        >>> D == S * P

    :parameters:
      - D       : np.ndarray, dtype=complex
          complex-valued spectrogram

    :returns:
      - D_mag   : np.ndarray, dtype=real
          magnitude of ``D``
      - D_phase : np.ndarray, dtype=complex
          ``exp(1.j * phi)`` where ``phi`` is the phase of ``D``
    """

    mag   = np.abs(D)
    phase = np.exp(1.j * np.angle(D))

    return mag, phase

def phase_vocoder(D, rate, hop_length=None):
    """Phase vocoder.  Given an STFT matrix D, speed up by a factor of ``rate``

    :usage:
        >>> # Play at double speed
        >>> y, sr   = librosa.load('file.wav')
        >>> D       = librosa.stft(y, n_fft=2048, hop_length=512)
        >>> D_fast  = librosa.phase_vocoder(D, 2.0, hop_length=512)
        >>> y_fast  = librosa.istft(D_fast, hop_length=512)

        >>> # Or play at 1/3 speed
        >>> D_slow  = librosa.phase_vocoder(D, 1./3, hop_length=512)
        >>> y_slow  = librosa.istft(D_slow, hop_length=512)

    :parameters:
      - D       : np.ndarray, dtype=complex
          STFT matrix

      - rate    :  float, positive
          Speed-up factor: ``rate > 1`` is faster, ``rate < 1`` is slower.

      - hop_length : int or None
          The number of samples between successive columns of ``D``.
          If None, defaults to ``n_fft/4 = (D.shape[0]-1)/2``

    :returns:
      - D_stretched  : np.ndarray, dtype=complex
          time-stretched STFT

    .. note::
      - This implementation was ported from the following:
      - @misc{Ellis02-pvoc
            author = {D. P. W. Ellis},
            year = {2002},
            title = {A Phase Vocoder in {M}atlab},
            note = {Web resource},
            url = {http://www.ee.columbia.edu/~dpwe/resources/matlab/pvoc/},}
            
    """
    
    n_fft = 2 * ( D.shape[0] - 1 )
    
    if hop_length is None:
        hop_length = n_fft / 4
    
    time_steps = np.arange(0, D.shape[1], rate, dtype=np.float)
    
    # Create an empty output array
    d_stretch = np.zeros((D.shape[0], len(time_steps)), D.dtype)
    
    # Expected phase advance in each bin
    phi_advance = np.linspace(0, np.pi * hop_length, D.shape[0])

    # Phase accumulator; initialize to the first sample
    phase_acc = np.angle(D[:, 0])
    
    # Pad 0 columns to simplify boundary logic
    D = np.pad(D, [(0, 0), (0, 2)], mode='constant')

    for (t, step) in enumerate(time_steps):
        
        columns  = D[:, int(step):int(step + 2)]
        
        # Weighting for linear magnitude interpolation
        alpha   = np.mod(step, 1.0)
        mag   = (1.0 - alpha) * np.abs(columns[:, 0]) + alpha * np.abs(columns[:, 1])
        
        # Store to output array
        d_stretch[:, t] = mag * np.exp(1.j * phase_acc)

        # Compute phase advance
        dphase  = np.angle(columns[:, 1]) - np.angle(columns[:, 0]) - phi_advance
        
        # Wrap to -pi:pi range
        dphase  = dphase - 2*np.pi * np.round(dphase / (2*np.pi))
        
        # Accumulate phase
        phase_acc += phi_advance + dphase
    
    return d_stretch

#-- FREQUENCY UTILITIES AND CONVERTERS--#
def note_to_midi(note):
    '''Convert one or more spelled notes to MIDI number(s).
    
    Notes may be spelled out with optional accidentals or octave numbers.

    The leading note name is case-insensitive.

    Sharps are indicated with ``#``, flats may be indicated with ``!`` or ``b``.

    :usage:
        >>> librosa.note_to_midi('C')
        0
        >>> librosa.note_to_midi('C#3')
        37
        >>> librosa.note_to_midi('f4')
        53
        >>> librosa.note_to_midi('Bb-1')
        -2
        >>> librosa.note_to_midi('A!8') 
        104

    :parameters:
      - note : str or iterable of str
        One or more note names.

    :returns:
      - midi : int or np.array
        Midi note numbers corresponding to inputs.
    '''

    if not isinstance(note, str):
        return np.array(map(note_to_midi, note))
    
    pitch_map   = {'C': 0, 'D': 2, 'E': 4, 'F': 5, 'G': 7, 'A': 9, 'B': 11}
    acc_map     = {'#': 1, '': 0, 'b': -1, '!': -1}
    
    try:
        match = re.match(r'^(?P<note>[A-Ga-g])(?P<offset>[#b!]?)(?P<octave>[+-]?\d+)$', note)
        
        pitch = match.group('note').upper()
        offset = acc_map[match.group('offset')]
        octave = int(match.group('octave'))
    except:
        raise ValueError('Improper note format: %s' % note)
    
    return 12 * octave + pitch_map[pitch] + offset

def midi_to_note(midi, octave=True, cents=False):
    '''Convert one or more MIDI numbers to note strings.

    MIDI numbers will be rounded to the nearest integer.

    Notes will be of the format 'C0', 'C#0', 'D0', ...

    :usage:
        >>> librosa.midi_to_note(0)
        'C0'
        >>> librosa.midi_to_note(37)
        'C#3'
        >>> librosa.midi_to_note(-2)
        'A#-1'
        >>> librosa.midi_to_note(104.7)
        'A8'
        >>> librosa.midi_to_note(104.7, cents=True)
        'A8-30'

    :parameters:
      - midi : int or iterable of int
          Midi numbers to convert.

      - octave: bool
          If True, include the octave number

      - cents: bool
          If true, cent markers will be appended for fractional notes.
          Eg, ``midi_to_note(69.3, cents=True)`` == ``A5+03``

    :returns:
      - notes : str or iterable of str
          Strings describing each midi note.
    '''

    if not np.isscalar(midi):
        return map(lambda x: midi_to_note(x, octave=octave, cents=cents), midi)
    
    note_map    = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']

    note_num    = int(np.round(midi))
    note_cents  = int(100 * np.around(midi - note_num, 2))

    note        = note_map[note_num % 12]

    if octave:
        note = '%s%0d' % (note, note_num / 12)
    if cents:
        note = '%s%+02d' % (note, note_cents)

    return note

def midi_to_hz( notes ):
    """Get the frequency (Hz) of MIDI note(s)

    :usage:
        >>> librosa.midi_to_hz(36)
        array([ 65.40639133])

        >>> librosa.midi_to_hz(np.arange(36, 48))
        array([  65.40639133,   69.29565774,   73.41619198,   77.78174593,
                 82.40688923,   87.30705786,   92.49860568,   97.998859  ,
                103.82617439,  110.        ,  116.54094038,  123.47082531])

    :parameters:
      - notes       : int, np.ndarray
          midi number(s) of the note(s)

    :returns:
      - frequency   : float, np.ndarray
          frequency (frequencies) of ``notes`` in Hz
    """

    notes = np.asarray([notes]).flatten()
    return 440.0 * (2.0 ** ((notes - 69)/12.0))

def hz_to_midi( frequencies ):
    """Get the closest MIDI note number(s) for given frequencies

    :usage:
        >>> librosa.hz_to_midi(60)
        array([ 34.50637059])
        >>> librosa.hz_to_midi([110, 220, 440])
        array([ 45.,  57.,  69.])

    :parameters:
      - frequencies   : float, np.ndarray
          frequencies to convert

    :returns:
      - note_nums     : int, np.ndarray
          closest MIDI notes to ``frequencies``
    """

    frequencies = np.asarray([frequencies]).flatten()
    return 12 * (np.log2(frequencies) - np.log2(440.0)) + 69

def hz_to_mel(frequencies, htk=False):
    """Convert Hz to Mels

    :usage:
        >>> librosa.hz_to_mel(60)
        array([0.9])
        >>> librosa.hz_to_mel([110, 220, 440])
        array([ 1.65,  3.3 ,  6.6 ])

    :parameters:
      - frequencies   : np.ndarray, float
          scalar or array of frequencies
      - htk           : bool
          use HTK formula instead of Slaney

    :returns:
      - mels        : np.ndarray
          input frequencies in Mels
    """

    frequencies = np.asarray([frequencies]).flatten()

    if np.isscalar(frequencies):
        frequencies = np.array([frequencies], dtype=float)
    else:
        frequencies = frequencies.astype(float)

    if htk:
        return 2595.0 * np.log10(1.0 + frequencies / 700.0)
    
    # Fill in the linear part
    f_min   = 0.0
    f_sp    = 200.0 / 3

    mels    = (frequencies - f_min) / f_sp

    # Fill in the log-scale part
    
    min_log_hz  = 1000.0                        # beginning of log region (Hz)
    min_log_mel = (min_log_hz - f_min) / f_sp   # same (Mels)
    logstep     = np.log(6.4) / 27.0            # step size for log region

    log_t       = (frequencies >= min_log_hz)
    mels[log_t] = min_log_mel + np.log(frequencies[log_t]/min_log_hz) / logstep

    return mels

def mel_to_hz(mels, htk=False):
    """Convert mel bin numbers to frequencies

    :usage:
        >>> librosa.mel_to_hz(3)
        array([ 200.])

        >>> librosa.mel_to_hz([1,2,3,4,5])
        array([  66.66666667,  133.33333333,  200.        ,  266.66666667,
                333.33333333])

    :parameters:
      - mels          : np.ndarray, float
          mel bins to convert
      - htk           : bool
          use HTK formula instead of Slaney

    :returns:
      - frequencies   : np.ndarray
          input mels in Hz
    """

    mels = np.asarray([mels], dtype=float).flatten()

    if htk:
        return 700.0 * (10.0**(mels / 2595.0) - 1.0)

    # Fill in the linear scale
    f_min       = 0.0
    f_sp        = 200.0 / 3
    freqs       = f_min + f_sp * mels

    # And now the nonlinear scale
    min_log_hz  = 1000.0                        # beginning of log region (Hz)
    min_log_mel = (min_log_hz - f_min) / f_sp   # same (Mels)
    logstep     = np.log(6.4) / 27.0            # step size for log region
    log_t       = (mels >= min_log_mel)

    freqs[log_t] = min_log_hz * np.exp(logstep * (mels[log_t] - min_log_mel))

    return freqs

def hz_to_octs(frequencies, A440=440.0):
    """Convert frequencies (Hz) to (fractional) octave numbers.

    :usage:
        >>> librosa.hz_to_octs(440.0)
        array([ 4.])
        >>> librosa.hz_to_octs([32, 64, 128, 256])
        array([ 0.21864029,  1.21864029,  2.21864029,  3.21864029])

    :parameters:
      - frequencies   : np.ndarray, float
          scalar or vector of frequencies
      - A440          : float
          frequency of A440

    :returns:
      - octaves       : np.ndarray
          octave number for each frequency

    """
    frequencies = np.asarray([frequencies]).flatten()
    return np.log2(frequencies / (A440 / 16.0))

def octs_to_hz(octs, A440=440.0):
    """Convert octaves numbers to frequencies.

    Octaves are counted relative to A.

    :usage:
        >>> librosa.octs_to_hz(1)
        array([ 55.])
        >>> librosa.octs_to_hz([-2, -1, 0, 1, 2])
        array([   6.875,   13.75 ,   27.5  ,   55.   ,  110.   ])

    :parameters:
      - octaves       : np.ndarray
          octave number for each frequency
      - A440          : float
          frequency of A440

    :returns:
      - frequencies   : np.ndarray, float
          scalar or vector of frequencies
    """
    octs = np.asarray([octs]).flatten()
    return (A440/16)*(2.0**octs)

def fft_frequencies(sr=22050, n_fft=2048):
    '''Alternative implementation of ``np.fft.fftfreqs``

    :usage:
        >>> librosa.fft_frequencies(sr=22050, n_fft=16)
        array([     0.   ,   1378.125,   2756.25 ,   4134.375,   5512.5  ,
                 6890.625,   8268.75 ,   9646.875,  11025.   ])

    :parameters:
      - sr : int > 0
          Audio sampling rate

      - n_fft : int > 0
          FFT window size

    :returns:
      - freqs : np.ndarray, shape = (1 + n_fft/2,)
          Frequencies (0, sr/n_fft, 2*sr/n_fft, ..., sr/2)
    '''

    return np.linspace(0, sr/2, 1 + n_fft/2, endpoint=True)

def cqt_frequencies(n_bins, fmin, bins_per_octave=12, tuning=0.0):
    """Compute the center frequencies of Constant-Q bins.

    :usage:
        >>> # Get the CQT frequencies for 24 notes, starting at C2
        >>> librosa.cqt_frequencies(24, fmin=librosa.midi_to_hz(librosa.note_to_midi('C2')))
        array([  32.70319566,   34.64782887,   36.70809599,   38.89087297,
                 41.20344461,   43.65352893,   46.24930284,   48.9994295 ,
                 51.9130872 ,   55.        ,   58.27047019,   61.73541266,
                 65.40639133,   69.29565774,   73.41619198,   77.78174593,
                 82.40688923,   87.30705786,   92.49860568,   97.998859  ,
                103.82617439,  110.        ,  116.54094038,  123.47082531])

    :parameters:
      - n_bins  : int > 0
          Number of constant-Q bins

      - fmin    : float >0
          Minimum frequency

      - bins_per_octave : int > 0
          Number of bins per octave

      - tuning : float in [-0.5, +0.5)
          Deviation from A440 tuning in fractional bins (cents)

    :returns:
      - frequencies : np.ndarray, shape=(n_bins,)
          Center frequency for each CQT bin
    """

    correction = 2.0**(float(tuning) / bins_per_octave)

    return correction * fmin * 2.0**(np.arange(0, n_bins, dtype=float)/bins_per_octave)

def mel_frequencies(n_mels=128, fmin=0.0, fmax=11025.0, htk=False, extra=False):
    """Compute the center frequencies of mel bands

    :usage:
        >>> librosa.mel_frequencies(n_mels=40)
        array([    0.        ,    81.15543818,   162.31087636,   243.46631454,
                324.62175272,   405.7771909 ,   486.93262907,   568.08806725,
                649.24350543,   730.39894361,   811.55438179,   892.70981997,
                973.86525815,  1058.38224675,  1150.77458676,  1251.23239132,
                1360.45974173,  1479.22218262,  1608.3520875 ,  1748.75449257,
                1901.4134399 ,  2067.39887435,  2247.87414245,  2444.10414603,
                2657.46420754,  2889.44970936,  3141.68657445,  3415.94266206,
                3714.14015814,  4038.36904745,  4390.90176166,  4774.2091062 ,
                5190.97757748,  5644.12819182,  6136.83695801,  6672.55713712,
                7255.04344548,  7888.37837041,  8577.0007833 ,  9325.73705043])

    :parameters:
      - n_mels    : int
          number of Mel bins  
      - fmin      : float
          minimum frequency (Hz)
      - fmax      : float
          maximum frequency (Hz)
      - htk       : bool
          use HTK formula instead of Slaney
      - extra     : bool
          include extra frequencies necessary for building Mel filters

    :returns:
      - bin_frequencies : ndarray
          vector of Mel frequencies

    """

    # 'Center freqs' of mel bands - uniformly spaced between limits
    minmel  = hz_to_mel(fmin, htk=htk)
    maxmel  = hz_to_mel(fmax, htk=htk)

    mels    = np.arange(minmel, maxmel + 1, (maxmel - minmel)/(n_mels + 1.0))

    if not extra:
        mels = mels[:n_mels]

    return  mel_to_hz(mels, htk=htk)

# A-weighting should be capitalized: suppress the naming warning
def A_weighting(frequencies, min_db=-80.0):     # pylint: disable=invalid-name
    '''Compute the A-weighting of a set of frequencies.

    :usage:
        >>> # Get the A-weighting for 20 Mel frequencies
        >>> freqs   = librosa.mel_frequencies(20)
        >>> librosa.A_weighting(freqs)
        array([-80.        , -13.35467911,  -6.59400464,  -3.57422971,
                -1.87710933,  -0.83465455,  -0.15991521,   0.3164558 ,
                0.68372258,   0.95279329,   1.13498903,   1.23933477,
                1.27124465,   1.23163355,   1.1163366 ,   0.91575476,
                0.6147545 ,   0.1929889 ,  -0.37407714,  -1.11314196])

    :parameters:
      - frequencies : scalar or np.ndarray
          One or more frequencies (in Hz)

      - min_db : float or None
          Clip weights below this threshold.
          If ``None``, no clipping is performed.

    :returns:
      - A_weighting : scalar or np.ndarray
          A[i] is the A-weighting of frequencies[i]
    '''

    # Vectorize to make our lives easier
    frequencies = np.asarray([frequencies]).flatten()

    # Pre-compute squared frequeny
    f_sq    = frequencies**2.0

    const   = np.array([12200, 20.6, 107.7, 737.9])**2.0

    r_a     = const[0] * f_sq**2
    r_a     /= (f_sq + const[0]) * (f_sq + const[1])
    r_a     /= np.sqrt((f_sq + const[2]) * (f_sq + const[3]))

    weights = 2.0 + 20 * np.log10(r_a)
    
    if min_db is not None:
        weights = np.maximum(min_db, weights)

    return weights

#-- UTILITIES --#
def frames_to_time(frames, sr=22050, hop_length=512, n_fft=None):
    """Converts frame counts to time (seconds)

    :usage:
        >>> y, sr = librosa.load('file.wav')
        >>> tempo, beats = librosa.beat.beat_track(y, sr, hop_length=64)
        >>> beat_times   = librosa.frames_to_time(beats, sr, hop_length=64)

        >>> # Time conversion with a framing correction
        >>> onset_env    = librosa.onset.onset_strength(y=y, sr=sr, n_fft=1024)
        >>> onsets       = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)
        >>> onset_times  = librosa.frames_to_time(onsets, 
                                                  sr=sr, 
                                                  hop_length=64,
                                                  n_fft=1024)


    :parameters:
      - frames     : np.ndarray
          vector of frame numbers

      - sr         : int > 0
          audio sampling rate 

      - hop_length : int
          number of samples between successive frames

      - n_fft : None or int > 0
          Optional: length of the FFT window.  
          If given, time conversion will include an offset of ``n_fft / 2``
          to counteract windowing effects in STFT.

    :returns:
      - times : np.ndarray 
          time (in seconds) of each given frame number:
          ``times[i] = frames[i] * hop_length / sr``

    """

    offset = 0
    if n_fft is not None:
        offset = n_fft / 2

    return (frames * hop_length + offset) / float(sr)

def time_to_frames(times, sr=22050, hop_length=512, n_fft=None):
    """Converts time stamps into STFT frames.

    :usage:
        >>> # Get the frame numbers for every 100ms
        >>> librosa.time_to_frames(np.arange(0, 1, 0.1), sr=22050, hop_length=512)
        array([ 0,  4,  8, 12, 17, 21, 25, 30, 34, 38])

    :parameters:
      - times : np.ndarray
          vector of time stamps

      - sr : int > 0
          audio sampling rate

      - hop_length : int > 0
          number of samples between successive frames

      - n_fft : None or int > 0
          Optional: length of the FFT window.  
          If given, time conversion will include an offset of ``- n_fft / 2``
          to counteract windowing effects in STFT.

          .. note:: This may result in negative frame indices. 

    :returns:
      - frames : np.ndarray, dtype=int
          Frame numbers corresponding to the given times:
          ``frames[i] = floor( times[i] * sr / hop_length )``
    """
    offset = 0
    if n_fft is not None:
        offset = n_fft / 2

    return np.floor((times * np.float(sr) - offset) / hop_length).astype(int)

def autocorrelate(y, max_size=None):
    """Bounded auto-correlation

    :usage:
        >>> # Compute full autocorrelation of y
        >>> y, sr   = librosa.load('file.wav')
        >>> y_ac    = librosa.autocorrelate(y)

        >>> # Compute autocorrelation up to 4 seconds lag
        >>> y_ac_4  = librosa.autocorrelate(y, 4 * sr)

    :parameters:
      - y         : np.ndarray
          vector to autocorrelate

      - max_size  : int
          maximum correlation lag.
          If unspecified, defaults to ``len(y)`` (unbounded)

    :returns:
      - z         : np.ndarray
          truncated autocorrelation ``y*y``

    """

    result = scipy.signal.fftconvolve(y, y[::-1], mode='full')

    result = result[len(result)/2:]

    if max_size is None:
        return result
    else:
        max_size = int(max_size)
    
    return result[:max_size]

def localmax(x):
    """Return 1 where there are local maxima in x (column-wise)
       left edges do not fire, right edges might.

    :usage:
        >>> x = np.array([1, 0, 1, 2, -1, 0, -2, 1])
        >>> librosa.localmax(x)
        array([False, False, False,  True, False,  True, False, True], dtype=bool)

    :parameters:
      - x     : np.ndarray
          input vector

    :returns:
      - m     : np.ndarray, dtype=bool
          indicator vector of local maxima:
          ``m[i] == True`` if ``x[i]`` is a local maximum
    """

    return np.logical_and(x > np.hstack([x[0], x[:-1]]), 
                             x >= np.hstack([x[1:], x[-1]]))

def peak_pick(x, pre_max, post_max, pre_avg, post_avg, delta, wait):
    '''Uses a flexible heuristic to pick peaks in a signal.

    :usage:
        >>> # Look +-3 steps
        >>> # compute the moving average over +-5 steps
        >>> # peaks must be > avg + 0.5
        >>> # skip 10 steps before taking another peak
        >>> librosa.peak_pick(x, 3, 3, 5, 5, 0.5, 10)
    
    :parameters:
      - x         : np.ndarray
          input signal to peak picks from
      - pre_max   : int
          number of samples before n over which max is computed
      - post_max  : int
          number of samples after n over which max is computed
      - pre_avg   : int
          number of samples before n over which mean is computed
      - post_avg  : int
          number of samples after n over which mean is computed
      - delta     : float
          threshold offset for mean
      - wait      : int
          number of samples to wait after picking a peak

    :returns:
      - peaks     : np.ndarray, dtype=int
          indices of peaks in x
    
    .. note::
      A sample n is selected as an peak if the corresponding x[n]
      fulfills the following three conditions:

        1. ``x[n] == max(x[n - pre_max:n + post_max])``
        2. ``x[n] >= mean(x[n - pre_avg:n + post_avg]) + delta``
        3. ``n - previous_n > wait``

      where ``previous_n`` is the last sample picked as a peak (greedily).
    
    .. note::
        @inproceedings{bock2012evaluating,
            title={Evaluating the Online Capabilities of Onset Detection Methods.},
            author={B{\"o}ck, Sebastian and Krebs, Florian and Schedl, Markus},
            booktitle={ISMIR},
            pages={49--54},
            year={2012}}
    
    .. note::
      Implementation based on 
      https://github.com/CPJKU/onset_detection/blob/master/onset_program.py
    '''

    # Get the maximum of the signal over a sliding window
    max_length  = pre_max + post_max + 1
    max_origin  = 0.5 * (pre_max - post_max)
    mov_max     = scipy.ndimage.filters.maximum_filter1d(x, int(max_length), 
                                                            mode='constant', 
                                                            origin=int(max_origin))

    # Get the mean of the signal over a sliding window
    avg_length  = pre_avg + post_avg + 1
    avg_origin  = 0.5 * (pre_avg - post_avg)
    mov_avg     = scipy.ndimage.filters.uniform_filter1d(x, int(avg_length), 
                                                            mode='constant', 
                                                            origin=int(avg_origin))

    # First mask out all entries not equal to the local max
    detections = x*(x == mov_max)

    # Then mask out all entries less than the thresholded average
    detections = detections*(detections >= mov_avg + delta)
    
    # Initialize peaks array, to be filled greedily
    peaks = []
    
    # Remove onsets which are close together in time
    last_onset = -np.inf
    
    for i in np.nonzero(detections)[0]:
        # Only report an onset if the "wait" samples was reported
        if i > last_onset + wait:
            peaks.append(i)
            # Save last reported onset
            last_onset = i
    
    return np.array( peaks )


########NEW FILE########
__FILENAME__ = decompose
#!/usr/bin/env python
"""Spectrogram decomposition"""

import numpy as np
import scipy
import scipy.signal

import sklearn.decomposition

import librosa.core


def decompose(S, n_components=None, transformer=None):
    """Decompose a feature matrix.
    
    By default, this is done with with non-negative matrix factorization,
    but any ``sklearn.decomposition``-type object will work.

    :usage:
        >>> # Decompose a magnitude spectrogram into 32 components with NMF
        >>> S = np.abs(librosa.stft(y))
        >>> components, activations = librosa.decompose.decompose(S, n_components=32)

        >>> # Or with sparse dictionary learning
        >>> T = sklearn.decomposition.DictionaryLearning(n_components=32)
        >>> components, activations = librosa.decompose.decompose(S, transformer=T)

    :parameters:
        - S : np.ndarray, shape=(n_features, n_samples)
            feature matrix

        - n_components : int > 0 or None
            number of desired components
            if None, then ``n_features`` components are used

        - transformer : None or object
            If None, use ``sklearn.decomposition.NMF``

            Otherwise, any object with a similar interface to NMF should work.
            ``transformer`` must follow the scikit-learn convention, where input data
            is (n_samples, n_features). 

            ``transformer.fit_transform()`` will be run on ``S.T`` (not ``S``),
            the return value of which is stored (transposed) as ``activations``.

            The components will be retrieved as ``transformer.components_.T``

            ``S ~= np.dot(activations, transformer.components_).T``
            
            or equivalently:
            ``S ~= np.dot(transformer.components_.T, activations.T)``

    :returns:
        - components: np.ndarray, shape=(n_features, n_components)
            dictionary matrix

        - activations: np.ndarray, shape=(n_components, n_samples)
            transformed matrix/activation matrix

    """

    if transformer is None:
        transformer = sklearn.decomposition.NMF(n_components=n_components)

    activations = transformer.fit_transform(S.T)

    return (transformer.components_.T, activations.T)

def hpss(S, kernel_size=31, power=2.0, mask=False):
    """Median-filtering harmonic percussive separation

    Decomposes an input spectrogram ``S = H + P``
    where ``H`` contains the harmonic components, 
    and ``P`` contains the percussive components.

    :usage:
        >>> D = librosa.stft(y)
        >>> H, P = librosa.decompose.hpss(D)
        >>> y_harmonic = librosa.istft(H)

        >>> # Or with a narrower horizontal filter
        >>> H, P = librosa.decompose.hpss(D, kernel_size=(13, 31))

    :parameters:
      - S : np.ndarray
          input spectrogram. May be real (magnitude) or complex.

      - kernel_size : int or tuple (kernel_harmonic, kernel_percussive)
          kernel size for the median filters.
          If scalar, the same size is used for both harmonic and percussive.
          If array_like, the first value specifies the width of the harmonic filter,
          and the second value specifies the width of the percussive filter.

      - power : float > 0
          Exponent for the Wiener filter

      - mask : bool
          Return the masking matrices instead of components

    :returns:
      - harmonic : np.ndarray
          harmonic component (or mask)

      - percussive : np.ndarray
          percussive component (or mask)

      .. note:: harmonic + percussive = S

    .. note::
      @article{fitzgerald2010harmonic,
        title={Harmonic/percussive separation using median filtering},
        author={Fitzgerald, Derry},
        year={2010},
        publisher={Dublin Institute of Technology}}
    
    """

    if np.iscomplex(S).any():
        S, phase = librosa.core.magphase(S)
    else:
        phase = 1

    if np.isscalar(kernel_size):
        win_harm = kernel_size
        win_perc = kernel_size
    else:
        win_harm = kernel_size[0]
        win_perc = kernel_size[1]

    # Compute median filters
    harm = scipy.signal.medfilt2d(S, [1, win_harm])
    perc = scipy.signal.medfilt2d(S, [win_perc, 1])

    if mask or power == 0:
        mask_harm = (harm > perc).astype(float)
        mask_perc = 1 - mask_harm
        if mask: 
            return mask_harm, mask_perc
    else:
        zero_perc = (perc == 0)
        perc = perc ** power
        perc[zero_perc] = 0.0
    
        zero_harm = (harm == 0)
        harm = harm ** power
        harm[zero_harm] = 0.0

        # Find points where both are zero, equalize
        harm[zero_harm & zero_perc] = 0.5
        perc[zero_harm & zero_perc] = 0.5

        # Compute harmonic mask
        mask_harm = harm / (harm + perc)
        mask_perc = perc / (harm + perc)

    return (mask_harm * S * phase, mask_perc * S * phase)


########NEW FILE########
__FILENAME__ = display
#!/usr/bin/env python
"""Display module for interacting with matplotlib"""

import numpy as np
import matplotlib.image as img
import matplotlib.pyplot as plt

import warnings

import librosa.core

# This function wraps xticks or yticks: star-args is okay
def time_ticks(locs, *args, **kwargs):  # pylint: disable=star-args
    '''Plot time-formatted axis ticks.

    :usage:
        >>> # Tick at pre-computed beat times
        >>> librosa.display.specshow(S)
        >>> librosa.display.time_ticks(beat_times)

        >>> # Set the locations of the time stamps
        >>> librosa.display.time_ticks(locations, timestamps)

        >>> # Format in seconds
        >>> librosa.display.time_ticks(beat_times, fmt='s')

        >>> # Tick along the y axis
        >>> librosa.display.time_ticks(beat_times, axis='y')

    :parameters:
       - locations : array
           Time-stamps for tick marks

       - n_ticks : int or None
           Show this number of ticks (evenly spaced).
           If none, all ticks are displayed.
           Default: 5

       - axis : 'x' or 'y'
           Which axis should the ticks be plotted on?
           Default: 'x'

       - fmt : None or {'ms', 's', 'm', 'h'}
           ms: milliseconds   (eg, 241ms)
           s: seconds         (eg, 1.43s)
           m: minutes         (eg, 1:02)
           h: hours           (eg, 1:02:03)

           If none, formatted is automatically selected by the
           range of the times data.

           Default: None

       - kwargs : additional keyword arguments
           See `matplotlib.pyplot.xticks` or `yticks` for details.

    :returns:
       - See `matplotlib.pyplot.xticks` or `yticks` for details.
    '''

    n_ticks = kwargs.pop('n_ticks', 5)
    axis    = kwargs.pop('axis', 'x')
    fmt     = kwargs.pop('fmt', None)

    if axis == 'x':
        ticker = plt.xticks
    elif axis == 'y':
        ticker = plt.yticks
    else:
        raise ValueError("axis must be either 'x' or 'y'.")

    if len(args) > 0:
        times = args[0]
    else:
        times = locs
        locs  = range(len(times))

    if n_ticks is not None:
        # Slice the locations and labels
        locs    = locs[::max(1, len(locs)/n_ticks)]
        times   = times[::max(1, len(times)/n_ticks)]

    # Format the labels by time
    formatters = {'ms': lambda t: '%dms' % (1e3 * t),
                  's':  lambda t: '%0.2fs' % t,
                  'm':  lambda t: '%d:%02d' % ( t / 60, np.mod(t, 60)),
                  'h':  lambda t: '%d:%02d:%02d' % (t / 3600,
                                                    np.mod(t / 60, 60),
                                                    np.mod(t, 60))}

    if fmt is None:
        if max(times) > 3600.0:
            fmt = 'h'
        elif max(times) > 60.0:
            fmt = 'm'
        elif max(times) > 1.0:
            fmt = 's'
        else:
            fmt = 'ms'

    elif fmt not in formatters:
        raise ValueError('Invalid format: %s' % fmt)

    times = map(formatters[fmt], times)

    return ticker(locs, times, **kwargs)

def cmap(data):
    '''Get a default colormap from the given data.

    If the data is boolean, use a black and white colormap.

    If the data has both positive and negative values, use a diverging colormap.

    Otherwise, use a sequential map.

    PuOr and OrRd are chosen to optimize visibility for color-blind people.

    :usage:
        >>> librosa.display.cmap([0, 1, 2])
        'OrRd'
        >>> librosa.display.cmap(np.arange(-10, -5))
        'BuPu_r'
        >>> librosa.display.cmap(np.arange(-10, 10))
        'PuOr_r'

    :parameters:
      - data : np.ndarray
          Input data

    :returns:
      - cmap_str
          - If data is type=boolean, cmap_Str is 'gray_r'
          - If data has only positive values, cmap_str is 'OrRd'
          - If data has only negative values, cmap_str is 'BuPu_r'
          - If data has both positive and negatives, cmap_str is 'PuOr_r'
    '''

    if data.dtype == 'bool':
        return 'gray_r'

    data = np.asarray(data)

    if data.min() >= 0:
        return 'OrRd'

    if data.max() <= 0:
        return 'BuPu_r'

    return 'PuOr_r'

def specshow(data, sr=22050, hop_length=512, x_axis=None, y_axis=None, n_xticks=5, n_yticks=5,
        fmin=None, fmax=None, **kwargs):
    '''Display a spectrogram/chromagram/cqt/etc.

    Functions as a drop-in replacement for ``matplotlib.pyplot.imshow``, but with useful defaults.

    :usage:
        >>> # Visualize an STFT with linear frequency scaling
        >>> D = np.abs(librosa.stft(y))
        >>> librosa.display.specshow(D, sr=sr, y_axis='linear')

        >>> # Or with logarithmic frequency scaling
        >>> librosa.display.specshow(D, sr=sr, y_axis='log')

        >>> # Visualize a CQT with note markers
        >>> CQT = librosa.cqt(y, sr, fmin=55, fmax=880)
        >>> librosa.display.specshow(CQT, sr=sr, y_axis='cqt_note', fmin=55, fmax=880)

        >>> # Draw time markers automatically
        >>> librosa.display.specshow(D, sr=sr, hop_length=hop_length, x_axis='time')

        >>> # Draw a chromagram with pitch classes
        >>> C = librosa.feature.chromagram(y, sr)
        >>> librosa.display.specshow(C, y_axis='chroma')

        >>> # Force a grayscale colormap (white -> black)
        >>> librosa.display.specshow(librosa.logamplitude(D), cmap='gray_r')

    :parameters:
      - data : np.ndarray
          Matrix to display (eg, spectrogram)

      - sr : int > 0
          Sample rate. Used to determine time scale in x-axis

      - hop_length : int > 0
          Hop length. Also used to determine time scale in x-axis

      - x_axis : None or {'time', 'frames', 'off'}
          If None or 'off', no x axis is displayed.
          If 'time', markers are shown as milliseconds, seconds, minutes, or hours.
          (See ``time_ticks()`` for details.)
          If 'frames', markers are shown as frame counts.

      - y_axis : None or {'linear', 'mel', 'cqt_hz', 'cqt_note', 'chroma', 'off'}
          - None or 'off': no y axis is displayed.
          - 'linear': frequency range is determined by the FFT window and sampling rate.
          - 'log': the image is displayed on a vertical log scale.
          - 'mel': frequencies are determined by the mel scale.
          - 'cqt_hz': frequencies are determined by the fmin and fmax values.
          - 'cqt_note': pitches are determined by the fmin and fmax values.
          - 'chroma': pitches are determined by the chroma filters.

      - n_xticks : int > 0
          If x_axis is drawn, the number of ticks to show

      - n_yticks : int > 0
          If y_axis is drawn, the number of ticks to show

      - fmin : float > 0 or None

      - fmax : float > 0 or None
          Used for setting the Mel or constantq frequency scales

      - kwargs
          Additional keyword arguments passed through to ``matplotlib.pyplot.imshow``.

    :returns:
      - image : ``matplotlib.image.AxesImage``
          As returned from ``matplotlib.pyplot.imshow``.

    :raises:
      - ValueError
          If y_axis is 'cqt_hz' or 'cqt_note' and fmin and fmax are not supplied.
    '''

    kwargs.setdefault('aspect',          'auto')
    kwargs.setdefault('origin',          'lower')
    kwargs.setdefault('interpolation',   'nearest')

    if np.issubdtype(data.dtype, np.complex):
        warnings.warn('Trying to display complex-valued input. Showing magnitude instead.')
        data = np.abs(data)

    kwargs.setdefault('cmap', cmap(data))

    # NOTE:  2013-11-14 16:15:33 by Brian McFee <brm2132@columbia.edu>pitch
    #  We draw the image twice here. This is a hack to get around NonUniformImage
    #  not properly setting hooks for color: drawing twice enables things like
    #  colorbar() to work properly.

    axes = plt.imshow(data, **kwargs)

    if y_axis is 'log':
        axes_phantom = plt.gca()

        # Non-uniform imshow doesn't like aspect
        del kwargs['aspect']
        im_phantom   = img.NonUniformImage(axes_phantom, **kwargs)

        y_log, y_inv = __log_scale(data.shape[0])

        im_phantom.set_data( np.arange(0, data.shape[1]), y_log, data)
        axes_phantom.images.append(im_phantom)
        axes_phantom.set_ylim(0, data.shape[0])
        axes_phantom.set_xlim(0, data.shape[1])

    # Set up the y ticks
    positions = np.asarray(np.linspace(0, data.shape[0], n_yticks), dtype=int)

    if y_axis is 'linear':
        values = np.asarray(np.linspace(0, 0.5 * sr,  data.shape[0] + 1), dtype=int)

        plt.yticks(positions, values[positions])
        plt.ylabel('Hz')

    elif y_axis is 'log':

        values = np.asarray(np.linspace(0, 0.5 * sr,  data.shape[0] + 1), dtype=int)
        plt.yticks(positions, values[y_inv[positions]])

        plt.ylabel('Hz')

    elif y_axis is 'mel':
        m_args = {}
        if fmin is not None:
            m_args['fmin'] = fmin
        if fmax is not None:
            m_args['fmax'] = fmax

        # only two star-args here, defined immediately above
        values = librosa.core.mel_frequencies(n_mels=data.shape[0], # pylint: disable=star-args
                                              extra=True,
                                              **m_args)[positions].astype(np.int)
        plt.yticks(positions, values)
        plt.ylabel('Hz')

    elif y_axis is 'cqt_hz':
        if fmax is None and fmin is None:
            raise ValueError('fmin and fmax must be supplied for CQT axis display')

        positions = np.arange(0, data.shape[0],
                             np.ceil(data.shape[0] / float(n_yticks)),
                             dtype=int)


        # Get frequencies
        values = librosa.core.cqt_frequencies(data.shape[0], fmin=fmin,
                                    bins_per_octave=int(data.shape[0] / np.ceil(np.log2(fmax) - np.log2(fmin))))
        plt.yticks(positions, values[positions].astype(int))
        plt.ylabel('Hz')

    elif y_axis is 'cqt_note':
        if fmax is None and fmin is None:
            raise ValueError('fmin and fmax must be supplied for CQT axis display')

        positions = np.arange(0, data.shape[0],
                             np.ceil(data.shape[0] / float(n_yticks)),
                             dtype=int)

        # Get frequencies
        values = librosa.core.cqt_frequencies(data.shape[0], fmin=fmin,
                                    bins_per_octave=int(data.shape[0] / np.ceil(np.log2(fmax) - np.log2(fmin))))
        values = librosa.core.midi_to_note(librosa.core.hz_to_midi(values[positions]))
        plt.yticks(positions, values)
        plt.ylabel('Note')

    elif y_axis is 'chroma':
        positions = np.arange(0, data.shape[0], max(1, data.shape[0] / 12))
        # Labels start at 9 here because chroma starts at A.
        values = librosa.core.midi_to_note(range(9, 9+12), octave=False)
        plt.yticks(positions, values)
        plt.ylabel('Pitch class')

    elif y_axis is None or y_axis is 'off':
        plt.yticks([])
        plt.ylabel('')

    else:
        raise ValueError('Unknown y_axis parameter: %s' % y_axis)

    # Set up the x ticks
    positions = np.asarray(np.linspace(0, data.shape[1], n_xticks), dtype=int)

    if x_axis is 'time':
        time_ticks( positions,
                    librosa.core.frames_to_time(positions, sr=sr, hop_length=hop_length),
                    n_ticks=None, axis='x')

        plt.xlabel('Time')

    elif x_axis is 'frames':
        # Nothing to do here, plot is in frames
        plt.xticks(positions, positions)
        plt.xlabel('Frames')

    elif x_axis is None or x_axis is 'off':
        plt.xticks([])
        plt.xlabel('')

    else:
        raise ValueError('Unknown x_axis parameter: %s' % x_axis)

    return axes

def __log_scale(n):
    '''Return a log-scale mapping of bins 0..n, and its inverse.

    :parameters:
      - n : int > 0
          Number of bins

    :returns:
      - y   : np.ndarray, shape=(n,)

      - y_inv   : np.ndarray, shape=(n,)
    '''

    logn = np.log2(n)
    y = n * (1 - 2.0**np.linspace(-logn, 0, n, endpoint=True))[::-1]

    y_inv = np.arange(len(y)+1)
    for i in range(len(y)-1):
        y_inv[y[i]:y[i+1]] = i

    return y, y_inv


########NEW FILE########
__FILENAME__ = feature
#!/usr/bin/env python
"""Feature extraction routines."""

import numpy as np

import librosa.core
import librosa.util

#-- Chroma --#
def logfsgram(y=None, sr=22050, S=None, n_fft=4096, hop_length=512, **kwargs):
    '''Compute a log-frequency spectrogram (piano roll) using a fixed-window STFT.

    :usage:
        >>> # From time-series input
        >>> S_log       = librosa.logfsgram(y=y, sr=sr)
        >>> # Or from spectrogram input
        >>> S           = np.abs(librosa.stft(y))**2
        >>> S_log       = librosa.logfsgram(S=S, sr=sr)
        >>> # Convert to chroma
        >>> chroma_map  = librosa.filters.cq_to_chroma(S_log.shape[0])
        >>> C           = chroma_map.dot(S_log)

    :parameters:
      - y : np.ndarray or None
          audio time series

      - sr : int > 0
          audio sampling rate of ``y``

      - S : np.ndarray or None
          optional power spectrogram 

      - n_fft : int > 0
          FFT window size

      - hop_length : int > 0
          hop length for STFT. See ``librosa.stft`` for details.

      - bins_per_octave : int > 0
          Number of bins per octave. 
          Defaults to 12.

      - tuning : float in [-0.5,  0.5)
          Deviation (in fractions of a bin) from A440 tuning.
          If not provided, it will be automatically estimated from ``y``.

      - kwargs : additional arguments
          See ``librosa.filters.logfrequency()`` 

    :returns:
      - P : np.ndarray, shape = (n_pitches, t)
          P(f, t) contains the energy at pitch bin f, frame t.

    .. note:: One of either ``S`` or ``y`` must be provided.
          If ``y`` is provided, the power spectrogram is computed automatically given
          the parameters ``n_fft`` and ``hop_length``.
          If ``S`` is provided, it is used as the input spectrogram, and ``n_fft`` is inferred
          from its shape.
    '''
    
    # If we don't have a spectrogram, build one
    if S is None:
        # If the user didn't specify tuning, do it ourselves
        if 'tuning' not in kwargs:
            pitches, magnitudes, S = ifptrack(y, sr, n_fft=n_fft, hop_length=hop_length)
            pitches = pitches[magnitudes > np.median(magnitudes)]
            del magnitudes

            bins_per_octave = kwargs.get('bins_per_octave', 12)
            kwargs['tuning'] = estimate_tuning(pitches, bins_per_octave=bins_per_octave)

            del pitches

        else:
            S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)

        # Retain power
        S = np.abs(S)**2

    else:
        n_fft       = (S.shape[0] -1 ) * 2

    # Build the CQ basis
    cq_basis = librosa.filters.logfrequency(sr, n_fft=n_fft, **kwargs)
    
    return cq_basis.dot(S)

def chromagram(y=None, sr=22050, S=None, norm=np.inf, n_fft=2048, hop_length=512, tuning=0.0, **kwargs):
    """Compute a chromagram from a spectrogram or waveform

    :usage:
        >>> C = librosa.chromagram(y, sr)

        >>> # Use a pre-computed spectrogram
        >>> S = np.abs(librosa.stft(y, n_fft=4096))
        >>> C = librosa.chromagram(S=S)


    :parameters:
      - y          : np.ndarray or None
          audio time series
      - sr         : int
          sampling rate of y
      - S          : np.ndarray or None
          spectrogram (STFT power)
      - norm       : float or None
          column-wise normalization. See
          ``librosa.util.normalize`` for details.
          If `None`, no normalization is performed.

      - n_fft      : int  > 0
          FFT window size if provided ``y, sr`` instead of ``S`` 

      - hop_length : int > 0
          hop length if provided ``y, sr`` instead of ``S``

      - tuning : float in [-0.5, 0.5)
          Deviation from A440 tuning in fractional bins (cents)

      - kwargs
          Parameters to build the chroma filterbank.
          See ``librosa.filters.chroma()`` for details.

    .. note:: One of either ``S`` or ``y`` must be provided.
          If y is provided, the magnitude spectrogram is computed automatically given
          the parameters ``n_fft`` and ``hop_length``.
          If S is provided, it is used as the input spectrogram, and n_fft is inferred
          from its shape.
      
    :returns:
      - chromagram  : np.ndarray
          Normalized energy for each chroma bin at each frame.

    :raises:
      - ValueError 
          if an improper value is supplied for norm

    """
    
    n_chroma = kwargs.get('n_chroma', 12)

    # Build the spectrogram, estimate tuning
    if S is None:
        pitches, magnitudes, S = ifptrack(y, sr=sr, n_fft=n_fft, hop_length=hop_length)
        tuning = estimate_tuning(pitches[magnitudes > np.median(magnitudes)], 
                                 bins_per_octave=n_chroma)

        S = np.abs(S / S.max())**2
    else:
        n_fft       = (S.shape[0] -1 ) * 2

    # Get the filter bank
    if 'A440' not in kwargs:
        kwargs['A440'] = 440.0 * 2.0**(tuning/n_chroma)

    chromafb = librosa.filters.chroma( sr, n_fft, **kwargs)

    # Compute raw chroma
    raw_chroma  = np.dot(chromafb, S)

    # Compute normalization factor for each frame
    if norm is None:
        return raw_chroma
    
    return librosa.util.normalize(raw_chroma, norm=norm, axis=0)

def perceptual_weighting(S, frequencies, ref_power=1e-12):
    '''Perceptual weighting of a power spectrogram:
    
    ``S_p[f] = A_weighting(f) + 10*log(S[f] / ref_power)``
    
    :usage:
        >>> # Re-weight a CQT representation, using peak power as reference
        >>> CQT             = librosa.cqt(y, sr, fmin=55, fmax=440)
        >>> freqs           = librosa.cqt_frequencies(CQT.shape[0], fmin=55)
        >>> percept_CQT     = librosa.feature.perceptual_weighting(CQT, freqs, 
                                                                    ref_power=CQT.max())

    :parameters:
      - S : np.ndarray, shape=(d,t)
          Power spectrogram
        
      - frequencies : np.ndarray, shape=(d,)
          Center frequency for each row of ``S``
        
      - ref_power : float > 0
          Reference power
        
    :returns:
      - S_p : np.ndarray, shape=(d,t)
          perceptually weighted version of ``S``, in dB relative to ``ref_power``
    '''
    
    offset = librosa.A_weighting(frequencies).reshape((-1, 1))
    
    return offset + librosa.logamplitude(S, ref_power=ref_power)

#-- Pitch and tuning --#
def estimate_tuning(frequencies, resolution=0.01, bins_per_octave=12):
    '''Given a collection of pitches, estimate its tuning offset
    (in fractions of a bin) relative to A440=440.0Hz.
    
    :usage:
        >>> # Generate notes at +25 cents
        >>> freqs = librosa.cqt_frequencies(24, 55, tuning=0.25)
        >>> librosa.feature.estimate_tuning(freqs)
        0.25

        >>> # Track frequencies from a real spectrogram
        >>> pitches, magnitudes, stft = librosa.feature.ifptrack(y, sr)
        >>> # Select out pitches with high energy
        >>> pitches = pitches[magnitudes > np.median(magnitudes)]
        >>> librosa.feature.estimate_tuning(pitches)

    :parameters:
      - frequencies : array-like, float
          A collection of frequencies detected in the signal.
          See ``ifptrack``.

      - resolution : float in (0, 1)
          Resolution of the tuning as a fraction of a bin.
          0.01 corresponds to cents.
        
      - bins_per_octave : int > 0
          How many frequency bins per octave
        
    :returns:
      - tuning: float in [-0.5, 0.5]
          estimated tuning deviation (fractions of a bin)                
    '''

    frequencies = np.asarray([frequencies], dtype=float).flatten()

    # Trim out any DC components
    frequencies = frequencies[frequencies > 0]

    # Compute the residual relative to the number of bins
    residual = np.mod(bins_per_octave * librosa.core.hz_to_octs(frequencies) , 1.0)

    # Are we on the wrong side of the semitone?
    # A residual of 0.95 is more likely to be a deviation of -0.05
    # from the next tone up.
    residual[residual >= 0.5] -= 1.0
    
    bins     = np.linspace(-0.5, 0.5, np.ceil(1./resolution), endpoint=False)
  
    counts, tuning = np.histogram(residual, bins)
    
    # return the histogram peak
    return tuning[np.argmax(counts)]

def ifptrack(y, sr=22050, n_fft=4096, hop_length=None, fmin=None, fmax=None, threshold=0.75):
    '''Instantaneous pitch frequency tracking.

    :usage:
        >>> pitches, magnitudes, D = librosa.feature.ifptrack(y, sr)

    :parameters:
      - y: np.ndarray
          audio signal
      
      - sr : int
          audio sampling rate of ``y``
        
      - n_fft: int
          FFT window size
        
      - hop_length : int
          Hop size for STFT.  Defaults to ``n_fft / 4``.
          See ``librosa.stft()`` for details.

      - threshold : float in (0, 1)
          Maximum fraction of expected frequency increment to tolerate
      
      - fmin : float or tuple of float
          Ramp parameter for lower frequency cutoff.
          If scalar, the ramp has 0 width.
          If tuple, a linear ramp is applied from ``fmin[0]`` to ``fmin[1]``
          Default: (150.0, 300.0)
        
      - fmax : float or tuple of float
          Ramp parameter for upper frequency cutoff.
          If scalar, the ramp has 0 width.
          If tuple, a linear ramp is applied from ``fmax[0]`` to ``fmax[1]``
          Default: (2000.0, 4000.0)

    :returns:
      - pitches : np.ndarray, shape=(d,t)
      - magnitudes : np.ndarray, shape=(d,t)
          Where ``d`` is the subset of FFT bins within ``fmin`` and ``fmax``.
        
          ``pitches[i, t]`` contains instantaneous frequencies at time ``t``
          ``magnitudes[i, t]`` contains their magnitudes.
        
      - D : np.ndarray, dtype=complex
          STFT matrix
    '''

    if fmin is None:
        fmin    = (150.0, 300.0)

    if fmax is None:
        fmax    = (2000.0, 4000.0)

    fmin = np.asarray([fmin]).squeeze()
    fmax = np.asarray([fmax]).squeeze()
    
    # Truncate to feasible region
    fmin = np.maximum(0, fmin)
    fmax = np.minimum(fmax, sr / 2)
    
    # What's our DFT bin resolution?
    fft_res = float(sr) / n_fft
    
    # Only look at bins up to 2 kHz
    max_bin = int(round(fmax[-1] / fft_res))
  
    if hop_length is None:
        hop_length = n_fft / 4

    # Calculate the inst freq gram
    if_gram, D = librosa.core.ifgram(y, sr=sr, 
                                     n_fft=n_fft, 
                                     win_length=n_fft/2, 
                                     hop_length=hop_length)

    # Find plateaus in ifgram - stretches where delta IF is < thr:
    # ie, places where the same frequency is spread across adjacent bins
    idx_above  = range(1, max_bin) + [max_bin - 1]
    idx_below  = [0] + range(0, max_bin - 1)
    
    # expected increment per bin = sr/w, threshold at 3/4 that
    matches    = abs(if_gram[idx_above] - if_gram[idx_below]) < threshold * fft_res
  
    # mask out any singleton bins (where both above and below are zero)
    matches    = matches * ((matches[idx_above] > 0) | (matches[idx_below] > 0))

    pitches    = np.zeros_like(matches, dtype=float)
    magnitudes = np.zeros_like(matches, dtype=float)

    # For each frame, extract all harmonic freqs & magnitudes
    for t in range(matches.shape[1]):
        
        # find nonzero regions in this vector
        # The mask selects out constant regions + active borders
        mask   = ~np.pad(matches[:, t], 1, mode='constant')
        
        starts = np.argwhere(matches[:, t] & mask[:-2]).astype(int)
        ends   = 1 + np.argwhere(matches[:, t] & mask[2:]).astype(int)
        
        # Set up inner loop    
        frqs = np.zeros_like(starts, dtype=float)
        mags = np.zeros_like(starts, dtype=float)
        
        for i, (start_i, end_i) in enumerate(zip(starts, ends)):

            start_i = np.asscalar(start_i)
            end_i   = np.asscalar(end_i)

            # Weight frequencies by energy
            weights = np.abs(D[start_i:end_i, t])
            mags[i] = weights.sum()
            
            # Compute the weighted average frequency.
            # FIXME: is this the right thing to do? 
            # These are frequencies... shouldn't this be a 
            # weighted geometric average?
            frqs[i] = weights.dot(if_gram[start_i:end_i, t])
            if mags[i] > 0:
                frqs[i] /= mags[i]
            
        # Clip outside the ramp zones
        idx        = (fmax[-1] < frqs) | (frqs < fmin[0])
        mags[idx]  = 0
        frqs[idx]  = 0
        
        # Ramp down at the high end
        idx        = (fmax[-1] > frqs) & (frqs > fmax[0])
        mags[idx] *= (fmax[-1] - frqs[idx]) / (fmax[-1] - fmax[0])
        
        # Ramp up from the bottom end
        idx        = (fmin[-1] > frqs) & (frqs > fmin[0])
        mags[idx] *= (frqs[idx] - fmin[0]) / (fmin[-1] - fmin[0])
        
        # Assign pitch and magnitude to their center bin
        bins                = (starts + ends) / 2
        pitches[bins, t]    = frqs
        magnitudes[bins, t] = mags

    return pitches, magnitudes, D
  
#-- Mel spectrogram and MFCCs --#
def mfcc(S=None, y=None, sr=22050, n_mfcc=20):
    """Mel-frequency cepstral coefficients

    :usage:
        >>> # Generate mfccs from a time series
        >>> mfccs = librosa.feature.mfcc(y=y, sr=sr)

        >>> # Use a pre-computed log-power Mel spectrogram
        >>> S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)
        >>> mfccs = librosa.feature.mfcc(S=librosa.logamplitude(S))

        >>> # Get more components
        >>> mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)

    :parameters:
      - S     : np.ndarray or None
          log-power Mel spectrogram
      - y     : np.ndarray or None
          audio time series
      - sr    : int > 0
          sampling rate of y
      - n_mfcc: int
          number of MFCCs to return

    .. note::
        One of ``S`` or ``y, sr`` must be provided.
        If ``S`` is not given, it is computed from ``y, sr`` using
        the default parameters of ``melspectrogram``.

    :returns:
      - M     : np.ndarray, shape=(n_mfcc, S.shape[1])
          MFCC sequence

    """

    if S is None:
        S = librosa.logamplitude(melspectrogram(y=y, sr=sr))
    
    return np.dot(librosa.filters.dct(n_mfcc, S.shape[0]), S)

def melspectrogram(y=None, sr=22050, S=None, n_fft=2048, hop_length=512, **kwargs):
    """Compute a Mel-scaled power spectrogram.

    :usage:
        >>> S = librosa.feature.melspectrogram(y=y, sr=sr)

        >>> # Using a pre-computed power spectrogram
        >>> D = np.abs(librosa.stft(y))**2
        >>> S = librosa.feature.melspectrogram(S=D)

        >>> # Passing through arguments to the Mel filters
        >>> S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)

    :parameters:
      - y : np.ndarray
          audio time-series
      - sr : int
          sampling rate of y  
      - S : np.ndarray
          magnitude or power spectrogram
      - n_fft : int
          length of the FFT window
      - hop_length : int
          number of samples between successive frames.
          See ``librosa.stft()``

      - kwargs
          Mel filterbank parameters
          See librosa.filters.mel() documentation for details.

    .. note:: One of either ``S`` or ``y, sr`` must be provided.
        If the pair y, sr is provided, the power spectrogram is computed.
        If S is provided, it is used as the spectrogram, and the parameters ``y, n_fft,
        hop_length`` are ignored.

    :returns:
      - S : np.ndarray
          Mel power spectrogram

    """

    # Compute the STFT
    if S is None:
        S       = np.abs(librosa.core.stft(y,   
                                            n_fft       =   n_fft, 
                                            hop_length  =   hop_length))**2
    else:
        n_fft = 2 * (S.shape[0] - 1)

    # Build a Mel filter
    mel_basis   = librosa.filters.mel(sr, n_fft, **kwargs)

    return np.dot(mel_basis, S)

#-- miscellaneous utilities --#
def delta(data, axis=-1, order=1, pad=True):
    '''Compute delta features.

    :usage:
        >>> # Compute MFCC deltas, delta-deltas
        >>> mfccs       = librosa.feature.mfcc(y=y, sr=sr)
        >>> delta_mfcc  = librosa.feature.delta(mfccs)
        >>> delta2_mfcc = librosa.feature.delta(mfccs, order=2)

    :parameters:
      - data      : np.ndarray, shape=(d, T)
          the input data matrix (eg, spectrogram)

      - axis      : int
          the axis along which to compute deltas.
          Default is -1 (columns).

      - order     : int
          the order of the difference operator.
          1 for first derivative, 2 for second, etc.

      - pad       : bool
          set to True to pad the output matrix to the original size.

    :returns:
      - delta_data   : np.ndarray
          delta matrix of ``data``.
    '''

    delta_x  = np.diff(data, n=order, axis=axis)

    if pad:
        padding         = [(0, 0)]  * data.ndim
        padding[axis]   = (order, 0)
        delta_x              = np.pad(delta_x, padding, mode='constant')

    return delta_x

def sync(data, frames, aggregate=None):
    """Synchronous aggregation of a feature matrix

    :usage:
        >>> # Beat-synchronous MFCCs
        >>> tempo, beats    = librosa.beat.beat_track(y, sr)
        >>> S               = librosa.feature.melspectrogram(y, sr, hop_length=64)
        >>> mfcc            = librosa.feature.mfcc(S=S)
        >>> mfcc_sync       = librosa.feature.sync(mfcc, beats)

        >>> # Use median-aggregation instead of mean
        >>> mfcc_sync       = librosa.feature.sync(mfcc, beats, aggregate=np.median)
        >>> # Or max aggregation
        >>> mfcc_sync       = librosa.feature.sync(mfcc, beats, aggregate=np.max)

    :parameters:
      - data      : np.ndarray, shape=(d, T)
          matrix of features
      - frames    : np.ndarray
          ordered array of frame segment boundaries
      - aggregate : function
          aggregation function (defualt: np.mean)

    :returns:
      - Y         : ndarray 
          ``Y[:, i] = aggregate(data[:, F[i-1]:F[i]], axis=1)``

    .. note:: In order to ensure total coverage, boundary points are added to frames

    .. note:: If synchronizing a feature matrix against beat tracker output, ensure
              that the frame numbers are properly aligned and use the same hop_length.

    """
    if data.ndim < 2:
        data = np.asarray([data])
    elif data.ndim > 2:
        raise ValueError('Synchronized data has ndim=%d, must be 1 or 2.' % data.ndim)

    if aggregate is None:
        aggregate = np.mean

    (dimension, n_frames) = data.shape

    frames      = np.unique(np.concatenate( ([0], frames, [n_frames]) ))

    if min(frames) < 0:
        raise ValueError('Negative frame index.')
    elif max(frames) > n_frames:
        raise ValueError('Frame index exceeds data length.')

    data_agg    = np.empty( (dimension, len(frames)-1), order='F')

    start       = frames[0]

    for (i, end) in enumerate(frames[1:]):
        data_agg[:, i] = aggregate(data[:, start:end], axis=1)
        start = end

    return data_agg

########NEW FILE########
__FILENAME__ = filters
#!/usr/bin/env python
"""Commonly used filter banks: DCT, Chroma, Mel, CQT"""

import numpy as np
import librosa

def dct(n_filts, n_input):
    """Discrete cosine transform basis

    :usage:
        >>> # Compute MFCCs
        >>> S           = librosa.melspectrogram(y, sr)
        >>> dct_filters = librosa.filters.dct(13, S.shape[0])
        >>> mfcc        = dct_filters.dot(librosa.logamplitude(S))

    :parameters:
      - n_filts   : int
          number of output components
      - n_input   : int
          number of input components

    :returns:
      - D         : np.ndarray, shape=(n_filts, n_input)
          DCT basis vectors

    """

    basis       = np.empty((n_filts, n_input))
    basis[0, :] = 1.0 / np.sqrt(n_input)

    samples     = np.arange(1, 2*n_input, 2) * np.pi / (2.0 * n_input)

    for i in xrange(1, n_filts):
        basis[i, :] = np.cos(i*samples) * np.sqrt(2.0/n_input)

    return basis

def mel(sr, n_fft, n_mels=128, fmin=0.0, fmax=None, htk=False):
    """Create a Filterbank matrix to combine FFT bins into Mel-frequency bins

    :usage:
        >>> mel_fb = librosa.filters.mel(22050, 2048)

        >>> # Or clip the maximum frequency to 8KHz
        >>> mel_fb = librosa.filters.mel(22050, 2048, fmax=8000)

    :parameters:
      - sr        : int
          sampling rate of the incoming signal
      - n_fft     : int
          number of FFT components
      - n_mels    : int
          number of Mel bands 
      - fmin      : float
          lowest frequency (in Hz) 
      - fmax      : float
          highest frequency (in Hz)
      - htk       : bool
          use HTK formula instead of Slaney

    :returns:
      - M         : np.ndarray, shape=(n_mels, 1+ n_fft/2)
          Mel transform matrix

    """

    if fmax is None:
        fmax = sr / 2.0

    # Initialize the weights
    size        = int(1 + n_fft / 2)
    n_mels      = int(n_mels)
    weights     = np.zeros( (n_mels, size) )

    # Center freqs of each FFT bin
    fftfreqs    = np.arange( size, dtype=float ) * sr / n_fft

    # 'Center freqs' of mel bands - uniformly spaced between limits
    freqs       = librosa.mel_frequencies(n_mels, fmin=fmin, fmax=fmax, htk=htk, extra=True)

    # Slaney-style mel is scaled to be approx constant energy per channel
    enorm       = 2.0 / (freqs[2:n_mels+2] - freqs[:n_mels])

    for i in xrange(n_mels):
        # lower and upper slopes for all bins
        lower   = (fftfreqs - freqs[i])     / (freqs[i+1] - freqs[i])
        upper   = (freqs[i+2] - fftfreqs)   / (freqs[i+2] - freqs[i+1])

        # .. then intersect them with each other and zero
        weights[i]   = np.maximum(0, np.minimum(lower, upper)) * enorm[i]
   
    return weights

def chroma(sr, n_fft, n_chroma=12, A440=440.0, ctroct=5.0, octwidth=2):
    """Create a Filterbank matrix to convert STFT to chroma

    :usage:
        >>> # Build a simple chroma filter bank
        >>> chroma_fb   = librosa.filters.chroma(22050, 4096)

        >>> # Use quarter-tones instead of semitones
        >>> chroma_fbq  = librosa.filters.chroma(22050, 4096, n_chroma=24)

        >>> # Equally weight all octaves
        >>> chroma_fb   = librosa.filters.chroma(22050, 4096, octwidth=None)

    :parameters:
      - sr        : int
          audio sampling rate
      - n_fft     : int
          FFT window size
      - n_chroma  : int
          number of chroma bins
      - A440      : float
          Reference frequency for A440
      - ctroct    : float
      - octwidth  : float or None
          These parameters specify a dominance window - Gaussian
          weighting centered on `ctroct` (in octs, re A0 = 27.5Hz) and
          with a gaussian half-width of `octwidth`.  
          Set `octwidth` to `None` to use a flat weighting.

    :returns:
      - wts       : ndarray, shape=(n_chroma, 1 + n_fft / 2) 
          Chroma filter matrix

    """

    wts         = np.zeros((n_chroma, n_fft))

    # Get the FFT bins, not counting the DC component
    frequencies = np.linspace(0, sr, n_fft, endpoint=False)[1:]

    fftfrqbins  = n_chroma * librosa.hz_to_octs(frequencies, A440)

    # make up a value for the 0 Hz bin = 1.5 octaves below bin 1
    # (so chroma is 50% rotated from bin 1, and bin width is broad)
    fftfrqbins = np.concatenate( (   [fftfrqbins[0] - 1.5 * n_chroma],
                                        fftfrqbins))

    binwidthbins = np.concatenate(
        (np.maximum(fftfrqbins[1:] - fftfrqbins[:-1], 1.0), [1]))

    D = np.tile(fftfrqbins, (n_chroma, 1))  \
        - np.tile(np.arange(0, n_chroma, dtype='d')[:, np.newaxis], 
        (1, n_fft))

    n_chroma2 = round(n_chroma / 2.0)

    # Project into range -n_chroma/2 .. n_chroma/2
    # add on fixed offset of 10*n_chroma to ensure all values passed to
    # rem are +ve
    D = np.remainder(D + n_chroma2 + 10*n_chroma, n_chroma) - n_chroma2

    # Gaussian bumps - 2*D to make them narrower
    wts = np.exp(-0.5 * (2*D / np.tile(binwidthbins, (n_chroma, 1)))**2)

    # normalize each column
    wts = librosa.util.normalize(wts, norm=2, axis=0)

    # Maybe apply scaling for fft bins
    if octwidth is not None:
        wts *= np.tile(
            np.exp(-0.5 * (((fftfrqbins/n_chroma - ctroct)/octwidth)**2)),
            (n_chroma, 1))

    # remove aliasing columns
    return wts[:, :(1 + n_fft/2)]

def logfrequency(sr, n_fft, bins_per_octave=12, tuning=0.0, fmin=None, fmax=None, spread=0.125):
    '''Approximate a constant-Q filterbank for a fixed-window STFT.
    
    Each filter is a log-normal window centered at the corresponding pitch frequency.
    
    :usage:
        >>> # Simple log frequency filters
        >>> logfs_fb = librosa.filters.logfrequency(22050, 4096)

        >>> # Use a narrower frequency range
        >>> logfs_fb = librosa.filters.logfrequency(22050, 4096, fmin=110, fmax=880)

        >>> # Use narrower filters for sparser response: 5% of a semitone
        >>> logfs_fb = librosa.filters.logfrequency(22050, 4096, spread=0.05)
        >>> # Or wider: 50% of a semitone
        >>> logfs_fb = librosa.filters.logfrequency(22050, 4096, spread=0.5)

    :parameters:
      - sr : int > 0
          audio sampling rate
        
      - n_fft : int > 0
          FFT window size
        
      - bins_per_octave : int > 0
          Number of bins per octave. Defaults to 12 (semitones).
        
      - tuning : None or float in [-0.5, +0.5]
          Tuning correction parameter, in fractions of a bin.
        
      - fmin : float > 0
          Minimum frequency bin. Defaults to ``C1 ~= 16.35``
        
      - fmax : float > 0
          Maximum frequency bin. Defaults to ``C9 = 4816.01``
        
      - spread : float > 0
          Spread of each filter, as a fraction of a bin.
        
    :returns:
      - C : np.ndarray, shape=(ceil(log(fmax/fmin)) * bins_per_octave, 1 + n_fft/2)
          CQT filter bank.
    '''
    
    if fmin is None:
        fmin = librosa.midi_to_hz(librosa.note_to_midi('C1'))
        
    if fmax is None:
        fmax = librosa.midi_to_hz(librosa.note_to_midi('C9'))
    
    # Apply tuning correction
    correction = 2.0**(float(tuning) / bins_per_octave)
    
    # How many bins can we get?
    n_filters = int(np.ceil(bins_per_octave * np.log2(float(fmax) / fmin)))
    
    # What's the shape parameter for our log-normal filters?
    sigma = float(spread) / bins_per_octave
    
    # Construct the output matrix
    basis = np.zeros( (n_filters, n_fft /2  + 1) )
    
    # Get log frequencies of bins
    log_freqs = np.log2(librosa.fft_frequencies(sr, n_fft)[1:])
                                
    for i in range(n_filters):
        # What's the center (median) frequency of this filter?
        center_freq = correction * fmin * (2.0**(float(i)/bins_per_octave))
        
        # Place a log-normal window around center_freq
        # We skip the sqrt(2*pi) normalization because it will wash out below anyway
        basis[i, 1:] = np.exp(-0.5 * ((log_freqs - np.log2(center_freq)) /sigma)**2 - np.log2(sigma) - log_freqs)
                                  
        # Normalize each filter
        c_norm = np.sqrt(np.sum(basis[i]**2))
        if c_norm > 0:
            basis[i] = basis[i] / c_norm
        
    return basis

def constant_q(sr, fmin=None, fmax=None, bins_per_octave=12, tuning=0.0, window=None, resolution=2, pad=False):
    '''Construct a constant-Q basis.

    :usage:
        >>> # Get the CQT basis for C1 to C9, standard tuning
        >>> basis   = librosa.filters.constant_q(22050)
        >>> CQT     = librosa.cqt(y, sr, basis=basis)
        
        >>> # Change the windowing function to Hanning instead of Hamming
        >>> basis   = librosa.filters.constant_q(22050, window=np.hanning)

        >>> # Use a longer window for each filter
        >>> basis   = librosa.filters.constant_q(22050, resolution=2)

    :parameters:
      - sr : int > 0
          Audio sampling rate

      - fmin : float > 0
          Minimum frequency bin. Defaults to ``C1 ~= 16.35``
        
      - fmax : float > 0
          Maximum frequency bin. Defaults to ``C9 = 4816.01``

      - bins_per_octave : int > 0
          Number of bins per octave

      - tuning : float in [-0.5, +0.5)
          Tuning deviation from A440 in fractions of a bin
      
      - window : function or None
          Windowing function to apply to filters. 
          If None, no window is applied.
          Default: np.hamming

      - resolution : float > 0
          Resolution of filter windows. Larger values use longer windows.

      - pad : boolean
          Zero-pad all filters to have a constant width (equal to the longest filter).

      .. note::
            @phdthesis{mcvicar2013,
              title  = {A machine learning approach to automatic chord extraction},
              author = {McVicar, M.},
              year   = {2013},
              school = {University of Bristol}}

    :returns:
      - filters : list of np.ndarray
          filters[i] is the time-domain representation of the i'th CQT basis.
    '''
    

    if fmin is None:
        fmin = librosa.midi_to_hz(librosa.note_to_midi('C1'))
        
    if fmax is None:
        fmax = librosa.midi_to_hz(librosa.note_to_midi('C9'))

    if window is None:
        window = np.hamming

    correction = 2.0**(float(tuning) / bins_per_octave)

    fmin       = correction * fmin
    fmax       = correction * fmax
    
    # Q should be capitalized here, so we suppress the name warning
    Q = float(resolution) / (2.0**(1./bins_per_octave) - 1) # pylint: disable=invalid-name
    
    # How many bins can we get?
    n_filters = int(np.ceil(bins_per_octave * np.log2(float(fmax) / fmin)))

    filters = []
    for i in np.arange(n_filters, dtype=float):
        
        # Length of this filter
        ilen = np.ceil(Q * sr / (fmin * 2.0**(i / bins_per_octave)))

        # Build the filter 
        win = np.exp(Q * 1j * np.linspace(0, 2 * np.pi, ilen, endpoint=False))

        # Apply the windowing function
        if window is not None:
            win = win * window(ilen) 

        # Normalize
        win = librosa.util.normalize(win, norm=2)
        
        filters.append(win)
    
    if pad:
        max_len = max(map(len, filters))
        
        for i in range(len(filters)):
            filters[i] = librosa.util.pad_center(filters[i], max_len)

    return filters

def cq_to_chroma(n_input, bins_per_octave=12, n_chroma=12, roll=0):
    '''Convert a Constant-Q basis to Chroma.

    :usage:
        >>> # Get a CQT, and wrap bins to chroma
        >>> CQT         = librosa.cqt(y, sr)
        >>> chroma_map  = librosa.filters.cq_to_chroma(CQT.shape[0])
        >>> chromagram  = chroma_map.dot(CQT)

    :parameters:
      - n_input : int > 0
          Number of input components (CQT bins)

      - bins_per_octave : int > 0
          How many bins per octave in the CQT

      - n_chroma : int > 0
          Number of output bins (per octave) in the chroma

      - roll : int
          Number of bins to offset the output by.
          For example, if the 0-bin of the CQT is C, and
          the desired 0-bin for the chroma is A, then roll=-3.

    :returns:
      - cq_to_chroma : np.ndarray, shape=(n_chroma, n_input)
          Transformation matrix: ``Chroma = np.dot(cq_to_chroma, CQT)``      
        
    :raises:
      - ValueError
          If n_input is not an integer multiple of n_chroma
    '''

    # How many fractional bins are we merging?
    n_merge = float(bins_per_octave) / n_chroma

    if np.mod(n_merge, 1) != 0:
        raise ValueError('Incompatible CQ merge: input bins must be an integer multiple of output bins.')

    # Tile the identity to merge fractional bins
    cq_to_ch = np.repeat(np.eye(n_chroma), n_merge, axis=1)

    # How many octaves are we repeating?
    n_octaves = np.ceil(np.float(n_input) / bins_per_octave)

    # Repeat and trim
    cq_to_ch = np.tile(cq_to_ch, n_octaves)[:, :n_input]

    # Apply the roll
    cq_to_ch = np.roll(cq_to_ch, -roll, axis=0)

    return cq_to_ch

########NEW FILE########
__FILENAME__ = onset
#!/usr/bin/env python
"""Onset detection"""

import numpy as np
import scipy
import scipy.signal

import librosa.core
import librosa.feature

def onset_detect(y=None, sr=22050, onset_envelope=None, hop_length=64, **kwargs):
    """Basic onset detector.  Locate note onset events by picking peaks in an
    onset strength envelope.

    See also: ``librosa.onset.onset_strength()``
        
    :usage:
        >>> # Get onset times from a signal
        >>> onset_frames    = librosa.onset.onset_detect(y=y, sr=sr, hop_length=64)
        >>> onset_times     = librosa.frames_to_time(onset_frames, sr, hop_length=64)

        >>> # Or use a pre-computed onset envelope
        >>> onsets          = librosa.onset.onset_strength(y, sr)
        >>> onset_frames    = librosa.onset.onset_detect(onset_envelope=onsets, sr=sr)

    :parameters:
      - y          : np.ndarray
          audio time series
    
      - sr         : int
          sampling rate of ``y``
    
      - onset_envelope     : np.ndarray
          (optional) pre-computed onset stength envelope
    
      - hop_length : int
          hop length (in samples)
      
      - kwargs  
          Parameters for peak picking
          
          See ``librosa.core.peak_pick()`` for details
 
      .. note:: One of either ``onset_envelope`` or ``y`` must be provided.
    
    
    :returns:
    
      - onsets : np.ndarray
          estimated frame numbers of onsets
    
    :raises:
      - ValueError
          if neither y nor onsets are provided
    
    .. note::
      If no onset strength could be detected, onset_detect returns an empty list.
    
    .. note::
      The peak_pick parameters were chosen by large-scale hyperparameter optimization over this dataset:
      https://github.com/CPJKU/onset_db
                
    """
    
    # First, get the frame->beat strength profile if we don't already have one
    if onset_envelope is None:
        if y is None:
            raise ValueError('Either "y" or "onsets" must be provided')
        onset_envelope  = onset_strength(y=y, sr=sr, hop_length=hop_length)

    # Do we have any onsets to grab?
    if not onset_envelope.any():
        return np.array([], dtype=np.int)
    
    # Normalize onset strength function to [0, 1] range
    # (a common normalization step to make the threshold more consistent)
    onset_envelope -= onset_envelope.min()
    onset_envelope /= onset_envelope.max()
    
    # These parameter settings found by large-scale search
    kwargs.setdefault('pre_max',    0.03*sr/hop_length )    # 30ms
    kwargs.setdefault('post_max',   0.0*sr/hop_length )     # 0ms
    kwargs.setdefault('pre_avg',    0.1*sr/hop_length )     # 100ms
    kwargs.setdefault('post_avg',   0.1*sr/hop_length )     # 100ms
    kwargs.setdefault('delta',      .06 )
    kwargs.setdefault('wait',       0.03*sr/hop_length )    # 30ms
    
    # Peak pick the onset envelope
    return librosa.core.peak_pick( onset_envelope, **kwargs )

def onset_strength(y=None, sr=22050, S=None, detrend=False, centering=True, feature=None, aggregate=None, **kwargs):
    """Spectral flux onset strength.

    Onset strength at time t is determined by:

    ``mean_f max(0, S[f, t+1] - S[f, t])``

    By default, if a time series is provided, S will be the log-power Mel spectrogram.

    :usage:
        >>> # Mean aggregation with Mel-scaled spectrogram
        >>> onsets = librosa.onset.onset_strength(y, sr)

        >>> # Median aggregation
        >>> onsets = librosa.onset.onset_strength(y, sr, aggregate=np.median)

        >>> # Log-frequency spectrogram instead of Mel
        >>> onsets = librosa.onset.onset_strength(y, sr, feature=librosa.feature.logfsgram)

        >>> # Or Mel spectrogram with customized options
        >>> onsets = librosa.onset.onset_strength(y, sr, n_mels=128, fmin=32, fmax=8000)

    :parameters:
      - y        : np.ndarray
          audio time-series

      - sr       : int
          sampling rate of ``y``

      - S        : np.ndarray 
          pre-computed (log-power) spectrogram
      
      - detrend : bool
          Filter the onset strength to remove 
    
      - centering : bool
          Shift the onset function by ``n_fft / (2 * hop_length)`` frames

      - feature : function
          Function for computing time-series features, eg, scaled spectrograms.
          By default, uses ``librosa.feature.melspectrogram``

      - aggregate : function
          Aggregation function to use when combining onsets
          at different frequency bins.
          Default: ``np.mean``

      - kwargs  
          Parameters to ``feature()``, if ``S`` is not provided.

    .. note:: if ``S`` is provided, then ``(y, sr)`` are optional.

    :returns:
      - onsets   : np.ndarray 
          vector of onset strengths

    :raises:
      - ValueError 
          if neither ``(y, sr)`` nor ``S`` are provided

    """

    if feature is None:
        feature = librosa.feature.melspectrogram

    if aggregate is None:
        aggregate = np.mean

    # First, compute mel spectrogram
    if S is None:
        if y is None:
            raise ValueError('One of "S" or "y" must be provided.')

        S   = np.abs(feature(y=y, sr=sr, **kwargs))

        # Convert to dBs
        S   = librosa.core.logamplitude(S)

    # Retrieve the n_fft and hop_length, 
    # or default values for onsets if not provided
    n_fft       = kwargs.get('n_fft', 2048)
    hop_length  = kwargs.get('hop_length', 64)

    # Compute first difference, include padding
    onsets  = librosa.feature.delta(S, order=1, axis=1)

    # Discard negatives (decreasing amplitude)
    onsets  = np.maximum(0.0, onsets)

    # Average over mel bands
    onsets  = aggregate(onsets, axis=0)

    # Counter-act framing effects. Shift the onsets by n_fft / hop_length
    if centering:
        onsets  = np.pad(onsets, (n_fft / (2 * hop_length), 0), mode='constant')

    # remove the DC component
    if detrend:
        onsets  = scipy.signal.lfilter([1.0, -1.0], [1.0, -0.99], onsets)

    return onsets


########NEW FILE########
__FILENAME__ = output
#!/usr/bin/env python
"""Output routines for audio and analysis"""

import csv

import numpy as np
import scipy
import scipy.io.wavfile

import librosa.core

def annotation(path, time_start, time_end, annotations=None, delimiter=',', fmt='%0.3f'):
    '''Save annotations in a 3-column format:
    ``
    time_start[0], time_end[0], annotations[0]\n
    time_start[1], time_end[1], annotations[0]\n
    time_start[2], time_end[2], annotations[0]\n
    ...
    ''
    This can be used for segment or chord annotations.

    :usage:
        >>> # Detect segment boundaries
        >>> boundaries = librosa.segment.agglomerative(data, k=10)
        >>> # Convert to time
        >>> boundary_times = librosa.frames_to_time(boundaries, sr=sr, 
                                                    hop_length=hop_length)
        >>> # Convert boundaries to start-ends
        >>> time_start, time_end = boundaries[:-1], boundaries[1:]
        >>> # Make some fake annotations
        >>> labels = ['Segment #%03d' % i for i in range(len(time_start))]
        >>> # Save the output
        >>> librosa.output.annotation('segments.csv', time_start, time_end,
                                      annotations=annotations)

    :parameters:
      - path : str
        path to save the output CSV file

      - time_start : list-like 
        array of starting times for annotations

      - time_end : list-like
        array of ending times for annotations

      - annotations : None or list-like
        optional list of annotation strings. ``annotations[i]`` applies to the time
        range ``time_start[i]`` to ``time_end[i]``

      - delimiter : str
          character to separate fields

      - fmt : str
          format-string for rendering time

    :raises:
      - ValueError
          if ``time_start`` and ``time_end`` have different length
      - ValueError
          if ``annotations`` is not ``None`` and length does not match ``time_start``
    '''

    if len(time_start) != len(time_end):
        raise ValueError('len(time_start) != len(time_end)')

    if annotations is not None and len(annotations) != len(time_start):
        raise ValueError('len(annotations) != len(time_start)')

    with open(path, 'w') as output_file:
        writer = csv.writer(output_file, delimiter=delimiter)

        if annotations is None:
            for t_s, t_e in zip(time_start, time_end): 
                writer.writerow([fmt % t_s, fmt % t_e])
        else:
            for t_s, t_e, lab in zip(time_start, time_end, annotations): 
                writer.writerow([fmt % t_s, fmt % t_e, lab])

def frames_csv(path, frames, sr=22050, hop_length=512, **kwargs):
    """Convert frames to time and store the output in CSV format.

    :usage:
        >>> tempo, beats = librosa.beat.beat_track(y, sr=sr, hop_length=64)
        >>> librosa.output.frames_csv('beat_times.csv', frames, sr=sr, hop_length=64)

    :parameters:
      - path : string
          path to save the output CSV file

      - frames : list-like of ints
          list of frame numbers for beat events
      
      - sr : int
          audio sampling rate
    
      - hop_length : int
          number of samples between success frames

      - kwargs 
          additional keyword arguments.  See ``librosa.output.times_csv``
    """

    times = librosa.frames_to_time(frames, sr=sr, hop_length=hop_length)

    times_csv(path, times, **kwargs)

def times_csv(path, times, annotations=None, delimiter=',', fmt='%0.3f'):
    """Save time steps as in CSV format.  This can be used to store the output
    of a beat-tracker or segmentation algorihtm.

    If only ``times`` are provided, the file will contain each value of ``times`` on a row:
      ``
      times[0]\n
      times[1]\n
      times[2]\n
      ...
      ``

    If ``annotations`` are also provided, the file will contain delimiter-separated values:
      ``
      times[0],annotations[0]\n
      times[1],annotations[1]\n
      times[2],annotations[2]\n
      ...
      ``

    :usage:
        >>> tempo, beats = librosa.beat.beat_track(y, sr=sr, hop_length=64)
        >>> times = librosa.frames_to_time(beats, sr=sr, hop_length=64)
        >>> librosa.output.times_csv('beat_times.csv', times)

    :parameters:
      - path : string
          path to save the output CSV file

      - times : list-like of floats
          list of frame numbers for beat events
      
      - annotations : None or list-like
          optional annotations for each time step

      - delimiter : str
          character to separate fields

      - fmt : str
          format-string for rendering time

    :raises:
      - ValueError
          if ``annotations`` is not ``None`` and length does not match ``times``
    """

    if annotations is not None and len(annotations) != len(times):
        raise ValueError('len(annotations) != len(times)')

    with open(path, 'w') as output_file:
        writer = csv.writer(output_file, delimiter=delimiter)

        if annotations is None:
            for t in times: 
                writer.writerow([fmt % t])
        else:
            for t, lab in zip(times, annotations):
                writer.writerow([(fmt % t), lab])

def write_wav(path, y, sr, normalize=True):
    """Output a time series as a .wav file

    :usage:
        >>> # Trim a signal to 5 seconds and save it back
        >>> y, sr = librosa.load('file.wav', duration=5)
        >>> librosa.output.write_wav('file_trim_5s.wav', y, sr)

    :parameters:
      - path : str 
          path to save the output wav file

      - y : np.ndarray    
          audio time series

      - sr : int
          sampling rate of ``y``

      - normalize : boolean
          turn normalization on or off
          
    """

    # normalize
    if normalize:
        wav = y / np.max(np.abs(y))
    else:
        wav = y
    
    # Scale up to pcm range
    #wav = (wav - wav.min()) * (1<<15) - (1<<15)
    wav = wav * 32767

    # Convert to 16bit int
    wav = wav.astype('<i2')

    # Save
    scipy.io.wavfile.write(path, sr, wav)

########NEW FILE########
__FILENAME__ = segment
#!/usr/bin/env python
"""Temporal segmentation utilities"""

import numpy as np
import scipy
import scipy.signal

import sklearn
import sklearn.cluster
import sklearn.feature_extraction

def stack_memory(data, n_steps=2, delay=1, trim=True):
    """Short-term history embedding.

    Each column ``data[:, i]`` is mapped to

    ``data[:,i] ->  [   data[:, i].T, data[:, i - delay].T ...  data[:, i - (n_steps-1)*delay].T ].T``


    :usage:
        >>> mfccs       = librosa.feature.mfcc(y=y, sr=sr)
        >>> mfcc_stack  = librosa.segment.stack_memory(mfccs)

    :parameters:
      - data : np.ndarray
          feature matrix (d-by-t)
      - n_steps : int > 0
          embedding dimension, the number of steps back in time to stack
      - delay : int > 0
          the number of columns to step
      - trim : bool
          Crop dimension to original number of columns

    :returns:
      - data_history : np.ndarray, shape=(d*m, t)
          data augmented with lagged copies of itself.
          
      .. note:: zeros are padded for the initial columns

    """

    t = data.shape[1]
    # Pad the end with zeros, which will roll to the front below
    data = np.pad(data, [(0, 0), (0, (n_steps-1) * delay)], mode='constant')

    history = data

    for i in range(1, n_steps):
        history = np.vstack([history, np.roll(data, i * delay, axis=1)])

    # Trim to original width
    if trim:
        history = history[:, :t]

    return history

def recurrence_matrix(data, k=None, width=1, metric='sqeuclidean', sym=False):
    '''Compute the binary recurrence matrix from a time-series.

    ``rec[i,j] == True`` <=> (``data[:,i]``, ``data[:,j]``) are k-nearest-neighbors and ``|i-j| >= width``

    :usage:
        >>> mfcc    = librosa.feature.mfcc(y=y, sr=sr)
        >>> R       = librosa.segment.recurrence_matrix(mfcc)

        >>> # Or fix the number of nearest neighbors to 5
        >>> R       = librosa.segment.recurrence_matrix(mfcc, k=5)

        >>> # Suppress neighbors within +- 7 samples
        >>> R       = librosa.segment.recurrence_matrix(mfcc, width=7)

        >>> # Use cosine similarity instead of Euclidean distance
        >>> R       = librosa.segment.recurrence_matrix(mfcc, metric='cosine')

        >>> # Require mutual nearest neighbors
        >>> R       = librosa.segment.recurrence_matrix(mfcc, sym=True)

    :parameters:
      - data : np.ndarray
          feature matrix (d-by-t)
      - k : int > 0 or None
          the number of nearest-neighbors for each sample
          Default: ``k = ceil(sqrt(t - 2 * width + 1))``
      - width : int > 0
          only link neighbors ``(data[:, i], data[:, j])`` if ``|i-j| >= width`` 
      - metric : see ``scipy.spatial.distance.pdist()``
          distance metric to use for nearest-neighbor calculation
      - sym : bool
          set ``sym=True`` to only link mutual nearest-neighbors

    :returns:
      - rec : np.ndarray, shape=(t,t), dtype=bool
          Binary recurrence matrix
    '''

    t = data.shape[1]

    if k is None:
        k = np.ceil(np.sqrt(t - 2 * width + 1))

    def _band_infinite():
        '''Suppress the diagonal+- of a distance matrix'''
        band       = np.empty( (t, t) )
        band[:]    = np.inf
        band[np.triu_indices_from(band, width)] = 0
        band[np.tril_indices_from(band, -width)] = 0

        return band

    # Build the distance matrix
    D = scipy.spatial.distance.squareform(
            scipy.spatial.distance.pdist(data.T, metric=metric))

    # Max out the diagonal band
    D = D + _band_infinite()

    # build the recurrence plot

    rec = np.zeros( (t, t), dtype=bool)

    # get the k nearest neighbors for each point
    for i in range(t):
        for j in np.argsort(D[i])[:k]:
            rec[i, j] = True

    # symmetrize
    if sym:
        rec = rec * rec.T

    return rec

def structure_feature(rec, pad=True, inverse=False):
    '''Compute the structure feature from a recurrence matrix.

    The i'th column of the recurrence matrix is shifted up by i.
    The resulting matrix is indexed horizontally by time,
    and vertically by lag.

    :usage:
        >>> # Build the structure feature over mfcc similarity
        >>> mfccs   = librosa.feature.mfcc(y=y, sr=sr)
        >>> R       = librosa.feature.recurrence_matrix(mfccs)
        >>> S       = librosa.feature.structure_feature(R)

        >>> # Invert the structure feature to get a recurrence matrix
        >>> R_hat   = librosa.feature.structure_feature(S, inverse=True)

    :parameters:
      - rec   : np.ndarray, shape=(t,t)
          recurrence matrix (see `librosa.segment.recurrence_matrix`)
      
      - pad : bool
          Pad the matrix with t rows of zeros to avoid looping.

      - inverse : bool
          Unroll the opposite direction. This is useful for converting
          structure features back into recurrence plots.

          .. note: Reversing with ``pad==True`` will truncate the inferred padding.

    :returns:
      - struct : np.ndarray
          ``struct[i, t]`` = the recurrence at time ``t`` with lag ``i``.

      .. note:: negative lag values are supported by wrapping to the end of the array.
    '''

    t = rec.shape[1]

    if pad and not inverse:
        # If we don't assume that the signal loops,
        # stack zeros underneath in the recurrence plot.
        struct = np.pad(rec, [(0, t), (0, 0)], mode='constant')
    else:
        struct = rec.copy()

    if inverse:
        direction = +1
    else:
        direction = -1

    for i in range(1, t):
        struct[:, i] = np.roll(struct[:, i], direction * i, axis=-1)

    if inverse and pad:
        struct = struct[:t]

    return struct

def agglomerative(data, k):
    """Bottom-up temporal segmentation.

    Use a temporally-constrained agglomerative clustering routine to partition
    ``data`` into ``k`` contiguous segments.

    :usage:
        >>> # Cluster by Mel spectrogram similarity
        >>> # Break into 32 segments
        >>> S                   = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)
        >>> boundary_frames     = librosa.segment.agglomerative(S, 32)
        >>> boundary_times      = librosa.frames_to_time(boundary_frames, sr=sr, hop_length=512)

    :parameters:
      - data     : np.ndarray    
          feature matrix (d-by-t)

      - k        : int > 0
          number of segments to produce

    :returns:
      - boundaries : np.ndarray, shape=(k,1)  
          left-boundaries (frame numbers) of detected segments

    """

    # Connect the temporal connectivity graph
    grid = sklearn.feature_extraction.image.grid_to_graph(  n_x=data.shape[1], 
                                                            n_y=1, 
                                                            n_z=1)

    # Instantiate the clustering object
    ward = sklearn.cluster.Ward(n_clusters=k, connectivity=grid)

    # Fit the model
    ward.fit(data.T)

    # Find the change points from the labels
    boundaries = [0]
    boundaries.extend(
        list(1 + np.nonzero(np.diff(ward.labels_))[0].astype(int)))
    return boundaries


########NEW FILE########
__FILENAME__ = util
#!/usr/bin/env python
"""Utility functions"""

import numpy as np
import os
import glob

from numpy.lib.stride_tricks import as_strided

def frame(y, frame_length=2048, hop_length=512):
    '''Slice a time series into overlapping frames.
    
    This implementation uses low-level stride manipulation to avoid
    redundant copies of the time series data.

    :usage:
        >>> # Load a file
        >>> y, sr = librosa.load('file.mp3')
        >>> # Extract 2048-sample frames from y with a hop of 64
        >>> y_frames = librosa.util.frame(y, frame_length=2048, hop_length=64)

    :parameters:
      - y : np.ndarray, ndim=1
        Time series to frame

      - frame_length : int > 0
        Length of the frame in samples

      - hop_length : int > 0
        Number of samples to hop between frames

    :returns:
      - y_frames : np.ndarray, shape=(frame_length, N_FRAMES)
        An array of frames sampled from ``y``:
        ``y_frames[i, j] == y[j * hop_length + i]``
    '''

    # Compute the number of frames that will fit. The end may get truncated.
    n_frames = 1 + int( (len(y) - frame_length) / hop_length)

    # Vertical stride is one sample
    # Horizontal stride is ``hop_length`` samples
    y_frames = as_strided(  y, 
                            shape=(frame_length, n_frames), 
                            strides=(y.itemsize, hop_length * y.itemsize))
    return y_frames

def pad_center(data, size, **kwargs):
    '''Wrapper for np.pad to automatically center a vector prior to padding.
    This is analogous to ``str.center()``

    :usage:
        >>> # Generate a window vector
        >>> window = scipy.signal.hann(256)
        >>> # Center and pad it out to length 1024
        >>> window = librosa.util.pad_center(window, 1024, mode='constant')

    :parameters:
        - data : np.ndarray, ndim=1
          Vector to be padded and centered 

        - size : int >= len(data)
          Length to pad ``data``

        - kwargs
          Additional keyword arguments passed to ``numpy.pad()``
    
    :returns:
        - data_padded : np.ndarray, ndim=1
          ``data`` centered and padded to length ``size``
    '''

    kwargs.setdefault('mode', 'constant')
    lpad = (size - len(data))/2
    return np.pad( data, (lpad, size - len(data) - lpad), **kwargs) 

def axis_sort(S, axis=-1, index=False, value=None): 
    '''Sort an array along its rows or columns.
    
    :usage:
        >>> # Visualize NMF output for a spectrogram S
        >>> # Sort the columns of W by peak frequency bin
        >>> W, H = librosa.decompose.decompose(S)
        >>> W_sort = librosa.util.axis_sort(W)

        >>> # Or sort by the lowest frequency bin
        >>> W_sort = librosa.util.axis_sort(W, value=np.argmin)

        >>> # Or sort the rows instead of the columns
        >>> W_sort_rows = librosa.util.axis_sort(W, axis=0)

        >>> # Get the sorting index also, and use it to permute the rows of H
        >>> W_sort, idx = librosa.util.axis_sort(W, index=True)
        >>> H_sort = H[index, :]
        >>> # np.dot(W_sort, H_sort) == np.dot(W, H)

    :parameters:
      - S : np.ndarray, ndim=2
        Matrix to sort
        
      - axis : int
        The axis along which to sort.  
        
        - ``axis=0`` to sort rows by peak column index
        - ``axis=1`` to sort columns by peak row index

      - index : boolean    
        If true, returns the index array as well as the permuted data.

      - value : function
        function to return the index corresponding to the sort order.
        Default: ``np.argmax``.

    :returns:
      - S_sort : np.ndarray
        ``S`` with the columns or rows permuted in sorting order
     
      - idx : np.ndarray (optional)
        If ``index == True``, the sorting index used to permute ``S``.

    :raises:
      - ValueError
        If ``S`` does not have 2 dimensions.
    '''
    
    if value is None:
        value = np.argmax

    if S.ndim != 2:
        raise ValueError('axis_sort is only defined for 2-dimensional arrays.')
        
    bin_idx = value(S, axis=np.mod(1-axis, S.ndim))
    idx     = np.argsort(bin_idx)
    
    if axis == 0:
        if index:
            return S[idx, :], idx
        else:
            return S[idx, :]
    else:
        if index:
            return S[:, idx], idx
        else:
            return S[:, idx]

def normalize(S, norm=np.inf, axis=0):
    '''Normalize the columns or rows of a matrix
    
    :parameters:
      - S : np.ndarray
        The matrix to normalize
      
      - norm : {inf, -inf, 0, float > 0}
        - ``inf``  : maximum absolute value
        - ``-inf`` : mininum absolute value
        - ``0``    : number of non-zeros
        - float  : corresponding l_p norm. See ``scipy.linalg.norm`` for details.
    
      - axis : int
        Axis along which to compute the norm.
        ``axis=0`` will normalize columns, ``axis=1`` will normalize rows.
      
    :returns: 
      - S_norm : np.ndarray
        Normalized matrix
      
    .. note::
        Columns/rows with length 0 will be left as zeros.
    '''
    
    # All norms only depend on magnitude, let's do that first
    mag = np.abs(S)
    
    if norm == np.inf:
        length = np.max(mag, axis=axis, keepdims=True)
        
    elif norm == -np.inf:
        length = np.min(mag, axis=axis, keepdims=True)
        
    elif norm == 0:
        length = np.sum(mag > 0, axis=axis, keepdims=True)
        
    elif np.issubdtype(type(norm), np.number) and norm > 0:
        length = np.sum(mag ** norm, axis=axis, keepdims=True)**(1./norm)
    else:
        raise ValueError('Unsupported norm value: ' + repr(norm))
        
    # Avoid div-by-zero
    length[length == 0] = 1.0
    
    return S / length

def find_files(directory, ext=None, recurse=True, case_sensitive=False, limit=None, offset=0):
    '''Get a sorted list of (audio) files in a directory or directory sub-tree.
    
    :usage:
       >>> # Get all audio files in a directory sub-tree
       >>> files = librosa.util.find_files('~/Music')
       
       >>> # Look only within a specific directory, not the sub-tree
       >>> files = librosa.util.find_files('~/Music', recurse=False)
       
       >>> # Only look for mp3 files
       >>> files = librosa.util.find_files('~/Music', ext='mp3')
       
       >>> # Or just mp3 and ogg
       >>> files = librosa.util.find_files('~/Music', ext=['mp3', 'ogg'])
       
       >>> # Only get the first 10 files
       >>> files = librosa.util.find_files('~/Music', limit=10)
       
       >>> # Or last 10 files
       >>> files = librosa.util.find_files('~/Music', offset=-10)
       
    :parameters:
      - directory : str
        Path to look for files
        
      - ext : str or list of str
        A file extension or list of file extensions to include in the search.
        Default: ``['aac', 'au', 'flac', 'm4a', 'mp3', 'ogg', 'wav']``
        
      - recurse : boolean
        If ``True``, then all subfolders of ``directory`` will be searched.
        Otherwise, only `directory` will be searched.
        
      - case_sensitive : boolean
        If ``False``, files matching upper-case version of extensions will be included.
        
      - limit : int >0 or None
        Return at most ``limit`` files. If ``None``, all files are returned.
        
      - offset : int
        Return files starting at ``offset`` within the list.
        Use negative values to offset from the end of the list.
        
    :returns:
      - files, list of str
        The list of audio files.
    '''
    
    def _get_files(D, extensions):
        '''Helper function to get files in a single directory'''

        # Expand out the directory
        D = os.path.abspath(os.path.expanduser(D))
        
        myfiles = []
        for sub_ext in extensions:
            globstr = os.path.join(D, '*' + os.path.extsep + sub_ext)
            myfiles.extend(glob.glob(globstr))
        
        return myfiles
            
    if ext is None:
        ext = ['aac', 'au', 'flac', 'm4a', 'mp3', 'ogg', 'wav']
        
    elif isinstance(ext, str):
        if not case_sensitive:
            ext = ext.lower()
        ext = [ext]
        
    # Generate upper-case versions
    if not case_sensitive:
        for i in range(len(ext)):
            ext.append(ext[i].upper())
    
    files = []
    
    if recurse:
        for walk in os.walk(directory):
            files.extend(_get_files(walk[0], ext))
    else:
        files = _get_files(directory, ext)
    
    files.sort()
    files = files[offset:]
    if limit is not None:
        files = files[:limit]
    
    return files

########NEW FILE########
__FILENAME__ = testLibrosaBeat
#!/usr/bin/env python
# CREATED:2013-03-11 18:14:30 by Brian McFee <brm2132@columbia.edu>
#  unit tests for librosa.beat

from nose.tools import nottest

import numpy
import librosa

from testLibrosaCore import files, load

def test_onset_strength():

    def __test(infile):
        DATA    = load(infile)

        # Compute onset envelope using the same spectrogram
        onsets  = librosa.onset.onset_strength(y=None, sr=8000, S=DATA['D'], centering=False, detrend=True)

        assert numpy.allclose(onsets[1:], DATA['onsetenv'][0])

        pass

    for infile in files('data/beat-onset-*.mat'):
        yield (__test, infile)
    pass

def test_tempo():
    def __test(infile):
        DATA    = load(infile)

        # Estimate tempo from the given onset envelope
        tempo   = librosa.beat.estimate_tempo(  DATA['onsetenv'][0],
                                                    sr=8000,
                                                    hop_length=32,
                                                    start_bpm=120.0)

        assert  (numpy.allclose(tempo, DATA['t'][0,0]) or 
                 numpy.allclose(tempo, DATA['t'][0,1]))
        pass

    for infile in files('data/beat-tempo-*.mat'):
        yield (__test, infile)
    pass

# Beat tracking test is no longer enabled due to librosa's various corrections
@nottest
def test_beat():
    def __test(infile):
        DATA    = load(infile)
        
        (bpm, beats) = librosa.beat.beat_track(y=None, sr=8000, hop_length=32,
                                               onsets=DATA['onsetenv'][0])

        beat_times = librosa.frames_to_time(beats, sr=8000, hop_length=32)
        print beat_times
        print DATA['beats']
        assert numpy.allclose(beat_times, DATA['beats'])
        pass
    for infile in files('data/beat-beat-*.mat'):
        yield (__test, infile)
    pass

########NEW FILE########
__FILENAME__ = testLibrosaCore
#!/usr/bin/env python
# CREATED:2013-03-08 15:25:18 by Brian McFee <brm2132@columbia.edu>
#  unit tests for librosa core (__init__.py)
#
# Run me as follows:
#   cd tests/
#   nosetests -v
#
# This test suite verifies that librosa core routines match (numerically) the output
# of various DPWE matlab implementations on a broad range of input parameters.
#
# All test data is generated by the Matlab script "makeTestData.m".
# Each test loads in a .mat file which contains the input and desired output for a given
# function.  The test then runs the librosa implementation and verifies the results
# against the desired output, typically via np.allclose().
#
# CAVEATS:
#   Currently, not all tests are exhaustive in parameter space.  This is typically due
#   restricted functionality of the librosa implementations.  Similarly, there is no
#   fuzz-testing here, so behavior on invalid inputs is not yet well-defined.
#

import librosa
import glob
import numpy as np
import scipy.io

from nose.tools import nottest

#-- utilities --#
def files(pattern):
    test_files = glob.glob(pattern)
    test_files.sort()
    return test_files

def load(infile):
    DATA = scipy.io.loadmat(infile, chars_as_strings=True)
    return DATA
#--           --#

#-- Tests     --#
def test_load():
    # Note: this does not test resampling.
    # That is a separate unit test.

    def __test(infile):
        DATA    = load(infile)
        (y, sr) = librosa.load(DATA['wavfile'][0], sr=None, mono=DATA['mono'])

        # Verify that the sample rate is correct
        assert sr == DATA['sr']

        assert np.allclose(y, DATA['y'])

    for infile in files('data/core-load-*.mat'):
        yield (__test, infile)
    pass

@nottest
def test_resample():

    def __test(infile):
        DATA    = load(infile)
        
        # load the wav file
        (y_in, sr_in) = librosa.load(DATA['wavfile'][0], sr=None, mono=True)

        # Resample it to the target rate
        y_out = librosa.resample(y_in, DATA['sr_in'], DATA['sr_out'])

        # Are we the same length?
        if len(y_out) == len(DATA['y_out']):
            # Is the data close?
            assert np.allclose(y_out, DATA['y_out'])
        elif len(y_out) == len(DATA['y_out']) - 1:
            assert (np.allclose(y_out, DATA['y_out'][:-1,0]) or
                    np.allclose(y_out, DATA['y_out'][1:,0]))
        elif len(y_out) == len(DATA['y_out']) + 1:
            assert (np.allclose(y_out[1:], DATA['y_out']) or
                    np.allclose(y_out[:-2], DATA['y_out']))
        else:
            assert False
        pass

    for infile in files('data/core-resample-*.mat'):
        yield (__test, infile)
    pass

def test_stft():

    def __test(infile):
        DATA    = load(infile)

        # Load the file
        (y, sr) = librosa.load(DATA['wavfile'][0], sr=None, mono=True)

        if DATA['hann_w'][0,0] == 0:
            # Set window to ones, swap back to nfft
            print 'Got hann_w == 0'
            window = np.ones
            win_length = None

        else:
            window = None
            win_length = DATA['hann_w'][0,0]

        # Compute the STFT
        D       = librosa.stft(y,       n_fft       =   DATA['nfft'][0,0].astype(int),
                                        hop_length  =   DATA['hop_length'][0,0].astype(int),
                                        win_length  =   win_length,
                                        window      =   window)

        assert  np.allclose(D, DATA['D'])   


    for infile in files('data/core-stft-*.mat'):
        yield (__test, infile)
    pass

def test_ifgram():

    def __test(infile):
        DATA    = load(infile)

        y, sr   = librosa.load(DATA['wavfile'][0], sr=None, mono=True)

        # Compute the IFgram
        F, D    = librosa.ifgram(y, n_fft       =   DATA['nfft'][0,0].astype(int),
                                    hop_length  =   DATA['hop_length'][0,0].astype(int),
                                    win_length  =   DATA['hann_w'][0,0].astype(int),
                                    sr          =   DATA['sr'][0,0].astype(int))

        # D fails to match here because of fftshift()
#         assert np.allclose(D, DATA['D'])
        assert np.allclose(F, DATA['F'], atol=1e-3)

    for infile in files('data/core-ifgram-*.mat'):
        yield (__test, infile)

    pass

def test_magphase():

    (y, sr) = librosa.load('data/test1_22050.wav')

    D = librosa.stft(y)

    S, P = librosa.magphase(D)

    assert np.allclose(S * P, D)

def test_istft():
    def __test(infile):
        DATA    = load(infile)

        if DATA['hann_w'][0,0] == 0:
            window      = np.ones
            win_length  = 2 * (DATA['D'].shape[0] - 1)
        else:
            window      = None
            win_length  = DATA['hann_w'][0,0]
            
        Dinv    = librosa.istft(DATA['D'],  hop_length  = DATA['hop_length'][0,0].astype(int),
                                            win_length  = win_length,
                                            window      = window)

        assert np.allclose(Dinv, DATA['Dinv'])

    for infile in files('data/core-istft-*.mat'):
        yield (__test, infile)
    pass


########NEW FILE########
__FILENAME__ = testLibrosaDecompose
#!/usr/bin/env python
# CREATED: 2013-10-06 22:31:29 by Dawen Liang <dl2771@columbia.edu>
# unit tests for librosa.decompose

import numpy as np
import librosa


def test_default_decompose():
    X = np.array([[1, 2, 3, 4, 5, 6], [1, 1, 1.2, 1, 0.8, 1]])
    (W, H) = librosa.decompose.decompose(X)
    assert np.allclose(X, W.dot(H), rtol=1e-2, atol=1e-2)
    pass

########NEW FILE########
__FILENAME__ = testLibrosaFeature
#!/usr/bin/env python
# CREATED:2013-03-08 15:25:18 by Brian McFee <brm2132@columbia.edu>
#  unit tests for librosa.feature (feature.py)
#
# Run me as follows:
#   cd tests/
#   nosetests -v
#
# This test suite verifies that librosa core routines match (numerically) the output
# of various DPWE matlab implementations on a broad range of input parameters.
#
# All test data is generated by the Matlab script "makeTestData.m".
# Each test loads in a .mat file which contains the input and desired output for a given
# function.  The test then runs the librosa implementation and verifies the results
# against the desired output, typically via numpy.allclose().
#
# CAVEATS:
#
#   Currently, not all tests are exhaustive in parameter space.  This is typically due
#   restricted functionality of the librosa implementations.  Similarly, there is no
#   fuzz-testing here, so behavior on invalid inputs is not yet well-defined.
#

import librosa
import os, glob
import numpy, scipy.io

from nose.tools import nottest

#-- utilities --#
def files(pattern):
    test_files = glob.glob(pattern)
    test_files.sort()
    return test_files

def load(infile):
    DATA = scipy.io.loadmat(infile, chars_as_strings=True)
    return DATA
#--           --#

#-- Tests     --#
def test_hz_to_mel():
    def __test_to_mel(infile):
        DATA    = load(infile)
        z       = librosa.hz_to_mel(DATA['f'], DATA['htk'])

        assert numpy.allclose(z, DATA['result'])
    
    for infile in files('data/feature-hz_to_mel-*.mat'):
        yield (__test_to_mel, infile)

    pass

def test_mel_to_hz():

    def __test_to_hz(infile):
        DATA    = load(infile)
        z       = librosa.mel_to_hz(DATA['f'], DATA['htk'])

        assert numpy.allclose(z, DATA['result'])
    
    for infile in files('data/feature-mel_to_hz-*.mat'):
        yield (__test_to_hz, infile)

    pass

def test_hz_to_octs():
    def __test_to_octs(infile):
        DATA    = load(infile)
        z       = librosa.hz_to_octs(DATA['f'])

        assert numpy.allclose(z, DATA['result'])

    for infile in files('data/feature-hz_to_octs-*.mat'):
        yield (__test_to_octs, infile)

    pass

def test_melfb():

    def __test(infile):
        DATA    = load(infile)

        wts = librosa.filters.mel( DATA['sr'][0], 
                                    DATA['nfft'][0], 
                                    n_mels  =   DATA['nfilts'][0],
                                    fmin    =   DATA['fmin'][0],
                                    fmax    =   DATA['fmax'][0],
                                    htk     =   DATA['htk'][0])

        # Our version only returns the real-valued part.
        # Pad out.
        wts = numpy.pad(wts, [ (0, 0), (0, int(DATA['nfft'][0]/2 - 1))], mode='constant')
                                
        assert wts.shape == DATA['wts'].shape

        assert numpy.allclose(wts, DATA['wts'])

    for infile in files('data/feature-melfb-*.mat'):
        yield (__test, infile)
    pass

def test_chromafb():

    def __test(infile):
        DATA    = load(infile)

        octwidth = DATA['octwidth'][0,0]
        if octwidth == 0:
            octwidth = None

        wts = librosa.filters.chroma( DATA['sr'][0,0], 
                                        DATA['nfft'][0,0], 
                                        DATA['nchroma'][0,0],
                                        A440    =   DATA['a440'][0,0],
                                        ctroct  =   DATA['ctroct'][0,0],
                                        octwidth=   octwidth)

        # Our version only returns the real-valued part.
        # Pad out.
        wts = numpy.pad(wts, [ (0, 0), (0, DATA['nfft'][0,0]/2 - 1)], mode='constant')
                                
        assert wts.shape == DATA['wts'].shape

        assert numpy.allclose(wts, DATA['wts'])

    for infile in files('data/feature-chromafb-*.mat'):
        yield (__test, infile)
    pass

########NEW FILE########
__FILENAME__ = testLibrosaUtil
#!/usr/bin/env python
# CREATED:2014-01-18 14:09:05 by Brian McFee <brm2132@columbia.edu>
# unit tests for util routines 

import numpy as np
import librosa

def test_frame():

    # Generate a random time series
    def __test(P):
        frame, hop = P

        y = np.random.randn(8000)
        y_frame = librosa.util.frame(y, frame_length=frame, hop_length=hop)

        for i in xrange(y_frame.shape[1]):
            assert np.allclose(y_frame[:, i], y[ i * hop : (i * hop + frame)])

    for frame in [256, 1024, 2048]:
        for hop_length in [64, 256, 512]:
            yield (__test, [frame, hop_length])

########NEW FILE########
